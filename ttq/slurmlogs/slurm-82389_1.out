sls-tesla-1 1
SLURM_JOBID=82390
SLURM_TASKID=1
[32m[0322 11:34:07 @logger.py:67][0m Existing log file 'train_log/fcn2_a_32_quant_ends_False_preload/log.log' backuped to 'train_log/fcn2_a_32_quant_ends_False_preload/log.log.0322-113407'
[32m[0322 11:34:07 @logger.py:74][0m Argv: ttq_run.py --model_name=fcn2 --quant_ends=False --load_ckpt=../dorefa/real/train_log/fcn2_w_4_a_32_quant_ends_False/checkpoint
[32m[0322 11:34:09 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0322 11:34:09 @ttq_run.py:140][0m Using 6 threads
('whole utterance size', 75290)
[32m[0322 11:34:09 @ttq_run.py:164][0m 18822 utterances per val epoch
[32m[0322 11:34:09 @ttq_run.py:165][0m Using host: sls-tesla-1
[32m[0322 11:34:09 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0322 11:34:09 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0322 11:34:09 @ttq_run.py:187][0m Using GPU: 1
[32m[0322 11:34:09 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0322 11:34:09 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0322 11:34:09 @training.py:108][0m Building graph for training tower 0 ...
[32m[0322 11:34:09 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0322 11:34:09 @ttq_run.py:68][0m Not ternarizing linear0/W
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear0/b
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear0/bn/beta
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear0/bn/gamma
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear0/bn/mean/EMA
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear0/bn/variance/EMA
[32m[0322 11:34:09 @registry.py:130][0m linear0 output: [None, 504]
[32m[0322 11:34:09 @registry.py:122][0m linear1 input: [None, 504]
[32m[0322 11:34:09 @ttq_run.py:71][0m Ternarizing weight linear1/W
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear1/Wp
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear1/Wn
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear1/b
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear1/bn/beta
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear1/bn/gamma
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear1/bn/mean/EMA
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear1/bn/variance/EMA
[32m[0322 11:34:09 @registry.py:130][0m linear1 output: [None, 504]
[32m[0322 11:34:09 @registry.py:122][0m linear2 input: [None, 504]
[32m[0322 11:34:09 @ttq_run.py:71][0m Ternarizing weight linear2/W
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear2/Wp
[32m[0322 11:34:09 @ttq_run.py:59][0m Not ternarizing linear2/Wn
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear2/b
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear2/bn/beta
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear2/bn/gamma
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear2/bn/mean/EMA
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear2/bn/variance/EMA
[32m[0322 11:34:10 @registry.py:130][0m linear2 output: [None, 504]
[32m[0322 11:34:10 @registry.py:122][0m linear3 input: [None, 504]
[32m[0322 11:34:10 @ttq_run.py:71][0m Ternarizing weight linear3/W
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear3/Wp
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear3/Wn
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear3/b
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear3/bn/beta
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear3/bn/gamma
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear3/bn/mean/EMA
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing linear3/bn/variance/EMA
[32m[0322 11:34:10 @registry.py:130][0m linear3 output: [None, 504]
[32m[0322 11:34:10 @registry.py:122][0m last_linear input: [None, 504]
[32m[0322 11:34:10 @ttq_run.py:65][0m Not ternarizing last_linear/W
[32m[0322 11:34:10 @ttq_run.py:59][0m Not ternarizing last_linear/b
[32m[0322 11:34:10 @registry.py:130][0m last_linear output: [None, 255]
[32m[0322 11:34:10 @ttq_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:34:10 @regularize.py:81][0m regularize_cost() found 11 tensors.
[32m[0322 11:34:10 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear1/Wp:0, linear1/Wn:0, linear2/W:0, linear2/Wp:0, linear2/Wn:0, linear3/W:0, linear3/Wp:0, linear3/Wn:0, last_linear/W:0
[32m[0322 11:34:10 @ttq_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0322 11:34:10 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/Wp:0        []                1
linear1/Wn:0        []                1
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/Wp:0        []                1
linear2/Wn:0        []                1
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/Wp:0        []                1
linear3/Wn:0        []                1
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=24, #params=1400877, size=5.34MB[0m
[32m[0322 11:34:10 @base.py:196][0m Setup callbacks graph ...
[32m[0322 11:34:11 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0322 11:34:11 @ttq_run.py:68][0m Not ternarizing linear0/W
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear0/b
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear0/bn/beta
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear0/bn/gamma
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear0/bn/mean/EMA
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear0/bn/variance/EMA
[32m[0322 11:34:11 @ttq_run.py:71][0m Ternarizing weight linear1/W
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear1/Wp
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear1/Wn
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear1/b
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear1/bn/beta
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear1/bn/gamma
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear1/bn/mean/EMA
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear1/bn/variance/EMA
[32m[0322 11:34:11 @ttq_run.py:71][0m Ternarizing weight linear2/W
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear2/Wp
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear2/Wn
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear2/b
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear2/bn/beta
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear2/bn/gamma
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear2/bn/mean/EMA
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear2/bn/variance/EMA
[32m[0322 11:34:11 @ttq_run.py:71][0m Ternarizing weight linear3/W
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear3/Wp
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear3/Wn
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear3/b
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear3/bn/beta
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear3/bn/gamma
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear3/bn/mean/EMA
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing linear3/bn/variance/EMA
[32m[0322 11:34:11 @ttq_run.py:65][0m Not ternarizing last_linear/W
[32m[0322 11:34:11 @ttq_run.py:59][0m Not ternarizing last_linear/b
[32m[0322 11:34:11 @ttq_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:34:11 @ttq_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0322 11:34:11 @collection.py:153][0m These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 47->65)
[32m[0322 11:34:11 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0322 11:34:11 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0322 11:34:11 @sessinit.py:89][0m [5m[31mWRN[0m The following variables are in the graph, but not found in the checkpoint: linear1/Wp, linear1/Wn, linear2/Wp, linear2/Wn, linear3/Wp, linear3/Wn
[32m[0322 11:34:12 @base.py:212][0m Creating the session ...
2018-03-22 11:34:12.407221: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-03-22 11:34:13.620997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:42:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-22 11:34:13.621048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:42:00.0, compute capability: 6.1)
[32m[0322 11:34:14 @base.py:220][0m Initializing the session ...
[32m[0322 11:34:14 @sessinit.py:116][0m Restoring checkpoint from ../dorefa/real/train_log/fcn2_w_4_a_32_quant_ends_False/model-5204430 ...
[32m[0322 11:34:15 @base.py:227][0m Graph Finalized.
[32m[0322 11:34:15 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0322 11:34:15 @steps.py:127][0m Start training with global_step=5204430
[32m[0322 11:34:22 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10279/173481[03:00<47:38,57.10it/s]  6%|6         |10854/173481[03:10<47:28,57.10it/s] 11%|#1        |19687/173481[06:00<46:58,54.57it/s] 12%|#1        |20204/173481[06:10<46:48,54.57it/s] 18%|#7        |30747/173481[09:00<41:09,57.80it/s] 18%|#8        |31426/173481[09:10<40:57,57.80it/s] 24%|##3       |41353/173481[12:00<37:44,58.35it/s] 24%|##4       |42130/173481[12:10<37:31,58.35it/s] 30%|##9       |51451/173481[15:00<35:33,57.20it/s] 30%|##9       |51990/173481[15:10<35:24,57.20it/s] 35%|###4      |60157/173481[18:00<36:02,52.40it/s] 35%|###4      |60636/173481[18:10<35:53,52.40it/s] 40%|###9      |68557/173481[21:00<35:25,49.37it/s] 40%|###9      |69228/173481[21:11<35:11,49.37it/s] 46%|####5     |79747/173481[24:00<28:23,55.03it/s] 46%|####6     |80460/173481[24:11<28:10,55.03it/s] 52%|#####1    |89479/173481[27:00<25:40,54.54it/s] 52%|#####1    |89970/173481[27:11<25:31,54.54it/s] 57%|#####7    |99285/173481[30:00<22:41,54.51it/s] 58%|#####7    |100044/173481[30:11<22:27,54.51it/s] 64%|######3   |110823/173481[33:00<17:43,58.92it/s] 64%|######4   |111603/173481[33:11<17:30,58.92it/s] 71%|#######   |122840/173481[36:00<13:29,62.59it/s] 71%|#######1  |123564/173481[36:11<13:17,62.59it/s] 77%|#######7  |134162/173481[39:00<10:26,62.75it/s] 78%|#######7  |134922/173481[39:12<10:14,62.75it/s] 84%|########4 |146197/173481[42:00<07:01,64.73it/s] 85%|########4 |147018/173481[42:12<06:48,64.73it/s] 91%|#########1|158465/173481[45:00<03:46,66.40it/s] 92%|#########1|159271/173481[45:12<03:34,66.40it/s] 98%|#########8|170239/173481[48:00<00:49,65.89it/s] 99%|#########8|171062/173481[48:12<00:36,65.89it/s]100%|##########|173481/173481[48:48<00:00,59.24it/s]
[32m[0322 12:23:11 @base.py:257][0m Epoch 1 (global_step 5377911) finished, time:2928.63 sec.
[32m[0322 12:23:11 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-5377911.
  0%|          |0/18822[00:00<?,?it/s] 86%|########6 |16266/18822[03:00<00:28,90.36it/s] 91%|#########1|17168/18822[03:10<00:18,90.36it/s]100%|##########|18822/18822[03:27<00:00,90.67it/s]
0
[32m[0322 12:26:39 @monitor.py:363][0m QueueInput/queue_size: 0.99225
[32m[0322 12:26:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 65.085
[32m[0322 12:26:39 @monitor.py:363][0m activation-summaries/output-rms: 0.035285
[32m[0322 12:26:39 @monitor.py:363][0m cross_entropy_loss: 3.966
[32m[0322 12:26:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.40079
[32m[0322 12:26:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.37446
[32m[0322 12:26:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.22475
[32m[0322 12:26:39 @monitor.py:363][0m linear1/Wn_0: 0.97224
[32m[0322 12:26:39 @monitor.py:363][0m linear1/Wp_0: 1.0278
[32m[0322 12:26:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.43665
[32m[0322 12:26:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.40938
[32m[0322 12:26:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.15397
[32m[0322 12:26:39 @monitor.py:363][0m linear2/Wn_0: 0.95095
[32m[0322 12:26:39 @monitor.py:363][0m linear2/Wp_0: 1.049
[32m[0322 12:26:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.44475
[32m[0322 12:26:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.41261
[32m[0322 12:26:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.14264
[32m[0322 12:26:39 @monitor.py:363][0m linear3/Wn_0: 1.0805
[32m[0322 12:26:39 @monitor.py:363][0m linear3/Wp_0: 0.91939
[32m[0322 12:26:39 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68719
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0485
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28838
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31423
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2921
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29003
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 12:26:39 @monitor.py:363][0m train-error-top1: 0.79389
[32m[0322 12:26:39 @monitor.py:363][0m val-error-top1: 0.80142
[32m[0322 12:26:39 @monitor.py:363][0m val-utt-error: 0.3693
[32m[0322 12:26:39 @monitor.py:363][0m validation_cost: 4.0988
[32m[0322 12:26:39 @monitor.py:363][0m wd_cost: 3.4967e-07
[32m[0322 12:26:39 @group.py:42][0m Callbacks took 207.964 sec in total. InferenceRunner: 207.620sec
[32m[0322 12:26:39 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12450/173481[03:00<38:48,69.17it/s]  8%|7         |13134/173481[03:10<38:38,69.17it/s] 14%|#4        |24502/173481[06:00<36:29,68.04it/s] 15%|#4        |25215/173481[06:10<36:19,68.04it/s] 21%|##1       |36592/173481[09:00<33:45,67.59it/s] 22%|##1       |37305/173481[09:10<33:34,67.59it/s] 28%|##7       |47784/173481[12:00<32:20,64.77it/s] 28%|##7       |48507/173481[12:10<32:09,64.77it/s] 35%|###4      |60191/173481[15:00<28:16,66.78it/s] 35%|###5      |60907/173481[15:10<28:05,66.78it/s] 41%|####1     |71884/173481[18:00<25:42,65.86it/s] 42%|####1     |72601/173481[18:10<25:31,65.86it/s] 48%|####8     |83548/173481[21:00<22:56,65.32it/s] 49%|####8     |84237/173481[21:11<22:46,65.32it/s] 54%|#####3    |93552/173481[24:00<22:10,60.06it/s] 54%|#####4    |94199/173481[24:11<22:00,60.06it/s] 61%|######    |105424/173481[27:00<18:02,62.87it/s] 61%|######1   |106168/173481[27:11<17:50,62.87it/s] 68%|######7   |117616/173481[30:00<14:16,65.21it/s] 68%|######8   |118439/173481[30:11<14:04,65.21it/s] 75%|#######4  |129988/173481[33:00<10:49,66.92it/s] 75%|#######5  |130793/173481[33:11<10:37,66.92it/s] 82%|########1 |141979/173481[36:00<07:51,66.77it/s] 82%|########2 |142755/173481[36:11<07:40,66.77it/s] 89%|########8 |153820/173481[39:00<04:56,66.27it/s] 89%|########9 |154617/173481[39:12<04:44,66.27it/s] 96%|#########5|165676/173481[42:00<01:58,66.05it/s] 96%|#########5|166452/173481[42:12<01:46,66.05it/s]100%|##########|173481/173481[43:57<00:00,65.77it/s]
[32m[0322 13:10:37 @base.py:257][0m Epoch 2 (global_step 5551392) finished, time:2637.81 sec.
[32m[0322 13:10:37 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-5551392.
[32m[0322 13:10:37 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 76%|#######6  |14314/18822[03:00<00:56,79.52it/s] 82%|########2 |15484/18822[03:10<00:41,79.52it/s]100%|##########|18822/18822[03:37<00:00,86.55it/s]
1
[32m[0322 13:14:15 @monitor.py:363][0m QueueInput/queue_size: 0.75272
[32m[0322 13:14:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 62.358
[32m[0322 13:14:15 @monitor.py:363][0m activation-summaries/output-rms: 0.034464
[32m[0322 13:14:15 @monitor.py:363][0m cross_entropy_loss: 3.1678
[32m[0322 13:14:15 @monitor.py:363][0m linear1/W_0_percent_n: 0.39668
[32m[0322 13:14:15 @monitor.py:363][0m linear1/W_0_percent_p: 0.36992
[32m[0322 13:14:15 @monitor.py:363][0m linear1/W_0_sparsity: 0.2334
[32m[0322 13:14:15 @monitor.py:363][0m linear1/Wn_0: 0.96864
[32m[0322 13:14:15 @monitor.py:363][0m linear1/Wp_0: 1.0314
[32m[0322 13:14:15 @monitor.py:363][0m linear2/W_0_percent_n: 0.43237
[32m[0322 13:14:15 @monitor.py:363][0m linear2/W_0_percent_p: 0.40532
[32m[0322 13:14:15 @monitor.py:363][0m linear2/W_0_sparsity: 0.1623
[32m[0322 13:14:15 @monitor.py:363][0m linear2/Wn_0: 0.96046
[32m[0322 13:14:15 @monitor.py:363][0m linear2/Wp_0: 1.0395
[32m[0322 13:14:15 @monitor.py:363][0m linear3/W_0_percent_n: 0.44217
[32m[0322 13:14:15 @monitor.py:363][0m linear3/W_0_percent_p: 0.40892
[32m[0322 13:14:15 @monitor.py:363][0m linear3/W_0_sparsity: 0.14892
[32m[0322 13:14:15 @monitor.py:363][0m linear3/Wn_0: 1.1076
[32m[0322 13:14:15 @monitor.py:363][0m linear3/Wp_0: 0.89231
[32m[0322 13:14:15 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68675
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0463
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28841
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31593
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29329
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29113
[32m[0322 13:14:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 13:14:15 @monitor.py:363][0m train-error-top1: 0.71805
[32m[0322 13:14:15 @monitor.py:363][0m val-error-top1: 0.71962
[32m[0322 13:14:15 @monitor.py:363][0m val-utt-error: 0.26416
[32m[0322 13:14:15 @monitor.py:363][0m validation_cost: 3.1737
[32m[0322 13:14:15 @monitor.py:363][0m wd_cost: 3.5077e-07
[32m[0322 13:14:15 @group.py:42][0m Callbacks took 218.257 sec in total. InferenceRunner: 217.470sec
[32m[0322 13:14:15 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12734/173481[03:00<37:52,70.74it/s]  8%|7         |13404/173481[03:10<37:42,70.74it/s] 14%|#4        |25068/173481[06:00<35:31,69.61it/s] 15%|#4        |25746/173481[06:10<35:22,69.61it/s] 21%|##1       |36985/173481[09:00<33:31,67.86it/s] 22%|##1       |37674/173481[09:10<33:21,67.86it/s] 28%|##8       |48748/173481[12:00<31:13,66.58it/s] 29%|##8       |49446/173481[12:10<31:02,66.58it/s] 35%|###5      |60727/173481[15:00<28:13,66.56it/s] 35%|###5      |61428/173481[15:10<28:03,66.56it/s] 42%|####1     |72738/173481[18:00<25:11,66.64it/s] 42%|####2     |73449/173481[18:10<25:00,66.64it/s] 49%|####8     |84753/173481[21:00<22:10,66.70it/s] 49%|####9     |85480/173481[21:11<21:59,66.70it/s] 55%|#####5    |96090/173481[24:00<19:54,64.79it/s] 56%|#####5    |96810/173481[24:11<19:43,64.79it/s] 62%|######2   |107941/173481[27:00<16:43,65.30it/s] 63%|######2   |108689/173481[27:11<16:32,65.30it/s] 69%|######9   |119865/173481[30:00<13:35,65.77it/s] 70%|######9   |120624/173481[30:11<13:23,65.77it/s] 76%|#######5  |131740/173481[33:00<10:33,65.87it/s] 76%|#######6  |132510/173481[33:11<10:22,65.87it/s] 82%|########2 |142742/173481[36:00<08:04,63.40it/s] 83%|########2 |143500/173481[36:11<07:52,63.40it/s] 91%|######### |157463/173481[39:00<03:44,71.43it/s] 92%|#########1|158832/173481[39:12<03:25,71.43it/s]100%|##########|173481/173481[41:41<00:00,69.36it/s]
[32m[0322 13:55:56 @base.py:257][0m Epoch 3 (global_step 5724873) finished, time:2501.07 sec.
[32m[0322 13:55:56 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-5724873.
[32m[0322 13:55:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:57<00:00,105.75it/s]
2
[32m[0322 13:58:55 @monitor.py:363][0m QueueInput/queue_size: 0.89295
[32m[0322 13:58:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 56.079
[32m[0322 13:58:55 @monitor.py:363][0m activation-summaries/output-rms: 0.035698
[32m[0322 13:58:55 @monitor.py:363][0m cross_entropy_loss: 2.6771
[32m[0322 13:58:55 @monitor.py:363][0m linear1/W_0_percent_n: 0.39281
[32m[0322 13:58:55 @monitor.py:363][0m linear1/W_0_percent_p: 0.36578
[32m[0322 13:58:55 @monitor.py:363][0m linear1/W_0_sparsity: 0.24141
[32m[0322 13:58:55 @monitor.py:363][0m linear1/Wn_0: 0.96832
[32m[0322 13:58:55 @monitor.py:363][0m linear1/Wp_0: 1.0317
[32m[0322 13:58:55 @monitor.py:363][0m linear2/W_0_percent_n: 0.42892
[32m[0322 13:58:55 @monitor.py:363][0m linear2/W_0_percent_p: 0.40218
[32m[0322 13:58:55 @monitor.py:363][0m linear2/W_0_sparsity: 0.1689
[32m[0322 13:58:55 @monitor.py:363][0m linear2/Wn_0: 0.97077
[32m[0322 13:58:55 @monitor.py:363][0m linear2/Wp_0: 1.0292
[32m[0322 13:58:55 @monitor.py:363][0m linear3/W_0_percent_n: 0.43927
[32m[0322 13:58:55 @monitor.py:363][0m linear3/W_0_percent_p: 0.40555
[32m[0322 13:58:55 @monitor.py:363][0m linear3/W_0_sparsity: 0.15519
[32m[0322 13:58:55 @monitor.py:363][0m linear3/Wn_0: 1.0981
[32m[0322 13:58:55 @monitor.py:363][0m linear3/Wp_0: 0.90181
[32m[0322 13:58:55 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68656
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0462
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28844
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31718
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29419
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29199
[32m[0322 13:58:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 13:58:55 @monitor.py:363][0m train-error-top1: 0.65094
[32m[0322 13:58:55 @monitor.py:363][0m val-error-top1: 0.67011
[32m[0322 13:58:55 @monitor.py:363][0m val-utt-error: 0.21911
[32m[0322 13:58:55 @monitor.py:363][0m validation_cost: 2.8507
[32m[0322 13:58:55 @monitor.py:363][0m wd_cost: 3.5167e-07
[32m[0322 13:58:55 @group.py:42][0m Callbacks took 178.831 sec in total. InferenceRunner: 178.004sec
[32m[0322 13:58:55 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12370/173481[03:00<39:04,68.72it/s]  8%|7         |13059/173481[03:10<38:54,68.72it/s] 14%|#4        |24298/173481[06:00<36:51,67.46it/s] 14%|#4        |24976/173481[06:10<36:41,67.46it/s] 21%|##        |36172/173481[09:00<34:18,66.70it/s] 21%|##1       |36867/173481[09:10<34:08,66.70it/s] 28%|##7       |48028/173481[12:00<31:32,66.28it/s] 28%|##8       |48731/173481[12:10<31:22,66.28it/s] 35%|###4      |59904/173481[15:00<28:37,66.13it/s] 35%|###5      |60729/173481[15:10<28:25,66.13it/s] 42%|####1     |72352/173481[18:00<24:55,67.61it/s] 42%|####2     |73077/173481[18:10<24:45,67.61it/s] 49%|####8     |84175/173481[21:00<22:20,66.63it/s] 49%|####8     |84909/173481[21:11<22:09,66.63it/s] 56%|#####5    |96879/173481[24:00<18:37,68.55it/s] 56%|#####6    |97611/173481[24:11<18:26,68.55it/s] 63%|######2   |108716/173481[27:00<16:04,67.12it/s] 63%|######3   |109512/173481[27:11<15:52,67.12it/s] 71%|#######   |122566/173481[30:00<11:50,71.70it/s] 71%|#######1  |123456/173481[30:11<11:37,71.70it/s] 78%|#######8  |135736/173481[33:00<08:41,72.41it/s] 79%|#######8  |136506/173481[33:11<08:30,72.41it/s] 85%|########5 |147586/173481[36:00<06:15,68.96it/s] 86%|########5 |148342/173481[36:11<06:04,68.96it/s] 92%|#########1|159563/173481[39:00<03:25,67.73it/s] 92%|#########2|160468/173481[39:12<03:12,67.73it/s]100%|##########|173481/173481[41:55<00:00,68.98it/s]
[32m[0322 14:40:50 @base.py:257][0m Epoch 4 (global_step 5898354) finished, time:2515.12 sec.
[32m[0322 14:40:50 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-5898354.
[32m[0322 14:40:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13927/18822[03:00<01:03,77.37it/s] 77%|#######6  |14415/18822[03:10<00:56,77.37it/s]100%|##########|18822/18822[04:31<00:00,69.40it/s]
3
[32m[0322 14:45:22 @monitor.py:363][0m QueueInput/queue_size: 0.90468
[32m[0322 14:45:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.415
[32m[0322 14:45:22 @monitor.py:363][0m activation-summaries/output-rms: 0.035204
[32m[0322 14:45:22 @monitor.py:363][0m cross_entropy_loss: 2.6046
[32m[0322 14:45:22 @monitor.py:363][0m linear1/W_0_percent_n: 0.39022
[32m[0322 14:45:22 @monitor.py:363][0m linear1/W_0_percent_p: 0.36339
[32m[0322 14:45:22 @monitor.py:363][0m linear1/W_0_sparsity: 0.24639
[32m[0322 14:45:22 @monitor.py:363][0m linear1/Wn_0: 0.9689
[32m[0322 14:45:22 @monitor.py:363][0m linear1/Wp_0: 1.0311
[32m[0322 14:45:22 @monitor.py:363][0m linear2/W_0_percent_n: 0.427
[32m[0322 14:45:22 @monitor.py:363][0m linear2/W_0_percent_p: 0.40018
[32m[0322 14:45:22 @monitor.py:363][0m linear2/W_0_sparsity: 0.17282
[32m[0322 14:45:22 @monitor.py:363][0m linear2/Wn_0: 0.9754
[32m[0322 14:45:22 @monitor.py:363][0m linear2/Wp_0: 1.0245
[32m[0322 14:45:22 @monitor.py:363][0m linear3/W_0_percent_n: 0.43714
[32m[0322 14:45:22 @monitor.py:363][0m linear3/W_0_percent_p: 0.4033
[32m[0322 14:45:22 @monitor.py:363][0m linear3/W_0_sparsity: 0.15956
[32m[0322 14:45:22 @monitor.py:363][0m linear3/Wn_0: 1.0913
[32m[0322 14:45:22 @monitor.py:363][0m linear3/Wp_0: 0.90863
[32m[0322 14:45:22 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68637
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0463
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28845
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31789
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2947
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29249
[32m[0322 14:45:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 14:45:22 @monitor.py:363][0m train-error-top1: 0.63175
[32m[0322 14:45:22 @monitor.py:363][0m val-error-top1: 0.64967
[32m[0322 14:45:22 @monitor.py:363][0m val-utt-error: 0.20295
[32m[0322 14:45:22 @monitor.py:363][0m validation_cost: 2.7212
[32m[0322 14:45:22 @monitor.py:363][0m wd_cost: 7.043e-08
[32m[0322 14:45:22 @group.py:42][0m Callbacks took 272.157 sec in total. InferenceRunner: 271.237sec
[32m[0322 14:45:22 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12488/173481[03:00<38:40,69.38it/s]  8%|7         |13146/173481[03:10<38:31,69.38it/s] 17%|#6        |29029/173481[06:00<30:27,79.06it/s] 17%|#7        |30172/173481[06:10<30:12,79.06it/s] 28%|##8       |48765/173481[09:00<22:37,91.87it/s] 29%|##8       |49909/173481[09:10<22:25,91.87it/s] 36%|###5      |62329/173481[12:00<22:22,82.79it/s] 36%|###6      |63114/173481[12:10<22:13,82.79it/s] 43%|####3     |75373/173481[15:00<21:09,77.28it/s] 44%|####3     |76155/173481[15:10<20:59,77.28it/s] 50%|#####     |86887/173481[18:00<20:37,69.99it/s] 50%|#####     |87467/173481[18:10<20:29,69.99it/s] 57%|#####7    |99356/173481[21:00<17:44,69.62it/s] 58%|#####7    |100156/173481[21:11<17:33,69.62it/s] 65%|######5   |113185/173481[24:00<13:45,73.05it/s] 66%|######5   |114018/173481[24:11<13:34,73.05it/s] 73%|#######2  |125989/173481[27:00<10:58,72.08it/s] 73%|#######3  |126774/173481[27:11<10:48,72.08it/s] 80%|#######9  |138481/173481[30:00<08:14,70.71it/s] 80%|########  |139252/173481[30:11<08:04,70.71it/s] 87%|########7 |151583/173481[33:00<05:05,71.73it/s] 88%|########7 |152352/173481[33:11<04:54,71.73it/s] 95%|#########5|165666/173481[36:00<01:44,74.84it/s] 96%|#########6|166836/173481[36:11<01:28,74.84it/s]100%|##########|173481/173481[37:38<00:00,76.80it/s]
[32m[0322 15:23:01 @base.py:257][0m Epoch 5 (global_step 6071835) finished, time:2258.77 sec.
[32m[0322 15:23:01 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-6071835.
[32m[0322 15:23:02 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 82%|########1 |15423/18822[03:01<00:39,85.18it/s] 91%|######### |17075/18822[03:20<00:20,85.18it/s]100%|##########|18822/18822[03:40<00:00,85.47it/s]
4
[32m[0322 15:26:42 @monitor.py:363][0m QueueInput/queue_size: 0.89863
[32m[0322 15:26:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.001
[32m[0322 15:26:42 @monitor.py:363][0m activation-summaries/output-rms: 0.038124
[32m[0322 15:26:42 @monitor.py:363][0m cross_entropy_loss: 2.381
[32m[0322 15:26:42 @monitor.py:363][0m linear1/W_0_percent_n: 0.3879
[32m[0322 15:26:42 @monitor.py:363][0m linear1/W_0_percent_p: 0.36053
[32m[0322 15:26:42 @monitor.py:363][0m linear1/W_0_sparsity: 0.25157
[32m[0322 15:26:42 @monitor.py:363][0m linear1/Wn_0: 0.97001
[32m[0322 15:26:42 @monitor.py:363][0m linear1/Wp_0: 1.03
[32m[0322 15:26:42 @monitor.py:363][0m linear2/W_0_percent_n: 0.4253
[32m[0322 15:26:42 @monitor.py:363][0m linear2/W_0_percent_p: 0.39829
[32m[0322 15:26:42 @monitor.py:363][0m linear2/W_0_sparsity: 0.17642
[32m[0322 15:26:42 @monitor.py:363][0m linear2/Wn_0: 0.97889
[32m[0322 15:26:42 @monitor.py:363][0m linear2/Wp_0: 1.021
[32m[0322 15:26:42 @monitor.py:363][0m linear3/W_0_percent_n: 0.43502
[32m[0322 15:26:42 @monitor.py:363][0m linear3/W_0_percent_p: 0.40065
[32m[0322 15:26:42 @monitor.py:363][0m linear3/W_0_sparsity: 0.16433
[32m[0322 15:26:42 @monitor.py:363][0m linear3/Wn_0: 1.0849
[32m[0322 15:26:42 @monitor.py:363][0m linear3/Wp_0: 0.91504
[32m[0322 15:26:42 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68621
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0464
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28847
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31855
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29519
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29299
[32m[0322 15:26:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 15:26:42 @monitor.py:363][0m train-error-top1: 0.60272
[32m[0322 15:26:42 @monitor.py:363][0m val-error-top1: 0.62342
[32m[0322 15:26:42 @monitor.py:363][0m val-utt-error: 0.18978
[32m[0322 15:26:42 @monitor.py:363][0m validation_cost: 2.5982
[32m[0322 15:26:42 @monitor.py:363][0m wd_cost: 7.0524e-08
[32m[0322 15:26:42 @group.py:42][0m Callbacks took 221.139 sec in total. InferenceRunner: 220.222sec
[32m[0322 15:26:42 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15248/173481[03:00<31:07,84.71it/s]  9%|9         |16053/173481[03:10<30:58,84.71it/s] 17%|#6        |29093/173481[06:00<29:50,80.62it/s] 17%|#7        |29925/173481[06:10<29:40,80.62it/s] 24%|##4       |42040/173481[09:00<28:49,76.02it/s] 25%|##4       |42705/173481[09:10<28:40,76.02it/s] 33%|###2      |56551/173481[12:00<24:54,78.25it/s] 33%|###3      |57492/173481[12:10<24:42,78.25it/s] 45%|####5     |78709/173481[15:00<16:30,95.68it/s] 46%|####6     |80062/173481[15:10<16:16,95.68it/s] 57%|#####6    |98045/173481[18:00<12:25,101.21it/s] 57%|#####6    |98706/173481[18:11<12:18,101.21it/s] 63%|######3   |109645/173481[21:00<13:30,78.75it/s] 64%|######3   |110913/173481[21:11<13:14,78.75it/s] 70%|#######   |121996/173481[24:00<11:42,73.33it/s] 71%|#######   |122709/173481[24:11<11:32,73.33it/s] 77%|#######6  |133247/173481[27:00<09:56,67.49it/s] 77%|#######7  |133851/173481[27:11<09:47,67.49it/s] 82%|########2 |142784/173481[30:00<08:37,59.36it/s] 83%|########2 |143427/173481[30:11<08:26,59.36it/s] 94%|#########3|162227/173481[33:00<02:26,76.62it/s] 94%|#########4|163752/173481[33:11<02:06,76.62it/s]100%|##########|173481/173481[34:29<00:00,83.83it/s]
[32m[0322 16:01:12 @base.py:257][0m Epoch 6 (global_step 6245316) finished, time:2069.53 sec.
[32m[0322 16:01:12 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-6245316.
[32m[0322 16:01:12 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:35<00:00,121.00it/s]
5
[32m[0322 16:03:48 @monitor.py:363][0m QueueInput/queue_size: 49.999
[32m[0322 16:03:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.879
[32m[0322 16:03:48 @monitor.py:363][0m activation-summaries/output-rms: 0.038095
[32m[0322 16:03:48 @monitor.py:363][0m cross_entropy_loss: 2.2656
[32m[0322 16:03:48 @monitor.py:363][0m linear1/W_0_percent_n: 0.38592
[32m[0322 16:03:48 @monitor.py:363][0m linear1/W_0_percent_p: 0.3587
[32m[0322 16:03:48 @monitor.py:363][0m linear1/W_0_sparsity: 0.25536
[32m[0322 16:03:48 @monitor.py:363][0m linear1/Wn_0: 0.97048
[32m[0322 16:03:48 @monitor.py:363][0m linear1/Wp_0: 1.0297
[32m[0322 16:03:48 @monitor.py:363][0m linear2/W_0_percent_n: 0.42419
[32m[0322 16:03:48 @monitor.py:363][0m linear2/W_0_percent_p: 0.39726
[32m[0322 16:03:48 @monitor.py:363][0m linear2/W_0_sparsity: 0.17854
[32m[0322 16:03:48 @monitor.py:363][0m linear2/Wn_0: 0.98153
[32m[0322 16:03:48 @monitor.py:363][0m linear2/Wp_0: 1.0186
[32m[0322 16:03:48 @monitor.py:363][0m linear3/W_0_percent_n: 0.43346
[32m[0322 16:03:48 @monitor.py:363][0m linear3/W_0_percent_p: 0.39876
[32m[0322 16:03:48 @monitor.py:363][0m linear3/W_0_sparsity: 0.16778
[32m[0322 16:03:48 @monitor.py:363][0m linear3/Wn_0: 1.0808
[32m[0322 16:03:48 @monitor.py:363][0m linear3/Wp_0: 0.91952
[32m[0322 16:03:48 @monitor.py:363][0m lr: 1.2207e-07
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68598
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0464
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31896
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29551
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29331
[32m[0322 16:03:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 16:03:48 @monitor.py:363][0m train-error-top1: 0.57554
[32m[0322 16:03:48 @monitor.py:363][0m val-error-top1: 0.60828
[32m[0322 16:03:48 @monitor.py:363][0m val-utt-error: 0.17161
[32m[0322 16:03:48 @monitor.py:363][0m validation_cost: 2.4946
[32m[0322 16:03:48 @monitor.py:363][0m wd_cost: 1.4115e-08
[32m[0322 16:03:48 @group.py:42][0m Callbacks took 156.361 sec in total. InferenceRunner: 155.570sec
[32m[0322 16:03:48 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21560/173481[03:00<21:08,119.77it/s] 13%|#3        |22845/173481[03:10<20:57,119.77it/s] 23%|##3       |40171/173481[06:00<20:01,110.97it/s] 24%|##3       |40836/173481[06:10<19:55,110.97it/s] 30%|###       |52639/173481[09:00<23:36,85.28it/s]  31%|###       |53388/173481[09:10<23:28,85.28it/s] 37%|###7      |64225/173481[12:00<24:49,73.36it/s] 37%|###7      |64986/173481[12:10<24:38,73.36it/s] 44%|####4     |77123/173481[15:00<22:09,72.50it/s] 45%|####4     |77814/173481[15:10<21:59,72.50it/s] 51%|#####     |88275/173481[18:00<21:15,66.81it/s] 51%|#####1    |89010/173481[18:10<21:04,66.81it/s] 58%|#####8    |100714/173481[21:00<17:51,67.94it/s] 58%|#####8    |101486/173481[21:11<17:39,67.94it/s] 65%|######4   |112411/173481[24:00<15:19,66.43it/s] 65%|######5   |113130/173481[24:11<15:08,66.43it/s] 72%|#######1  |124066/173481[27:00<12:33,65.58it/s] 72%|#######1  |124782/173481[27:11<12:22,65.58it/s] 78%|#######8  |135506/173481[30:00<09:48,64.55it/s] 79%|#######8  |136248/173481[30:11<09:36,64.55it/s] 85%|########4 |147336/173481[33:00<06:41,65.13it/s] 85%|########5 |148105/173481[33:11<06:29,65.13it/s] 92%|#########2|159829/173481[36:00<03:23,67.19it/s] 93%|#########2|160650/173481[36:11<03:10,67.19it/s]100%|#########9|172775/173481[39:00<00:10,69.47it/s]100%|##########|173481/173481[39:11<00:00,73.79it/s]
[32m[0322 16:42:59 @base.py:257][0m Epoch 7 (global_step 6418797) finished, time:2351.08 sec.
[32m[0322 16:42:59 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-6418797.
[32m[0322 16:43:00 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:18<00:00,135.89it/s]
6
[32m[0322 16:45:19 @monitor.py:363][0m QueueInput/queue_size: 0.82579
[32m[0322 16:45:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.142
[32m[0322 16:45:19 @monitor.py:363][0m activation-summaries/output-rms: 0.038214
[32m[0322 16:45:19 @monitor.py:363][0m cross_entropy_loss: 2.2631
[32m[0322 16:45:19 @monitor.py:363][0m linear1/W_0_percent_n: 0.38429
[32m[0322 16:45:19 @monitor.py:363][0m linear1/W_0_percent_p: 0.35677
[32m[0322 16:45:19 @monitor.py:363][0m linear1/W_0_sparsity: 0.25893
[32m[0322 16:45:19 @monitor.py:363][0m linear1/Wn_0: 0.97061
[32m[0322 16:45:19 @monitor.py:363][0m linear1/Wp_0: 1.0296
[32m[0322 16:45:19 @monitor.py:363][0m linear2/W_0_percent_n: 0.42313
[32m[0322 16:45:19 @monitor.py:363][0m linear2/W_0_percent_p: 0.39622
[32m[0322 16:45:19 @monitor.py:363][0m linear2/W_0_sparsity: 0.18065
[32m[0322 16:45:19 @monitor.py:363][0m linear2/Wn_0: 0.98293
[32m[0322 16:45:19 @monitor.py:363][0m linear2/Wp_0: 1.0174
[32m[0322 16:45:19 @monitor.py:363][0m linear3/W_0_percent_n: 0.43217
[32m[0322 16:45:19 @monitor.py:363][0m linear3/W_0_percent_p: 0.3973
[32m[0322 16:45:19 @monitor.py:363][0m linear3/W_0_sparsity: 0.17054
[32m[0322 16:45:19 @monitor.py:363][0m linear3/Wn_0: 1.0784
[32m[0322 16:45:19 @monitor.py:363][0m linear3/Wp_0: 0.92221
[32m[0322 16:45:19 @monitor.py:363][0m lr: 1.2207e-07
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68569
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0464
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31925
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29574
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29355
[32m[0322 16:45:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 16:45:19 @monitor.py:363][0m train-error-top1: 0.57733
[32m[0322 16:45:19 @monitor.py:363][0m val-error-top1: 0.59753
[32m[0322 16:45:19 @monitor.py:363][0m val-utt-error: 0.15588
[32m[0322 16:45:19 @monitor.py:363][0m validation_cost: 2.4184
[32m[0322 16:45:19 @monitor.py:363][0m wd_cost: 1.4121e-08
[32m[0322 16:45:19 @group.py:42][0m Callbacks took 139.800 sec in total. InferenceRunner: 138.523sec
[32m[0322 16:45:19 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19780/173481[03:00<23:19,109.85it/s] 12%|#1        |20447/173481[03:10<23:13,109.85it/s] 19%|#8        |32122/173481[06:00<27:54,84.41it/s]  19%|#8        |32822/173481[06:10<27:46,84.41it/s] 25%|##5       |44042/173481[09:00<29:04,74.22it/s] 26%|##5       |44679/173481[09:10<28:55,74.22it/s] 32%|###2      |55942/173481[12:00<28:01,69.92it/s] 33%|###2      |56640/173481[12:10<27:51,69.92it/s] 39%|###8      |67497/173481[15:00<26:23,66.93it/s] 39%|###9      |68205/173481[15:10<26:12,66.93it/s] 45%|####5     |78634/173481[18:00<24:35,64.29it/s] 46%|####5     |79311/173481[18:10<24:24,64.29it/s] 52%|#####1    |89864/173481[21:00<22:00,63.33it/s] 52%|#####2    |90549/173481[21:11<21:49,63.33it/s] 58%|#####8    |100997/173481[24:00<19:18,62.58it/s] 59%|#####8    |101721/173481[24:11<19:06,62.58it/s] 65%|######4   |112375/173481[27:00<16:11,62.89it/s] 65%|######5   |112803/173481[27:11<16:04,62.89it/s] 71%|#######   |123055/173481[30:00<13:45,61.06it/s] 71%|#######1  |123789/173481[30:11<13:33,61.06it/s] 78%|#######7  |134590/173481[33:00<10:21,62.53it/s] 78%|#######7  |135267/173481[33:11<10:11,62.53it/s] 82%|########2 |142461/173481[36:00<10:02,51.46it/s] 82%|########2 |142777/173481[36:11<09:56,51.46it/s] 88%|########8 |153072/173481[39:00<06:11,54.95it/s] 89%|########8 |153829/173481[39:11<05:57,54.95it/s] 94%|#########4|163930/173481[42:00<02:46,57.51it/s] 95%|#########4|164715/173481[42:12<02:32,57.51it/s]100%|##########|173481/173481[44:26<00:00,65.06it/s]
[32m[0322 17:29:45 @base.py:257][0m Epoch 8 (global_step 6592278) finished, time:2666.63 sec.
[32m[0322 17:29:46 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-6592278.
[32m[0322 17:29:46 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:39<00:00,118.19it/s]
7
[32m[0322 17:32:25 @monitor.py:363][0m QueueInput/queue_size: 0.80164
[32m[0322 17:32:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.376
[32m[0322 17:32:25 @monitor.py:363][0m activation-summaries/output-rms: 0.037988
[32m[0322 17:32:25 @monitor.py:363][0m cross_entropy_loss: 2.2432
[32m[0322 17:32:25 @monitor.py:363][0m linear1/W_0_percent_n: 0.38266
[32m[0322 17:32:25 @monitor.py:363][0m linear1/W_0_percent_p: 0.35499
[32m[0322 17:32:25 @monitor.py:363][0m linear1/W_0_sparsity: 0.26234
[32m[0322 17:32:25 @monitor.py:363][0m linear1/Wn_0: 0.97086
[32m[0322 17:32:25 @monitor.py:363][0m linear1/Wp_0: 1.0294
[32m[0322 17:32:25 @monitor.py:363][0m linear2/W_0_percent_n: 0.42262
[32m[0322 17:32:25 @monitor.py:363][0m linear2/W_0_percent_p: 0.39555
[32m[0322 17:32:25 @monitor.py:363][0m linear2/W_0_sparsity: 0.18183
[32m[0322 17:32:25 @monitor.py:363][0m linear2/Wn_0: 0.98399
[32m[0322 17:32:25 @monitor.py:363][0m linear2/Wp_0: 1.0163
[32m[0322 17:32:25 @monitor.py:363][0m linear3/W_0_percent_n: 0.43107
[32m[0322 17:32:25 @monitor.py:363][0m linear3/W_0_percent_p: 0.39599
[32m[0322 17:32:25 @monitor.py:363][0m linear3/W_0_sparsity: 0.17294
[32m[0322 17:32:25 @monitor.py:363][0m linear3/Wn_0: 1.0762
[32m[0322 17:32:25 @monitor.py:363][0m linear3/Wp_0: 0.92442
[32m[0322 17:32:25 @monitor.py:363][0m lr: 1.2207e-07
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68539
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0464
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28849
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31955
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29596
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29378
[32m[0322 17:32:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 17:32:25 @monitor.py:363][0m train-error-top1: 0.57708
[32m[0322 17:32:25 @monitor.py:363][0m val-error-top1: 0.59641
[32m[0322 17:32:25 @monitor.py:363][0m val-utt-error: 0.16178
[32m[0322 17:32:25 @monitor.py:363][0m validation_cost: 2.412
[32m[0322 17:32:25 @monitor.py:363][0m wd_cost: 1.4126e-08
[32m[0322 17:32:25 @group.py:42][0m Callbacks took 160.020 sec in total. InferenceRunner: 159.259sec
[32m[0322 17:32:25 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14217/173481[03:00<33:36,78.98it/s]  9%|8         |14883/173481[03:10<33:28,78.98it/s] 15%|#5        |26203/173481[06:00<33:58,72.25it/s] 16%|#5        |26898/173481[06:10<33:48,72.25it/s] 22%|##1       |38134/173481[09:00<32:37,69.14it/s] 22%|##2       |38916/173481[09:10<32:26,69.14it/s] 29%|##8       |49948/173481[12:00<30:34,67.34it/s] 29%|##9       |50646/173481[12:10<30:24,67.34it/s] 36%|###5      |61777/173481[15:00<27:59,66.51it/s] 36%|###6      |62477/173481[15:10<27:48,66.51it/s] 46%|####5     |79471/173481[18:02<19:52,78.85it/s] 47%|####6     |80958/173481[18:20<19:33,78.85it/s] 53%|#####3    |92329/173481[21:02<18:02,74.96it/s] 54%|#####3    |93528/173481[21:21<17:46,74.96it/s] 60%|######    |104097/173481[24:02<16:33,69.84it/s] 61%|######    |105312/173481[24:21<16:16,69.84it/s] 67%|######6   |115856/173481[27:02<14:13,67.51it/s] 67%|######7   |117078/173481[27:21<13:55,67.51it/s] 73%|#######3  |127217/173481[30:02<11:49,65.24it/s] 74%|#######4  |128426/173481[30:21<11:30,65.24it/s] 80%|########  |138985/173481[33:02<08:48,65.30it/s] 81%|########  |140225/173481[33:21<08:29,65.30it/s] 87%|########6 |150750/173481[36:02<05:47,65.33it/s] 88%|########7 |151968/173481[36:21<05:29,65.33it/s] 94%|#########3|162427/173481[39:02<02:49,65.09it/s] 94%|#########4|163650/173481[39:21<02:31,65.09it/s]100%|##########|173481/173481[41:54<00:00,68.98it/s]
[32m[0322 18:14:20 @base.py:257][0m Epoch 9 (global_step 6765759) finished, time:2514.83 sec.
[32m[0322 18:14:21 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-6765759.
[32m[0322 18:14:21 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 66%|######6   |12499/18822[03:00<01:31,69.44it/s] 70%|#######   |13254/18822[03:10<01:20,69.44it/s]100%|##########|18822/18822[04:27<00:00,70.33it/s]
8
[32m[0322 18:18:49 @monitor.py:363][0m QueueInput/queue_size: 0.71355
[32m[0322 18:18:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.388
[32m[0322 18:18:49 @monitor.py:363][0m activation-summaries/output-rms: 0.03807
[32m[0322 18:18:49 @monitor.py:363][0m cross_entropy_loss: 2.1748
[32m[0322 18:18:49 @monitor.py:363][0m linear1/W_0_percent_n: 0.38307
[32m[0322 18:18:49 @monitor.py:363][0m linear1/W_0_percent_p: 0.3553
[32m[0322 18:18:49 @monitor.py:363][0m linear1/W_0_sparsity: 0.26163
[32m[0322 18:18:49 @monitor.py:363][0m linear1/Wn_0: 0.97118
[32m[0322 18:18:49 @monitor.py:363][0m linear1/Wp_0: 1.0293
[32m[0322 18:18:49 @monitor.py:363][0m linear2/W_0_percent_n: 0.42251
[32m[0322 18:18:49 @monitor.py:363][0m linear2/W_0_percent_p: 0.3953
[32m[0322 18:18:49 @monitor.py:363][0m linear2/W_0_sparsity: 0.18218
[32m[0322 18:18:49 @monitor.py:363][0m linear2/Wn_0: 0.98482
[32m[0322 18:18:49 @monitor.py:363][0m linear2/Wp_0: 1.0159
[32m[0322 18:18:49 @monitor.py:363][0m linear3/W_0_percent_n: 0.43121
[32m[0322 18:18:49 @monitor.py:363][0m linear3/W_0_percent_p: 0.39588
[32m[0322 18:18:49 @monitor.py:363][0m linear3/W_0_sparsity: 0.17289
[32m[0322 18:18:49 @monitor.py:363][0m linear3/Wn_0: 1.0754
[32m[0322 18:18:49 @monitor.py:363][0m linear3/Wp_0: 0.92596
[32m[0322 18:18:49 @monitor.py:363][0m lr: 6.1035e-08
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68503
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28849
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31966
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29608
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29391
[32m[0322 18:18:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 18:18:49 @monitor.py:363][0m train-error-top1: 0.56105
[32m[0322 18:18:49 @monitor.py:363][0m val-error-top1: 0.6017
[32m[0322 18:18:49 @monitor.py:363][0m val-utt-error: 0.17437
[32m[0322 18:18:49 @monitor.py:363][0m validation_cost: 2.4597
[32m[0322 18:18:49 @monitor.py:363][0m wd_cost: 2.8251e-09
[32m[0322 18:18:49 @group.py:42][0m Callbacks took 268.398 sec in total. InferenceRunner: 267.642sec
[32m[0322 18:18:49 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12599/173481[03:00<38:18,69.99it/s]  8%|7         |13463/173481[03:10<38:06,69.99it/s] 15%|#5        |26371/173481[06:00<33:32,73.11it/s] 16%|#5        |27093/173481[06:10<33:22,73.11it/s] 22%|##2       |38542/173481[09:00<32:00,70.25it/s] 23%|##2       |39328/173481[09:10<31:49,70.25it/s] 29%|##9       |50880/173481[12:00<29:26,69.39it/s] 30%|##9       |51792/173481[12:10<29:13,69.39it/s] 37%|###6      |63333/173481[15:00<26:29,69.28it/s] 37%|###6      |64075/173481[15:10<26:19,69.28it/s] 43%|####3     |75232/173481[18:00<24:12,67.65it/s] 44%|####3     |75981/173481[18:10<24:01,67.65it/s] 50%|#####     |87471/173481[21:00<21:08,67.82it/s] 51%|#####     |88205/173481[21:11<20:57,67.82it/s] 60%|#####9    |103736/173481[24:00<15:00,77.48it/s] 61%|######    |105003/173481[24:11<14:43,77.48it/s] 72%|#######1  |124201/173481[27:00<08:54,92.16it/s] 72%|#######2  |125481/173481[27:11<08:40,92.16it/s] 80%|#######9  |138058/173481[30:00<07:02,83.88it/s] 80%|########  |138819/173481[30:11<06:53,83.88it/s] 86%|########6 |149966/173481[33:00<05:17,73.97it/s] 87%|########6 |150726/173481[33:11<05:07,73.97it/s] 93%|#########3|161788/173481[36:00<02:48,69.57it/s] 94%|#########3|162537/173481[36:11<02:37,69.57it/s]100%|##########|173481/173481[38:58<00:00,74.20it/s]
[32m[0322 18:57:47 @base.py:257][0m Epoch 10 (global_step 6939240) finished, time:2338.15 sec.
[32m[0322 18:57:47 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-6939240.
  0%|          |0/18822[00:00<?,?it/s] 63%|######3   |11941/18822[03:00<01:43,66.33it/s] 67%|######7   |12637/18822[03:10<01:33,66.33it/s]100%|##########|18822/18822[04:38<00:00,67.68it/s]
9
[32m[0322 19:02:25 @monitor.py:363][0m QueueInput/queue_size: 0.67816
[32m[0322 19:02:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.5
[32m[0322 19:02:25 @monitor.py:363][0m activation-summaries/output-rms: 0.037391
[32m[0322 19:02:25 @monitor.py:363][0m cross_entropy_loss: 2.2668
[32m[0322 19:02:25 @monitor.py:363][0m linear1/W_0_percent_n: 0.38239
[32m[0322 19:02:25 @monitor.py:363][0m linear1/W_0_percent_p: 0.35449
[32m[0322 19:02:25 @monitor.py:363][0m linear1/W_0_sparsity: 0.26311
[32m[0322 19:02:25 @monitor.py:363][0m linear1/Wn_0: 0.97147
[32m[0322 19:02:25 @monitor.py:363][0m linear1/Wp_0: 1.0291
[32m[0322 19:02:25 @monitor.py:363][0m linear2/W_0_percent_n: 0.42225
[32m[0322 19:02:25 @monitor.py:363][0m linear2/W_0_percent_p: 0.39504
[32m[0322 19:02:25 @monitor.py:363][0m linear2/W_0_sparsity: 0.18271
[32m[0322 19:02:25 @monitor.py:363][0m linear2/Wn_0: 0.98564
[32m[0322 19:02:25 @monitor.py:363][0m linear2/Wp_0: 1.0156
[32m[0322 19:02:25 @monitor.py:363][0m linear3/W_0_percent_n: 0.431
[32m[0322 19:02:25 @monitor.py:363][0m linear3/W_0_percent_p: 0.39542
[32m[0322 19:02:25 @monitor.py:363][0m linear3/W_0_sparsity: 0.17357
[32m[0322 19:02:25 @monitor.py:363][0m linear3/Wn_0: 1.0747
[32m[0322 19:02:25 @monitor.py:363][0m linear3/Wp_0: 0.92751
[32m[0322 19:02:25 @monitor.py:363][0m lr: 6.1035e-08
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68466
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28849
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31975
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29619
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29402
[32m[0322 19:02:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 19:02:25 @monitor.py:363][0m train-error-top1: 0.57885
[32m[0322 19:02:25 @monitor.py:363][0m val-error-top1: 0.5896
[32m[0322 19:02:25 @monitor.py:363][0m val-utt-error: 0.15599
[32m[0322 19:02:25 @monitor.py:363][0m validation_cost: 2.3697
[32m[0322 19:02:25 @monitor.py:363][0m wd_cost: 2.8248e-09
[32m[0322 19:02:25 @group.py:42][0m Callbacks took 278.416 sec in total. InferenceRunner: 278.114sec
[32m[0322 19:02:25 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21675/173481[03:00<21:00,120.42it/s] 13%|#3        |22912/173481[03:10<20:50,120.42it/s] 24%|##3       |41255/173481[06:00<19:16,114.30it/s] 24%|##4       |42282/173481[06:10<19:07,114.30it/s] 32%|###1      |55513/173481[09:00<21:00,93.57it/s]  32%|###2      |56310/173481[09:10<20:52,93.57it/s] 40%|###9      |69077/173481[12:00<20:50,83.48it/s] 40%|####      |69846/173481[12:10<20:41,83.48it/s] 47%|####7     |81961/173481[15:00<19:47,77.07it/s] 48%|####7     |82736/173481[15:10<19:37,77.07it/s] 55%|#####4    |94940/173481[18:00<17:34,74.50it/s] 55%|#####5    |95745/173481[18:10<17:23,74.50it/s] 62%|######2   |108178/173481[21:00<14:42,74.02it/s] 63%|######2   |108979/173481[21:11<14:31,74.02it/s] 70%|#######   |121580/173481[24:00<11:39,74.23it/s] 71%|#######   |122436/173481[24:11<11:27,74.23it/s] 78%|#######7  |134576/173481[27:00<08:51,73.20it/s] 78%|#######8  |135363/173481[27:11<08:40,73.20it/s] 85%|########4 |147403/173481[30:00<06:01,72.22it/s] 85%|########5 |148189/173481[30:11<05:50,72.22it/s] 92%|#########1|159277/173481[33:00<03:26,68.94it/s] 92%|#########2|160044/173481[33:11<03:14,68.94it/s] 99%|#########8|171175/173481[36:00<00:34,67.49it/s] 99%|#########9|171948/173481[36:11<00:22,67.49it/s]100%|##########|173481/173481[36:35<00:00,79.03it/s]
[32m[0322 19:39:00 @base.py:257][0m Epoch 11 (global_step 7112721) finished, time:2195.12 sec.
[32m[0322 19:39:01 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-7112721.
[32m[0322 19:39:01 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 80%|#######9  |14971/18822[03:00<00:46,83.17it/s] 86%|########5 |16186/18822[03:10<00:31,83.17it/s]100%|##########|18822/18822[03:32<00:00,88.46it/s]
10
[32m[0322 19:42:34 @monitor.py:363][0m QueueInput/queue_size: 0.40728
[32m[0322 19:42:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.459
[32m[0322 19:42:34 @monitor.py:363][0m activation-summaries/output-rms: 0.039075
[32m[0322 19:42:34 @monitor.py:363][0m cross_entropy_loss: 2.1857
[32m[0322 19:42:34 @monitor.py:363][0m linear1/W_0_percent_n: 0.38282
[32m[0322 19:42:34 @monitor.py:363][0m linear1/W_0_percent_p: 0.35491
[32m[0322 19:42:34 @monitor.py:363][0m linear1/W_0_sparsity: 0.26225
[32m[0322 19:42:34 @monitor.py:363][0m linear1/Wn_0: 0.97175
[32m[0322 19:42:34 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0322 19:42:34 @monitor.py:363][0m linear2/W_0_percent_n: 0.42226
[32m[0322 19:42:34 @monitor.py:363][0m linear2/W_0_percent_p: 0.39497
[32m[0322 19:42:34 @monitor.py:363][0m linear2/W_0_sparsity: 0.18276
[32m[0322 19:42:34 @monitor.py:363][0m linear2/Wn_0: 0.98634
[32m[0322 19:42:34 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0322 19:42:34 @monitor.py:363][0m linear3/W_0_percent_n: 0.43121
[32m[0322 19:42:34 @monitor.py:363][0m linear3/W_0_percent_p: 0.39546
[32m[0322 19:42:34 @monitor.py:363][0m linear3/W_0_sparsity: 0.17333
[32m[0322 19:42:34 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0322 19:42:34 @monitor.py:363][0m linear3/Wp_0: 0.92882
[32m[0322 19:42:34 @monitor.py:363][0m lr: 3.0518e-08
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68433
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28849
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29628
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29411
[32m[0322 19:42:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 19:42:34 @monitor.py:363][0m train-error-top1: 0.55937
[32m[0322 19:42:34 @monitor.py:363][0m val-error-top1: 0.58975
[32m[0322 19:42:34 @monitor.py:363][0m val-utt-error: 0.16204
[32m[0322 19:42:34 @monitor.py:363][0m validation_cost: 2.3689
[32m[0322 19:42:34 @monitor.py:363][0m wd_cost: 2.8245e-09
[32m[0322 19:42:34 @group.py:42][0m Callbacks took 213.610 sec in total. InferenceRunner: 212.795sec
[32m[0322 19:42:34 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14218/173481[03:00<33:36,78.97it/s]  9%|8         |14896/173481[03:10<33:28,78.97it/s] 16%|#5        |27364/173481[06:00<32:05,75.88it/s] 16%|#6        |28125/173481[06:10<31:55,75.88it/s] 25%|##5       |44146/173481[09:00<25:45,83.66it/s] 26%|##5       |44889/173481[09:10<25:37,83.66it/s] 33%|###2      |56911/173481[12:00<25:18,76.76it/s] 33%|###3      |57675/173481[12:10<25:08,76.76it/s] 40%|####      |70142/173481[15:00<22:56,75.10it/s] 41%|####      |70887/173481[15:10<22:46,75.10it/s] 48%|####7     |83066/173481[18:00<20:31,73.41it/s] 48%|####8     |83854/173481[18:10<20:20,73.41it/s] 56%|#####5    |96454/173481[21:00<17:22,73.88it/s] 56%|#####6    |97220/173481[21:11<17:12,73.88it/s] 63%|######3   |109405/173481[24:00<14:38,72.90it/s] 64%|######3   |110226/173481[24:11<14:27,72.90it/s] 71%|#######   |122746/173481[27:00<11:30,73.49it/s] 71%|#######1  |123604/173481[27:11<11:18,73.49it/s] 79%|#######8  |136558/173481[30:00<08:11,75.07it/s] 79%|#######9  |137355/173481[30:11<08:01,75.07it/s] 86%|########6 |149566/173481[33:00<05:24,73.64it/s] 87%|########6 |150426/173481[33:11<05:13,73.64it/s] 96%|#########5|166272/173481[36:00<01:27,82.12it/s] 96%|#########6|167259/173481[36:11<01:15,82.12it/s]100%|##########|173481/173481[37:38<00:00,76.80it/s]
[32m[0322 20:20:13 @base.py:257][0m Epoch 12 (global_step 7286202) finished, time:2258.96 sec.
[32m[0322 20:20:13 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-7286202.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,183.61it/s]
11
[32m[0322 20:21:56 @monitor.py:363][0m QueueInput/queue_size: 0.63641
[32m[0322 20:21:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 56.326
[32m[0322 20:21:56 @monitor.py:363][0m activation-summaries/output-rms: 0.039314
[32m[0322 20:21:56 @monitor.py:363][0m cross_entropy_loss: 2.1156
[32m[0322 20:21:56 @monitor.py:363][0m linear1/W_0_percent_n: 0.38272
[32m[0322 20:21:56 @monitor.py:363][0m linear1/W_0_percent_p: 0.35491
[32m[0322 20:21:56 @monitor.py:363][0m linear1/W_0_sparsity: 0.26233
[32m[0322 20:21:56 @monitor.py:363][0m linear1/Wn_0: 0.97186
[32m[0322 20:21:56 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0322 20:21:56 @monitor.py:363][0m linear2/W_0_percent_n: 0.42243
[32m[0322 20:21:56 @monitor.py:363][0m linear2/W_0_percent_p: 0.39495
[32m[0322 20:21:56 @monitor.py:363][0m linear2/W_0_sparsity: 0.18261
[32m[0322 20:21:56 @monitor.py:363][0m linear2/Wn_0: 0.98654
[32m[0322 20:21:56 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0322 20:21:56 @monitor.py:363][0m linear3/W_0_percent_n: 0.43117
[32m[0322 20:21:56 @monitor.py:363][0m linear3/W_0_percent_p: 0.39546
[32m[0322 20:21:56 @monitor.py:363][0m linear3/W_0_sparsity: 0.17337
[32m[0322 20:21:56 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0322 20:21:56 @monitor.py:363][0m linear3/Wp_0: 0.9292
[32m[0322 20:21:56 @monitor.py:363][0m lr: 3.0518e-08
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68414
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28849
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31984
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2963
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29413
[32m[0322 20:21:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 20:21:56 @monitor.py:363][0m train-error-top1: 0.54482
[32m[0322 20:21:56 @monitor.py:363][0m val-error-top1: 0.58846
[32m[0322 20:21:56 @monitor.py:363][0m val-utt-error: 0.16125
[32m[0322 20:21:56 @monitor.py:363][0m validation_cost: 2.3771
[32m[0322 20:21:56 @monitor.py:363][0m wd_cost: 5.6481e-10
[32m[0322 20:21:56 @group.py:42][0m Callbacks took 102.925 sec in total. InferenceRunner: 102.526sec
[32m[0322 20:21:56 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13728/173481[03:00<34:54,76.27it/s]  8%|8         |14456/173481[03:10<34:45,76.27it/s] 16%|#6        |28015/173481[06:00<31:10,77.78it/s] 17%|#6        |28765/173481[06:10<31:00,77.78it/s] 23%|##3       |40477/173481[09:00<30:15,73.26it/s] 24%|##3       |41250/173481[09:10<30:05,73.26it/s] 31%|###       |53461/173481[12:00<27:31,72.69it/s] 31%|###1      |54245/173481[12:10<27:20,72.69it/s] 38%|###8      |66668/173481[15:00<24:22,73.03it/s] 39%|###8      |67530/173481[15:10<24:10,73.03it/s] 46%|####6     |79892/173481[18:00<21:17,73.24it/s] 47%|####6     |80682/173481[18:10<21:06,73.24it/s] 53%|#####3    |92155/173481[21:00<19:12,70.59it/s] 54%|#####3    |92910/173481[21:11<19:01,70.59it/s] 60%|######    |104909/173481[24:00<16:09,70.72it/s] 61%|######    |105718/173481[24:11<15:58,70.72it/s] 68%|######7   |117505/173481[27:00<13:15,70.34it/s] 68%|######8   |118224/173481[27:11<13:05,70.34it/s] 75%|#######4  |129806/173481[30:00<10:30,69.32it/s] 75%|#######5  |130560/173481[30:11<10:19,69.32it/s] 82%|########1 |142243/173481[33:00<07:31,69.20it/s] 82%|########2 |142992/173481[33:11<07:20,69.20it/s] 89%|########9 |154947/173481[36:00<04:25,69.88it/s] 90%|########9 |155749/173481[36:11<04:13,69.88it/s] 97%|#########6|167523/173481[39:00<01:25,69.87it/s] 97%|#########7|168306/173481[39:11<01:14,69.87it/s]100%|##########|173481/173481[40:24<00:00,71.57it/s]
[32m[0322 21:02:20 @base.py:257][0m Epoch 13 (global_step 7459683) finished, time:2424.04 sec.
[32m[0322 21:02:20 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-7459683.
[32m[0322 21:02:21 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:23<00:00,131.62it/s]
12
[32m[0322 21:04:44 @monitor.py:363][0m QueueInput/queue_size: 0.33809
[32m[0322 21:04:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.541
[32m[0322 21:04:44 @monitor.py:363][0m activation-summaries/output-rms: 0.038807
[32m[0322 21:04:44 @monitor.py:363][0m cross_entropy_loss: 2.1527
[32m[0322 21:04:44 @monitor.py:363][0m linear1/W_0_percent_n: 0.38278
[32m[0322 21:04:44 @monitor.py:363][0m linear1/W_0_percent_p: 0.35479
[32m[0322 21:04:44 @monitor.py:363][0m linear1/W_0_sparsity: 0.2624
[32m[0322 21:04:44 @monitor.py:363][0m linear1/Wn_0: 0.97198
[32m[0322 21:04:44 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0322 21:04:44 @monitor.py:363][0m linear2/W_0_percent_n: 0.42221
[32m[0322 21:04:44 @monitor.py:363][0m linear2/W_0_percent_p: 0.39485
[32m[0322 21:04:44 @monitor.py:363][0m linear2/W_0_sparsity: 0.18291
[32m[0322 21:04:44 @monitor.py:363][0m linear2/Wn_0: 0.98674
[32m[0322 21:04:44 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0322 21:04:44 @monitor.py:363][0m linear3/W_0_percent_n: 0.43114
[32m[0322 21:04:44 @monitor.py:363][0m linear3/W_0_percent_p: 0.39525
[32m[0322 21:04:44 @monitor.py:363][0m linear3/W_0_sparsity: 0.17359
[32m[0322 21:04:44 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0322 21:04:44 @monitor.py:363][0m linear3/Wp_0: 0.92962
[32m[0322 21:04:44 @monitor.py:363][0m lr: 3.0518e-08
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68393
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28849
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31984
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29415
[32m[0322 21:04:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 21:04:44 @monitor.py:363][0m train-error-top1: 0.55504
[32m[0322 21:04:44 @monitor.py:363][0m val-error-top1: 0.58541
[32m[0322 21:04:44 @monitor.py:363][0m val-utt-error: 0.15551
[32m[0322 21:04:44 @monitor.py:363][0m validation_cost: 2.3543
[32m[0322 21:04:44 @monitor.py:363][0m wd_cost: 5.6472e-10
[32m[0322 21:04:44 @group.py:42][0m Callbacks took 143.763 sec in total. InferenceRunner: 143.015sec
[32m[0322 21:04:44 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s] 13%|#3        |22750/173481[03:00<19:52,126.38it/s] 14%|#3        |23625/173481[03:10<19:45,126.38it/s] 21%|##1       |36678/173481[06:00<23:45,95.99it/s]  22%|##1       |37456/173481[06:10<23:37,95.99it/s] 28%|##8       |49420/173481[09:00<25:22,81.48it/s] 29%|##8       |50130/173481[09:10<25:13,81.48it/s] 36%|###5      |61627/173481[12:00<25:11,74.02it/s] 36%|###5      |62319/173481[12:10<25:01,74.02it/s] 42%|####2     |73534/173481[15:00<23:50,69.86it/s] 43%|####2     |74235/173481[15:10<23:40,69.86it/s] 49%|####9     |85186/173481[18:00<21:54,67.19it/s] 50%|####9     |85893/173481[18:10<21:43,67.19it/s] 56%|#####6    |97150/173481[21:00<19:02,66.82it/s] 56%|#####6    |97870/173481[21:10<18:51,66.82it/s] 63%|######2   |108952/173481[24:00<16:15,66.18it/s] 63%|######3   |109693/173481[24:11<16:03,66.18it/s] 70%|######9   |120849/173481[27:00<13:15,66.14it/s] 70%|#######   |121599/173481[27:11<13:04,66.14it/s] 77%|#######6  |132790/173481[30:00<10:14,66.23it/s] 77%|#######6  |133527/173481[30:11<10:03,66.23it/s] 83%|########3 |144790/173481[33:00<07:11,66.44it/s] 84%|########3 |145545/173481[33:11<07:00,66.44it/s] 90%|######### |156795/173481[36:00<04:10,66.57it/s] 91%|######### |157558/173481[36:11<03:59,66.57it/s] 97%|#########7|168766/173481[39:00<01:10,66.53it/s] 98%|#########7|169528/173481[39:11<00:59,66.53it/s]100%|##########|173481/173481[40:11<00:00,71.94it/s]
[32m[0322 21:44:55 @base.py:257][0m Epoch 14 (global_step 7633164) finished, time:2411.41 sec.
[32m[0322 21:44:55 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-7633164.
[32m[0322 21:44:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 65%|######4   |12202/18822[03:00<01:37,67.79it/s] 68%|######8   |12892/18822[03:10<01:27,67.79it/s]100%|##########|18822/18822[04:12<00:00,74.60it/s]
13
[32m[0322 21:49:09 @monitor.py:363][0m QueueInput/queue_size: 0.61325
[32m[0322 21:49:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.815
[32m[0322 21:49:09 @monitor.py:363][0m activation-summaries/output-rms: 0.03835
[32m[0322 21:49:09 @monitor.py:363][0m cross_entropy_loss: 2.1512
[32m[0322 21:49:09 @monitor.py:363][0m linear1/W_0_percent_n: 0.38259
[32m[0322 21:49:09 @monitor.py:363][0m linear1/W_0_percent_p: 0.35476
[32m[0322 21:49:09 @monitor.py:363][0m linear1/W_0_sparsity: 0.26257
[32m[0322 21:49:09 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0322 21:49:09 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0322 21:49:09 @monitor.py:363][0m linear2/W_0_percent_n: 0.4222
[32m[0322 21:49:09 @monitor.py:363][0m linear2/W_0_percent_p: 0.3948
[32m[0322 21:49:09 @monitor.py:363][0m linear2/W_0_sparsity: 0.18298
[32m[0322 21:49:09 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0322 21:49:09 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0322 21:49:09 @monitor.py:363][0m linear3/W_0_percent_n: 0.43097
[32m[0322 21:49:09 @monitor.py:363][0m linear3/W_0_percent_p: 0.39518
[32m[0322 21:49:09 @monitor.py:363][0m linear3/W_0_sparsity: 0.17382
[32m[0322 21:49:09 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0322 21:49:09 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0322 21:49:09 @monitor.py:363][0m lr: 1.5259e-08
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68381
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31985
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29634
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29416
[32m[0322 21:49:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 21:49:09 @monitor.py:363][0m train-error-top1: 0.55167
[32m[0322 21:49:09 @monitor.py:363][0m val-error-top1: 0.60844
[32m[0322 21:49:09 @monitor.py:363][0m val-utt-error: 0.19647
[32m[0322 21:49:09 @monitor.py:363][0m validation_cost: 2.4831
[32m[0322 21:49:09 @monitor.py:363][0m wd_cost: 5.6465e-10
[32m[0322 21:49:09 @group.py:42][0m Callbacks took 253.485 sec in total. InferenceRunner: 252.334sec
[32m[0322 21:49:09 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13981/173481[03:00<34:13,77.66it/s]  9%|8         |14892/173481[03:10<34:02,77.66it/s] 16%|#5        |26893/173481[06:00<32:45,74.57it/s] 16%|#5        |27576/173481[06:10<32:36,74.57it/s] 23%|##2       |39873/173481[09:00<30:22,73.32it/s] 23%|##3       |40748/173481[09:10<30:10,73.32it/s] 30%|###       |52723/173481[12:00<27:49,72.33it/s] 31%|###       |53416/173481[12:10<27:39,72.33it/s] 40%|###9      |68661/173481[15:00<21:56,79.62it/s] 40%|####      |70057/173481[15:10<21:38,79.62it/s] 52%|#####1    |89794/173481[18:00<14:41,94.89it/s] 52%|#####2    |91063/173481[18:10<14:28,94.89it/s] 60%|#####9    |103345/173481[21:00<13:55,83.94it/s] 60%|#####9    |104070/173481[21:11<13:46,83.94it/s] 67%|######6   |115733/173481[24:00<12:43,75.63it/s] 67%|######7   |116496/173481[24:11<12:33,75.63it/s] 73%|#######3  |127025/173481[27:00<11:17,68.58it/s] 74%|#######3  |127770/173481[27:11<11:06,68.58it/s] 80%|########  |139015/173481[30:00<08:30,67.58it/s] 81%|########  |139766/173481[30:11<08:18,67.58it/s] 87%|########7 |150981/173481[33:00<05:35,67.02it/s] 87%|########7 |151746/173481[33:11<05:24,67.02it/s] 94%|#########3|163039/173481[36:00<02:35,67.00it/s] 94%|#########4|163830/173481[36:11<02:24,67.00it/s]100%|##########|173481/173481[38:34<00:00,74.95it/s]
[32m[0322 22:27:43 @base.py:257][0m Epoch 15 (global_step 7806645) finished, time:2314.66 sec.
[32m[0322 22:27:44 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-7806645.
  0%|          |0/18822[00:00<?,?it/s] 69%|######8   |12947/18822[03:00<01:21,71.92it/s] 74%|#######3  |13869/18822[03:10<01:08,71.92it/s]100%|##########|18822/18822[04:12<00:00,74.46it/s]
14
[32m[0322 22:31:57 @monitor.py:363][0m QueueInput/queue_size: 0.36037
[32m[0322 22:31:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.753
[32m[0322 22:31:57 @monitor.py:363][0m activation-summaries/output-rms: 0.038846
[32m[0322 22:31:57 @monitor.py:363][0m cross_entropy_loss: 2.1284
[32m[0322 22:31:57 @monitor.py:363][0m linear1/W_0_percent_n: 0.38261
[32m[0322 22:31:57 @monitor.py:363][0m linear1/W_0_percent_p: 0.35462
[32m[0322 22:31:57 @monitor.py:363][0m linear1/W_0_sparsity: 0.2627
[32m[0322 22:31:57 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0322 22:31:57 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0322 22:31:57 @monitor.py:363][0m linear2/W_0_percent_n: 0.4222
[32m[0322 22:31:57 @monitor.py:363][0m linear2/W_0_percent_p: 0.39464
[32m[0322 22:31:57 @monitor.py:363][0m linear2/W_0_sparsity: 0.18314
[32m[0322 22:31:57 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0322 22:31:57 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0322 22:31:57 @monitor.py:363][0m linear3/W_0_percent_n: 0.43103
[32m[0322 22:31:57 @monitor.py:363][0m linear3/W_0_percent_p: 0.39508
[32m[0322 22:31:57 @monitor.py:363][0m linear3/W_0_sparsity: 0.17389
[32m[0322 22:31:57 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0322 22:31:57 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0322 22:31:57 @monitor.py:363][0m lr: 1.5259e-08
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68377
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31984
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29634
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29416
[32m[0322 22:31:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 22:31:57 @monitor.py:363][0m train-error-top1: 0.55142
[32m[0322 22:31:57 @monitor.py:363][0m val-error-top1: 0.59288
[32m[0322 22:31:57 @monitor.py:363][0m val-utt-error: 0.17097
[32m[0322 22:31:57 @monitor.py:363][0m validation_cost: 2.4057
[32m[0322 22:31:57 @monitor.py:363][0m wd_cost: 1.1292e-10
[32m[0322 22:31:57 @group.py:42][0m Callbacks took 253.336 sec in total. InferenceRunner: 252.804sec
[32m[0322 22:31:57 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20361/173481[03:00<22:33,113.12it/s] 12%|#2        |21437/173481[03:10<22:24,113.12it/s] 22%|##2       |38714/173481[06:00<20:56,107.25it/s] 23%|##2       |39735/173481[06:10<20:47,107.25it/s] 31%|###       |53774/173481[09:00<21:13,94.00it/s]  31%|###1      |54603/173481[09:10<21:04,94.00it/s] 39%|###8      |67276/173481[12:00<21:12,83.43it/s] 39%|###9      |68004/173481[12:10<21:04,83.43it/s] 47%|####6     |80864/173481[15:00<19:28,79.26it/s] 47%|####7     |81711/173481[15:10<19:17,79.26it/s] 55%|#####4    |94960/173481[18:00<16:36,78.78it/s] 55%|#####5    |95809/173481[18:10<16:25,78.78it/s] 63%|######2   |108964/173481[21:00<13:44,78.28it/s] 63%|######3   |109775/173481[21:11<13:33,78.28it/s] 70%|#######   |122098/173481[24:00<11:20,75.52it/s] 71%|#######   |122841/173481[24:11<11:10,75.52it/s] 77%|#######7  |134131/173481[27:00<09:14,70.92it/s] 78%|#######7  |134883/173481[27:11<09:04,70.92it/s] 84%|########4 |146194/173481[30:00<06:35,68.91it/s] 85%|########4 |146943/173481[30:11<06:25,68.91it/s] 91%|#########1|158140/173481[33:00<03:46,67.61it/s] 92%|#########1|158899/173481[33:11<03:35,67.61it/s] 98%|#########8|170069/173481[36:00<00:50,66.93it/s] 98%|#########8|170853/173481[36:11<00:39,66.93it/s]100%|##########|173481/173481[36:50<00:00,78.48it/s]
[32m[0322 23:08:47 @base.py:257][0m Epoch 16 (global_step 7980126) finished, time:2210.57 sec.
[32m[0322 23:08:47 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-7980126.
  0%|          |0/18822[00:00<?,?it/s] 73%|#######2  |13664/18822[03:00<01:07,75.91it/s] 77%|#######6  |14405/18822[03:10<00:58,75.91it/s]100%|##########|18822/18822[04:11<00:00,74.87it/s]
15
[32m[0322 23:12:59 @monitor.py:363][0m QueueInput/queue_size: 0.65448
[32m[0322 23:12:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.928
[32m[0322 23:12:59 @monitor.py:363][0m activation-summaries/output-rms: 0.037795
[32m[0322 23:12:59 @monitor.py:363][0m cross_entropy_loss: 2.2246
[32m[0322 23:12:59 @monitor.py:363][0m linear1/W_0_percent_n: 0.38243
[32m[0322 23:12:59 @monitor.py:363][0m linear1/W_0_percent_p: 0.35451
[32m[0322 23:12:59 @monitor.py:363][0m linear1/W_0_sparsity: 0.26296
[32m[0322 23:12:59 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0322 23:12:59 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0322 23:12:59 @monitor.py:363][0m linear2/W_0_percent_n: 0.42217
[32m[0322 23:12:59 @monitor.py:363][0m linear2/W_0_percent_p: 0.39451
[32m[0322 23:12:59 @monitor.py:363][0m linear2/W_0_sparsity: 0.1833
[32m[0322 23:12:59 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0322 23:12:59 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0322 23:12:59 @monitor.py:363][0m linear3/W_0_percent_n: 0.43085
[32m[0322 23:12:59 @monitor.py:363][0m linear3/W_0_percent_p: 0.39512
[32m[0322 23:12:59 @monitor.py:363][0m linear3/W_0_sparsity: 0.17399
[32m[0322 23:12:59 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0322 23:12:59 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0322 23:12:59 @monitor.py:363][0m lr: 1.5259e-08
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68373
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31984
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29415
[32m[0322 23:12:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 23:12:59 @monitor.py:363][0m train-error-top1: 0.57043
[32m[0322 23:12:59 @monitor.py:363][0m val-error-top1: 0.60403
[32m[0322 23:12:59 @monitor.py:363][0m val-utt-error: 0.19095
[32m[0322 23:12:59 @monitor.py:363][0m validation_cost: 2.4956
[32m[0322 23:12:59 @monitor.py:363][0m wd_cost: 1.1292e-10
[32m[0322 23:12:59 @group.py:42][0m Callbacks took 251.713 sec in total. InferenceRunner: 251.416sec
[32m[0322 23:12:59 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#         |18631/173481[03:00<24:56,103.51it/s] 11%|#1        |19902/173481[03:10<24:43,103.51it/s] 23%|##3       |40248/173481[06:00<19:58,111.18it/s] 24%|##3       |41517/173481[06:10<19:46,111.18it/s] 34%|###4      |59695/173481[09:00<17:18,109.59it/s] 35%|###4      |60618/173481[09:10<17:09,109.59it/s] 45%|####5     |78581/173481[12:00<14:45,107.20it/s] 46%|####6     |79817/173481[12:10<14:33,107.20it/s] 56%|#####5    |96579/173481[15:00<12:23,103.47it/s] 56%|#####6    |97779/173481[15:10<12:11,103.47it/s] 66%|######6   |114938/173481[18:00<09:29,102.72it/s] 67%|######6   |115914/173481[18:10<09:20,102.72it/s] 76%|#######6  |132231/173481[21:00<06:55,99.29it/s]  77%|#######6  |133323/173481[21:11<06:44,99.29it/s] 87%|########7 |151466/173481[24:00<03:33,102.93it/s] 88%|########8 |152760/173481[24:11<03:21,102.93it/s]100%|#########9|172634/173481[27:00<00:07,109.78it/s]100%|##########|173481/173481[27:07<00:00,106.60it/s]
[32m[0322 23:40:06 @base.py:257][0m Epoch 17 (global_step 8153607) finished, time:1627.37 sec.
[32m[0322 23:40:07 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-8153607.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########8|18504/18822[03:00<00:03,102.80it/s]100%|##########|18822/18822[03:02<00:00,103.09it/s]
16
[32m[0322 23:43:09 @monitor.py:363][0m QueueInput/queue_size: 0.56079
[32m[0322 23:43:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.384
[32m[0322 23:43:09 @monitor.py:363][0m activation-summaries/output-rms: 0.039123
[32m[0322 23:43:09 @monitor.py:363][0m cross_entropy_loss: 2.1539
[32m[0322 23:43:09 @monitor.py:363][0m linear1/W_0_percent_n: 0.38252
[32m[0322 23:43:09 @monitor.py:363][0m linear1/W_0_percent_p: 0.35465
[32m[0322 23:43:09 @monitor.py:363][0m linear1/W_0_sparsity: 0.26268
[32m[0322 23:43:09 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0322 23:43:09 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0322 23:43:09 @monitor.py:363][0m linear2/W_0_percent_n: 0.42192
[32m[0322 23:43:09 @monitor.py:363][0m linear2/W_0_percent_p: 0.39451
[32m[0322 23:43:09 @monitor.py:363][0m linear2/W_0_sparsity: 0.18352
[32m[0322 23:43:09 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0322 23:43:09 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0322 23:43:09 @monitor.py:363][0m linear3/W_0_percent_n: 0.43089
[32m[0322 23:43:09 @monitor.py:363][0m linear3/W_0_percent_p: 0.39498
[32m[0322 23:43:09 @monitor.py:363][0m linear3/W_0_sparsity: 0.17408
[32m[0322 23:43:09 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0322 23:43:09 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0322 23:43:09 @monitor.py:363][0m lr: 7.6294e-09
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68372
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29415
[32m[0322 23:43:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0322 23:43:09 @monitor.py:363][0m train-error-top1: 0.55784
[32m[0322 23:43:09 @monitor.py:363][0m val-error-top1: 0.58073
[32m[0322 23:43:09 @monitor.py:363][0m val-utt-error: 0.15168
[32m[0322 23:43:09 @monitor.py:363][0m validation_cost: 2.3287
[32m[0322 23:43:09 @monitor.py:363][0m wd_cost: 1.1292e-10
[32m[0322 23:43:09 @group.py:42][0m Callbacks took 182.874 sec in total. InferenceRunner: 182.585sec
[32m[0322 23:43:09 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12838/173481[03:00<37:32,71.32it/s]  8%|7         |13517/173481[03:10<37:22,71.32it/s] 14%|#4        |25102/173481[06:00<35:29,69.68it/s] 15%|#4        |25785/173481[06:10<35:19,69.68it/s] 21%|##1       |37069/173481[09:00<33:24,68.05it/s] 22%|##1       |37767/173481[09:10<33:14,68.05it/s] 28%|##8       |48970/173481[12:00<30:56,67.05it/s] 29%|##8       |49659/173481[12:10<30:46,67.05it/s] 35%|###5      |61054/173481[15:00<27:55,67.08it/s] 36%|###5      |61770/173481[15:10<27:45,67.08it/s] 43%|####2     |74160/173481[18:00<23:42,69.83it/s] 43%|####3     |74865/173481[18:10<23:32,69.83it/s] 54%|#####3    |92974/173481[21:00<16:01,83.72it/s] 54%|#####4    |94131/173481[21:11<15:47,83.72it/s] 62%|######2   |107560/173481[24:00<13:20,82.34it/s] 62%|######2   |108277/173481[24:11<13:11,82.34it/s] 69%|######8   |119422/173481[27:00<12:18,73.21it/s] 69%|######9   |120142/173481[27:11<12:08,73.21it/s] 76%|#######5  |131468/173481[30:00<10:00,69.92it/s] 76%|#######6  |132227/173481[30:11<09:49,69.92it/s] 83%|########2 |143389/173481[33:00<07:22,68.02it/s] 83%|########3 |144128/173481[33:11<07:11,68.02it/s] 90%|########9 |155403/173481[36:00<04:28,67.38it/s] 90%|######### |156158/173481[36:11<04:17,67.38it/s] 97%|#########6|167439/173481[39:00<01:30,67.12it/s] 97%|#########7|168397/173481[39:11<01:15,67.12it/s]100%|##########|173481/173481[39:56<00:00,72.38it/s]
[32m[0323 00:23:06 @base.py:257][0m Epoch 18 (global_step 8327088) finished, time:2396.70 sec.
[32m[0323 00:23:06 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-8327088.
[32m[0323 00:23:07 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:38<00:00,119.00it/s]
17
[32m[0323 00:25:45 @monitor.py:363][0m QueueInput/queue_size: 30.053
[32m[0323 00:25:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 56.5
[32m[0323 00:25:45 @monitor.py:363][0m activation-summaries/output-rms: 0.039423
[32m[0323 00:25:45 @monitor.py:363][0m cross_entropy_loss: 2.0892
[32m[0323 00:25:45 @monitor.py:363][0m linear1/W_0_percent_n: 0.3824
[32m[0323 00:25:45 @monitor.py:363][0m linear1/W_0_percent_p: 0.35431
[32m[0323 00:25:45 @monitor.py:363][0m linear1/W_0_sparsity: 0.26314
[32m[0323 00:25:45 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 00:25:45 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 00:25:45 @monitor.py:363][0m linear2/W_0_percent_n: 0.42217
[32m[0323 00:25:45 @monitor.py:363][0m linear2/W_0_percent_p: 0.39451
[32m[0323 00:25:45 @monitor.py:363][0m linear2/W_0_sparsity: 0.18328
[32m[0323 00:25:45 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 00:25:45 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 00:25:45 @monitor.py:363][0m linear3/W_0_percent_n: 0.43076
[32m[0323 00:25:45 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 00:25:45 @monitor.py:363][0m linear3/W_0_sparsity: 0.17428
[32m[0323 00:25:45 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 00:25:45 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 00:25:45 @monitor.py:363][0m lr: 7.6294e-09
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68372
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29415
[32m[0323 00:25:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 00:25:45 @monitor.py:363][0m train-error-top1: 0.53993
[32m[0323 00:25:45 @monitor.py:363][0m val-error-top1: 0.58594
[32m[0323 00:25:45 @monitor.py:363][0m val-utt-error: 0.16693
[32m[0323 00:25:45 @monitor.py:363][0m validation_cost: 2.3717
[32m[0323 00:25:45 @monitor.py:363][0m wd_cost: 2.2583e-11
[32m[0323 00:25:45 @group.py:42][0m Callbacks took 158.991 sec in total. InferenceRunner: 158.180sec
[32m[0323 00:25:45 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20815/173481[03:00<22:00,115.63it/s] 13%|#2        |21961/173481[03:10<21:50,115.63it/s] 21%|##1       |37147/173481[06:00<22:20,101.68it/s] 22%|##1       |37716/173481[06:10<22:15,101.68it/s] 28%|##8       |48862/173481[09:00<26:10,79.36it/s]  29%|##8       |49554/173481[09:10<26:01,79.36it/s] 35%|###5      |60723/173481[12:00<26:05,72.00it/s] 35%|###5      |61431/173481[12:10<25:56,72.00it/s] 42%|####1     |72781/173481[15:00<24:11,69.40it/s] 42%|####2     |73496/173481[15:10<24:00,69.40it/s] 49%|####9     |85089/173481[18:00<21:23,68.88it/s] 50%|####9     |86235/173481[18:10<21:06,68.88it/s] 60%|######    |104623/173481[21:00<13:37,84.27it/s] 61%|######    |105381/173481[21:11<13:28,84.27it/s] 70%|######9   |121261/173481[24:00<09:52,88.16it/s] 70%|#######   |122004/173481[24:11<09:43,88.16it/s] 77%|#######6  |133219/173481[27:00<08:51,75.77it/s] 77%|#######7  |133970/173481[27:11<08:41,75.77it/s] 84%|########3 |145123/173481[30:00<06:41,70.62it/s] 84%|########4 |145878/173481[30:11<06:30,70.62it/s] 91%|######### |157077/173481[33:00<03:59,68.45it/s] 91%|######### |157844/173481[33:11<03:48,68.45it/s] 98%|#########7|169232/173481[36:00<01:02,67.98it/s] 98%|#########8|170047/173481[36:11<00:50,67.98it/s]100%|##########|173481/173481[37:01<00:00,78.11it/s]
[32m[0323 01:02:46 @base.py:257][0m Epoch 19 (global_step 8500569) finished, time:2221.03 sec.
[32m[0323 01:02:46 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-8500569.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########8|18485/18822[03:00<00:03,102.69it/s]100%|##########|18822/18822[03:05<00:00,101.53it/s]
18
[32m[0323 01:05:52 @monitor.py:363][0m QueueInput/queue_size: 1.4404
[32m[0323 01:05:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.615
[32m[0323 01:05:52 @monitor.py:363][0m activation-summaries/output-rms: 0.039279
[32m[0323 01:05:52 @monitor.py:363][0m cross_entropy_loss: 2.1568
[32m[0323 01:05:52 @monitor.py:363][0m linear1/W_0_percent_n: 0.3824
[32m[0323 01:05:52 @monitor.py:363][0m linear1/W_0_percent_p: 0.3544
[32m[0323 01:05:52 @monitor.py:363][0m linear1/W_0_sparsity: 0.26293
[32m[0323 01:05:52 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 01:05:52 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 01:05:52 @monitor.py:363][0m linear2/W_0_percent_n: 0.42214
[32m[0323 01:05:52 @monitor.py:363][0m linear2/W_0_percent_p: 0.39431
[32m[0323 01:05:52 @monitor.py:363][0m linear2/W_0_sparsity: 0.18345
[32m[0323 01:05:52 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 01:05:52 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 01:05:52 @monitor.py:363][0m linear3/W_0_percent_n: 0.43074
[32m[0323 01:05:52 @monitor.py:363][0m linear3/W_0_percent_p: 0.39481
[32m[0323 01:05:52 @monitor.py:363][0m linear3/W_0_sparsity: 0.1744
[32m[0323 01:05:52 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 01:05:52 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 01:05:52 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68372
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29415
[32m[0323 01:05:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 01:05:52 @monitor.py:363][0m train-error-top1: 0.55495
[32m[0323 01:05:52 @monitor.py:363][0m val-error-top1: 0.57197
[32m[0323 01:05:52 @monitor.py:363][0m val-utt-error: 0.14547
[32m[0323 01:05:52 @monitor.py:363][0m validation_cost: 2.2853
[32m[0323 01:05:52 @monitor.py:363][0m wd_cost: 2.2583e-11
[32m[0323 01:05:52 @group.py:42][0m Callbacks took 185.708 sec in total. InferenceRunner: 185.402sec
[32m[0323 01:05:52 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15692/173481[03:00<30:10,87.18it/s]  9%|9         |16353/173481[03:10<30:02,87.18it/s] 16%|#5        |27646/173481[06:00<32:14,75.38it/s] 16%|#6        |28317/173481[06:10<32:05,75.38it/s] 23%|##2       |39642/173481[09:00<31:31,70.74it/s] 23%|##3       |40737/173481[09:10<31:16,70.74it/s] 35%|###4      |60502/173481[12:00<21:25,87.85it/s] 36%|###5      |61742/173481[12:10<21:11,87.85it/s] 46%|####5     |79555/173481[15:00<16:18,96.02it/s] 46%|####6     |80289/173481[15:10<16:10,96.02it/s] 55%|#####4    |94640/173481[18:00<14:40,89.49it/s] 55%|#####5    |95421/173481[18:11<14:32,89.49it/s] 62%|######1   |107319/173481[21:00<13:59,78.83it/s] 62%|######2   |108207/173481[21:11<13:48,78.83it/s] 70%|######9   |121121/173481[24:00<11:13,77.74it/s] 70%|#######   |122009/173481[24:11<11:02,77.74it/s] 77%|#######7  |133959/173481[27:00<08:51,74.39it/s] 78%|#######7  |134763/173481[27:11<08:40,74.39it/s] 85%|########5 |147946/173481[30:00<05:35,76.01it/s] 86%|########5 |148730/173481[30:11<05:25,76.01it/s] 93%|#########2|160630/173481[33:00<02:55,73.12it/s] 93%|#########3|161409/173481[33:11<02:45,73.12it/s]100%|#########9|173279/173481[36:00<00:02,71.67it/s]100%|##########|173481/173481[36:02<00:00,80.20it/s]
[32m[0323 01:41:55 @base.py:257][0m Epoch 20 (global_step 8674050) finished, time:2162.99 sec.
[32m[0323 01:41:55 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-8674050.
[32m[0323 01:41:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 80%|########  |15112/18822[03:00<00:44,83.95it/s] 86%|########6 |16189/18822[03:10<00:31,83.95it/s]100%|##########|18822/18822[03:32<00:00,88.68it/s]
19
[32m[0323 01:45:28 @monitor.py:363][0m QueueInput/queue_size: 0.77716
[32m[0323 01:45:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.928
[32m[0323 01:45:28 @monitor.py:363][0m activation-summaries/output-rms: 0.038638
[32m[0323 01:45:28 @monitor.py:363][0m cross_entropy_loss: 2.1412
[32m[0323 01:45:28 @monitor.py:363][0m linear1/W_0_percent_n: 0.38232
[32m[0323 01:45:28 @monitor.py:363][0m linear1/W_0_percent_p: 0.35442
[32m[0323 01:45:28 @monitor.py:363][0m linear1/W_0_sparsity: 0.26288
[32m[0323 01:45:28 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 01:45:28 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 01:45:28 @monitor.py:363][0m linear2/W_0_percent_n: 0.42202
[32m[0323 01:45:28 @monitor.py:363][0m linear2/W_0_percent_p: 0.39456
[32m[0323 01:45:28 @monitor.py:363][0m linear2/W_0_sparsity: 0.18335
[32m[0323 01:45:28 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 01:45:28 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 01:45:28 @monitor.py:363][0m linear3/W_0_percent_n: 0.43071
[32m[0323 01:45:28 @monitor.py:363][0m linear3/W_0_percent_p: 0.3949
[32m[0323 01:45:28 @monitor.py:363][0m linear3/W_0_sparsity: 0.17431
[32m[0323 01:45:28 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 01:45:28 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 01:45:28 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68372
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29415
[32m[0323 01:45:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 01:45:28 @monitor.py:363][0m train-error-top1: 0.54976
[32m[0323 01:45:28 @monitor.py:363][0m val-error-top1: 0.57417
[32m[0323 01:45:28 @monitor.py:363][0m val-utt-error: 0.15253
[32m[0323 01:45:28 @monitor.py:363][0m validation_cost: 2.2942
[32m[0323 01:45:28 @monitor.py:363][0m wd_cost: 4.5166e-12
[32m[0323 01:45:28 @group.py:42][0m Callbacks took 213.293 sec in total. InferenceRunner: 212.265sec
[32m[0323 01:45:28 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16784/173481[03:00<28:00,93.24it/s] 10%|#         |17770/173481[03:10<27:49,93.24it/s] 17%|#6        |29233/173481[06:00<30:16,79.41it/s] 17%|#7        |29934/173481[06:10<30:07,79.41it/s] 25%|##5       |43999/173481[09:00<26:44,80.70it/s] 26%|##6       |45150/173481[09:10<26:30,80.70it/s] 35%|###4      |60132/173481[12:00<22:14,84.93it/s] 35%|###5      |60957/173481[12:10<22:04,84.93it/s] 42%|####2     |72876/173481[15:00<21:42,77.22it/s] 42%|####2     |73701/173481[15:10<21:32,77.22it/s] 52%|#####2    |90854/173481[18:00<15:48,87.10it/s] 53%|#####3    |92131/173481[18:10<15:33,87.10it/s] 63%|######2   |109202/173481[21:00<11:24,93.93it/s] 63%|######3   |109797/173481[21:11<11:17,93.93it/s] 70%|######9   |121057/173481[24:00<11:17,77.41it/s] 70%|#######   |121794/173481[24:11<11:07,77.41it/s] 77%|#######7  |133840/173481[27:00<08:55,74.08it/s] 78%|#######7  |134658/173481[27:11<08:44,74.08it/s] 84%|########4 |146344/173481[30:00<06:18,71.70it/s] 85%|########4 |147099/173481[30:11<06:07,71.70it/s] 92%|#########2|159787/173481[33:00<03:07,73.15it/s] 93%|#########2|160547/173481[33:11<02:56,73.15it/s] 99%|#########9|171967/173481[36:00<00:21,70.30it/s]100%|#########9|172764/173481[36:11<00:10,70.30it/s]100%|##########|173481/173481[36:22<00:00,79.48it/s]
[32m[0323 02:21:51 @base.py:257][0m Epoch 21 (global_step 8847531) finished, time:2182.74 sec.
[32m[0323 02:21:51 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-8847531.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########7|18398/18822[03:00<00:04,102.21it/s]100%|##########|18822/18822[03:03<00:00,102.80it/s]
20
[32m[0323 02:24:54 @monitor.py:363][0m QueueInput/queue_size: 0.34527
[32m[0323 02:24:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.617
[32m[0323 02:24:54 @monitor.py:363][0m activation-summaries/output-rms: 0.038895
[32m[0323 02:24:54 @monitor.py:363][0m cross_entropy_loss: 2.1336
[32m[0323 02:24:54 @monitor.py:363][0m linear1/W_0_percent_n: 0.38223
[32m[0323 02:24:54 @monitor.py:363][0m linear1/W_0_percent_p: 0.35409
[32m[0323 02:24:54 @monitor.py:363][0m linear1/W_0_sparsity: 0.26331
[32m[0323 02:24:54 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 02:24:54 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 02:24:54 @monitor.py:363][0m linear2/W_0_percent_n: 0.42206
[32m[0323 02:24:54 @monitor.py:363][0m linear2/W_0_percent_p: 0.39435
[32m[0323 02:24:54 @monitor.py:363][0m linear2/W_0_sparsity: 0.1835
[32m[0323 02:24:54 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 02:24:54 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 02:24:54 @monitor.py:363][0m linear3/W_0_percent_n: 0.43067
[32m[0323 02:24:54 @monitor.py:363][0m linear3/W_0_percent_p: 0.3947
[32m[0323 02:24:54 @monitor.py:363][0m linear3/W_0_sparsity: 0.17454
[32m[0323 02:24:54 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 02:24:54 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 02:24:54 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 02:24:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 02:24:54 @monitor.py:363][0m train-error-top1: 0.55438
[32m[0323 02:24:54 @monitor.py:363][0m val-error-top1: 0.57
[32m[0323 02:24:54 @monitor.py:363][0m val-utt-error: 0.14244
[32m[0323 02:24:54 @monitor.py:363][0m validation_cost: 2.2744
[32m[0323 02:24:54 @monitor.py:363][0m wd_cost: 4.5166e-12
[32m[0323 02:24:54 @group.py:42][0m Callbacks took 183.537 sec in total. InferenceRunner: 183.108sec
[32m[0323 02:24:54 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20636/173481[03:00<22:13,114.64it/s] 13%|#2        |21829/173481[03:10<22:02,114.64it/s] 21%|##1       |37036/173481[06:00<22:23,101.53it/s] 22%|##1       |37755/173481[06:10<22:16,101.53it/s] 28%|##8       |49264/173481[09:00<25:26,81.40it/s]  29%|##8       |49989/173481[09:10<25:17,81.40it/s] 35%|###5      |61516/173481[12:00<25:10,74.13it/s] 36%|###5      |62234/173481[12:10<25:00,74.13it/s] 43%|####3     |74873/173481[15:00<22:09,74.17it/s] 44%|####3     |76122/173481[15:10<21:52,74.17it/s] 54%|#####4    |94116/173481[18:00<15:06,87.58it/s] 55%|#####4    |95412/173481[18:11<14:51,87.58it/s] 65%|######5   |112794/173481[21:00<10:38,94.98it/s] 65%|######5   |113520/173481[21:11<10:31,94.98it/s] 74%|#######3  |128048/173481[24:00<08:27,89.57it/s] 75%|#######4  |129364/173481[24:11<08:12,89.57it/s] 86%|########5 |148902/173481[27:00<04:03,101.03it/s] 87%|########6 |150210/173481[27:11<03:50,101.03it/s] 95%|#########5|165635/173481[30:00<01:21,96.83it/s]  96%|#########5|166437/173481[30:11<01:12,96.83it/s]100%|##########|173481/173481[32:06<00:00,90.06it/s]
[32m[0323 02:57:01 @base.py:257][0m Epoch 22 (global_step 9021012) finished, time:1926.37 sec.
[32m[0323 02:57:01 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-9021012.
[32m[0323 02:57:02 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 83%|########3 |15650/18822[03:00<00:36,86.94it/s] 88%|########7 |16524/18822[03:10<00:26,86.94it/s]100%|##########|18822/18822[03:36<00:00,86.78it/s]
21
[32m[0323 03:00:39 @monitor.py:363][0m QueueInput/queue_size: 0.78423
[32m[0323 03:00:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.75
[32m[0323 03:00:39 @monitor.py:363][0m activation-summaries/output-rms: 0.037523
[32m[0323 03:00:39 @monitor.py:363][0m cross_entropy_loss: 2.2088
[32m[0323 03:00:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.38219
[32m[0323 03:00:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.35402
[32m[0323 03:00:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.26318
[32m[0323 03:00:39 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 03:00:39 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 03:00:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.42195
[32m[0323 03:00:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.39439
[32m[0323 03:00:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.1835
[32m[0323 03:00:39 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 03:00:39 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 03:00:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.43047
[32m[0323 03:00:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 03:00:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.17441
[32m[0323 03:00:39 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 03:00:39 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 03:00:39 @monitor.py:363][0m lr: 1.9073e-09
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 03:00:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 03:00:39 @monitor.py:363][0m train-error-top1: 0.56546
[32m[0323 03:00:39 @monitor.py:363][0m val-error-top1: 0.56417
[32m[0323 03:00:39 @monitor.py:363][0m val-utt-error: 0.13766
[32m[0323 03:00:39 @monitor.py:363][0m validation_cost: 2.2449
[32m[0323 03:00:39 @monitor.py:363][0m wd_cost: 4.5166e-12
[32m[0323 03:00:39 @group.py:42][0m Callbacks took 218.144 sec in total. InferenceRunner: 216.909sec
[32m[0323 03:00:39 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11413/173481[03:00<42:37,63.38it/s]  7%|6         |11958/173481[03:10<42:28,63.38it/s] 12%|#2        |20839/173481[06:00<44:21,57.34it/s] 12%|#2        |21397/173481[06:10<44:12,57.34it/s] 20%|##        |35260/173481[09:00<34:27,66.84it/s] 21%|##        |36223/173481[09:10<34:13,66.84it/s] 28%|##8       |49431/173481[12:00<28:35,72.30it/s] 29%|##8       |49973/173481[12:10<28:28,72.30it/s] 34%|###3      |58873/173481[15:00<31:25,60.80it/s] 34%|###4      |59424/173481[15:10<31:15,60.80it/s] 42%|####1     |72835/173481[18:00<24:36,68.15it/s] 42%|####2     |73722/173481[18:11<24:23,68.15it/s] 50%|####9     |86545/173481[21:00<20:08,71.93it/s] 50%|#####     |87497/173481[21:11<19:55,71.93it/s] 57%|#####7    |98965/173481[24:00<17:38,70.43it/s] 57%|#####7    |99552/173481[24:11<17:29,70.43it/s] 65%|######4   |112527/173481[27:00<13:57,72.80it/s] 65%|######5   |113509/173481[27:11<13:43,72.80it/s] 74%|#######4  |128896/173481[30:00<09:11,80.86it/s] 75%|#######4  |129923/173481[30:11<08:58,80.86it/s] 84%|########4 |145984/173481[33:00<05:14,87.33it/s] 85%|########4 |147257/173481[33:11<05:00,87.33it/s] 95%|#########5|164852/173481[36:00<01:30,95.28it/s] 96%|#########5|166031/173481[36:11<01:18,95.28it/s]100%|##########|173481/173481[37:48<00:00,76.47it/s]
[32m[0323 03:38:27 @base.py:257][0m Epoch 23 (global_step 9194493) finished, time:2268.64 sec.
[32m[0323 03:38:28 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-9194493.
[32m[0323 03:38:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 87%|########7 |16451/18822[03:00<00:25,91.39it/s] 92%|#########2|17346/18822[03:10<00:16,91.39it/s]100%|##########|18822/18822[03:26<00:00,91.18it/s]
22
[32m[0323 03:41:55 @monitor.py:363][0m QueueInput/queue_size: 0.60241
[32m[0323 03:41:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.724
[32m[0323 03:41:55 @monitor.py:363][0m activation-summaries/output-rms: 0.038727
[32m[0323 03:41:55 @monitor.py:363][0m cross_entropy_loss: 2.1642
[32m[0323 03:41:55 @monitor.py:363][0m linear1/W_0_percent_n: 0.38197
[32m[0323 03:41:55 @monitor.py:363][0m linear1/W_0_percent_p: 0.354
[32m[0323 03:41:55 @monitor.py:363][0m linear1/W_0_sparsity: 0.26318
[32m[0323 03:41:55 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 03:41:55 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 03:41:55 @monitor.py:363][0m linear2/W_0_percent_n: 0.42197
[32m[0323 03:41:55 @monitor.py:363][0m linear2/W_0_percent_p: 0.39436
[32m[0323 03:41:55 @monitor.py:363][0m linear2/W_0_sparsity: 0.18348
[32m[0323 03:41:55 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 03:41:55 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 03:41:55 @monitor.py:363][0m linear3/W_0_percent_n: 0.43045
[32m[0323 03:41:55 @monitor.py:363][0m linear3/W_0_percent_p: 0.39496
[32m[0323 03:41:55 @monitor.py:363][0m linear3/W_0_sparsity: 0.17438
[32m[0323 03:41:55 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 03:41:55 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 03:41:55 @monitor.py:363][0m lr: 1.9073e-09
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 03:41:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 03:41:55 @monitor.py:363][0m train-error-top1: 0.5607
[32m[0323 03:41:55 @monitor.py:363][0m val-error-top1: 0.55823
[32m[0323 03:41:55 @monitor.py:363][0m val-utt-error: 0.13229
[32m[0323 03:41:55 @monitor.py:363][0m validation_cost: 2.2076
[32m[0323 03:41:55 @monitor.py:363][0m wd_cost: 9.0332e-13
[32m[0323 03:41:55 @group.py:42][0m Callbacks took 207.307 sec in total. InferenceRunner: 206.444sec
[32m[0323 03:41:55 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12479/173481[03:00<38:42,69.33it/s]  8%|7         |13386/173481[03:10<38:29,69.33it/s] 15%|#5        |26722/173481[06:00<33:05,73.90it/s] 16%|#5        |27664/173481[06:10<32:53,73.90it/s] 24%|##4       |42263/173481[09:00<27:27,79.64it/s] 25%|##4       |43131/173481[09:10<27:16,79.64it/s] 34%|###3      |58121/173481[12:00<22:59,83.65it/s] 34%|###4      |59073/173481[12:10<22:47,83.65it/s] 43%|####2     |74433/173481[15:00<18:58,87.00it/s] 43%|####3     |75355/173481[15:10<18:47,87.00it/s] 52%|#####2    |90462/173481[18:00<15:43,88.01it/s] 53%|#####2    |91580/173481[18:11<15:30,88.01it/s] 62%|######2   |107669/173481[21:00<11:58,91.64it/s] 63%|######2   |108689/173481[21:11<11:46,91.64it/s] 71%|#######1  |123269/173481[24:00<09:23,89.09it/s] 72%|#######1  |124264/173481[24:11<09:12,89.09it/s] 81%|########  |140062/173481[27:00<06:06,91.14it/s] 81%|########1 |141111/173481[27:11<05:55,91.14it/s] 90%|######### |156454/173481[30:00<03:06,91.10it/s] 91%|######### |157461/173481[30:11<02:55,91.10it/s]100%|#########9|172647/173481[33:00<00:09,90.52it/s]100%|##########|173481/173481[33:08<00:00,87.22it/s]
[32m[0323 04:15:04 @base.py:257][0m Epoch 24 (global_step 9367974) finished, time:1988.97 sec.
[32m[0323 04:15:04 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-9367974.
[32m[0323 04:15:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.46it/s]
23
[32m[0323 04:17:00 @monitor.py:363][0m QueueInput/queue_size: 0.75029
[32m[0323 04:17:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 56.395
[32m[0323 04:17:00 @monitor.py:363][0m activation-summaries/output-rms: 0.039588
[32m[0323 04:17:00 @monitor.py:363][0m cross_entropy_loss: 2.1023
[32m[0323 04:17:00 @monitor.py:363][0m linear1/W_0_percent_n: 0.38191
[32m[0323 04:17:00 @monitor.py:363][0m linear1/W_0_percent_p: 0.35391
[32m[0323 04:17:00 @monitor.py:363][0m linear1/W_0_sparsity: 0.2632
[32m[0323 04:17:00 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 04:17:00 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 04:17:00 @monitor.py:363][0m linear2/W_0_percent_n: 0.42189
[32m[0323 04:17:00 @monitor.py:363][0m linear2/W_0_percent_p: 0.39446
[32m[0323 04:17:00 @monitor.py:363][0m linear2/W_0_sparsity: 0.18348
[32m[0323 04:17:00 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 04:17:00 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 04:17:00 @monitor.py:363][0m linear3/W_0_percent_n: 0.43037
[32m[0323 04:17:00 @monitor.py:363][0m linear3/W_0_percent_p: 0.39503
[32m[0323 04:17:00 @monitor.py:363][0m linear3/W_0_sparsity: 0.17442
[32m[0323 04:17:00 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 04:17:00 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 04:17:00 @monitor.py:363][0m lr: 1.9073e-09
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 04:17:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 04:17:00 @monitor.py:363][0m train-error-top1: 0.5388
[32m[0323 04:17:00 @monitor.py:363][0m val-error-top1: 0.55857
[32m[0323 04:17:00 @monitor.py:363][0m val-utt-error: 0.13022
[32m[0323 04:17:00 @monitor.py:363][0m validation_cost: 2.2045
[32m[0323 04:17:00 @monitor.py:363][0m wd_cost: 9.0332e-13
[32m[0323 04:17:00 @group.py:42][0m Callbacks took 116.555 sec in total. InferenceRunner: 115.161sec
[32m[0323 04:17:00 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16918/173481[03:00<27:45,93.99it/s] 10%|#         |17905/173481[03:10<27:35,93.99it/s] 20%|#9        |33938/173481[06:00<24:40,94.27it/s] 20%|##        |34921/173481[06:10<24:29,94.27it/s] 30%|###       |52908/173481[09:00<20:11,99.52it/s] 31%|###1      |54063/173481[09:10<19:59,99.52it/s] 41%|####1     |71824/173481[12:00<16:34,102.23it/s] 42%|####1     |72762/173481[12:10<16:25,102.23it/s] 52%|#####1    |89382/173481[15:00<14:02,99.83it/s]  52%|#####2    |90457/173481[15:10<13:51,99.83it/s] 62%|######1   |107307/173481[18:00<11:03,99.70it/s] 62%|######2   |108343/173481[18:11<10:53,99.70it/s] 71%|#######1  |123918/173481[21:00<08:37,95.85it/s] 72%|#######1  |124877/173481[21:11<08:27,95.85it/s] 82%|########1 |141469/173481[24:00<05:31,96.67it/s] 82%|########2 |142510/173481[24:11<05:20,96.67it/s] 91%|#########1|158711/173481[27:00<02:33,96.22it/s] 92%|#########2|159902/173481[27:11<02:21,96.22it/s]100%|##########|173481/173481[29:33<00:00,97.81it/s]
[32m[0323 04:46:34 @base.py:257][0m Epoch 25 (global_step 9541455) finished, time:1773.70 sec.
[32m[0323 04:46:34 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-9541455.
  0%|          |0/18822[00:00<?,?it/s] 73%|#######3  |13802/18822[03:00<01:05,76.67it/s] 77%|#######7  |14527/18822[03:10<00:56,76.67it/s]100%|##########|18822/18822[04:14<00:00,74.09it/s]
24
[32m[0323 04:50:48 @monitor.py:363][0m QueueInput/queue_size: 0.79084
[32m[0323 04:50:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.386
[32m[0323 04:50:48 @monitor.py:363][0m activation-summaries/output-rms: 0.038916
[32m[0323 04:50:48 @monitor.py:363][0m cross_entropy_loss: 2.1459
[32m[0323 04:50:48 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 04:50:48 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 04:50:48 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 04:50:48 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 04:50:48 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 04:50:48 @monitor.py:363][0m linear2/W_0_percent_n: 0.42186
[32m[0323 04:50:48 @monitor.py:363][0m linear2/W_0_percent_p: 0.39429
[32m[0323 04:50:48 @monitor.py:363][0m linear2/W_0_sparsity: 0.18352
[32m[0323 04:50:48 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 04:50:48 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 04:50:48 @monitor.py:363][0m linear3/W_0_percent_n: 0.43021
[32m[0323 04:50:48 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 04:50:48 @monitor.py:363][0m linear3/W_0_sparsity: 0.1745
[32m[0323 04:50:48 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 04:50:48 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 04:50:48 @monitor.py:363][0m lr: 9.5367e-10
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 04:50:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 04:50:48 @monitor.py:363][0m train-error-top1: 0.55671
[32m[0323 04:50:48 @monitor.py:363][0m val-error-top1: 0.55622
[32m[0323 04:50:48 @monitor.py:363][0m val-utt-error: 0.12873
[32m[0323 04:50:48 @monitor.py:363][0m validation_cost: 2.1922
[32m[0323 04:50:48 @monitor.py:363][0m wd_cost: 9.0332e-13
[32m[0323 04:50:48 @group.py:42][0m Callbacks took 254.374 sec in total. InferenceRunner: 254.041sec
[32m[0323 04:50:48 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21071/173481[03:00<21:42,117.06it/s] 13%|#2        |22412/173481[03:10<21:30,117.06it/s] 25%|##4       |42544/173481[06:00<18:28,118.16it/s] 25%|##5       |43671/173481[06:10<18:18,118.16it/s] 36%|###6      |63119/173481[09:00<15:49,116.20it/s] 37%|###7      |64328/173481[09:10<15:39,116.20it/s] 47%|####6     |81458/173481[12:00<14:07,108.57it/s] 47%|####7     |82172/173481[12:10<14:00,108.57it/s] 54%|#####3    |92917/173481[15:00<16:43,80.26it/s]  54%|#####3    |93657/173481[15:10<16:34,80.26it/s] 61%|######    |105539/173481[18:00<15:07,74.85it/s] 61%|######1   |106317/173481[18:10<14:57,74.85it/s] 68%|######8   |118305/173481[21:00<12:37,72.83it/s] 69%|######8   |119117/173481[21:11<12:26,72.83it/s] 76%|#######5  |131343/173481[24:00<09:40,72.63it/s] 76%|#######6  |132166/173481[24:11<09:28,72.63it/s] 83%|########3 |144310/173481[27:00<06:43,72.33it/s] 84%|########3 |145131/173481[27:11<06:31,72.33it/s] 91%|######### |157084/173481[30:00<03:48,71.64it/s] 91%|#########1|157964/173481[30:11<03:36,71.64it/s] 98%|#########8|170050/173481[33:00<00:47,71.83it/s] 98%|#########8|170850/173481[33:11<00:36,71.83it/s]100%|##########|173481/173481[33:50<00:00,85.44it/s]
[32m[0323 05:24:39 @base.py:257][0m Epoch 26 (global_step 9714936) finished, time:2030.45 sec.
[32m[0323 05:24:39 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-9714936.
[32m[0323 05:24:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:59<00:00,105.03it/s]
25
[32m[0323 05:27:39 @monitor.py:363][0m QueueInput/queue_size: 0.61301
[32m[0323 05:27:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.688
[32m[0323 05:27:39 @monitor.py:363][0m activation-summaries/output-rms: 0.039343
[32m[0323 05:27:39 @monitor.py:363][0m cross_entropy_loss: 2.1377
[32m[0323 05:27:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 05:27:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 05:27:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 05:27:39 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 05:27:39 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 05:27:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.42171
[32m[0323 05:27:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.39426
[32m[0323 05:27:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.1836
[32m[0323 05:27:39 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 05:27:39 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 05:27:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.43018
[32m[0323 05:27:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.39487
[32m[0323 05:27:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.17453
[32m[0323 05:27:39 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 05:27:39 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 05:27:39 @monitor.py:363][0m lr: 9.5367e-10
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 05:27:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 05:27:39 @monitor.py:363][0m train-error-top1: 0.55874
[32m[0323 05:27:39 @monitor.py:363][0m val-error-top1: 0.55668
[32m[0323 05:27:39 @monitor.py:363][0m val-utt-error: 0.12857
[32m[0323 05:27:39 @monitor.py:363][0m validation_cost: 2.1965
[32m[0323 05:27:39 @monitor.py:363][0m wd_cost: 1.8066e-13
[32m[0323 05:27:39 @group.py:42][0m Callbacks took 180.164 sec in total. InferenceRunner: 179.230sec
[32m[0323 05:27:39 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 13%|#2        |22279/173481[03:00<20:21,123.77it/s] 14%|#3        |23567/173481[03:10<20:11,123.77it/s] 21%|##1       |36932/173481[06:00<23:10,98.21it/s]  22%|##1       |37655/173481[06:10<23:02,98.21it/s] 29%|##8       |49456/173481[09:00<25:22,81.45it/s] 29%|##8       |50157/173481[09:10<25:14,81.45it/s] 36%|###5      |61633/173481[12:00<25:13,73.91it/s] 36%|###5      |62322/173481[12:10<25:03,73.91it/s] 42%|####2     |73596/173481[15:00<23:47,69.99it/s] 43%|####2     |74424/173481[15:10<23:35,69.99it/s] 50%|#####     |86905/173481[18:00<20:04,71.91it/s] 51%|#####     |87666/173481[18:10<19:53,71.91it/s] 57%|#####7    |98923/173481[21:00<17:56,69.24it/s] 57%|#####7    |99652/173481[21:11<17:46,69.24it/s] 65%|######5   |113209/173481[24:00<13:35,73.95it/s] 66%|######5   |113982/173481[24:11<13:24,73.95it/s] 73%|#######2  |126019/173481[27:00<10:54,72.53it/s] 73%|#######3  |126774/173481[27:11<10:43,72.53it/s] 80%|#######9  |138223/173481[30:00<08:23,70.08it/s] 80%|########  |138996/173481[30:11<08:12,70.08it/s] 87%|########6 |150922/173481[33:00<05:20,70.31it/s] 87%|########7 |151680/173481[33:11<05:10,70.31it/s] 96%|#########6|166918/173481[36:00<01:23,78.51it/s] 97%|#########6|168138/173481[36:11<01:08,78.51it/s]100%|##########|173481/173481[37:20<00:00,77.45it/s]
[32m[0323 06:04:59 @base.py:257][0m Epoch 27 (global_step 9888417) finished, time:2240.04 sec.
[32m[0323 06:04:59 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-9888417.
  0%|          |0/18822[00:00<?,?it/s] 64%|######3   |11956/18822[03:00<01:43,66.42it/s] 67%|######6   |12578/18822[03:10<01:34,66.42it/s]100%|##########|18822/18822[04:54<00:00,63.99it/s]
26
[32m[0323 06:09:53 @monitor.py:363][0m QueueInput/queue_size: 0.6796
[32m[0323 06:09:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.73
[32m[0323 06:09:53 @monitor.py:363][0m activation-summaries/output-rms: 0.038965
[32m[0323 06:09:53 @monitor.py:363][0m cross_entropy_loss: 2.1133
[32m[0323 06:09:53 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 06:09:53 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 06:09:53 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 06:09:53 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 06:09:53 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 06:09:53 @monitor.py:363][0m linear2/W_0_percent_n: 0.42175
[32m[0323 06:09:53 @monitor.py:363][0m linear2/W_0_percent_p: 0.39417
[32m[0323 06:09:53 @monitor.py:363][0m linear2/W_0_sparsity: 0.18369
[32m[0323 06:09:53 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 06:09:53 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 06:09:53 @monitor.py:363][0m linear3/W_0_percent_n: 0.4301
[32m[0323 06:09:53 @monitor.py:363][0m linear3/W_0_percent_p: 0.39494
[32m[0323 06:09:53 @monitor.py:363][0m linear3/W_0_sparsity: 0.17451
[32m[0323 06:09:53 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 06:09:53 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 06:09:53 @monitor.py:363][0m lr: 9.5367e-10
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 06:09:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 06:09:53 @monitor.py:363][0m train-error-top1: 0.54629
[32m[0323 06:09:53 @monitor.py:363][0m val-error-top1: 0.557
[32m[0323 06:09:53 @monitor.py:363][0m val-utt-error: 0.12783
[32m[0323 06:09:53 @monitor.py:363][0m validation_cost: 2.1995
[32m[0323 06:09:53 @monitor.py:363][0m wd_cost: 1.8066e-13
[32m[0323 06:09:53 @group.py:42][0m Callbacks took 294.477 sec in total. InferenceRunner: 294.150sec
[32m[0323 06:09:53 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20423/173481[03:00<22:29,113.46it/s] 12%|#2        |21655/173481[03:10<22:18,113.46it/s] 24%|##4       |42165/173481[06:00<18:42,117.01it/s] 25%|##5       |43480/173481[06:10<18:31,117.01it/s] 37%|###7      |64760/173481[09:00<14:57,121.11it/s] 38%|###8      |66083/173481[09:10<14:46,121.11it/s] 47%|####6     |80920/173481[12:00<14:57,103.11it/s] 47%|####7     |81729/173481[12:10<14:49,103.11it/s] 54%|#####4    |94396/173481[15:00<15:11,86.74it/s]  55%|#####4    |95193/173481[15:10<15:02,86.74it/s] 62%|######1   |107422/173481[18:00<13:57,78.90it/s] 62%|######2   |108273/173481[18:10<13:46,78.90it/s] 70%|######9   |120629/173481[21:00<11:35,76.04it/s] 70%|#######   |121477/173481[21:11<11:23,76.04it/s] 77%|#######7  |133677/173481[24:00<08:56,74.22it/s] 77%|#######7  |134427/173481[24:11<08:46,74.22it/s] 84%|########4 |145874/173481[27:00<06:29,70.84it/s] 85%|########4 |146658/173481[27:11<06:18,70.84it/s] 91%|#########1|158592/173481[30:00<03:30,70.75it/s] 92%|#########1|159441/173481[30:11<03:18,70.75it/s] 98%|#########8|170842/173481[33:00<00:38,69.38it/s] 99%|#########8|171626/173481[33:11<00:26,69.38it/s]100%|##########|173481/173481[33:39<00:00,85.88it/s]
[32m[0323 06:43:33 @base.py:257][0m Epoch 28 (global_step 10061898) finished, time:2019.95 sec.
[32m[0323 06:43:34 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-10061898.
  0%|          |0/18822[00:00<?,?it/s] 66%|######5   |12359/18822[03:00<01:34,68.66it/s] 69%|######9   |13057/18822[03:10<01:23,68.66it/s]100%|##########|18822/18822[04:24<00:00,71.17it/s]
27
[32m[0323 06:47:58 @monitor.py:363][0m QueueInput/queue_size: 0.90955
[32m[0323 06:47:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.805
[32m[0323 06:47:58 @monitor.py:363][0m activation-summaries/output-rms: 0.037379
[32m[0323 06:47:58 @monitor.py:363][0m cross_entropy_loss: 2.2149
[32m[0323 06:47:58 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 06:47:58 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 06:47:58 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 06:47:58 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 06:47:58 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 06:47:58 @monitor.py:363][0m linear2/W_0_percent_n: 0.42173
[32m[0323 06:47:58 @monitor.py:363][0m linear2/W_0_percent_p: 0.39414
[32m[0323 06:47:58 @monitor.py:363][0m linear2/W_0_sparsity: 0.18369
[32m[0323 06:47:58 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 06:47:58 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 06:47:58 @monitor.py:363][0m linear3/W_0_percent_n: 0.43008
[32m[0323 06:47:58 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 06:47:58 @monitor.py:363][0m linear3/W_0_sparsity: 0.17449
[32m[0323 06:47:58 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 06:47:58 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 06:47:58 @monitor.py:363][0m lr: 4.7684e-10
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 06:47:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 06:47:58 @monitor.py:363][0m train-error-top1: 0.56166
[32m[0323 06:47:58 @monitor.py:363][0m val-error-top1: 0.5575
[32m[0323 06:47:58 @monitor.py:363][0m val-utt-error: 0.12948
[32m[0323 06:47:58 @monitor.py:363][0m validation_cost: 2.2023
[32m[0323 06:47:58 @monitor.py:363][0m wd_cost: 1.8066e-13
[32m[0323 06:47:58 @group.py:42][0m Callbacks took 264.786 sec in total. InferenceRunner: 264.477sec
[32m[0323 06:47:58 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17186/173481[03:00<27:16,95.48it/s] 11%|#         |18441/173481[03:10<27:03,95.48it/s] 22%|##2       |38188/173481[06:00<21:28,105.02it/s] 23%|##2       |39447/173481[06:10<21:16,105.02it/s] 35%|###4      |59892/173481[09:00<16:51,112.26it/s] 35%|###5      |61062/173481[09:10<16:41,112.26it/s] 45%|####4     |77657/173481[12:00<15:12,105.04it/s] 45%|####5     |78685/173481[12:10<15:02,105.04it/s] 55%|#####5    |95790/173481[15:00<12:35,102.84it/s] 56%|#####5    |96528/173481[15:10<12:28,102.84it/s] 64%|######3   |110947/173481[18:00<11:15,92.59it/s] 64%|######4   |111666/173481[18:10<11:07,92.59it/s] 72%|#######2  |125576/173481[21:00<09:13,86.56it/s] 73%|#######2  |126282/173481[21:11<09:05,86.56it/s] 82%|########2 |142739/173481[24:00<05:38,90.74it/s] 83%|########3 |144023/173481[24:11<05:24,90.74it/s] 92%|#########1|158737/173481[27:00<02:44,89.80it/s] 92%|#########1|159574/173481[27:11<02:34,89.80it/s] 99%|#########8|171321/173481[30:00<00:27,78.62it/s] 99%|#########9|172143/173481[30:11<00:17,78.62it/s]100%|##########|173481/173481[30:30<00:00,94.76it/s]
[32m[0323 07:18:29 @base.py:257][0m Epoch 29 (global_step 10235379) finished, time:1830.79 sec.
[32m[0323 07:18:29 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-10235379.
  0%|          |0/18822[00:00<?,?it/s] 70%|#######   |13260/18822[03:00<01:15,73.66it/s] 74%|#######3  |13915/18822[03:10<01:06,73.66it/s]100%|##########|18822/18822[04:18<00:00,72.76it/s]
28
[32m[0323 07:22:48 @monitor.py:363][0m QueueInput/queue_size: 0.85395
[32m[0323 07:22:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.668
[32m[0323 07:22:48 @monitor.py:363][0m activation-summaries/output-rms: 0.038581
[32m[0323 07:22:48 @monitor.py:363][0m cross_entropy_loss: 2.1704
[32m[0323 07:22:48 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 07:22:48 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 07:22:48 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 07:22:48 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 07:22:48 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 07:22:48 @monitor.py:363][0m linear2/W_0_percent_n: 0.42173
[32m[0323 07:22:48 @monitor.py:363][0m linear2/W_0_percent_p: 0.39414
[32m[0323 07:22:48 @monitor.py:363][0m linear2/W_0_sparsity: 0.18369
[32m[0323 07:22:48 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 07:22:48 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 07:22:48 @monitor.py:363][0m linear3/W_0_percent_n: 0.43008
[32m[0323 07:22:48 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 07:22:48 @monitor.py:363][0m linear3/W_0_sparsity: 0.17449
[32m[0323 07:22:48 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 07:22:48 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 07:22:48 @monitor.py:363][0m lr: 4.7684e-10
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 07:22:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 07:22:48 @monitor.py:363][0m train-error-top1: 0.56128
[32m[0323 07:22:48 @monitor.py:363][0m val-error-top1: 0.55673
[32m[0323 07:22:48 @monitor.py:363][0m val-utt-error: 0.13091
[32m[0323 07:22:48 @monitor.py:363][0m validation_cost: 2.198
[32m[0323 07:22:48 @monitor.py:363][0m wd_cost: 3.6133e-14
[32m[0323 07:22:48 @group.py:42][0m Callbacks took 259.029 sec in total. InferenceRunner: 258.709sec
[32m[0323 07:22:48 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21135/173481[03:00<21:37,117.41it/s] 13%|#2        |22260/173481[03:10<21:27,117.41it/s] 21%|##1       |36707/173481[06:00<22:52,99.62it/s]  22%|##1       |37748/173481[06:10<22:42,99.62it/s] 31%|###1      |54151/173481[09:00<20:14,98.25it/s] 32%|###1      |55082/173481[09:10<20:05,98.25it/s] 41%|####1     |71546/173481[12:00<17:26,97.43it/s] 42%|####1     |72609/173481[12:10<17:15,97.43it/s] 52%|#####1    |89764/173481[15:00<14:03,99.27it/s] 52%|#####2    |90495/173481[15:10<13:55,99.27it/s] 61%|######1   |106533/173481[18:00<11:36,96.12it/s] 62%|######2   |107701/173481[18:10<11:24,96.12it/s] 72%|#######1  |124459/173481[21:00<08:21,97.82it/s] 72%|#######2  |125623/173481[21:11<08:09,97.82it/s] 80%|########  |138851/173481[24:00<06:33,87.99it/s] 81%|########  |139696/173481[24:11<06:23,87.99it/s] 88%|########7 |152386/173481[27:00<04:20,81.09it/s] 88%|########8 |153192/173481[27:11<04:10,81.09it/s] 95%|#########5|165292/173481[30:00<01:47,76.10it/s] 96%|#########5|166164/173481[30:11<01:36,76.10it/s]100%|##########|173481/173481[31:52<00:00,90.73it/s]
[32m[0323 07:54:40 @base.py:257][0m Epoch 30 (global_step 10408860) finished, time:1912.05 sec.
[32m[0323 07:54:41 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-10408860.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.61it/s]
29
[32m[0323 07:56:40 @monitor.py:363][0m QueueInput/queue_size: 0.84124
[32m[0323 07:56:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 56.438
[32m[0323 07:56:40 @monitor.py:363][0m activation-summaries/output-rms: 0.039168
[32m[0323 07:56:40 @monitor.py:363][0m cross_entropy_loss: 2.0919
[32m[0323 07:56:40 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 07:56:40 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 07:56:40 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 07:56:40 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 07:56:40 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 07:56:40 @monitor.py:363][0m linear2/W_0_percent_n: 0.42173
[32m[0323 07:56:40 @monitor.py:363][0m linear2/W_0_percent_p: 0.39414
[32m[0323 07:56:40 @monitor.py:363][0m linear2/W_0_sparsity: 0.18369
[32m[0323 07:56:40 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 07:56:40 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 07:56:40 @monitor.py:363][0m linear3/W_0_percent_n: 0.43008
[32m[0323 07:56:40 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 07:56:40 @monitor.py:363][0m linear3/W_0_sparsity: 0.17449
[32m[0323 07:56:40 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 07:56:40 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 07:56:40 @monitor.py:363][0m lr: 2.3842e-10
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 07:56:40 @monitor.py:363][0m train-error-top1: 0.54058
[32m[0323 07:56:40 @monitor.py:363][0m val-error-top1: 0.55661
[32m[0323 07:56:40 @monitor.py:363][0m val-utt-error: 0.12937
[32m[0323 07:56:40 @monitor.py:363][0m validation_cost: 2.194
[32m[0323 07:56:40 @monitor.py:363][0m wd_cost: 3.6133e-14
[32m[0323 07:56:40 @group.py:42][0m Callbacks took 120.412 sec in total. InferenceRunner: 119.434sec
[32m[0323 07:56:40 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14917/173481[03:00<31:53,82.87it/s]  9%|9         |15714/173481[03:10<31:43,82.87it/s] 16%|#6        |28549/173481[06:00<30:31,79.13it/s] 17%|#6        |29340/173481[06:10<30:21,79.13it/s] 24%|##4       |41965/173481[09:00<28:33,76.76it/s] 25%|##4       |42777/173481[09:10<28:22,76.76it/s] 32%|###1      |55225/173481[12:00<26:13,75.18it/s] 32%|###2      |55976/173481[12:10<26:03,75.18it/s] 39%|###9      |67970/173481[15:00<24:06,72.92it/s] 40%|###9      |68784/173481[15:10<23:55,72.92it/s] 47%|####6     |81253/173481[18:00<20:57,73.36it/s] 47%|####7     |82062/173481[18:10<20:46,73.36it/s] 54%|#####4    |94039/173481[21:00<18:20,72.17it/s] 55%|#####4    |94860/173481[21:11<18:09,72.17it/s] 62%|######1   |106772/173481[24:00<15:33,71.45it/s] 62%|######2   |107563/173481[24:11<15:22,71.45it/s] 69%|######8   |119255/173481[27:00<12:50,70.38it/s] 69%|######9   |120077/173481[27:11<12:38,70.38it/s] 76%|#######6  |132049/173481[30:00<09:45,70.73it/s] 77%|#######6  |132827/173481[30:11<09:34,70.73it/s] 83%|########3 |144511/173481[33:00<06:54,69.96it/s] 84%|########3 |145302/173481[33:11<06:42,69.96it/s] 91%|######### |157331/173481[36:00<03:48,70.59it/s] 91%|#########1|158160/173481[36:11<03:37,70.59it/s] 98%|#########8|170158/173481[39:00<00:46,70.92it/s] 99%|#########8|171006/173481[39:11<00:34,70.92it/s]100%|##########|173481/173481[39:46<00:00,72.70it/s]
[32m[0323 08:36:27 @base.py:257][0m Epoch 31 (global_step 10582341) finished, time:2386.38 sec.
[32m[0323 08:36:27 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 82%|########2 |15481/18822[03:00<00:38,86.00it/s] 88%|########7 |16555/18822[03:10<00:26,86.00it/s]100%|##########|18822/18822[03:28<00:00,90.33it/s]
30
[32m[0323 08:39:56 @monitor.py:363][0m QueueInput/queue_size: 0.64413
[32m[0323 08:39:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.533
[32m[0323 08:39:56 @monitor.py:363][0m activation-summaries/output-rms: 0.039029
[32m[0323 08:39:56 @monitor.py:363][0m cross_entropy_loss: 2.1473
[32m[0323 08:39:56 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 08:39:56 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 08:39:56 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 08:39:56 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 08:39:56 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 08:39:56 @monitor.py:363][0m linear2/W_0_percent_n: 0.42173
[32m[0323 08:39:56 @monitor.py:363][0m linear2/W_0_percent_p: 0.39414
[32m[0323 08:39:56 @monitor.py:363][0m linear2/W_0_sparsity: 0.18369
[32m[0323 08:39:56 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 08:39:56 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 08:39:56 @monitor.py:363][0m linear3/W_0_percent_n: 0.43008
[32m[0323 08:39:56 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 08:39:56 @monitor.py:363][0m linear3/W_0_sparsity: 0.17449
[32m[0323 08:39:56 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 08:39:56 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 08:39:56 @monitor.py:363][0m lr: 2.3842e-10
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 08:39:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 08:39:56 @monitor.py:363][0m train-error-top1: 0.55101
[32m[0323 08:39:56 @monitor.py:363][0m val-error-top1: 0.55593
[32m[0323 08:39:56 @monitor.py:363][0m val-utt-error: 0.12863
[32m[0323 08:39:56 @monitor.py:363][0m validation_cost: 2.192
[32m[0323 08:39:56 @monitor.py:363][0m wd_cost: 7.2266e-15
[32m[0323 08:39:56 @group.py:42][0m Callbacks took 208.758 sec in total. InferenceRunner: 208.384sec
[32m[0323 08:39:56 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s] 13%|#3        |22824/173481[03:00<19:48,126.80it/s] 14%|#3        |24076/173481[03:10<19:38,126.80it/s] 23%|##2       |39772/173481[06:00<20:37,108.06it/s] 23%|##3       |40479/173481[06:10<20:30,108.06it/s] 30%|###       |52175/173481[09:00<24:01,84.15it/s]  30%|###       |52875/173481[09:10<23:53,84.15it/s] 37%|###7      |64324/173481[12:00<24:17,74.90it/s] 37%|###7      |65031/173481[12:10<24:07,74.90it/s] 44%|####3     |76138/173481[15:00<23:11,69.96it/s] 44%|####4     |76773/173481[15:10<23:02,69.96it/s] 50%|#####     |87391/173481[18:00<21:43,66.03it/s] 51%|#####     |88112/173481[18:10<21:32,66.03it/s] 57%|#####7    |99424/173481[21:00<18:34,66.44it/s] 58%|#####7    |100205/173481[21:11<18:22,66.44it/s] 65%|######4   |112567/173481[24:00<14:35,69.57it/s] 65%|######5   |113362/173481[24:11<14:24,69.57it/s] 73%|#######2  |126000/173481[27:00<10:59,72.01it/s] 73%|#######3  |126790/173481[27:11<10:48,72.01it/s] 80%|########  |139444/173481[30:00<07:44,73.32it/s] 81%|########  |140306/173481[30:11<07:32,73.32it/s] 88%|########8 |152722/173481[33:00<04:42,73.54it/s] 89%|########8 |153572/173481[33:11<04:30,73.54it/s] 96%|#########5|165940/173481[36:00<01:42,73.48it/s] 96%|#########6|166793/173481[36:11<01:31,73.48it/s]100%|##########|173481/173481[37:42<00:00,76.67it/s]
[32m[0323 09:17:38 @base.py:257][0m Epoch 32 (global_step 10755822) finished, time:2262.65 sec.
[32m[0323 09:17:39 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-10755822.
[32m[0323 09:17:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######7  |14524/18822[03:00<00:53,80.69it/s] 81%|########1 |15289/18822[03:10<00:43,80.69it/s]100%|##########|18822/18822[03:54<00:00,80.34it/s]
31
[32m[0323 09:21:34 @monitor.py:363][0m QueueInput/queue_size: 0.46823
[32m[0323 09:21:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 57.857
[32m[0323 09:21:34 @monitor.py:363][0m activation-summaries/output-rms: 0.039217
[32m[0323 09:21:34 @monitor.py:363][0m cross_entropy_loss: 2.1408
[32m[0323 09:21:34 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 09:21:34 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 09:21:34 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 09:21:34 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 09:21:34 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 09:21:34 @monitor.py:363][0m linear2/W_0_percent_n: 0.42173
[32m[0323 09:21:34 @monitor.py:363][0m linear2/W_0_percent_p: 0.39414
[32m[0323 09:21:34 @monitor.py:363][0m linear2/W_0_sparsity: 0.18369
[32m[0323 09:21:34 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 09:21:34 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 09:21:34 @monitor.py:363][0m linear3/W_0_percent_n: 0.43008
[32m[0323 09:21:34 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 09:21:34 @monitor.py:363][0m linear3/W_0_sparsity: 0.17449
[32m[0323 09:21:34 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 09:21:34 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 09:21:34 @monitor.py:363][0m lr: 2.3842e-10
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 09:21:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 09:21:34 @monitor.py:363][0m train-error-top1: 0.5569
[32m[0323 09:21:34 @monitor.py:363][0m val-error-top1: 0.55661
[32m[0323 09:21:34 @monitor.py:363][0m val-utt-error: 0.1307
[32m[0323 09:21:34 @monitor.py:363][0m validation_cost: 2.1967
[32m[0323 09:21:34 @monitor.py:363][0m wd_cost: 7.2266e-15
[32m[0323 09:21:34 @group.py:42][0m Callbacks took 235.353 sec in total. InferenceRunner: 234.290sec
[32m[0323 09:21:34 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s] 13%|#3        |22589/173481[03:00<20:02,125.49it/s] 14%|#3        |23897/173481[03:10<19:51,125.49it/s] 25%|##4       |43183/173481[06:00<18:08,119.69it/s] 25%|##5       |43936/173481[06:10<18:02,119.69it/s] 33%|###2      |56387/173481[09:00<21:27,90.96it/s]  33%|###2      |57156/173481[09:10<21:18,90.96it/s] 40%|####      |69842/173481[12:00<21:02,82.06it/s] 41%|####      |70521/173481[12:10<20:54,82.06it/s] 48%|####8     |83449/173481[15:00<19:04,78.69it/s] 48%|####8     |84103/173481[15:10<18:55,78.69it/s] 55%|#####5    |95905/173481[18:00<17:33,73.63it/s] 56%|#####5    |96630/173481[18:10<17:23,73.63it/s] 62%|######2   |108010/173481[21:00<15:31,70.29it/s] 63%|######2   |108940/173481[21:11<15:18,70.29it/s] 72%|#######2  |125134/173481[24:00<09:57,80.85it/s] 73%|#######2  |126383/173481[24:11<09:42,80.85it/s] 80%|#######9  |137962/173481[27:00<07:48,75.76it/s] 80%|#######9  |138720/173481[27:11<07:38,75.76it/s] 87%|########6 |150097/173481[30:00<05:27,71.34it/s] 87%|########6 |150852/173481[30:11<05:17,71.34it/s] 97%|#########6|167437/173481[33:00<01:13,81.97it/s] 97%|#########7|168710/173481[33:11<00:58,81.97it/s]100%|##########|173481/173481[34:12<00:00,84.52it/s]
[32m[0323 09:55:46 @base.py:257][0m Epoch 33 (global_step 10929303) finished, time:2052.44 sec.
[32m[0323 09:55:46 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s] 68%|######7   |12729/18822[03:00<01:26,70.71it/s] 71%|#######   |13338/18822[03:10<01:17,70.71it/s]100%|##########|18822/18822[04:38<00:00,67.56it/s]
32
[32m[0323 10:00:25 @monitor.py:363][0m QueueInput/queue_size: 0.73976
[32m[0323 10:00:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.763
[32m[0323 10:00:25 @monitor.py:363][0m activation-summaries/output-rms: 0.03899
[32m[0323 10:00:25 @monitor.py:363][0m cross_entropy_loss: 2.1086
[32m[0323 10:00:25 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 10:00:25 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 10:00:25 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 10:00:25 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 10:00:25 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 10:00:25 @monitor.py:363][0m linear2/W_0_percent_n: 0.42173
[32m[0323 10:00:25 @monitor.py:363][0m linear2/W_0_percent_p: 0.39414
[32m[0323 10:00:25 @monitor.py:363][0m linear2/W_0_sparsity: 0.18369
[32m[0323 10:00:25 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 10:00:25 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 10:00:25 @monitor.py:363][0m linear3/W_0_percent_n: 0.43008
[32m[0323 10:00:25 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 10:00:25 @monitor.py:363][0m linear3/W_0_sparsity: 0.17449
[32m[0323 10:00:25 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 10:00:25 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 10:00:25 @monitor.py:363][0m lr: 1.1921e-10
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 10:00:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 10:00:25 @monitor.py:363][0m train-error-top1: 0.54459
[32m[0323 10:00:25 @monitor.py:363][0m val-error-top1: 0.55707
[32m[0323 10:00:25 @monitor.py:363][0m val-utt-error: 0.12884
[32m[0323 10:00:25 @monitor.py:363][0m validation_cost: 2.1996
[32m[0323 10:00:25 @monitor.py:363][0m wd_cost: 7.2266e-15
[32m[0323 10:00:25 @group.py:42][0m Callbacks took 278.918 sec in total. InferenceRunner: 278.606sec
[32m[0323 10:00:25 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19506/173481[03:00<23:40,108.36it/s] 12%|#1        |20616/173481[03:10<23:30,108.36it/s] 23%|##2       |39052/173481[06:00<20:39,108.47it/s] 23%|##3       |40170/173481[06:10<20:28,108.47it/s] 34%|###3      |58583/173481[09:00<17:39,108.49it/s] 34%|###4      |59708/173481[09:10<17:28,108.49it/s] 45%|####5     |78128/173481[12:00<14:38,108.53it/s] 46%|####5     |79289/173481[12:10<14:27,108.53it/s] 56%|#####6    |97865/173481[15:00<11:33,109.09it/s] 57%|#####7    |99237/173481[15:10<11:20,109.09it/s] 68%|######8   |118642/173481[18:00<08:08,112.16it/s] 69%|######9   |119777/173481[18:11<07:58,112.16it/s] 79%|#######9  |137738/173481[21:00<05:27,109.04it/s] 80%|########  |138935/173481[21:11<05:16,109.04it/s] 91%|######### |157201/173481[24:00<02:29,108.58it/s] 91%|#########1|158318/173481[24:11<02:19,108.58it/s] 98%|#########8|170071/173481[27:00<00:39,86.22it/s]  98%|#########8|170859/173481[27:11<00:30,86.22it/s]100%|##########|173481/173481[27:49<00:00,103.92it/s]
[32m[0323 10:28:14 @base.py:257][0m Epoch 34 (global_step 11102784) finished, time:1669.34 sec.
[32m[0323 10:28:15 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_False_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s] 88%|########7 |16480/18822[03:00<00:25,91.55it/s] 98%|#########7|18385/18822[03:10<00:04,91.55it/s]100%|##########|18822/18822[03:12<00:00,97.80it/s]
33
[32m[0323 10:31:27 @monitor.py:363][0m QueueInput/queue_size: 0.94191
[32m[0323 10:31:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.805
[32m[0323 10:31:27 @monitor.py:363][0m activation-summaries/output-rms: 0.037379
[32m[0323 10:31:27 @monitor.py:363][0m cross_entropy_loss: 2.2149
[32m[0323 10:31:27 @monitor.py:363][0m linear1/W_0_percent_n: 0.38185
[32m[0323 10:31:27 @monitor.py:363][0m linear1/W_0_percent_p: 0.35401
[32m[0323 10:31:27 @monitor.py:363][0m linear1/W_0_sparsity: 0.2631
[32m[0323 10:31:27 @monitor.py:363][0m linear1/Wn_0: 0.97206
[32m[0323 10:31:27 @monitor.py:363][0m linear1/Wp_0: 1.029
[32m[0323 10:31:27 @monitor.py:363][0m linear2/W_0_percent_n: 0.42173
[32m[0323 10:31:27 @monitor.py:363][0m linear2/W_0_percent_p: 0.39414
[32m[0323 10:31:27 @monitor.py:363][0m linear2/W_0_sparsity: 0.18369
[32m[0323 10:31:27 @monitor.py:363][0m linear2/Wn_0: 0.98687
[32m[0323 10:31:27 @monitor.py:363][0m linear2/Wp_0: 1.0153
[32m[0323 10:31:27 @monitor.py:363][0m linear3/W_0_percent_n: 0.43008
[32m[0323 10:31:27 @monitor.py:363][0m linear3/W_0_percent_p: 0.39492
[32m[0323 10:31:27 @monitor.py:363][0m linear3/W_0_sparsity: 0.17449
[32m[0323 10:31:27 @monitor.py:363][0m linear3/Wn_0: 1.0741
[32m[0323 10:31:27 @monitor.py:363][0m linear3/Wp_0: 0.92986
[32m[0323 10:31:27 @monitor.py:363][0m lr: 1.1921e-10
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68371
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0465
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28848
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061313
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31983
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064122
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29633
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.06223
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0323 10:31:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.0643
[32m[0323 10:31:27 @monitor.py:363][0m train-error-top1: 0.5617
[32m[0323 10:31:27 @monitor.py:363][0m val-error-top1: 0.5575
[32m[0323 10:31:27 @monitor.py:363][0m val-utt-error: 0.12948
[32m[0323 10:31:27 @monitor.py:363][0m validation_cost: 2.2023
[32m[0323 10:31:27 @monitor.py:363][0m wd_cost: 1.4453e-15
[32m[0323 10:31:27 @group.py:42][0m Callbacks took 192.845 sec in total. InferenceRunner: 192.477sec
[32m[0323 10:31:27 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |18146/173481[03:00<25:40,100.81it/s] 11%|#1        |19245/173481[03:10<25:30,100.81it/s] 20%|##        |35357/173481[06:00<23:27,98.14it/s]  21%|##        |36427/173481[06:10<23:16,98.14it/s] 31%|###       |53499/173481[09:00<20:06,99.45it/s] 31%|###1      |54612/173481[09:10<19:55,99.45it/s]slurmstepd: *** JOB 82390 ON sls-tesla-1 CANCELLED AT 2018-03-23T10:41:26 ***
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 82390.0 ON sls-tesla-1 CANCELLED AT 2018-03-23T10:41:26 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
