sls-sm-16 1
SLURM_JOBID=340355
SLURM_TASKID=1
../dorefa/real/train_log/fcn1_w_4_a_32_quant_ends_True_preload/checkpoint
[32m[0417 14:46:16 @logger.py:74][0m Argv: ttq_run.py --model_name=fcn1 --quant_ends=True
[32m[0417 14:46:18 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0417 14:46:18 @ttq_run.py:140][0m Using 6 threads
('whole utterance size', 75290)
[32m[0417 14:46:18 @ttq_run.py:164][0m 18822 utterances per val epoch
[32m[0417 14:46:18 @ttq_run.py:165][0m Using host: sls-sm-16
[32m[0417 14:46:18 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0417 14:46:18 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0417 14:46:18 @ttq_run.py:187][0m Using GPU: 1
[32m[0417 14:46:18 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0417 14:46:18 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0417 14:46:18 @training.py:108][0m Building graph for training tower 0 ...
[32m[0417 14:46:18 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0417 14:46:18 @ttq_run.py:71][0m Ternarizing weight linear0/W
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear0/Wp
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear0/Wn
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear0/b
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear0/bn/beta
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear0/bn/gamma
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear0/bn/mean/EMA
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear0/bn/variance/EMA
[32m[0417 14:46:18 @registry.py:130][0m linear0 output: [None, 256]
[32m[0417 14:46:18 @registry.py:122][0m linear1 input: [None, 256]
[32m[0417 14:46:18 @ttq_run.py:71][0m Ternarizing weight linear1/W
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear1/Wp
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear1/Wn
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear1/b
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear1/bn/beta
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear1/bn/gamma
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear1/bn/mean/EMA
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear1/bn/variance/EMA
[32m[0417 14:46:18 @registry.py:130][0m linear1 output: [None, 256]
[32m[0417 14:46:18 @registry.py:122][0m linear2 input: [None, 256]
[32m[0417 14:46:18 @ttq_run.py:71][0m Ternarizing weight linear2/W
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear2/Wp
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear2/Wn
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear2/b
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear2/bn/beta
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear2/bn/gamma
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear2/bn/mean/EMA
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear2/bn/variance/EMA
[32m[0417 14:46:18 @registry.py:130][0m linear2 output: [None, 256]
[32m[0417 14:46:18 @registry.py:122][0m linear3 input: [None, 256]
[32m[0417 14:46:18 @ttq_run.py:71][0m Ternarizing weight linear3/W
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear3/Wp
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear3/Wn
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear3/b
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear3/bn/beta
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear3/bn/gamma
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear3/bn/mean/EMA
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing linear3/bn/variance/EMA
[32m[0417 14:46:18 @registry.py:130][0m linear3 output: [None, 256]
[32m[0417 14:46:18 @registry.py:122][0m last_linear input: [None, 256]
[32m[0417 14:46:18 @ttq_run.py:71][0m Ternarizing weight last_linear/W
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing last_linear/Wp
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing last_linear/Wn
[32m[0417 14:46:18 @ttq_run.py:59][0m Not ternarizing last_linear/b
[32m[0417 14:46:18 @registry.py:130][0m last_linear output: [None, 255]
[32m[0417 14:46:19 @ttq_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0417 14:46:19 @regularize.py:81][0m regularize_cost() found 15 tensors.
[32m[0417 14:46:19 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear0/Wp:0, linear0/Wn:0, linear1/W:0, linear1/Wp:0, linear1/Wn:0, linear2/W:0, linear2/Wp:0, linear2/Wn:0, linear3/W:0, linear3/Wp:0, linear3/Wn:0, last_linear/W:0, last_linear/Wp:0, last_linear/Wn:0
[32m[0417 14:46:19 @ttq_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0417 14:46:19 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/Wp:0        []                1
linear0/Wn:0        []                1
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/Wp:0        []                1
linear1/Wn:0        []                1
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/Wp:0        []                1
linear2/Wn:0        []                1
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/Wp:0        []                1
linear3/Wn:0        []                1
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/Wp:0    []                1
last_linear/Wn:0    []                1
last_linear/b:0     [255]           255[36m
Total #vars=28, #params=521225, size=1.99MB[0m
[32m[0417 14:46:19 @base.py:196][0m Setup callbacks graph ...
[32m[0417 14:46:20 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0417 14:46:20 @ttq_run.py:71][0m Ternarizing weight linear0/W
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear0/Wp
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear0/Wn
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear0/b
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear0/bn/beta
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear0/bn/gamma
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear0/bn/mean/EMA
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear0/bn/variance/EMA
[32m[0417 14:46:20 @ttq_run.py:71][0m Ternarizing weight linear1/W
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear1/Wp
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear1/Wn
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear1/b
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear1/bn/beta
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear1/bn/gamma
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear1/bn/mean/EMA
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear1/bn/variance/EMA
[32m[0417 14:46:20 @ttq_run.py:71][0m Ternarizing weight linear2/W
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear2/Wp
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear2/Wn
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear2/b
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear2/bn/beta
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear2/bn/gamma
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear2/bn/mean/EMA
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear2/bn/variance/EMA
[32m[0417 14:46:20 @ttq_run.py:71][0m Ternarizing weight linear3/W
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear3/Wp
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear3/Wn
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear3/b
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear3/bn/beta
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear3/bn/gamma
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear3/bn/mean/EMA
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing linear3/bn/variance/EMA
[32m[0417 14:46:20 @ttq_run.py:71][0m Ternarizing weight last_linear/W
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing last_linear/Wp
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing last_linear/Wn
[32m[0417 14:46:20 @ttq_run.py:59][0m Not ternarizing last_linear/b
[32m[0417 14:46:20 @ttq_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0417 14:46:20 @ttq_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0417 14:46:20 @collection.py:153][0m These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 59->89)
[32m[0417 14:46:20 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0417 14:46:20 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0417 14:46:20 @base.py:212][0m Creating the session ...
2018-04-17 14:46:20.784758: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-17 14:46:22.957508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:03:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-04-17 14:46:22.957561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
[32m[0417 14:46:31 @base.py:220][0m Initializing the session ...
[32m[0417 14:46:31 @base.py:227][0m Graph Finalized.
[32m[0417 14:46:31 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0417 14:46:35 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  2%|2         |3829/173481[03:04<2:16:02,20.78it/s]  2%|2         |3864/173481[03:20<2:16:01,20.78it/s]  3%|2         |4714/173481[06:04<5:54:07, 7.94it/s]  3%|2         |4788/173481[06:20<5:53:58, 7.94it/s]  5%|4         |8140/173481[09:04<4:05:51,11.21it/s]  5%|5         |9372/173481[09:20<4:04:01,11.21it/s] 12%|#2        |21523/173481[12:04<2:10:00,19.48it/s] 13%|#3        |22735/173481[12:20<2:08:58,19.48it/s] 20%|#9        |34519/173481[15:04<1:15:29,30.68it/s] 21%|##        |35657/173481[15:20<1:14:52,30.68it/s] 26%|##6       |45751/173481[18:04<51:45,41.13it/s]   27%|##6       |46664/173481[18:20<51:23,41.13it/s] 31%|###       |53131/173481[21:04<48:51,41.06it/s] 31%|###       |53592/173481[21:21<48:40,41.06it/s] 34%|###4      |59773/173481[24:04<48:45,38.86it/s] 35%|###4      |60600/173481[24:21<48:24,38.86it/s] 40%|###9      |68587/173481[27:04<40:20,43.33it/s] 40%|####      |69402/173481[27:21<40:01,43.33it/s] 44%|####4     |76507/173481[30:04<37:00,43.66it/s] 45%|####4     |77317/173481[30:21<36:42,43.66it/s] 50%|####9     |85897/173481[33:04<30:42,47.54it/s] 50%|#####     |86826/173481[33:21<30:22,47.54it/s] 55%|#####5    |95437/173481[36:04<25:57,50.12it/s] 56%|#####5    |96288/173481[36:21<25:40,50.12it/s] 61%|######    |105043/173481[39:04<22:04,51.69it/s] 61%|######1   |106011/173481[39:21<21:45,51.69it/s] 66%|######6   |114523/173481[42:04<18:50,52.16it/s] 67%|######6   |115381/173481[42:22<18:33,52.16it/s] 71%|#######   |122563/173481[45:04<17:38,48.11it/s] 71%|#######1  |123402/173481[45:22<17:20,48.11it/s] 76%|#######6  |132431/173481[48:04<13:20,51.25it/s] 77%|#######6  |133423/173481[48:22<13:01,51.25it/s] 82%|########2 |142711/173481[51:05<09:29,54.01it/s] 83%|########2 |143733/173481[51:22<09:10,54.01it/s] 88%|########8 |153343/173481[54:05<05:56,56.42it/s] 89%|########8 |154392/173481[54:22<05:38,56.42it/s] 94%|#########4|163438/173481[57:05<02:58,56.25it/s] 95%|#########4|164154/173481[57:22<02:45,56.25it/s]100%|#########9|172877/173481[1:00:05<00:11,54.28it/s]100%|##########|173481/173481[1:00:13<00:00,48.00it/s]
[32m[0417 15:46:49 @base.py:257][0m Epoch 1 (global_step 173481) finished, time:3613.92 sec.
[32m[0417 15:46:49 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:33<00:00,122.84it/s]
0
[32m[0417 15:49:23 @monitor.py:363][0m QueueInput/queue_size: 2.4378
[32m[0417 15:49:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.1236
[32m[0417 15:49:23 @monitor.py:363][0m activation-summaries/output-rms: 0.014261
[32m[0417 15:49:23 @monitor.py:363][0m cross_entropy_loss: 3.9287
[32m[0417 15:49:23 @monitor.py:363][0m last_linear/W_0_percent_n: 0.21244
[32m[0417 15:49:23 @monitor.py:363][0m last_linear/W_0_percent_p: 0.1665
[32m[0417 15:49:23 @monitor.py:363][0m last_linear/W_0_sparsity: 0.62106
[32m[0417 15:49:23 @monitor.py:363][0m last_linear/Wn_0: 0.17464
[32m[0417 15:49:23 @monitor.py:363][0m last_linear/Wp_0: 0.18258
[32m[0417 15:49:23 @monitor.py:363][0m linear0/W_0_percent_n: 0.2722
[32m[0417 15:49:23 @monitor.py:363][0m linear0/W_0_percent_p: 0.22762
[32m[0417 15:49:23 @monitor.py:363][0m linear0/W_0_sparsity: 0.50018
[32m[0417 15:49:23 @monitor.py:363][0m linear0/Wn_0: 0.61445
[32m[0417 15:49:23 @monitor.py:363][0m linear0/Wp_0: 1.0924
[32m[0417 15:49:23 @monitor.py:363][0m linear1/W_0_percent_n: 0.14873
[32m[0417 15:49:23 @monitor.py:363][0m linear1/W_0_percent_p: 0.11401
[32m[0417 15:49:23 @monitor.py:363][0m linear1/W_0_sparsity: 0.73726
[32m[0417 15:49:23 @monitor.py:363][0m linear1/Wn_0: 0.78136
[32m[0417 15:49:23 @monitor.py:363][0m linear1/Wp_0: 0.71801
[32m[0417 15:49:23 @monitor.py:363][0m linear2/W_0_percent_n: 0.043213
[32m[0417 15:49:23 @monitor.py:363][0m linear2/W_0_percent_p: 0.047333
[32m[0417 15:49:23 @monitor.py:363][0m linear2/W_0_sparsity: 0.90945
[32m[0417 15:49:23 @monitor.py:363][0m linear2/Wn_0: 0.92876
[32m[0417 15:49:23 @monitor.py:363][0m linear2/Wp_0: 0.61181
[32m[0417 15:49:23 @monitor.py:363][0m linear3/W_0_percent_n: 0.042358
[32m[0417 15:49:23 @monitor.py:363][0m linear3/W_0_percent_p: 0.038162
[32m[0417 15:49:23 @monitor.py:363][0m linear3/W_0_sparsity: 0.91948
[32m[0417 15:49:23 @monitor.py:363][0m linear3/Wn_0: 0.63429
[32m[0417 15:49:23 @monitor.py:363][0m linear3/Wp_0: 0.61877
[32m[0417 15:49:23 @monitor.py:363][0m lr: 0.001
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.075867
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.57382
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.032803
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.068078
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083935
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.041897
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.039586
[32m[0417 15:49:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089962
[32m[0417 15:49:23 @monitor.py:363][0m train-error-top1: 0.85921
[32m[0417 15:49:23 @monitor.py:363][0m val-error-top1: 0.94358
[32m[0417 15:49:23 @monitor.py:363][0m val-utt-error: 0.87244
[32m[0417 15:49:23 @monitor.py:363][0m validation_cost: 4.8299
[32m[0417 15:49:23 @monitor.py:363][0m wd_cost: 0.1177
[32m[0417 15:49:23 @group.py:42][0m Callbacks took 153.637 sec in total. InferenceRunner: 153.240sec
[32m[0417 15:49:23 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14878/173481[03:00<31:58,82.65it/s]  9%|9         |15669/173481[03:10<31:49,82.65it/s] 17%|#6        |28648/173481[06:00<30:22,79.45it/s] 17%|#6        |29419/173481[06:10<30:13,79.45it/s] 23%|##3       |40676/173481[09:00<30:29,72.59it/s] 24%|##3       |41186/173481[09:10<30:22,72.59it/s] 28%|##7       |48316/173481[12:00<38:57,53.55it/s] 28%|##8       |48777/173481[12:10<38:48,53.55it/s] 32%|###2      |56290/173481[15:00<40:17,48.48it/s] 33%|###2      |56793/173481[15:10<40:06,48.48it/s] 37%|###6      |64102/173481[18:00<39:48,45.79it/s] 37%|###7      |64545/173481[18:10<39:38,45.79it/s] 41%|####1     |71444/173481[21:00<39:24,43.15it/s] 41%|####1     |71895/173481[21:11<39:14,43.15it/s] 45%|####5     |78806/173481[24:00<37:34,41.99it/s] 46%|####5     |79197/173481[24:11<37:25,41.99it/s] 50%|####9     |86464/173481[27:00<34:19,42.26it/s] 50%|#####     |86990/173481[27:11<34:06,42.26it/s] 54%|#####4    |94235/173481[30:00<30:55,42.71it/s] 55%|#####4    |94701/173481[30:11<30:44,42.71it/s] 60%|#####9    |103834/173481[33:00<24:29,47.39it/s] 60%|######    |104198/173481[33:11<24:21,47.39it/s] 65%|######4   |112732/173481[36:00<20:55,48.38it/s] 65%|######5   |113254/173481[36:11<20:44,48.38it/s] 71%|#######   |122723/173481[39:00<16:21,51.70it/s] 71%|#######1  |123460/173481[39:11<16:07,51.70it/s] 78%|#######7  |135187/173481[42:00<10:46,59.20it/s] 78%|#######8  |136059/173481[42:12<10:32,59.20it/s] 85%|########5 |147580/173481[45:00<06:46,63.65it/s] 85%|########5 |148101/173481[45:12<06:38,63.65it/s] 91%|#########1|158212/173481[48:00<04:09,61.27it/s] 92%|#########1|159039/173481[48:12<03:55,61.27it/s] 98%|#########7|169770/173481[51:00<00:59,62.70it/s] 98%|#########8|170667/173481[51:12<00:44,62.70it/s]100%|##########|173481/173481[52:05<00:00,55.51it/s]
[32m[0417 16:41:28 @base.py:257][0m Epoch 2 (global_step 346962) finished, time:3125.23 sec.
[32m[0417 16:41:28 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-346962.
[32m[0417 16:41:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,154.15it/s]
1
[32m[0417 16:43:30 @monitor.py:363][0m QueueInput/queue_size: 0.59637
[32m[0417 16:43:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.246
[32m[0417 16:43:30 @monitor.py:363][0m activation-summaries/output-rms: 0.015226
[32m[0417 16:43:30 @monitor.py:363][0m cross_entropy_loss: 3.8547
[32m[0417 16:43:30 @monitor.py:363][0m last_linear/W_0_percent_n: 0.22889
[32m[0417 16:43:30 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17345
[32m[0417 16:43:30 @monitor.py:363][0m last_linear/W_0_sparsity: 0.59766
[32m[0417 16:43:30 @monitor.py:363][0m last_linear/Wn_0: 0.1474
[32m[0417 16:43:31 @monitor.py:363][0m last_linear/Wp_0: 0.15146
[32m[0417 16:43:31 @monitor.py:363][0m linear0/W_0_percent_n: 0.27863
[32m[0417 16:43:31 @monitor.py:363][0m linear0/W_0_percent_p: 0.23175
[32m[0417 16:43:31 @monitor.py:363][0m linear0/W_0_sparsity: 0.48962
[32m[0417 16:43:31 @monitor.py:363][0m linear0/Wn_0: 0.60215
[32m[0417 16:43:31 @monitor.py:363][0m linear0/Wp_0: 1.0427
[32m[0417 16:43:31 @monitor.py:363][0m linear1/W_0_percent_n: 0.13084
[32m[0417 16:43:31 @monitor.py:363][0m linear1/W_0_percent_p: 0.10507
[32m[0417 16:43:31 @monitor.py:363][0m linear1/W_0_sparsity: 0.76408
[32m[0417 16:43:31 @monitor.py:363][0m linear1/Wn_0: 0.76668
[32m[0417 16:43:31 @monitor.py:363][0m linear1/Wp_0: 0.65192
[32m[0417 16:43:31 @monitor.py:363][0m linear2/W_0_percent_n: 0.042984
[32m[0417 16:43:31 @monitor.py:363][0m linear2/W_0_percent_p: 0.046585
[32m[0417 16:43:31 @monitor.py:363][0m linear2/W_0_sparsity: 0.91043
[32m[0417 16:43:31 @monitor.py:363][0m linear2/Wn_0: 0.88312
[32m[0417 16:43:31 @monitor.py:363][0m linear2/Wp_0: 0.61171
[32m[0417 16:43:31 @monitor.py:363][0m linear3/W_0_percent_n: 0.04303
[32m[0417 16:43:31 @monitor.py:363][0m linear3/W_0_percent_p: 0.039474
[32m[0417 16:43:31 @monitor.py:363][0m linear3/W_0_sparsity: 0.9175
[32m[0417 16:43:31 @monitor.py:363][0m linear3/Wn_0: 0.6425
[32m[0417 16:43:31 @monitor.py:363][0m linear3/Wp_0: 0.55523
[32m[0417 16:43:31 @monitor.py:363][0m lr: 0.001
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.074583
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.65072
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.032693
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.070296
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083936
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.04397
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086064
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.040448
[32m[0417 16:43:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 16:43:31 @monitor.py:363][0m train-error-top1: 0.85354
[32m[0417 16:43:31 @monitor.py:363][0m val-error-top1: 0.93527
[32m[0417 16:43:31 @monitor.py:363][0m val-utt-error: 0.8549
[32m[0417 16:43:31 @monitor.py:363][0m validation_cost: 4.6867
[32m[0417 16:43:31 @monitor.py:363][0m wd_cost: 0.11989
[32m[0417 16:43:31 @group.py:42][0m Callbacks took 122.656 sec in total. InferenceRunner: 122.114sec
[32m[0417 16:43:31 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16211/173481[03:00<29:06,90.06it/s] 10%|9         |17091/173481[03:10<28:56,90.06it/s] 18%|#8        |31703/173481[06:00<26:50,88.02it/s] 19%|#8        |32588/173481[06:10<26:40,88.02it/s] 27%|##6       |46467/173481[09:00<24:55,84.91it/s] 27%|##7       |47342/173481[09:10<24:45,84.91it/s] 35%|###5      |61420/173481[12:00<22:14,83.98it/s] 36%|###5      |62295/173481[12:10<22:03,83.98it/s] 44%|####3     |75889/173481[15:00<19:48,82.14it/s] 44%|####4     |76728/173481[15:10<19:37,82.14it/s] 52%|#####1    |89815/173481[18:00<17:30,79.67it/s] 52%|#####2    |90637/173481[18:10<17:19,79.67it/s] 60%|#####9    |103705/173481[21:00<14:50,78.39it/s] 60%|######    |104555/173481[21:10<14:39,78.39it/s] 66%|######6   |114907/173481[24:00<14:04,69.38it/s] 67%|######6   |115470/173481[24:11<13:56,69.38it/s] 72%|#######1  |124180/173481[27:00<13:53,59.13it/s] 72%|#######1  |124763/173481[27:11<13:43,59.13it/s] 77%|#######6  |133423/173481[30:00<12:08,54.96it/s] 77%|#######7  |134022/173481[30:11<11:57,54.96it/s] 82%|########2 |142747/173481[33:00<09:36,53.33it/s] 83%|########2 |143526/173481[33:11<09:21,53.33it/s] 89%|########9 |154675/173481[36:00<05:18,59.10it/s] 90%|########9 |155453/173481[36:11<05:05,59.10it/s] 95%|#########5|165571/173481[39:00<02:12,59.80it/s] 96%|#########5|166279/173481[39:11<02:00,59.80it/s]100%|##########|173481/173481[41:19<00:00,69.95it/s]
[32m[0417 17:24:50 @base.py:257][0m Epoch 3 (global_step 520443) finished, time:2479.97 sec.
[32m[0417 17:24:51 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-520443.
[32m[0417 17:24:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:27<00:00,127.37it/s]
2
[32m[0417 17:27:19 @monitor.py:363][0m QueueInput/queue_size: 0.79927
[32m[0417 17:27:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.1993
[32m[0417 17:27:19 @monitor.py:363][0m activation-summaries/output-rms: 0.01891
[32m[0417 17:27:19 @monitor.py:363][0m cross_entropy_loss: 3.4798
[32m[0417 17:27:19 @monitor.py:363][0m last_linear/W_0_percent_n: 0.2815
[32m[0417 17:27:19 @monitor.py:363][0m last_linear/W_0_percent_p: 0.1693
[32m[0417 17:27:19 @monitor.py:363][0m last_linear/W_0_sparsity: 0.5492
[32m[0417 17:27:19 @monitor.py:363][0m last_linear/Wn_0: 0.1556
[32m[0417 17:27:19 @monitor.py:363][0m last_linear/Wp_0: 0.1215
[32m[0417 17:27:19 @monitor.py:363][0m linear0/W_0_percent_n: 0.19518
[32m[0417 17:27:19 @monitor.py:363][0m linear0/W_0_percent_p: 0.17945
[32m[0417 17:27:19 @monitor.py:363][0m linear0/W_0_sparsity: 0.62536
[32m[0417 17:27:19 @monitor.py:363][0m linear0/Wn_0: 0.68149
[32m[0417 17:27:19 @monitor.py:363][0m linear0/Wp_0: 0.97637
[32m[0417 17:27:19 @monitor.py:363][0m linear1/W_0_percent_n: 0.12985
[32m[0417 17:27:19 @monitor.py:363][0m linear1/W_0_percent_p: 0.10567
[32m[0417 17:27:19 @monitor.py:363][0m linear1/W_0_sparsity: 0.76448
[32m[0417 17:27:19 @monitor.py:363][0m linear1/Wn_0: 0.72965
[32m[0417 17:27:19 @monitor.py:363][0m linear1/Wp_0: 0.70545
[32m[0417 17:27:19 @monitor.py:363][0m linear2/W_0_percent_n: 0.039963
[32m[0417 17:27:19 @monitor.py:363][0m linear2/W_0_percent_p: 0.045013
[32m[0417 17:27:19 @monitor.py:363][0m linear2/W_0_sparsity: 0.91502
[32m[0417 17:27:19 @monitor.py:363][0m linear2/Wn_0: 0.8597
[32m[0417 17:27:19 @monitor.py:363][0m linear2/Wp_0: 0.66703
[32m[0417 17:27:19 @monitor.py:363][0m linear3/W_0_percent_n: 0.04509
[32m[0417 17:27:19 @monitor.py:363][0m linear3/W_0_percent_p: 0.039886
[32m[0417 17:27:19 @monitor.py:363][0m linear3/W_0_sparsity: 0.91502
[32m[0417 17:27:19 @monitor.py:363][0m linear3/Wn_0: 0.61522
[32m[0417 17:27:19 @monitor.py:363][0m linear3/Wp_0: 0.61105
[32m[0417 17:27:19 @monitor.py:363][0m lr: 0.0005
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.1719
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.73895
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.091168
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20594
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.1336
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.12607
[32m[0417 17:27:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 17:27:19 @monitor.py:363][0m train-error-top1: 0.80497
[32m[0417 17:27:19 @monitor.py:363][0m val-error-top1: 0.87346
[32m[0417 17:27:19 @monitor.py:363][0m val-utt-error: 0.70476
[32m[0417 17:27:19 @monitor.py:363][0m validation_cost: 4.0164
[32m[0417 17:27:19 @monitor.py:363][0m wd_cost: 0.18099
[32m[0417 17:27:19 @group.py:42][0m Callbacks took 148.086 sec in total. InferenceRunner: 147.791sec
[32m[0417 17:27:19 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10760/173481[03:00<45:22,59.78it/s]  6%|6         |11265/173481[03:10<45:13,59.78it/s] 12%|#2        |21040/173481[06:00<43:30,58.41it/s] 12%|#2        |21631/173481[06:10<43:19,58.41it/s] 18%|#8        |31742/173481[09:00<40:05,58.93it/s] 19%|#8        |32344/173481[09:10<39:55,58.93it/s] 24%|##4       |42018/173481[12:00<37:46,57.99it/s] 25%|##4       |42627/173481[12:10<37:36,57.99it/s] 30%|###       |52048/173481[15:00<35:36,56.83it/s] 30%|###       |52647/173481[15:10<35:26,56.83it/s] 36%|###5      |62200/173481[18:00<32:45,56.61it/s] 36%|###6      |62873/173481[18:10<32:33,56.61it/s] 39%|###9      |67744/173481[21:00<44:12,39.86it/s] 39%|###9      |67965/173481[21:11<44:07,39.86it/s] 41%|####1     |71566/173481[24:00<1:01:20,27.69it/s] 41%|####1     |71781/173481[24:11<1:01:13,27.69it/s] 45%|####5     |78677/173481[27:00<48:31,32.56it/s]   46%|####5     |79527/173481[27:11<48:05,32.56it/s] 52%|#####2    |90751/173481[30:00<31:27,43.84it/s] 53%|#####2    |91503/173481[30:11<31:10,43.84it/s] 60%|######    |104344/173481[33:00<20:46,55.47it/s] 61%|######    |105322/173481[33:11<20:28,55.47it/s] 69%|######8   |119637/173481[36:00<13:22,67.12it/s] 69%|######9   |120558/173481[36:11<13:08,67.12it/s] 76%|#######5  |131338/173481[39:00<10:38,66.04it/s] 76%|#######6  |131931/173481[39:11<10:29,66.04it/s] 80%|########  |139618/173481[42:00<10:24,54.21it/s] 81%|########  |139757/173481[42:11<10:22,54.21it/s] 84%|########3 |144898/173481[45:00<12:31,38.04it/s] 84%|########3 |144993/173481[45:12<12:28,38.04it/s] 89%|########8 |153670/173481[48:00<07:43,42.73it/s] 89%|########9 |154542/173481[48:12<07:23,42.73it/s] 96%|#########6|166729/173481[51:00<02:05,53.78it/s] 97%|#########6|167523/173481[51:12<01:50,53.78it/s]100%|##########|173481/173481[52:33<00:00,55.01it/s]
[32m[0417 18:19:52 @base.py:257][0m Epoch 4 (global_step 693924) finished, time:3153.83 sec.
[32m[0417 18:19:53 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-693924.
[32m[0417 18:19:54 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:36<00:00,120.30it/s]
3
[32m[0417 18:22:30 @monitor.py:363][0m QueueInput/queue_size: 0.55559
[32m[0417 18:22:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9384
[32m[0417 18:22:30 @monitor.py:363][0m activation-summaries/output-rms: 0.017686
[32m[0417 18:22:30 @monitor.py:363][0m cross_entropy_loss: 3.5073
[32m[0417 18:22:30 @monitor.py:363][0m last_linear/W_0_percent_n: 0.26723
[32m[0417 18:22:30 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17946
[32m[0417 18:22:30 @monitor.py:363][0m last_linear/W_0_sparsity: 0.55331
[32m[0417 18:22:30 @monitor.py:363][0m last_linear/Wn_0: 0.1266
[32m[0417 18:22:30 @monitor.py:363][0m last_linear/Wp_0: 0.13453
[32m[0417 18:22:30 @monitor.py:363][0m linear0/W_0_percent_n: 0.22905
[32m[0417 18:22:30 @monitor.py:363][0m linear0/W_0_percent_p: 0.21476
[32m[0417 18:22:30 @monitor.py:363][0m linear0/W_0_sparsity: 0.55618
[32m[0417 18:22:30 @monitor.py:363][0m linear0/Wn_0: 0.7445
[32m[0417 18:22:30 @monitor.py:363][0m linear0/Wp_0: 1.0245
[32m[0417 18:22:30 @monitor.py:363][0m linear1/W_0_percent_n: 0.14203
[32m[0417 18:22:30 @monitor.py:363][0m linear1/W_0_percent_p: 0.1143
[32m[0417 18:22:30 @monitor.py:363][0m linear1/W_0_sparsity: 0.74367
[32m[0417 18:22:30 @monitor.py:363][0m linear1/Wn_0: 0.77545
[32m[0417 18:22:30 @monitor.py:363][0m linear1/Wp_0: 0.79158
[32m[0417 18:22:30 @monitor.py:363][0m linear2/W_0_percent_n: 0.036636
[32m[0417 18:22:30 @monitor.py:363][0m linear2/W_0_percent_p: 0.043777
[32m[0417 18:22:30 @monitor.py:363][0m linear2/W_0_sparsity: 0.91959
[32m[0417 18:22:30 @monitor.py:363][0m linear2/Wn_0: 0.93958
[32m[0417 18:22:30 @monitor.py:363][0m linear2/Wp_0: 0.71331
[32m[0417 18:22:30 @monitor.py:363][0m linear3/W_0_percent_n: 0.04306
[32m[0417 18:22:30 @monitor.py:363][0m linear3/W_0_percent_p: 0.038696
[32m[0417 18:22:30 @monitor.py:363][0m linear3/W_0_sparsity: 0.91824
[32m[0417 18:22:30 @monitor.py:363][0m linear3/Wn_0: 0.6866
[32m[0417 18:22:30 @monitor.py:363][0m linear3/Wp_0: 0.68205
[32m[0417 18:22:30 @monitor.py:363][0m lr: 0.0005
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.23033
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.8625
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.085437
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2641
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21372
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18915
[32m[0417 18:22:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 18:22:30 @monitor.py:363][0m train-error-top1: 0.80932
[32m[0417 18:22:30 @monitor.py:363][0m val-error-top1: 0.87172
[32m[0417 18:22:30 @monitor.py:363][0m val-utt-error: 0.725
[32m[0417 18:22:30 @monitor.py:363][0m validation_cost: 4.0864
[32m[0417 18:22:30 @monitor.py:363][0m wd_cost: 0.30492
[32m[0417 18:22:30 @group.py:42][0m Callbacks took 157.668 sec in total. InferenceRunner: 156.482sec
[32m[0417 18:22:30 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14140/173481[03:00<33:48,78.55it/s]  9%|8         |15010/173481[03:10<33:37,78.55it/s] 14%|#4        |24960/173481[06:00<36:20,68.11it/s] 15%|#4        |25494/173481[06:10<36:12,68.11it/s] 20%|#9        |34633/173481[09:00<38:31,60.07it/s] 20%|##        |35171/173481[09:10<38:22,60.07it/s] 26%|##6       |45264/173481[12:00<35:52,59.56it/s] 26%|##6       |45942/173481[12:10<35:41,59.56it/s] 33%|###2      |56594/173481[15:00<31:49,61.20it/s] 33%|###3      |57264/173481[15:10<31:38,61.20it/s] 39%|###9      |67861/173481[18:00<28:26,61.89it/s] 40%|###9      |68527/173481[18:10<28:15,61.89it/s] 46%|####6     |80147/173481[21:00<23:57,64.92it/s] 47%|####6     |80906/173481[21:11<23:46,64.92it/s] 53%|#####2    |91470/173481[24:00<21:23,63.89it/s] 53%|#####3    |92082/173481[24:11<21:13,63.89it/s] 59%|#####8    |101910/173481[27:00<19:37,60.80it/s] 59%|#####9    |102680/173481[27:11<19:24,60.80it/s] 66%|######5   |113926/173481[30:00<15:35,63.64it/s] 66%|######6   |114666/173481[30:11<15:24,63.64it/s] 72%|#######1  |124768/173481[33:00<13:07,61.89it/s] 72%|#######2  |125417/173481[33:11<12:56,61.89it/s] 78%|#######8  |135385/173481[36:00<10:30,60.40it/s] 78%|#######8  |136153/173481[36:11<10:18,60.40it/s] 85%|########5 |147577/173481[39:00<06:45,63.85it/s] 85%|########5 |148220/173481[39:11<06:35,63.85it/s] 92%|#########1|159115/173481[42:00<03:44,63.96it/s] 92%|#########2|159870/173481[42:12<03:32,63.96it/s] 98%|#########7|169837/173481[45:00<00:59,61.68it/s] 98%|#########8|170736/173481[45:12<00:44,61.68it/s]100%|##########|173481/173481[45:48<00:00,63.12it/s]
[32m[0417 19:08:19 @base.py:257][0m Epoch 5 (global_step 867405) finished, time:2748.57 sec.
[32m[0417 19:08:19 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-867405.
[32m[0417 19:08:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:26<00:00,128.21it/s]
4
[32m[0417 19:10:46 @monitor.py:363][0m QueueInput/queue_size: 0.75606
[32m[0417 19:10:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.0601
[32m[0417 19:10:46 @monitor.py:363][0m activation-summaries/output-rms: 0.019516
[32m[0417 19:10:46 @monitor.py:363][0m cross_entropy_loss: 3.4171
[32m[0417 19:10:46 @monitor.py:363][0m last_linear/W_0_percent_n: 0.26095
[32m[0417 19:10:46 @monitor.py:363][0m last_linear/W_0_percent_p: 0.18217
[32m[0417 19:10:46 @monitor.py:363][0m last_linear/W_0_sparsity: 0.55688
[32m[0417 19:10:46 @monitor.py:363][0m last_linear/Wn_0: 0.12724
[32m[0417 19:10:46 @monitor.py:363][0m last_linear/Wp_0: 0.13437
[32m[0417 19:10:46 @monitor.py:363][0m linear0/W_0_percent_n: 0.21575
[32m[0417 19:10:46 @monitor.py:363][0m linear0/W_0_percent_p: 0.20812
[32m[0417 19:10:46 @monitor.py:363][0m linear0/W_0_sparsity: 0.57613
[32m[0417 19:10:46 @monitor.py:363][0m linear0/Wn_0: 0.79533
[32m[0417 19:10:46 @monitor.py:363][0m linear0/Wp_0: 1.0646
[32m[0417 19:10:46 @monitor.py:363][0m linear1/W_0_percent_n: 0.1561
[32m[0417 19:10:46 @monitor.py:363][0m linear1/W_0_percent_p: 0.12428
[32m[0417 19:10:46 @monitor.py:363][0m linear1/W_0_sparsity: 0.71962
[32m[0417 19:10:46 @monitor.py:363][0m linear1/Wn_0: 0.82662
[32m[0417 19:10:46 @monitor.py:363][0m linear1/Wp_0: 0.84409
[32m[0417 19:10:46 @monitor.py:363][0m linear2/W_0_percent_n: 0.034668
[32m[0417 19:10:46 @monitor.py:363][0m linear2/W_0_percent_p: 0.042816
[32m[0417 19:10:46 @monitor.py:363][0m linear2/W_0_sparsity: 0.92252
[32m[0417 19:10:46 @monitor.py:363][0m linear2/Wn_0: 1.0051
[32m[0417 19:10:46 @monitor.py:363][0m linear2/Wp_0: 0.74652
[32m[0417 19:10:46 @monitor.py:363][0m linear3/W_0_percent_n: 0.042831
[32m[0417 19:10:46 @monitor.py:363][0m linear3/W_0_percent_p: 0.037598
[32m[0417 19:10:46 @monitor.py:363][0m linear3/W_0_sparsity: 0.91957
[32m[0417 19:10:46 @monitor.py:363][0m linear3/Wn_0: 0.7249
[32m[0417 19:10:46 @monitor.py:363][0m linear3/Wp_0: 0.74157
[32m[0417 19:10:46 @monitor.py:363][0m lr: 0.0005
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.25191
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.89458
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/linear0/W-rms: 0.085073
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.24279
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.22296
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19765
[32m[0417 19:10:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 19:10:46 @monitor.py:363][0m train-error-top1: 0.80527
[32m[0417 19:10:46 @monitor.py:363][0m val-error-top1: 0.87503
[32m[0417 19:10:46 @monitor.py:363][0m val-utt-error: 0.7326
[32m[0417 19:10:46 @monitor.py:363][0m validation_cost: 4.147
[32m[0417 19:10:46 @monitor.py:363][0m wd_cost: 0.31366
[32m[0417 19:10:46 @group.py:42][0m Callbacks took 147.351 sec in total. InferenceRunner: 146.815sec
[32m[0417 19:10:46 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13407/173481[03:00<35:49,74.48it/s]  8%|8         |14147/173481[03:10<35:39,74.48it/s] 15%|#5        |26374/173481[06:00<33:28,73.24it/s] 16%|#5        |27123/173481[06:10<33:18,73.24it/s] 23%|##2       |39520/173481[09:00<30:31,73.13it/s] 23%|##3       |40307/173481[09:10<30:20,73.13it/s] 30%|###       |52396/173481[12:00<27:54,72.32it/s] 31%|###       |53247/173481[12:10<27:42,72.32it/s] 38%|###7      |65384/173481[15:00<24:56,72.24it/s] 38%|###8      |66157/173481[15:10<24:45,72.24it/s] 45%|####5     |78432/173481[18:00<21:53,72.36it/s] 46%|####5     |79150/173481[18:10<21:43,72.36it/s] 52%|#####2    |91012/173481[21:00<19:19,71.10it/s] 53%|#####2    |91809/173481[21:11<19:08,71.10it/s] 60%|#####9    |103582/173481[24:00<16:32,70.46it/s] 60%|######    |104351/173481[24:11<16:21,70.46it/s] 67%|######7   |116441/173481[27:00<13:24,70.94it/s] 68%|######7   |117226/173481[27:11<13:12,70.94it/s] 74%|#######4  |129183/173481[30:00<10:25,70.87it/s] 75%|#######4  |130022/173481[30:11<10:13,70.87it/s] 82%|########1 |141994/173481[33:00<07:23,71.02it/s] 82%|########2 |142660/173481[33:11<07:13,71.02it/s] 89%|########9 |154450/173481[36:00<04:31,70.09it/s] 90%|########9 |155297/173481[36:11<04:19,70.09it/s] 96%|#########6|167166/173481[39:00<01:29,70.37it/s] 97%|#########6|168000/173481[39:11<01:17,70.37it/s]100%|##########|173481/173481[40:33<00:00,71.29it/s]
[32m[0417 19:51:20 @base.py:257][0m Epoch 6 (global_step 1040886) finished, time:2433.50 sec.
[32m[0417 19:51:20 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-1040886.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:21<00:00,132.67it/s]
5
[32m[0417 19:53:42 @monitor.py:363][0m QueueInput/queue_size: 0.67369
[32m[0417 19:53:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.5829
[32m[0417 19:53:42 @monitor.py:363][0m activation-summaries/output-rms: 0.021015
[32m[0417 19:53:42 @monitor.py:363][0m cross_entropy_loss: 3.2651
[32m[0417 19:53:42 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29308
[32m[0417 19:53:42 @monitor.py:363][0m last_linear/W_0_percent_p: 0.18215
[32m[0417 19:53:42 @monitor.py:363][0m last_linear/W_0_sparsity: 0.52477
[32m[0417 19:53:42 @monitor.py:363][0m last_linear/Wn_0: 0.14971
[32m[0417 19:53:42 @monitor.py:363][0m last_linear/Wp_0: 0.10349
[32m[0417 19:53:42 @monitor.py:363][0m linear0/W_0_percent_n: 0.13312
[32m[0417 19:53:42 @monitor.py:363][0m linear0/W_0_percent_p: 0.14217
[32m[0417 19:53:42 @monitor.py:363][0m linear0/W_0_sparsity: 0.72471
[32m[0417 19:53:42 @monitor.py:363][0m linear0/Wn_0: 0.8665
[32m[0417 19:53:42 @monitor.py:363][0m linear0/Wp_0: 1.0419
[32m[0417 19:53:42 @monitor.py:363][0m linear1/W_0_percent_n: 0.16475
[32m[0417 19:53:42 @monitor.py:363][0m linear1/W_0_percent_p: 0.13156
[32m[0417 19:53:42 @monitor.py:363][0m linear1/W_0_sparsity: 0.70369
[32m[0417 19:53:42 @monitor.py:363][0m linear1/Wn_0: 0.84856
[32m[0417 19:53:42 @monitor.py:363][0m linear1/Wp_0: 0.88025
[32m[0417 19:53:42 @monitor.py:363][0m linear2/W_0_percent_n: 0.037125
[32m[0417 19:53:42 @monitor.py:363][0m linear2/W_0_percent_p: 0.045502
[32m[0417 19:53:42 @monitor.py:363][0m linear2/W_0_sparsity: 0.91737
[32m[0417 19:53:42 @monitor.py:363][0m linear2/Wn_0: 1.0205
[32m[0417 19:53:42 @monitor.py:363][0m linear2/Wp_0: 0.78388
[32m[0417 19:53:42 @monitor.py:363][0m linear3/W_0_percent_n: 0.043945
[32m[0417 19:53:42 @monitor.py:363][0m linear3/W_0_percent_p: 0.038696
[32m[0417 19:53:42 @monitor.py:363][0m linear3/W_0_sparsity: 0.91736
[32m[0417 19:53:42 @monitor.py:363][0m linear3/Wn_0: 0.75318
[32m[0417 19:53:42 @monitor.py:363][0m linear3/Wp_0: 0.7611
[32m[0417 19:53:42 @monitor.py:363][0m lr: 0.00025
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.44919
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.95872
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2629
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44043
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34859
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33087
[32m[0417 19:53:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 19:53:42 @monitor.py:363][0m train-error-top1: 0.76438
[32m[0417 19:53:42 @monitor.py:363][0m val-error-top1: 0.84328
[32m[0417 19:53:42 @monitor.py:363][0m val-utt-error: 0.67942
[32m[0417 19:53:42 @monitor.py:363][0m validation_cost: 3.8081
[32m[0417 19:53:42 @monitor.py:363][0m wd_cost: 0.23485
[32m[0417 19:53:42 @group.py:42][0m Callbacks took 142.069 sec in total. InferenceRunner: 141.884sec
[32m[0417 19:53:42 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15546/173481[03:00<30:28,86.36it/s]  9%|9         |16367/173481[03:10<30:19,86.36it/s] 16%|#6        |28294/173481[06:00<31:05,77.82it/s] 17%|#6        |29082/173481[06:10<30:55,77.82it/s] 25%|##4       |43141/173481[09:00<27:07,80.08it/s] 25%|##5       |43816/173481[09:10<26:59,80.08it/s] 32%|###2      |56185/173481[12:00<25:41,76.08it/s] 33%|###2      |56706/173481[12:10<25:34,76.08it/s] 38%|###8      |65925/173481[15:00<28:20,63.24it/s] 38%|###8      |66510/173481[15:10<28:11,63.24it/s] 44%|####3     |75841/173481[18:00<27:38,58.88it/s] 44%|####4     |76423/173481[18:10<27:28,58.88it/s] 49%|####9     |85315/173481[21:00<26:26,55.58it/s] 49%|####9     |85867/173481[21:10<26:16,55.58it/s] 54%|#####4    |94357/173481[24:00<24:59,52.77it/s] 55%|#####4    |94914/173481[24:11<24:48,52.77it/s] 60%|#####9    |103329/173481[27:00<22:48,51.26it/s] 60%|#####9    |103867/173481[27:11<22:37,51.26it/s] 65%|######5   |112843/173481[30:00<19:25,52.04it/s] 65%|######5   |113588/173481[30:11<19:10,52.04it/s] 72%|#######1  |124801/173481[33:00<13:54,58.36it/s] 72%|#######2  |125539/173481[33:11<13:41,58.36it/s] 79%|#######8  |136375/173481[36:00<10:06,61.19it/s] 79%|#######8  |136998/173481[36:11<09:56,61.19it/s] 84%|########3 |145651/173481[39:00<08:17,55.94it/s] 84%|########4 |146250/173481[39:11<08:06,55.94it/s] 89%|########9 |154819/173481[42:00<05:50,53.31it/s] 90%|########9 |155418/173481[42:12<05:38,53.31it/s] 94%|#########4|163644/173481[45:00<03:12,51.08it/s] 95%|#########4|164178/173481[45:12<03:02,51.08it/s] 99%|#########9|172351/173481[48:00<00:22,49.68it/s]100%|#########9|172956/173481[48:12<00:10,49.68it/s]100%|##########|173481/173481[48:22<00:00,59.76it/s]
[32m[0417 20:42:04 @base.py:257][0m Epoch 7 (global_step 1214367) finished, time:2902.75 sec.
[32m[0417 20:42:05 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-1214367.
[32m[0417 20:42:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 52%|#####2    |9850/18822[03:00<02:43,54.72it/s] 56%|#####5    |10470/18822[03:10<02:32,54.72it/s]100%|##########|18822/18822[04:50<00:00,64.70it/s]
6
[32m[0417 20:46:56 @monitor.py:363][0m QueueInput/queue_size: 0.84617
[32m[0417 20:46:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.407
[32m[0417 20:46:56 @monitor.py:363][0m activation-summaries/output-rms: 0.02082
[32m[0417 20:46:56 @monitor.py:363][0m cross_entropy_loss: 3.3103
[32m[0417 20:46:56 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29726
[32m[0417 20:46:56 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17525
[32m[0417 20:46:56 @monitor.py:363][0m last_linear/W_0_sparsity: 0.5275
[32m[0417 20:46:56 @monitor.py:363][0m last_linear/Wn_0: 0.14418
[32m[0417 20:46:56 @monitor.py:363][0m last_linear/Wp_0: 0.10961
[32m[0417 20:46:56 @monitor.py:363][0m linear0/W_0_percent_n: 0.11616
[32m[0417 20:46:56 @monitor.py:363][0m linear0/W_0_percent_p: 0.1306
[32m[0417 20:46:56 @monitor.py:363][0m linear0/W_0_sparsity: 0.75325
[32m[0417 20:46:56 @monitor.py:363][0m linear0/Wn_0: 0.89839
[32m[0417 20:46:56 @monitor.py:363][0m linear0/Wp_0: 1.0414
[32m[0417 20:46:56 @monitor.py:363][0m linear1/W_0_percent_n: 0.1579
[32m[0417 20:46:56 @monitor.py:363][0m linear1/W_0_percent_p: 0.12825
[32m[0417 20:46:56 @monitor.py:363][0m linear1/W_0_sparsity: 0.71385
[32m[0417 20:46:56 @monitor.py:363][0m linear1/Wn_0: 0.86366
[32m[0417 20:46:56 @monitor.py:363][0m linear1/Wp_0: 0.90085
[32m[0417 20:46:56 @monitor.py:363][0m linear2/W_0_percent_n: 0.035828
[32m[0417 20:46:56 @monitor.py:363][0m linear2/W_0_percent_p: 0.044327
[32m[0417 20:46:56 @monitor.py:363][0m linear2/W_0_sparsity: 0.91985
[32m[0417 20:46:56 @monitor.py:363][0m linear2/Wn_0: 1.0441
[32m[0417 20:46:56 @monitor.py:363][0m linear2/Wp_0: 0.79535
[32m[0417 20:46:56 @monitor.py:363][0m linear3/W_0_percent_n: 0.043579
[32m[0417 20:46:56 @monitor.py:363][0m linear3/W_0_percent_p: 0.038834
[32m[0417 20:46:56 @monitor.py:363][0m linear3/W_0_sparsity: 0.91759
[32m[0417 20:46:56 @monitor.py:363][0m linear3/Wn_0: 0.76627
[32m[0417 20:46:56 @monitor.py:363][0m linear3/Wp_0: 0.78616
[32m[0417 20:46:56 @monitor.py:363][0m lr: 0.00025
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68756
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.013
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.38184
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.72863
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.54832
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.5439
[32m[0417 20:46:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 20:46:56 @monitor.py:363][0m train-error-top1: 0.77987
[32m[0417 20:46:56 @monitor.py:363][0m val-error-top1: 0.84883
[32m[0417 20:46:56 @monitor.py:363][0m val-utt-error: 0.68659
[32m[0417 20:46:56 @monitor.py:363][0m validation_cost: 3.8249
[32m[0417 20:46:56 @monitor.py:363][0m wd_cost: 0.56828
[32m[0417 20:46:56 @group.py:42][0m Callbacks took 291.588 sec in total. InferenceRunner: 290.947sec
[32m[0417 20:46:56 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16427/173481[03:00<28:40,91.26it/s] 10%|9         |17295/173481[03:10<28:31,91.26it/s] 17%|#6        |28719/173481[06:00<30:53,78.12it/s] 17%|#7        |29610/173481[06:10<30:41,78.12it/s] 26%|##5       |44275/173481[09:00<26:14,82.06it/s] 26%|##6       |45163/173481[09:10<26:03,82.06it/s] 34%|###4      |59524/173481[12:00<22:47,83.36it/s] 35%|###4      |60341/173481[12:10<22:37,83.36it/s] 41%|####1     |71692/173481[15:00<22:43,74.64it/s] 42%|####1     |72092/173481[15:10<22:38,74.64it/s] 46%|####5     |79710/173481[18:00<28:00,55.79it/s] 46%|####6     |80183/173481[18:10<27:52,55.79it/s] 50%|#####     |87546/173481[21:00<29:17,48.91it/s] 51%|#####     |88016/173481[21:11<29:07,48.91it/s] 55%|#####4    |95177/173481[24:00<28:44,45.42it/s] 55%|#####5    |95679/173481[24:11<28:33,45.42it/s] 59%|#####9    |103066/173481[27:00<26:18,44.60it/s] 60%|#####9    |103550/173481[27:11<26:07,44.60it/s] 64%|######4   |111139/173481[30:00<23:13,44.72it/s] 64%|######4   |111657/173481[30:11<23:02,44.72it/s] 69%|######9   |120551/173481[33:00<18:17,48.21it/s] 70%|######9   |121175/173481[33:11<18:04,48.21it/s] 75%|#######4  |129436/173481[36:00<15:03,48.77it/s] 75%|#######4  |129969/173481[36:11<14:52,48.77it/s] 80%|########  |139281/173481[39:00<11:03,51.56it/s] 81%|########  |139935/173481[39:11<10:50,51.56it/s] 86%|########5 |148487/173481[42:00<08:06,51.35it/s] 86%|########5 |149055/173481[42:12<07:55,51.35it/s] 90%|######### |156789/173481[45:00<05:43,48.60it/s] 91%|######### |157335/173481[45:12<05:32,48.60it/s] 95%|#########4|164469/173481[48:00<03:18,45.44it/s] 95%|#########5|164950/173481[48:12<03:07,45.44it/s]100%|#########9|172702/173481[51:00<00:17,45.59it/s]100%|#########9|173265/173481[51:12<00:04,45.59it/s]100%|##########|173481/173481[51:17<00:00,56.38it/s]
[32m[0417 21:38:13 @base.py:257][0m Epoch 8 (global_step 1387848) finished, time:3077.24 sec.
[32m[0417 21:38:13 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-1387848.
  0%|          |0/18822[00:00<?,?it/s] 69%|######8   |12914/18822[03:00<01:22,71.73it/s] 73%|#######2  |13726/18822[03:10<01:11,71.73it/s]100%|##########|18822/18822[04:11<00:00,74.70it/s]
7
[32m[0417 21:42:25 @monitor.py:363][0m QueueInput/queue_size: 0.5908
[32m[0417 21:42:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.0944
[32m[0417 21:42:25 @monitor.py:363][0m activation-summaries/output-rms: 0.020501
[32m[0417 21:42:25 @monitor.py:363][0m cross_entropy_loss: 3.2546
[32m[0417 21:42:25 @monitor.py:363][0m last_linear/W_0_percent_n: 0.30035
[32m[0417 21:42:25 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17862
[32m[0417 21:42:25 @monitor.py:363][0m last_linear/W_0_sparsity: 0.52103
[32m[0417 21:42:25 @monitor.py:363][0m last_linear/Wn_0: 0.13861
[32m[0417 21:42:25 @monitor.py:363][0m last_linear/Wp_0: 0.11358
[32m[0417 21:42:25 @monitor.py:363][0m linear0/W_0_percent_n: 0.10664
[32m[0417 21:42:25 @monitor.py:363][0m linear0/W_0_percent_p: 0.12128
[32m[0417 21:42:25 @monitor.py:363][0m linear0/W_0_sparsity: 0.77208
[32m[0417 21:42:25 @monitor.py:363][0m linear0/Wn_0: 0.91091
[32m[0417 21:42:25 @monitor.py:363][0m linear0/Wp_0: 1.0589
[32m[0417 21:42:25 @monitor.py:363][0m linear1/W_0_percent_n: 0.15459
[32m[0417 21:42:25 @monitor.py:363][0m linear1/W_0_percent_p: 0.12312
[32m[0417 21:42:25 @monitor.py:363][0m linear1/W_0_sparsity: 0.72227
[32m[0417 21:42:25 @monitor.py:363][0m linear1/Wn_0: 0.88192
[32m[0417 21:42:25 @monitor.py:363][0m linear1/Wp_0: 0.91865
[32m[0417 21:42:25 @monitor.py:363][0m linear2/W_0_percent_n: 0.035767
[32m[0417 21:42:25 @monitor.py:363][0m linear2/W_0_percent_p: 0.044312
[32m[0417 21:42:25 @monitor.py:363][0m linear2/W_0_sparsity: 0.91992
[32m[0417 21:42:25 @monitor.py:363][0m linear2/Wn_0: 1.0607
[32m[0417 21:42:25 @monitor.py:363][0m linear2/Wp_0: 0.81366
[32m[0417 21:42:25 @monitor.py:363][0m linear3/W_0_percent_n: 0.043167
[32m[0417 21:42:25 @monitor.py:363][0m linear3/W_0_percent_p: 0.038315
[32m[0417 21:42:25 @monitor.py:363][0m linear3/W_0_sparsity: 0.91852
[32m[0417 21:42:25 @monitor.py:363][0m linear3/Wn_0: 0.7988
[32m[0417 21:42:25 @monitor.py:363][0m linear3/Wp_0: 0.79009
[32m[0417 21:42:25 @monitor.py:363][0m lr: 0.00025
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.79264
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0466
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.43175
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.8773
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.69304
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.68435
[32m[0417 21:42:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 21:42:25 @monitor.py:363][0m train-error-top1: 0.76787
[32m[0417 21:42:25 @monitor.py:363][0m val-error-top1: 0.84051
[32m[0417 21:42:25 @monitor.py:363][0m val-utt-error: 0.67262
[32m[0417 21:42:25 @monitor.py:363][0m validation_cost: 3.7511
[32m[0417 21:42:25 @monitor.py:363][0m wd_cost: 0.80539
[32m[0417 21:42:25 @group.py:42][0m Callbacks took 252.176 sec in total. InferenceRunner: 251.987sec
[32m[0417 21:42:25 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8035/173481[03:00<1:01:46,44.63it/s]  5%|4         |8502/173481[03:10<1:01:36,44.63it/s]  9%|9         |16141/173481[06:00<58:30,44.82it/s]  10%|9         |16590/173481[06:10<58:20,44.82it/s] 14%|#3        |24271/173481[09:00<55:16,44.99it/s] 14%|#4        |24739/173481[09:10<55:05,44.99it/s] 19%|#8        |32299/173481[12:00<52:32,44.79it/s] 19%|#8        |32770/173481[12:10<52:21,44.79it/s] 23%|##3       |40267/173481[15:00<49:52,44.51it/s] 23%|##3       |40729/173481[15:10<49:42,44.51it/s] 28%|##7       |48281/173481[18:00<46:52,44.52it/s] 28%|##8       |48738/173481[18:10<46:42,44.52it/s] 32%|###2      |56083/173481[21:00<44:33,43.91it/s] 33%|###2      |56526/173481[21:11<44:23,43.91it/s] 38%|###7      |65580/173481[24:00<37:31,47.93it/s] 38%|###8      |66276/173481[24:11<37:16,47.93it/s] 44%|####4     |76543/173481[27:00<30:07,53.64it/s] 45%|####4     |77232/173481[27:11<29:54,53.64it/s] 49%|####9     |85369/173481[30:00<28:40,51.23it/s] 49%|####9     |85782/173481[30:11<28:32,51.23it/s] 54%|#####3    |92881/173481[33:00<29:12,45.99it/s] 54%|#####3    |93378/173481[33:11<29:01,45.99it/s] 58%|#####8    |100856/173481[36:00<26:49,45.13it/s] 58%|#####8    |101358/173481[36:11<26:38,45.13it/s] 63%|######2   |108991/173481[39:00<23:48,45.15it/s] 63%|######3   |109536/173481[39:11<23:36,45.15it/s] 68%|######8   |118315/173481[42:00<19:03,48.25it/s] 69%|######8   |118980/173481[42:12<18:49,48.25it/s] 74%|#######3  |127951/173481[45:00<14:57,50.75it/s] 74%|#######4  |128566/173481[45:12<14:44,50.75it/s] 79%|#######9  |137450/173481[48:00<11:36,51.74it/s] 80%|#######9  |138060/173481[48:12<11:24,51.74it/s] 85%|########4 |146933/173481[51:00<08:28,52.21it/s] 85%|########5 |147582/173481[51:12<08:16,52.21it/s] 90%|########9 |155893/173481[54:00<05:45,50.96it/s] 90%|######### |156522/173481[54:12<05:32,50.96it/s] 93%|#########3|161690/173481[57:00<04:58,39.47it/s] 94%|#########3|162324/173481[57:12<04:42,39.47it/s] 99%|#########8|171361/173481[1:00:00<00:46,45.50it/s] 99%|#########9|172044/173481[1:00:12<00:31,45.50it/s]100%|##########|173481/173481[1:00:39<00:00,47.67it/s]
[32m[0417 22:43:05 @base.py:257][0m Epoch 9 (global_step 1561329) finished, time:3639.25 sec.
[32m[0417 22:43:05 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-1561329.
[32m[0417 22:43:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######8  |14732/18822[03:00<00:49,81.84it/s] 83%|########3 |15633/18822[03:10<00:38,81.84it/s]100%|##########|18822/18822[03:42<00:00,84.68it/s]
8
[32m[0417 22:46:48 @monitor.py:363][0m QueueInput/queue_size: 0.39162
[32m[0417 22:46:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.7257
[32m[0417 22:46:48 @monitor.py:363][0m activation-summaries/output-rms: 0.02172
[32m[0417 22:46:48 @monitor.py:363][0m cross_entropy_loss: 3.2386
[32m[0417 22:46:48 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29966
[32m[0417 22:46:48 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17149
[32m[0417 22:46:48 @monitor.py:363][0m last_linear/W_0_sparsity: 0.52884
[32m[0417 22:46:48 @monitor.py:363][0m last_linear/Wn_0: 0.14661
[32m[0417 22:46:48 @monitor.py:363][0m last_linear/Wp_0: 0.11095
[32m[0417 22:46:48 @monitor.py:363][0m linear0/W_0_percent_n: 0.12057
[32m[0417 22:46:48 @monitor.py:363][0m linear0/W_0_percent_p: 0.1342
[32m[0417 22:46:48 @monitor.py:363][0m linear0/W_0_sparsity: 0.74523
[32m[0417 22:46:48 @monitor.py:363][0m linear0/Wn_0: 0.94136
[32m[0417 22:46:48 @monitor.py:363][0m linear0/Wp_0: 1.0403
[32m[0417 22:46:48 @monitor.py:363][0m linear1/W_0_percent_n: 0.15623
[32m[0417 22:46:48 @monitor.py:363][0m linear1/W_0_percent_p: 0.12474
[32m[0417 22:46:48 @monitor.py:363][0m linear1/W_0_sparsity: 0.71902
[32m[0417 22:46:48 @monitor.py:363][0m linear1/Wn_0: 0.88896
[32m[0417 22:46:48 @monitor.py:363][0m linear1/Wp_0: 0.92673
[32m[0417 22:46:48 @monitor.py:363][0m linear2/W_0_percent_n: 0.035385
[32m[0417 22:46:48 @monitor.py:363][0m linear2/W_0_percent_p: 0.043945
[32m[0417 22:46:48 @monitor.py:363][0m linear2/W_0_sparsity: 0.92067
[32m[0417 22:46:48 @monitor.py:363][0m linear2/Wn_0: 1.0692
[32m[0417 22:46:48 @monitor.py:363][0m linear2/Wp_0: 0.81952
[32m[0417 22:46:48 @monitor.py:363][0m linear3/W_0_percent_n: 0.042908
[32m[0417 22:46:48 @monitor.py:363][0m linear3/W_0_percent_p: 0.03833
[32m[0417 22:46:48 @monitor.py:363][0m linear3/W_0_sparsity: 0.91876
[32m[0417 22:46:48 @monitor.py:363][0m linear3/Wn_0: 0.81041
[32m[0417 22:46:48 @monitor.py:363][0m linear3/Wp_0: 0.79537
[32m[0417 22:46:48 @monitor.py:363][0m lr: 0.000125
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 1.0184
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0684
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.66224
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/linear1/W-rms: 1.0924
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.82789
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.82424
[32m[0417 22:46:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 22:46:48 @monitor.py:363][0m train-error-top1: 0.76738
[32m[0417 22:46:48 @monitor.py:363][0m val-error-top1: 0.84698
[32m[0417 22:46:48 @monitor.py:363][0m val-utt-error: 0.69456
[32m[0417 22:46:48 @monitor.py:363][0m validation_cost: 3.8205
[32m[0417 22:46:48 @monitor.py:363][0m wd_cost: 0.27809
[32m[0417 22:46:48 @group.py:42][0m Callbacks took 223.021 sec in total. InferenceRunner: 222.299sec
[32m[0417 22:46:48 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10173/173481[03:00<48:09,56.52it/s]  6%|6         |10695/173481[03:10<48:00,56.52it/s] 11%|#1        |19425/173481[06:00<47:41,53.84it/s] 12%|#1        |19977/173481[06:10<47:31,53.84it/s] 17%|#6        |28654/173481[09:00<45:57,52.52it/s] 17%|#6        |29199/173481[09:10<45:47,52.52it/s] 22%|##1       |37858/173481[12:00<43:37,51.82it/s] 22%|##2       |38405/173481[12:10<43:26,51.82it/s] 27%|##7       |46884/173481[15:00<41:23,50.97it/s] 27%|##7       |47421/173481[15:10<41:13,50.97it/s] 32%|###2      |55822/173481[18:00<38:59,50.30it/s] 32%|###2      |56355/173481[18:10<38:48,50.30it/s] 37%|###7      |64588/173481[21:00<36:40,49.48it/s] 38%|###7      |65104/173481[21:11<36:30,49.48it/s] 44%|####3     |76210/173481[24:00<28:56,56.02it/s] 44%|####4     |76509/173481[24:11<28:50,56.02it/s] 50%|#####     |87541/173481[27:00<24:09,59.28it/s] 51%|#####     |88095/173481[27:11<24:00,59.28it/s] 55%|#####5    |95434/173481[30:00<25:48,50.41it/s] 55%|#####5    |95908/173481[30:11<25:38,50.41it/s] 60%|#####9    |103522/173481[33:00<24:32,47.51it/s] 60%|#####9    |104061/173481[33:11<24:21,47.51it/s] 64%|######4   |111828/173481[36:00<21:56,46.82it/s] 65%|######4   |112339/173481[36:11<21:45,46.82it/s] 69%|######8   |119536/173481[39:00<20:06,44.72it/s] 69%|######9   |120027/173481[39:11<19:55,44.72it/s] 73%|#######3  |126682/173481[42:00<18:32,42.06it/s] 73%|#######3  |127137/173481[42:12<18:21,42.06it/s] 77%|#######6  |133090/173481[45:00<17:27,38.55it/s] 77%|#######6  |133566/173481[45:12<17:15,38.55it/s] 81%|########1 |141298/173481[48:00<12:50,41.78it/s] 82%|########1 |141849/173481[48:12<12:37,41.78it/s] 86%|########6 |150034/173481[51:00<08:42,44.90it/s] 87%|########6 |150711/173481[51:12<08:27,44.90it/s] 92%|#########2|160132/173481[54:00<04:27,49.88it/s] 93%|#########2|160812/173481[54:12<04:14,49.88it/s] 98%|#########8|170500/173481[57:00<00:55,53.45it/s] 99%|#########8|171255/173481[57:12<00:41,53.45it/s]100%|##########|173481/173481[57:49<00:00,50.00it/s]
[32m[0417 23:44:37 @base.py:257][0m Epoch 10 (global_step 1734810) finished, time:3469.60 sec.
[32m[0417 23:44:37 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-1734810.
  0%|          |0/18822[00:00<?,?it/s] 81%|########  |15237/18822[03:00<00:42,84.65it/s] 85%|########4 |15996/18822[03:10<00:33,84.65it/s]100%|##########|18822/18822[03:38<00:00,86.02it/s]
9
[32m[0417 23:48:16 @monitor.py:363][0m QueueInput/queue_size: 0.59413
[32m[0417 23:48:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.4584
[32m[0417 23:48:16 @monitor.py:363][0m activation-summaries/output-rms: 0.020629
[32m[0417 23:48:16 @monitor.py:363][0m cross_entropy_loss: 3.2978
[32m[0417 23:48:16 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29822
[32m[0417 23:48:16 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17051
[32m[0417 23:48:16 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53127
[32m[0417 23:48:16 @monitor.py:363][0m last_linear/Wn_0: 0.14466
[32m[0417 23:48:16 @monitor.py:363][0m last_linear/Wp_0: 0.11302
[32m[0417 23:48:16 @monitor.py:363][0m linear0/W_0_percent_n: 0.11577
[32m[0417 23:48:16 @monitor.py:363][0m linear0/W_0_percent_p: 0.12995
[32m[0417 23:48:16 @monitor.py:363][0m linear0/W_0_sparsity: 0.75429
[32m[0417 23:48:16 @monitor.py:363][0m linear0/Wn_0: 0.94351
[32m[0417 23:48:16 @monitor.py:363][0m linear0/Wp_0: 1.0476
[32m[0417 23:48:16 @monitor.py:363][0m linear1/W_0_percent_n: 0.1591
[32m[0417 23:48:16 @monitor.py:363][0m linear1/W_0_percent_p: 0.12599
[32m[0417 23:48:16 @monitor.py:363][0m linear1/W_0_sparsity: 0.7149
[32m[0417 23:48:16 @monitor.py:363][0m linear1/Wn_0: 0.8923
[32m[0417 23:48:16 @monitor.py:363][0m linear1/Wp_0: 0.93508
[32m[0417 23:48:16 @monitor.py:363][0m linear2/W_0_percent_n: 0.035278
[32m[0417 23:48:16 @monitor.py:363][0m linear2/W_0_percent_p: 0.044083
[32m[0417 23:48:16 @monitor.py:363][0m linear2/W_0_sparsity: 0.92064
[32m[0417 23:48:16 @monitor.py:363][0m linear2/Wn_0: 1.0662
[32m[0417 23:48:16 @monitor.py:363][0m linear2/Wp_0: 0.83506
[32m[0417 23:48:16 @monitor.py:363][0m linear3/W_0_percent_n: 0.042374
[32m[0417 23:48:16 @monitor.py:363][0m linear3/W_0_percent_p: 0.037842
[32m[0417 23:48:16 @monitor.py:363][0m linear3/W_0_sparsity: 0.91978
[32m[0417 23:48:16 @monitor.py:363][0m linear3/Wn_0: 0.82112
[32m[0417 23:48:16 @monitor.py:363][0m linear3/Wp_0: 0.79858
[32m[0417 23:48:16 @monitor.py:363][0m lr: 0.000125
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 1.2997
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0806
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.91204
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/linear1/W-rms: 1.349
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.98021
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.98248
[32m[0417 23:48:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0417 23:48:16 @monitor.py:363][0m train-error-top1: 0.77459
[32m[0417 23:48:16 @monitor.py:363][0m val-error-top1: 0.84418
[32m[0417 23:48:16 @monitor.py:363][0m val-utt-error: 0.69876
[32m[0417 23:48:16 @monitor.py:363][0m validation_cost: 3.8351
[32m[0417 23:48:16 @monitor.py:363][0m wd_cost: 0.45495
[32m[0417 23:48:16 @group.py:42][0m Callbacks took 219.021 sec in total. InferenceRunner: 218.814sec
[32m[0417 23:48:16 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10357/173481[03:00<47:16,57.52it/s]  6%|6         |10908/173481[03:10<47:06,57.52it/s] 12%|#1        |20095/173481[06:00<45:51,55.75it/s] 12%|#1        |20634/173481[06:10<45:41,55.75it/s] 17%|#7        |29689/173481[09:00<43:59,54.48it/s] 17%|#7        |30228/173481[09:10<43:49,54.48it/s] 23%|##2       |39105/173481[12:00<41:57,53.37it/s] 23%|##2       |39642/173481[12:10<41:47,53.37it/s] 28%|##7       |48496/173481[15:00<39:28,52.77it/s] 28%|##8       |49026/173481[15:10<39:18,52.77it/s] 33%|###3      |57574/173481[18:00<37:27,51.57it/s] 34%|###3      |58122/173481[18:10<37:16,51.57it/s] 38%|###8      |66496/173481[21:00<35:16,50.55it/s] 39%|###8      |67062/173481[21:11<35:05,50.55it/s] 44%|####4     |77132/173481[24:00<29:28,54.49it/s] 45%|####4     |77882/173481[24:11<29:14,54.49it/s] 52%|#####1    |89449/173481[27:00<23:05,60.66it/s] 52%|#####1    |90167/173481[27:11<22:53,60.66it/s] 57%|#####6    |98492/173481[30:00<22:44,54.96it/s] 57%|#####7    |99008/173481[30:11<22:35,54.96it/s] 62%|######1   |107203/173481[33:00<21:27,51.47it/s] 62%|######2   |107772/173481[33:11<21:16,51.47it/s] 67%|######7   |116497/173481[36:00<18:25,51.54it/s] 67%|######7   |117037/173481[36:11<18:15,51.54it/s] 72%|#######2  |124987/173481[39:00<16:24,49.26it/s] 72%|#######2  |125592/173481[39:11<16:12,49.26it/s] 77%|#######7  |134161/173481[42:00<13:04,50.09it/s] 78%|#######7  |134728/173481[42:12<12:53,50.09it/s] 83%|########2 |143233/173481[45:00<10:02,50.24it/s] 83%|########2 |143808/173481[45:12<09:50,50.24it/s] 88%|########7 |151897/173481[48:00<07:19,49.16it/s] 88%|########7 |152484/173481[48:12<07:07,49.16it/s] 93%|#########2|160940/173481[51:00<04:12,49.69it/s] 93%|#########3|161562/173481[51:12<03:59,49.69it/s] 98%|#########7|169975/173481[54:00<01:10,49.94it/s] 98%|#########8|170598/173481[54:12<00:57,49.94it/s]100%|##########|173481/173481[55:20<00:00,52.25it/s]
[32m[0418 00:43:36 @base.py:257][0m Epoch 11 (global_step 1908291) finished, time:3320.10 sec.
[32m[0418 00:43:37 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-1908291.
  0%|          |0/18822[00:00<?,?it/s] 73%|#######3  |13761/18822[03:00<01:06,76.45it/s] 78%|#######7  |14672/18822[03:10<00:54,76.45it/s]100%|##########|18822/18822[03:54<00:00,80.18it/s]
10
[32m[0418 00:47:31 @monitor.py:363][0m QueueInput/queue_size: 0.80552
[32m[0418 00:47:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.5712
[32m[0418 00:47:31 @monitor.py:363][0m activation-summaries/output-rms: 0.021207
[32m[0418 00:47:31 @monitor.py:363][0m cross_entropy_loss: 3.2247
[32m[0418 00:47:31 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29749
[32m[0418 00:47:31 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16714
[32m[0418 00:47:31 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53537
[32m[0418 00:47:31 @monitor.py:363][0m last_linear/Wn_0: 0.14768
[32m[0418 00:47:31 @monitor.py:363][0m last_linear/Wp_0: 0.11539
[32m[0418 00:47:31 @monitor.py:363][0m linear0/W_0_percent_n: 0.10807
[32m[0418 00:47:31 @monitor.py:363][0m linear0/W_0_percent_p: 0.12324
[32m[0418 00:47:31 @monitor.py:363][0m linear0/W_0_sparsity: 0.76869
[32m[0418 00:47:31 @monitor.py:363][0m linear0/Wn_0: 0.95634
[32m[0418 00:47:31 @monitor.py:363][0m linear0/Wp_0: 1.0436
[32m[0418 00:47:31 @monitor.py:363][0m linear1/W_0_percent_n: 0.15695
[32m[0418 00:47:31 @monitor.py:363][0m linear1/W_0_percent_p: 0.12645
[32m[0418 00:47:31 @monitor.py:363][0m linear1/W_0_sparsity: 0.7166
[32m[0418 00:47:31 @monitor.py:363][0m linear1/Wn_0: 0.90318
[32m[0418 00:47:31 @monitor.py:363][0m linear1/Wp_0: 0.93558
[32m[0418 00:47:31 @monitor.py:363][0m linear2/W_0_percent_n: 0.034607
[32m[0418 00:47:31 @monitor.py:363][0m linear2/W_0_percent_p: 0.043991
[32m[0418 00:47:31 @monitor.py:363][0m linear2/W_0_sparsity: 0.9214
[32m[0418 00:47:31 @monitor.py:363][0m linear2/Wn_0: 1.08
[32m[0418 00:47:31 @monitor.py:363][0m linear2/Wp_0: 0.83462
[32m[0418 00:47:31 @monitor.py:363][0m linear3/W_0_percent_n: 0.042908
[32m[0418 00:47:31 @monitor.py:363][0m linear3/W_0_percent_p: 0.038147
[32m[0418 00:47:31 @monitor.py:363][0m linear3/W_0_sparsity: 0.91895
[32m[0418 00:47:31 @monitor.py:363][0m linear3/Wn_0: 0.82449
[32m[0418 00:47:31 @monitor.py:363][0m linear3/Wp_0: 0.80838
[32m[0418 00:47:31 @monitor.py:363][0m lr: 6.25e-05
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 1.5387
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0934
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/linear0/W-rms: 1.0915
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/linear1/W-rms: 1.5777
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/linear2/W-rms: 1.119
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/linear3/W-rms: 1.1272
[32m[0418 00:47:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 00:47:31 @monitor.py:363][0m train-error-top1: 0.76652
[32m[0418 00:47:31 @monitor.py:363][0m val-error-top1: 0.83896
[32m[0418 00:47:31 @monitor.py:363][0m val-utt-error: 0.68106
[32m[0418 00:47:31 @monitor.py:363][0m validation_cost: 3.7711
[32m[0418 00:47:31 @monitor.py:363][0m wd_cost: 0.63041
[32m[0418 00:47:31 @group.py:42][0m Callbacks took 234.938 sec in total. InferenceRunner: 234.754sec
[32m[0418 00:47:31 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9324/173481[03:00<52:49,51.80it/s]  6%|5         |9869/173481[03:10<52:38,51.80it/s] 11%|#         |18736/173481[06:00<49:33,52.04it/s] 11%|#1        |19276/173481[06:10<49:23,52.04it/s] 16%|#6        |28256/173481[09:00<46:08,52.46it/s] 17%|#6        |28821/173481[09:10<45:57,52.46it/s] 22%|##2       |38212/173481[12:00<41:52,53.84it/s] 22%|##2       |38793/173481[12:10<41:41,53.84it/s] 28%|##7       |47982/173481[15:00<38:41,54.06it/s] 28%|##7       |48555/173481[15:10<38:30,54.06it/s] 33%|###3      |57904/173481[18:00<35:17,54.58it/s] 34%|###3      |58521/173481[18:10<35:06,54.58it/s] 40%|###9      |68883/173481[21:00<30:15,57.61it/s] 40%|####      |69733/173481[21:11<30:00,57.61it/s] 48%|####7     |82500/173481[24:00<23:10,65.41it/s] 48%|####8     |83382/173481[24:11<22:57,65.41it/s] 54%|#####3    |93304/173481[27:00<21:21,62.59it/s] 54%|#####4    |93921/173481[27:11<21:11,62.59it/s] 59%|#####9    |103198/173481[30:00<20:00,58.52it/s] 60%|#####9    |103814/173481[30:11<19:50,58.52it/s] 65%|######4   |112066/173481[33:00<19:08,53.49it/s] 65%|######4   |112695/173481[33:11<18:56,53.49it/s] 70%|#######   |121936/173481[36:00<15:51,54.15it/s] 71%|#######   |122571/173481[36:11<15:40,54.15it/s] 76%|#######5  |131764/173481[39:00<12:47,54.37it/s] 76%|#######6  |132399/173481[39:11<12:35,54.37it/s] 82%|########1 |141556/173481[42:00<09:47,54.38it/s] 82%|########1 |142116/173481[42:12<09:36,54.38it/s] 87%|########7 |151192/173481[45:00<06:53,53.95it/s] 88%|########7 |151835/173481[45:12<06:41,53.95it/s] 93%|#########2|160888/173481[48:00<03:53,53.90it/s] 93%|#########3|161489/173481[48:12<03:42,53.90it/s] 98%|#########8|170254/173481[51:00<01:00,52.95it/s] 98%|#########8|170841/173481[51:12<00:49,52.95it/s]100%|##########|173481/173481[52:04<00:00,55.53it/s]
[32m[0418 01:39:35 @base.py:257][0m Epoch 12 (global_step 2081772) finished, time:3124.05 sec.
[32m[0418 01:39:35 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-2081772.
[32m[0418 01:39:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 67%|######7   |12650/18822[03:00<01:27,70.28it/s] 72%|#######1  |13524/18822[03:10<01:15,70.28it/s]100%|##########|18822/18822[04:08<00:00,75.89it/s]
11
[32m[0418 01:43:47 @monitor.py:363][0m QueueInput/queue_size: 0.43197
[32m[0418 01:43:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.6629
[32m[0418 01:43:47 @monitor.py:363][0m activation-summaries/output-rms: 0.021566
[32m[0418 01:43:47 @monitor.py:363][0m cross_entropy_loss: 3.2251
[32m[0418 01:43:47 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29802
[32m[0418 01:43:47 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16657
[32m[0418 01:43:47 @monitor.py:363][0m last_linear/W_0_sparsity: 0.5354
[32m[0418 01:43:47 @monitor.py:363][0m last_linear/Wn_0: 0.15148
[32m[0418 01:43:47 @monitor.py:363][0m last_linear/Wp_0: 0.1159
[32m[0418 01:43:47 @monitor.py:363][0m linear0/W_0_percent_n: 0.11234
[32m[0418 01:43:47 @monitor.py:363][0m linear0/W_0_percent_p: 0.12648
[32m[0418 01:43:47 @monitor.py:363][0m linear0/W_0_sparsity: 0.76118
[32m[0418 01:43:47 @monitor.py:363][0m linear0/Wn_0: 0.96054
[32m[0418 01:43:47 @monitor.py:363][0m linear0/Wp_0: 1.0428
[32m[0418 01:43:47 @monitor.py:363][0m linear1/W_0_percent_n: 0.15504
[32m[0418 01:43:47 @monitor.py:363][0m linear1/W_0_percent_p: 0.12271
[32m[0418 01:43:47 @monitor.py:363][0m linear1/W_0_sparsity: 0.72224
[32m[0418 01:43:47 @monitor.py:363][0m linear1/Wn_0: 0.90254
[32m[0418 01:43:47 @monitor.py:363][0m linear1/Wp_0: 0.9435
[32m[0418 01:43:47 @monitor.py:363][0m linear2/W_0_percent_n: 0.034744
[32m[0418 01:43:47 @monitor.py:363][0m linear2/W_0_percent_p: 0.043777
[32m[0418 01:43:47 @monitor.py:363][0m linear2/W_0_sparsity: 0.92148
[32m[0418 01:43:47 @monitor.py:363][0m linear2/Wn_0: 1.0842
[32m[0418 01:43:47 @monitor.py:363][0m linear2/Wp_0: 0.83849
[32m[0418 01:43:47 @monitor.py:363][0m linear3/W_0_percent_n: 0.042862
[32m[0418 01:43:47 @monitor.py:363][0m linear3/W_0_percent_p: 0.038162
[32m[0418 01:43:47 @monitor.py:363][0m linear3/W_0_sparsity: 0.91898
[32m[0418 01:43:47 @monitor.py:363][0m linear3/Wn_0: 0.82595
[32m[0418 01:43:47 @monitor.py:363][0m linear3/Wp_0: 0.81438
[32m[0418 01:43:47 @monitor.py:363][0m lr: 6.25e-05
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 1.7146
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0982
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/linear0/W-rms: 1.2882
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/linear1/W-rms: 1.733
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/linear2/W-rms: 1.2061
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/linear3/W-rms: 1.2169
[32m[0418 01:43:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 01:43:47 @monitor.py:363][0m train-error-top1: 0.76222
[32m[0418 01:43:47 @monitor.py:363][0m val-error-top1: 0.84209
[32m[0418 01:43:47 @monitor.py:363][0m val-utt-error: 0.68664
[32m[0418 01:43:47 @monitor.py:363][0m validation_cost: 3.7518
[32m[0418 01:43:47 @monitor.py:363][0m wd_cost: 0.16095
[32m[0418 01:43:47 @group.py:42][0m Callbacks took 251.431 sec in total. InferenceRunner: 248.022sec
[32m[0418 01:43:47 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10159/173481[03:00<48:14,56.43it/s]  6%|6         |10710/173481[03:10<48:04,56.43it/s] 12%|#1        |20095/173481[06:00<45:48,55.81it/s] 12%|#1        |20634/173481[06:10<45:38,55.81it/s] 17%|#7        |29650/173481[09:00<44:03,54.41it/s] 17%|#7        |30215/173481[09:10<43:53,54.41it/s] 22%|##2       |38993/173481[12:00<42:11,53.13it/s] 23%|##2       |39534/173481[12:10<42:01,53.13it/s] 28%|##7       |48169/173481[15:00<40:08,52.03it/s] 28%|##8       |48721/173481[15:10<39:57,52.03it/s] 33%|###3      |57637/173481[18:00<36:54,52.31it/s] 34%|###3      |58284/173481[18:10<36:42,52.31it/s] 41%|####      |70723/173481[21:00<28:09,60.84it/s] 41%|####1     |71592/173481[21:10<27:54,60.84it/s] 48%|####8     |83899/173481[24:00<22:28,66.44it/s] 49%|####8     |84468/173481[24:11<22:19,66.44it/s] 54%|#####3    |93511/173481[27:00<22:30,59.21it/s] 54%|#####4    |94106/173481[27:11<22:20,59.21it/s] 59%|#####8    |102004/173481[30:00<22:41,52.52it/s] 59%|#####9    |102606/173481[30:11<22:29,52.52it/s] 64%|######4   |111517/173481[33:00<19:36,52.68it/s] 65%|######4   |112136/173481[33:11<19:24,52.68it/s] 70%|######9   |120979/173481[36:00<16:37,52.62it/s] 70%|#######   |121583/173481[36:11<16:26,52.62it/s] 75%|#######5  |130343/173481[39:00<13:44,52.32it/s] 75%|#######5  |130956/173481[39:11<13:32,52.32it/s] 80%|########  |139525/173481[42:00<10:57,51.64it/s] 81%|########  |139692/173481[42:11<10:54,51.64it/s] 84%|########4 |145936/173481[45:00<10:53,42.16it/s] 85%|########4 |146760/173481[45:12<10:33,42.16it/s] 90%|######### |156739/173481[48:00<05:38,49.52it/s] 91%|######### |157363/173481[48:12<05:25,49.52it/s] 96%|#########6|166727/173481[51:00<02:09,52.34it/s] 96%|#########6|167406/173481[51:12<01:56,52.34it/s]100%|##########|173481/173481[53:01<00:00,54.52it/s]
[32m[0418 02:36:49 @base.py:257][0m Epoch 13 (global_step 2255253) finished, time:3181.83 sec.
[32m[0418 02:36:49 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-2255253.
  0%|          |0/18822[00:00<?,?it/s] 87%|########7 |16396/18822[03:00<00:26,91.09it/s] 93%|#########2|17470/18822[03:10<00:14,91.09it/s]100%|##########|18822/18822[03:22<00:00,92.82it/s]
12
[32m[0418 02:40:12 @monitor.py:363][0m QueueInput/queue_size: 1.2907
[32m[0418 02:40:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.6001
[32m[0418 02:40:12 @monitor.py:363][0m activation-summaries/output-rms: 0.021241
[32m[0418 02:40:12 @monitor.py:363][0m cross_entropy_loss: 3.2332
[32m[0418 02:40:12 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29692
[32m[0418 02:40:12 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16461
[32m[0418 02:40:12 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53847
[32m[0418 02:40:12 @monitor.py:363][0m last_linear/Wn_0: 0.15669
[32m[0418 02:40:12 @monitor.py:363][0m last_linear/Wp_0: 0.12286
[32m[0418 02:40:12 @monitor.py:363][0m linear0/W_0_percent_n: 0.11589
[32m[0418 02:40:12 @monitor.py:363][0m linear0/W_0_percent_p: 0.13074
[32m[0418 02:40:12 @monitor.py:363][0m linear0/W_0_sparsity: 0.75337
[32m[0418 02:40:12 @monitor.py:363][0m linear0/Wn_0: 0.96055
[32m[0418 02:40:12 @monitor.py:363][0m linear0/Wp_0: 1.0462
[32m[0418 02:40:12 @monitor.py:363][0m linear1/W_0_percent_n: 0.15628
[32m[0418 02:40:12 @monitor.py:363][0m linear1/W_0_percent_p: 0.12579
[32m[0418 02:40:12 @monitor.py:363][0m linear1/W_0_sparsity: 0.71791
[32m[0418 02:40:12 @monitor.py:363][0m linear1/Wn_0: 0.90646
[32m[0418 02:40:12 @monitor.py:363][0m linear1/Wp_0: 0.94716
[32m[0418 02:40:12 @monitor.py:363][0m linear2/W_0_percent_n: 0.034332
[32m[0418 02:40:12 @monitor.py:363][0m linear2/W_0_percent_p: 0.043182
[32m[0418 02:40:12 @monitor.py:363][0m linear2/W_0_sparsity: 0.92247
[32m[0418 02:40:12 @monitor.py:363][0m linear2/Wn_0: 1.0902
[32m[0418 02:40:12 @monitor.py:363][0m linear2/Wp_0: 0.84062
[32m[0418 02:40:12 @monitor.py:363][0m linear3/W_0_percent_n: 0.042435
[32m[0418 02:40:12 @monitor.py:363][0m linear3/W_0_percent_p: 0.037766
[32m[0418 02:40:12 @monitor.py:363][0m linear3/W_0_sparsity: 0.9198
[32m[0418 02:40:12 @monitor.py:363][0m linear3/Wn_0: 0.83515
[32m[0418 02:40:12 @monitor.py:363][0m linear3/Wp_0: 0.81436
[32m[0418 02:40:12 @monitor.py:363][0m lr: 6.25e-05
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 1.8882
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1033
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/linear0/W-rms: 1.4872
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/linear1/W-rms: 1.89
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/linear2/W-rms: 1.2925
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/linear3/W-rms: 1.3054
[32m[0418 02:40:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 02:40:12 @monitor.py:363][0m train-error-top1: 0.76185
[32m[0418 02:40:12 @monitor.py:363][0m val-error-top1: 0.83655
[32m[0418 02:40:12 @monitor.py:363][0m val-utt-error: 0.65322
[32m[0418 02:40:12 @monitor.py:363][0m validation_cost: 3.7008
[32m[0418 02:40:12 @monitor.py:363][0m wd_cost: 0.20067
[32m[0418 02:40:12 @group.py:42][0m Callbacks took 203.194 sec in total. InferenceRunner: 202.800sec
[32m[0418 02:40:12 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11014/173481[03:00<44:16,61.17it/s]  7%|6         |11572/173481[03:10<44:06,61.17it/s] 12%|#1        |20744/173481[06:00<44:21,57.39it/s] 12%|#2        |21267/173481[06:10<44:12,57.39it/s] 18%|#7        |30378/173481[09:00<43:03,55.39it/s] 18%|#7        |30927/173481[09:10<42:53,55.39it/s] 23%|##3       |40030/173481[12:00<40:49,54.48it/s] 23%|##3       |40581/173481[12:10<40:39,54.48it/s] 29%|##8       |49525/173481[15:00<38:32,53.60it/s] 29%|##8       |50086/173481[15:10<38:22,53.60it/s] 34%|###4      |59540/173481[18:00<34:46,54.60it/s] 35%|###4      |60177/173481[18:10<34:35,54.60it/s] 43%|####3     |74713/173481[21:00<24:50,66.27it/s] 43%|####3     |75423/173481[21:11<24:39,66.27it/s] 49%|####9     |85006/173481[24:00<24:01,61.39it/s] 49%|####9     |85557/173481[24:11<23:52,61.39it/s] 54%|#####3    |93202/173481[27:00<25:35,52.28it/s] 54%|#####3    |93657/173481[27:11<25:26,52.28it/s] 57%|#####6    |98602/173481[30:00<32:44,38.12it/s] 57%|#####7    |99177/173481[30:11<32:29,38.12it/s] 62%|######2   |107913/173481[33:00<24:53,43.89it/s] 63%|######2   |108519/173481[33:11<24:40,43.89it/s] 68%|######7   |117598/173481[36:00<19:16,48.34it/s] 68%|######8   |118235/173481[36:11<19:02,48.34it/s] 73%|#######3  |127474/173481[39:00<14:55,51.39it/s] 74%|#######3  |128069/173481[39:11<14:43,51.39it/s] 79%|#######9  |137164/173481[42:00<11:30,52.58it/s] 79%|#######9  |137761/173481[42:12<11:19,52.58it/s] 85%|########5 |147490/173481[45:00<07:53,54.87it/s] 85%|########5 |148125/173481[45:12<07:42,54.87it/s] 91%|######### |157114/173481[48:00<05:02,54.15it/s] 91%|######### |157761/173481[48:12<04:50,54.15it/s] 96%|#########6|166804/173481[51:00<02:03,53.99it/s] 97%|#########6|167457/173481[51:12<01:51,53.99it/s]100%|##########|173481/173481[53:05<00:00,54.46it/s]
[32m[0418 03:33:17 @base.py:257][0m Epoch 14 (global_step 2428734) finished, time:3185.36 sec.
[32m[0418 03:33:18 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-2428734.
[32m[0418 03:33:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 83%|########3 |15678/18822[03:00<00:36,87.10it/s] 89%|########8 |16731/18822[03:10<00:24,87.10it/s]100%|##########|18822/18822[03:29<00:00,89.70it/s]
13
[32m[0418 03:36:49 @monitor.py:363][0m QueueInput/queue_size: 0.5982
[32m[0418 03:36:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.3264
[32m[0418 03:36:49 @monitor.py:363][0m activation-summaries/output-rms: 0.021074
[32m[0418 03:36:49 @monitor.py:363][0m cross_entropy_loss: 3.2431
[32m[0418 03:36:49 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29795
[32m[0418 03:36:49 @monitor.py:363][0m last_linear/W_0_percent_p: 0.1674
[32m[0418 03:36:49 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53465
[32m[0418 03:36:49 @monitor.py:363][0m last_linear/Wn_0: 0.16197
[32m[0418 03:36:49 @monitor.py:363][0m last_linear/Wp_0: 0.13106
[32m[0418 03:36:49 @monitor.py:363][0m linear0/W_0_percent_n: 0.10261
[32m[0418 03:36:49 @monitor.py:363][0m linear0/W_0_percent_p: 0.11749
[32m[0418 03:36:49 @monitor.py:363][0m linear0/W_0_sparsity: 0.77989
[32m[0418 03:36:49 @monitor.py:363][0m linear0/Wn_0: 0.96622
[32m[0418 03:36:49 @monitor.py:363][0m linear0/Wp_0: 1.044
[32m[0418 03:36:49 @monitor.py:363][0m linear1/W_0_percent_n: 0.15576
[32m[0418 03:36:49 @monitor.py:363][0m linear1/W_0_percent_p: 0.12354
[32m[0418 03:36:49 @monitor.py:363][0m linear1/W_0_sparsity: 0.7207
[32m[0418 03:36:49 @monitor.py:363][0m linear1/Wn_0: 0.90715
[32m[0418 03:36:49 @monitor.py:363][0m linear1/Wp_0: 0.95319
[32m[0418 03:36:49 @monitor.py:363][0m linear2/W_0_percent_n: 0.035004
[32m[0418 03:36:49 @monitor.py:363][0m linear2/W_0_percent_p: 0.044083
[32m[0418 03:36:49 @monitor.py:363][0m linear2/W_0_sparsity: 0.92091
[32m[0418 03:36:49 @monitor.py:363][0m linear2/Wn_0: 1.0724
[32m[0418 03:36:49 @monitor.py:363][0m linear2/Wp_0: 0.8654
[32m[0418 03:36:49 @monitor.py:363][0m linear3/W_0_percent_n: 0.041916
[32m[0418 03:36:49 @monitor.py:363][0m linear3/W_0_percent_p: 0.037476
[32m[0418 03:36:49 @monitor.py:363][0m linear3/W_0_sparsity: 0.92059
[32m[0418 03:36:49 @monitor.py:363][0m linear3/Wn_0: 0.84531
[32m[0418 03:36:49 @monitor.py:363][0m linear3/Wp_0: 0.81549
[32m[0418 03:36:49 @monitor.py:363][0m lr: 3.125e-05
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.0234
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1075
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/linear0/W-rms: 1.6447
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/linear1/W-rms: 2.0149
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/linear2/W-rms: 1.3607
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/linear3/W-rms: 1.3751
[32m[0418 03:36:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 03:36:49 @monitor.py:363][0m train-error-top1: 0.77234
[32m[0418 03:36:49 @monitor.py:363][0m val-error-top1: 0.84164
[32m[0418 03:36:49 @monitor.py:363][0m val-utt-error: 0.67177
[32m[0418 03:36:49 @monitor.py:363][0m validation_cost: 3.7758
[32m[0418 03:36:49 @monitor.py:363][0m wd_cost: 0.047073
[32m[0418 03:36:49 @group.py:42][0m Callbacks took 211.513 sec in total. InferenceRunner: 209.866sec
[32m[0418 03:36:49 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10065/173481[03:00<48:42,55.91it/s]  6%|6         |10608/173481[03:10<48:32,55.91it/s] 11%|#1        |19411/173481[06:00<47:41,53.84it/s] 11%|#1        |19944/173481[06:10<47:31,53.84it/s] 17%|#6        |28759/173481[09:00<45:37,52.87it/s] 17%|#6        |29292/173481[09:10<45:27,52.87it/s] 22%|##1       |38083/173481[12:00<43:07,52.32it/s] 22%|##2       |38628/173481[12:10<42:57,52.32it/s] 27%|##7       |47374/173481[15:00<40:26,51.96it/s] 28%|##7       |47922/173481[15:10<40:16,51.96it/s] 33%|###2      |56701/173481[18:00<37:30,51.89it/s] 33%|###3      |57264/173481[18:10<37:19,51.89it/s] 40%|###9      |68646/173481[21:00<30:00,58.24it/s] 40%|####      |69484/173481[21:11<29:45,58.24it/s] 47%|####7     |82210/173481[24:00<23:09,65.70it/s] 48%|####7     |82837/173481[24:11<22:59,65.70it/s] 52%|#####2    |90848/173481[27:00<24:49,55.46it/s] 53%|#####2    |91446/173481[27:11<24:39,55.46it/s] 58%|#####7    |100597/173481[30:00<22:09,54.80it/s] 58%|#####8    |101190/173481[30:11<21:59,54.80it/s] 63%|######3   |110011/173481[33:00<19:46,53.52it/s] 64%|######3   |110604/173481[33:11<19:34,53.52it/s] 69%|######8   |119407/173481[36:00<17:03,52.84it/s] 69%|######9   |120000/173481[36:11<16:52,52.84it/s] 74%|#######4  |128719/173481[39:00<14:16,52.28it/s] 75%|#######4  |129330/173481[39:11<14:04,52.28it/s] 80%|#######9  |138097/173481[42:00<11:18,52.18it/s] 80%|#######9  |138686/173481[42:12<11:06,52.18it/s] 85%|########5 |147475/173481[45:00<08:18,52.14it/s] 85%|########5 |148074/173481[45:12<08:07,52.14it/s] 91%|######### |157027/173481[48:00<05:12,52.60it/s] 91%|######### |157662/173481[48:12<05:00,52.60it/s] 96%|#########6|166712/173481[51:00<02:07,53.19it/s] 97%|#########6|167418/173481[51:12<01:53,53.19it/s]100%|##########|173481/173481[53:01<00:00,54.53it/s]
[32m[0418 04:29:50 @base.py:257][0m Epoch 15 (global_step 2602215) finished, time:3181.39 sec.
[32m[0418 04:29:50 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-2602215.
  0%|          |0/18822[00:00<?,?it/s] 92%|#########2|17375/18822[03:00<00:14,96.52it/s] 98%|#########8|18480/18822[03:10<00:03,96.52it/s]100%|##########|18822/18822[03:13<00:00,97.32it/s]
14
[32m[0418 04:33:04 @monitor.py:363][0m QueueInput/queue_size: 0.84859
[32m[0418 04:33:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.0592
[32m[0418 04:33:04 @monitor.py:363][0m activation-summaries/output-rms: 0.021345
[32m[0418 04:33:04 @monitor.py:363][0m cross_entropy_loss: 3.2016
[32m[0418 04:33:04 @monitor.py:363][0m last_linear/W_0_percent_n: 0.2945
[32m[0418 04:33:04 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16513
[32m[0418 04:33:04 @monitor.py:363][0m last_linear/W_0_sparsity: 0.54035
[32m[0418 04:33:04 @monitor.py:363][0m last_linear/Wn_0: 0.16655
[32m[0418 04:33:04 @monitor.py:363][0m last_linear/Wp_0: 0.13868
[32m[0418 04:33:04 @monitor.py:363][0m linear0/W_0_percent_n: 0.096816
[32m[0418 04:33:04 @monitor.py:363][0m linear0/W_0_percent_p: 0.11177
[32m[0418 04:33:04 @monitor.py:363][0m linear0/W_0_sparsity: 0.7914
[32m[0418 04:33:04 @monitor.py:363][0m linear0/Wn_0: 0.97174
[32m[0418 04:33:04 @monitor.py:363][0m linear0/Wp_0: 1.0417
[32m[0418 04:33:04 @monitor.py:363][0m linear1/W_0_percent_n: 0.15395
[32m[0418 04:33:04 @monitor.py:363][0m linear1/W_0_percent_p: 0.12219
[32m[0418 04:33:04 @monitor.py:363][0m linear1/W_0_sparsity: 0.72386
[32m[0418 04:33:04 @monitor.py:363][0m linear1/Wn_0: 0.90995
[32m[0418 04:33:04 @monitor.py:363][0m linear1/Wp_0: 0.9561
[32m[0418 04:33:04 @monitor.py:363][0m linear2/W_0_percent_n: 0.034424
[32m[0418 04:33:04 @monitor.py:363][0m linear2/W_0_percent_p: 0.043396
[32m[0418 04:33:04 @monitor.py:363][0m linear2/W_0_sparsity: 0.92218
[32m[0418 04:33:04 @monitor.py:363][0m linear2/Wn_0: 1.085
[32m[0418 04:33:04 @monitor.py:363][0m linear2/Wp_0: 0.85849
[32m[0418 04:33:04 @monitor.py:363][0m linear3/W_0_percent_n: 0.041916
[32m[0418 04:33:04 @monitor.py:363][0m linear3/W_0_percent_p: 0.036987
[32m[0418 04:33:04 @monitor.py:363][0m linear3/W_0_sparsity: 0.9211
[32m[0418 04:33:04 @monitor.py:363][0m linear3/Wn_0: 0.84907
[32m[0418 04:33:04 @monitor.py:363][0m linear3/Wp_0: 0.82206
[32m[0418 04:33:04 @monitor.py:363][0m lr: 3.125e-05
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.1121
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1064
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/linear0/W-rms: 1.7571
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/linear1/W-rms: 2.0964
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/linear2/W-rms: 1.4032
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/linear3/W-rms: 1.419
[32m[0418 04:33:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 04:33:04 @monitor.py:363][0m train-error-top1: 0.7686
[32m[0418 04:33:04 @monitor.py:363][0m val-error-top1: 0.83578
[32m[0418 04:33:04 @monitor.py:363][0m val-utt-error: 0.67001
[32m[0418 04:33:04 @monitor.py:363][0m validation_cost: 3.7292
[32m[0418 04:33:04 @monitor.py:363][0m wd_cost: 0.05218
[32m[0418 04:33:04 @group.py:42][0m Callbacks took 193.719 sec in total. InferenceRunner: 193.423sec
[32m[0418 04:33:04 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8981/173481[03:00<54:57,49.89it/s]  5%|5         |9537/173481[03:10<54:46,49.89it/s] 11%|#         |18893/173481[06:00<49:12,52.35it/s] 11%|#1        |19485/173481[06:10<49:01,52.35it/s] 17%|#6        |28967/173481[09:00<44:31,54.10it/s] 17%|#7        |29531/173481[09:10<44:20,54.10it/s] 22%|##2       |38998/173481[12:00<40:49,54.90it/s] 23%|##2       |39600/173481[12:10<40:38,54.90it/s] 28%|##8       |48958/173481[15:00<37:39,55.11it/s] 29%|##8       |49554/173481[15:10<37:28,55.11it/s] 34%|###3      |58918/173481[18:00<34:34,55.22it/s] 34%|###4      |59499/173481[18:10<34:24,55.22it/s] 41%|####      |71104/173481[21:00<28:03,60.82it/s] 41%|####1     |71942/173481[21:10<27:49,60.82it/s] 48%|####8     |83922/173481[24:00<22:45,65.61it/s] 49%|####8     |84609/173481[24:11<22:34,65.61it/s] 55%|#####5    |95644/173481[27:00<19:51,65.35it/s] 56%|#####5    |96457/173481[27:11<19:38,65.35it/s] 62%|######1   |106796/173481[30:00<17:28,63.61it/s] 62%|######1   |107397/173481[30:11<17:18,63.61it/s] 67%|######7   |116265/173481[33:00<16:33,57.59it/s] 67%|######7   |116847/173481[33:11<16:23,57.59it/s] 72%|#######2  |125464/173481[36:00<14:46,54.14it/s] 73%|#######2  |126039/173481[36:11<14:36,54.14it/s] 78%|#######7  |134484/173481[39:00<12:29,52.05it/s] 78%|#######7  |135064/173481[39:11<12:18,52.05it/s] 83%|########2 |143586/173481[42:00<09:42,51.30it/s] 83%|########3 |144156/173481[42:12<09:31,51.30it/s] 88%|########7 |152662/173481[45:00<06:49,50.85it/s] 88%|########8 |153243/173481[45:12<06:37,50.85it/s] 93%|#########3|161617/173481[48:00<03:55,50.29it/s] 93%|#########3|162195/173481[48:12<03:44,50.29it/s] 99%|#########8|170968/173481[51:00<00:49,51.10it/s] 99%|#########8|171615/173481[51:12<00:36,51.10it/s]100%|##########|173481/173481[51:46<00:00,55.85it/s]
[32m[0418 05:24:50 @base.py:257][0m Epoch 16 (global_step 2775696) finished, time:3106.11 sec.
[32m[0418 05:24:50 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-2775696.
[32m[0418 05:24:50 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 96%|#########5|17999/18822[03:00<00:08,99.99it/s]100%|##########|18822/18822[03:08<00:00,99.96it/s]
15
[32m[0418 05:27:59 @monitor.py:363][0m QueueInput/queue_size: 0.58695
[32m[0418 05:27:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.9125
[32m[0418 05:27:59 @monitor.py:363][0m activation-summaries/output-rms: 0.020543
[32m[0418 05:27:59 @monitor.py:363][0m cross_entropy_loss: 3.308
[32m[0418 05:27:59 @monitor.py:363][0m last_linear/W_0_percent_n: 0.2918
[32m[0418 05:27:59 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16195
[32m[0418 05:27:59 @monitor.py:363][0m last_linear/W_0_sparsity: 0.54625
[32m[0418 05:27:59 @monitor.py:363][0m last_linear/Wn_0: 0.17353
[32m[0418 05:27:59 @monitor.py:363][0m last_linear/Wp_0: 0.14599
[32m[0418 05:27:59 @monitor.py:363][0m linear0/W_0_percent_n: 0.097336
[32m[0418 05:27:59 @monitor.py:363][0m linear0/W_0_percent_p: 0.1128
[32m[0418 05:27:59 @monitor.py:363][0m linear0/W_0_sparsity: 0.78987
[32m[0418 05:27:59 @monitor.py:363][0m linear0/Wn_0: 0.97202
[32m[0418 05:27:59 @monitor.py:363][0m linear0/Wp_0: 1.0449
[32m[0418 05:27:59 @monitor.py:363][0m linear1/W_0_percent_n: 0.15382
[32m[0418 05:27:59 @monitor.py:363][0m linear1/W_0_percent_p: 0.1212
[32m[0418 05:27:59 @monitor.py:363][0m linear1/W_0_sparsity: 0.72495
[32m[0418 05:27:59 @monitor.py:363][0m linear1/Wn_0: 0.91666
[32m[0418 05:27:59 @monitor.py:363][0m linear1/Wp_0: 0.95507
[32m[0418 05:27:59 @monitor.py:363][0m linear2/W_0_percent_n: 0.033783
[32m[0418 05:27:59 @monitor.py:363][0m linear2/W_0_percent_p: 0.042236
[32m[0418 05:27:59 @monitor.py:363][0m linear2/W_0_sparsity: 0.92398
[32m[0418 05:27:59 @monitor.py:363][0m linear2/Wn_0: 1.0882
[32m[0418 05:27:59 @monitor.py:363][0m linear2/Wp_0: 0.86145
[32m[0418 05:27:59 @monitor.py:363][0m linear3/W_0_percent_n: 0.042038
[32m[0418 05:27:59 @monitor.py:363][0m linear3/W_0_percent_p: 0.037186
[32m[0418 05:27:59 @monitor.py:363][0m linear3/W_0_sparsity: 0.92078
[32m[0418 05:27:59 @monitor.py:363][0m linear3/Wn_0: 0.85617
[32m[0418 05:27:59 @monitor.py:363][0m linear3/Wp_0: 0.82508
[32m[0418 05:27:59 @monitor.py:363][0m lr: 3.125e-05
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.2047
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1039
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/linear0/W-rms: 1.8705
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/linear1/W-rms: 2.1783
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/linear2/W-rms: 1.4467
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/linear3/W-rms: 1.4639
[32m[0418 05:27:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 05:27:59 @monitor.py:363][0m train-error-top1: 0.77555
[32m[0418 05:27:59 @monitor.py:363][0m val-error-top1: 0.84545
[32m[0418 05:27:59 @monitor.py:363][0m val-utt-error: 0.69536
[32m[0418 05:27:59 @monitor.py:363][0m validation_cost: 3.7787
[32m[0418 05:27:59 @monitor.py:363][0m wd_cost: 0.057648
[32m[0418 05:27:59 @group.py:42][0m Callbacks took 188.768 sec in total. InferenceRunner: 188.310sec
[32m[0418 05:27:59 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10351/173481[03:00<47:17,57.48it/s]  6%|6         |10886/173481[03:10<47:08,57.48it/s] 11%|#1        |19801/173481[06:00<46:40,54.87it/s] 12%|#1        |20355/173481[06:10<46:30,54.87it/s] 17%|#7        |29696/173481[09:00<43:38,54.92it/s] 17%|#7        |30271/173481[09:10<43:27,54.92it/s] 23%|##2       |39355/173481[12:00<41:11,54.28it/s] 23%|##3       |39984/173481[12:10<40:59,54.28it/s] 29%|##8       |49924/173481[15:00<36:30,56.41it/s] 29%|##9       |50532/173481[15:10<36:19,56.41it/s] 35%|###4      |60202/173481[18:00<33:16,56.75it/s] 35%|###5      |60801/173481[18:10<33:05,56.75it/s] 40%|####      |69597/173481[21:00<31:50,54.38it/s] 40%|####      |70116/173481[21:10<31:40,54.38it/s] 48%|####8     |83287/173481[24:00<23:42,63.41it/s] 49%|####8     |84150/173481[24:11<23:28,63.41it/s] 55%|#####5    |95689/173481[27:00<19:38,66.03it/s] 56%|#####5    |96282/173481[27:11<19:29,66.03it/s] 62%|######1   |106885/173481[30:00<17:19,64.05it/s] 62%|######2   |107652/173481[30:11<17:07,64.05it/s] 68%|######7   |117733/173481[33:00<14:57,62.10it/s] 68%|######8   |118380/173481[33:11<14:47,62.10it/s] 74%|#######3  |128149/173481[36:00<12:36,59.90it/s] 74%|#######4  |128813/173481[36:11<12:25,59.90it/s] 80%|#######9  |138212/173481[39:00<10:09,57.83it/s] 80%|########  |138846/173481[39:11<09:58,57.83it/s] 85%|########5 |148291/173481[42:00<07:22,56.90it/s] 86%|########5 |148962/173481[42:11<07:10,56.90it/s] 91%|#########1|158468/173481[45:00<04:24,56.72it/s] 92%|#########1|159132/173481[45:12<04:12,56.72it/s] 97%|#########7|168508/173481[48:00<01:28,56.24it/s] 98%|#########7|169202/173481[48:12<01:16,56.24it/s]100%|##########|173481/173481[49:26<00:00,58.47it/s]
[32m[0418 06:17:26 @base.py:257][0m Epoch 17 (global_step 2949177) finished, time:2966.93 sec.
[32m[0418 06:17:26 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-2949177.
  0%|          |0/18822[00:00<?,?it/s] 89%|########8 |16665/18822[03:00<00:23,92.58it/s] 94%|#########4|17740/18822[03:10<00:11,92.58it/s]100%|##########|18822/18822[03:20<00:00,93.95it/s]
16
[32m[0418 06:20:46 @monitor.py:363][0m QueueInput/queue_size: 0.43851
[32m[0418 06:20:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.86
[32m[0418 06:20:46 @monitor.py:363][0m activation-summaries/output-rms: 0.026732
[32m[0418 06:20:46 @monitor.py:363][0m cross_entropy_loss: 3.3339
[32m[0418 06:20:46 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29049
[32m[0418 06:20:46 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16094
[32m[0418 06:20:46 @monitor.py:363][0m last_linear/W_0_sparsity: 0.54853
[32m[0418 06:20:46 @monitor.py:363][0m last_linear/Wn_0: 0.1815
[32m[0418 06:20:46 @monitor.py:363][0m last_linear/Wp_0: 0.15317
[32m[0418 06:20:46 @monitor.py:363][0m linear0/W_0_percent_n: 0.097535
[32m[0418 06:20:46 @monitor.py:363][0m linear0/W_0_percent_p: 0.11319
[32m[0418 06:20:46 @monitor.py:363][0m linear0/W_0_sparsity: 0.78926
[32m[0418 06:20:46 @monitor.py:363][0m linear0/Wn_0: 0.97889
[32m[0418 06:20:46 @monitor.py:363][0m linear0/Wp_0: 1.0411
[32m[0418 06:20:46 @monitor.py:363][0m linear1/W_0_percent_n: 0.15512
[32m[0418 06:20:46 @monitor.py:363][0m linear1/W_0_percent_p: 0.12502
[32m[0418 06:20:46 @monitor.py:363][0m linear1/W_0_sparsity: 0.71986
[32m[0418 06:20:46 @monitor.py:363][0m linear1/Wn_0: 0.91844
[32m[0418 06:20:46 @monitor.py:363][0m linear1/Wp_0: 0.95861
[32m[0418 06:20:46 @monitor.py:363][0m linear2/W_0_percent_n: 0.034286
[32m[0418 06:20:46 @monitor.py:363][0m linear2/W_0_percent_p: 0.043106
[32m[0418 06:20:46 @monitor.py:363][0m linear2/W_0_sparsity: 0.92261
[32m[0418 06:20:46 @monitor.py:363][0m linear2/Wn_0: 1.0848
[32m[0418 06:20:46 @monitor.py:363][0m linear2/Wp_0: 0.8705
[32m[0418 06:20:46 @monitor.py:363][0m linear3/W_0_percent_n: 0.04129
[32m[0418 06:20:46 @monitor.py:363][0m linear3/W_0_percent_p: 0.036209
[32m[0418 06:20:46 @monitor.py:363][0m linear3/W_0_sparsity: 0.9225
[32m[0418 06:20:46 @monitor.py:363][0m linear3/Wn_0: 0.86015
[32m[0418 06:20:46 @monitor.py:363][0m linear3/Wp_0: 0.83141
[32m[0418 06:20:46 @monitor.py:363][0m lr: 1.5625e-05
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.2675
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1028
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/linear0/W-rms: 1.9462
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/linear1/W-rms: 2.2329
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/linear2/W-rms: 1.4755
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/linear3/W-rms: 1.4938
[32m[0418 06:20:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 06:20:46 @monitor.py:363][0m train-error-top1: 0.78428
[32m[0418 06:20:46 @monitor.py:363][0m val-error-top1: 0.8587
[32m[0418 06:20:46 @monitor.py:363][0m val-utt-error: 0.758
[32m[0418 06:20:46 @monitor.py:363][0m validation_cost: 3.9058
[32m[0418 06:20:46 @monitor.py:363][0m wd_cost: 0.012294
[32m[0418 06:20:46 @group.py:42][0m Callbacks took 200.517 sec in total. InferenceRunner: 200.344sec
[32m[0418 06:20:46 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10875/173481[03:00<44:51,60.41it/s]  7%|6         |11481/173481[03:10<44:41,60.41it/s] 12%|#2        |21184/173481[06:00<43:10,58.80it/s] 13%|#2        |21755/173481[06:10<43:00,58.80it/s] 18%|#7        |31198/173481[09:00<41:29,57.16it/s] 18%|#8        |31782/173481[09:10<41:18,57.16it/s] 24%|##3       |40924/173481[12:00<39:46,55.55it/s] 24%|##3       |41485/173481[12:10<39:36,55.55it/s] 29%|##9       |50587/173481[15:00<37:30,54.60it/s] 30%|##9       |51179/173481[15:10<37:19,54.60it/s] 35%|###4      |60310/173481[18:00<34:44,54.30it/s] 35%|###5      |60891/173481[18:10<34:33,54.30it/s] 40%|####      |69906/173481[21:00<32:07,53.74it/s] 40%|####      |69930/173481[21:11<32:06,53.74it/s] 46%|####5     |78971/173481[24:00<30:17,51.99it/s] 46%|####5     |79587/173481[24:11<30:05,51.99it/s] 53%|#####3    |92470/173481[27:00<21:59,61.40it/s] 54%|#####3    |93343/173481[27:11<21:45,61.40it/s] 61%|######1   |106538/173481[30:00<16:13,68.77it/s] 62%|######1   |107187/173481[30:11<16:03,68.77it/s] 68%|######8   |118064/173481[33:00<13:55,66.32it/s] 68%|######8   |118689/173481[33:11<13:46,66.32it/s] 74%|#######4  |128507/173481[36:00<12:06,61.89it/s] 74%|#######4  |129135/173481[36:11<11:56,61.89it/s] 80%|########  |138976/173481[39:00<09:35,59.96it/s] 80%|########  |139631/173481[39:11<09:24,59.96it/s] 86%|########6 |149410/173481[42:00<06:48,58.94it/s] 87%|########6 |150078/173481[42:12<06:37,58.94it/s] 92%|#########2|159934/173481[45:00<03:50,58.70it/s] 93%|#########2|160605/173481[45:12<03:39,58.70it/s] 98%|#########8|170260/173481[48:00<00:55,58.02it/s] 99%|#########8|170920/173481[48:12<00:44,58.02it/s]100%|##########|173481/173481[48:57<00:00,59.07it/s]
[32m[0418 07:09:43 @base.py:257][0m Epoch 18 (global_step 3122658) finished, time:2937.04 sec.
[32m[0418 07:09:43 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-3122658.
  0%|          |0/18822[00:00<?,?it/s] 94%|#########4|17729/18822[03:00<00:11,98.49it/s]100%|##########|18822/18822[03:09<00:00,99.10it/s]
17
[32m[0418 07:12:53 @monitor.py:363][0m QueueInput/queue_size: 0.73065
[32m[0418 07:12:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6975
[32m[0418 07:12:53 @monitor.py:363][0m activation-summaries/output-rms: 0.022032
[32m[0418 07:12:53 @monitor.py:363][0m cross_entropy_loss: 3.259
[32m[0418 07:12:53 @monitor.py:363][0m last_linear/W_0_percent_n: 0.28831
[32m[0418 07:12:53 @monitor.py:363][0m last_linear/W_0_percent_p: 0.15841
[32m[0418 07:12:53 @monitor.py:363][0m last_linear/W_0_sparsity: 0.55328
[32m[0418 07:12:53 @monitor.py:363][0m last_linear/Wn_0: 0.18554
[32m[0418 07:12:53 @monitor.py:363][0m last_linear/Wp_0: 0.16021
[32m[0418 07:12:53 @monitor.py:363][0m linear0/W_0_percent_n: 0.09407
[32m[0418 07:12:53 @monitor.py:363][0m linear0/W_0_percent_p: 0.10943
[32m[0418 07:12:53 @monitor.py:363][0m linear0/W_0_sparsity: 0.79649
[32m[0418 07:12:53 @monitor.py:363][0m linear0/Wn_0: 0.98138
[32m[0418 07:12:53 @monitor.py:363][0m linear0/Wp_0: 1.0416
[32m[0418 07:12:53 @monitor.py:363][0m linear1/W_0_percent_n: 0.15254
[32m[0418 07:12:53 @monitor.py:363][0m linear1/W_0_percent_p: 0.12181
[32m[0418 07:12:53 @monitor.py:363][0m linear1/W_0_sparsity: 0.72563
[32m[0418 07:12:53 @monitor.py:363][0m linear1/Wn_0: 0.92063
[32m[0418 07:12:53 @monitor.py:363][0m linear1/Wp_0: 0.96172
[32m[0418 07:12:53 @monitor.py:363][0m linear2/W_0_percent_n: 0.03418
[32m[0418 07:12:53 @monitor.py:363][0m linear2/W_0_percent_p: 0.042862
[32m[0418 07:12:53 @monitor.py:363][0m linear2/W_0_sparsity: 0.92296
[32m[0418 07:12:53 @monitor.py:363][0m linear2/Wn_0: 1.0887
[32m[0418 07:12:53 @monitor.py:363][0m linear2/Wp_0: 0.87225
[32m[0418 07:12:53 @monitor.py:363][0m linear3/W_0_percent_n: 0.041077
[32m[0418 07:12:53 @monitor.py:363][0m linear3/W_0_percent_p: 0.036819
[32m[0418 07:12:53 @monitor.py:363][0m linear3/W_0_sparsity: 0.9221
[32m[0418 07:12:53 @monitor.py:363][0m linear3/Wn_0: 0.86685
[32m[0418 07:12:53 @monitor.py:363][0m linear3/Wp_0: 0.83458
[32m[0418 07:12:53 @monitor.py:363][0m lr: 1.5625e-05
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.316
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1012
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/linear0/W-rms: 2.0051
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/linear1/W-rms: 2.2743
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/linear2/W-rms: 1.4973
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5163
[32m[0418 07:12:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 07:12:53 @monitor.py:363][0m train-error-top1: 0.76605
[32m[0418 07:12:53 @monitor.py:363][0m val-error-top1: 0.84714
[32m[0418 07:12:53 @monitor.py:363][0m val-utt-error: 0.6927
[32m[0418 07:12:53 @monitor.py:363][0m validation_cost: 3.8818
[32m[0418 07:12:53 @monitor.py:363][0m wd_cost: 0.012902
[32m[0418 07:12:53 @group.py:42][0m Callbacks took 190.137 sec in total. InferenceRunner: 189.936sec
[32m[0418 07:12:53 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10133/173481[03:00<48:21,56.29it/s]  6%|6         |10734/173481[03:10<48:11,56.29it/s] 12%|#2        |21085/173481[06:00<43:26,58.48it/s] 12%|#2        |21684/173481[06:10<43:15,58.48it/s] 18%|#8        |31663/173481[09:00<40:19,58.61it/s] 19%|#8        |32256/173481[09:10<40:09,58.61it/s] 24%|##4       |41869/173481[12:00<38:03,57.63it/s] 24%|##4       |42458/173481[12:10<37:53,57.63it/s] 30%|##9       |52003/173481[15:00<35:33,56.95it/s] 30%|###       |52593/173481[15:10<35:22,56.95it/s] 36%|###5      |62396/173481[18:00<32:17,57.34it/s] 36%|###6      |63048/173481[18:10<32:05,57.34it/s] 42%|####2     |73261/173481[21:00<28:24,58.81it/s] 43%|####2     |73920/173481[21:11<28:12,58.81it/s] 47%|####6     |81491/173481[24:00<29:48,51.45it/s] 47%|####7     |81654/173481[24:11<29:44,51.45it/s] 51%|#####     |87888/173481[27:00<33:56,42.04it/s] 51%|#####     |88416/173481[27:11<33:43,42.04it/s] 58%|#####8    |101149/173481[30:00<22:31,53.53it/s] 59%|#####8    |102162/173481[30:11<22:12,53.53it/s] 66%|######5   |114255/173481[33:00<15:59,61.70it/s] 66%|######6   |114763/173481[33:11<15:51,61.70it/s] 71%|#######   |122627/173481[36:00<15:58,53.04it/s] 71%|#######   |123156/173481[36:11<15:48,53.04it/s] 75%|#######5  |130801/173481[39:00<14:32,48.92it/s] 76%|#######5  |131412/173481[39:11<14:19,48.92it/s] 81%|########1 |141104/173481[42:00<10:13,52.75it/s] 82%|########1 |141856/173481[42:12<09:59,52.75it/s] 88%|########8 |152797/173481[45:00<05:55,58.22it/s] 88%|########8 |153394/173481[45:12<05:45,58.22it/s] 94%|#########3|162576/173481[48:00<03:14,56.20it/s] 94%|#########4|163247/173481[48:12<03:02,56.20it/s]100%|#########9|172727/173481[51:00<00:13,56.29it/s]100%|#########9|173394/173481[51:12<00:01,56.29it/s]100%|##########|173481/173481[51:13<00:00,56.44it/s]
[32m[0418 08:04:07 @base.py:257][0m Epoch 19 (global_step 3296139) finished, time:3073.85 sec.
[32m[0418 08:04:07 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-3296139.
  0%|          |0/18822[00:00<?,?it/s] 94%|#########3|17606/18822[03:00<00:12,97.80it/s] 99%|#########9|18718/18822[03:10<00:01,97.80it/s]100%|##########|18822/18822[03:11<00:00,98.38it/s]
18
[32m[0418 08:07:19 @monitor.py:363][0m QueueInput/queue_size: 1.2736
[32m[0418 08:07:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.7047
[32m[0418 08:07:19 @monitor.py:363][0m activation-summaries/output-rms: 0.021759
[32m[0418 08:07:19 @monitor.py:363][0m cross_entropy_loss: 3.2555
[32m[0418 08:07:19 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29023
[32m[0418 08:07:19 @monitor.py:363][0m last_linear/W_0_percent_p: 0.15996
[32m[0418 08:07:19 @monitor.py:363][0m last_linear/W_0_sparsity: 0.5498
[32m[0418 08:07:19 @monitor.py:363][0m last_linear/Wn_0: 0.19177
[32m[0418 08:07:19 @monitor.py:363][0m last_linear/Wp_0: 0.16599
[32m[0418 08:07:19 @monitor.py:363][0m linear0/W_0_percent_n: 0.092094
[32m[0418 08:07:19 @monitor.py:363][0m linear0/W_0_percent_p: 0.10725
[32m[0418 08:07:19 @monitor.py:363][0m linear0/W_0_sparsity: 0.80065
[32m[0418 08:07:19 @monitor.py:363][0m linear0/Wn_0: 0.983
[32m[0418 08:07:19 @monitor.py:363][0m linear0/Wp_0: 1.0431
[32m[0418 08:07:19 @monitor.py:363][0m linear1/W_0_percent_n: 0.15363
[32m[0418 08:07:19 @monitor.py:363][0m linear1/W_0_percent_p: 0.12273
[32m[0418 08:07:19 @monitor.py:363][0m linear1/W_0_sparsity: 0.72365
[32m[0418 08:07:19 @monitor.py:363][0m linear1/Wn_0: 0.92386
[32m[0418 08:07:19 @monitor.py:363][0m linear1/Wp_0: 0.96379
[32m[0418 08:07:19 @monitor.py:363][0m linear2/W_0_percent_n: 0.033691
[32m[0418 08:07:19 @monitor.py:363][0m linear2/W_0_percent_p: 0.042099
[32m[0418 08:07:19 @monitor.py:363][0m linear2/W_0_sparsity: 0.92421
[32m[0418 08:07:19 @monitor.py:363][0m linear2/Wn_0: 1.0978
[32m[0418 08:07:19 @monitor.py:363][0m linear2/Wp_0: 0.8691
[32m[0418 08:07:19 @monitor.py:363][0m linear3/W_0_percent_n: 0.041397
[32m[0418 08:07:19 @monitor.py:363][0m linear3/W_0_percent_p: 0.036499
[32m[0418 08:07:19 @monitor.py:363][0m linear3/W_0_sparsity: 0.92209
[32m[0418 08:07:19 @monitor.py:363][0m linear3/Wn_0: 0.87258
[32m[0418 08:07:19 @monitor.py:363][0m linear3/Wp_0: 0.83872
[32m[0418 08:07:19 @monitor.py:363][0m lr: 1.5625e-05
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.3662
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0997
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/linear0/W-rms: 2.064
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/linear1/W-rms: 2.3158
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5195
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5392
[32m[0418 08:07:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 08:07:19 @monitor.py:363][0m train-error-top1: 0.76456
[32m[0418 08:07:19 @monitor.py:363][0m val-error-top1: 0.85036
[32m[0418 08:07:19 @monitor.py:363][0m val-utt-error: 0.70816
[32m[0418 08:07:19 @monitor.py:363][0m validation_cost: 3.8742
[32m[0418 08:07:19 @monitor.py:363][0m wd_cost: 0.01353
[32m[0418 08:07:19 @group.py:42][0m Callbacks took 191.511 sec in total. InferenceRunner: 191.341sec
[32m[0418 08:07:19 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11134/173481[03:00<43:45,61.82it/s]  7%|6         |11673/173481[03:10<43:37,61.82it/s] 12%|#2        |20950/173481[06:00<43:52,57.94it/s] 12%|#2        |21453/173481[06:10<43:43,57.94it/s] 17%|#7        |30306/173481[09:00<43:32,54.80it/s] 18%|#7        |30835/173481[09:10<43:23,54.80it/s] 24%|##3       |41146/173481[12:00<38:26,57.38it/s] 24%|##4       |41917/173481[12:10<38:12,57.38it/s] 31%|###1      |54482/173481[15:00<30:40,64.67it/s] 32%|###1      |55185/173481[15:10<30:29,64.67it/s] 40%|###9      |69172/173481[18:00<24:05,72.16it/s] 40%|####      |70143/173481[18:10<23:52,72.16it/s] 48%|####7     |82522/173481[21:00<20:43,73.15it/s] 48%|####8     |83309/173481[21:11<20:32,73.15it/s] 55%|#####5    |95752/173481[24:00<17:40,73.32it/s] 56%|#####5    |96585/173481[24:11<17:28,73.32it/s] 63%|######2   |109175/173481[27:00<14:29,73.94it/s] 63%|######3   |110058/173481[27:11<14:17,73.94it/s] 71%|#######   |122474/173481[30:00<11:30,73.91it/s] 71%|#######1  |123312/173481[30:11<11:18,73.91it/s] 78%|#######8  |136157/173481[33:00<08:17,74.95it/s] 79%|#######9  |137050/173481[33:11<08:06,74.95it/s] 87%|########6 |150219/173481[36:00<05:04,76.50it/s] 87%|########7 |151116/173481[36:11<04:52,76.50it/s] 95%|#########4|164086/173481[39:00<02:02,76.76it/s] 95%|#########5|164948/173481[39:11<01:51,76.76it/s]100%|##########|173481/173481[41:20<00:00,69.94it/s]
[32m[0418 08:48:39 @base.py:257][0m Epoch 20 (global_step 3469620) finished, time:2480.35 sec.
[32m[0418 08:48:39 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-3469620.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########9|18659/18822[03:00<00:01,103.65it/s]100%|##########|18822/18822[03:01<00:00,103.74it/s]
19
[32m[0418 08:51:41 @monitor.py:363][0m QueueInput/queue_size: 0.53134
[32m[0418 08:51:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.7629
[32m[0418 08:51:41 @monitor.py:363][0m activation-summaries/output-rms: 0.021721
[32m[0418 08:51:41 @monitor.py:363][0m cross_entropy_loss: 3.2766
[32m[0418 08:51:41 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29427
[32m[0418 08:51:41 @monitor.py:363][0m last_linear/W_0_percent_p: 0.1631
[32m[0418 08:51:41 @monitor.py:363][0m last_linear/W_0_sparsity: 0.5426
[32m[0418 08:51:41 @monitor.py:363][0m last_linear/Wn_0: 0.19723
[32m[0418 08:51:41 @monitor.py:363][0m last_linear/Wp_0: 0.16967
[32m[0418 08:51:41 @monitor.py:363][0m linear0/W_0_percent_n: 0.09348
[32m[0418 08:51:41 @monitor.py:363][0m linear0/W_0_percent_p: 0.10844
[32m[0418 08:51:41 @monitor.py:363][0m linear0/W_0_sparsity: 0.79804
[32m[0418 08:51:41 @monitor.py:363][0m linear0/Wn_0: 0.98571
[32m[0418 08:51:41 @monitor.py:363][0m linear0/Wp_0: 1.0434
[32m[0418 08:51:41 @monitor.py:363][0m linear1/W_0_percent_n: 0.15025
[32m[0418 08:51:41 @monitor.py:363][0m linear1/W_0_percent_p: 0.11996
[32m[0418 08:51:41 @monitor.py:363][0m linear1/W_0_sparsity: 0.72975
[32m[0418 08:51:41 @monitor.py:363][0m linear1/Wn_0: 0.92561
[32m[0418 08:51:41 @monitor.py:363][0m linear1/Wp_0: 0.96735
[32m[0418 08:51:41 @monitor.py:363][0m linear2/W_0_percent_n: 0.033447
[32m[0418 08:51:41 @monitor.py:363][0m linear2/W_0_percent_p: 0.042419
[32m[0418 08:51:41 @monitor.py:363][0m linear2/W_0_sparsity: 0.92412
[32m[0418 08:51:41 @monitor.py:363][0m linear2/Wn_0: 1.097
[32m[0418 08:51:41 @monitor.py:363][0m linear2/Wp_0: 0.87543
[32m[0418 08:51:41 @monitor.py:363][0m linear3/W_0_percent_n: 0.040985
[32m[0418 08:51:41 @monitor.py:363][0m linear3/W_0_percent_p: 0.03627
[32m[0418 08:51:41 @monitor.py:363][0m linear3/W_0_sparsity: 0.92274
[32m[0418 08:51:41 @monitor.py:363][0m linear3/Wn_0: 0.87936
[32m[0418 08:51:41 @monitor.py:363][0m linear3/Wp_0: 0.84161
[32m[0418 08:51:41 @monitor.py:363][0m lr: 7.8125e-06
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.3921
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0995
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/linear0/W-rms: 2.0948
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/linear1/W-rms: 2.3374
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/linear2/W-rms: 1.531
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5512
[32m[0418 08:51:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 08:51:41 @monitor.py:363][0m train-error-top1: 0.77008
[32m[0418 08:51:41 @monitor.py:363][0m val-error-top1: 0.85238
[32m[0418 08:51:41 @monitor.py:363][0m val-utt-error: 0.71438
[32m[0418 08:51:41 @monitor.py:363][0m validation_cost: 3.8844
[32m[0418 08:51:41 @monitor.py:363][0m wd_cost: 0.0027729
[32m[0418 08:51:41 @group.py:42][0m Callbacks took 181.685 sec in total. InferenceRunner: 181.463sec
[32m[0418 08:51:41 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14689/173481[03:00<32:26,81.58it/s]  9%|8         |15425/173481[03:10<32:17,81.58it/s] 16%|#6        |27949/173481[06:00<31:20,77.41it/s] 17%|#6        |28692/173481[06:10<31:10,77.41it/s] 24%|##3       |40897/173481[09:00<29:37,74.57it/s] 24%|##4       |41696/173481[09:10<29:27,74.57it/s] 32%|###1      |55383/173481[12:00<25:25,77.41it/s] 32%|###2      |56230/173481[12:10<25:14,77.41it/s] 40%|####      |69782/173481[15:00<21:57,78.68it/s] 41%|####      |70677/173481[15:10<21:46,78.68it/s] 49%|####8     |84743/173481[18:00<18:17,80.84it/s] 49%|####9     |85617/173481[18:10<18:06,80.84it/s] 56%|#####6    |97667/173481[21:00<16:36,76.05it/s] 57%|#####6    |98464/173481[21:11<16:26,76.05it/s] 64%|######3   |110950/173481[24:00<13:54,74.90it/s] 64%|######4   |111786/173481[24:11<13:43,74.90it/s] 72%|#######1  |124519/173481[27:00<10:51,75.13it/s] 72%|#######2  |125328/173481[27:11<10:40,75.13it/s] 79%|#######8  |136384/173481[30:00<08:48,70.22it/s] 79%|#######9  |137088/173481[30:11<08:38,70.22it/s] 86%|########6 |149443/173481[33:00<05:36,71.36it/s] 86%|########6 |150048/173481[33:11<05:28,71.36it/s] 93%|#########3|161586/173481[36:00<02:51,69.35it/s] 94%|#########3|162495/173481[36:11<02:38,69.35it/s]100%|##########|173481/173481[38:29<00:00,75.12it/s]
[32m[0418 09:30:10 @base.py:257][0m Epoch 21 (global_step 3643101) finished, time:2309.47 sec.
[32m[0418 09:30:10 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-3643101.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:28<00:00,126.43it/s]
20
[32m[0418 09:32:39 @monitor.py:363][0m QueueInput/queue_size: 0.71049
[32m[0418 09:32:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.5787
[32m[0418 09:32:39 @monitor.py:363][0m activation-summaries/output-rms: 0.022173
[32m[0418 09:32:39 @monitor.py:363][0m cross_entropy_loss: 3.2253
[32m[0418 09:32:39 @monitor.py:363][0m last_linear/W_0_percent_n: 0.28912
[32m[0418 09:32:39 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16016
[32m[0418 09:32:39 @monitor.py:363][0m last_linear/W_0_sparsity: 0.55069
[32m[0418 09:32:39 @monitor.py:363][0m last_linear/Wn_0: 0.2004
[32m[0418 09:32:39 @monitor.py:363][0m last_linear/Wp_0: 0.17497
[32m[0418 09:32:39 @monitor.py:363][0m linear0/W_0_percent_n: 0.09416
[32m[0418 09:32:39 @monitor.py:363][0m linear0/W_0_percent_p: 0.10923
[32m[0418 09:32:39 @monitor.py:363][0m linear0/W_0_sparsity: 0.7966
[32m[0418 09:32:39 @monitor.py:363][0m linear0/Wn_0: 0.98593
[32m[0418 09:32:39 @monitor.py:363][0m linear0/Wp_0: 1.0461
[32m[0418 09:32:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.15453
[32m[0418 09:32:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.12314
[32m[0418 09:32:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.72223
[32m[0418 09:32:39 @monitor.py:363][0m linear1/Wn_0: 0.92945
[32m[0418 09:32:39 @monitor.py:363][0m linear1/Wp_0: 0.96864
[32m[0418 09:32:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.033707
[32m[0418 09:32:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.041534
[32m[0418 09:32:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.92476
[32m[0418 09:32:39 @monitor.py:363][0m linear2/Wn_0: 1.0986
[32m[0418 09:32:39 @monitor.py:363][0m linear2/Wp_0: 0.87933
[32m[0418 09:32:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.041046
[32m[0418 09:32:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.035934
[32m[0418 09:32:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.92299
[32m[0418 09:32:39 @monitor.py:363][0m linear3/Wn_0: 0.88233
[32m[0418 09:32:39 @monitor.py:363][0m linear3/Wp_0: 0.84849
[32m[0418 09:32:39 @monitor.py:363][0m lr: 7.8125e-06
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4174
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0984
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/linear0/W-rms: 2.1246
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/linear1/W-rms: 2.3582
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5421
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5627
[32m[0418 09:32:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 09:32:39 @monitor.py:363][0m train-error-top1: 0.77715
[32m[0418 09:32:39 @monitor.py:363][0m val-error-top1: 0.83611
[32m[0418 09:32:39 @monitor.py:363][0m val-utt-error: 0.66173
[32m[0418 09:32:39 @monitor.py:363][0m validation_cost: 3.7569
[32m[0418 09:32:39 @monitor.py:363][0m wd_cost: 0.0028382
[32m[0418 09:32:39 @group.py:42][0m Callbacks took 149.122 sec in total. InferenceRunner: 148.884sec
[32m[0418 09:32:39 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21017/173481[03:00<21:45,116.76it/s] 13%|#2        |22167/173481[03:10<21:35,116.76it/s] 21%|##        |36028/173481[06:00<23:32,97.29it/s]  21%|##        |36417/173481[06:10<23:28,97.29it/s] 28%|##8       |48671/173481[09:00<25:29,81.58it/s] 29%|##8       |49515/173481[09:10<25:19,81.58it/s] 36%|###6      |62986/173481[12:00<22:52,80.54it/s] 37%|###6      |63850/173481[12:10<22:41,80.54it/s] 44%|####4     |76996/173481[15:00<20:18,79.16it/s] 45%|####4     |77818/173481[15:10<20:08,79.16it/s] 53%|#####3    |92692/173481[18:00<16:13,82.98it/s] 54%|#####4    |93740/173481[18:10<16:00,82.98it/s] 63%|######2   |109168/173481[21:00<12:18,87.03it/s] 63%|######3   |109991/173481[21:11<12:09,87.03it/s] 71%|#######   |122743/173481[24:00<10:27,80.81it/s] 71%|#######1  |123586/173481[24:11<10:17,80.81it/s] 78%|#######8  |135484/173481[27:00<08:23,75.45it/s] 79%|#######8  |136299/173481[27:11<08:12,75.45it/s] 86%|########5 |148524/173481[30:00<05:37,73.92it/s] 86%|########6 |149271/173481[30:11<05:27,73.92it/s] 92%|#########2|160165/173481[33:00<03:13,68.99it/s] 93%|#########2|160908/173481[33:11<03:02,68.99it/s] 99%|#########8|171250/173481[36:00<00:34,65.06it/s] 99%|#########9|172131/173481[36:11<00:20,65.06it/s]100%|##########|173481/173481[36:29<00:00,79.25it/s]
[32m[0418 10:09:08 @base.py:257][0m Epoch 22 (global_step 3816582) finished, time:2189.01 sec.
[32m[0418 10:09:09 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-3816582.
  0%|          |0/18822[00:00<?,?it/s] 96%|#########5|18029/18822[03:00<00:07,100.16it/s]100%|##########|18822/18822[03:06<00:00,100.71it/s]
21
[32m[0418 10:12:16 @monitor.py:363][0m QueueInput/queue_size: 0.98108
[32m[0418 10:12:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6982
[32m[0418 10:12:16 @monitor.py:363][0m activation-summaries/output-rms: 0.020784
[32m[0418 10:12:16 @monitor.py:363][0m cross_entropy_loss: 3.3143
[32m[0418 10:12:16 @monitor.py:363][0m last_linear/W_0_percent_n: 0.28888
[32m[0418 10:12:16 @monitor.py:363][0m last_linear/W_0_percent_p: 0.15896
[32m[0418 10:12:16 @monitor.py:363][0m last_linear/W_0_sparsity: 0.55207
[32m[0418 10:12:16 @monitor.py:363][0m last_linear/Wn_0: 0.20673
[32m[0418 10:12:16 @monitor.py:363][0m last_linear/Wp_0: 0.17962
[32m[0418 10:12:16 @monitor.py:363][0m linear0/W_0_percent_n: 0.092441
[32m[0418 10:12:16 @monitor.py:363][0m linear0/W_0_percent_p: 0.1083
[32m[0418 10:12:16 @monitor.py:363][0m linear0/W_0_sparsity: 0.7992
[32m[0418 10:12:16 @monitor.py:363][0m linear0/Wn_0: 0.98702
[32m[0418 10:12:16 @monitor.py:363][0m linear0/Wp_0: 1.0481
[32m[0418 10:12:16 @monitor.py:363][0m linear1/W_0_percent_n: 0.15579
[32m[0418 10:12:16 @monitor.py:363][0m linear1/W_0_percent_p: 0.12413
[32m[0418 10:12:16 @monitor.py:363][0m linear1/W_0_sparsity: 0.71999
[32m[0418 10:12:16 @monitor.py:363][0m linear1/Wn_0: 0.93113
[32m[0418 10:12:16 @monitor.py:363][0m linear1/Wp_0: 0.97207
[32m[0418 10:12:16 @monitor.py:363][0m linear2/W_0_percent_n: 0.033325
[32m[0418 10:12:16 @monitor.py:363][0m linear2/W_0_percent_p: 0.042145
[32m[0418 10:12:16 @monitor.py:363][0m linear2/W_0_sparsity: 0.92447
[32m[0418 10:12:16 @monitor.py:363][0m linear2/Wn_0: 1.1038
[32m[0418 10:12:16 @monitor.py:363][0m linear2/Wp_0: 0.87972
[32m[0418 10:12:16 @monitor.py:363][0m linear3/W_0_percent_n: 0.040985
[32m[0418 10:12:16 @monitor.py:363][0m linear3/W_0_percent_p: 0.036133
[32m[0418 10:12:16 @monitor.py:363][0m linear3/W_0_sparsity: 0.92288
[32m[0418 10:12:16 @monitor.py:363][0m linear3/Wn_0: 0.88837
[32m[0418 10:12:16 @monitor.py:363][0m linear3/Wp_0: 0.85217
[32m[0418 10:12:16 @monitor.py:363][0m lr: 3.9063e-06
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4399
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0975
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/linear0/W-rms: 2.1508
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/linear1/W-rms: 2.3764
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5517
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5729
[32m[0418 10:12:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 10:12:16 @monitor.py:363][0m train-error-top1: 0.78214
[32m[0418 10:12:16 @monitor.py:363][0m val-error-top1: 0.85578
[32m[0418 10:12:16 @monitor.py:363][0m val-utt-error: 0.7436
[32m[0418 10:12:16 @monitor.py:363][0m validation_cost: 3.9287
[32m[0418 10:12:16 @monitor.py:363][0m wd_cost: 0.0028966
[32m[0418 10:12:16 @group.py:42][0m Callbacks took 187.207 sec in total. InferenceRunner: 186.907sec
[32m[0418 10:12:16 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13313/173481[03:00<36:05,73.96it/s]  8%|8         |14118/173481[03:10<35:54,73.96it/s] 16%|#5        |27271/173481[06:00<32:11,75.70it/s] 16%|#6        |28084/173481[06:10<32:00,75.70it/s] 23%|##3       |39913/173481[09:00<30:33,72.86it/s] 23%|##3       |40074/173481[09:10<30:31,72.86it/s] 27%|##6       |46561/173481[12:00<43:09,49.01it/s] 27%|##7       |47303/173481[12:10<42:54,49.01it/s] 34%|###3      |58555/173481[15:00<33:55,56.47it/s] 34%|###4      |59266/173481[15:10<33:42,56.47it/s] 41%|####1     |71906/173481[18:00<26:24,64.12it/s] 42%|####1     |72723/173481[18:10<26:11,64.12it/s] 49%|####8     |84967/173481[21:00<21:40,68.08it/s] 49%|####9     |85759/173481[21:11<21:28,68.08it/s] 58%|#####8    |100781/173481[24:00<15:47,76.71it/s] 59%|#####8    |101588/173481[24:11<15:37,76.71it/s] 67%|######7   |116444/173481[27:00<11:39,81.54it/s] 68%|######7   |117644/173481[27:11<11:24,81.54it/s] 77%|#######7  |134306/173481[30:00<07:17,89.52it/s] 78%|#######8  |135397/173481[30:11<07:05,89.52it/s] 87%|########6 |150625/173481[33:00<04:13,90.08it/s] 87%|########7 |151475/173481[33:11<04:04,90.08it/s] 95%|#########4|164234/173481[36:00<01:52,82.21it/s] 95%|#########5|164997/173481[36:11<01:43,82.21it/s]100%|##########|173481/173481[38:17<00:00,75.49it/s]
[32m[0418 10:50:34 @base.py:257][0m Epoch 23 (global_step 3990063) finished, time:2297.95 sec.
[32m[0418 10:50:34 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-3990063.
  0%|          |0/18822[00:00<?,?it/s] 97%|#########6|18219/18822[03:00<00:05,101.21it/s]100%|##########|18822/18822[03:05<00:00,101.51it/s]
22
[32m[0418 10:53:39 @monitor.py:363][0m QueueInput/queue_size: 0.63323
[32m[0418 10:53:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6473
[32m[0418 10:53:39 @monitor.py:363][0m activation-summaries/output-rms: 0.020706
[32m[0418 10:53:39 @monitor.py:363][0m cross_entropy_loss: 3.2765
[32m[0418 10:53:39 @monitor.py:363][0m last_linear/W_0_percent_n: 0.28755
[32m[0418 10:53:39 @monitor.py:363][0m last_linear/W_0_percent_p: 0.15611
[32m[0418 10:53:39 @monitor.py:363][0m last_linear/W_0_sparsity: 0.55633
[32m[0418 10:53:39 @monitor.py:363][0m last_linear/Wn_0: 0.20935
[32m[0418 10:53:39 @monitor.py:363][0m last_linear/Wp_0: 0.18173
[32m[0418 10:53:39 @monitor.py:363][0m linear0/W_0_percent_n: 0.096918
[32m[0418 10:53:39 @monitor.py:363][0m linear0/W_0_percent_p: 0.11239
[32m[0418 10:53:39 @monitor.py:363][0m linear0/W_0_sparsity: 0.79062
[32m[0418 10:53:39 @monitor.py:363][0m linear0/Wn_0: 0.98971
[32m[0418 10:53:39 @monitor.py:363][0m linear0/Wp_0: 1.0483
[32m[0418 10:53:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.15614
[32m[0418 10:53:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.12607
[32m[0418 10:53:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.71774
[32m[0418 10:53:39 @monitor.py:363][0m linear1/Wn_0: 0.93375
[32m[0418 10:53:39 @monitor.py:363][0m linear1/Wp_0: 0.97451
[32m[0418 10:53:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.033295
[32m[0418 10:53:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.042358
[32m[0418 10:53:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.92435
[32m[0418 10:53:39 @monitor.py:363][0m linear2/Wn_0: 1.1058
[32m[0418 10:53:39 @monitor.py:363][0m linear2/Wp_0: 0.88316
[32m[0418 10:53:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.040024
[32m[0418 10:53:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.035736
[32m[0418 10:53:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.92424
[32m[0418 10:53:39 @monitor.py:363][0m linear3/Wn_0: 0.89484
[32m[0418 10:53:39 @monitor.py:363][0m linear3/Wp_0: 0.85535
[32m[0418 10:53:39 @monitor.py:363][0m lr: 3.9063e-06
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4526
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.097
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/linear0/W-rms: 2.1657
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/linear1/W-rms: 2.3866
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5572
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5786
[32m[0418 10:53:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 10:53:39 @monitor.py:363][0m train-error-top1: 0.77467
[32m[0418 10:53:39 @monitor.py:363][0m val-error-top1: 0.84669
[32m[0418 10:53:39 @monitor.py:363][0m val-utt-error: 0.70566
[32m[0418 10:53:39 @monitor.py:363][0m validation_cost: 3.8329
[32m[0418 10:53:39 @monitor.py:363][0m wd_cost: 0.00058595
[32m[0418 10:53:39 @group.py:42][0m Callbacks took 185.742 sec in total. InferenceRunner: 185.441sec
[32m[0418 10:53:39 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11830/173481[03:00<41:00,65.71it/s]  7%|7         |12405/173481[03:10<40:51,65.71it/s] 12%|#2        |21652/173481[06:00<42:26,59.61it/s] 13%|#2        |22217/173481[06:10<42:17,59.61it/s] 18%|#8        |31641/173481[09:00<41:07,57.48it/s] 19%|#8        |32183/173481[09:10<40:58,57.48it/s] 24%|##3       |41448/173481[12:00<39:20,55.94it/s] 24%|##4       |42009/173481[12:10<39:10,55.94it/s] 29%|##8       |50031/173481[15:00<39:57,51.48it/s] 29%|##9       |50603/173481[15:10<39:46,51.48it/s] 34%|###4      |59806/173481[18:00<35:51,52.84it/s] 35%|###4      |60387/173481[18:10<35:40,52.84it/s] 40%|####      |69520/173481[21:00<32:27,53.39it/s] 40%|####      |70083/173481[21:11<32:16,53.39it/s] 46%|####6     |80243/173481[24:00<27:35,56.31it/s] 47%|####6     |81035/173481[24:11<27:21,56.31it/s] 53%|#####2    |91123/173481[27:00<23:32,58.30it/s] 53%|#####2    |91767/173481[27:11<23:21,58.30it/s] 59%|#####9    |102526/173481[30:00<19:28,60.72it/s] 59%|#####9    |103185/173481[30:11<19:17,60.72it/s] 66%|######5   |113854/173481[33:00<16:04,61.81it/s] 66%|######5   |114495/173481[33:11<15:54,61.81it/s] 72%|#######1  |124186/173481[36:00<13:48,59.52it/s] 72%|#######1  |124859/173481[36:11<13:36,59.52it/s] 78%|#######7  |134585/173481[39:00<11:03,58.63it/s] 78%|#######7  |135268/173481[39:11<10:51,58.63it/s] 84%|########3 |145288/173481[42:00<07:57,59.04it/s] 84%|########4 |146220/173481[42:12<07:41,59.04it/s] 92%|#########2|159626/173481[45:00<03:24,67.81it/s] 93%|#########2|160591/173481[45:12<03:10,67.81it/s] 99%|#########8|171218/173481[48:00<00:34,66.06it/s] 99%|#########9|171909/173481[48:12<00:23,66.06it/s]100%|##########|173481/173481[48:40<00:00,59.41it/s]
[32m[0418 11:42:19 @base.py:257][0m Epoch 24 (global_step 4163544) finished, time:2920.24 sec.
[32m[0418 11:42:20 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-4163544.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:55<00:00,107.00it/s]
23
[32m[0418 11:45:16 @monitor.py:363][0m QueueInput/queue_size: 0.72262
[32m[0418 11:45:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.58
[32m[0418 11:45:16 @monitor.py:363][0m activation-summaries/output-rms: 0.02236
[32m[0418 11:45:16 @monitor.py:363][0m cross_entropy_loss: 3.247
[32m[0418 11:45:16 @monitor.py:363][0m last_linear/W_0_percent_n: 0.28629
[32m[0418 11:45:16 @monitor.py:363][0m last_linear/W_0_percent_p: 0.15585
[32m[0418 11:45:16 @monitor.py:363][0m last_linear/W_0_sparsity: 0.55775
[32m[0418 11:45:16 @monitor.py:363][0m last_linear/Wn_0: 0.21259
[32m[0418 11:45:16 @monitor.py:363][0m last_linear/Wp_0: 0.18536
[32m[0418 11:45:16 @monitor.py:363][0m linear0/W_0_percent_n: 0.094578
[32m[0418 11:45:16 @monitor.py:363][0m linear0/W_0_percent_p: 0.10989
[32m[0418 11:45:16 @monitor.py:363][0m linear0/W_0_sparsity: 0.7955
[32m[0418 11:45:16 @monitor.py:363][0m linear0/Wn_0: 0.99253
[32m[0418 11:45:16 @monitor.py:363][0m linear0/Wp_0: 1.0485
[32m[0418 11:45:16 @monitor.py:363][0m linear1/W_0_percent_n: 0.15163
[32m[0418 11:45:16 @monitor.py:363][0m linear1/W_0_percent_p: 0.12212
[32m[0418 11:45:16 @monitor.py:363][0m linear1/W_0_sparsity: 0.72623
[32m[0418 11:45:16 @monitor.py:363][0m linear1/Wn_0: 0.93691
[32m[0418 11:45:16 @monitor.py:363][0m linear1/Wp_0: 0.97646
[32m[0418 11:45:16 @monitor.py:363][0m linear2/W_0_percent_n: 0.0336
[32m[0418 11:45:16 @monitor.py:363][0m linear2/W_0_percent_p: 0.042465
[32m[0418 11:45:16 @monitor.py:363][0m linear2/W_0_sparsity: 0.9239
[32m[0418 11:45:16 @monitor.py:363][0m linear2/Wn_0: 1.1103
[32m[0418 11:45:16 @monitor.py:363][0m linear2/Wp_0: 0.88403
[32m[0418 11:45:16 @monitor.py:363][0m linear3/W_0_percent_n: 0.040131
[32m[0418 11:45:16 @monitor.py:363][0m linear3/W_0_percent_p: 0.035828
[32m[0418 11:45:16 @monitor.py:363][0m linear3/W_0_sparsity: 0.924
[32m[0418 11:45:16 @monitor.py:363][0m linear3/Wn_0: 0.89859
[32m[0418 11:45:16 @monitor.py:363][0m linear3/Wp_0: 0.86097
[32m[0418 11:45:16 @monitor.py:363][0m lr: 3.9063e-06
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4654
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0963
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/linear0/W-rms: 2.1806
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/linear1/W-rms: 2.3969
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5625
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5843
[32m[0418 11:45:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 11:45:16 @monitor.py:363][0m train-error-top1: 0.76739
[32m[0418 11:45:16 @monitor.py:363][0m val-error-top1: 0.86129
[32m[0418 11:45:16 @monitor.py:363][0m val-utt-error: 0.74493
[32m[0418 11:45:16 @monitor.py:363][0m validation_cost: 4.0159
[32m[0418 11:45:16 @monitor.py:363][0m wd_cost: 0.00059267
[32m[0418 11:45:16 @group.py:42][0m Callbacks took 176.120 sec in total. InferenceRunner: 175.915sec
[32m[0418 11:45:16 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11084/173481[03:00<43:57,61.57it/s]  7%|6         |11661/173481[03:10<43:48,61.57it/s] 13%|#2        |22062/173481[06:00<41:10,61.28it/s] 13%|#3        |22668/173481[06:10<41:01,61.28it/s] 18%|#8        |31903/173481[09:00<40:50,57.77it/s] 19%|#8        |32453/173481[09:10<40:41,57.77it/s] 24%|##4       |41839/173481[12:00<38:51,56.45it/s] 24%|##4       |42419/173481[12:10<38:41,56.45it/s] 28%|##8       |48799/173481[15:00<45:17,45.88it/s] 28%|##8       |48948/173481[15:10<45:14,45.88it/s] 32%|###2      |56161/173481[18:00<45:12,43.24it/s] 33%|###2      |56756/173481[18:10<44:59,43.24it/s] 38%|###8      |66591/173481[21:00<35:58,49.53it/s] 39%|###8      |67242/173481[21:11<35:45,49.53it/s] 45%|####4     |77504/173481[24:00<29:20,54.52it/s] 45%|####5     |78157/173481[24:11<29:08,54.52it/s] 51%|#####1    |88621/173481[27:00<24:25,57.91it/s] 51%|#####1    |89226/173481[27:11<24:14,57.91it/s] 57%|#####6    |98035/173481[30:00<22:52,54.96it/s] 57%|#####6    |98604/173481[30:11<22:42,54.96it/s] 63%|######2   |108835/173481[33:00<18:46,57.36it/s] 63%|######3   |109524/173481[33:11<18:34,57.36it/s] 68%|######8   |118449/173481[36:00<16:34,55.32it/s] 69%|######8   |119040/173481[36:11<16:24,55.32it/s] 74%|#######3  |127572/173481[39:00<14:27,52.90it/s] 74%|#######3  |128082/173481[39:11<14:18,52.90it/s] 79%|#######9  |137761/173481[42:00<10:53,54.68it/s] 80%|#######9  |138616/173481[42:12<10:37,54.68it/s] 87%|########7 |151075/173481[45:00<05:56,62.88it/s] 88%|########7 |151812/173481[45:12<05:44,62.88it/s] 95%|#########4|164793/173481[48:00<02:06,68.90it/s] 96%|#########5|165765/173481[48:12<01:51,68.90it/s]100%|##########|173481/173481[49:57<00:00,57.88it/s]
[32m[0418 12:35:13 @base.py:257][0m Epoch 25 (global_step 4337025) finished, time:2997.16 sec.
[32m[0418 12:35:13 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-4337025.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:56<00:00,106.72it/s]
24
[32m[0418 12:38:09 @monitor.py:363][0m QueueInput/queue_size: 0.88503
[32m[0418 12:38:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6055
[32m[0418 12:38:09 @monitor.py:363][0m activation-summaries/output-rms: 0.021537
[32m[0418 12:38:09 @monitor.py:363][0m cross_entropy_loss: 3.2422
[32m[0418 12:38:09 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29331
[32m[0418 12:38:09 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16261
[32m[0418 12:38:09 @monitor.py:363][0m last_linear/W_0_sparsity: 0.544
[32m[0418 12:38:09 @monitor.py:363][0m last_linear/Wn_0: 0.21563
[32m[0418 12:38:09 @monitor.py:363][0m last_linear/Wp_0: 0.19
[32m[0418 12:38:09 @monitor.py:363][0m linear0/W_0_percent_n: 0.091625
[32m[0418 12:38:09 @monitor.py:363][0m linear0/W_0_percent_p: 0.10667
[32m[0418 12:38:09 @monitor.py:363][0m linear0/W_0_sparsity: 0.80162
[32m[0418 12:38:09 @monitor.py:363][0m linear0/Wn_0: 0.99311
[32m[0418 12:38:09 @monitor.py:363][0m linear0/Wp_0: 1.0508
[32m[0418 12:38:09 @monitor.py:363][0m linear1/W_0_percent_n: 0.15491
[32m[0418 12:38:09 @monitor.py:363][0m linear1/W_0_percent_p: 0.1243
[32m[0418 12:38:09 @monitor.py:363][0m linear1/W_0_sparsity: 0.7206
[32m[0418 12:38:09 @monitor.py:363][0m linear1/Wn_0: 0.93891
[32m[0418 12:38:09 @monitor.py:363][0m linear1/Wp_0: 0.97937
[32m[0418 12:38:09 @monitor.py:363][0m linear2/W_0_percent_n: 0.034973
[32m[0418 12:38:09 @monitor.py:363][0m linear2/W_0_percent_p: 0.043457
[32m[0418 12:38:09 @monitor.py:363][0m linear2/W_0_sparsity: 0.92152
[32m[0418 12:38:09 @monitor.py:363][0m linear2/Wn_0: 1.1071
[32m[0418 12:38:09 @monitor.py:363][0m linear2/Wp_0: 0.89241
[32m[0418 12:38:09 @monitor.py:363][0m linear3/W_0_percent_n: 0.040878
[32m[0418 12:38:09 @monitor.py:363][0m linear3/W_0_percent_p: 0.03595
[32m[0418 12:38:09 @monitor.py:363][0m linear3/W_0_sparsity: 0.92316
[32m[0418 12:38:09 @monitor.py:363][0m linear3/Wn_0: 0.90378
[32m[0418 12:38:09 @monitor.py:363][0m linear3/Wp_0: 0.86519
[32m[0418 12:38:09 @monitor.py:363][0m lr: 1.9531e-06
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.475
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0961
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/linear0/W-rms: 2.1917
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4046
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5666
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5886
[32m[0418 12:38:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 12:38:09 @monitor.py:363][0m train-error-top1: 0.77026
[32m[0418 12:38:09 @monitor.py:363][0m val-error-top1: 0.84145
[32m[0418 12:38:09 @monitor.py:363][0m val-utt-error: 0.68367
[32m[0418 12:38:09 @monitor.py:363][0m validation_cost: 3.8219
[32m[0418 12:38:09 @monitor.py:363][0m wd_cost: 0.00011954
[32m[0418 12:38:09 @group.py:42][0m Callbacks took 176.578 sec in total. InferenceRunner: 176.394sec
[32m[0418 12:38:09 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11134/173481[03:00<43:46,61.82it/s]  7%|6         |11703/173481[03:10<43:36,61.82it/s] 12%|#2        |21126/173481[06:00<43:24,58.49it/s] 13%|#2        |21723/173481[06:10<43:14,58.49it/s] 18%|#7        |31083/173481[09:00<41:44,56.86it/s] 18%|#8        |31663/173481[09:10<41:34,56.86it/s] 24%|##3       |41218/173481[12:00<38:57,56.57it/s] 24%|##4       |41797/173481[12:10<38:47,56.57it/s] 29%|##9       |50429/173481[15:00<38:10,53.73it/s] 29%|##9       |50823/173481[15:10<38:02,53.73it/s] 35%|###5      |61216/173481[18:00<33:01,56.66it/s] 36%|###5      |61939/173481[18:10<32:48,56.66it/s] 43%|####2     |74370/173481[21:00<25:52,63.83it/s] 43%|####3     |74958/173481[21:11<25:43,63.83it/s] 48%|####8     |84066/173481[24:00<25:30,58.42it/s] 49%|####8     |84676/173481[24:11<25:20,58.42it/s] 54%|#####4    |93932/173481[27:00<23:26,56.56it/s] 54%|#####4    |94539/173481[27:11<23:15,56.56it/s] 60%|#####9    |103833/173481[30:00<20:48,55.77it/s] 60%|######    |104449/173481[30:11<20:37,55.77it/s] 66%|######6   |114970/173481[33:00<16:37,58.66it/s] 67%|######6   |115702/173481[33:11<16:25,58.66it/s] 72%|#######2  |125308/173481[36:00<13:50,58.03it/s] 73%|#######2  |125919/173481[36:11<13:39,58.03it/s] 78%|#######7  |135100/173481[39:00<11:23,56.15it/s] 78%|#######8  |135735/173481[39:11<11:12,56.15it/s] 83%|########3 |144848/173481[42:00<08:39,55.13it/s] 84%|########3 |145497/173481[42:12<08:27,55.13it/s] 89%|########9 |154455/173481[45:00<05:50,54.24it/s] 89%|########9 |155058/173481[45:12<05:39,54.24it/s] 96%|#########6|166714/173481[48:00<01:52,60.39it/s] 97%|#########6|167636/173481[48:12<01:36,60.39it/s]100%|##########|173481/173481[49:33<00:00,58.35it/s]
[32m[0418 13:27:42 @base.py:257][0m Epoch 26 (global_step 4510506) finished, time:2973.03 sec.
[32m[0418 13:27:43 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,109.37it/s]
25
[32m[0418 13:30:35 @monitor.py:363][0m QueueInput/queue_size: 0.75605
[32m[0418 13:30:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.5893
[32m[0418 13:30:35 @monitor.py:363][0m activation-summaries/output-rms: 0.020791
[32m[0418 13:30:35 @monitor.py:363][0m cross_entropy_loss: 3.2455
[32m[0418 13:30:35 @monitor.py:363][0m last_linear/W_0_percent_n: 0.2979
[32m[0418 13:30:35 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16661
[32m[0418 13:30:35 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53543
[32m[0418 13:30:35 @monitor.py:363][0m last_linear/Wn_0: 0.21608
[32m[0418 13:30:35 @monitor.py:363][0m last_linear/Wp_0: 0.19194
[32m[0418 13:30:35 @monitor.py:363][0m linear0/W_0_percent_n: 0.092559
[32m[0418 13:30:35 @monitor.py:363][0m linear0/W_0_percent_p: 0.10775
[32m[0418 13:30:35 @monitor.py:363][0m linear0/W_0_sparsity: 0.7996
[32m[0418 13:30:35 @monitor.py:363][0m linear0/Wn_0: 0.99446
[32m[0418 13:30:35 @monitor.py:363][0m linear0/Wp_0: 1.0524
[32m[0418 13:30:35 @monitor.py:363][0m linear1/W_0_percent_n: 0.15175
[32m[0418 13:30:35 @monitor.py:363][0m linear1/W_0_percent_p: 0.12289
[32m[0418 13:30:35 @monitor.py:363][0m linear1/W_0_sparsity: 0.7252
[32m[0418 13:30:35 @monitor.py:363][0m linear1/Wn_0: 0.94099
[32m[0418 13:30:35 @monitor.py:363][0m linear1/Wp_0: 0.98232
[32m[0418 13:30:35 @monitor.py:363][0m linear2/W_0_percent_n: 0.035339
[32m[0418 13:30:35 @monitor.py:363][0m linear2/W_0_percent_p: 0.044083
[32m[0418 13:30:35 @monitor.py:363][0m linear2/W_0_sparsity: 0.92049
[32m[0418 13:30:35 @monitor.py:363][0m linear2/Wn_0: 1.1058
[32m[0418 13:30:35 @monitor.py:363][0m linear2/Wp_0: 0.89862
[32m[0418 13:30:35 @monitor.py:363][0m linear3/W_0_percent_n: 0.041122
[32m[0418 13:30:35 @monitor.py:363][0m linear3/W_0_percent_p: 0.036087
[32m[0418 13:30:35 @monitor.py:363][0m linear3/W_0_sparsity: 0.92271
[32m[0418 13:30:35 @monitor.py:363][0m linear3/Wn_0: 0.91003
[32m[0418 13:30:35 @monitor.py:363][0m linear3/Wp_0: 0.86805
[32m[0418 13:30:35 @monitor.py:363][0m lr: 1.9531e-06
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4812
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0959
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/linear0/W-rms: 2.1991
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4098
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5692
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5915
[32m[0418 13:30:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 13:30:35 @monitor.py:363][0m train-error-top1: 0.77438
[32m[0418 13:30:35 @monitor.py:363][0m val-error-top1: 0.84848
[32m[0418 13:30:35 @monitor.py:363][0m val-utt-error: 0.70152
[32m[0418 13:30:35 @monitor.py:363][0m validation_cost: 3.7889
[32m[0418 13:30:35 @monitor.py:363][0m wd_cost: 0.00012021
[32m[0418 13:30:35 @group.py:42][0m Callbacks took 172.344 sec in total. InferenceRunner: 172.118sec
[32m[0418 13:30:35 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10794/173481[03:00<45:13,59.96it/s]  7%|6         |11374/173481[03:10<45:03,59.96it/s] 12%|#1        |20114/173481[06:00<45:59,55.57it/s] 12%|#1        |20730/173481[06:10<45:48,55.57it/s] 17%|#7        |30247/173481[09:00<42:41,55.92it/s] 18%|#7        |30834/173481[09:10<42:30,55.92it/s] 23%|##3       |40447/173481[12:00<39:23,56.28it/s] 24%|##3       |41037/173481[12:10<39:13,56.28it/s] 29%|##8       |49646/173481[15:00<38:31,53.57it/s] 29%|##8       |50244/173481[15:10<38:20,53.57it/s] 35%|###4      |59974/173481[18:00<34:08,55.41it/s] 35%|###4      |60600/173481[18:10<33:57,55.41it/s] 41%|####      |70429/173481[21:00<30:17,56.71it/s] 41%|####      |71028/173481[21:11<30:06,56.71it/s] 47%|####6     |81147/173481[24:00<26:29,58.09it/s] 47%|####7     |81762/173481[24:11<26:18,58.09it/s] 53%|#####2    |91418/173481[27:00<23:45,57.57it/s] 53%|#####3    |92087/173481[27:11<23:33,57.57it/s] 59%|#####9    |102741/173481[30:00<19:36,60.12it/s] 60%|#####9    |103350/173481[30:11<19:26,60.12it/s] 65%|######4   |112597/173481[33:00<17:42,57.31it/s] 65%|######5   |113232/173481[33:11<17:31,57.31it/s] 71%|#######   |122659/173481[36:00<14:58,56.58it/s] 71%|#######1  |123288/173481[36:11<14:47,56.58it/s] 77%|#######6  |132763/173481[39:00<12:02,56.35it/s] 77%|#######6  |133418/173481[39:11<11:50,56.35it/s] 82%|########2 |142843/173481[42:00<09:05,56.17it/s] 83%|########2 |143495/173481[42:12<08:53,56.17it/s] 88%|########8 |153152/173481[45:00<05:58,56.72it/s] 89%|########8 |153823/173481[45:12<05:46,56.72it/s] 95%|#########4|164325/173481[48:00<02:34,59.27it/s] 95%|#########5|165176/173481[48:12<02:20,59.27it/s]100%|##########|173481/173481[50:00<00:00,57.82it/s]
[32m[0418 14:20:35 @base.py:257][0m Epoch 27 (global_step 4683987) finished, time:3000.59 sec.
[32m[0418 14:20:35 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:10<00:00,144.19it/s]
26
[32m[0418 14:22:46 @monitor.py:363][0m QueueInput/queue_size: 0.52203
[32m[0418 14:22:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.548
[32m[0418 14:22:46 @monitor.py:363][0m activation-summaries/output-rms: 0.021795
[32m[0418 14:22:46 @monitor.py:363][0m cross_entropy_loss: 3.2028
[32m[0418 14:22:46 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29585
[32m[0418 14:22:46 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16503
[32m[0418 14:22:46 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53906
[32m[0418 14:22:46 @monitor.py:363][0m last_linear/Wn_0: 0.21754
[32m[0418 14:22:46 @monitor.py:363][0m last_linear/Wp_0: 0.19323
[32m[0418 14:22:46 @monitor.py:363][0m linear0/W_0_percent_n: 0.093539
[32m[0418 14:22:46 @monitor.py:363][0m linear0/W_0_percent_p: 0.10802
[32m[0418 14:22:46 @monitor.py:363][0m linear0/W_0_sparsity: 0.79834
[32m[0418 14:22:46 @monitor.py:363][0m linear0/Wn_0: 0.99513
[32m[0418 14:22:46 @monitor.py:363][0m linear0/Wp_0: 1.0546
[32m[0418 14:22:46 @monitor.py:363][0m linear1/W_0_percent_n: 0.15126
[32m[0418 14:22:46 @monitor.py:363][0m linear1/W_0_percent_p: 0.12135
[32m[0418 14:22:46 @monitor.py:363][0m linear1/W_0_sparsity: 0.72725
[32m[0418 14:22:46 @monitor.py:363][0m linear1/Wn_0: 0.94424
[32m[0418 14:22:46 @monitor.py:363][0m linear1/Wp_0: 0.98389
[32m[0418 14:22:46 @monitor.py:363][0m linear2/W_0_percent_n: 0.036057
[32m[0418 14:22:46 @monitor.py:363][0m linear2/W_0_percent_p: 0.043625
[32m[0418 14:22:46 @monitor.py:363][0m linear2/W_0_sparsity: 0.92021
[32m[0418 14:22:46 @monitor.py:363][0m linear2/Wn_0: 1.1066
[32m[0418 14:22:46 @monitor.py:363][0m linear2/Wp_0: 0.90261
[32m[0418 14:22:46 @monitor.py:363][0m linear3/W_0_percent_n: 0.040405
[32m[0418 14:22:46 @monitor.py:363][0m linear3/W_0_percent_p: 0.035767
[32m[0418 14:22:46 @monitor.py:363][0m linear3/W_0_sparsity: 0.9238
[32m[0418 14:22:46 @monitor.py:363][0m linear3/Wn_0: 0.91289
[32m[0418 14:22:46 @monitor.py:363][0m linear3/Wp_0: 0.87393
[32m[0418 14:22:46 @monitor.py:363][0m lr: 1.9531e-06
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4875
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0956
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2065
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4149
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5718
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5944
[32m[0418 14:22:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 14:22:46 @monitor.py:363][0m train-error-top1: 0.76905
[32m[0418 14:22:46 @monitor.py:363][0m val-error-top1: 0.85427
[32m[0418 14:22:46 @monitor.py:363][0m val-utt-error: 0.72771
[32m[0418 14:22:46 @monitor.py:363][0m validation_cost: 3.9149
[32m[0418 14:22:46 @monitor.py:363][0m wd_cost: 0.00012089
[32m[0418 14:22:46 @group.py:42][0m Callbacks took 130.716 sec in total. InferenceRunner: 130.550sec
[32m[0418 14:22:46 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9035/173481[03:00<54:36,50.19it/s]  6%|5         |9576/173481[03:10<54:25,50.19it/s] 11%|#         |18796/173481[06:00<49:27,52.13it/s] 11%|#1        |19378/173481[06:10<49:16,52.13it/s] 16%|#6        |28576/173481[09:00<45:23,53.21it/s] 17%|#6        |29289/173481[09:10<45:10,53.21it/s] 23%|##2       |39089/173481[12:00<40:13,55.68it/s] 23%|##2       |39669/173481[12:10<40:03,55.68it/s] 27%|##7       |47511/173481[15:00<41:17,50.85it/s] 28%|##7       |48093/173481[15:10<41:05,50.85it/s] 33%|###3      |57416/173481[18:00<36:35,52.86it/s] 33%|###3      |58069/173481[18:10<36:23,52.86it/s] 40%|###9      |68564/173481[21:00<30:39,57.04it/s] 40%|###9      |69175/173481[21:11<30:28,57.04it/s] 45%|####5     |78920/173481[24:00<27:30,57.28it/s] 46%|####5     |79670/173481[24:11<27:17,57.28it/s] 50%|#####     |87178/173481[27:00<28:14,50.94it/s] 51%|#####     |87920/173481[27:11<27:59,50.94it/s] 58%|#####7    |100192/173481[30:00<20:26,59.77it/s] 58%|#####8    |100989/173481[30:11<20:12,59.77it/s] 64%|######4   |111039/173481[33:00<17:20,60.01it/s] 64%|######4   |111723/173481[33:11<17:09,60.01it/s] 70%|#######   |121486/173481[36:00<14:41,59.00it/s] 70%|#######   |122127/173481[36:11<14:30,59.00it/s] 76%|#######5  |131506/173481[39:00<12:12,57.28it/s] 76%|#######6  |132186/173481[39:11<12:00,57.28it/s] 82%|########1 |141784/173481[42:00<09:14,57.19it/s] 82%|########2 |142467/173481[42:12<09:02,57.19it/s] 88%|########7 |152002/173481[45:00<06:17,56.97it/s] 88%|########8 |152693/173481[45:12<06:04,56.97it/s] 94%|#########3|162339/173481[48:00<03:14,57.19it/s] 94%|#########3|163035/173481[48:12<03:02,57.19it/s] 99%|#########8|171736/173481[51:00<00:31,54.58it/s] 99%|#########9|172425/173481[51:12<00:19,54.58it/s]100%|##########|173481/173481[51:30<00:00,56.13it/s]
[32m[0418 15:14:17 @base.py:257][0m Epoch 28 (global_step 4857468) finished, time:3090.65 sec.
[32m[0418 15:14:17 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-4857468.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:12<00:00,141.52it/s]
27
[32m[0418 15:16:30 @monitor.py:363][0m QueueInput/queue_size: 0.6395
[32m[0418 15:16:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6677
[32m[0418 15:16:30 @monitor.py:363][0m activation-summaries/output-rms: 0.021062
[32m[0418 15:16:30 @monitor.py:363][0m cross_entropy_loss: 3.2971
[32m[0418 15:16:30 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29741
[32m[0418 15:16:30 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16642
[32m[0418 15:16:30 @monitor.py:363][0m last_linear/W_0_sparsity: 0.536
[32m[0418 15:16:30 @monitor.py:363][0m last_linear/Wn_0: 0.2214
[32m[0418 15:16:30 @monitor.py:363][0m last_linear/Wp_0: 0.1965
[32m[0418 15:16:30 @monitor.py:363][0m linear0/W_0_percent_n: 0.11717
[32m[0418 15:16:30 @monitor.py:363][0m linear0/W_0_percent_p: 0.13353
[32m[0418 15:16:30 @monitor.py:363][0m linear0/W_0_sparsity: 0.7491
[32m[0418 15:16:30 @monitor.py:363][0m linear0/Wn_0: 0.99584
[32m[0418 15:16:30 @monitor.py:363][0m linear0/Wp_0: 1.0564
[32m[0418 15:16:30 @monitor.py:363][0m linear1/W_0_percent_n: 0.16576
[32m[0418 15:16:30 @monitor.py:363][0m linear1/W_0_percent_p: 0.13319
[32m[0418 15:16:30 @monitor.py:363][0m linear1/W_0_sparsity: 0.70068
[32m[0418 15:16:30 @monitor.py:363][0m linear1/Wn_0: 0.9473
[32m[0418 15:16:30 @monitor.py:363][0m linear1/Wp_0: 0.98513
[32m[0418 15:16:30 @monitor.py:363][0m linear2/W_0_percent_n: 0.036514
[32m[0418 15:16:30 @monitor.py:363][0m linear2/W_0_percent_p: 0.044601
[32m[0418 15:16:30 @monitor.py:363][0m linear2/W_0_sparsity: 0.91879
[32m[0418 15:16:30 @monitor.py:363][0m linear2/Wn_0: 1.1067
[32m[0418 15:16:30 @monitor.py:363][0m linear2/Wp_0: 0.90701
[32m[0418 15:16:30 @monitor.py:363][0m linear3/W_0_percent_n: 0.042191
[32m[0418 15:16:30 @monitor.py:363][0m linear3/W_0_percent_p: 0.037476
[32m[0418 15:16:30 @monitor.py:363][0m linear3/W_0_sparsity: 0.92018
[32m[0418 15:16:30 @monitor.py:363][0m linear3/Wn_0: 0.91701
[32m[0418 15:16:30 @monitor.py:363][0m linear3/Wp_0: 0.87793
[32m[0418 15:16:30 @monitor.py:363][0m lr: 9.7656e-07
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4906
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0957
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2108
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4179
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5733
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5961
[32m[0418 15:16:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 15:16:30 @monitor.py:363][0m train-error-top1: 0.77344
[32m[0418 15:16:30 @monitor.py:363][0m val-error-top1: 0.83602
[32m[0418 15:16:30 @monitor.py:363][0m val-utt-error: 0.67713
[32m[0418 15:16:30 @monitor.py:363][0m validation_cost: 3.7973
[32m[0418 15:16:30 @monitor.py:363][0m wd_cost: 2.4253e-05
[32m[0418 15:16:30 @group.py:42][0m Callbacks took 133.191 sec in total. InferenceRunner: 133.016sec
[32m[0418 15:16:30 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11639/173481[03:00<41:42,64.66it/s]  7%|7         |12150/173481[03:10<41:35,64.66it/s] 13%|#2        |21709/173481[06:00<42:10,59.98it/s] 13%|#2        |22296/173481[06:10<42:00,59.98it/s] 18%|#8        |31284/173481[09:00<42:01,56.38it/s] 18%|#8        |31873/173481[09:10<41:51,56.38it/s] 23%|##3       |39968/173481[12:00<42:47,52.00it/s] 23%|##3       |40531/173481[12:10<42:36,52.00it/s] 29%|##8       |49581/173481[15:00<39:11,52.69it/s] 29%|##8       |50142/173481[15:10<39:00,52.69it/s] 34%|###4      |59053/173481[18:00<36:13,52.65it/s] 34%|###4      |59587/173481[18:10<36:03,52.65it/s] 39%|###9      |68100/173481[21:00<34:09,51.43it/s] 40%|###9      |68643/173481[21:11<33:58,51.43it/s] 44%|####4     |77116/173481[24:00<31:38,50.75it/s] 45%|####4     |77658/173481[24:11<31:28,50.75it/s] 50%|####9     |86053/173481[27:00<29:01,50.19it/s] 50%|####9     |86592/173481[27:11<28:51,50.19it/s] 55%|#####4    |95155/173481[30:00<25:55,50.37it/s] 55%|#####5    |95940/173481[30:11<25:39,50.37it/s] 61%|######    |105254/173481[33:00<21:25,53.08it/s] 61%|######1   |105978/173481[33:11<21:11,53.08it/s] 67%|######6   |115638/173481[36:00<17:26,55.29it/s] 67%|######7   |116290/173481[36:11<17:14,55.29it/s] 72%|#######2  |125559/173481[39:00<14:28,55.20it/s] 73%|#######2  |126210/173481[39:11<14:16,55.20it/s] 78%|#######7  |135205/173481[42:00<11:43,54.37it/s] 78%|#######8  |135843/173481[42:12<11:32,54.37it/s] 84%|########3 |145077/173481[45:00<08:40,54.61it/s] 84%|########3 |145687/173481[45:12<08:28,54.61it/s] 89%|########9 |154639/173481[48:00<05:49,53.85it/s] 90%|########9 |155298/173481[48:12<05:37,53.85it/s] 95%|#########4|164497/173481[51:00<02:45,54.30it/s] 95%|#########5|165132/173481[51:12<02:33,54.30it/s]100%|##########|173481/173481[53:56<00:00,53.61it/s]
[32m[0418 16:10:26 @base.py:257][0m Epoch 29 (global_step 5030949) finished, time:3236.19 sec.
[32m[0418 16:10:26 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-5030949.
  0%|          |0/18822[00:00<?,?it/s] 85%|########4 |15935/18822[03:00<00:32,88.52it/s] 90%|######### |17007/18822[03:10<00:20,88.52it/s]100%|##########|18822/18822[03:25<00:00,91.56it/s]
28
[32m[0418 16:13:52 @monitor.py:363][0m QueueInput/queue_size: 0.93441
[32m[0418 16:13:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6334
[32m[0418 16:13:52 @monitor.py:363][0m activation-summaries/output-rms: 0.021365
[32m[0418 16:13:52 @monitor.py:363][0m cross_entropy_loss: 3.2329
[32m[0418 16:13:52 @monitor.py:363][0m last_linear/W_0_percent_n: 0.2975
[32m[0418 16:13:52 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16705
[32m[0418 16:13:52 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53532
[32m[0418 16:13:52 @monitor.py:363][0m last_linear/Wn_0: 0.22247
[32m[0418 16:13:52 @monitor.py:363][0m last_linear/Wp_0: 0.19708
[32m[0418 16:13:52 @monitor.py:363][0m linear0/W_0_percent_n: 0.11875
[32m[0418 16:13:52 @monitor.py:363][0m linear0/W_0_percent_p: 0.13439
[32m[0418 16:13:52 @monitor.py:363][0m linear0/W_0_sparsity: 0.74664
[32m[0418 16:13:52 @monitor.py:363][0m linear0/Wn_0: 0.99664
[32m[0418 16:13:52 @monitor.py:363][0m linear0/Wp_0: 1.0579
[32m[0418 16:13:52 @monitor.py:363][0m linear1/W_0_percent_n: 0.16609
[32m[0418 16:13:52 @monitor.py:363][0m linear1/W_0_percent_p: 0.13425
[32m[0418 16:13:52 @monitor.py:363][0m linear1/W_0_sparsity: 0.69937
[32m[0418 16:13:52 @monitor.py:363][0m linear1/Wn_0: 0.95036
[32m[0418 16:13:52 @monitor.py:363][0m linear1/Wp_0: 0.98611
[32m[0418 16:13:52 @monitor.py:363][0m linear2/W_0_percent_n: 0.036179
[32m[0418 16:13:52 @monitor.py:363][0m linear2/W_0_percent_p: 0.044769
[32m[0418 16:13:52 @monitor.py:363][0m linear2/W_0_sparsity: 0.91893
[32m[0418 16:13:52 @monitor.py:363][0m linear2/Wn_0: 1.1079
[32m[0418 16:13:52 @monitor.py:363][0m linear2/Wp_0: 0.91019
[32m[0418 16:13:52 @monitor.py:363][0m linear3/W_0_percent_n: 0.042282
[32m[0418 16:13:52 @monitor.py:363][0m linear3/W_0_percent_p: 0.037399
[32m[0418 16:13:52 @monitor.py:363][0m linear3/W_0_sparsity: 0.92023
[32m[0418 16:13:52 @monitor.py:363][0m linear3/Wn_0: 0.92187
[32m[0418 16:13:52 @monitor.py:363][0m linear3/Wp_0: 0.88094
[32m[0418 16:13:52 @monitor.py:363][0m lr: 9.7656e-07
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4927
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0958
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2142
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4202
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5745
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5974
[32m[0418 16:13:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 16:13:52 @monitor.py:363][0m train-error-top1: 0.77112
[32m[0418 16:13:52 @monitor.py:363][0m val-error-top1: 0.82833
[32m[0418 16:13:52 @monitor.py:363][0m val-utt-error: 0.65508
[32m[0418 16:13:52 @monitor.py:363][0m validation_cost: 3.6636
[32m[0418 16:13:52 @monitor.py:363][0m wd_cost: 2.4313e-05
[32m[0418 16:13:52 @group.py:42][0m Callbacks took 205.840 sec in total. InferenceRunner: 205.591sec
[32m[0418 16:13:52 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14772/173481[03:00<32:14,82.06it/s]  9%|8         |15461/173481[03:10<32:05,82.06it/s] 14%|#3        |24099/173481[06:00<39:11,63.52it/s] 14%|#4        |24481/173481[06:10<39:05,63.52it/s] 17%|#7        |29710/173481[09:00<57:18,41.81it/s] 17%|#7        |30264/173481[09:10<57:05,41.81it/s] 23%|##2       |39070/173481[12:00<48:19,46.35it/s] 23%|##2       |39639/173481[12:10<48:07,46.35it/s] 28%|##7       |48258/173481[15:00<42:57,48.58it/s] 28%|##8       |48741/173481[15:10<42:47,48.58it/s] 33%|###3      |57712/173481[18:00<38:13,50.47it/s] 34%|###3      |58287/173481[18:10<38:02,50.47it/s] 39%|###8      |67408/173481[21:00<33:55,52.11it/s] 39%|###9      |68007/173481[21:10<33:44,52.11it/s] 44%|####4     |77152/173481[24:00<30:14,53.09it/s] 45%|####4     |77667/173481[24:11<30:04,53.09it/s] 50%|#####     |87346/173481[27:00<26:11,54.80it/s] 51%|#####     |87929/173481[27:11<26:01,54.80it/s] 55%|#####5    |96065/173481[30:00<25:05,51.42it/s] 56%|#####5    |96657/173481[30:11<24:53,51.42it/s] 61%|######1   |106662/173481[33:00<20:17,54.90it/s] 62%|######1   |107287/173481[33:11<20:05,54.90it/s] 68%|######7   |117352/173481[36:00<16:23,57.05it/s] 68%|######7   |117963/173481[36:11<16:13,57.05it/s] 73%|#######3  |126966/173481[39:00<14:03,55.17it/s] 74%|#######3  |127553/173481[39:11<13:52,55.17it/s] 79%|#######8  |136334/173481[42:00<11:33,53.56it/s] 79%|#######8  |136930/173481[42:11<11:22,53.56it/s] 84%|########4 |146434/173481[45:00<08:13,54.80it/s] 85%|########4 |147089/173481[45:12<08:01,54.80it/s] 90%|######### |156718/173481[48:00<04:59,55.94it/s] 91%|######### |157407/173481[48:12<04:47,55.94it/s] 96%|#########6|167110/173481[51:00<01:52,56.82it/s] 97%|#########6|167799/173481[51:12<01:39,56.82it/s]100%|##########|173481/173481[52:50<00:00,54.71it/s]
[32m[0418 17:06:43 @base.py:257][0m Epoch 30 (global_step 5204430) finished, time:3170.74 sec.
[32m[0418 17:06:43 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-5204430.
[32m[0418 17:06:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 96%|#########6|18158/18822[03:00<00:06,100.88it/s]100%|##########|18822/18822[03:05<00:00,101.51it/s]
29
[32m[0418 17:09:49 @monitor.py:363][0m QueueInput/queue_size: 0.62311
[32m[0418 17:09:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6684
[32m[0418 17:09:49 @monitor.py:363][0m activation-summaries/output-rms: 0.022071
[32m[0418 17:09:49 @monitor.py:363][0m cross_entropy_loss: 3.1767
[32m[0418 17:09:49 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29689
[32m[0418 17:09:49 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16584
[32m[0418 17:09:49 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53695
[32m[0418 17:09:49 @monitor.py:363][0m last_linear/Wn_0: 0.22437
[32m[0418 17:09:49 @monitor.py:363][0m last_linear/Wp_0: 0.19841
[32m[0418 17:09:49 @monitor.py:363][0m linear0/W_0_percent_n: 0.12136
[32m[0418 17:09:49 @monitor.py:363][0m linear0/W_0_percent_p: 0.13786
[32m[0418 17:09:49 @monitor.py:363][0m linear0/W_0_sparsity: 0.74042
[32m[0418 17:09:49 @monitor.py:363][0m linear0/Wn_0: 0.99718
[32m[0418 17:09:49 @monitor.py:363][0m linear0/Wp_0: 1.0597
[32m[0418 17:09:49 @monitor.py:363][0m linear1/W_0_percent_n: 0.1698
[32m[0418 17:09:49 @monitor.py:363][0m linear1/W_0_percent_p: 0.13826
[32m[0418 17:09:49 @monitor.py:363][0m linear1/W_0_sparsity: 0.6913
[32m[0418 17:09:49 @monitor.py:363][0m linear1/Wn_0: 0.95266
[32m[0418 17:09:49 @monitor.py:363][0m linear1/Wp_0: 0.98779
[32m[0418 17:09:49 @monitor.py:363][0m linear2/W_0_percent_n: 0.03656
[32m[0418 17:09:49 @monitor.py:363][0m linear2/W_0_percent_p: 0.044724
[32m[0418 17:09:49 @monitor.py:363][0m linear2/W_0_sparsity: 0.9185
[32m[0418 17:09:49 @monitor.py:363][0m linear2/Wn_0: 1.1101
[32m[0418 17:09:49 @monitor.py:363][0m linear2/Wp_0: 0.91234
[32m[0418 17:09:49 @monitor.py:363][0m linear3/W_0_percent_n: 0.042435
[32m[0418 17:09:49 @monitor.py:363][0m linear3/W_0_percent_p: 0.037231
[32m[0418 17:09:49 @monitor.py:363][0m linear3/W_0_sparsity: 0.92007
[32m[0418 17:09:49 @monitor.py:363][0m linear3/Wn_0: 0.92568
[32m[0418 17:09:49 @monitor.py:363][0m linear3/Wp_0: 0.88483
[32m[0418 17:09:49 @monitor.py:363][0m lr: 4.8828e-07
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4948
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0959
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2174
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4223
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5757
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5986
[32m[0418 17:09:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 17:09:49 @monitor.py:363][0m train-error-top1: 0.75982
[32m[0418 17:09:49 @monitor.py:363][0m val-error-top1: 0.83531
[32m[0418 17:09:49 @monitor.py:363][0m val-utt-error: 0.69084
[32m[0418 17:09:49 @monitor.py:363][0m validation_cost: 3.8713
[32m[0418 17:09:49 @monitor.py:363][0m wd_cost: 2.4369e-05
[32m[0418 17:09:49 @group.py:42][0m Callbacks took 186.056 sec in total. InferenceRunner: 185.435sec
[32m[0418 17:09:49 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10669/173481[03:00<45:46,59.27it/s]  6%|6         |11226/173481[03:10<45:37,59.27it/s] 12%|#2        |20857/173481[06:00<43:55,57.90it/s] 12%|#2        |21566/173481[06:10<43:43,57.90it/s] 19%|#8        |32329/173481[09:00<38:46,60.67it/s] 19%|#8        |32900/173481[09:10<38:37,60.67it/s] 24%|##3       |41368/173481[12:00<40:04,54.95it/s] 24%|##4       |41904/173481[12:10<39:54,54.95it/s] 29%|##9       |50881/173481[15:00<37:56,53.86it/s] 30%|##9       |51475/173481[15:10<37:45,53.86it/s] 35%|###4      |60022/173481[18:00<36:10,52.28it/s] 35%|###4      |60678/173481[18:10<35:57,52.28it/s] 41%|####      |70399/173481[21:00<31:19,54.83it/s] 41%|####      |71080/173481[21:11<31:07,54.83it/s] 47%|####6     |81496/173481[24:00<26:24,58.04it/s] 48%|####7     |82482/173481[24:11<26:07,58.04it/s] 53%|#####3    |92775/173481[27:00<22:19,60.26it/s] 54%|#####3    |93424/173481[27:11<22:08,60.26it/s] 59%|#####9    |102512/173481[30:00<20:44,57.01it/s] 60%|#####9    |103302/173481[30:11<20:31,57.01it/s] 65%|######5   |113467/173481[33:00<16:59,58.87it/s] 66%|######5   |114072/173481[33:11<16:49,58.87it/s] 71%|#######   |122851/173481[36:00<15:15,55.30it/s] 71%|#######1  |123450/173481[36:11<15:04,55.30it/s] 76%|#######6  |131995/173481[39:00<13:03,52.95it/s] 76%|#######6  |132606/173481[39:11<12:51,52.95it/s] 82%|########1 |141767/173481[42:00<09:51,53.61it/s] 82%|########2 |142362/173481[42:12<09:40,53.61it/s] 88%|########8 |153235/173481[45:00<05:47,58.22it/s] 89%|########8 |153822/173481[45:12<05:37,58.22it/s] 94%|#########3|162749/173481[48:00<03:13,55.41it/s] 94%|#########4|163400/173481[48:12<03:01,55.41it/s] 99%|#########9|172327/173481[51:00<00:21,54.28it/s]100%|#########9|172920/173481[51:12<00:10,54.28it/s]100%|##########|173481/173481[51:23<00:00,56.26it/s]
[32m[0418 18:01:12 @base.py:257][0m Epoch 31 (global_step 5377911) finished, time:3083.45 sec.
[32m[0418 18:01:12 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-5377911.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########9|18649/18822[03:00<00:01,103.60it/s]100%|##########|18822/18822[03:01<00:00,103.78it/s]
30
[32m[0418 18:04:14 @monitor.py:363][0m QueueInput/queue_size: 0.1939
[32m[0418 18:04:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.7314
[32m[0418 18:04:14 @monitor.py:363][0m activation-summaries/output-rms: 0.022179
[32m[0418 18:04:14 @monitor.py:363][0m cross_entropy_loss: 3.1389
[32m[0418 18:04:14 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29625
[32m[0418 18:04:14 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16524
[32m[0418 18:04:14 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53819
[32m[0418 18:04:14 @monitor.py:363][0m last_linear/Wn_0: 0.2271
[32m[0418 18:04:14 @monitor.py:363][0m last_linear/Wp_0: 0.20111
[32m[0418 18:04:14 @monitor.py:363][0m linear0/W_0_percent_n: 0.12515
[32m[0418 18:04:14 @monitor.py:363][0m linear0/W_0_percent_p: 0.14164
[32m[0418 18:04:14 @monitor.py:363][0m linear0/W_0_sparsity: 0.73287
[32m[0418 18:04:14 @monitor.py:363][0m linear0/Wn_0: 0.99831
[32m[0418 18:04:14 @monitor.py:363][0m linear0/Wp_0: 1.0607
[32m[0418 18:04:14 @monitor.py:363][0m linear1/W_0_percent_n: 0.16951
[32m[0418 18:04:14 @monitor.py:363][0m linear1/W_0_percent_p: 0.13911
[32m[0418 18:04:14 @monitor.py:363][0m linear1/W_0_sparsity: 0.69081
[32m[0418 18:04:14 @monitor.py:363][0m linear1/Wn_0: 0.95451
[32m[0418 18:04:14 @monitor.py:363][0m linear1/Wp_0: 0.98946
[32m[0418 18:04:14 @monitor.py:363][0m linear2/W_0_percent_n: 0.03627
[32m[0418 18:04:14 @monitor.py:363][0m linear2/W_0_percent_p: 0.04483
[32m[0418 18:04:14 @monitor.py:363][0m linear2/W_0_sparsity: 0.91873
[32m[0418 18:04:14 @monitor.py:363][0m linear2/Wn_0: 1.1118
[32m[0418 18:04:14 @monitor.py:363][0m linear2/Wp_0: 0.91495
[32m[0418 18:04:14 @monitor.py:363][0m linear3/W_0_percent_n: 0.04274
[32m[0418 18:04:14 @monitor.py:363][0m linear3/W_0_percent_p: 0.037491
[32m[0418 18:04:14 @monitor.py:363][0m linear3/W_0_sparsity: 0.91943
[32m[0418 18:04:14 @monitor.py:363][0m linear3/Wn_0: 0.93013
[32m[0418 18:04:14 @monitor.py:363][0m linear3/Wp_0: 0.88772
[32m[0418 18:04:14 @monitor.py:363][0m lr: 4.8828e-07
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4948
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.096
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2185
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4231
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/linear2/W-rms: 1.576
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/linear3/W-rms: 1.599
[32m[0418 18:04:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 18:04:14 @monitor.py:363][0m train-error-top1: 0.75177
[32m[0418 18:04:14 @monitor.py:363][0m val-error-top1: 0.83559
[32m[0418 18:04:14 @monitor.py:363][0m val-utt-error: 0.68207
[32m[0418 18:04:14 @monitor.py:363][0m validation_cost: 3.7473
[32m[0418 18:04:14 @monitor.py:363][0m wd_cost: 4.877e-06
[32m[0418 18:04:14 @group.py:42][0m Callbacks took 181.558 sec in total. InferenceRunner: 181.390sec
[32m[0418 18:04:14 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10147/173481[03:00<48:17,56.37it/s]  6%|6         |10684/173481[03:10<48:07,56.37it/s] 11%|#1        |19746/173481[06:00<46:45,54.81it/s] 12%|#1        |20295/173481[06:10<46:35,54.81it/s] 17%|#6        |29366/173481[09:00<44:23,54.12it/s] 17%|#7        |29943/173481[09:10<44:12,54.12it/s] 22%|##2       |38381/173481[12:00<43:17,52.02it/s] 22%|##2       |38955/173481[12:10<43:05,52.02it/s] 25%|##5       |43847/173481[15:00<56:20,38.35it/s] 26%|##5       |44433/173481[15:10<56:05,38.35it/s] 32%|###2      |55647/173481[18:00<40:35,48.38it/s] 33%|###2      |56391/173481[18:10<40:20,48.38it/s] 40%|####      |69555/173481[21:00<29:06,59.50it/s] 41%|####      |70355/173481[21:10<28:53,59.50it/s] 46%|####5     |79717/173481[24:00<26:58,57.94it/s] 46%|####6     |80295/173481[24:11<26:48,57.94it/s] 51%|#####1    |89062/173481[27:00<25:41,54.76it/s] 52%|#####1    |89673/173481[27:11<25:30,54.76it/s] 57%|#####6    |98848/173481[30:00<22:48,54.55it/s] 57%|#####7    |99501/173481[30:11<22:36,54.55it/s] 63%|######3   |109358/173481[33:00<18:56,56.41it/s] 63%|######3   |110061/173481[33:11<18:44,56.41it/s] 69%|######8   |119050/173481[36:00<16:28,55.08it/s] 69%|######8   |119649/173481[36:11<16:17,55.08it/s] 74%|#######4  |128717/173481[39:00<13:43,54.39it/s] 75%|#######4  |129325/173481[39:11<13:31,54.39it/s] 80%|#######9  |138178/173481[42:00<11:00,53.45it/s] 80%|########  |138825/173481[42:12<10:48,53.45it/s] 85%|########5 |148113/173481[45:00<07:47,54.31it/s] 86%|########5 |148732/173481[45:12<07:35,54.31it/s] 91%|######### |157021/173481[48:00<05:17,51.78it/s] 91%|######### |157611/173481[48:12<05:06,51.78it/s] 96%|#########5|166254/173481[51:00<02:20,51.54it/s] 96%|#########6|166893/173481[51:12<02:07,51.54it/s]100%|##########|173481/173481[53:12<00:00,54.34it/s]
[32m[0418 18:57:27 @base.py:257][0m Epoch 32 (global_step 5551392) finished, time:3192.77 sec.
[32m[0418 18:57:27 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-5551392.
  0%|          |0/18822[00:00<?,?it/s] 86%|########5 |16162/18822[03:00<00:29,89.78it/s] 92%|#########1|17291/18822[03:10<00:17,89.78it/s]100%|##########|18822/18822[03:24<00:00,92.10it/s]
31
[32m[0418 19:00:51 @monitor.py:363][0m QueueInput/queue_size: 0.36439
[32m[0418 19:00:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6999
[32m[0418 19:00:51 @monitor.py:363][0m activation-summaries/output-rms: 0.021834
[32m[0418 19:00:51 @monitor.py:363][0m cross_entropy_loss: 3.2073
[32m[0418 19:00:51 @monitor.py:363][0m last_linear/W_0_percent_n: 0.29596
[32m[0418 19:00:51 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16595
[32m[0418 19:00:51 @monitor.py:363][0m last_linear/W_0_sparsity: 0.53791
[32m[0418 19:00:51 @monitor.py:363][0m last_linear/Wn_0: 0.2275
[32m[0418 19:00:51 @monitor.py:363][0m last_linear/Wp_0: 0.2015
[32m[0418 19:00:51 @monitor.py:363][0m linear0/W_0_percent_n: 0.12566
[32m[0418 19:00:51 @monitor.py:363][0m linear0/W_0_percent_p: 0.14273
[32m[0418 19:00:51 @monitor.py:363][0m linear0/W_0_sparsity: 0.73121
[32m[0418 19:00:51 @monitor.py:363][0m linear0/Wn_0: 0.99936
[32m[0418 19:00:51 @monitor.py:363][0m linear0/Wp_0: 1.0617
[32m[0418 19:00:51 @monitor.py:363][0m linear1/W_0_percent_n: 0.17024
[32m[0418 19:00:51 @monitor.py:363][0m linear1/W_0_percent_p: 0.13956
[32m[0418 19:00:51 @monitor.py:363][0m linear1/W_0_sparsity: 0.68964
[32m[0418 19:00:51 @monitor.py:363][0m linear1/Wn_0: 0.95638
[32m[0418 19:00:51 @monitor.py:363][0m linear1/Wp_0: 0.99113
[32m[0418 19:00:51 @monitor.py:363][0m linear2/W_0_percent_n: 0.036453
[32m[0418 19:00:51 @monitor.py:363][0m linear2/W_0_percent_p: 0.044556
[32m[0418 19:00:51 @monitor.py:363][0m linear2/W_0_sparsity: 0.91876
[32m[0418 19:00:51 @monitor.py:363][0m linear2/Wn_0: 1.1136
[32m[0418 19:00:51 @monitor.py:363][0m linear2/Wp_0: 0.91741
[32m[0418 19:00:51 @monitor.py:363][0m linear3/W_0_percent_n: 0.042603
[32m[0418 19:00:51 @monitor.py:363][0m linear3/W_0_percent_p: 0.037201
[32m[0418 19:00:51 @monitor.py:363][0m linear3/W_0_sparsity: 0.92007
[32m[0418 19:00:51 @monitor.py:363][0m linear3/Wn_0: 0.93422
[32m[0418 19:00:51 @monitor.py:363][0m linear3/Wp_0: 0.89081
[32m[0418 19:00:51 @monitor.py:363][0m lr: 4.8828e-07
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4948
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0961
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2195
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4239
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5764
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5994
[32m[0418 19:00:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 19:00:51 @monitor.py:363][0m train-error-top1: 0.76518
[32m[0418 19:00:51 @monitor.py:363][0m val-error-top1: 0.84615
[32m[0418 19:00:51 @monitor.py:363][0m val-utt-error: 0.70508
[32m[0418 19:00:51 @monitor.py:363][0m validation_cost: 3.8118
[32m[0418 19:00:51 @monitor.py:363][0m wd_cost: 4.8802e-06
[32m[0418 19:00:51 @group.py:42][0m Callbacks took 204.652 sec in total. InferenceRunner: 204.371sec
[32m[0418 19:00:51 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9947/173481[03:00<49:19,55.26it/s]  6%|6         |10458/173481[03:10<49:10,55.26it/s] 11%|#         |18673/173481[06:00<49:57,51.65it/s] 11%|#1        |19154/173481[06:10<49:48,51.65it/s] 16%|#5        |27433/173481[09:00<48:34,50.11it/s] 16%|#6        |27942/173481[09:10<48:24,50.11it/s] 21%|##1       |36486/173481[12:00<45:28,50.20it/s] 21%|##1       |37014/173481[12:10<45:18,50.20it/s] 27%|##6       |45975/173481[15:00<41:19,51.43it/s] 27%|##6       |46559/173481[15:10<41:07,51.43it/s] 32%|###2      |55765/173481[18:00<37:06,52.86it/s] 32%|###2      |56303/173481[18:10<36:56,52.86it/s] 38%|###8      |66444/173481[21:00<31:54,55.91it/s] 39%|###8      |67226/173481[21:11<31:40,55.91it/s] 44%|####4     |77005/173481[24:00<28:05,57.25it/s] 45%|####4     |77616/173481[24:11<27:54,57.25it/s] 50%|#####     |86995/173481[27:00<25:34,56.36it/s] 50%|#####     |87594/173481[27:11<25:24,56.36it/s] 56%|#####5    |96727/173481[30:00<23:10,55.18it/s] 56%|#####6    |97398/173481[30:11<22:58,55.18it/s] 61%|######1   |106363/173481[33:00<20:35,54.35it/s] 62%|######1   |106940/173481[33:11<20:24,54.35it/s] 67%|######6   |115633/173481[36:00<18:13,52.88it/s] 67%|######7   |116238/173481[36:11<18:02,52.88it/s] 72%|#######2  |124908/173481[39:00<15:30,52.19it/s] 72%|#######2  |125490/173481[39:11<15:19,52.19it/s] 77%|#######7  |134191/173481[42:00<12:37,51.87it/s] 78%|#######7  |134814/173481[42:12<12:25,51.87it/s] 83%|########2 |143722/173481[45:00<09:27,52.40it/s] 83%|########3 |144384/173481[45:12<09:15,52.40it/s] 88%|########8 |153286/173481[48:00<06:22,52.77it/s] 89%|########8 |153944/173481[48:12<06:10,52.77it/s] 94%|#########3|162991/173481[51:00<03:16,53.33it/s] 94%|#########4|163668/173481[51:12<03:03,53.33it/s] 98%|#########8|170500/173481[54:00<01:03,46.81it/s] 99%|#########8|171120/173481[54:12<00:50,46.81it/s]100%|##########|173481/173481[54:56<00:00,52.62it/s]
[32m[0418 19:55:48 @base.py:257][0m Epoch 33 (global_step 5724873) finished, time:3296.83 sec.
[32m[0418 19:55:48 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-5724873.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,108.95it/s]
32
[32m[0418 19:58:41 @monitor.py:363][0m QueueInput/queue_size: 0.66703
[32m[0418 19:58:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.5257
[32m[0418 19:58:41 @monitor.py:363][0m activation-summaries/output-rms: 0.022219
[32m[0418 19:58:41 @monitor.py:363][0m cross_entropy_loss: 3.2685
[32m[0418 19:58:41 @monitor.py:363][0m last_linear/W_0_percent_n: 0.28454
[32m[0418 19:58:41 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16633
[32m[0418 19:58:41 @monitor.py:363][0m last_linear/W_0_sparsity: 0.54862
[32m[0418 19:58:41 @monitor.py:363][0m last_linear/Wn_0: 0.23232
[32m[0418 19:58:41 @monitor.py:363][0m last_linear/Wp_0: 0.20469
[32m[0418 19:58:41 @monitor.py:363][0m linear0/W_0_percent_n: 0.1263
[32m[0418 19:58:41 @monitor.py:363][0m linear0/W_0_percent_p: 0.14223
[32m[0418 19:58:41 @monitor.py:363][0m linear0/W_0_sparsity: 0.73071
[32m[0418 19:58:41 @monitor.py:363][0m linear0/Wn_0: 1.0004
[32m[0418 19:58:41 @monitor.py:363][0m linear0/Wp_0: 1.0626
[32m[0418 19:58:41 @monitor.py:363][0m linear1/W_0_percent_n: 0.16888
[32m[0418 19:58:41 @monitor.py:363][0m linear1/W_0_percent_p: 0.13919
[32m[0418 19:58:41 @monitor.py:363][0m linear1/W_0_sparsity: 0.69073
[32m[0418 19:58:41 @monitor.py:363][0m linear1/Wn_0: 0.95788
[32m[0418 19:58:41 @monitor.py:363][0m linear1/Wp_0: 0.99299
[32m[0418 19:58:41 @monitor.py:363][0m linear2/W_0_percent_n: 0.036484
[32m[0418 19:58:41 @monitor.py:363][0m linear2/W_0_percent_p: 0.044098
[32m[0418 19:58:41 @monitor.py:363][0m linear2/W_0_sparsity: 0.91905
[32m[0418 19:58:41 @monitor.py:363][0m linear2/Wn_0: 1.1154
[32m[0418 19:58:41 @monitor.py:363][0m linear2/Wp_0: 0.91969
[32m[0418 19:58:41 @monitor.py:363][0m linear3/W_0_percent_n: 0.042465
[32m[0418 19:58:41 @monitor.py:363][0m linear3/W_0_percent_p: 0.037186
[32m[0418 19:58:41 @monitor.py:363][0m linear3/W_0_sparsity: 0.92004
[32m[0418 19:58:41 @monitor.py:363][0m linear3/Wn_0: 0.93765
[32m[0418 19:58:41 @monitor.py:363][0m linear3/Wp_0: 0.89405
[32m[0418 19:58:41 @monitor.py:363][0m lr: 2.4414e-07
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4947
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0962
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2202
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4244
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5767
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5996
[32m[0418 19:58:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 19:58:41 @monitor.py:363][0m train-error-top1: 0.77966
[32m[0418 19:58:41 @monitor.py:363][0m val-error-top1: 0.83065
[32m[0418 19:58:41 @monitor.py:363][0m val-utt-error: 0.65896
[32m[0418 19:58:41 @monitor.py:363][0m validation_cost: 3.7106
[32m[0418 19:58:41 @monitor.py:363][0m wd_cost: 4.8825e-06
[32m[0418 19:58:41 @group.py:42][0m Callbacks took 172.954 sec in total. InferenceRunner: 172.774sec
[32m[0418 19:58:41 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9880/173481[03:00<49:41,54.88it/s]  6%|6         |10419/173481[03:10<49:31,54.88it/s] 11%|#1        |19402/173481[06:00<47:40,53.86it/s] 11%|#1        |19941/173481[06:10<47:30,53.86it/s] 17%|#6        |29157/173481[09:00<44:31,54.02it/s] 17%|#7        |29744/173481[09:10<44:20,54.02it/s] 23%|##2       |39226/173481[12:00<40:42,54.96it/s] 23%|##2       |39771/173481[12:10<40:32,54.96it/s] 28%|##7       |48418/173481[15:00<39:22,52.94it/s] 28%|##8       |48993/173481[15:10<39:11,52.94it/s] 33%|###3      |57644/173481[18:00<37:04,52.08it/s] 34%|###3      |58227/173481[18:10<36:52,52.08it/s] 39%|###8      |67272/173481[21:00<33:32,52.78it/s] 39%|###9      |68035/173481[21:11<33:18,52.78it/s] 46%|####6     |79903/173481[24:00<25:53,60.24it/s] 47%|####6     |80706/173481[24:11<25:40,60.24it/s] 52%|#####1    |90061/173481[27:00<23:51,58.28it/s] 52%|#####2    |90693/173481[27:11<23:40,58.28it/s] 59%|#####8    |101979/173481[30:00<19:13,61.99it/s] 59%|#####9    |102726/173481[30:11<19:01,61.99it/s] 64%|######4   |111633/173481[33:00<17:55,57.50it/s] 65%|######4   |112196/173481[33:11<17:45,57.50it/s] 69%|######9   |119953/173481[36:00<17:24,51.25it/s] 69%|######9   |120440/173481[36:11<17:14,51.25it/s] 74%|#######3  |127736/173481[39:00<16:15,46.90it/s] 74%|#######3  |128301/173481[39:11<16:03,46.90it/s] 79%|#######8  |136798/173481[42:00<12:35,48.56it/s] 79%|#######9  |137421/173481[42:12<12:22,48.56it/s] 84%|########3 |145678/173481[45:00<09:28,48.94it/s] 84%|########4 |146247/173481[45:12<09:16,48.94it/s] 88%|########8 |153424/173481[48:00<07:17,45.79it/s] 89%|########8 |153900/173481[48:12<07:07,45.79it/s] 92%|#########1|158744/173481[51:00<06:50,35.92it/s] 92%|#########1|159363/173481[51:12<06:32,35.92it/s] 97%|#########6|168118/173481[54:00<02:06,42.52it/s] 97%|#########7|168735/173481[54:12<01:51,42.52it/s]100%|##########|173481/173481[55:46<00:00,51.84it/s]
[32m[0418 20:54:27 @base.py:257][0m Epoch 34 (global_step 5898354) finished, time:3346.28 sec.
[32m[0418 20:54:28 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-5898354.
  0%|          |0/18822[00:00<?,?it/s] 86%|########6 |16209/18822[03:00<00:29,90.05it/s] 92%|#########1|17254/18822[03:10<00:17,90.05it/s]100%|##########|18822/18822[03:26<00:00,91.27it/s]
33
[32m[0418 20:57:54 @monitor.py:363][0m QueueInput/queue_size: 0.39045
[32m[0418 20:57:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.605
[32m[0418 20:57:54 @monitor.py:363][0m activation-summaries/output-rms: 0.022108
[32m[0418 20:57:54 @monitor.py:363][0m cross_entropy_loss: 3.3343
[32m[0418 20:57:54 @monitor.py:363][0m last_linear/W_0_percent_n: 0.28146
[32m[0418 20:57:54 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16625
[32m[0418 20:57:54 @monitor.py:363][0m last_linear/W_0_sparsity: 0.5517
[32m[0418 20:57:54 @monitor.py:363][0m last_linear/Wn_0: 0.23893
[32m[0418 20:57:54 @monitor.py:363][0m last_linear/Wp_0: 0.20953
[32m[0418 20:57:54 @monitor.py:363][0m linear0/W_0_percent_n: 0.12611
[32m[0418 20:57:54 @monitor.py:363][0m linear0/W_0_percent_p: 0.14241
[32m[0418 20:57:54 @monitor.py:363][0m linear0/W_0_sparsity: 0.7307
[32m[0418 20:57:54 @monitor.py:363][0m linear0/Wn_0: 1.0006
[32m[0418 20:57:54 @monitor.py:363][0m linear0/Wp_0: 1.0642
[32m[0418 20:57:54 @monitor.py:363][0m linear1/W_0_percent_n: 0.1701
[32m[0418 20:57:54 @monitor.py:363][0m linear1/W_0_percent_p: 0.1391
[32m[0418 20:57:54 @monitor.py:363][0m linear1/W_0_sparsity: 0.68974
[32m[0418 20:57:54 @monitor.py:363][0m linear1/Wn_0: 0.95825
[32m[0418 20:57:54 @monitor.py:363][0m linear1/Wp_0: 0.99572
[32m[0418 20:57:54 @monitor.py:363][0m linear2/W_0_percent_n: 0.036026
[32m[0418 20:57:54 @monitor.py:363][0m linear2/W_0_percent_p: 0.044266
[32m[0418 20:57:54 @monitor.py:363][0m linear2/W_0_sparsity: 0.91933
[32m[0418 20:57:54 @monitor.py:363][0m linear2/Wn_0: 1.1153
[32m[0418 20:57:54 @monitor.py:363][0m linear2/Wp_0: 0.92335
[32m[0418 20:57:54 @monitor.py:363][0m linear3/W_0_percent_n: 0.04187
[32m[0418 20:57:54 @monitor.py:363][0m linear3/W_0_percent_p: 0.037704
[32m[0418 20:57:54 @monitor.py:363][0m linear3/W_0_sparsity: 0.92017
[32m[0418 20:57:54 @monitor.py:363][0m linear3/Wn_0: 0.94298
[32m[0418 20:57:54 @monitor.py:363][0m linear3/Wp_0: 0.89453
[32m[0418 20:57:54 @monitor.py:363][0m lr: 2.4414e-07
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4945
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0963
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2204
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4246
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5767
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5997
[32m[0418 20:57:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 20:57:54 @monitor.py:363][0m train-error-top1: 0.78056
[32m[0418 20:57:54 @monitor.py:363][0m val-error-top1: 0.82414
[32m[0418 20:57:54 @monitor.py:363][0m val-utt-error: 0.63176
[32m[0418 20:57:54 @monitor.py:363][0m validation_cost: 3.6266
[32m[0418 20:57:54 @monitor.py:363][0m wd_cost: 9.766e-07
[32m[0418 20:57:54 @group.py:42][0m Callbacks took 206.529 sec in total. InferenceRunner: 206.249sec
[32m[0418 20:57:54 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8470/173481[03:00<58:26,47.05it/s]  5%|5         |8940/173481[03:10<58:16,47.05it/s] 10%|9         |16885/173481[06:00<55:39,46.89it/s] 10%|#         |17478/173481[06:10<55:27,46.89it/s] 15%|#5        |26137/173481[09:00<50:05,49.02it/s] 15%|#5        |26610/173481[09:10<49:55,49.02it/s] 21%|##1       |37225/173481[12:00<41:35,54.59it/s] 22%|##1       |37971/173481[12:10<41:22,54.59it/s] 28%|##8       |48848/173481[15:00<35:06,59.16it/s] 28%|##8       |49362/173481[15:10<34:57,59.16it/s] 33%|###2      |56773/173481[18:00<38:31,50.48it/s] 33%|###3      |57252/173481[18:10<38:22,50.48it/s] 37%|###7      |64541/173481[21:00<39:01,46.53it/s] 37%|###7      |64995/173481[21:10<38:51,46.53it/s] 42%|####1     |72001/173481[24:00<38:35,43.83it/s] 42%|####1     |72526/173481[24:11<38:23,43.83it/s] 46%|####5     |79453/173481[27:00<36:48,42.57it/s] 46%|####6     |79890/173481[27:11<36:38,42.57it/s] 50%|#####     |86755/173481[30:00<34:48,41.53it/s] 50%|#####     |87198/173481[30:11<34:37,41.53it/s] 54%|#####4    |94386/173481[33:00<31:25,41.96it/s] 55%|#####4    |95010/173481[33:11<31:10,41.96it/s] 60%|#####9    |103322/173481[36:00<25:42,45.48it/s] 60%|#####9    |103848/173481[36:11<25:31,45.48it/s] 65%|######4   |112286/173481[39:00<21:27,47.54it/s] 65%|######5   |112813/173481[39:11<21:16,47.54it/s] 70%|######9   |121064/173481[42:00<18:08,48.15it/s] 70%|#######   |121618/173481[42:11<17:57,48.15it/s] 74%|#######4  |128521/173481[45:00<16:49,44.52it/s] 74%|#######4  |129042/173481[45:12<16:38,44.52it/s] 79%|#######8  |136705/173481[48:00<13:37,44.98it/s] 79%|#######9  |137256/173481[48:12<13:25,44.98it/s] 84%|########3 |145261/173481[51:00<10:10,46.22it/s] 84%|########4 |145764/173481[51:12<09:59,46.22it/s] 88%|########8 |153379/173481[54:00<07:20,45.64it/s] 89%|########8 |153956/173481[54:12<07:07,45.64it/s] 93%|#########3|162049/173481[57:00<04:03,46.86it/s] 94%|#########3|162630/173481[57:12<03:51,46.86it/s]100%|##########|173481/173481[59:53<00:00,48.27it/s]
[32m[0418 21:57:48 @base.py:257][0m Epoch 35 (global_step 6071835) finished, time:3593.96 sec.
[32m[0418 21:57:48 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-6071835.
[32m[0418 21:57:48 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.73it/s]
34
[32m[0418 22:00:13 @monitor.py:363][0m QueueInput/queue_size: 0.87171
[32m[0418 22:00:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.652
[32m[0418 22:00:13 @monitor.py:363][0m activation-summaries/output-rms: 0.023082
[32m[0418 22:00:13 @monitor.py:363][0m cross_entropy_loss: 3.2909
[32m[0418 22:00:13 @monitor.py:363][0m last_linear/W_0_percent_n: 0.28068
[32m[0418 22:00:13 @monitor.py:363][0m last_linear/W_0_percent_p: 0.16555
[32m[0418 22:00:13 @monitor.py:363][0m last_linear/W_0_sparsity: 0.55317
[32m[0418 22:00:13 @monitor.py:363][0m last_linear/Wn_0: 0.24112
[32m[0418 22:00:13 @monitor.py:363][0m last_linear/Wp_0: 0.21221
[32m[0418 22:00:13 @monitor.py:363][0m linear0/W_0_percent_n: 0.12678
[32m[0418 22:00:13 @monitor.py:363][0m linear0/W_0_percent_p: 0.14237
[32m[0418 22:00:13 @monitor.py:363][0m linear0/W_0_sparsity: 0.73003
[32m[0418 22:00:13 @monitor.py:363][0m linear0/Wn_0: 1.0009
[32m[0418 22:00:13 @monitor.py:363][0m linear0/Wp_0: 1.0657
[32m[0418 22:00:13 @monitor.py:363][0m linear1/W_0_percent_n: 0.16864
[32m[0418 22:00:13 @monitor.py:363][0m linear1/W_0_percent_p: 0.13875
[32m[0418 22:00:13 @monitor.py:363][0m linear1/W_0_sparsity: 0.69165
[32m[0418 22:00:13 @monitor.py:363][0m linear1/Wn_0: 0.95816
[32m[0418 22:00:13 @monitor.py:363][0m linear1/Wp_0: 0.99889
[32m[0418 22:00:13 @monitor.py:363][0m linear2/W_0_percent_n: 0.035461
[32m[0418 22:00:13 @monitor.py:363][0m linear2/W_0_percent_p: 0.044434
[32m[0418 22:00:13 @monitor.py:363][0m linear2/W_0_sparsity: 0.91982
[32m[0418 22:00:13 @monitor.py:363][0m linear2/Wn_0: 1.1157
[32m[0418 22:00:13 @monitor.py:363][0m linear2/Wp_0: 0.92646
[32m[0418 22:00:13 @monitor.py:363][0m linear3/W_0_percent_n: 0.041992
[32m[0418 22:00:13 @monitor.py:363][0m linear3/W_0_percent_p: 0.037521
[32m[0418 22:00:13 @monitor.py:363][0m linear3/W_0_sparsity: 0.92017
[32m[0418 22:00:13 @monitor.py:363][0m linear3/Wn_0: 0.94908
[32m[0418 22:00:13 @monitor.py:363][0m linear3/Wp_0: 0.89411
[32m[0418 22:00:13 @monitor.py:363][0m lr: 2.4414e-07
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4943
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0965
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2207
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4248
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5997
[32m[0418 22:00:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 22:00:13 @monitor.py:363][0m train-error-top1: 0.78093
[32m[0418 22:00:13 @monitor.py:363][0m val-error-top1: 0.84085
[32m[0418 22:00:13 @monitor.py:363][0m val-utt-error: 0.7165
[32m[0418 22:00:13 @monitor.py:363][0m validation_cost: 3.7494
[32m[0418 22:00:13 @monitor.py:363][0m wd_cost: 9.7671e-07
[32m[0418 22:00:13 @group.py:42][0m Callbacks took 145.522 sec in total. InferenceRunner: 145.111sec
[32m[0418 22:00:13 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10184/173481[03:00<48:06,56.58it/s]  6%|6         |10785/173481[03:10<47:55,56.58it/s] 11%|#1        |19793/173481[06:00<46:37,54.93it/s] 12%|#1        |20341/173481[06:10<46:27,54.93it/s] 16%|#6        |28302/173481[09:00<47:37,50.81it/s] 17%|#6        |28803/173481[09:10<47:27,50.81it/s] 21%|##1       |36670/173481[12:00<46:57,48.55it/s] 21%|##1       |37173/173481[12:10<46:47,48.55it/s] 26%|##6       |45184/173481[15:00<44:37,47.92it/s] 26%|##6       |45729/173481[15:10<44:26,47.92it/s] 31%|###       |53492/173481[18:00<42:31,47.02it/s] 31%|###1      |53955/173481[18:10<42:22,47.02it/s] 35%|###5      |61432/173481[21:00<41:01,45.51it/s] 36%|###5      |61905/173481[21:10<40:51,45.51it/s] 40%|####      |70008/173481[24:00<37:02,46.55it/s] 41%|####      |70479/173481[24:11<36:52,46.55it/s] 45%|####5     |78226/173481[27:00<34:26,46.10it/s] 45%|####5     |78729/173481[27:11<34:15,46.10it/s] 50%|####9     |86374/173481[30:00<31:47,45.68it/s] 50%|#####     |86842/173481[30:11<31:36,45.68it/s] 54%|#####3    |93286/173481[33:00<32:04,41.66it/s] 54%|#####3    |93543/173481[33:11<31:58,41.66it/s] 58%|#####8    |101140/173481[36:00<28:17,42.62it/s] 59%|#####8    |101703/173481[36:11<28:04,42.62it/s] 63%|######3   |109390/173481[39:00<24:11,44.16it/s] 63%|######3   |109930/173481[39:11<23:59,44.16it/s] 68%|######8   |118498/173481[42:00<19:26,47.15it/s] 69%|######8   |119259/173481[42:12<19:09,47.15it/s] 76%|#######5  |131212/173481[45:00<12:27,56.55it/s] 76%|#######6  |132053/173481[45:12<12:12,56.55it/s] 82%|########1 |141460/173481[48:00<09:24,56.74it/s] 82%|########1 |142065/173481[48:12<09:13,56.74it/s] 87%|########7 |151294/173481[51:00<06:38,55.66it/s] 88%|########7 |151941/173481[51:12<06:26,55.66it/s] 93%|#########2|161089/173481[54:00<03:45,55.03it/s] 93%|#########3|161703/173481[54:12<03:34,55.03it/s] 98%|#########8|170739/173481[57:00<00:50,54.31it/s] 99%|#########8|171385/173481[57:12<00:38,54.31it/s]100%|##########|173481/173481[57:52<00:00,49.96it/s]
[32m[0418 22:58:06 @base.py:257][0m Epoch 36 (global_step 6245316) finished, time:3472.32 sec.
[32m[0418 22:58:06 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:55<00:00,107.39it/s]
35
[32m[0418 23:01:02 @monitor.py:363][0m QueueInput/queue_size: 0.64923
[32m[0418 23:01:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.9099
[32m[0418 23:01:02 @monitor.py:363][0m activation-summaries/output-rms: 0.028113
[32m[0418 23:01:02 @monitor.py:363][0m cross_entropy_loss: 3.2995
[32m[0418 23:01:02 @monitor.py:363][0m last_linear/W_0_percent_n: 0.25017
[32m[0418 23:01:02 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17073
[32m[0418 23:01:02 @monitor.py:363][0m last_linear/W_0_sparsity: 0.57825
[32m[0418 23:01:02 @monitor.py:363][0m last_linear/Wn_0: 0.24186
[32m[0418 23:01:02 @monitor.py:363][0m last_linear/Wp_0: 0.21651
[32m[0418 23:01:02 @monitor.py:363][0m linear0/W_0_percent_n: 0.12612
[32m[0418 23:01:02 @monitor.py:363][0m linear0/W_0_percent_p: 0.14162
[32m[0418 23:01:02 @monitor.py:363][0m linear0/W_0_sparsity: 0.73077
[32m[0418 23:01:02 @monitor.py:363][0m linear0/Wn_0: 1.0016
[32m[0418 23:01:02 @monitor.py:363][0m linear0/Wp_0: 1.0666
[32m[0418 23:01:02 @monitor.py:363][0m linear1/W_0_percent_n: 0.17001
[32m[0418 23:01:02 @monitor.py:363][0m linear1/W_0_percent_p: 0.13701
[32m[0418 23:01:02 @monitor.py:363][0m linear1/W_0_sparsity: 0.69066
[32m[0418 23:01:02 @monitor.py:363][0m linear1/Wn_0: 0.95904
[32m[0418 23:01:02 @monitor.py:363][0m linear1/Wp_0: 1.0007
[32m[0418 23:01:02 @monitor.py:363][0m linear2/W_0_percent_n: 0.035706
[32m[0418 23:01:02 @monitor.py:363][0m linear2/W_0_percent_p: 0.044022
[32m[0418 23:01:02 @monitor.py:363][0m linear2/W_0_sparsity: 0.91962
[32m[0418 23:01:02 @monitor.py:363][0m linear2/Wn_0: 1.1172
[32m[0418 23:01:02 @monitor.py:363][0m linear2/Wp_0: 0.92795
[32m[0418 23:01:02 @monitor.py:363][0m linear3/W_0_percent_n: 0.041855
[32m[0418 23:01:02 @monitor.py:363][0m linear3/W_0_percent_p: 0.037323
[32m[0418 23:01:02 @monitor.py:363][0m linear3/W_0_sparsity: 0.9202
[32m[0418 23:01:02 @monitor.py:363][0m linear3/Wn_0: 0.95204
[32m[0418 23:01:02 @monitor.py:363][0m linear3/Wp_0: 0.89621
[32m[0418 23:01:02 @monitor.py:363][0m lr: 1.2207e-07
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4941
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0966
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2208
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4248
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5997
[32m[0418 23:01:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 23:01:02 @monitor.py:363][0m train-error-top1: 0.77397
[32m[0418 23:01:02 @monitor.py:363][0m val-error-top1: 0.83135
[32m[0418 23:01:02 @monitor.py:363][0m val-utt-error: 0.68978
[32m[0418 23:01:02 @monitor.py:363][0m validation_cost: 3.7086
[32m[0418 23:01:02 @monitor.py:363][0m wd_cost: 1.9535e-07
[32m[0418 23:01:02 @group.py:42][0m Callbacks took 176.048 sec in total. InferenceRunner: 175.294sec
[32m[0418 23:01:02 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10531/173481[03:00<46:25,58.50it/s]  6%|6         |11102/173481[03:10<46:15,58.50it/s] 11%|#1        |19731/173481[06:00<46:58,54.56it/s] 12%|#1        |20301/173481[06:10<46:47,54.56it/s] 17%|#7        |29635/173481[09:00<43:45,54.78it/s] 17%|#7        |30230/173481[09:10<43:34,54.78it/s] 23%|##2       |39700/173481[12:00<40:17,55.34it/s] 23%|##3       |40272/173481[12:10<40:06,55.34it/s] 29%|##8       |49753/173481[15:00<37:05,55.59it/s] 29%|##9       |50354/173481[15:10<36:54,55.59it/s] 34%|###4      |59815/173481[18:00<33:59,55.74it/s] 35%|###4      |60439/173481[18:10<33:47,55.74it/s] 40%|####      |69925/173481[21:00<30:50,55.95it/s] 41%|####      |70601/173481[21:11<30:38,55.95it/s] 46%|####6     |80194/173481[24:00<27:31,56.49it/s] 47%|####6     |80820/173481[24:11<27:20,56.49it/s] 52%|#####1    |89677/173481[27:00<25:37,54.52it/s] 52%|#####2    |90270/173481[27:11<25:26,54.52it/s] 57%|#####7    |99121/173481[30:00<23:10,53.47it/s] 57%|#####7    |99684/173481[30:11<23:00,53.47it/s] 63%|######3   |109585/173481[33:00<19:07,55.70it/s] 64%|######3   |110215/173481[33:11<18:55,55.70it/s] 68%|######7   |117661/173481[36:00<18:43,49.66it/s] 68%|######8   |118068/173481[36:11<18:35,49.66it/s] 71%|#######1  |123979/173481[39:00<20:03,41.12it/s] 72%|#######1  |124326/173481[39:11<19:55,41.12it/s] 75%|#######4  |129689/173481[42:00<20:22,35.81it/s] 75%|#######4  |130056/173481[42:12<20:12,35.81it/s] 79%|#######8  |136909/173481[45:00<16:06,37.84it/s] 79%|#######9  |137514/173481[45:12<15:50,37.84it/s] 85%|########5 |147739/173481[48:00<09:14,46.46it/s] 86%|########5 |148656/173481[48:12<08:54,46.46it/s] 91%|#########1|158521/173481[51:00<04:45,52.32it/s] 92%|#########1|159179/173481[51:12<04:33,52.32it/s] 97%|#########7|168530/173481[54:00<01:31,53.91it/s] 98%|#########7|169251/173481[54:12<01:18,53.91it/s]100%|##########|173481/173481[55:26<00:00,52.15it/s]
[32m[0418 23:56:28 @base.py:257][0m Epoch 37 (global_step 6418797) finished, time:3326.68 sec.
[32m[0418 23:56:28 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:55<00:00,107.00it/s]
36
[32m[0418 23:59:24 @monitor.py:363][0m QueueInput/queue_size: 1.0255
[32m[0418 23:59:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.7307
[32m[0418 23:59:24 @monitor.py:363][0m activation-summaries/output-rms: 0.023515
[32m[0418 23:59:24 @monitor.py:363][0m cross_entropy_loss: 3.207
[32m[0418 23:59:24 @monitor.py:363][0m last_linear/W_0_percent_n: 0.24502
[32m[0418 23:59:24 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17093
[32m[0418 23:59:24 @monitor.py:363][0m last_linear/W_0_sparsity: 0.58356
[32m[0418 23:59:24 @monitor.py:363][0m last_linear/Wn_0: 0.24171
[32m[0418 23:59:24 @monitor.py:363][0m last_linear/Wp_0: 0.22248
[32m[0418 23:59:24 @monitor.py:363][0m linear0/W_0_percent_n: 0.12573
[32m[0418 23:59:24 @monitor.py:363][0m linear0/W_0_percent_p: 0.14176
[32m[0418 23:59:24 @monitor.py:363][0m linear0/W_0_sparsity: 0.73093
[32m[0418 23:59:24 @monitor.py:363][0m linear0/Wn_0: 1.0024
[32m[0418 23:59:24 @monitor.py:363][0m linear0/Wp_0: 1.0673
[32m[0418 23:59:24 @monitor.py:363][0m linear1/W_0_percent_n: 0.16881
[32m[0418 23:59:24 @monitor.py:363][0m linear1/W_0_percent_p: 0.13727
[32m[0418 23:59:24 @monitor.py:363][0m linear1/W_0_sparsity: 0.69176
[32m[0418 23:59:24 @monitor.py:363][0m linear1/Wn_0: 0.96031
[32m[0418 23:59:24 @monitor.py:363][0m linear1/Wp_0: 1.0019
[32m[0418 23:59:24 @monitor.py:363][0m linear2/W_0_percent_n: 0.035812
[32m[0418 23:59:24 @monitor.py:363][0m linear2/W_0_percent_p: 0.04393
[32m[0418 23:59:24 @monitor.py:363][0m linear2/W_0_sparsity: 0.91951
[32m[0418 23:59:24 @monitor.py:363][0m linear2/Wn_0: 1.1192
[32m[0418 23:59:24 @monitor.py:363][0m linear2/Wp_0: 0.92881
[32m[0418 23:59:24 @monitor.py:363][0m linear3/W_0_percent_n: 0.042145
[32m[0418 23:59:24 @monitor.py:363][0m linear3/W_0_percent_p: 0.037094
[32m[0418 23:59:24 @monitor.py:363][0m linear3/W_0_sparsity: 0.9201
[32m[0418 23:59:24 @monitor.py:363][0m linear3/Wn_0: 0.95312
[32m[0418 23:59:24 @monitor.py:363][0m linear3/Wp_0: 0.9
[32m[0418 23:59:24 @monitor.py:363][0m lr: 1.2207e-07
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4941
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2209
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0418 23:59:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0418 23:59:24 @monitor.py:363][0m train-error-top1: 0.76654
[32m[0418 23:59:24 @monitor.py:363][0m val-error-top1: 0.83305
[32m[0418 23:59:24 @monitor.py:363][0m val-utt-error: 0.68468
[32m[0418 23:59:24 @monitor.py:363][0m validation_cost: 3.7603
[32m[0418 23:59:24 @monitor.py:363][0m wd_cost: 1.9536e-07
[32m[0418 23:59:24 @group.py:42][0m Callbacks took 176.074 sec in total. InferenceRunner: 175.920sec
[32m[0418 23:59:24 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10931/173481[03:00<44:36,60.73it/s]  7%|6         |11463/173481[03:10<44:28,60.73it/s] 12%|#1        |20230/173481[06:00<45:45,55.82it/s] 12%|#1        |20745/173481[06:10<45:36,55.82it/s] 17%|#6        |29152/173481[09:00<45:48,52.50it/s] 17%|#7        |29691/173481[09:10<45:38,52.50it/s] 22%|##2       |38404/173481[12:00<43:20,51.94it/s] 22%|##2       |38954/173481[12:10<43:10,51.94it/s] 28%|##7       |47806/173481[15:00<40:13,52.08it/s] 28%|##7       |48350/173481[15:10<40:02,52.08it/s] 33%|###3      |57406/173481[18:00<36:42,52.69it/s] 33%|###3      |57591/173481[18:10<36:39,52.69it/s] 39%|###8      |66850/173481[21:00<33:48,52.57it/s] 39%|###8      |67281/173481[21:11<33:40,52.57it/s] 44%|####4     |76353/173481[24:00<30:43,52.68it/s] 44%|####4     |76911/173481[24:11<30:33,52.68it/s] 49%|####9     |85567/173481[27:00<28:13,51.92it/s] 50%|####9     |86127/173481[27:11<28:02,51.92it/s] 54%|#####4    |94360/173481[30:00<26:11,50.34it/s] 55%|#####4    |94911/173481[30:11<26:00,50.34it/s] 59%|#####9    |103141/173481[33:00<23:39,49.55it/s] 60%|#####9    |103692/173481[33:11<23:28,49.55it/s] 65%|######5   |113564/173481[36:00<18:42,53.40it/s] 66%|######5   |114159/173481[36:11<18:30,53.40it/s] 71%|#######   |123165/173481[39:00<15:42,53.37it/s] 71%|#######1  |123822/173481[39:11<15:30,53.37it/s] 78%|#######8  |136175/173481[42:00<10:07,61.40it/s] 79%|#######8  |136911/173481[42:11<09:55,61.40it/s] 85%|########4 |146818/173481[45:00<07:22,60.24it/s] 85%|########4 |147417/173481[45:12<07:12,60.24it/s] 90%|######### |156388/173481[48:00<05:02,56.47it/s] 90%|######### |156993/173481[48:12<04:51,56.47it/s] 96%|#########5|165868/173481[51:00<02:19,54.50it/s] 96%|#########5|166490/173481[51:12<02:08,54.50it/s]100%|##########|173481/173481[53:25<00:00,54.12it/s]
[32m[0419 00:52:50 @base.py:257][0m Epoch 38 (global_step 6592278) finished, time:3205.46 sec.
[32m[0419 00:52:50 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-6592278.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:40<00:00,116.91it/s]
37
[32m[0419 00:55:31 @monitor.py:363][0m QueueInput/queue_size: 0.57324
[32m[0419 00:55:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.5882
[32m[0419 00:55:31 @monitor.py:363][0m activation-summaries/output-rms: 0.022053
[32m[0419 00:55:31 @monitor.py:363][0m cross_entropy_loss: 3.254
[32m[0419 00:55:31 @monitor.py:363][0m last_linear/W_0_percent_n: 0.24061
[32m[0419 00:55:31 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17099
[32m[0419 00:55:31 @monitor.py:363][0m last_linear/W_0_sparsity: 0.58761
[32m[0419 00:55:31 @monitor.py:363][0m last_linear/Wn_0: 0.24051
[32m[0419 00:55:31 @monitor.py:363][0m last_linear/Wp_0: 0.22733
[32m[0419 00:55:31 @monitor.py:363][0m linear0/W_0_percent_n: 0.12602
[32m[0419 00:55:31 @monitor.py:363][0m linear0/W_0_percent_p: 0.14242
[32m[0419 00:55:31 @monitor.py:363][0m linear0/W_0_sparsity: 0.73006
[32m[0419 00:55:31 @monitor.py:363][0m linear0/Wn_0: 1.0032
[32m[0419 00:55:31 @monitor.py:363][0m linear0/Wp_0: 1.0679
[32m[0419 00:55:31 @monitor.py:363][0m linear1/W_0_percent_n: 0.16887
[32m[0419 00:55:31 @monitor.py:363][0m linear1/W_0_percent_p: 0.1377
[32m[0419 00:55:31 @monitor.py:363][0m linear1/W_0_sparsity: 0.69121
[32m[0419 00:55:31 @monitor.py:363][0m linear1/Wn_0: 0.96151
[32m[0419 00:55:31 @monitor.py:363][0m linear1/Wp_0: 1.0031
[32m[0419 00:55:31 @monitor.py:363][0m linear2/W_0_percent_n: 0.035812
[32m[0419 00:55:31 @monitor.py:363][0m linear2/W_0_percent_p: 0.043793
[32m[0419 00:55:31 @monitor.py:363][0m linear2/W_0_sparsity: 0.91957
[32m[0419 00:55:31 @monitor.py:363][0m linear2/Wn_0: 1.121
[32m[0419 00:55:31 @monitor.py:363][0m linear2/Wp_0: 0.92986
[32m[0419 00:55:31 @monitor.py:363][0m linear3/W_0_percent_n: 0.041962
[32m[0419 00:55:31 @monitor.py:363][0m linear3/W_0_percent_p: 0.036865
[32m[0419 00:55:31 @monitor.py:363][0m linear3/W_0_sparsity: 0.92061
[32m[0419 00:55:31 @monitor.py:363][0m linear3/Wn_0: 0.95469
[32m[0419 00:55:31 @monitor.py:363][0m linear3/Wp_0: 0.90332
[32m[0419 00:55:31 @monitor.py:363][0m lr: 1.2207e-07
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.494
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2209
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 00:55:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 00:55:31 @monitor.py:363][0m train-error-top1: 0.76645
[32m[0419 00:55:31 @monitor.py:363][0m val-error-top1: 0.82923
[32m[0419 00:55:31 @monitor.py:363][0m val-utt-error: 0.65562
[32m[0419 00:55:31 @monitor.py:363][0m validation_cost: 3.731
[32m[0419 00:55:31 @monitor.py:363][0m wd_cost: 1.9536e-07
[32m[0419 00:55:31 @group.py:42][0m Callbacks took 161.184 sec in total. InferenceRunner: 161.020sec
[32m[0419 00:55:31 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10978/173481[03:00<44:24,60.99it/s]  7%|6         |11535/173481[03:10<44:15,60.99it/s] 12%|#1        |20773/173481[06:00<44:15,57.50it/s] 12%|#2        |21364/173481[06:10<44:05,57.50it/s] 18%|#7        |31189/173481[09:00<41:07,57.68it/s] 18%|#8        |31788/173481[09:10<40:56,57.68it/s] 24%|##3       |41423/173481[12:00<38:26,57.26it/s] 24%|##4       |42015/173481[12:10<38:15,57.26it/s] 29%|##9       |51097/173481[15:00<36:48,55.41it/s] 30%|##9       |51432/173481[15:10<36:42,55.41it/s] 33%|###3      |57523/173481[18:00<44:33,43.37it/s] 33%|###3      |57920/173481[18:10<44:24,43.37it/s] 39%|###8      |67558/173481[21:00<36:11,48.79it/s] 39%|###9      |68111/173481[21:11<35:59,48.79it/s] 44%|####3     |76267/173481[24:00<33:21,48.57it/s] 44%|####4     |76884/173481[24:11<33:08,48.57it/s] 50%|#####     |86887/173481[27:00<27:05,53.28it/s] 50%|#####     |87486/173481[27:11<26:54,53.28it/s] 56%|#####6    |97681/173481[30:00<22:23,56.42it/s] 57%|#####6    |98358/173481[30:11<22:11,56.42it/s] 62%|######1   |107233/173481[33:00<20:11,54.68it/s] 62%|######2   |107802/173481[33:11<20:01,54.68it/s] 67%|######7   |116749/173481[36:00<17:35,53.76it/s] 68%|######7   |117323/173481[36:11<17:24,53.76it/s] 73%|#######2  |126310/173481[39:00<14:42,53.43it/s] 73%|#######3  |126889/173481[39:11<14:31,53.43it/s] 78%|#######8  |135715/173481[42:00<11:54,52.83it/s] 79%|#######8  |136302/173481[42:12<11:43,52.83it/s] 84%|########3 |145191/173481[45:01<08:56,52.74it/s] 84%|########4 |145788/173481[45:12<08:45,52.74it/s] 91%|######### |157546/173481[48:01<04:27,59.65it/s] 91%|#########1|158373/173481[48:12<04:13,59.65it/s] 97%|#########7|168916/173481[51:01<01:14,61.35it/s] 98%|#########7|169577/173481[51:12<01:03,61.35it/s]100%|##########|173481/173481[52:25<00:00,55.16it/s]
[32m[0419 01:47:56 @base.py:257][0m Epoch 39 (global_step 6765759) finished, time:3145.31 sec.
[32m[0419 01:47:57 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-6765759.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:41<00:00,116.64it/s]
38
[32m[0419 01:50:38 @monitor.py:363][0m QueueInput/queue_size: 0.51095
[32m[0419 01:50:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.014
[32m[0419 01:50:38 @monitor.py:363][0m activation-summaries/output-rms: 0.021545
[32m[0419 01:50:38 @monitor.py:363][0m cross_entropy_loss: 3.1861
[32m[0419 01:50:38 @monitor.py:363][0m last_linear/W_0_percent_n: 0.20574
[32m[0419 01:50:38 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17212
[32m[0419 01:50:38 @monitor.py:363][0m last_linear/W_0_sparsity: 0.62198
[32m[0419 01:50:38 @monitor.py:363][0m last_linear/Wn_0: 0.24308
[32m[0419 01:50:38 @monitor.py:363][0m last_linear/Wp_0: 0.23291
[32m[0419 01:50:38 @monitor.py:363][0m linear0/W_0_percent_n: 0.12387
[32m[0419 01:50:38 @monitor.py:363][0m linear0/W_0_percent_p: 0.13921
[32m[0419 01:50:38 @monitor.py:363][0m linear0/W_0_sparsity: 0.7337
[32m[0419 01:50:38 @monitor.py:363][0m linear0/Wn_0: 1.0037
[32m[0419 01:50:38 @monitor.py:363][0m linear0/Wp_0: 1.0682
[32m[0419 01:50:38 @monitor.py:363][0m linear1/W_0_percent_n: 0.16814
[32m[0419 01:50:38 @monitor.py:363][0m linear1/W_0_percent_p: 0.13332
[32m[0419 01:50:38 @monitor.py:363][0m linear1/W_0_sparsity: 0.69469
[32m[0419 01:50:38 @monitor.py:363][0m linear1/Wn_0: 0.96191
[32m[0419 01:50:38 @monitor.py:363][0m linear1/Wp_0: 1.0039
[32m[0419 01:50:38 @monitor.py:363][0m linear2/W_0_percent_n: 0.035324
[32m[0419 01:50:38 @monitor.py:363][0m linear2/W_0_percent_p: 0.043732
[32m[0419 01:50:38 @monitor.py:363][0m linear2/W_0_sparsity: 0.91975
[32m[0419 01:50:38 @monitor.py:363][0m linear2/Wn_0: 1.122
[32m[0419 01:50:38 @monitor.py:363][0m linear2/Wp_0: 0.92995
[32m[0419 01:50:38 @monitor.py:363][0m linear3/W_0_percent_n: 0.041931
[32m[0419 01:50:38 @monitor.py:363][0m linear3/W_0_percent_p: 0.037064
[32m[0419 01:50:38 @monitor.py:363][0m linear3/W_0_sparsity: 0.91995
[32m[0419 01:50:38 @monitor.py:363][0m linear3/Wn_0: 0.95519
[32m[0419 01:50:38 @monitor.py:363][0m linear3/Wp_0: 0.90682
[32m[0419 01:50:38 @monitor.py:363][0m lr: 6.1035e-08
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0968
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2209
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 01:50:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 01:50:38 @monitor.py:363][0m train-error-top1: 0.76711
[32m[0419 01:50:38 @monitor.py:363][0m val-error-top1: 0.78955
[32m[0419 01:50:38 @monitor.py:363][0m val-utt-error: 0.55334
[32m[0419 01:50:38 @monitor.py:363][0m validation_cost: 3.3774
[32m[0419 01:50:38 @monitor.py:363][0m wd_cost: 3.9072e-08
[32m[0419 01:50:38 @group.py:42][0m Callbacks took 161.623 sec in total. InferenceRunner: 161.379sec
[32m[0419 01:50:38 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11050/173481[03:00<44:06,61.37it/s]  7%|6         |11577/173481[03:10<43:58,61.37it/s] 12%|#1        |20416/173481[06:00<45:18,56.31it/s] 12%|#2        |20931/173481[06:10<45:08,56.31it/s] 17%|#7        |30286/173481[09:00<42:57,55.56it/s] 18%|#7        |30966/173481[09:10<42:45,55.56it/s] 25%|##4       |43210/173481[12:00<34:39,62.64it/s] 25%|##5       |44031/173481[12:10<34:26,62.64it/s] 32%|###2      |56314/173481[15:00<29:01,67.29it/s] 33%|###2      |56447/173481[15:10<28:59,67.29it/s] 40%|####      |70084/173481[18:00<24:04,71.60it/s] 41%|####      |70979/173481[18:10<23:51,71.60it/s] 48%|####7     |83135/173481[21:00<20:53,72.05it/s] 48%|####8     |83991/173481[21:11<20:42,72.05it/s] 52%|#####2    |90568/173481[24:00<26:19,52.50it/s] 53%|#####2    |91454/173481[24:11<26:02,52.50it/s] 61%|######1   |106564/173481[27:00<16:53,66.00it/s] 62%|######1   |107432/173481[27:11<16:40,66.00it/s] 70%|######9   |121269/173481[30:00<11:55,73.01it/s] 70%|#######   |122151/173481[30:11<11:43,73.01it/s] 78%|#######8  |135974/173481[33:00<08:06,77.11it/s] 79%|#######8  |136922/173481[33:11<07:54,77.11it/s] 87%|########7 |151422/173481[36:00<04:31,81.23it/s] 88%|########7 |152393/173481[36:11<04:19,81.23it/s] 96%|#########5|166399/173481[39:00<01:26,82.21it/s] 96%|#########6|167367/173481[39:11<01:14,82.21it/s]100%|##########|173481/173481[40:36<00:00,71.21it/s]
[32m[0419 02:31:14 @base.py:257][0m Epoch 40 (global_step 6939240) finished, time:2436.29 sec.
[32m[0419 02:31:15 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-6939240.
[32m[0419 02:31:15 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:51<00:00,109.85it/s]
39
[32m[0419 02:34:06 @monitor.py:363][0m QueueInput/queue_size: 0.80295
[32m[0419 02:34:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9899
[32m[0419 02:34:06 @monitor.py:363][0m activation-summaries/output-rms: 0.020941
[32m[0419 02:34:06 @monitor.py:363][0m cross_entropy_loss: 3.254
[32m[0419 02:34:06 @monitor.py:363][0m last_linear/W_0_percent_n: 0.20219
[32m[0419 02:34:06 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17201
[32m[0419 02:34:06 @monitor.py:363][0m last_linear/W_0_sparsity: 0.62566
[32m[0419 02:34:06 @monitor.py:363][0m last_linear/Wn_0: 0.24443
[32m[0419 02:34:06 @monitor.py:363][0m last_linear/Wp_0: 0.23818
[32m[0419 02:34:06 @monitor.py:363][0m linear0/W_0_percent_n: 0.12359
[32m[0419 02:34:06 @monitor.py:363][0m linear0/W_0_percent_p: 0.13918
[32m[0419 02:34:06 @monitor.py:363][0m linear0/W_0_sparsity: 0.73403
[32m[0419 02:34:06 @monitor.py:363][0m linear0/Wn_0: 1.0042
[32m[0419 02:34:06 @monitor.py:363][0m linear0/Wp_0: 1.0684
[32m[0419 02:34:06 @monitor.py:363][0m linear1/W_0_percent_n: 0.16751
[32m[0419 02:34:06 @monitor.py:363][0m linear1/W_0_percent_p: 0.13214
[32m[0419 02:34:06 @monitor.py:363][0m linear1/W_0_sparsity: 0.69647
[32m[0419 02:34:06 @monitor.py:363][0m linear1/Wn_0: 0.96218
[32m[0419 02:34:06 @monitor.py:363][0m linear1/Wp_0: 1.0047
[32m[0419 02:34:06 @monitor.py:363][0m linear2/W_0_percent_n: 0.035019
[32m[0419 02:34:06 @monitor.py:363][0m linear2/W_0_percent_p: 0.043701
[32m[0419 02:34:06 @monitor.py:363][0m linear2/W_0_sparsity: 0.91986
[32m[0419 02:34:06 @monitor.py:363][0m linear2/Wn_0: 1.1231
[32m[0419 02:34:06 @monitor.py:363][0m linear2/Wp_0: 0.9298
[32m[0419 02:34:06 @monitor.py:363][0m linear3/W_0_percent_n: 0.041504
[32m[0419 02:34:06 @monitor.py:363][0m linear3/W_0_percent_p: 0.03685
[32m[0419 02:34:06 @monitor.py:363][0m linear3/W_0_sparsity: 0.92055
[32m[0419 02:34:06 @monitor.py:363][0m linear3/Wn_0: 0.95575
[32m[0419 02:34:06 @monitor.py:363][0m linear3/Wp_0: 0.91005
[32m[0419 02:34:06 @monitor.py:363][0m lr: 6.1035e-08
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0968
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2209
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 02:34:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 02:34:06 @monitor.py:363][0m train-error-top1: 0.76204
[32m[0419 02:34:06 @monitor.py:363][0m val-error-top1: 0.78552
[32m[0419 02:34:06 @monitor.py:363][0m val-utt-error: 0.54984
[32m[0419 02:34:06 @monitor.py:363][0m validation_cost: 3.3649
[32m[0419 02:34:06 @monitor.py:363][0m wd_cost: 3.9072e-08
[32m[0419 02:34:06 @group.py:42][0m Callbacks took 171.999 sec in total. InferenceRunner: 171.360sec
[32m[0419 02:34:06 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15488/173481[03:00<30:36,86.04it/s]  9%|9         |16348/173481[03:10<30:26,86.04it/s] 18%|#8        |31267/173481[06:00<27:17,86.84it/s] 18%|#8        |32091/173481[06:10<27:08,86.84it/s] 26%|##5       |44659/173481[09:00<26:47,80.12it/s] 26%|##6       |45372/173481[09:10<26:38,80.12it/s] 33%|###2      |56453/173481[12:00<27:03,72.09it/s] 33%|###2      |57120/173481[12:10<26:54,72.09it/s] 41%|####      |70343/173481[15:00<23:03,74.54it/s] 41%|####1     |71506/173481[15:10<22:48,74.54it/s] 51%|#####1    |89119/173481[18:00<16:10,86.95it/s] 52%|#####2    |90282/173481[18:10<15:56,86.95it/s] 61%|######    |105405/173481[21:00<12:47,88.68it/s] 61%|######1   |106234/173481[21:11<12:38,88.68it/s] 69%|######8   |119374/173481[24:00<10:53,82.77it/s] 69%|######9   |120192/173481[24:11<10:43,82.77it/s] 75%|#######4  |130009/173481[27:00<10:30,68.94it/s] 75%|#######5  |130760/173481[27:11<10:19,68.94it/s] 82%|########2 |142579/173481[30:00<07:25,69.38it/s] 83%|########2 |143471/173481[30:11<07:12,69.38it/s] 90%|######### |156314/173481[33:00<03:56,72.68it/s] 91%|######### |157127/173481[33:11<03:45,72.68it/s] 98%|#########7|169522/173481[36:00<00:54,73.03it/s] 98%|#########8|170322/173481[36:11<00:43,73.03it/s]100%|##########|173481/173481[36:56<00:00,78.26it/s]
[32m[0419 03:11:03 @base.py:257][0m Epoch 41 (global_step 7112721) finished, time:2216.68 sec.
[32m[0419 03:11:03 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-7112721.
[32m[0419 03:11:04 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:34<00:00,121.75it/s]
40
[32m[0419 03:13:39 @monitor.py:363][0m QueueInput/queue_size: 0.69949
[32m[0419 03:13:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9467
[32m[0419 03:13:39 @monitor.py:363][0m activation-summaries/output-rms: 0.021348
[32m[0419 03:13:39 @monitor.py:363][0m cross_entropy_loss: 3.2485
[32m[0419 03:13:39 @monitor.py:363][0m last_linear/W_0_percent_n: 0.19239
[32m[0419 03:13:39 @monitor.py:363][0m last_linear/W_0_percent_p: 0.1722
[32m[0419 03:13:39 @monitor.py:363][0m last_linear/W_0_sparsity: 0.63534
[32m[0419 03:13:39 @monitor.py:363][0m last_linear/Wn_0: 0.24432
[32m[0419 03:13:39 @monitor.py:363][0m last_linear/Wp_0: 0.24203
[32m[0419 03:13:39 @monitor.py:363][0m linear0/W_0_percent_n: 0.12284
[32m[0419 03:13:39 @monitor.py:363][0m linear0/W_0_percent_p: 0.13855
[32m[0419 03:13:39 @monitor.py:363][0m linear0/W_0_sparsity: 0.73481
[32m[0419 03:13:39 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 03:13:39 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 03:13:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.1655
[32m[0419 03:13:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.1331
[32m[0419 03:13:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.69661
[32m[0419 03:13:39 @monitor.py:363][0m linear1/Wn_0: 0.96246
[32m[0419 03:13:39 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 03:13:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.034714
[32m[0419 03:13:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.043304
[32m[0419 03:13:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.92033
[32m[0419 03:13:39 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 03:13:39 @monitor.py:363][0m linear2/Wp_0: 0.9297
[32m[0419 03:13:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.041306
[32m[0419 03:13:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.036102
[32m[0419 03:13:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.92087
[32m[0419 03:13:39 @monitor.py:363][0m linear3/Wn_0: 0.95644
[32m[0419 03:13:39 @monitor.py:363][0m linear3/Wp_0: 0.91269
[32m[0419 03:13:39 @monitor.py:363][0m lr: 3.0518e-08
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0968
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/linear0/W-rms: 2.2209
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 03:13:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 03:13:39 @monitor.py:363][0m train-error-top1: 0.76625
[32m[0419 03:13:39 @monitor.py:363][0m val-error-top1: 0.77858
[32m[0419 03:13:39 @monitor.py:363][0m val-utt-error: 0.5578
[32m[0419 03:13:39 @monitor.py:363][0m validation_cost: 3.3061
[32m[0419 03:13:39 @monitor.py:363][0m wd_cost: 3.9073e-08
[32m[0419 03:13:39 @group.py:42][0m Callbacks took 155.727 sec in total. InferenceRunner: 154.620sec
[32m[0419 03:13:39 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15616/173481[03:00<30:20,86.74it/s]  9%|9         |16415/173481[03:10<30:10,86.74it/s] 17%|#7        |29771/173481[06:00<29:02,82.49it/s] 18%|#7        |30559/173481[06:10<28:52,82.49it/s] 26%|##5       |44319/173481[09:00<26:21,81.65it/s] 26%|##6       |45197/173481[09:10<26:11,81.65it/s] 34%|###3      |58959/173481[12:00<23:25,81.49it/s] 34%|###4      |59812/173481[12:10<23:14,81.49it/s] 43%|####2     |73942/173481[15:00<20:08,82.35it/s] 43%|####3     |74913/173481[15:10<19:56,82.35it/s] 52%|#####1    |89428/173481[18:00<16:38,84.15it/s] 52%|#####2    |90219/173481[18:10<16:29,84.15it/s] 60%|######    |104632/173481[21:00<13:36,84.30it/s] 61%|######    |105603/173481[21:11<13:25,84.30it/s] 69%|######9   |120133/173481[24:00<10:26,85.20it/s] 70%|######9   |121096/173481[24:11<10:14,85.20it/s] 78%|#######7  |135246/173481[27:00<07:32,84.57it/s] 79%|#######8  |136203/173481[27:11<07:20,84.57it/s] 87%|########6 |150529/173481[30:00<04:30,84.74it/s] 87%|########7 |151487/173481[30:11<04:19,84.74it/s] 96%|#########5|165882/173481[33:00<01:29,85.01it/s] 96%|#########6|166821/173481[33:11<01:18,85.01it/s]100%|##########|173481/173481[34:34<00:00,83.61it/s]
[32m[0419 03:48:14 @base.py:257][0m Epoch 42 (global_step 7286202) finished, time:2074.95 sec.
[32m[0419 03:48:14 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-7286202.
[32m[0419 03:48:15 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:37<00:00,119.52it/s]
41
[32m[0419 03:50:52 @monitor.py:363][0m QueueInput/queue_size: 0.56179
[32m[0419 03:50:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9638
[32m[0419 03:50:52 @monitor.py:363][0m activation-summaries/output-rms: 0.022061
[32m[0419 03:50:52 @monitor.py:363][0m cross_entropy_loss: 3.2717
[32m[0419 03:50:52 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18615
[32m[0419 03:50:52 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17229
[32m[0419 03:50:52 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64154
[32m[0419 03:50:52 @monitor.py:363][0m last_linear/Wn_0: 0.24097
[32m[0419 03:50:52 @monitor.py:363][0m last_linear/Wp_0: 0.24583
[32m[0419 03:50:52 @monitor.py:363][0m linear0/W_0_percent_n: 0.12211
[32m[0419 03:50:52 @monitor.py:363][0m linear0/W_0_percent_p: 0.1382
[32m[0419 03:50:52 @monitor.py:363][0m linear0/W_0_sparsity: 0.73477
[32m[0419 03:50:52 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 03:50:52 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 03:50:52 @monitor.py:363][0m linear1/W_0_percent_n: 0.16444
[32m[0419 03:50:52 @monitor.py:363][0m linear1/W_0_percent_p: 0.13336
[32m[0419 03:50:52 @monitor.py:363][0m linear1/W_0_sparsity: 0.69505
[32m[0419 03:50:52 @monitor.py:363][0m linear1/Wn_0: 0.96334
[32m[0419 03:50:52 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 03:50:52 @monitor.py:363][0m linear2/W_0_percent_n: 0.034454
[32m[0419 03:50:52 @monitor.py:363][0m linear2/W_0_percent_p: 0.043015
[32m[0419 03:50:52 @monitor.py:363][0m linear2/W_0_sparsity: 0.92061
[32m[0419 03:50:52 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 03:50:52 @monitor.py:363][0m linear2/Wp_0: 0.92949
[32m[0419 03:50:52 @monitor.py:363][0m linear3/W_0_percent_n: 0.040802
[32m[0419 03:50:52 @monitor.py:363][0m linear3/W_0_percent_p: 0.0354
[32m[0419 03:50:52 @monitor.py:363][0m linear3/W_0_sparsity: 0.92215
[32m[0419 03:50:52 @monitor.py:363][0m linear3/Wn_0: 0.95691
[32m[0419 03:50:52 @monitor.py:363][0m linear3/Wp_0: 0.91394
[32m[0419 03:50:52 @monitor.py:363][0m lr: 3.0518e-08
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0968
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 03:50:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 03:50:52 @monitor.py:363][0m train-error-top1: 0.7758
[32m[0419 03:50:52 @monitor.py:363][0m val-error-top1: 0.7726
[32m[0419 03:50:52 @monitor.py:363][0m val-utt-error: 0.51992
[32m[0419 03:50:52 @monitor.py:363][0m validation_cost: 3.2909
[32m[0419 03:50:52 @monitor.py:363][0m wd_cost: 7.8145e-09
[32m[0419 03:50:52 @group.py:42][0m Callbacks took 158.638 sec in total. InferenceRunner: 157.492sec
[32m[0419 03:50:52 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12133/173481[03:00<39:54,67.39it/s]  7%|7         |12922/173481[03:10<39:42,67.39it/s] 15%|#5        |26568/173481[06:00<33:26,73.24it/s] 16%|#5        |27409/173481[06:10<33:14,73.24it/s] 24%|##3       |40884/173481[09:00<28:58,76.25it/s] 24%|##3       |41496/173481[09:10<28:50,76.25it/s] 30%|###       |52312/173481[12:00<29:08,69.28it/s] 31%|###       |53080/173481[12:10<28:57,69.28it/s] 37%|###7      |64770/173481[15:00<26:10,69.24it/s] 38%|###7      |65584/173481[15:10<25:58,69.24it/s] 45%|####4     |77559/173481[18:00<22:47,70.13it/s] 45%|####5     |78374/173481[18:10<22:36,70.13it/s] 52%|#####2    |90385/173481[21:00<19:35,70.68it/s] 53%|#####2    |91116/173481[21:11<19:25,70.68it/s] 59%|#####9    |102583/173481[24:00<17:04,69.19it/s] 60%|#####9    |103266/173481[24:11<16:54,69.19it/s] 66%|######6   |114625/173481[27:00<14:25,68.01it/s] 66%|######6   |115324/173481[27:11<14:15,68.01it/s] 73%|#######3  |126697/173481[30:00<11:32,67.53it/s] 73%|#######3  |127428/173481[30:11<11:21,67.53it/s] 79%|#######9  |137821/173481[33:00<09:12,64.54it/s] 80%|#######9  |138588/173481[33:11<09:00,64.54it/s] 86%|########6 |149588/173481[36:00<06:07,64.95it/s] 87%|########6 |150444/173481[36:11<05:54,64.95it/s] 93%|#########3|161746/173481[39:00<02:57,66.22it/s] 94%|#########3|162507/173481[39:11<02:45,66.22it/s]100%|##########|173481/173481[41:49<00:00,69.13it/s]
[32m[0419 04:32:42 @base.py:257][0m Epoch 43 (global_step 7459683) finished, time:2509.55 sec.
[32m[0419 04:32:42 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-7459683.
[32m[0419 04:32:42 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:42<00:00,116.11it/s]
42
[32m[0419 04:35:25 @monitor.py:363][0m QueueInput/queue_size: 1.0027
[32m[0419 04:35:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9264
[32m[0419 04:35:25 @monitor.py:363][0m activation-summaries/output-rms: 0.021095
[32m[0419 04:35:25 @monitor.py:363][0m cross_entropy_loss: 3.2406
[32m[0419 04:35:25 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18513
[32m[0419 04:35:25 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17235
[32m[0419 04:35:25 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64246
[32m[0419 04:35:25 @monitor.py:363][0m last_linear/Wn_0: 0.23671
[32m[0419 04:35:25 @monitor.py:363][0m last_linear/Wp_0: 0.25001
[32m[0419 04:35:25 @monitor.py:363][0m linear0/W_0_percent_n: 0.12157
[32m[0419 04:35:25 @monitor.py:363][0m linear0/W_0_percent_p: 0.13788
[32m[0419 04:35:25 @monitor.py:363][0m linear0/W_0_sparsity: 0.73518
[32m[0419 04:35:25 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 04:35:25 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 04:35:25 @monitor.py:363][0m linear1/W_0_percent_n: 0.16278
[32m[0419 04:35:25 @monitor.py:363][0m linear1/W_0_percent_p: 0.13295
[32m[0419 04:35:25 @monitor.py:363][0m linear1/W_0_sparsity: 0.69559
[32m[0419 04:35:25 @monitor.py:363][0m linear1/Wn_0: 0.96428
[32m[0419 04:35:25 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 04:35:25 @monitor.py:363][0m linear2/W_0_percent_n: 0.034485
[32m[0419 04:35:25 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 04:35:25 @monitor.py:363][0m linear2/W_0_sparsity: 0.92058
[32m[0419 04:35:25 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 04:35:25 @monitor.py:363][0m linear2/Wp_0: 0.92968
[32m[0419 04:35:25 @monitor.py:363][0m linear3/W_0_percent_n: 0.040771
[32m[0419 04:35:25 @monitor.py:363][0m linear3/W_0_percent_p: 0.03511
[32m[0419 04:35:25 @monitor.py:363][0m linear3/W_0_sparsity: 0.92229
[32m[0419 04:35:25 @monitor.py:363][0m linear3/Wn_0: 0.95725
[32m[0419 04:35:25 @monitor.py:363][0m linear3/Wp_0: 0.91538
[32m[0419 04:35:25 @monitor.py:363][0m lr: 3.0518e-08
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 04:35:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 04:35:25 @monitor.py:363][0m train-error-top1: 0.7619
[32m[0419 04:35:25 @monitor.py:363][0m val-error-top1: 0.7706
[32m[0419 04:35:25 @monitor.py:363][0m val-utt-error: 0.51509
[32m[0419 04:35:25 @monitor.py:363][0m validation_cost: 3.2764
[32m[0419 04:35:25 @monitor.py:363][0m wd_cost: 7.8145e-09
[32m[0419 04:35:25 @group.py:42][0m Callbacks took 162.601 sec in total. InferenceRunner: 162.118sec
[32m[0419 04:35:25 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14777/173481[03:00<32:13,82.09it/s]  9%|8         |15464/173481[03:10<32:04,82.09it/s] 16%|#5        |26938/173481[06:00<32:57,74.11it/s] 16%|#5        |27599/173481[06:10<32:48,74.11it/s] 22%|##2       |38638/173481[09:00<32:27,69.25it/s] 23%|##2       |39323/173481[09:10<32:17,69.25it/s] 29%|##9       |50612/173481[12:00<30:10,67.86it/s] 30%|##9       |51372/173481[12:10<29:59,67.86it/s] 37%|###6      |63813/173481[15:00<25:55,70.49it/s] 37%|###7      |64803/173481[15:10<25:41,70.49it/s] 44%|####4     |77189/173481[18:00<22:10,72.35it/s] 45%|####4     |77865/173481[18:10<22:01,72.35it/s] 51%|#####1    |88618/173481[21:00<20:54,67.63it/s] 52%|#####1    |89350/173481[21:10<20:43,67.63it/s] 58%|#####8    |101239/173481[24:00<17:29,68.85it/s] 59%|#####8    |102062/173481[24:11<17:17,68.85it/s] 65%|######5   |113590/173481[27:00<14:31,68.72it/s] 66%|######5   |114399/173481[27:11<14:19,68.72it/s] 73%|#######3  |126753/173481[30:00<10:59,70.86it/s] 74%|#######3  |127555/173481[30:11<10:48,70.86it/s] 80%|########  |139215/173481[33:00<08:09,70.03it/s] 81%|########  |140017/173481[33:11<07:57,70.03it/s] 87%|########7 |151264/173481[36:00<05:24,68.44it/s] 87%|########7 |151720/173481[36:11<05:17,68.44it/s] 95%|#########5|165053/173481[39:00<01:56,72.29it/s] 96%|#########5|165873/173481[39:11<01:45,72.29it/s]100%|##########|173481/173481[40:58<00:00,70.56it/s]
[32m[0419 05:16:23 @base.py:257][0m Epoch 44 (global_step 7633164) finished, time:2458.73 sec.
[32m[0419 05:16:24 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-7633164.
[32m[0419 05:16:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:41<00:00,116.24it/s]
43
[32m[0419 05:19:06 @monitor.py:363][0m QueueInput/queue_size: 0.19054
[32m[0419 05:19:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9425
[32m[0419 05:19:06 @monitor.py:363][0m activation-summaries/output-rms: 0.020698
[32m[0419 05:19:06 @monitor.py:363][0m cross_entropy_loss: 3.3108
[32m[0419 05:19:06 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 05:19:06 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 05:19:06 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 05:19:06 @monitor.py:363][0m last_linear/Wn_0: 0.23318
[32m[0419 05:19:06 @monitor.py:363][0m last_linear/Wp_0: 0.25313
[32m[0419 05:19:06 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 05:19:06 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 05:19:06 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 05:19:06 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 05:19:06 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 05:19:06 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 05:19:06 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 05:19:06 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 05:19:06 @monitor.py:363][0m linear1/Wn_0: 0.96472
[32m[0419 05:19:06 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 05:19:06 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 05:19:06 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 05:19:06 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 05:19:06 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 05:19:06 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 05:19:06 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 05:19:06 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 05:19:06 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 05:19:06 @monitor.py:363][0m linear3/Wn_0: 0.95749
[32m[0419 05:19:06 @monitor.py:363][0m linear3/Wp_0: 0.91616
[32m[0419 05:19:06 @monitor.py:363][0m lr: 1.5259e-08
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 05:19:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 05:19:06 @monitor.py:363][0m train-error-top1: 0.78518
[32m[0419 05:19:06 @monitor.py:363][0m val-error-top1: 0.7706
[32m[0419 05:19:06 @monitor.py:363][0m val-utt-error: 0.52067
[32m[0419 05:19:06 @monitor.py:363][0m validation_cost: 3.2788
[32m[0419 05:19:06 @monitor.py:363][0m wd_cost: 7.8145e-09
[32m[0419 05:19:06 @group.py:42][0m Callbacks took 162.809 sec in total. InferenceRunner: 161.939sec
[32m[0419 05:19:06 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15697/173481[03:00<30:09,87.20it/s] 10%|9         |16562/173481[03:10<29:59,87.20it/s] 17%|#6        |29017/173481[06:00<30:04,80.05it/s] 17%|#7        |29768/173481[06:10<29:55,80.05it/s] 24%|##4       |42075/173481[09:00<28:46,76.11it/s] 25%|##4       |42819/173481[09:10<28:36,76.11it/s] 32%|###1      |54724/173481[12:00<27:05,73.08it/s] 32%|###1      |55488/173481[12:10<26:54,73.08it/s] 39%|###8      |67033/173481[15:00<25:06,70.65it/s] 39%|###9      |67840/173481[15:10<24:55,70.65it/s] 46%|####5     |79447/173481[18:00<22:27,69.78it/s] 46%|####6     |80190/173481[18:10<22:16,69.78it/s] 52%|#####2    |90991/173481[21:00<20:34,66.83it/s] 53%|#####2    |91737/173481[21:11<20:23,66.83it/s] 57%|#####7    |98944/173481[24:00<23:21,53.20it/s] 58%|#####7    |99867/173481[24:11<23:03,53.20it/s] 66%|######5   |113928/173481[27:00<15:17,64.91it/s] 66%|######6   |114853/173481[27:11<15:03,64.91it/s] 74%|#######4  |128671/173481[30:00<10:18,72.42it/s] 75%|#######4  |129595/173481[30:11<10:05,72.42it/s] 83%|########2 |143599/173481[33:00<06:26,77.31it/s] 83%|########3 |144516/173481[33:11<06:14,77.31it/s] 91%|######### |157741/173481[36:00<03:21,77.92it/s] 91%|#########1|158634/173481[36:11<03:10,77.92it/s] 99%|#########9|171963/173481[39:00<00:19,78.46it/s]100%|#########9|172896/173481[39:11<00:07,78.46it/s]100%|##########|173481/173481[39:19<00:00,73.53it/s]
[32m[0419 05:58:25 @base.py:257][0m Epoch 45 (global_step 7806645) finished, time:2359.41 sec.
[32m[0419 05:58:26 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-7806645.
[32m[0419 05:58:26 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 89%|########9 |16839/18822[03:00<00:21,93.55it/s] 96%|#########6|18094/18822[03:10<00:07,93.55it/s]100%|##########|18822/18822[03:16<00:00,95.96it/s]
44
[32m[0419 06:01:42 @monitor.py:363][0m QueueInput/queue_size: 0.61489
[32m[0419 06:01:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8718
[32m[0419 06:01:42 @monitor.py:363][0m activation-summaries/output-rms: 0.021843
[32m[0419 06:01:42 @monitor.py:363][0m cross_entropy_loss: 3.2243
[32m[0419 06:01:42 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 06:01:42 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 06:01:42 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 06:01:42 @monitor.py:363][0m last_linear/Wn_0: 0.23082
[32m[0419 06:01:42 @monitor.py:363][0m last_linear/Wp_0: 0.25452
[32m[0419 06:01:42 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 06:01:42 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 06:01:42 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 06:01:42 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 06:01:42 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 06:01:42 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 06:01:42 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 06:01:42 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 06:01:42 @monitor.py:363][0m linear1/Wn_0: 0.96472
[32m[0419 06:01:42 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 06:01:42 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 06:01:42 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 06:01:42 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 06:01:42 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 06:01:42 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 06:01:42 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 06:01:42 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 06:01:42 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 06:01:42 @monitor.py:363][0m linear3/Wn_0: 0.95749
[32m[0419 06:01:42 @monitor.py:363][0m linear3/Wp_0: 0.91616
[32m[0419 06:01:42 @monitor.py:363][0m lr: 1.5259e-08
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 06:01:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 06:01:42 @monitor.py:363][0m train-error-top1: 0.76235
[32m[0419 06:01:42 @monitor.py:363][0m val-error-top1: 0.77102
[32m[0419 06:01:42 @monitor.py:363][0m val-utt-error: 0.51881
[32m[0419 06:01:42 @monitor.py:363][0m validation_cost: 3.2804
[32m[0419 06:01:42 @monitor.py:363][0m wd_cost: 1.5629e-09
[32m[0419 06:01:42 @group.py:42][0m Callbacks took 196.655 sec in total. InferenceRunner: 196.166sec
[32m[0419 06:01:42 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15534/173481[03:00<30:30,86.30it/s]  9%|9         |16383/173481[03:10<30:20,86.30it/s] 18%|#7        |31110/173481[06:00<27:27,86.41it/s] 19%|#8        |32148/173481[06:10<27:15,86.41it/s] 27%|##6       |46115/173481[09:00<25:00,84.86it/s] 27%|##7       |46941/173481[09:10<24:51,84.86it/s] 35%|###4      |60547/173481[12:00<22:49,82.45it/s] 35%|###5      |61408/173481[12:10<22:39,82.45it/s] 43%|####3     |74988/173481[15:00<20:11,81.32it/s] 44%|####3     |75813/173481[15:10<20:00,81.32it/s] 51%|#####1    |89140/173481[18:00<17:35,79.94it/s] 52%|#####1    |90003/173481[18:10<17:24,79.94it/s] 61%|######    |105452/173481[21:00<13:20,84.94it/s] 61%|######1   |106347/173481[21:11<13:10,84.94it/s] 71%|#######   |122683/173481[24:00<09:24,90.01it/s] 71%|#######1  |123499/173481[24:11<09:15,90.01it/s] 78%|#######8  |135895/173481[27:00<07:44,80.86it/s] 79%|#######8  |136717/173481[27:11<07:34,80.86it/s] 86%|########5 |149017/173481[30:00<05:19,76.67it/s] 86%|########6 |149928/173481[30:11<05:07,76.67it/s] 94%|#########4|163186/173481[33:00<02:12,77.68it/s] 95%|#########4|164079/173481[33:11<02:01,77.68it/s]100%|##########|173481/173481[35:43<00:00,80.92it/s]
[32m[0419 06:37:26 @base.py:257][0m Epoch 46 (global_step 7980126) finished, time:2143.95 sec.
[32m[0419 06:37:26 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-7980126.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:47<00:00,112.44it/s]
45
[32m[0419 06:40:14 @monitor.py:363][0m QueueInput/queue_size: 0.34444
[32m[0419 06:40:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9066
[32m[0419 06:40:14 @monitor.py:363][0m activation-summaries/output-rms: 0.022023
[32m[0419 06:40:14 @monitor.py:363][0m cross_entropy_loss: 3.2999
[32m[0419 06:40:14 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 06:40:14 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 06:40:14 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 06:40:14 @monitor.py:363][0m last_linear/Wn_0: 0.22853
[32m[0419 06:40:14 @monitor.py:363][0m last_linear/Wp_0: 0.25583
[32m[0419 06:40:14 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 06:40:14 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 06:40:14 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 06:40:14 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 06:40:14 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 06:40:14 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 06:40:14 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 06:40:14 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 06:40:14 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 06:40:14 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 06:40:14 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 06:40:14 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 06:40:14 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 06:40:14 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 06:40:14 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 06:40:14 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 06:40:14 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 06:40:14 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 06:40:14 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 06:40:14 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 06:40:14 @monitor.py:363][0m lr: 1.5259e-08
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 06:40:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 06:40:14 @monitor.py:363][0m train-error-top1: 0.76853
[32m[0419 06:40:14 @monitor.py:363][0m val-error-top1: 0.77045
[32m[0419 06:40:14 @monitor.py:363][0m val-utt-error: 0.5196
[32m[0419 06:40:14 @monitor.py:363][0m validation_cost: 3.275
[32m[0419 06:40:14 @monitor.py:363][0m wd_cost: 1.5629e-09
[32m[0419 06:40:14 @group.py:42][0m Callbacks took 167.680 sec in total. InferenceRunner: 167.406sec
[32m[0419 06:40:14 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14114/173481[03:00<33:52,78.41it/s]  9%|8         |14867/173481[03:10<33:42,78.41it/s] 16%|#5        |27739/173481[06:01<31:38,76.75it/s] 17%|#6        |29100/173481[06:20<31:21,76.75it/s] 24%|##3       |40867/173481[09:01<29:33,74.79it/s] 24%|##4       |42102/173481[09:20<29:16,74.79it/s] 30%|###       |52828/173481[12:01<28:34,70.37it/s] 31%|###1      |54154/173481[12:20<28:15,70.37it/s] 38%|###7      |65778/173481[15:01<25:13,71.15it/s] 39%|###8      |67338/173481[15:20<24:51,71.15it/s] 47%|####6     |80683/173481[18:01<20:12,76.53it/s] 47%|####7     |82231/173481[18:20<19:52,76.53it/s] 55%|#####4    |95239/173481[21:01<16:34,78.64it/s] 56%|#####5    |97119/173481[21:21<16:11,78.64it/s] 63%|######3   |109831/173481[24:01<13:17,79.83it/s] 64%|######4   |111435/173481[24:21<12:57,79.83it/s] 72%|#######1  |124669/173481[27:01<10:01,81.11it/s] 72%|#######2  |125478/173481[27:11<09:51,81.11it/s] 79%|#######9  |137437/173481[30:01<07:56,75.68it/s] 80%|#######9  |138102/173481[30:11<07:47,75.68it/s] 86%|########5 |149005/173481[33:01<05:52,69.50it/s] 86%|########6 |149802/173481[33:11<05:40,69.50it/s] 94%|#########4|163220/173481[36:01<02:18,73.93it/s] 95%|#########4|164045/173481[36:11<02:07,73.93it/s]100%|##########|173481/173481[38:17<00:00,75.51it/s]
[32m[0419 07:18:31 @base.py:257][0m Epoch 47 (global_step 8153607) finished, time:2297.44 sec.
[32m[0419 07:18:31 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-8153607.
[32m[0419 07:18:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:46<00:00,112.92it/s]
46
[32m[0419 07:21:18 @monitor.py:363][0m QueueInput/queue_size: 0.23743
[32m[0419 07:21:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.925
[32m[0419 07:21:18 @monitor.py:363][0m activation-summaries/output-rms: 0.020975
[32m[0419 07:21:18 @monitor.py:363][0m cross_entropy_loss: 3.2742
[32m[0419 07:21:18 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 07:21:18 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 07:21:18 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 07:21:18 @monitor.py:363][0m last_linear/Wn_0: 0.22741
[32m[0419 07:21:18 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 07:21:18 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 07:21:18 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 07:21:18 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 07:21:18 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 07:21:18 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 07:21:18 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 07:21:18 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 07:21:18 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 07:21:18 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 07:21:18 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 07:21:18 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 07:21:18 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 07:21:18 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 07:21:18 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 07:21:18 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 07:21:18 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 07:21:18 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 07:21:18 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 07:21:18 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 07:21:18 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 07:21:18 @monitor.py:363][0m lr: 7.6294e-09
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 07:21:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 07:21:18 @monitor.py:363][0m train-error-top1: 0.77547
[32m[0419 07:21:18 @monitor.py:363][0m val-error-top1: 0.77058
[32m[0419 07:21:18 @monitor.py:363][0m val-utt-error: 0.52226
[32m[0419 07:21:18 @monitor.py:363][0m validation_cost: 3.2809
[32m[0419 07:21:18 @monitor.py:363][0m wd_cost: 1.5629e-09
[32m[0419 07:21:18 @group.py:42][0m Callbacks took 167.205 sec in total. InferenceRunner: 166.707sec
[32m[0419 07:21:18 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16458/173481[03:00<28:37,91.43it/s] 10%|9         |17275/173481[03:10<28:28,91.43it/s] 18%|#8        |31708/173481[06:00<26:51,87.95it/s] 19%|#8        |32572/173481[06:10<26:42,87.95it/s] 26%|##5       |44890/173481[09:00<26:49,79.91it/s] 26%|##6       |45603/173481[09:10<26:40,79.91it/s] 36%|###6      |62818/173481[12:00<20:47,88.67it/s] 37%|###6      |64019/173481[12:10<20:34,88.67it/s] 49%|####8     |84202/173481[15:00<14:39,101.55it/s] 49%|####9     |85376/173481[15:10<14:27,101.55it/s] 57%|#####7    |99688/173481[18:00<13:12,93.14it/s]  58%|#####7    |100558/173481[18:10<13:02,93.14it/s] 66%|######5   |114232/173481[21:00<11:24,86.52it/s] 66%|######6   |115072/173481[21:10<11:15,86.52it/s] 74%|#######3  |128197/173481[24:00<09:13,81.81it/s] 74%|#######4  |129045/173481[24:11<09:03,81.81it/s] 82%|########1 |141984/173481[27:00<06:38,79.11it/s] 82%|########2 |142842/173481[27:11<06:27,79.11it/s] 90%|########9 |155803/173481[30:00<03:46,77.93it/s] 90%|######### |156658/173481[30:11<03:35,77.93it/s] 97%|#########7|169019/173481[33:00<00:59,75.61it/s] 98%|#########7|169846/173481[33:11<00:48,75.61it/s]100%|##########|173481/173481[34:03<00:00,84.90it/s]
[32m[0419 07:55:22 @base.py:257][0m Epoch 48 (global_step 8327088) finished, time:2043.34 sec.
[32m[0419 07:55:22 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-8327088.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:46<00:00,113.34it/s]
47
[32m[0419 07:58:08 @monitor.py:363][0m QueueInput/queue_size: 0.65128
[32m[0419 07:58:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8984
[32m[0419 07:58:08 @monitor.py:363][0m activation-summaries/output-rms: 0.02149
[32m[0419 07:58:08 @monitor.py:363][0m cross_entropy_loss: 3.2458
[32m[0419 07:58:08 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 07:58:08 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 07:58:08 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 07:58:08 @monitor.py:363][0m last_linear/Wn_0: 0.22674
[32m[0419 07:58:08 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 07:58:08 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 07:58:08 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 07:58:08 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 07:58:08 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 07:58:08 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 07:58:08 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 07:58:08 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 07:58:08 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 07:58:08 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 07:58:08 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 07:58:08 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 07:58:08 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 07:58:08 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 07:58:08 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 07:58:08 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 07:58:08 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 07:58:08 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 07:58:08 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 07:58:08 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 07:58:08 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 07:58:08 @monitor.py:363][0m lr: 7.6294e-09
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 07:58:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 07:58:08 @monitor.py:363][0m train-error-top1: 0.76869
[32m[0419 07:58:08 @monitor.py:363][0m val-error-top1: 0.77055
[32m[0419 07:58:08 @monitor.py:363][0m val-utt-error: 0.52051
[32m[0419 07:58:08 @monitor.py:363][0m validation_cost: 3.2821
[32m[0419 07:58:08 @monitor.py:363][0m wd_cost: 3.1258e-10
[32m[0419 07:58:08 @group.py:42][0m Callbacks took 166.272 sec in total. InferenceRunner: 166.075sec
[32m[0419 07:58:08 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14342/173481[03:00<33:17,79.67it/s]  9%|8         |15189/173481[03:10<33:06,79.67it/s] 17%|#6        |28867/173481[06:00<30:03,80.18it/s] 17%|#7        |29674/173481[06:10<29:53,80.18it/s] 24%|##4       |41875/173481[09:00<28:51,76.01it/s] 24%|##4       |42270/173481[09:10<28:46,76.01it/s] 30%|###       |52573/173481[12:00<30:12,66.70it/s] 31%|###       |53244/173481[12:10<30:02,66.70it/s] 37%|###7      |64773/173481[15:00<26:56,67.24it/s] 38%|###7      |65568/173481[15:10<26:45,67.24it/s] 44%|####3     |76135/173481[18:00<24:55,65.11it/s] 44%|####4     |76788/173481[18:10<24:45,65.11it/s] 52%|#####1    |89588/173481[21:00<20:05,69.59it/s] 52%|#####2    |90330/173481[21:11<19:54,69.59it/s] 59%|#####8    |101992/173481[24:00<17:12,69.25it/s] 59%|#####9    |102840/173481[24:11<17:00,69.25it/s] 66%|######5   |114127/173481[27:00<14:28,68.32it/s] 66%|######6   |114797/173481[27:11<14:19,68.32it/s] 72%|#######2  |125335/173481[30:00<12:19,65.15it/s] 73%|#######2  |126030/173481[30:11<12:08,65.15it/s] 81%|########  |139835/173481[33:00<07:47,72.04it/s] 81%|########1 |141150/173481[33:11<07:28,72.04it/s] 95%|#########4|164049/173481[36:00<01:40,93.83it/s] 95%|#########5|165670/173481[36:11<01:23,93.83it/s]100%|##########|173481/173481[37:08<00:00,77.84it/s]
[32m[0419 08:35:17 @base.py:257][0m Epoch 49 (global_step 8500569) finished, time:2228.68 sec.
[32m[0419 08:35:17 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-8500569.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########7|18367/18822[03:00<00:04,102.04it/s]100%|##########|18822/18822[03:04<00:00,102.16it/s]
48
[32m[0419 08:38:21 @monitor.py:363][0m QueueInput/queue_size: 49.998
[32m[0419 08:38:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.885
[32m[0419 08:38:21 @monitor.py:363][0m activation-summaries/output-rms: 0.021233
[32m[0419 08:38:21 @monitor.py:363][0m cross_entropy_loss: 3.2434
[32m[0419 08:38:21 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 08:38:21 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 08:38:21 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 08:38:21 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 08:38:21 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 08:38:21 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 08:38:21 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 08:38:21 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 08:38:21 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 08:38:21 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 08:38:21 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 08:38:21 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 08:38:21 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 08:38:21 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 08:38:21 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 08:38:21 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 08:38:21 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 08:38:21 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 08:38:21 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 08:38:21 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 08:38:21 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 08:38:21 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 08:38:21 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 08:38:21 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 08:38:21 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 08:38:21 @monitor.py:363][0m lr: 3.8147e-09
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 08:38:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 08:38:21 @monitor.py:363][0m train-error-top1: 0.77471
[32m[0419 08:38:21 @monitor.py:363][0m val-error-top1: 0.76981
[32m[0419 08:38:21 @monitor.py:363][0m val-utt-error: 0.51674
[32m[0419 08:38:21 @monitor.py:363][0m validation_cost: 3.2726
[32m[0419 08:38:21 @monitor.py:363][0m wd_cost: 3.1258e-10
[32m[0419 08:38:21 @group.py:42][0m Callbacks took 184.373 sec in total. InferenceRunner: 184.256sec
[32m[0419 08:38:21 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s] 14%|#4        |24500/173481[03:00<18:14,136.11it/s] 15%|#4        |25861/173481[03:10<18:04,136.11it/s] 26%|##6       |45880/173481[06:00<16:45,126.85it/s] 27%|##7       |47003/173481[06:10<16:37,126.85it/s] 38%|###8      |66444/173481[09:00<14:50,120.21it/s] 39%|###9      |67752/173481[09:10<14:39,120.21it/s] 47%|####6     |81112/173481[12:00<15:51,97.13it/s]  47%|####7     |81753/173481[12:10<15:44,97.13it/s] 53%|#####3    |92248/173481[15:00<17:54,75.58it/s] 54%|#####3    |92961/173481[15:10<17:45,75.58it/s] 60%|######    |104944/173481[18:00<15:39,72.96it/s] 61%|######    |105734/173481[18:10<15:28,72.96it/s] 67%|######7   |117080/173481[21:00<13:24,70.08it/s] 68%|######7   |117854/173481[21:10<13:13,70.08it/s] 75%|#######4  |130034/173481[24:00<10:11,71.01it/s] 75%|#######5  |130835/173481[24:11<10:00,71.01it/s] 83%|########2 |143152/173481[27:00<07:01,71.93it/s] 83%|########2 |143978/173481[27:11<06:50,71.93it/s] 90%|########9 |155402/173481[30:00<04:18,69.94it/s] 90%|######### |156162/173481[30:11<04:07,69.94it/s] 97%|#########6|167688/173481[33:00<01:23,69.08it/s] 97%|#########7|168539/173481[33:11<01:11,69.08it/s]100%|##########|173481/173481[34:19<00:00,84.25it/s]
[32m[0419 09:12:40 @base.py:257][0m Epoch 50 (global_step 8674050) finished, time:2059.23 sec.
[32m[0419 09:12:41 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-8674050.
[32m[0419 09:12:41 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,155.91it/s]
49
[32m[0419 09:14:42 @monitor.py:363][0m QueueInput/queue_size: 0.66949
[32m[0419 09:14:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9118
[32m[0419 09:14:42 @monitor.py:363][0m activation-summaries/output-rms: 0.020647
[32m[0419 09:14:42 @monitor.py:363][0m cross_entropy_loss: 3.2887
[32m[0419 09:14:42 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 09:14:42 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 09:14:42 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 09:14:42 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 09:14:42 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 09:14:42 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 09:14:42 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 09:14:42 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 09:14:42 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 09:14:42 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 09:14:42 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 09:14:42 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 09:14:42 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 09:14:42 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 09:14:42 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 09:14:42 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 09:14:42 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 09:14:42 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 09:14:42 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 09:14:42 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 09:14:42 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 09:14:42 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 09:14:42 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 09:14:42 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 09:14:42 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 09:14:42 @monitor.py:363][0m lr: 3.8147e-09
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 09:14:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 09:14:42 @monitor.py:363][0m train-error-top1: 0.78116
[32m[0419 09:14:42 @monitor.py:363][0m val-error-top1: 0.77035
[32m[0419 09:14:42 @monitor.py:363][0m val-utt-error: 0.52285
[32m[0419 09:14:42 @monitor.py:363][0m validation_cost: 3.2796
[32m[0419 09:14:42 @monitor.py:363][0m wd_cost: 6.2516e-11
[32m[0419 09:14:42 @group.py:42][0m Callbacks took 121.740 sec in total. InferenceRunner: 120.739sec
[32m[0419 09:14:42 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12673/173481[03:00<38:04,70.39it/s]  8%|7         |13362/173481[03:10<37:54,70.39it/s] 15%|#4        |25158/173481[06:00<35:22,69.87it/s] 15%|#4        |25893/173481[06:10<35:12,69.87it/s] 22%|##1       |37610/173481[09:00<32:34,69.52it/s] 22%|##2       |38244/173481[09:10<32:25,69.52it/s] 29%|##8       |50217/173481[12:00<29:26,69.78it/s] 29%|##9       |50968/173481[12:10<29:15,69.78it/s] 36%|###6      |63194/173481[15:00<25:55,70.92it/s] 37%|###6      |63995/173481[15:10<25:43,70.92it/s] 44%|####3     |75679/173481[18:00<23:14,70.12it/s] 44%|####4     |76356/173481[18:10<23:05,70.12it/s] 51%|#####     |88420/173481[21:00<20:07,70.45it/s] 51%|#####1    |89195/173481[21:11<19:56,70.45it/s] 58%|#####8    |101251/173481[24:00<16:59,70.86it/s] 59%|#####8    |102108/173481[24:11<16:47,70.86it/s] 65%|######5   |113609/173481[27:00<14:18,69.74it/s] 66%|######5   |114366/173481[27:11<14:07,69.74it/s] 72%|#######2  |125541/173481[30:00<11:45,67.97it/s] 73%|#######2  |126294/173481[30:11<11:34,67.97it/s] 79%|#######9  |137887/173481[33:00<08:41,68.27it/s] 80%|#######9  |138576/173481[33:11<08:31,68.27it/s] 86%|########5 |149149/173481[36:00<06:12,65.29it/s] 86%|########6 |149842/173481[36:11<06:02,65.29it/s] 92%|#########2|160135/173481[39:00<03:31,63.08it/s] 93%|#########2|160854/173481[39:11<03:20,63.08it/s] 99%|#########8|170935/173481[42:00<00:41,61.49it/s] 99%|#########8|171641/173481[42:12<00:29,61.49it/s]100%|##########|173481/173481[42:42<00:00,67.69it/s]
[32m[0419 09:57:25 @base.py:257][0m Epoch 51 (global_step 8847531) finished, time:2562.93 sec.
[32m[0419 09:57:25 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-8847531.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:50<00:00,110.09it/s]
50
[32m[0419 10:00:16 @monitor.py:363][0m QueueInput/queue_size: 0.41235
[32m[0419 10:00:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8513
[32m[0419 10:00:16 @monitor.py:363][0m activation-summaries/output-rms: 0.021788
[32m[0419 10:00:16 @monitor.py:363][0m cross_entropy_loss: 3.2221
[32m[0419 10:00:16 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 10:00:16 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 10:00:16 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 10:00:16 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 10:00:16 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 10:00:16 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 10:00:16 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 10:00:16 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 10:00:16 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 10:00:16 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 10:00:16 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 10:00:16 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 10:00:16 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 10:00:16 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 10:00:16 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 10:00:16 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 10:00:16 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 10:00:16 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 10:00:16 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 10:00:16 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 10:00:16 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 10:00:16 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 10:00:16 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 10:00:16 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 10:00:16 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 10:00:16 @monitor.py:363][0m lr: 3.8147e-09
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 10:00:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 10:00:16 @monitor.py:363][0m train-error-top1: 0.76221
[32m[0419 10:00:16 @monitor.py:363][0m val-error-top1: 0.77056
[32m[0419 10:00:16 @monitor.py:363][0m val-utt-error: 0.51881
[32m[0419 10:00:16 @monitor.py:363][0m validation_cost: 3.2783
[32m[0419 10:00:16 @monitor.py:363][0m wd_cost: 6.2516e-11
[32m[0419 10:00:16 @group.py:42][0m Callbacks took 171.133 sec in total. InferenceRunner: 170.974sec
[32m[0419 10:00:16 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19265/173481[03:00<24:00,107.02it/s] 12%|#1        |20338/173481[03:10<23:50,107.02it/s] 21%|##        |36000/173481[06:00<23:01,99.50it/s]  21%|##1       |37101/173481[06:10<22:50,99.50it/s] 31%|###1      |54114/173481[09:00<19:52,100.06it/s] 32%|###1      |55195/173481[09:10<19:42,100.06it/s] 38%|###7      |65074/173481[12:00<23:53,75.63it/s]  38%|###7      |65223/173481[12:10<23:51,75.63it/s] 42%|####1     |72413/173481[15:00<31:47,52.98it/s] 42%|####2     |73095/173481[15:10<31:34,52.98it/s] 49%|####9     |85186/173481[18:00<24:15,60.65it/s] 50%|####9     |85975/173481[18:10<24:02,60.65it/s] 58%|#####7    |100066/173481[21:00<17:29,69.97it/s] 58%|#####8    |101132/173481[21:11<17:14,69.97it/s] 66%|######6   |114940/173481[24:00<12:52,75.78it/s] 67%|######6   |115772/173481[24:11<12:41,75.78it/s] 74%|#######4  |129118/173481[27:00<09:34,77.24it/s] 75%|#######4  |129977/173481[27:11<09:23,77.24it/s] 78%|#######8  |135814/173481[30:00<12:30,50.18it/s] 79%|#######8  |136369/173481[30:11<12:19,50.18it/s] 86%|########6 |149674/173481[33:00<06:31,60.76it/s] 87%|########6 |150457/173481[33:11<06:18,60.76it/s] 94%|#########3|162673/173481[36:00<02:43,66.00it/s] 94%|#########4|163532/173481[36:11<02:30,66.00it/s]100%|##########|173481/173481[38:23<00:00,75.31it/s]
[32m[0419 10:38:40 @base.py:257][0m Epoch 52 (global_step 9021012) finished, time:2303.60 sec.
[32m[0419 10:38:40 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-9021012.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:55<00:00,107.28it/s]
51
[32m[0419 10:41:35 @monitor.py:363][0m QueueInput/queue_size: 0.26266
[32m[0419 10:41:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.886
[32m[0419 10:41:35 @monitor.py:363][0m activation-summaries/output-rms: 0.020922
[32m[0419 10:41:35 @monitor.py:363][0m cross_entropy_loss: 3.32
[32m[0419 10:41:35 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 10:41:35 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 10:41:35 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 10:41:35 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 10:41:35 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 10:41:35 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 10:41:35 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 10:41:35 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 10:41:35 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 10:41:35 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 10:41:35 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 10:41:35 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 10:41:35 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 10:41:35 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 10:41:35 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 10:41:35 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 10:41:35 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 10:41:35 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 10:41:35 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 10:41:35 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 10:41:35 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 10:41:35 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 10:41:35 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 10:41:35 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 10:41:35 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 10:41:35 @monitor.py:363][0m lr: 1.9073e-09
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 10:41:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 10:41:35 @monitor.py:363][0m train-error-top1: 0.77224
[32m[0419 10:41:35 @monitor.py:363][0m val-error-top1: 0.77044
[32m[0419 10:41:35 @monitor.py:363][0m val-utt-error: 0.52024
[32m[0419 10:41:35 @monitor.py:363][0m validation_cost: 3.2758
[32m[0419 10:41:35 @monitor.py:363][0m wd_cost: 6.2516e-11
[32m[0419 10:41:35 @group.py:42][0m Callbacks took 175.698 sec in total. InferenceRunner: 175.461sec
[32m[0419 10:41:35 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14480/173481[03:00<32:56,80.44it/s]  9%|8         |15318/173481[03:10<32:46,80.44it/s] 17%|#6        |28658/173481[06:00<30:19,79.60it/s] 17%|#6        |29480/173481[06:10<30:09,79.60it/s] 24%|##4       |42301/173481[09:00<28:09,77.65it/s] 25%|##4       |42981/173481[09:10<28:00,77.65it/s] 31%|###1      |53863/173481[12:00<28:21,70.30it/s] 31%|###1      |54497/173481[12:10<28:12,70.30it/s] 38%|###8      |66049/173481[15:00<25:57,68.96it/s] 39%|###8      |66811/173481[15:10<25:46,68.96it/s] 46%|####6     |80377/173481[18:00<20:59,73.90it/s] 47%|####6     |81236/173481[18:10<20:48,73.90it/s] 55%|#####4    |94706/173481[21:00<17:07,76.64it/s] 55%|#####5    |95664/173481[21:11<16:55,76.64it/s] 63%|######2   |108831/173481[24:00<13:53,77.54it/s] 63%|######3   |109620/173481[24:11<13:43,77.54it/s] 69%|######9   |119980/173481[27:00<12:56,68.87it/s] 70%|######9   |120825/173481[27:11<12:44,68.87it/s] 76%|#######6  |132193/173481[30:00<10:04,68.35it/s] 77%|#######6  |132934/173481[30:11<09:53,68.35it/s] 83%|########2 |143421/173481[33:00<07:40,65.23it/s] 83%|########3 |144199/173481[33:11<07:28,65.23it/s] 90%|########9 |155760/173481[36:00<04:25,66.85it/s] 90%|######### |156625/173481[36:11<04:12,66.85it/s] 99%|#########8|171211/173481[39:00<00:30,75.16it/s] 99%|#########9|172291/173481[39:12<00:15,75.16it/s]100%|##########|173481/173481[39:25<00:00,73.33it/s]
[32m[0419 11:21:01 @base.py:257][0m Epoch 53 (global_step 9194493) finished, time:2365.87 sec.
[32m[0419 11:21:01 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-9194493.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.59it/s]
52
[32m[0419 11:23:07 @monitor.py:363][0m QueueInput/queue_size: 0.4692
[32m[0419 11:23:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8729
[32m[0419 11:23:07 @monitor.py:363][0m activation-summaries/output-rms: 0.021458
[32m[0419 11:23:07 @monitor.py:363][0m cross_entropy_loss: 3.2734
[32m[0419 11:23:07 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 11:23:07 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 11:23:07 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 11:23:07 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 11:23:07 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 11:23:07 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 11:23:07 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 11:23:07 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 11:23:07 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 11:23:07 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 11:23:07 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 11:23:07 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 11:23:07 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 11:23:07 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 11:23:07 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 11:23:07 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 11:23:07 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 11:23:07 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 11:23:07 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 11:23:07 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 11:23:07 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 11:23:07 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 11:23:07 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 11:23:07 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 11:23:07 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 11:23:07 @monitor.py:363][0m lr: 1.9073e-09
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 11:23:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 11:23:07 @monitor.py:363][0m train-error-top1: 0.77472
[32m[0419 11:23:07 @monitor.py:363][0m val-error-top1: 0.77047
[32m[0419 11:23:07 @monitor.py:363][0m val-utt-error: 0.52253
[32m[0419 11:23:07 @monitor.py:363][0m validation_cost: 3.2803
[32m[0419 11:23:07 @monitor.py:363][0m wd_cost: 1.2503e-11
[32m[0419 11:23:07 @group.py:42][0m Callbacks took 125.269 sec in total. InferenceRunner: 125.009sec
[32m[0419 11:23:07 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15274/173481[03:00<31:04,84.85it/s]  9%|9         |16039/173481[03:10<30:55,84.85it/s] 17%|#7        |30117/173481[06:00<28:34,83.64it/s] 18%|#7        |30963/173481[06:10<28:23,83.64it/s] 26%|##5       |44862/173481[09:00<25:53,82.77it/s] 26%|##6       |45717/173481[09:10<25:43,82.77it/s] 34%|###4      |59514/173481[12:00<23:08,82.07it/s] 35%|###4      |60372/173481[12:10<22:58,82.07it/s] 43%|####2     |74298/173481[15:00<20:08,82.10it/s] 43%|####3     |75279/173481[15:10<19:56,82.10it/s] 52%|#####1    |89602/173481[18:00<16:44,83.53it/s] 52%|#####2    |90411/173481[18:10<16:34,83.53it/s] 60%|#####9    |103222/173481[21:00<14:44,79.40it/s] 60%|#####9    |103833/173481[21:10<14:37,79.40it/s] 66%|######6   |114563/173481[24:00<13:58,70.26it/s] 67%|######6   |115377/173481[24:11<13:46,70.26it/s] 74%|#######3  |127524/173481[27:00<10:46,71.12it/s] 74%|#######3  |128303/173481[27:11<10:35,71.12it/s] 81%|########  |140365/173481[30:00<07:44,71.23it/s] 81%|########1 |141245/173481[30:11<07:32,71.23it/s] 89%|########8 |153902/173481[33:00<04:27,73.16it/s] 89%|########9 |154688/173481[33:11<04:16,73.16it/s] 96%|#########5|165916/173481[36:00<01:48,69.80it/s] 96%|#########6|166821/173481[36:11<01:35,69.80it/s]100%|##########|173481/173481[37:37<00:00,76.85it/s]
[32m[0419 12:00:44 @base.py:257][0m Epoch 54 (global_step 9367974) finished, time:2257.52 sec.
[32m[0419 12:00:44 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-9367974.
  0%|          |0/18822[00:00<?,?it/s] 97%|#########6|18203/18822[03:00<00:06,101.13it/s]100%|##########|18822/18822[03:05<00:00,101.58it/s]
53
[32m[0419 12:03:50 @monitor.py:363][0m QueueInput/queue_size: 0.37883
[32m[0419 12:03:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8943
[32m[0419 12:03:50 @monitor.py:363][0m activation-summaries/output-rms: 0.021471
[32m[0419 12:03:50 @monitor.py:363][0m cross_entropy_loss: 3.2454
[32m[0419 12:03:50 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 12:03:50 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 12:03:50 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 12:03:50 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 12:03:50 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 12:03:50 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 12:03:50 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 12:03:50 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 12:03:50 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 12:03:50 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 12:03:50 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 12:03:50 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 12:03:50 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 12:03:50 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 12:03:50 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 12:03:50 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 12:03:50 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 12:03:50 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 12:03:50 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 12:03:50 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 12:03:50 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 12:03:50 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 12:03:50 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 12:03:50 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 12:03:50 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 12:03:50 @monitor.py:363][0m lr: 1.9073e-09
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 12:03:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 12:03:50 @monitor.py:363][0m train-error-top1: 0.76867
[32m[0419 12:03:50 @monitor.py:363][0m val-error-top1: 0.7705
[32m[0419 12:03:50 @monitor.py:363][0m val-utt-error: 0.52014
[32m[0419 12:03:50 @monitor.py:363][0m validation_cost: 3.2818
[32m[0419 12:03:50 @monitor.py:363][0m wd_cost: 1.2503e-11
[32m[0419 12:03:50 @group.py:42][0m Callbacks took 185.541 sec in total. InferenceRunner: 185.296sec
[32m[0419 12:03:50 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13420/173481[03:00<35:46,74.55it/s]  8%|8         |14215/173481[03:10<35:36,74.55it/s] 16%|#5        |27421/173481[06:00<31:58,76.13it/s] 16%|#6        |28230/173481[06:10<31:47,76.13it/s] 24%|##3       |41099/173481[09:00<29:00,76.06it/s] 24%|##4       |41953/173481[09:10<28:49,76.06it/s] 31%|###       |53179/173481[12:00<28:07,71.29it/s] 31%|###1      |53838/173481[12:10<27:58,71.29it/s] 37%|###6      |63913/173481[15:00<28:07,64.92it/s] 37%|###7      |64552/173481[15:10<27:57,64.92it/s] 44%|####3     |76321/173481[18:00<24:13,66.86it/s] 44%|####4     |77136/173481[18:10<24:01,66.86it/s] 51%|#####1    |88831/173481[21:00<20:42,68.15it/s] 52%|#####1    |89514/173481[21:11<20:32,68.15it/s] 58%|#####7    |100458/173481[24:00<18:20,66.32it/s] 58%|#####8    |101249/173481[24:11<18:09,66.32it/s] 66%|######5   |113732/173481[27:00<14:15,69.84it/s] 66%|######6   |114555/173481[27:11<14:03,69.84it/s] 72%|#######2  |125643/173481[30:00<11:43,67.95it/s] 73%|#######2  |126418/173481[30:11<11:32,67.95it/s] 80%|#######9  |138091/173481[33:00<08:36,68.54it/s] 80%|########  |138979/173481[33:11<08:23,68.54it/s] 87%|########7 |151123/173481[36:00<05:17,70.42it/s] 88%|########7 |151992/173481[36:11<05:05,70.42it/s] 94%|#########4|163687/173481[39:00<02:19,70.09it/s] 95%|#########4|164588/173481[39:11<02:06,70.09it/s]100%|##########|173481/173481[41:16<00:00,70.05it/s]
[32m[0419 12:45:06 @base.py:257][0m Epoch 55 (global_step 9541455) finished, time:2476.46 sec.
[32m[0419 12:45:06 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-9541455.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:30<00:00,124.91it/s]
54
[32m[0419 12:47:37 @monitor.py:363][0m QueueInput/queue_size: 0.39155
[32m[0419 12:47:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9126
[32m[0419 12:47:37 @monitor.py:363][0m activation-summaries/output-rms: 0.021508
[32m[0419 12:47:37 @monitor.py:363][0m cross_entropy_loss: 3.2513
[32m[0419 12:47:37 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 12:47:37 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 12:47:37 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 12:47:37 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 12:47:37 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 12:47:37 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 12:47:37 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 12:47:37 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 12:47:37 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 12:47:37 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 12:47:37 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 12:47:37 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 12:47:37 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 12:47:37 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 12:47:37 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 12:47:37 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 12:47:37 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 12:47:37 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 12:47:37 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 12:47:37 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 12:47:37 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 12:47:37 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 12:47:37 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 12:47:37 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 12:47:37 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 12:47:37 @monitor.py:363][0m lr: 9.5367e-10
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 12:47:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 12:47:37 @monitor.py:363][0m train-error-top1: 0.78398
[32m[0419 12:47:37 @monitor.py:363][0m val-error-top1: 0.77007
[32m[0419 12:47:37 @monitor.py:363][0m val-utt-error: 0.51844
[32m[0419 12:47:37 @monitor.py:363][0m validation_cost: 3.2756
[32m[0419 12:47:37 @monitor.py:363][0m wd_cost: 1.2503e-11
[32m[0419 12:47:37 @group.py:42][0m Callbacks took 150.918 sec in total. InferenceRunner: 150.692sec
[32m[0419 12:47:37 @base.py:247][0m Start Epoch 56 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14866/173481[03:00<32:00,82.58it/s]  9%|8         |15525/173481[03:10<31:52,82.58it/s] 15%|#4        |25577/173481[06:00<35:38,69.17it/s] 15%|#5        |26169/173481[06:10<35:29,69.17it/s] 21%|##        |36402/173481[09:00<35:30,64.34it/s] 21%|##1       |37011/173481[09:10<35:21,64.34it/s] 27%|##7       |47035/173481[12:00<34:13,61.59it/s] 27%|##7       |47616/173481[12:10<34:03,61.59it/s] 33%|###3      |57894/173481[15:00<31:36,60.95it/s] 34%|###3      |58509/173481[15:10<31:26,60.95it/s] 40%|###9      |69306/173481[18:00<27:56,62.15it/s] 40%|####      |70005/173481[18:10<27:44,62.15it/s] 46%|####5     |78938/173481[21:00<27:24,57.51it/s] 46%|####5     |79499/173481[21:10<27:14,57.51it/s] 51%|#####1    |88618/173481[24:00<25:26,55.58it/s] 51%|#####1    |89219/173481[24:11<25:16,55.58it/s] 57%|#####7    |99171/173481[27:00<21:42,57.06it/s] 58%|#####7    |99872/173481[27:11<21:30,57.06it/s] 64%|######3   |110689/173481[30:00<17:20,60.32it/s] 64%|######4   |111359/173481[30:11<17:09,60.32it/s] 71%|#######   |122573/173481[33:00<13:27,63.04it/s] 71%|#######1  |123278/173481[33:11<13:16,63.04it/s] 77%|#######7  |134136/173481[36:00<10:18,63.63it/s] 78%|#######7  |134932/173481[36:11<10:05,63.63it/s] 84%|########4 |146308/173481[39:00<06:54,65.55it/s] 85%|########4 |147099/173481[39:11<06:42,65.55it/s] 91%|#########1|158044/173481[42:00<03:56,65.34it/s] 92%|#########1|158912/173481[42:11<03:42,65.34it/s] 98%|#########8|170692/173481[45:00<00:41,67.71it/s] 99%|#########8|171454/173481[45:12<00:29,67.71it/s]100%|##########|173481/173481[45:42<00:00,63.26it/s]
[32m[0419 13:33:19 @base.py:257][0m Epoch 56 (global_step 9714936) finished, time:2742.43 sec.
[32m[0419 13:33:20 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-9714936.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.73it/s]
55
[32m[0419 13:35:13 @monitor.py:363][0m QueueInput/queue_size: 0.22655
[32m[0419 13:35:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9118
[32m[0419 13:35:13 @monitor.py:363][0m activation-summaries/output-rms: 0.020647
[32m[0419 13:35:13 @monitor.py:363][0m cross_entropy_loss: 3.2891
[32m[0419 13:35:13 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 13:35:13 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 13:35:13 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 13:35:13 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 13:35:13 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 13:35:13 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 13:35:13 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 13:35:13 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 13:35:13 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 13:35:13 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 13:35:13 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 13:35:13 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 13:35:13 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 13:35:13 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 13:35:13 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 13:35:13 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 13:35:13 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 13:35:13 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 13:35:13 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 13:35:13 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 13:35:13 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 13:35:13 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 13:35:13 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 13:35:13 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 13:35:13 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 13:35:13 @monitor.py:363][0m lr: 9.5367e-10
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 13:35:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 13:35:13 @monitor.py:363][0m train-error-top1: 0.7811
[32m[0419 13:35:13 @monitor.py:363][0m val-error-top1: 0.77032
[32m[0419 13:35:13 @monitor.py:363][0m val-utt-error: 0.52269
[32m[0419 13:35:13 @monitor.py:363][0m validation_cost: 3.2794
[32m[0419 13:35:13 @monitor.py:363][0m wd_cost: 2.5006e-12
[32m[0419 13:35:13 @group.py:42][0m Callbacks took 113.121 sec in total. InferenceRunner: 112.898sec
[32m[0419 13:35:13 @base.py:247][0m Start Epoch 57 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12175/173481[03:00<39:45,67.62it/s]  7%|7         |12756/173481[03:10<39:36,67.62it/s] 14%|#3        |23479/173481[06:00<38:23,65.12it/s] 14%|#3        |24102/173481[06:10<38:13,65.12it/s] 20%|##        |35425/173481[09:00<35:00,65.73it/s] 21%|##        |36084/173481[09:10<34:50,65.73it/s] 27%|##7       |47191/173481[12:00<32:06,65.55it/s] 28%|##7       |47825/173481[12:10<31:57,65.55it/s] 34%|###3      |58916/173481[15:00<29:13,65.34it/s] 34%|###4      |59594/173481[15:10<29:02,65.34it/s] 41%|####      |70326/173481[18:00<26:43,64.35it/s] 41%|####      |70890/173481[18:10<26:34,64.35it/s] 47%|####7     |82098/173481[21:00<23:28,64.86it/s] 48%|####7     |82701/173481[21:11<23:19,64.86it/s] 54%|#####4    |94419/173481[24:00<19:47,66.60it/s] 55%|#####5    |95415/173481[24:11<19:32,66.60it/s] 61%|######    |105043/173481[27:00<18:13,62.58it/s] 61%|######    |105696/173481[27:11<18:03,62.58it/s] 66%|######6   |115327/173481[30:00<16:13,59.72it/s] 67%|######6   |116017/173481[30:11<16:02,59.72it/s] 73%|#######2  |125800/173481[33:00<13:28,58.94it/s] 73%|#######2  |126498/173481[33:11<13:17,58.94it/s] 78%|#######8  |135365/173481[36:00<11:21,55.89it/s] 78%|#######8  |135960/173481[36:11<11:11,55.89it/s] 83%|########2 |143388/173481[39:00<10:06,49.58it/s] 83%|########2 |143694/173481[39:11<10:00,49.58it/s] 87%|########6 |150217/173481[42:00<09:01,42.96it/s] 87%|########6 |150807/173481[42:12<08:47,42.96it/s] 95%|#########4|164400/173481[45:00<02:43,55.60it/s] 95%|#########5|165114/173481[45:12<02:30,55.60it/s]100%|##########|173481/173481[47:43<00:00,60.58it/s]
[32m[0419 14:22:57 @base.py:257][0m Epoch 57 (global_step 9888417) finished, time:2863.86 sec.
[32m[0419 14:22:58 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:57<00:00,105.76it/s]
56
[32m[0419 14:25:56 @monitor.py:363][0m QueueInput/queue_size: 0.56727
[32m[0419 14:25:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8513
[32m[0419 14:25:56 @monitor.py:363][0m activation-summaries/output-rms: 0.021788
[32m[0419 14:25:56 @monitor.py:363][0m cross_entropy_loss: 3.2218
[32m[0419 14:25:56 @monitor.py:363][0m last_linear/W_0_percent_n: 0.18483
[32m[0419 14:25:56 @monitor.py:363][0m last_linear/W_0_percent_p: 0.17243
[32m[0419 14:25:56 @monitor.py:363][0m last_linear/W_0_sparsity: 0.64272
[32m[0419 14:25:56 @monitor.py:363][0m last_linear/Wn_0: 0.22611
[32m[0419 14:25:56 @monitor.py:363][0m last_linear/Wp_0: 0.25616
[32m[0419 14:25:56 @monitor.py:363][0m linear0/W_0_percent_n: 0.12134
[32m[0419 14:25:56 @monitor.py:363][0m linear0/W_0_percent_p: 0.13749
[32m[0419 14:25:56 @monitor.py:363][0m linear0/W_0_sparsity: 0.7355
[32m[0419 14:25:56 @monitor.py:363][0m linear0/Wn_0: 1.0045
[32m[0419 14:25:56 @monitor.py:363][0m linear0/Wp_0: 1.0686
[32m[0419 14:25:56 @monitor.py:363][0m linear1/W_0_percent_n: 0.16226
[32m[0419 14:25:56 @monitor.py:363][0m linear1/W_0_percent_p: 0.1324
[32m[0419 14:25:56 @monitor.py:363][0m linear1/W_0_sparsity: 0.69704
[32m[0419 14:25:56 @monitor.py:363][0m linear1/Wn_0: 0.96473
[32m[0419 14:25:56 @monitor.py:363][0m linear1/Wp_0: 1.0054
[32m[0419 14:25:56 @monitor.py:363][0m linear2/W_0_percent_n: 0.034729
[32m[0419 14:25:56 @monitor.py:363][0m linear2/W_0_percent_p: 0.042801
[32m[0419 14:25:56 @monitor.py:363][0m linear2/W_0_sparsity: 0.92052
[32m[0419 14:25:56 @monitor.py:363][0m linear2/Wn_0: 1.1239
[32m[0419 14:25:56 @monitor.py:363][0m linear2/Wp_0: 0.92977
[32m[0419 14:25:56 @monitor.py:363][0m linear3/W_0_percent_n: 0.040604
[32m[0419 14:25:56 @monitor.py:363][0m linear3/W_0_percent_p: 0.035202
[32m[0419 14:25:56 @monitor.py:363][0m linear3/W_0_sparsity: 0.92216
[32m[0419 14:25:56 @monitor.py:363][0m linear3/Wn_0: 0.9575
[32m[0419 14:25:56 @monitor.py:363][0m linear3/Wp_0: 0.91617
[32m[0419 14:25:56 @monitor.py:363][0m lr: 9.5367e-10
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 2.4939
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0967
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/linear0/W-rms: 2.221
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.089074
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/linear1/W-rms: 2.4249
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.083937
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/linear2/W-rms: 1.5768
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086065
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/linear3/W-rms: 1.5998
[32m[0419 14:25:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089963
[32m[0419 14:25:56 @monitor.py:363][0m train-error-top1: 0.76221
[32m[0419 14:25:56 @monitor.py:363][0m val-error-top1: 0.77055
[32m[0419 14:25:56 @monitor.py:363][0m val-utt-error: 0.5186
[32m[0419 14:25:56 @monitor.py:363][0m validation_cost: 3.2783
[32m[0419 14:25:56 @monitor.py:363][0m wd_cost: 2.5006e-12
[32m[0419 14:25:56 @group.py:42][0m Callbacks took 179.937 sec in total. InferenceRunner: 177.985sec
[32m[0419 14:25:56 @base.py:247][0m Start Epoch 58 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14599/173481[03:00<32:39,81.10it/s]  9%|8         |15420/173481[03:10<32:28,81.10it/s] 17%|#6        |28701/173481[06:00<30:16,79.70it/s] 17%|#6        |29387/173481[06:10<30:07,79.70it/s] 23%|##3       |39927/173481[09:00<31:48,69.97it/s] 23%|##3       |40521/173481[09:10<31:40,69.97it/s] 29%|##9       |50752/173481[12:00<31:37,64.67it/s] 30%|##9       |51339/173481[12:10<31:28,64.67it/s] 35%|###5      |60794/173481[15:00<31:21,59.90it/s] 35%|###5      |61413/173481[15:10<31:10,59.90it/s] 42%|####1     |72538/173481[18:00<26:56,62.45it/s] 42%|####2     |73291/173481[18:10<26:44,62.45it/s]slurmstepd: *** STEP 340355.0 ON sls-sm-16 CANCELLED AT 2018-04-19T14:46:12 DUE TO TIME LIMIT ***
srun: error: sls-sm-16: task 0: Terminated
srun: Force Terminated job step 340355.0
