sls-sm-6 1
SLURM_JOBID=82391
SLURM_TASKID=1
[32m[0322 11:43:52 @logger.py:67][0m Existing log file 'train_log/fcn2_a_32_quant_ends_True_preload/log.log' backuped to 'train_log/fcn2_a_32_quant_ends_True_preload/log.log.0322-114352'
[32m[0322 11:43:52 @logger.py:74][0m Argv: ttq_run.py --model_name=fcn2 --quant_ends=True --load_ckpt=../dorefa/real/train_log/fcn2_w_4_a_32_quant_ends_True/checkpoint
[32m[0322 11:43:54 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0322 11:43:54 @ttq_run.py:140][0m Using 6 threads
('whole utterance size', 75290)
[32m[0322 11:43:54 @ttq_run.py:164][0m 18822 utterances per val epoch
[32m[0322 11:43:54 @ttq_run.py:165][0m Using host: sls-sm-6
[32m[0322 11:43:54 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0322 11:43:54 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0322 11:43:54 @ttq_run.py:187][0m Using GPU: 1
[32m[0322 11:43:54 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0322 11:43:54 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0322 11:43:54 @training.py:108][0m Building graph for training tower 0 ...
[32m[0322 11:43:54 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0322 11:43:54 @ttq_run.py:71][0m Ternarizing weight linear0/W
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear0/Wp
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear0/Wn
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear0/b
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear0/bn/beta
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear0/bn/gamma
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear0/bn/mean/EMA
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear0/bn/variance/EMA
[32m[0322 11:43:54 @registry.py:130][0m linear0 output: [None, 504]
[32m[0322 11:43:54 @registry.py:122][0m linear1 input: [None, 504]
[32m[0322 11:43:54 @ttq_run.py:71][0m Ternarizing weight linear1/W
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear1/Wp
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear1/Wn
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear1/b
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear1/bn/beta
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear1/bn/gamma
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear1/bn/mean/EMA
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear1/bn/variance/EMA
[32m[0322 11:43:54 @registry.py:130][0m linear1 output: [None, 504]
[32m[0322 11:43:54 @registry.py:122][0m linear2 input: [None, 504]
[32m[0322 11:43:54 @ttq_run.py:71][0m Ternarizing weight linear2/W
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear2/Wp
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear2/Wn
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear2/b
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear2/bn/beta
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear2/bn/gamma
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear2/bn/mean/EMA
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear2/bn/variance/EMA
[32m[0322 11:43:54 @registry.py:130][0m linear2 output: [None, 504]
[32m[0322 11:43:54 @registry.py:122][0m linear3 input: [None, 504]
[32m[0322 11:43:54 @ttq_run.py:71][0m Ternarizing weight linear3/W
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear3/Wp
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear3/Wn
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear3/b
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear3/bn/beta
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear3/bn/gamma
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear3/bn/mean/EMA
[32m[0322 11:43:54 @ttq_run.py:59][0m Not ternarizing linear3/bn/variance/EMA
[32m[0322 11:43:55 @registry.py:130][0m linear3 output: [None, 504]
[32m[0322 11:43:55 @registry.py:122][0m last_linear input: [None, 504]
[32m[0322 11:43:55 @ttq_run.py:71][0m Ternarizing weight last_linear/W
[32m[0322 11:43:55 @ttq_run.py:59][0m Not ternarizing last_linear/Wp
[32m[0322 11:43:55 @ttq_run.py:59][0m Not ternarizing last_linear/Wn
[32m[0322 11:43:55 @ttq_run.py:59][0m Not ternarizing last_linear/b
[32m[0322 11:43:55 @registry.py:130][0m last_linear output: [None, 255]
[32m[0322 11:43:55 @ttq_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:43:55 @regularize.py:81][0m regularize_cost() found 15 tensors.
[32m[0322 11:43:55 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear0/Wp:0, linear0/Wn:0, linear1/W:0, linear1/Wp:0, linear1/Wn:0, linear2/W:0, linear2/Wp:0, linear2/Wn:0, linear3/W:0, linear3/Wp:0, linear3/Wn:0, last_linear/W:0, last_linear/Wp:0, last_linear/Wn:0
[32m[0322 11:43:55 @ttq_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0322 11:43:55 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/Wp:0        []                1
linear0/Wn:0        []                1
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/Wp:0        []                1
linear1/Wn:0        []                1
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/Wp:0        []                1
linear2/Wn:0        []                1
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/Wp:0        []                1
linear3/Wn:0        []                1
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/Wp:0    []                1
last_linear/Wn:0    []                1
last_linear/b:0     [255]           255[36m
Total #vars=28, #params=1400881, size=5.34MB[0m
[32m[0322 11:43:55 @base.py:196][0m Setup callbacks graph ...
[32m[0322 11:43:56 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0322 11:43:56 @ttq_run.py:71][0m Ternarizing weight linear0/W
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear0/Wp
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear0/Wn
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear0/b
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear0/bn/beta
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear0/bn/gamma
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear0/bn/mean/EMA
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear0/bn/variance/EMA
[32m[0322 11:43:56 @ttq_run.py:71][0m Ternarizing weight linear1/W
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear1/Wp
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear1/Wn
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear1/b
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear1/bn/beta
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear1/bn/gamma
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear1/bn/mean/EMA
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear1/bn/variance/EMA
[32m[0322 11:43:56 @ttq_run.py:71][0m Ternarizing weight linear2/W
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear2/Wp
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear2/Wn
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear2/b
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear2/bn/beta
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear2/bn/gamma
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear2/bn/mean/EMA
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear2/bn/variance/EMA
[32m[0322 11:43:56 @ttq_run.py:71][0m Ternarizing weight linear3/W
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear3/Wp
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear3/Wn
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear3/b
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear3/bn/beta
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear3/bn/gamma
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear3/bn/mean/EMA
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing linear3/bn/variance/EMA
[32m[0322 11:43:56 @ttq_run.py:71][0m Ternarizing weight last_linear/W
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing last_linear/Wp
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing last_linear/Wn
[32m[0322 11:43:56 @ttq_run.py:59][0m Not ternarizing last_linear/b
[32m[0322 11:43:56 @ttq_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:43:56 @ttq_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0322 11:43:56 @collection.py:153][0m These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 59->89)
[32m[0322 11:43:56 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0322 11:43:56 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0322 11:43:56 @sessinit.py:89][0m [5m[31mWRN[0m The following variables are in the graph, but not found in the checkpoint: linear0/Wp, linear0/Wn, linear1/Wp, linear1/Wn, linear2/Wp, linear2/Wn, linear3/Wp, linear3/Wn, last_linear/Wp, last_linear/Wn
[32m[0322 11:43:57 @base.py:212][0m Creating the session ...
2018-03-22 11:43:57.277022: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-22 11:44:00.093262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:03:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-22 11:44:00.093325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
[32m[0322 11:44:00 @base.py:220][0m Initializing the session ...
[32m[0322 11:44:00 @sessinit.py:116][0m Restoring checkpoint from ../dorefa/real/train_log/fcn2_w_4_a_32_quant_ends_True/model-3296139 ...
[32m[0322 11:44:00 @base.py:227][0m Graph Finalized.
[32m[0322 11:44:00 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0322 11:44:00 @steps.py:127][0m Start training with global_step=3296139
[32m[0322 11:44:02 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20803/173481[03:00<22:05,115.18it/s] 13%|#3        |22992/173481[03:20<21:46,115.18it/s] 18%|#8        |31297/173481[06:00<30:36,77.41it/s]  19%|#9        |33148/173481[06:20<30:12,77.41it/s] 28%|##7       |48528/173481[09:00<24:19,85.60it/s] 29%|##8       |49596/173481[09:20<24:07,85.60it/s] 38%|###8      |66544/173481[12:00<19:18,92.28it/s] 39%|###9      |67694/173481[12:10<19:06,92.28it/s] 47%|####7     |82121/173481[15:00<17:02,89.32it/s] 48%|####7     |82712/173481[15:10<16:56,89.32it/s] 52%|#####1    |89605/173481[18:00<24:39,56.70it/s] 52%|#####1    |89871/173481[18:10<24:34,56.70it/s] 59%|#####8    |101863/173481[21:00<19:17,61.87it/s] 59%|#####9    |102510/173481[21:11<19:07,61.87it/s] 65%|######5   |113569/173481[24:00<15:44,63.41it/s] 66%|######5   |114282/173481[24:11<15:33,63.41it/s] 72%|#######2  |125233/173481[27:00<12:32,64.09it/s] 73%|#######2  |125868/173481[27:11<12:22,64.09it/s] 79%|#######8  |136845/173481[30:00<09:29,64.30it/s] 79%|#######9  |137550/173481[30:11<09:18,64.30it/s] 86%|########5 |148957/173481[33:00<06:12,65.76it/s] 86%|########6 |149693/173481[33:11<06:01,65.76it/s] 93%|#########2|161209/173481[36:01<03:03,66.88it/s] 93%|#########3|161983/173481[36:11<02:51,66.88it/s]100%|#########9|173149/173481[39:01<00:04,66.60it/s]100%|##########|173481/173481[39:06<00:00,73.94it/s]
[32m[0322 12:23:08 @base.py:257][0m Epoch 1 (global_step 3469620) finished, time:2346.35 sec.
[32m[0322 12:23:08 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-3469620.
  0%|          |0/18822[00:00<?,?it/s] 85%|########5 |16059/18822[03:00<00:30,89.22it/s] 90%|########9 |16920/18822[03:10<00:21,89.22it/s]100%|##########|18822/18822[03:30<00:00,89.52it/s]
0
[32m[0322 12:26:39 @monitor.py:363][0m QueueInput/queue_size: 1.9025
[32m[0322 12:26:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.853
[32m[0322 12:26:39 @monitor.py:363][0m activation-summaries/output-rms: 0.032176
[32m[0322 12:26:39 @monitor.py:363][0m cross_entropy_loss: 2.4501
[32m[0322 12:26:39 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77794
[32m[0322 12:26:39 @monitor.py:363][0m last_linear/W_0_percent_p: 0.096226
[32m[0322 12:26:39 @monitor.py:363][0m last_linear/W_0_sparsity: 0.12583
[32m[0322 12:26:39 @monitor.py:363][0m last_linear/Wn_0: 0.46074
[32m[0322 12:26:39 @monitor.py:363][0m last_linear/Wp_0: 0.39045
[32m[0322 12:26:39 @monitor.py:363][0m linear0/W_0_percent_n: 0.17219
[32m[0322 12:26:39 @monitor.py:363][0m linear0/W_0_percent_p: 0.1733
[32m[0322 12:26:39 @monitor.py:363][0m linear0/W_0_sparsity: 0.65451
[32m[0322 12:26:39 @monitor.py:363][0m linear0/Wn_0: 1.0425
[32m[0322 12:26:39 @monitor.py:363][0m linear0/Wp_0: 0.95553
[32m[0322 12:26:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.34274
[32m[0322 12:26:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.31517
[32m[0322 12:26:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.34209
[32m[0322 12:26:39 @monitor.py:363][0m linear1/Wn_0: 0.9773
[32m[0322 12:26:39 @monitor.py:363][0m linear1/Wp_0: 1.0207
[32m[0322 12:26:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.39206
[32m[0322 12:26:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.36958
[32m[0322 12:26:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.23836
[32m[0322 12:26:39 @monitor.py:363][0m linear2/Wn_0: 1.0059
[32m[0322 12:26:39 @monitor.py:363][0m linear2/Wp_0: 0.99201
[32m[0322 12:26:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.41859
[32m[0322 12:26:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.35273
[32m[0322 12:26:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.22867
[32m[0322 12:26:39 @monitor.py:363][0m linear3/Wn_0: 1.0311
[32m[0322 12:26:39 @monitor.py:363][0m linear3/Wp_0: 0.96683
[32m[0322 12:26:39 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72817
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9887
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.35383
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32414
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30542
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29661
[32m[0322 12:26:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 12:26:39 @monitor.py:363][0m train-error-top1: 0.61497
[32m[0322 12:26:39 @monitor.py:363][0m val-error-top1: 0.65612
[32m[0322 12:26:39 @monitor.py:363][0m val-utt-error: 0.24764
[32m[0322 12:26:39 @monitor.py:363][0m validation_cost: 2.6701
[32m[0322 12:26:39 @monitor.py:363][0m wd_cost: 0.00026109
[32m[0322 12:26:39 @group.py:42][0m Callbacks took 210.569 sec in total. InferenceRunner: 210.265sec
[32m[0322 12:26:39 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12580/173481[03:00<38:22,69.87it/s]  8%|7         |13281/173481[03:10<38:12,69.87it/s] 14%|#4        |24580/173481[06:00<36:22,68.22it/s] 15%|#4        |25269/173481[06:10<36:12,68.22it/s] 21%|##1       |36740/173481[09:00<33:34,67.89it/s] 22%|##1       |37419/173481[09:10<33:24,67.89it/s] 28%|##7       |47794/173481[12:00<32:29,64.48it/s] 28%|##7       |48531/173481[12:10<32:17,64.48it/s] 35%|###4      |60198/173481[15:00<28:20,66.62it/s] 35%|###5      |60911/173481[15:10<28:09,66.62it/s] 42%|####1     |72216/173481[18:00<25:18,66.69it/s] 42%|####2     |72918/173481[18:10<25:07,66.69it/s] 48%|####8     |83553/173481[21:00<23:08,64.79it/s] 49%|####8     |84243/173481[21:11<22:57,64.79it/s] 54%|#####3    |93556/173481[24:00<22:16,59.82it/s] 54%|#####4    |94203/173481[24:11<22:05,59.82it/s] 61%|######    |105604/173481[27:00<17:54,63.17it/s] 61%|######1   |106396/173481[27:11<17:41,63.17it/s] 68%|######7   |117622/173481[30:00<14:20,64.92it/s] 68%|######8   |118439/173481[30:11<14:07,64.92it/s] 75%|#######4  |129997/173481[33:00<10:51,66.78it/s] 75%|#######5  |130792/173481[33:11<10:39,66.78it/s] 82%|########2 |142324/173481[36:00<07:40,67.62it/s] 83%|########2 |143170/173481[36:11<07:28,67.62it/s] 89%|########9 |154840/173481[39:00<04:31,68.56it/s] 90%|########9 |155691/173481[39:12<04:19,68.56it/s] 97%|#########6|167701/173481[42:00<01:22,69.97it/s] 97%|#########7|168608/173481[42:12<01:09,69.97it/s]100%|##########|173481/173481[43:23<00:00,66.65it/s]
[32m[0322 13:10:02 @base.py:257][0m Epoch 2 (global_step 3643101) finished, time:2603.02 sec.
[32m[0322 13:10:02 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-3643101.
[32m[0322 13:10:03 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:31<00:00,124.33it/s]
1
[32m[0322 13:12:34 @monitor.py:363][0m QueueInput/queue_size: 0.98072
[32m[0322 13:12:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 26.416
[32m[0322 13:12:34 @monitor.py:363][0m activation-summaries/output-rms: 0.035523
[32m[0322 13:12:34 @monitor.py:363][0m cross_entropy_loss: 2.0693
[32m[0322 13:12:34 @monitor.py:363][0m last_linear/W_0_percent_n: 0.76303
[32m[0322 13:12:34 @monitor.py:363][0m last_linear/W_0_percent_p: 0.097323
[32m[0322 13:12:34 @monitor.py:363][0m last_linear/W_0_sparsity: 0.13964
[32m[0322 13:12:34 @monitor.py:363][0m last_linear/Wn_0: 0.41871
[32m[0322 13:12:34 @monitor.py:363][0m last_linear/Wp_0: 0.37029
[32m[0322 13:12:34 @monitor.py:363][0m linear0/W_0_percent_n: 0.14102
[32m[0322 13:12:34 @monitor.py:363][0m linear0/W_0_percent_p: 0.14097
[32m[0322 13:12:34 @monitor.py:363][0m linear0/W_0_sparsity: 0.71801
[32m[0322 13:12:34 @monitor.py:363][0m linear0/Wn_0: 1.0326
[32m[0322 13:12:34 @monitor.py:363][0m linear0/Wp_0: 0.96563
[32m[0322 13:12:34 @monitor.py:363][0m linear1/W_0_percent_n: 0.31224
[32m[0322 13:12:34 @monitor.py:363][0m linear1/W_0_percent_p: 0.28231
[32m[0322 13:12:34 @monitor.py:363][0m linear1/W_0_sparsity: 0.40544
[32m[0322 13:12:34 @monitor.py:363][0m linear1/Wn_0: 0.97909
[32m[0322 13:12:34 @monitor.py:363][0m linear1/Wp_0: 1.019
[32m[0322 13:12:34 @monitor.py:363][0m linear2/W_0_percent_n: 0.36336
[32m[0322 13:12:34 @monitor.py:363][0m linear2/W_0_percent_p: 0.33646
[32m[0322 13:12:34 @monitor.py:363][0m linear2/W_0_sparsity: 0.30018
[32m[0322 13:12:34 @monitor.py:363][0m linear2/Wn_0: 1.0102
[32m[0322 13:12:34 @monitor.py:363][0m linear2/Wp_0: 0.98775
[32m[0322 13:12:34 @monitor.py:363][0m linear3/W_0_percent_n: 0.38575
[32m[0322 13:12:34 @monitor.py:363][0m linear3/W_0_percent_p: 0.31692
[32m[0322 13:12:34 @monitor.py:363][0m linear3/W_0_sparsity: 0.29734
[32m[0322 13:12:34 @monitor.py:363][0m linear3/Wn_0: 1.0141
[32m[0322 13:12:34 @monitor.py:363][0m linear3/Wp_0: 0.98384
[32m[0322 13:12:34 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.75847
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9755
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.38029
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33763
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31518
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30623
[32m[0322 13:12:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 13:12:34 @monitor.py:363][0m train-error-top1: 0.53023
[32m[0322 13:12:34 @monitor.py:363][0m val-error-top1: 0.64126
[32m[0322 13:12:34 @monitor.py:363][0m val-utt-error: 0.25194
[32m[0322 13:12:34 @monitor.py:363][0m validation_cost: 2.6022
[32m[0322 13:12:34 @monitor.py:363][0m wd_cost: 0.0002878
[32m[0322 13:12:34 @group.py:42][0m Callbacks took 152.206 sec in total. InferenceRunner: 151.397sec
[32m[0322 13:12:34 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12439/173481[03:00<38:50,69.10it/s]  8%|7         |13111/173481[03:10<38:40,69.10it/s] 14%|#4        |24559/173481[06:00<36:23,68.19it/s] 15%|#4        |25165/173481[06:10<36:14,68.19it/s] 21%|##1       |36638/173481[09:00<33:42,67.64it/s] 22%|##1       |37366/173481[09:10<33:32,67.64it/s] 27%|##7       |47516/173481[12:00<32:53,63.84it/s] 28%|##7       |48205/173481[12:10<32:42,63.84it/s] 34%|###4      |59598/173481[15:00<29:00,65.44it/s] 35%|###4      |60371/173481[15:10<28:48,65.44it/s] 41%|####1     |71455/173481[18:00<25:54,65.65it/s] 42%|####1     |72138/173481[18:10<25:43,65.65it/s] 49%|####8     |84877/173481[21:00<21:08,69.82it/s] 49%|####9     |85638/173481[21:11<20:58,69.82it/s] 55%|#####5    |95939/173481[24:00<19:46,65.37it/s] 56%|#####5    |96804/173481[24:11<19:32,65.37it/s] 62%|######2   |108253/173481[27:00<16:15,66.85it/s] 63%|######2   |109014/173481[27:11<16:04,66.85it/s] 69%|######9   |120511/173481[30:00<13:05,67.47it/s] 70%|######9   |121265/173481[30:11<12:53,67.47it/s] 76%|#######6  |131854/173481[33:00<10:38,65.17it/s] 76%|#######6  |132558/173481[33:11<10:27,65.17it/s] 82%|########2 |142909/173481[36:00<08:03,63.23it/s] 83%|########2 |143670/173481[36:11<07:51,63.23it/s] 89%|########9 |155251/173481[39:00<04:37,65.79it/s] 90%|######### |156163/173481[39:12<04:23,65.79it/s] 97%|#########6|167905/173481[42:00<01:22,67.97it/s] 97%|#########7|168666/173481[42:12<01:10,67.97it/s]100%|##########|173481/173481[43:21<00:00,66.67it/s]
[32m[0322 13:55:56 @base.py:257][0m Epoch 3 (global_step 3816582) finished, time:2601.92 sec.
[32m[0322 13:55:56 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-3816582.
[32m[0322 13:55:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:44<00:00,114.56it/s]
2
[32m[0322 13:58:41 @monitor.py:363][0m QueueInput/queue_size: 1.0524
[32m[0322 13:58:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 24.959
[32m[0322 13:58:41 @monitor.py:363][0m activation-summaries/output-rms: 0.036265
[32m[0322 13:58:41 @monitor.py:363][0m cross_entropy_loss: 2.0977
[32m[0322 13:58:41 @monitor.py:363][0m last_linear/W_0_percent_n: 0.75524
[32m[0322 13:58:41 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10123
[32m[0322 13:58:41 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14353
[32m[0322 13:58:41 @monitor.py:363][0m last_linear/Wn_0: 0.40812
[32m[0322 13:58:41 @monitor.py:363][0m last_linear/Wp_0: 0.37521
[32m[0322 13:58:41 @monitor.py:363][0m linear0/W_0_percent_n: 0.1245
[32m[0322 13:58:41 @monitor.py:363][0m linear0/W_0_percent_p: 0.12465
[32m[0322 13:58:41 @monitor.py:363][0m linear0/W_0_sparsity: 0.75085
[32m[0322 13:58:41 @monitor.py:363][0m linear0/Wn_0: 1.0292
[32m[0322 13:58:41 @monitor.py:363][0m linear0/Wp_0: 0.96915
[32m[0322 13:58:41 @monitor.py:363][0m linear1/W_0_percent_n: 0.28891
[32m[0322 13:58:41 @monitor.py:363][0m linear1/W_0_percent_p: 0.25859
[32m[0322 13:58:41 @monitor.py:363][0m linear1/W_0_sparsity: 0.4525
[32m[0322 13:58:41 @monitor.py:363][0m linear1/Wn_0: 0.97815
[32m[0322 13:58:41 @monitor.py:363][0m linear1/Wp_0: 1.0201
[32m[0322 13:58:41 @monitor.py:363][0m linear2/W_0_percent_n: 0.34775
[32m[0322 13:58:41 @monitor.py:363][0m linear2/W_0_percent_p: 0.31998
[32m[0322 13:58:41 @monitor.py:363][0m linear2/W_0_sparsity: 0.33227
[32m[0322 13:58:41 @monitor.py:363][0m linear2/Wn_0: 1.0096
[32m[0322 13:58:41 @monitor.py:363][0m linear2/Wp_0: 0.98837
[32m[0322 13:58:41 @monitor.py:363][0m linear3/W_0_percent_n: 0.36418
[32m[0322 13:58:41 @monitor.py:363][0m linear3/W_0_percent_p: 0.29626
[32m[0322 13:58:41 @monitor.py:363][0m linear3/W_0_sparsity: 0.33956
[32m[0322 13:58:41 @monitor.py:363][0m linear3/Wn_0: 1.0102
[32m[0322 13:58:41 @monitor.py:363][0m linear3/Wp_0: 0.98779
[32m[0322 13:58:41 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.78372
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9656
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.40233
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.34914
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.32315
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.31423
[32m[0322 13:58:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 13:58:41 @monitor.py:363][0m train-error-top1: 0.54196
[32m[0322 13:58:41 @monitor.py:363][0m val-error-top1: 0.64774
[32m[0322 13:58:41 @monitor.py:363][0m val-utt-error: 0.26687
[32m[0322 13:58:41 @monitor.py:363][0m validation_cost: 2.6917
[32m[0322 13:58:41 @monitor.py:363][0m wd_cost: 0.00031117
[32m[0322 13:58:41 @group.py:42][0m Callbacks took 165.273 sec in total. InferenceRunner: 164.320sec
[32m[0322 13:58:41 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13372/173481[03:00<35:55,74.28it/s]  8%|8         |14092/173481[03:10<35:45,74.28it/s] 15%|#5        |26471/173481[06:00<33:19,73.52it/s] 16%|#5        |27180/173481[06:10<33:10,73.52it/s] 22%|##2       |38470/173481[09:00<32:11,69.91it/s] 23%|##2       |39109/173481[09:10<32:01,69.91it/s] 29%|##8       |50103/173481[12:00<30:36,67.17it/s] 29%|##9       |50784/173481[12:10<30:26,67.17it/s] 35%|###5      |61213/173481[15:00<29:05,64.33it/s] 36%|###5      |61929/173481[15:10<28:54,64.33it/s] 43%|####2     |74498/173481[18:00<23:59,68.74it/s] 43%|####3     |75340/173481[18:11<23:47,68.74it/s] 50%|####9     |86140/173481[21:00<21:50,66.65it/s] 50%|#####     |86829/173481[21:11<21:40,66.65it/s] 57%|#####7    |99363/173481[24:00<17:40,69.89it/s] 58%|#####7    |100155/173481[24:11<17:29,69.89it/s] 65%|######4   |111998/173481[27:00<14:37,70.04it/s] 65%|######4   |112704/173481[27:11<14:27,70.04it/s] 72%|#######1  |124267/173481[30:00<11:52,69.09it/s] 72%|#######2  |125050/173481[30:11<11:41,69.09it/s] 79%|#######9  |137264/173481[33:00<08:32,70.61it/s] 80%|#######9  |138117/173481[33:11<08:20,70.61it/s] 87%|########6 |150737/173481[36:00<05:12,72.67it/s] 87%|########7 |151647/173481[36:11<05:00,72.67it/s] 94%|#########3|162964/173481[39:00<02:29,70.22it/s] 94%|#########4|163892/173481[39:12<02:16,70.22it/s]100%|##########|173481/173481[41:23<00:00,69.85it/s]
[32m[0322 14:40:05 @base.py:257][0m Epoch 4 (global_step 3990063) finished, time:2483.58 sec.
[32m[0322 14:40:05 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-3990063.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:22<00:00,132.39it/s]
3
[32m[0322 14:42:27 @monitor.py:363][0m QueueInput/queue_size: 1.0136
[32m[0322 14:42:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 24.324
[32m[0322 14:42:27 @monitor.py:363][0m activation-summaries/output-rms: 0.035977
[32m[0322 14:42:27 @monitor.py:363][0m cross_entropy_loss: 2.0485
[32m[0322 14:42:27 @monitor.py:363][0m last_linear/W_0_percent_n: 0.75145
[32m[0322 14:42:27 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10284
[32m[0322 14:42:27 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14571
[32m[0322 14:42:27 @monitor.py:363][0m last_linear/Wn_0: 0.40207
[32m[0322 14:42:27 @monitor.py:363][0m last_linear/Wp_0: 0.37702
[32m[0322 14:42:27 @monitor.py:363][0m linear0/W_0_percent_n: 0.11892
[32m[0322 14:42:27 @monitor.py:363][0m linear0/W_0_percent_p: 0.11891
[32m[0322 14:42:27 @monitor.py:363][0m linear0/W_0_sparsity: 0.76216
[32m[0322 14:42:27 @monitor.py:363][0m linear0/Wn_0: 1.0276
[32m[0322 14:42:27 @monitor.py:363][0m linear0/Wp_0: 0.97109
[32m[0322 14:42:27 @monitor.py:363][0m linear1/W_0_percent_n: 0.27791
[32m[0322 14:42:27 @monitor.py:363][0m linear1/W_0_percent_p: 0.247
[32m[0322 14:42:27 @monitor.py:363][0m linear1/W_0_sparsity: 0.47509
[32m[0322 14:42:27 @monitor.py:363][0m linear1/Wn_0: 0.97922
[32m[0322 14:42:27 @monitor.py:363][0m linear1/Wp_0: 1.0192
[32m[0322 14:42:27 @monitor.py:363][0m linear2/W_0_percent_n: 0.33597
[32m[0322 14:42:27 @monitor.py:363][0m linear2/W_0_percent_p: 0.30783
[32m[0322 14:42:27 @monitor.py:363][0m linear2/W_0_sparsity: 0.35621
[32m[0322 14:42:27 @monitor.py:363][0m linear2/Wn_0: 1.0092
[32m[0322 14:42:27 @monitor.py:363][0m linear2/Wp_0: 0.98887
[32m[0322 14:42:27 @monitor.py:363][0m linear3/W_0_percent_n: 0.35346
[32m[0322 14:42:27 @monitor.py:363][0m linear3/W_0_percent_p: 0.28547
[32m[0322 14:42:27 @monitor.py:363][0m linear3/W_0_sparsity: 0.36107
[32m[0322 14:42:27 @monitor.py:363][0m linear3/Wn_0: 1.009
[32m[0322 14:42:27 @monitor.py:363][0m linear3/Wp_0: 0.98911
[32m[0322 14:42:27 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.79762
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9605
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.41451
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.35552
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.32749
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.31857
[32m[0322 14:42:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 14:42:27 @monitor.py:363][0m train-error-top1: 0.53047
[32m[0322 14:42:27 @monitor.py:363][0m val-error-top1: 0.62439
[32m[0322 14:42:27 @monitor.py:363][0m val-utt-error: 0.22235
[32m[0322 14:42:27 @monitor.py:363][0m validation_cost: 2.5472
[32m[0322 14:42:27 @monitor.py:363][0m wd_cost: 6.4895e-05
[32m[0322 14:42:27 @group.py:42][0m Callbacks took 142.453 sec in total. InferenceRunner: 142.191sec
[32m[0322 14:42:27 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12971/173481[03:00<37:07,72.06it/s]  8%|7         |13711/173481[03:10<36:57,72.06it/s] 15%|#4        |25933/173481[06:00<34:08,72.03it/s] 15%|#5        |26635/173481[06:10<33:58,72.03it/s] 22%|##1       |37975/173481[09:00<32:33,69.35it/s] 22%|##2       |38627/173481[09:10<32:24,69.35it/s] 29%|##8       |49855/173481[12:00<30:28,67.63it/s] 29%|##9       |50567/173481[12:10<30:17,67.63it/s] 36%|###6      |62716/173481[15:00<26:34,69.48it/s] 37%|###6      |63440/173481[15:10<26:23,69.48it/s] 44%|####3     |75769/173481[18:00<22:56,70.96it/s] 44%|####4     |76536/173481[18:10<22:46,70.96it/s] 50%|#####     |86952/173481[21:00<21:46,66.25it/s] 51%|#####     |87846/173481[21:11<21:32,66.25it/s] 58%|#####7    |100441/173481[24:00<17:18,70.32it/s] 58%|#####8    |101221/173481[24:11<17:07,70.32it/s] 65%|######5   |113567/173481[27:00<13:56,71.60it/s] 66%|######5   |114376/173481[27:11<13:45,71.60it/s] 73%|#######2  |126351/173481[30:00<11:00,71.31it/s] 73%|#######3  |127142/173481[30:11<10:49,71.31it/s] 80%|########  |138798/173481[33:00<08:13,70.21it/s] 80%|########  |139646/173481[33:11<08:01,70.21it/s] 88%|########7 |151915/173481[36:00<05:01,71.51it/s] 88%|########8 |152742/173481[36:11<04:50,71.51it/s] 96%|#########5|165997/173481[39:00<01:40,74.72it/s] 96%|#########6|166776/173481[39:12<01:29,74.72it/s]100%|##########|173481/173481[40:33<00:00,71.28it/s]
[32m[0322 15:23:01 @base.py:257][0m Epoch 5 (global_step 4163544) finished, time:2433.64 sec.
[32m[0322 15:23:01 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-4163544.
[32m[0322 15:23:01 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,169.58it/s]
4
[32m[0322 15:24:52 @monitor.py:363][0m QueueInput/queue_size: 0.81269
[32m[0322 15:24:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 23.625
[32m[0322 15:24:52 @monitor.py:363][0m activation-summaries/output-rms: 0.036725
[32m[0322 15:24:52 @monitor.py:363][0m cross_entropy_loss: 2.0002
[32m[0322 15:24:52 @monitor.py:363][0m last_linear/W_0_percent_n: 0.7452
[32m[0322 15:24:52 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10402
[32m[0322 15:24:52 @monitor.py:363][0m last_linear/W_0_sparsity: 0.15076
[32m[0322 15:24:52 @monitor.py:363][0m last_linear/Wn_0: 0.39603
[32m[0322 15:24:52 @monitor.py:363][0m last_linear/Wp_0: 0.37792
[32m[0322 15:24:52 @monitor.py:363][0m linear0/W_0_percent_n: 0.11396
[32m[0322 15:24:52 @monitor.py:363][0m linear0/W_0_percent_p: 0.1137
[32m[0322 15:24:52 @monitor.py:363][0m linear0/W_0_sparsity: 0.77234
[32m[0322 15:24:52 @monitor.py:363][0m linear0/Wn_0: 1.0283
[32m[0322 15:24:52 @monitor.py:363][0m linear0/Wp_0: 0.97063
[32m[0322 15:24:52 @monitor.py:363][0m linear1/W_0_percent_n: 0.27283
[32m[0322 15:24:52 @monitor.py:363][0m linear1/W_0_percent_p: 0.24174
[32m[0322 15:24:52 @monitor.py:363][0m linear1/W_0_sparsity: 0.48543
[32m[0322 15:24:52 @monitor.py:363][0m linear1/Wn_0: 0.97797
[32m[0322 15:24:52 @monitor.py:363][0m linear1/Wp_0: 1.0206
[32m[0322 15:24:52 @monitor.py:363][0m linear2/W_0_percent_n: 0.32563
[32m[0322 15:24:52 @monitor.py:363][0m linear2/W_0_percent_p: 0.29765
[32m[0322 15:24:52 @monitor.py:363][0m linear2/W_0_sparsity: 0.37672
[32m[0322 15:24:52 @monitor.py:363][0m linear2/Wn_0: 1.0102
[32m[0322 15:24:52 @monitor.py:363][0m linear2/Wp_0: 0.98793
[32m[0322 15:24:52 @monitor.py:363][0m linear3/W_0_percent_n: 0.34479
[32m[0322 15:24:52 @monitor.py:363][0m linear3/W_0_percent_p: 0.27643
[32m[0322 15:24:52 @monitor.py:363][0m linear3/W_0_sparsity: 0.37878
[32m[0322 15:24:52 @monitor.py:363][0m linear3/Wn_0: 1.0091
[32m[0322 15:24:52 @monitor.py:363][0m linear3/Wp_0: 0.98905
[32m[0322 15:24:52 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.81134
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9553
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.42666
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.36191
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.33174
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.32288
[32m[0322 15:24:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 15:24:52 @monitor.py:363][0m train-error-top1: 0.51608
[32m[0322 15:24:52 @monitor.py:363][0m val-error-top1: 0.65108
[32m[0322 15:24:52 @monitor.py:363][0m val-utt-error: 0.28111
[32m[0322 15:24:52 @monitor.py:363][0m validation_cost: 2.7403
[32m[0322 15:24:52 @monitor.py:363][0m wd_cost: 6.7601e-05
[32m[0322 15:24:52 @group.py:42][0m Callbacks took 111.679 sec in total. InferenceRunner: 111.009sec
[32m[0322 15:24:52 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11260/173481[03:00<43:13,62.54it/s]  7%|6         |11991/173481[03:10<43:02,62.54it/s] 14%|#3        |23500/173481[06:00<38:22,65.14it/s] 14%|#3        |24100/173481[06:10<38:13,65.14it/s] 20%|#9        |34684/173481[09:00<36:22,63.59it/s] 20%|##        |35343/173481[09:10<36:12,63.59it/s] 27%|##7       |46901/173481[12:00<32:07,65.66it/s] 27%|##7       |47706/173481[12:10<31:55,65.66it/s] 35%|###5      |61529/173481[15:00<25:41,72.64it/s] 36%|###5      |62291/173481[15:10<25:30,72.64it/s] 43%|####2     |73865/173481[18:00<23:32,70.52it/s] 43%|####2     |74570/173481[18:11<23:22,70.52it/s] 49%|####8     |84810/173481[21:00<22:37,65.30it/s] 49%|####9     |85449/173481[21:11<22:28,65.30it/s] 56%|#####5    |96310/173481[24:00<19:55,64.56it/s] 56%|#####5    |96453/173481[24:11<19:53,64.56it/s] 64%|######3   |110711/173481[27:00<14:38,71.46it/s] 64%|######4   |111648/173481[27:11<14:25,71.46it/s] 71%|#######   |122536/173481[30:00<12:24,68.41it/s] 71%|#######   |122727/173481[30:11<12:21,68.41it/s] 80%|########  |138983/173481[33:00<07:20,78.24it/s] 81%|########  |140204/173481[33:11<07:05,78.24it/s] 90%|######### |156510/173481[36:00<03:15,86.76it/s] 91%|######### |157518/173481[36:12<03:03,86.76it/s]100%|##########|173481/173481[38:55<00:00,74.29it/s]
[32m[0322 16:03:48 @base.py:257][0m Epoch 6 (global_step 4337025) finished, time:2335.21 sec.
[32m[0322 16:03:48 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-4337025.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:27<00:00,127.28it/s]
5
[32m[0322 16:06:16 @monitor.py:363][0m QueueInput/queue_size: 1.0836
[32m[0322 16:06:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 23.253
[32m[0322 16:06:16 @monitor.py:363][0m activation-summaries/output-rms: 0.038143
[32m[0322 16:06:16 @monitor.py:363][0m cross_entropy_loss: 1.9475
[32m[0322 16:06:16 @monitor.py:363][0m last_linear/W_0_percent_n: 0.74304
[32m[0322 16:06:16 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10654
[32m[0322 16:06:16 @monitor.py:363][0m last_linear/W_0_sparsity: 0.1504
[32m[0322 16:06:16 @monitor.py:363][0m last_linear/Wn_0: 0.39387
[32m[0322 16:06:16 @monitor.py:363][0m last_linear/Wp_0: 0.37982
[32m[0322 16:06:16 @monitor.py:363][0m linear0/W_0_percent_n: 0.11123
[32m[0322 16:06:16 @monitor.py:363][0m linear0/W_0_percent_p: 0.11097
[32m[0322 16:06:16 @monitor.py:363][0m linear0/W_0_sparsity: 0.7778
[32m[0322 16:06:16 @monitor.py:363][0m linear0/Wn_0: 1.0284
[32m[0322 16:06:16 @monitor.py:363][0m linear0/Wp_0: 0.97088
[32m[0322 16:06:16 @monitor.py:363][0m linear1/W_0_percent_n: 0.26594
[32m[0322 16:06:16 @monitor.py:363][0m linear1/W_0_percent_p: 0.23537
[32m[0322 16:06:16 @monitor.py:363][0m linear1/W_0_sparsity: 0.49867
[32m[0322 16:06:16 @monitor.py:363][0m linear1/Wn_0: 0.97794
[32m[0322 16:06:16 @monitor.py:363][0m linear1/Wp_0: 1.0207
[32m[0322 16:06:16 @monitor.py:363][0m linear2/W_0_percent_n: 0.31905
[32m[0322 16:06:16 @monitor.py:363][0m linear2/W_0_percent_p: 0.29098
[32m[0322 16:06:16 @monitor.py:363][0m linear2/W_0_sparsity: 0.38998
[32m[0322 16:06:16 @monitor.py:363][0m linear2/Wn_0: 1.0102
[32m[0322 16:06:16 @monitor.py:363][0m linear2/Wp_0: 0.98801
[32m[0322 16:06:16 @monitor.py:363][0m linear3/W_0_percent_n: 0.33747
[32m[0322 16:06:16 @monitor.py:363][0m linear3/W_0_percent_p: 0.26911
[32m[0322 16:06:16 @monitor.py:363][0m linear3/W_0_sparsity: 0.39341
[32m[0322 16:06:16 @monitor.py:363][0m linear3/Wn_0: 1.008
[32m[0322 16:06:16 @monitor.py:363][0m linear3/Wp_0: 0.99015
[32m[0322 16:06:16 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.8215
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9515
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.4357
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.36663
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.33485
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.32606
[32m[0322 16:06:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 16:06:16 @monitor.py:363][0m train-error-top1: 0.50867
[32m[0322 16:06:16 @monitor.py:363][0m val-error-top1: 0.64956
[32m[0322 16:06:16 @monitor.py:363][0m val-utt-error: 0.27888
[32m[0322 16:06:16 @monitor.py:363][0m validation_cost: 2.7193
[32m[0322 16:06:16 @monitor.py:363][0m wd_cost: 1.3929e-05
[32m[0322 16:06:16 @group.py:42][0m Callbacks took 148.192 sec in total. InferenceRunner: 147.899sec
[32m[0322 16:06:16 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19204/173481[03:00<24:06,106.69it/s] 12%|#1        |20236/173481[03:10<23:56,106.69it/s] 22%|##1       |38148/173481[06:00<21:17,105.96it/s] 23%|##2       |39230/173481[06:10<21:07,105.96it/s] 32%|###2      |56123/173481[09:00<19:01,102.82it/s] 33%|###2      |57198/173481[09:10<18:50,102.82it/s] 43%|####3     |74934/173481[12:00<15:50,103.65it/s] 44%|####3     |75673/173481[12:10<15:43,103.65it/s] 50%|####9     |86119/173481[15:00<18:44,77.69it/s]  50%|#####     |86826/173481[15:10<18:35,77.69it/s] 57%|#####6    |98599/173481[18:00<17:02,73.26it/s] 57%|#####7    |98994/173481[18:10<16:56,73.26it/s] 64%|######3   |110321/173481[21:00<15:16,68.95it/s] 64%|######3   |111026/173481[21:11<15:05,68.95it/s] 70%|#######   |122034/173481[24:00<12:48,66.95it/s] 71%|#######   |122715/173481[24:11<12:38,66.95it/s] 77%|#######6  |133443/173481[27:00<10:14,65.12it/s] 77%|#######7  |134190/173481[27:11<10:03,65.12it/s] 84%|########3 |145178/173481[30:00<07:14,65.16it/s] 84%|########4 |145976/173481[30:11<07:02,65.16it/s] 91%|######### |157676/173481[33:00<03:55,67.23it/s] 91%|#########1|158443/173481[33:11<03:43,67.23it/s] 98%|#########8|170513/173481[36:00<00:42,69.21it/s] 99%|#########8|171333/173481[36:11<00:31,69.21it/s]100%|##########|173481/173481[36:43<00:00,78.75it/s]
[32m[0322 16:42:59 @base.py:257][0m Epoch 7 (global_step 4510506) finished, time:2203.05 sec.
[32m[0322 16:42:59 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:35<00:00,120.87it/s]
6
[32m[0322 16:45:35 @monitor.py:363][0m QueueInput/queue_size: 1.0981
[32m[0322 16:45:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.981
[32m[0322 16:45:35 @monitor.py:363][0m activation-summaries/output-rms: 0.036753
[32m[0322 16:45:35 @monitor.py:363][0m cross_entropy_loss: 2.042
[32m[0322 16:45:35 @monitor.py:363][0m last_linear/W_0_percent_n: 0.74072
[32m[0322 16:45:35 @monitor.py:363][0m last_linear/W_0_percent_p: 0.1071
[32m[0322 16:45:35 @monitor.py:363][0m last_linear/W_0_sparsity: 0.15217
[32m[0322 16:45:35 @monitor.py:363][0m last_linear/Wn_0: 0.39181
[32m[0322 16:45:35 @monitor.py:363][0m last_linear/Wp_0: 0.38036
[32m[0322 16:45:35 @monitor.py:363][0m linear0/W_0_percent_n: 0.10894
[32m[0322 16:45:35 @monitor.py:363][0m linear0/W_0_percent_p: 0.10886
[32m[0322 16:45:35 @monitor.py:363][0m linear0/W_0_sparsity: 0.7822
[32m[0322 16:45:35 @monitor.py:363][0m linear0/Wn_0: 1.0281
[32m[0322 16:45:35 @monitor.py:363][0m linear0/Wp_0: 0.97158
[32m[0322 16:45:35 @monitor.py:363][0m linear1/W_0_percent_n: 0.26301
[32m[0322 16:45:35 @monitor.py:363][0m linear1/W_0_percent_p: 0.23156
[32m[0322 16:45:35 @monitor.py:363][0m linear1/W_0_sparsity: 0.50542
[32m[0322 16:45:35 @monitor.py:363][0m linear1/Wn_0: 0.97695
[32m[0322 16:45:35 @monitor.py:363][0m linear1/Wp_0: 1.0219
[32m[0322 16:45:35 @monitor.py:363][0m linear2/W_0_percent_n: 0.31451
[32m[0322 16:45:35 @monitor.py:363][0m linear2/W_0_percent_p: 0.28673
[32m[0322 16:45:35 @monitor.py:363][0m linear2/W_0_sparsity: 0.39875
[32m[0322 16:45:35 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0322 16:45:35 @monitor.py:363][0m linear2/Wp_0: 0.98759
[32m[0322 16:45:35 @monitor.py:363][0m linear3/W_0_percent_n: 0.3346
[32m[0322 16:45:35 @monitor.py:363][0m linear3/W_0_percent_p: 0.26639
[32m[0322 16:45:35 @monitor.py:363][0m linear3/W_0_sparsity: 0.399
[32m[0322 16:45:35 @monitor.py:363][0m linear3/Wn_0: 1.0087
[32m[0322 16:45:35 @monitor.py:363][0m linear3/Wp_0: 0.98957
[32m[0322 16:45:35 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.82822
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.949
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.44173
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.36976
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.33691
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.32818
[32m[0322 16:45:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 16:45:35 @monitor.py:363][0m train-error-top1: 0.52781
[32m[0322 16:45:35 @monitor.py:363][0m val-error-top1: 0.64391
[32m[0322 16:45:35 @monitor.py:363][0m val-utt-error: 0.2505
[32m[0322 16:45:35 @monitor.py:363][0m validation_cost: 2.6682
[32m[0322 16:45:35 @monitor.py:363][0m wd_cost: 1.4204e-05
[32m[0322 16:45:35 @group.py:42][0m Callbacks took 156.105 sec in total. InferenceRunner: 155.739sec
[32m[0322 16:45:35 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16958/173481[03:00<27:41,94.21it/s] 10%|#         |18086/173481[03:10<27:29,94.21it/s] 19%|#9        |33225/173481[06:00<25:20,92.25it/s] 20%|#9        |33921/173481[06:10<25:12,92.25it/s] 26%|##5       |45052/173481[09:00<27:53,76.74it/s] 26%|##6       |45741/173481[09:10<27:44,76.74it/s] 33%|###2      |57091/173481[12:00<27:08,71.47it/s] 33%|###3      |57617/173481[12:10<27:01,71.47it/s] 40%|###9      |68614/173481[15:00<25:52,67.53it/s] 40%|###9      |69354/173481[15:10<25:41,67.53it/s] 46%|####5     |79672/173481[18:00<24:18,64.34it/s] 46%|####6     |80330/173481[18:11<24:07,64.34it/s] 52%|#####2    |90886/173481[21:00<21:44,63.29it/s] 53%|#####2    |91581/173481[21:11<21:33,63.29it/s] 59%|#####8    |102160/173481[24:00<18:52,62.95it/s] 59%|#####9    |102934/173481[24:11<18:40,62.95it/s] 65%|######4   |112714/173481[27:00<16:40,60.72it/s] 65%|######5   |113589/173481[27:11<16:26,60.72it/s] 72%|#######1  |124144/173481[30:00<13:14,62.07it/s] 72%|#######1  |124904/173481[30:11<13:02,62.07it/s] 78%|#######8  |135568/173481[33:00<10:04,62.76it/s] 79%|#######8  |136269/173481[33:11<09:52,62.76it/s] 82%|########2 |142714/173481[36:00<10:32,48.63it/s] 82%|########2 |142773/173481[36:11<10:31,48.63it/s] 89%|########8 |154150/173481[39:00<05:50,55.08it/s] 89%|########9 |154761/173481[39:12<05:39,55.08it/s] 95%|#########5|165501/173481[42:00<02:15,58.80it/s] 96%|#########5|166291/173481[42:12<02:02,58.80it/s]100%|##########|173481/173481[43:55<00:00,65.84it/s]
[32m[0322 17:29:30 @base.py:257][0m Epoch 8 (global_step 4683987) finished, time:2635.02 sec.
[32m[0322 17:29:30 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:38<00:00,118.74it/s]
7
[32m[0322 17:32:09 @monitor.py:363][0m QueueInput/queue_size: 1.0443
[32m[0322 17:32:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.632
[32m[0322 17:32:09 @monitor.py:363][0m activation-summaries/output-rms: 0.037725
[32m[0322 17:32:09 @monitor.py:363][0m cross_entropy_loss: 1.8823
[32m[0322 17:32:09 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73207
[32m[0322 17:32:09 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10612
[32m[0322 17:32:09 @monitor.py:363][0m last_linear/W_0_sparsity: 0.16178
[32m[0322 17:32:09 @monitor.py:363][0m last_linear/Wn_0: 0.38896
[32m[0322 17:32:09 @monitor.py:363][0m last_linear/Wp_0: 0.38142
[32m[0322 17:32:09 @monitor.py:363][0m linear0/W_0_percent_n: 0.10789
[32m[0322 17:32:09 @monitor.py:363][0m linear0/W_0_percent_p: 0.10781
[32m[0322 17:32:09 @monitor.py:363][0m linear0/W_0_sparsity: 0.7843
[32m[0322 17:32:09 @monitor.py:363][0m linear0/Wn_0: 1.0284
[32m[0322 17:32:09 @monitor.py:363][0m linear0/Wp_0: 0.97161
[32m[0322 17:32:09 @monitor.py:363][0m linear1/W_0_percent_n: 0.25803
[32m[0322 17:32:09 @monitor.py:363][0m linear1/W_0_percent_p: 0.22671
[32m[0322 17:32:09 @monitor.py:363][0m linear1/W_0_sparsity: 0.51525
[32m[0322 17:32:09 @monitor.py:363][0m linear1/Wn_0: 0.97717
[32m[0322 17:32:09 @monitor.py:363][0m linear1/Wp_0: 1.0218
[32m[0322 17:32:09 @monitor.py:363][0m linear2/W_0_percent_n: 0.31228
[32m[0322 17:32:09 @monitor.py:363][0m linear2/W_0_percent_p: 0.28378
[32m[0322 17:32:09 @monitor.py:363][0m linear2/W_0_sparsity: 0.40394
[32m[0322 17:32:09 @monitor.py:363][0m linear2/Wn_0: 1.0108
[32m[0322 17:32:09 @monitor.py:363][0m linear2/Wp_0: 0.98745
[32m[0322 17:32:09 @monitor.py:363][0m linear3/W_0_percent_n: 0.33152
[32m[0322 17:32:09 @monitor.py:363][0m linear3/W_0_percent_p: 0.2632
[32m[0322 17:32:09 @monitor.py:363][0m linear3/W_0_sparsity: 0.40528
[32m[0322 17:32:09 @monitor.py:363][0m linear3/Wn_0: 1.0079
[32m[0322 17:32:09 @monitor.py:363][0m linear3/Wp_0: 0.99043
[32m[0322 17:32:09 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.83491
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9465
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.44779
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3729
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.33898
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3303
[32m[0322 17:32:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 17:32:09 @monitor.py:363][0m train-error-top1: 0.48786
[32m[0322 17:32:09 @monitor.py:363][0m val-error-top1: 0.62982
[32m[0322 17:32:09 @monitor.py:363][0m val-utt-error: 0.25135
[32m[0322 17:32:09 @monitor.py:363][0m validation_cost: 2.5898
[32m[0322 17:32:09 @monitor.py:363][0m wd_cost: 1.4483e-05
[32m[0322 17:32:09 @group.py:42][0m Callbacks took 158.834 sec in total. InferenceRunner: 158.536sec
[32m[0322 17:32:09 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16987/173481[03:00<27:38,94.35it/s] 10%|#         |17634/173481[03:10<27:31,94.35it/s] 17%|#6        |28886/173481[06:00<30:59,77.74it/s] 17%|#7        |29586/173481[06:10<30:50,77.74it/s] 24%|##3       |41027/173481[09:00<30:33,72.23it/s] 24%|##3       |41214/173481[09:10<30:31,72.23it/s] 31%|###       |53090/173481[12:00<28:51,69.53it/s] 31%|###1      |53858/173481[12:10<28:40,69.53it/s] 38%|###7      |65813/173481[15:00<25:35,70.10it/s] 38%|###8      |66609/173481[15:10<25:24,70.10it/s] 45%|####5     |78640/173481[18:00<22:21,70.67it/s] 46%|####5     |79392/173481[18:10<22:11,70.67it/s] 53%|#####2    |91330/173481[21:00<19:23,70.59it/s] 53%|#####3    |92036/173481[21:11<19:13,70.59it/s] 59%|#####9    |102889/173481[24:00<17:29,67.24it/s] 60%|#####9    |103576/173481[24:11<17:19,67.24it/s] 66%|######6   |114685/173481[27:00<14:45,66.37it/s] 67%|######6   |115411/173481[27:11<14:34,66.37it/s] 73%|#######2  |126207/173481[30:00<12:05,65.17it/s] 73%|#######3  |126972/173481[30:11<11:53,65.17it/s] 80%|#######9  |138332/173481[33:00<08:50,66.25it/s] 80%|########  |139098/173481[33:11<08:39,66.25it/s] 87%|########7 |151174/173481[36:00<05:24,68.70it/s] 88%|########7 |152111/173481[36:11<05:11,68.70it/s] 94%|#########4|163440/173481[39:00<02:26,68.42it/s] 95%|#########4|164304/173481[39:12<02:14,68.42it/s]100%|##########|173481/173481[41:32<00:00,69.59it/s]
[32m[0322 18:13:42 @base.py:257][0m Epoch 9 (global_step 4857468) finished, time:2492.77 sec.
[32m[0322 18:13:42 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-4857468.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:12<00:00,142.23it/s]
8
[32m[0322 18:15:54 @monitor.py:363][0m QueueInput/queue_size: 0.97017
[32m[0322 18:15:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.02
[32m[0322 18:15:54 @monitor.py:363][0m activation-summaries/output-rms: 0.037099
[32m[0322 18:15:54 @monitor.py:363][0m cross_entropy_loss: 1.994
[32m[0322 18:15:54 @monitor.py:363][0m last_linear/W_0_percent_n: 0.72516
[32m[0322 18:15:54 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10479
[32m[0322 18:15:54 @monitor.py:363][0m last_linear/W_0_sparsity: 0.17
[32m[0322 18:15:54 @monitor.py:363][0m last_linear/Wn_0: 0.38921
[32m[0322 18:15:54 @monitor.py:363][0m last_linear/Wp_0: 0.38306
[32m[0322 18:15:54 @monitor.py:363][0m linear0/W_0_percent_n: 0.10578
[32m[0322 18:15:54 @monitor.py:363][0m linear0/W_0_percent_p: 0.1057
[32m[0322 18:15:54 @monitor.py:363][0m linear0/W_0_sparsity: 0.7885
[32m[0322 18:15:54 @monitor.py:363][0m linear0/Wn_0: 1.0277
[32m[0322 18:15:54 @monitor.py:363][0m linear0/Wp_0: 0.97267
[32m[0322 18:15:54 @monitor.py:363][0m linear1/W_0_percent_n: 0.25913
[32m[0322 18:15:54 @monitor.py:363][0m linear1/W_0_percent_p: 0.22734
[32m[0322 18:15:54 @monitor.py:363][0m linear1/W_0_sparsity: 0.51352
[32m[0322 18:15:54 @monitor.py:363][0m linear1/Wn_0: 0.97689
[32m[0322 18:15:54 @monitor.py:363][0m linear1/Wp_0: 1.0223
[32m[0322 18:15:54 @monitor.py:363][0m linear2/W_0_percent_n: 0.30827
[32m[0322 18:15:54 @monitor.py:363][0m linear2/W_0_percent_p: 0.281
[32m[0322 18:15:54 @monitor.py:363][0m linear2/W_0_sparsity: 0.41072
[32m[0322 18:15:54 @monitor.py:363][0m linear2/Wn_0: 1.0106
[32m[0322 18:15:54 @monitor.py:363][0m linear2/Wp_0: 0.98771
[32m[0322 18:15:54 @monitor.py:363][0m linear3/W_0_percent_n: 0.32792
[32m[0322 18:15:54 @monitor.py:363][0m linear3/W_0_percent_p: 0.2597
[32m[0322 18:15:54 @monitor.py:363][0m linear3/W_0_sparsity: 0.41238
[32m[0322 18:15:54 @monitor.py:363][0m linear3/Wn_0: 1.0074
[32m[0322 18:15:54 @monitor.py:363][0m linear3/Wp_0: 0.99099
[32m[0322 18:15:54 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.83891
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9451
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.45142
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.37479
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34022
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33157
[32m[0322 18:15:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 18:15:54 @monitor.py:363][0m train-error-top1: 0.52143
[32m[0322 18:15:54 @monitor.py:363][0m val-error-top1: 0.63295
[32m[0322 18:15:54 @monitor.py:363][0m val-utt-error: 0.24583
[32m[0322 18:15:54 @monitor.py:363][0m validation_cost: 2.6187
[32m[0322 18:15:54 @monitor.py:363][0m wd_cost: 2.9304e-06
[32m[0322 18:15:54 @group.py:42][0m Callbacks took 132.631 sec in total. InferenceRunner: 132.350sec
[32m[0322 18:15:54 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12754/173481[03:00<37:53,70.69it/s]  8%|8         |14210/173481[03:20<37:33,70.69it/s] 15%|#5        |26157/173481[06:00<33:51,72.52it/s] 16%|#5        |27591/173481[06:20<33:31,72.52it/s] 23%|##2       |39689/173481[09:00<30:12,73.83it/s] 23%|##3       |40403/173481[09:10<30:02,73.83it/s] 30%|###       |52658/173481[12:00<27:36,72.93it/s] 31%|###       |53313/173481[12:10<27:27,72.93it/s] 38%|###7      |65083/173481[15:00<25:28,70.92it/s] 38%|###7      |65871/173481[15:10<25:17,70.92it/s] 45%|####5     |78658/173481[18:00<21:37,73.10it/s] 46%|####5     |79455/173481[18:10<21:26,73.10it/s] 53%|#####3    |92332/173481[21:00<18:09,74.50it/s] 54%|#####3    |93171/173481[21:11<17:57,74.50it/s] 60%|######    |104764/173481[24:00<15:58,71.68it/s] 61%|######    |105592/173481[24:11<15:47,71.68it/s] 68%|######8   |118138/173481[27:00<12:38,72.96it/s] 69%|######8   |118928/173481[27:11<12:27,72.96it/s] 75%|#######5  |130844/173481[30:00<09:54,71.75it/s] 76%|#######5  |131679/173481[30:11<09:42,71.75it/s] 82%|########2 |142540/173481[33:00<07:33,68.19it/s] 83%|########2 |143381/173481[33:11<07:21,68.19it/s] 90%|########9 |155806/173481[36:00<04:09,70.84it/s] 90%|######### |156678/173481[36:11<03:57,70.84it/s] 98%|#########7|169366/173481[39:00<00:56,73.01it/s] 98%|#########8|170192/173481[39:12<00:45,73.01it/s]100%|##########|173481/173481[40:12<00:00,71.90it/s]
[32m[0322 18:56:07 @base.py:257][0m Epoch 10 (global_step 5030949) finished, time:2412.66 sec.
[32m[0322 18:56:07 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-5030949.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.64it/s]
9
[32m[0322 18:58:12 @monitor.py:363][0m QueueInput/queue_size: 1.2159
[32m[0322 18:58:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.948
[32m[0322 18:58:12 @monitor.py:363][0m activation-summaries/output-rms: 0.036638
[32m[0322 18:58:12 @monitor.py:363][0m cross_entropy_loss: 2.0229
[32m[0322 18:58:12 @monitor.py:363][0m last_linear/W_0_percent_n: 0.72561
[32m[0322 18:58:12 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10534
[32m[0322 18:58:12 @monitor.py:363][0m last_linear/W_0_sparsity: 0.16895
[32m[0322 18:58:12 @monitor.py:363][0m last_linear/Wn_0: 0.38833
[32m[0322 18:58:12 @monitor.py:363][0m last_linear/Wp_0: 0.3832
[32m[0322 18:58:12 @monitor.py:363][0m linear0/W_0_percent_n: 0.10437
[32m[0322 18:58:12 @monitor.py:363][0m linear0/W_0_percent_p: 0.10414
[32m[0322 18:58:12 @monitor.py:363][0m linear0/W_0_sparsity: 0.79148
[32m[0322 18:58:12 @monitor.py:363][0m linear0/Wn_0: 1.0276
[32m[0322 18:58:12 @monitor.py:363][0m linear0/Wp_0: 0.97311
[32m[0322 18:58:12 @monitor.py:363][0m linear1/W_0_percent_n: 0.25741
[32m[0322 18:58:12 @monitor.py:363][0m linear1/W_0_percent_p: 0.22541
[32m[0322 18:58:12 @monitor.py:363][0m linear1/W_0_sparsity: 0.51716
[32m[0322 18:58:12 @monitor.py:363][0m linear1/Wn_0: 0.97724
[32m[0322 18:58:12 @monitor.py:363][0m linear1/Wp_0: 1.0221
[32m[0322 18:58:12 @monitor.py:363][0m linear2/W_0_percent_n: 0.30645
[32m[0322 18:58:12 @monitor.py:363][0m linear2/W_0_percent_p: 0.27832
[32m[0322 18:58:12 @monitor.py:363][0m linear2/W_0_sparsity: 0.41522
[32m[0322 18:58:12 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0322 18:58:12 @monitor.py:363][0m linear2/Wp_0: 0.98767
[32m[0322 18:58:12 @monitor.py:363][0m linear3/W_0_percent_n: 0.32769
[32m[0322 18:58:12 @monitor.py:363][0m linear3/W_0_percent_p: 0.25914
[32m[0322 18:58:12 @monitor.py:363][0m linear3/W_0_sparsity: 0.41317
[32m[0322 18:58:12 @monitor.py:363][0m linear3/Wn_0: 1.0076
[32m[0322 18:58:12 @monitor.py:363][0m linear3/Wp_0: 0.99083
[32m[0322 18:58:12 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84219
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9439
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/linear0/W-rms: 0.45442
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.37635
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34124
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33262
[32m[0322 18:58:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 18:58:12 @monitor.py:363][0m train-error-top1: 0.51784
[32m[0322 18:58:12 @monitor.py:363][0m val-error-top1: 0.63493
[32m[0322 18:58:12 @monitor.py:363][0m val-utt-error: 0.24158
[32m[0322 18:58:12 @monitor.py:363][0m validation_cost: 2.6038
[32m[0322 18:58:12 @monitor.py:363][0m wd_cost: 2.9583e-06
[32m[0322 18:58:12 @group.py:42][0m Callbacks took 125.339 sec in total. InferenceRunner: 124.969sec
[32m[0322 18:58:12 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12958/173481[03:00<37:09,71.99it/s]  8%|7         |13747/173481[03:10<36:58,71.99it/s] 15%|#4        |25976/173481[06:00<34:04,72.15it/s] 15%|#5        |26681/173481[06:10<33:54,72.15it/s] 21%|##1       |36697/173481[09:00<34:56,65.25it/s] 22%|##1       |37454/173481[09:10<34:44,65.25it/s] 29%|##8       |49981/173481[12:00<29:43,69.26it/s] 29%|##9       |50748/173481[12:10<29:32,69.26it/s] 37%|###6      |63547/173481[15:00<25:23,72.18it/s] 37%|###7      |64375/173481[15:10<25:11,72.18it/s] 44%|####4     |76731/173481[18:00<22:10,72.71it/s] 45%|####4     |77514/173481[18:10<21:59,72.71it/s] 52%|#####1    |89580/173481[21:00<19:24,72.04it/s] 52%|#####2    |90392/173481[21:11<19:13,72.04it/s] 59%|#####9    |102751/173481[24:00<16:14,72.60it/s] 60%|#####9    |103554/173481[24:11<16:03,72.60it/s] 67%|######6   |115938/173481[27:00<13:09,72.93it/s] 67%|######7   |116884/173481[27:11<12:56,72.93it/s] 75%|#######4  |129599/173481[30:00<09:49,74.38it/s] 75%|#######5  |130347/173481[30:11<09:39,74.38it/s] 82%|########1 |142210/173481[33:00<07:13,72.16it/s] 83%|########2 |143142/173481[33:11<07:00,72.16it/s] 89%|########9 |155154/173481[36:00<04:14,72.03it/s] 90%|########9 |155676/173481[36:11<04:07,72.03it/s] 96%|#########6|167251/173481[39:00<01:29,69.53it/s] 97%|#########6|168182/173481[39:12<01:16,69.53it/s]100%|##########|173481/173481[40:22<00:00,71.60it/s]
[32m[0322 19:38:35 @base.py:257][0m Epoch 11 (global_step 5204430) finished, time:2422.79 sec.
[32m[0322 19:38:35 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-5204430.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:33<00:00,122.58it/s]
10
[32m[0322 19:41:09 @monitor.py:363][0m QueueInput/queue_size: 1.067
[32m[0322 19:41:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22
[32m[0322 19:41:09 @monitor.py:363][0m activation-summaries/output-rms: 0.037431
[32m[0322 19:41:09 @monitor.py:363][0m cross_entropy_loss: 1.9652
[32m[0322 19:41:09 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73015
[32m[0322 19:41:09 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10795
[32m[0322 19:41:09 @monitor.py:363][0m last_linear/W_0_sparsity: 0.16185
[32m[0322 19:41:09 @monitor.py:363][0m last_linear/Wn_0: 0.38802
[32m[0322 19:41:09 @monitor.py:363][0m last_linear/Wp_0: 0.38402
[32m[0322 19:41:09 @monitor.py:363][0m linear0/W_0_percent_n: 0.10387
[32m[0322 19:41:09 @monitor.py:363][0m linear0/W_0_percent_p: 0.10368
[32m[0322 19:41:09 @monitor.py:363][0m linear0/W_0_sparsity: 0.79242
[32m[0322 19:41:09 @monitor.py:363][0m linear0/Wn_0: 1.0279
[32m[0322 19:41:09 @monitor.py:363][0m linear0/Wp_0: 0.97321
[32m[0322 19:41:09 @monitor.py:363][0m linear1/W_0_percent_n: 0.25461
[32m[0322 19:41:09 @monitor.py:363][0m linear1/W_0_percent_p: 0.22287
[32m[0322 19:41:09 @monitor.py:363][0m linear1/W_0_sparsity: 0.52249
[32m[0322 19:41:09 @monitor.py:363][0m linear1/Wn_0: 0.97702
[32m[0322 19:41:09 @monitor.py:363][0m linear1/Wp_0: 1.0227
[32m[0322 19:41:09 @monitor.py:363][0m linear2/W_0_percent_n: 0.30658
[32m[0322 19:41:09 @monitor.py:363][0m linear2/W_0_percent_p: 0.27833
[32m[0322 19:41:09 @monitor.py:363][0m linear2/W_0_sparsity: 0.41509
[32m[0322 19:41:09 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0322 19:41:09 @monitor.py:363][0m linear2/Wp_0: 0.98783
[32m[0322 19:41:09 @monitor.py:363][0m linear3/W_0_percent_n: 0.32282
[32m[0322 19:41:09 @monitor.py:363][0m linear3/W_0_percent_p: 0.25435
[32m[0322 19:41:09 @monitor.py:363][0m linear3/W_0_sparsity: 0.42282
[32m[0322 19:41:09 @monitor.py:363][0m linear3/Wn_0: 1.0073
[32m[0322 19:41:09 @monitor.py:363][0m linear3/Wp_0: 0.9912
[32m[0322 19:41:09 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84536
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9427
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.45731
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.37786
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34224
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33364
[32m[0322 19:41:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 19:41:09 @monitor.py:363][0m train-error-top1: 0.50488
[32m[0322 19:41:09 @monitor.py:363][0m val-error-top1: 0.62307
[32m[0322 19:41:09 @monitor.py:363][0m val-utt-error: 0.2352
[32m[0322 19:41:09 @monitor.py:363][0m validation_cost: 2.5339
[32m[0322 19:41:09 @monitor.py:363][0m wd_cost: 2.9855e-06
[32m[0322 19:41:09 @group.py:42][0m Callbacks took 153.878 sec in total. InferenceRunner: 153.569sec
[32m[0322 19:41:09 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14218/173481[03:00<33:40,78.82it/s]  9%|8         |15207/173481[03:20<33:27,78.82it/s] 15%|#5        |26743/173481[06:00<33:05,73.91it/s] 16%|#6        |28269/173481[06:20<32:44,73.91it/s] 22%|##1       |37840/173481[09:00<33:37,67.23it/s] 22%|##2       |38616/173481[09:10<33:26,67.23it/s] 29%|##9       |50800/173481[12:00<29:24,69.53it/s] 30%|##9       |51575/173481[12:10<29:13,69.53it/s] 37%|###6      |63832/173481[15:00<25:45,70.93it/s] 37%|###7      |64571/173481[15:10<25:35,70.93it/s] 44%|####4     |76972/173481[18:00<22:21,71.95it/s] 45%|####4     |77735/173481[18:11<22:10,71.95it/s] 52%|#####1    |89588/173481[21:00<19:41,71.01it/s] 52%|#####2    |90331/173481[21:11<19:31,71.01it/s] 60%|#####9    |103486/173481[24:00<15:46,73.97it/s] 60%|######    |104243/173481[24:11<15:36,73.97it/s] 67%|######7   |116388/173481[27:00<13:04,72.80it/s] 68%|######7   |117225/173481[27:11<12:52,72.80it/s] 75%|#######5  |130265/173481[30:00<09:37,74.89it/s] 76%|#######5  |131067/173481[30:11<09:26,74.89it/s] 83%|########2 |143323/173481[33:00<06:49,73.70it/s] 83%|########3 |144150/173481[33:11<06:37,73.70it/s] 90%|######### |156994/173481[36:00<03:40,74.80it/s] 91%|#########1|157912/173481[36:12<03:28,74.80it/s]100%|#########9|173217/173481[39:00<00:03,81.75it/s]100%|##########|173481/173481[39:03<00:00,74.01it/s]
[32m[0322 20:20:13 @base.py:257][0m Epoch 12 (global_step 5377911) finished, time:2343.95 sec.
[32m[0322 20:20:13 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-5377911.
[32m[0322 20:20:14 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:37<00:00,119.42it/s]
11
[32m[0322 20:22:52 @monitor.py:363][0m QueueInput/queue_size: 1.7165
[32m[0322 20:22:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.143
[32m[0322 20:22:52 @monitor.py:363][0m activation-summaries/output-rms: 0.038746
[32m[0322 20:22:52 @monitor.py:363][0m cross_entropy_loss: 1.948
[32m[0322 20:22:52 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73136
[32m[0322 20:22:52 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10825
[32m[0322 20:22:52 @monitor.py:363][0m last_linear/W_0_sparsity: 0.16033
[32m[0322 20:22:52 @monitor.py:363][0m last_linear/Wn_0: 0.38841
[32m[0322 20:22:52 @monitor.py:363][0m last_linear/Wp_0: 0.38485
[32m[0322 20:22:52 @monitor.py:363][0m linear0/W_0_percent_n: 0.10354
[32m[0322 20:22:52 @monitor.py:363][0m linear0/W_0_percent_p: 0.10355
[32m[0322 20:22:52 @monitor.py:363][0m linear0/W_0_sparsity: 0.79289
[32m[0322 20:22:52 @monitor.py:363][0m linear0/Wn_0: 1.0282
[32m[0322 20:22:52 @monitor.py:363][0m linear0/Wp_0: 0.97316
[32m[0322 20:22:52 @monitor.py:363][0m linear1/W_0_percent_n: 0.25494
[32m[0322 20:22:52 @monitor.py:363][0m linear1/W_0_percent_p: 0.22372
[32m[0322 20:22:52 @monitor.py:363][0m linear1/W_0_sparsity: 0.52129
[32m[0322 20:22:52 @monitor.py:363][0m linear1/Wn_0: 0.97725
[32m[0322 20:22:52 @monitor.py:363][0m linear1/Wp_0: 1.0228
[32m[0322 20:22:52 @monitor.py:363][0m linear2/W_0_percent_n: 0.30528
[32m[0322 20:22:52 @monitor.py:363][0m linear2/W_0_percent_p: 0.27707
[32m[0322 20:22:52 @monitor.py:363][0m linear2/W_0_sparsity: 0.41764
[32m[0322 20:22:52 @monitor.py:363][0m linear2/Wn_0: 1.0109
[32m[0322 20:22:52 @monitor.py:363][0m linear2/Wp_0: 0.98764
[32m[0322 20:22:52 @monitor.py:363][0m linear3/W_0_percent_n: 0.32277
[32m[0322 20:22:52 @monitor.py:363][0m linear3/W_0_percent_p: 0.25441
[32m[0322 20:22:52 @monitor.py:363][0m linear3/W_0_sparsity: 0.4228
[32m[0322 20:22:52 @monitor.py:363][0m linear3/Wn_0: 1.0072
[32m[0322 20:22:52 @monitor.py:363][0m linear3/Wp_0: 0.99142
[32m[0322 20:22:52 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.8469
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9421
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.4588
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.37863
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34274
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33416
[32m[0322 20:22:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 20:22:52 @monitor.py:363][0m train-error-top1: 0.50214
[32m[0322 20:22:52 @monitor.py:363][0m val-error-top1: 0.62042
[32m[0322 20:22:52 @monitor.py:363][0m val-utt-error: 0.23531
[32m[0322 20:22:52 @monitor.py:363][0m validation_cost: 2.5295
[32m[0322 20:22:52 @monitor.py:363][0m wd_cost: 5.9985e-07
[32m[0322 20:22:52 @group.py:42][0m Callbacks took 158.588 sec in total. InferenceRunner: 157.624sec
[32m[0322 20:22:52 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17797/173481[03:00<26:15,98.84it/s] 11%|#         |18617/173481[03:10<26:06,98.84it/s] 19%|#8        |32225/173481[06:00<26:35,88.52it/s] 19%|#9        |32972/173481[06:10<26:27,88.52it/s] 25%|##5       |44077/173481[09:00<28:34,75.47it/s] 26%|##5       |44375/173481[09:10<28:30,75.47it/s] 33%|###3      |57596/173481[12:00<25:39,75.29it/s] 34%|###3      |58379/173481[12:10<25:28,75.29it/s] 41%|####      |70911/173481[15:00<22:54,74.62it/s] 41%|####1     |71694/173481[15:10<22:43,74.62it/s] 48%|####8     |83827/173481[18:00<20:25,73.16it/s] 49%|####8     |84148/173481[18:10<20:21,73.16it/s] 55%|#####5    |96145/173481[21:00<18:13,70.72it/s] 56%|#####5    |96954/173481[21:11<18:02,70.72it/s] 63%|######2   |108823/173481[24:00<15:16,70.57it/s] 63%|######3   |109585/173481[24:11<15:05,70.57it/s] 70%|######9   |121214/173481[27:00<12:29,69.70it/s] 70%|#######   |121976/173481[27:11<12:18,69.70it/s] 77%|#######7  |133601/173481[30:00<09:35,69.25it/s] 77%|#######7  |134366/173481[30:11<09:24,69.25it/s] 84%|########4 |146082/173481[33:00<06:35,69.30it/s] 85%|########4 |146915/173481[33:11<06:23,69.30it/s] 92%|#########1|158743/173481[36:00<03:31,69.80it/s] 92%|#########1|159546/173481[36:11<03:19,69.80it/s] 98%|#########8|170545/173481[39:00<00:43,67.62it/s] 99%|#########9|171885/173481[39:12<00:23,67.62it/s]100%|##########|173481/173481[39:28<00:00,73.25it/s]
[32m[0322 21:02:20 @base.py:257][0m Epoch 13 (global_step 5551392) finished, time:2368.32 sec.
[32m[0322 21:02:20 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-5551392.
[32m[0322 21:02:21 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.65it/s]
12
[32m[0322 21:04:25 @monitor.py:363][0m QueueInput/queue_size: 1.0902
[32m[0322 21:04:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.015
[32m[0322 21:04:25 @monitor.py:363][0m activation-summaries/output-rms: 0.036719
[32m[0322 21:04:25 @monitor.py:363][0m cross_entropy_loss: 2.0008
[32m[0322 21:04:25 @monitor.py:363][0m last_linear/W_0_percent_n: 0.72842
[32m[0322 21:04:25 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10726
[32m[0322 21:04:25 @monitor.py:363][0m last_linear/W_0_sparsity: 0.16427
[32m[0322 21:04:25 @monitor.py:363][0m last_linear/Wn_0: 0.38843
[32m[0322 21:04:25 @monitor.py:363][0m last_linear/Wp_0: 0.38481
[32m[0322 21:04:25 @monitor.py:363][0m linear0/W_0_percent_n: 0.1025
[32m[0322 21:04:25 @monitor.py:363][0m linear0/W_0_percent_p: 0.10268
[32m[0322 21:04:25 @monitor.py:363][0m linear0/W_0_sparsity: 0.7948
[32m[0322 21:04:25 @monitor.py:363][0m linear0/Wn_0: 1.0286
[32m[0322 21:04:25 @monitor.py:363][0m linear0/Wp_0: 0.97315
[32m[0322 21:04:25 @monitor.py:363][0m linear1/W_0_percent_n: 0.25244
[32m[0322 21:04:25 @monitor.py:363][0m linear1/W_0_percent_p: 0.22083
[32m[0322 21:04:25 @monitor.py:363][0m linear1/W_0_sparsity: 0.5267
[32m[0322 21:04:25 @monitor.py:363][0m linear1/Wn_0: 0.97732
[32m[0322 21:04:25 @monitor.py:363][0m linear1/Wp_0: 1.0231
[32m[0322 21:04:25 @monitor.py:363][0m linear2/W_0_percent_n: 0.30268
[32m[0322 21:04:25 @monitor.py:363][0m linear2/W_0_percent_p: 0.27518
[32m[0322 21:04:25 @monitor.py:363][0m linear2/W_0_sparsity: 0.42213
[32m[0322 21:04:25 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0322 21:04:25 @monitor.py:363][0m linear2/Wp_0: 0.98786
[32m[0322 21:04:25 @monitor.py:363][0m linear3/W_0_percent_n: 0.32396
[32m[0322 21:04:25 @monitor.py:363][0m linear3/W_0_percent_p: 0.25532
[32m[0322 21:04:25 @monitor.py:363][0m linear3/W_0_sparsity: 0.42071
[32m[0322 21:04:25 @monitor.py:363][0m linear3/Wn_0: 1.0074
[32m[0322 21:04:25 @monitor.py:363][0m linear3/Wp_0: 0.9913
[32m[0322 21:04:25 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84844
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9416
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46028
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.37941
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34325
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33468
[32m[0322 21:04:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 21:04:25 @monitor.py:363][0m train-error-top1: 0.50743
[32m[0322 21:04:25 @monitor.py:363][0m val-error-top1: 0.64005
[32m[0322 21:04:25 @monitor.py:363][0m val-utt-error: 0.26326
[32m[0322 21:04:25 @monitor.py:363][0m validation_cost: 2.6866
[32m[0322 21:04:25 @monitor.py:363][0m wd_cost: 6.0262e-07
[32m[0322 21:04:25 @group.py:42][0m Callbacks took 125.362 sec in total. InferenceRunner: 124.136sec
[32m[0322 21:04:25 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19611/173481[03:00<23:32,108.95it/s] 12%|#1        |20576/173481[03:10<23:23,108.95it/s] 20%|##        |35264/173481[06:00<23:49,96.72it/s]  21%|##        |36063/173481[06:10<23:40,96.72it/s] 28%|##7       |48154/173481[09:00<25:23,82.29it/s] 28%|##8       |48904/173481[09:10<25:13,82.29it/s] 35%|###5      |60940/173481[12:00<24:36,76.24it/s] 36%|###5      |61694/173481[12:10<24:26,76.24it/s] 42%|####2     |73372/173481[15:00<23:01,72.47it/s] 43%|####2     |74067/173481[15:10<22:51,72.47it/s] 48%|####8     |84034/173481[18:00<22:52,65.18it/s] 49%|####8     |84735/173481[18:10<22:41,65.18it/s] 55%|#####5    |96136/173481[21:00<19:28,66.19it/s] 56%|#####5    |96850/173481[21:11<19:17,66.19it/s] 63%|######2   |108754/173481[24:00<15:50,68.09it/s] 63%|######3   |109472/173481[24:11<15:40,68.09it/s] 69%|######9   |120232/173481[27:00<13:28,65.85it/s] 70%|######9   |121089/173481[27:11<13:15,65.85it/s] 77%|#######6  |133324/173481[30:00<09:40,69.12it/s] 77%|#######7  |134155/173481[30:11<09:28,69.12it/s] 84%|########4 |146452/173481[33:00<06:20,70.97it/s] 85%|########4 |147316/173481[33:11<06:08,70.97it/s] 91%|#########1|158655/173481[36:00<03:33,69.34it/s] 92%|#########1|159525/173481[36:11<03:21,69.34it/s] 99%|#########9|171760/173481[39:00<00:24,71.03it/s]100%|#########9|172635/173481[39:12<00:11,71.03it/s]100%|##########|173481/173481[39:23<00:00,73.40it/s]
[32m[0322 21:43:49 @base.py:257][0m Epoch 14 (global_step 5724873) finished, time:2363.65 sec.
[32m[0322 21:43:49 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-5724873.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.31it/s]
13
[32m[0322 21:45:47 @monitor.py:363][0m QueueInput/queue_size: 1.0522
[32m[0322 21:45:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.432
[32m[0322 21:45:47 @monitor.py:363][0m activation-summaries/output-rms: 0.038403
[32m[0322 21:45:47 @monitor.py:363][0m cross_entropy_loss: 1.9066
[32m[0322 21:45:47 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73633
[32m[0322 21:45:47 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11019
[32m[0322 21:45:47 @monitor.py:363][0m last_linear/W_0_sparsity: 0.15342
[32m[0322 21:45:47 @monitor.py:363][0m last_linear/Wn_0: 0.38886
[32m[0322 21:45:47 @monitor.py:363][0m last_linear/Wp_0: 0.38527
[32m[0322 21:45:47 @monitor.py:363][0m linear0/W_0_percent_n: 0.11021
[32m[0322 21:45:47 @monitor.py:363][0m linear0/W_0_percent_p: 0.11044
[32m[0322 21:45:47 @monitor.py:363][0m linear0/W_0_sparsity: 0.7793
[32m[0322 21:45:47 @monitor.py:363][0m linear0/Wn_0: 1.0291
[32m[0322 21:45:47 @monitor.py:363][0m linear0/Wp_0: 0.97303
[32m[0322 21:45:47 @monitor.py:363][0m linear1/W_0_percent_n: 0.25106
[32m[0322 21:45:47 @monitor.py:363][0m linear1/W_0_percent_p: 0.21964
[32m[0322 21:45:47 @monitor.py:363][0m linear1/W_0_sparsity: 0.52924
[32m[0322 21:45:47 @monitor.py:363][0m linear1/Wn_0: 0.97773
[32m[0322 21:45:47 @monitor.py:363][0m linear1/Wp_0: 1.023
[32m[0322 21:45:47 @monitor.py:363][0m linear2/W_0_percent_n: 0.30413
[32m[0322 21:45:47 @monitor.py:363][0m linear2/W_0_percent_p: 0.2758
[32m[0322 21:45:47 @monitor.py:363][0m linear2/W_0_sparsity: 0.42004
[32m[0322 21:45:47 @monitor.py:363][0m linear2/Wn_0: 1.0108
[32m[0322 21:45:47 @monitor.py:363][0m linear2/Wp_0: 0.98783
[32m[0322 21:45:47 @monitor.py:363][0m linear3/W_0_percent_n: 0.32231
[32m[0322 21:45:47 @monitor.py:363][0m linear3/W_0_percent_p: 0.25446
[32m[0322 21:45:47 @monitor.py:363][0m linear3/W_0_sparsity: 0.42321
[32m[0322 21:45:47 @monitor.py:363][0m linear3/Wn_0: 1.0078
[32m[0322 21:45:47 @monitor.py:363][0m linear3/Wp_0: 0.99103
[32m[0322 21:45:47 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84959
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9411
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.4615
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38005
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34368
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33512
[32m[0322 21:45:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 21:45:47 @monitor.py:363][0m train-error-top1: 0.49549
[32m[0322 21:45:47 @monitor.py:363][0m val-error-top1: 0.63436
[32m[0322 21:45:47 @monitor.py:363][0m val-utt-error: 0.25954
[32m[0322 21:45:47 @monitor.py:363][0m validation_cost: 2.6398
[32m[0322 21:45:47 @monitor.py:363][0m wd_cost: 6.0485e-07
[32m[0322 21:45:47 @group.py:42][0m Callbacks took 117.778 sec in total. InferenceRunner: 117.429sec
[32m[0322 21:45:47 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12205/173481[03:00<39:38,67.80it/s]  7%|7         |12929/173481[03:10<39:27,67.80it/s] 14%|#4        |24997/173481[06:00<35:39,69.39it/s] 15%|#4        |25746/173481[06:10<35:29,69.39it/s] 22%|##1       |37904/173481[09:00<32:02,70.53it/s] 22%|##2       |38640/173481[09:10<31:51,70.53it/s] 29%|##8       |50101/173481[12:00<29:45,69.11it/s] 29%|##9       |50862/173481[12:10<29:34,69.11it/s] 37%|###6      |63505/173481[15:00<25:34,71.69it/s] 37%|###7      |64298/173481[15:10<25:23,71.69it/s] 44%|####4     |76672/173481[18:00<22:16,72.41it/s] 45%|####4     |77529/173481[18:10<22:05,72.41it/s] 52%|#####1    |89379/173481[21:00<19:36,71.49it/s] 52%|#####1    |90172/173481[21:11<19:25,71.49it/s] 59%|#####8    |102008/173481[24:00<16:49,70.82it/s] 59%|#####9    |102760/173481[24:11<16:38,70.82it/s] 66%|######5   |114427/173481[27:00<14:04,69.89it/s] 66%|######6   |115193/173481[27:11<13:53,69.89it/s] 72%|#######2  |125569/173481[30:00<12:09,65.64it/s] 73%|#######2  |126402/173481[30:11<11:57,65.64it/s] 80%|#######9  |138439/173481[33:00<08:32,68.44it/s] 80%|########  |139223/173481[33:11<08:20,68.44it/s] 88%|########7 |152139/173481[36:00<04:56,72.07it/s] 88%|########8 |153097/173481[36:11<04:42,72.07it/s] 96%|#########5|165759/173481[39:00<01:44,73.82it/s] 96%|#########6|166696/173481[39:12<01:31,73.82it/s]100%|##########|173481/173481[40:57<00:00,70.60it/s]
[32m[0322 22:26:44 @base.py:257][0m Epoch 15 (global_step 5898354) finished, time:2457.22 sec.
[32m[0322 22:26:44 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,141.25it/s]
14
[32m[0322 22:28:58 @monitor.py:363][0m QueueInput/queue_size: 1.1098
[32m[0322 22:28:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.147
[32m[0322 22:28:58 @monitor.py:363][0m activation-summaries/output-rms: 0.037142
[32m[0322 22:28:58 @monitor.py:363][0m cross_entropy_loss: 1.9914
[32m[0322 22:28:58 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73378
[32m[0322 22:28:58 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10915
[32m[0322 22:28:58 @monitor.py:363][0m last_linear/W_0_sparsity: 0.15694
[32m[0322 22:28:58 @monitor.py:363][0m last_linear/Wn_0: 0.38889
[32m[0322 22:28:58 @monitor.py:363][0m last_linear/Wp_0: 0.38516
[32m[0322 22:28:58 @monitor.py:363][0m linear0/W_0_percent_n: 0.1112
[32m[0322 22:28:58 @monitor.py:363][0m linear0/W_0_percent_p: 0.11142
[32m[0322 22:28:58 @monitor.py:363][0m linear0/W_0_sparsity: 0.77735
[32m[0322 22:28:58 @monitor.py:363][0m linear0/Wn_0: 1.0306
[32m[0322 22:28:58 @monitor.py:363][0m linear0/Wp_0: 0.97191
[32m[0322 22:28:58 @monitor.py:363][0m linear1/W_0_percent_n: 0.25302
[32m[0322 22:28:58 @monitor.py:363][0m linear1/W_0_percent_p: 0.22105
[32m[0322 22:28:58 @monitor.py:363][0m linear1/W_0_sparsity: 0.52584
[32m[0322 22:28:58 @monitor.py:363][0m linear1/Wn_0: 0.97824
[32m[0322 22:28:58 @monitor.py:363][0m linear1/Wp_0: 1.0229
[32m[0322 22:28:58 @monitor.py:363][0m linear2/W_0_percent_n: 0.30428
[32m[0322 22:28:58 @monitor.py:363][0m linear2/W_0_percent_p: 0.27641
[32m[0322 22:28:58 @monitor.py:363][0m linear2/W_0_sparsity: 0.41929
[32m[0322 22:28:58 @monitor.py:363][0m linear2/Wn_0: 1.0108
[32m[0322 22:28:58 @monitor.py:363][0m linear2/Wp_0: 0.98789
[32m[0322 22:28:58 @monitor.py:363][0m linear3/W_0_percent_n: 0.32165
[32m[0322 22:28:58 @monitor.py:363][0m linear3/W_0_percent_p: 0.2536
[32m[0322 22:28:58 @monitor.py:363][0m linear3/W_0_sparsity: 0.42474
[32m[0322 22:28:58 @monitor.py:363][0m linear3/Wn_0: 1.0078
[32m[0322 22:28:58 @monitor.py:363][0m linear3/Wp_0: 0.99108
[32m[0322 22:28:58 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.85002
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9409
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46223
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38044
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34393
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33538
[32m[0322 22:28:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 22:28:58 @monitor.py:363][0m train-error-top1: 0.52164
[32m[0322 22:28:58 @monitor.py:363][0m val-error-top1: 0.62814
[32m[0322 22:28:58 @monitor.py:363][0m val-utt-error: 0.22856
[32m[0322 22:28:58 @monitor.py:363][0m validation_cost: 2.584
[32m[0322 22:28:58 @monitor.py:363][0m wd_cost: 1.2121e-07
[32m[0322 22:28:58 @group.py:42][0m Callbacks took 133.644 sec in total. InferenceRunner: 133.271sec
[32m[0322 22:28:58 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14018/173481[03:00<34:07,77.88it/s]  9%|8         |14799/173481[03:10<33:57,77.88it/s] 15%|#5        |26506/173481[06:00<33:22,73.38it/s] 16%|#5        |27259/173481[06:10<33:12,73.38it/s] 23%|##3       |40361/173481[09:00<29:31,75.13it/s] 24%|##3       |41133/173481[09:10<29:21,75.13it/s] 31%|###1      |53849/173481[12:00<26:34,75.03it/s] 32%|###1      |54687/173481[12:10<26:23,75.03it/s] 39%|###8      |67030/173481[15:00<23:57,74.08it/s] 39%|###8      |67173/173481[15:10<23:55,74.08it/s] 47%|####6     |80950/173481[18:00<20:22,75.67it/s] 47%|####7     |81804/173481[18:10<20:11,75.67it/s] 55%|#####4    |95052/173481[21:00<16:58,76.98it/s] 55%|#####5    |95901/173481[21:11<16:47,76.98it/s] 63%|######2   |109051/173481[24:00<13:52,77.37it/s] 63%|######3   |109870/173481[24:11<13:42,77.37it/s] 71%|#######   |122649/173481[27:00<11:04,76.45it/s] 71%|#######1  |123432/173481[27:11<10:54,76.45it/s] 78%|#######8  |136030/173481[30:00<08:16,75.37it/s] 79%|#######8  |136965/173481[30:11<08:04,75.37it/s] 87%|########6 |150479/173481[33:00<04:55,77.74it/s] 87%|########7 |151376/173481[33:11<04:44,77.74it/s] 94%|#########4|163918/173481[36:00<02:05,76.17it/s] 95%|#########5|164845/173481[36:11<01:53,76.17it/s]100%|##########|173481/173481[38:01<00:00,76.02it/s]
[32m[0322 23:06:59 @base.py:257][0m Epoch 16 (global_step 6071835) finished, time:2281.93 sec.
[32m[0322 23:07:00 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-6071835.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:12<00:00,142.51it/s]
15
[32m[0322 23:09:12 @monitor.py:363][0m QueueInput/queue_size: 0.89235
[32m[0322 23:09:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.038
[32m[0322 23:09:12 @monitor.py:363][0m activation-summaries/output-rms: 0.037009
[32m[0322 23:09:12 @monitor.py:363][0m cross_entropy_loss: 2.0342
[32m[0322 23:09:12 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73232
[32m[0322 23:09:12 @monitor.py:363][0m last_linear/W_0_percent_p: 0.10906
[32m[0322 23:09:12 @monitor.py:363][0m last_linear/W_0_sparsity: 0.1585
[32m[0322 23:09:12 @monitor.py:363][0m last_linear/Wn_0: 0.38882
[32m[0322 23:09:12 @monitor.py:363][0m last_linear/Wp_0: 0.38499
[32m[0322 23:09:12 @monitor.py:363][0m linear0/W_0_percent_n: 0.11121
[32m[0322 23:09:12 @monitor.py:363][0m linear0/W_0_percent_p: 0.11207
[32m[0322 23:09:12 @monitor.py:363][0m linear0/W_0_sparsity: 0.77666
[32m[0322 23:09:12 @monitor.py:363][0m linear0/Wn_0: 1.0317
[32m[0322 23:09:12 @monitor.py:363][0m linear0/Wp_0: 0.97122
[32m[0322 23:09:12 @monitor.py:363][0m linear1/W_0_percent_n: 0.25167
[32m[0322 23:09:12 @monitor.py:363][0m linear1/W_0_percent_p: 0.22026
[32m[0322 23:09:12 @monitor.py:363][0m linear1/W_0_sparsity: 0.52798
[32m[0322 23:09:12 @monitor.py:363][0m linear1/Wn_0: 0.97854
[32m[0322 23:09:12 @monitor.py:363][0m linear1/Wp_0: 1.0229
[32m[0322 23:09:12 @monitor.py:363][0m linear2/W_0_percent_n: 0.30246
[32m[0322 23:09:12 @monitor.py:363][0m linear2/W_0_percent_p: 0.27417
[32m[0322 23:09:12 @monitor.py:363][0m linear2/W_0_sparsity: 0.42336
[32m[0322 23:09:12 @monitor.py:363][0m linear2/Wn_0: 1.0108
[32m[0322 23:09:12 @monitor.py:363][0m linear2/Wp_0: 0.98803
[32m[0322 23:09:12 @monitor.py:363][0m linear3/W_0_percent_n: 0.32309
[32m[0322 23:09:12 @monitor.py:363][0m linear3/W_0_percent_p: 0.25479
[32m[0322 23:09:12 @monitor.py:363][0m linear3/W_0_sparsity: 0.4221
[32m[0322 23:09:12 @monitor.py:363][0m linear3/Wn_0: 1.008
[32m[0322 23:09:12 @monitor.py:363][0m linear3/Wp_0: 0.99088
[32m[0322 23:09:12 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.85045
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9406
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46295
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38082
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34418
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33564
[32m[0322 23:09:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 23:09:12 @monitor.py:363][0m train-error-top1: 0.52697
[32m[0322 23:09:12 @monitor.py:363][0m val-error-top1: 0.62923
[32m[0322 23:09:12 @monitor.py:363][0m val-utt-error: 0.24078
[32m[0322 23:09:12 @monitor.py:363][0m validation_cost: 2.6027
[32m[0322 23:09:12 @monitor.py:363][0m wd_cost: 1.2146e-07
[32m[0322 23:09:12 @group.py:42][0m Callbacks took 132.393 sec in total. InferenceRunner: 132.096sec
[32m[0322 23:09:12 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13953/173481[03:00<34:18,77.52it/s]  8%|8         |14686/173481[03:10<34:08,77.52it/s] 16%|#5        |27475/173481[06:00<31:53,76.29it/s] 16%|#6        |28207/173481[06:10<31:44,76.29it/s] 24%|##3       |41040/173481[09:00<29:06,75.82it/s] 24%|##4       |41854/173481[09:10<28:56,75.82it/s] 32%|###2      |55536/173481[12:00<25:10,78.11it/s] 33%|###2      |56464/173481[12:10<24:58,78.11it/s] 42%|####2     |73237/173481[15:00<19:11,87.06it/s] 43%|####2     |74468/173481[15:10<18:57,87.06it/s] 54%|#####4    |93760/173481[18:00<13:27,98.73it/s] 55%|#####4    |94994/173481[18:11<13:14,98.73it/s] 65%|######4   |112466/173481[21:00<10:02,101.26it/s] 66%|######5   |113747/173481[21:11<09:49,101.26it/s] 77%|#######6  |132990/173481[24:00<06:17,107.26it/s] 77%|#######7  |134262/173481[24:11<06:05,107.26it/s] 88%|########8 |153410/173481[27:00<03:02,110.26it/s] 89%|########9 |154707/173481[27:11<02:50,110.26it/s] 99%|#########9|172015/173481[30:00<00:13,106.70it/s]100%|#########9|173312/173481[30:11<00:01,106.70it/s]100%|##########|173481/173481[30:13<00:00,95.67it/s] 
[32m[0322 23:39:25 @base.py:257][0m Epoch 17 (global_step 6245316) finished, time:1813.24 sec.
[32m[0322 23:39:25 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.58it/s]
16
[32m[0322 23:41:24 @monitor.py:363][0m QueueInput/queue_size: 1.3795
[32m[0322 23:41:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.107
[32m[0322 23:41:24 @monitor.py:363][0m activation-summaries/output-rms: 0.037413
[32m[0322 23:41:24 @monitor.py:363][0m cross_entropy_loss: 1.993
[32m[0322 23:41:24 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73911
[32m[0322 23:41:24 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11117
[32m[0322 23:41:24 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14956
[32m[0322 23:41:24 @monitor.py:363][0m last_linear/Wn_0: 0.38915
[32m[0322 23:41:24 @monitor.py:363][0m last_linear/Wp_0: 0.38531
[32m[0322 23:41:24 @monitor.py:363][0m linear0/W_0_percent_n: 0.11601
[32m[0322 23:41:24 @monitor.py:363][0m linear0/W_0_percent_p: 0.11663
[32m[0322 23:41:24 @monitor.py:363][0m linear0/W_0_sparsity: 0.76725
[32m[0322 23:41:24 @monitor.py:363][0m linear0/Wn_0: 1.0326
[32m[0322 23:41:24 @monitor.py:363][0m linear0/Wp_0: 0.9707
[32m[0322 23:41:24 @monitor.py:363][0m linear1/W_0_percent_n: 0.26062
[32m[0322 23:41:24 @monitor.py:363][0m linear1/W_0_percent_p: 0.22801
[32m[0322 23:41:24 @monitor.py:363][0m linear1/W_0_sparsity: 0.51121
[32m[0322 23:41:24 @monitor.py:363][0m linear1/Wn_0: 0.9786
[32m[0322 23:41:24 @monitor.py:363][0m linear1/Wp_0: 1.0232
[32m[0322 23:41:24 @monitor.py:363][0m linear2/W_0_percent_n: 0.30775
[32m[0322 23:41:24 @monitor.py:363][0m linear2/W_0_percent_p: 0.27973
[32m[0322 23:41:24 @monitor.py:363][0m linear2/W_0_sparsity: 0.41247
[32m[0322 23:41:24 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0322 23:41:24 @monitor.py:363][0m linear2/Wp_0: 0.98814
[32m[0322 23:41:24 @monitor.py:363][0m linear3/W_0_percent_n: 0.32934
[32m[0322 23:41:24 @monitor.py:363][0m linear3/W_0_percent_p: 0.26065
[32m[0322 23:41:24 @monitor.py:363][0m linear3/W_0_sparsity: 0.40995
[32m[0322 23:41:24 @monitor.py:363][0m linear3/Wn_0: 1.0081
[32m[0322 23:41:24 @monitor.py:363][0m linear3/Wp_0: 0.99088
[32m[0322 23:41:24 @monitor.py:363][0m lr: 1.2207e-07
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.85046
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46335
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38108
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34436
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33582
[32m[0322 23:41:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 23:41:24 @monitor.py:363][0m train-error-top1: 0.50967
[32m[0322 23:41:24 @monitor.py:363][0m val-error-top1: 0.62686
[32m[0322 23:41:24 @monitor.py:363][0m val-utt-error: 0.23712
[32m[0322 23:41:24 @monitor.py:363][0m validation_cost: 2.5718
[32m[0322 23:41:24 @monitor.py:363][0m wd_cost: 2.4316e-08
[32m[0322 23:41:24 @group.py:42][0m Callbacks took 119.061 sec in total. InferenceRunner: 118.705sec
[32m[0322 23:41:24 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21087/173481[03:00<21:40,117.14it/s] 13%|#2        |22261/173481[03:10<21:30,117.14it/s] 24%|##3       |41522/173481[06:00<19:04,115.30it/s] 25%|##4       |42703/173481[06:10<18:54,115.30it/s] 35%|###4      |60307/173481[09:00<17:13,109.56it/s] 35%|###5      |61515/173481[09:10<17:01,109.56it/s] 46%|####5     |78994/173481[12:00<14:46,106.60it/s] 46%|####6     |79811/173481[12:10<14:38,106.60it/s] 53%|#####3    |92615/173481[15:00<15:13,88.51it/s]  54%|#####3    |93429/173481[15:10<15:04,88.51it/s] 61%|######1   |106156/173481[18:00<13:47,81.32it/s] 62%|######1   |106989/173481[18:11<13:37,81.32it/s] 69%|######8   |119634/173481[21:00<11:30,77.97it/s] 69%|######9   |120495/173481[21:11<11:19,77.97it/s] 77%|#######6  |133281/173481[24:00<08:42,76.88it/s] 77%|#######7  |134148/173481[24:11<08:31,76.88it/s] 85%|########4 |147220/173481[27:00<05:40,77.15it/s] 85%|########5 |148117/173481[27:11<05:28,77.15it/s] 93%|#########2|160943/173481[30:00<02:43,76.69it/s] 93%|#########3|161829/173481[30:11<02:31,76.69it/s]100%|##########|173481/173481[32:40<00:00,88.50it/s]
[32m[0323 00:14:04 @base.py:257][0m Epoch 18 (global_step 6418797) finished, time:1960.31 sec.
[32m[0323 00:14:05 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:09<00:00,145.05it/s]
17
[32m[0323 00:16:14 @monitor.py:363][0m QueueInput/queue_size: 1.0392
[32m[0323 00:16:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.245
[32m[0323 00:16:14 @monitor.py:363][0m activation-summaries/output-rms: 0.03926
[32m[0323 00:16:14 @monitor.py:363][0m cross_entropy_loss: 1.9534
[32m[0323 00:16:14 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73766
[32m[0323 00:16:14 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11089
[32m[0323 00:16:14 @monitor.py:363][0m last_linear/W_0_sparsity: 0.1513
[32m[0323 00:16:14 @monitor.py:363][0m last_linear/Wn_0: 0.38932
[32m[0323 00:16:14 @monitor.py:363][0m last_linear/Wp_0: 0.38555
[32m[0323 00:16:14 @monitor.py:363][0m linear0/W_0_percent_n: 0.11661
[32m[0323 00:16:14 @monitor.py:363][0m linear0/W_0_percent_p: 0.1172
[32m[0323 00:16:14 @monitor.py:363][0m linear0/W_0_sparsity: 0.76608
[32m[0323 00:16:14 @monitor.py:363][0m linear0/Wn_0: 1.0334
[32m[0323 00:16:14 @monitor.py:363][0m linear0/Wp_0: 0.97022
[32m[0323 00:16:14 @monitor.py:363][0m linear1/W_0_percent_n: 0.26176
[32m[0323 00:16:14 @monitor.py:363][0m linear1/W_0_percent_p: 0.22953
[32m[0323 00:16:14 @monitor.py:363][0m linear1/W_0_sparsity: 0.50855
[32m[0323 00:16:14 @monitor.py:363][0m linear1/Wn_0: 0.97888
[32m[0323 00:16:14 @monitor.py:363][0m linear1/Wp_0: 1.0232
[32m[0323 00:16:14 @monitor.py:363][0m linear2/W_0_percent_n: 0.30979
[32m[0323 00:16:14 @monitor.py:363][0m linear2/W_0_percent_p: 0.2813
[32m[0323 00:16:14 @monitor.py:363][0m linear2/W_0_sparsity: 0.40884
[32m[0323 00:16:14 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 00:16:14 @monitor.py:363][0m linear2/Wp_0: 0.98823
[32m[0323 00:16:14 @monitor.py:363][0m linear3/W_0_percent_n: 0.33149
[32m[0323 00:16:14 @monitor.py:363][0m linear3/W_0_percent_p: 0.26155
[32m[0323 00:16:14 @monitor.py:363][0m linear3/W_0_sparsity: 0.40691
[32m[0323 00:16:14 @monitor.py:363][0m linear3/Wn_0: 1.0081
[32m[0323 00:16:14 @monitor.py:363][0m linear3/Wp_0: 0.9909
[32m[0323 00:16:14 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.85022
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46355
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38127
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34448
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33595
[32m[0323 00:16:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 00:16:14 @monitor.py:363][0m train-error-top1: 0.49918
[32m[0323 00:16:14 @monitor.py:363][0m val-error-top1: 0.62937
[32m[0323 00:16:14 @monitor.py:363][0m val-utt-error: 0.2504
[32m[0323 00:16:14 @monitor.py:363][0m validation_cost: 2.611
[32m[0323 00:16:14 @monitor.py:363][0m wd_cost: 2.4326e-08
[32m[0323 00:16:14 @group.py:42][0m Callbacks took 130.022 sec in total. InferenceRunner: 129.779sec
[32m[0323 00:16:14 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14395/173481[03:00<33:09,79.96it/s]  9%|8         |15185/173481[03:10<32:59,79.96it/s] 16%|#6        |28423/173481[06:00<30:37,78.93it/s] 17%|#6        |29205/173481[06:10<30:27,78.93it/s] 24%|##3       |41185/173481[09:00<29:31,74.70it/s] 24%|##4       |41930/173481[09:10<29:21,74.70it/s] 31%|###1      |54203/173481[12:00<27:03,73.49it/s] 32%|###1      |54984/173481[12:10<26:52,73.49it/s] 39%|###8      |67088/173481[15:00<24:27,72.52it/s] 39%|###9      |67909/173481[15:10<24:15,72.52it/s] 46%|####6     |80533/173481[18:00<21:03,73.59it/s] 47%|####6     |81360/173481[18:11<20:51,73.59it/s] 53%|#####3    |91969/173481[21:00<19:55,68.18it/s] 53%|#####3    |92730/173481[21:11<19:44,68.18it/s] 60%|######    |104697/173481[24:00<16:30,69.42it/s] 61%|######    |105524/173481[24:11<16:18,69.42it/s] 68%|######7   |117521/173481[27:00<13:15,70.32it/s] 68%|######8   |118326/173481[27:11<13:04,70.32it/s] 75%|#######4  |129865/173481[30:00<10:28,69.43it/s] 75%|#######5  |130668/173481[30:11<10:16,69.43it/s] 82%|########2 |142303/173481[33:00<07:30,69.26it/s] 83%|########2 |143130/173481[33:11<07:18,69.26it/s] 90%|########9 |155369/173481[36:00<04:15,70.89it/s] 90%|######### |156213/173481[36:11<04:03,70.89it/s] 97%|#########7|168509/173481[39:00<01:09,71.93it/s] 98%|#########7|169434/173481[39:12<00:56,71.93it/s]100%|##########|173481/173481[40:06<00:00,72.08it/s]
[32m[0323 00:56:21 @base.py:257][0m Epoch 19 (global_step 6592278) finished, time:2406.76 sec.
[32m[0323 00:56:22 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-6592278.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.29it/s]
18
[32m[0323 00:58:23 @monitor.py:363][0m QueueInput/queue_size: 0.94988
[32m[0323 00:58:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.256
[32m[0323 00:58:23 @monitor.py:363][0m activation-summaries/output-rms: 0.03733
[32m[0323 00:58:23 @monitor.py:363][0m cross_entropy_loss: 2.0136
[32m[0323 00:58:23 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73634
[32m[0323 00:58:23 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11
[32m[0323 00:58:23 @monitor.py:363][0m last_linear/W_0_sparsity: 0.15346
[32m[0323 00:58:23 @monitor.py:363][0m last_linear/Wn_0: 0.38945
[32m[0323 00:58:23 @monitor.py:363][0m last_linear/Wp_0: 0.38571
[32m[0323 00:58:23 @monitor.py:363][0m linear0/W_0_percent_n: 0.11689
[32m[0323 00:58:23 @monitor.py:363][0m linear0/W_0_percent_p: 0.11759
[32m[0323 00:58:23 @monitor.py:363][0m linear0/W_0_sparsity: 0.7654
[32m[0323 00:58:23 @monitor.py:363][0m linear0/Wn_0: 1.0339
[32m[0323 00:58:23 @monitor.py:363][0m linear0/Wp_0: 0.96994
[32m[0323 00:58:23 @monitor.py:363][0m linear1/W_0_percent_n: 0.26153
[32m[0323 00:58:23 @monitor.py:363][0m linear1/W_0_percent_p: 0.22807
[32m[0323 00:58:23 @monitor.py:363][0m linear1/W_0_sparsity: 0.51028
[32m[0323 00:58:23 @monitor.py:363][0m linear1/Wn_0: 0.97907
[32m[0323 00:58:23 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 00:58:23 @monitor.py:363][0m linear2/W_0_percent_n: 0.30908
[32m[0323 00:58:23 @monitor.py:363][0m linear2/W_0_percent_p: 0.28138
[32m[0323 00:58:23 @monitor.py:363][0m linear2/W_0_sparsity: 0.40947
[32m[0323 00:58:23 @monitor.py:363][0m linear2/Wn_0: 1.0106
[32m[0323 00:58:23 @monitor.py:363][0m linear2/Wp_0: 0.98835
[32m[0323 00:58:23 @monitor.py:363][0m linear3/W_0_percent_n: 0.3325
[32m[0323 00:58:23 @monitor.py:363][0m linear3/W_0_percent_p: 0.26266
[32m[0323 00:58:23 @monitor.py:363][0m linear3/W_0_sparsity: 0.40477
[32m[0323 00:58:23 @monitor.py:363][0m linear3/Wn_0: 1.0082
[32m[0323 00:58:23 @monitor.py:363][0m linear3/Wp_0: 0.99084
[32m[0323 00:58:23 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84998
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46376
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38145
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34461
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33607
[32m[0323 00:58:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 00:58:23 @monitor.py:363][0m train-error-top1: 0.51404
[32m[0323 00:58:23 @monitor.py:363][0m val-error-top1: 0.64036
[32m[0323 00:58:23 @monitor.py:363][0m val-utt-error: 0.26198
[32m[0323 00:58:23 @monitor.py:363][0m validation_cost: 2.6795
[32m[0323 00:58:23 @monitor.py:363][0m wd_cost: 2.4336e-08
[32m[0323 00:58:23 @group.py:42][0m Callbacks took 121.708 sec in total. InferenceRunner: 121.215sec
[32m[0323 00:58:23 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19738/173481[03:00<23:22,109.64it/s] 12%|#1        |20457/173481[03:10<23:15,109.64it/s] 18%|#8        |32052/173481[06:00<27:58,84.25it/s]  19%|#8        |32762/173481[06:10<27:50,84.25it/s] 26%|##5       |44344/173481[09:00<28:31,75.43it/s] 26%|##5       |44968/173481[09:10<28:23,75.43it/s] 33%|###2      |56851/173481[12:00<26:52,72.33it/s] 33%|###3      |57583/173481[12:10<26:42,72.33it/s] 40%|####      |69523/173481[15:00<24:16,71.35it/s] 41%|####      |70303/173481[15:10<24:06,71.35it/s] 47%|####7     |82067/173481[18:00<21:36,70.51it/s] 48%|####7     |82857/173481[18:10<21:25,70.51it/s] 55%|#####5    |95663/173481[21:00<17:46,72.93it/s] 56%|#####5    |96482/173481[21:11<17:35,72.93it/s] 63%|######3   |109757/173481[24:00<14:03,75.52it/s] 64%|######3   |110708/173481[24:11<13:51,75.52it/s] 72%|#######2  |125225/173481[27:00<10:00,80.39it/s] 73%|#######2  |126208/173481[27:11<09:48,80.39it/s] 81%|########1 |140710/173481[30:00<06:34,83.11it/s] 82%|########1 |141775/173481[30:11<06:21,83.11it/s] 91%|#########1|158098/173481[33:00<02:52,89.35it/s] 92%|#########1|159239/173481[33:11<02:39,89.35it/s]100%|##########|173481/173481[35:49<00:00,80.71it/s]
[32m[0323 01:34:12 @base.py:257][0m Epoch 20 (global_step 6765759) finished, time:2149.45 sec.
[32m[0323 01:34:13 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-6765759.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:06<00:00,149.15it/s]
19
[32m[0323 01:36:19 @monitor.py:363][0m QueueInput/queue_size: 7.8968
[32m[0323 01:36:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.447
[32m[0323 01:36:19 @monitor.py:363][0m activation-summaries/output-rms: 0.038394
[32m[0323 01:36:19 @monitor.py:363][0m cross_entropy_loss: 1.8946
[32m[0323 01:36:19 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73927
[32m[0323 01:36:19 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11188
[32m[0323 01:36:19 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14852
[32m[0323 01:36:19 @monitor.py:363][0m last_linear/Wn_0: 0.39003
[32m[0323 01:36:19 @monitor.py:363][0m last_linear/Wp_0: 0.38634
[32m[0323 01:36:19 @monitor.py:363][0m linear0/W_0_percent_n: 0.11709
[32m[0323 01:36:19 @monitor.py:363][0m linear0/W_0_percent_p: 0.11756
[32m[0323 01:36:19 @monitor.py:363][0m linear0/W_0_sparsity: 0.76512
[32m[0323 01:36:19 @monitor.py:363][0m linear0/Wn_0: 1.0342
[32m[0323 01:36:19 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 01:36:19 @monitor.py:363][0m linear1/W_0_percent_n: 0.26818
[32m[0323 01:36:19 @monitor.py:363][0m linear1/W_0_percent_p: 0.23549
[32m[0323 01:36:19 @monitor.py:363][0m linear1/W_0_sparsity: 0.49604
[32m[0323 01:36:19 @monitor.py:363][0m linear1/Wn_0: 0.97926
[32m[0323 01:36:19 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 01:36:19 @monitor.py:363][0m linear2/W_0_percent_n: 0.31531
[32m[0323 01:36:19 @monitor.py:363][0m linear2/W_0_percent_p: 0.28607
[32m[0323 01:36:19 @monitor.py:363][0m linear2/W_0_sparsity: 0.39852
[32m[0323 01:36:19 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 01:36:19 @monitor.py:363][0m linear2/Wp_0: 0.98842
[32m[0323 01:36:19 @monitor.py:363][0m linear3/W_0_percent_n: 0.33735
[32m[0323 01:36:19 @monitor.py:363][0m linear3/W_0_percent_p: 0.26729
[32m[0323 01:36:19 @monitor.py:363][0m linear3/W_0_sparsity: 0.39529
[32m[0323 01:36:19 @monitor.py:363][0m linear3/Wn_0: 1.0082
[32m[0323 01:36:19 @monitor.py:363][0m linear3/Wp_0: 0.99086
[32m[0323 01:36:19 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84969
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46381
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38151
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34466
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33613
[32m[0323 01:36:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 01:36:19 @monitor.py:363][0m train-error-top1: 0.48673
[32m[0323 01:36:19 @monitor.py:363][0m val-error-top1: 0.64055
[32m[0323 01:36:19 @monitor.py:363][0m val-utt-error: 0.25226
[32m[0323 01:36:19 @monitor.py:363][0m validation_cost: 2.6481
[32m[0323 01:36:19 @monitor.py:363][0m wd_cost: 4.8671e-09
[32m[0323 01:36:19 @group.py:42][0m Callbacks took 126.694 sec in total. InferenceRunner: 126.209sec
[32m[0323 01:36:19 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#         |18630/173481[03:00<24:56,103.50it/s] 11%|#1        |19581/173481[03:10<24:47,103.50it/s] 22%|##1       |37521/173481[06:00<21:44,104.22it/s] 22%|##2       |38317/173481[06:10<21:36,104.22it/s] 30%|##9       |51497/173481[09:00<22:50,88.99it/s]  30%|###       |52333/173481[09:10<22:41,88.99it/s] 40%|###9      |68762/173481[12:00<18:54,92.32it/s] 40%|####      |69990/173481[12:10<18:40,92.32it/s] 51%|#####1    |88519/173481[15:00<14:07,100.29it/s] 52%|#####1    |89360/173481[15:10<13:58,100.29it/s] 59%|#####8    |101695/173481[18:00<14:08,84.63it/s] 59%|#####9    |103071/173481[18:11<13:51,84.63it/s] 71%|#######1  |123337/173481[21:00<08:24,99.33it/s] 72%|#######1  |124068/173481[21:11<08:17,99.33it/s] 78%|#######7  |134905/173481[24:00<08:14,78.03it/s] 78%|#######8  |135561/173481[24:11<08:05,78.03it/s] 84%|########3 |145483/173481[27:00<06:57,67.04it/s] 84%|########4 |146212/173481[27:11<06:46,67.04it/s] 91%|######### |157459/173481[30:00<03:59,66.78it/s] 91%|#########1|158298/173481[30:11<03:47,66.78it/s] 97%|#########7|168919/173481[33:00<01:09,65.18it/s] 98%|#########7|169674/173481[33:11<00:58,65.18it/s]100%|##########|173481/173481[34:11<00:00,84.56it/s]
[32m[0323 02:10:31 @base.py:257][0m Epoch 21 (global_step 6939240) finished, time:2051.56 sec.
[32m[0323 02:10:31 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-6939240.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.45it/s]
20
[32m[0323 02:12:30 @monitor.py:363][0m QueueInput/queue_size: 0.96377
[32m[0323 02:12:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.2
[32m[0323 02:12:30 @monitor.py:363][0m activation-summaries/output-rms: 0.037767
[32m[0323 02:12:30 @monitor.py:363][0m cross_entropy_loss: 1.99
[32m[0323 02:12:30 @monitor.py:363][0m last_linear/W_0_percent_n: 0.73867
[32m[0323 02:12:30 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11149
[32m[0323 02:12:30 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14944
[32m[0323 02:12:30 @monitor.py:363][0m last_linear/Wn_0: 0.39083
[32m[0323 02:12:30 @monitor.py:363][0m last_linear/Wp_0: 0.38725
[32m[0323 02:12:30 @monitor.py:363][0m linear0/W_0_percent_n: 0.11727
[32m[0323 02:12:30 @monitor.py:363][0m linear0/W_0_percent_p: 0.11771
[32m[0323 02:12:30 @monitor.py:363][0m linear0/W_0_sparsity: 0.7648
[32m[0323 02:12:30 @monitor.py:363][0m linear0/Wn_0: 1.0343
[32m[0323 02:12:30 @monitor.py:363][0m linear0/Wp_0: 0.96985
[32m[0323 02:12:30 @monitor.py:363][0m linear1/W_0_percent_n: 0.26907
[32m[0323 02:12:30 @monitor.py:363][0m linear1/W_0_percent_p: 0.23631
[32m[0323 02:12:30 @monitor.py:363][0m linear1/W_0_sparsity: 0.49431
[32m[0323 02:12:30 @monitor.py:363][0m linear1/Wn_0: 0.97956
[32m[0323 02:12:30 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 02:12:30 @monitor.py:363][0m linear2/W_0_percent_n: 0.31548
[32m[0323 02:12:30 @monitor.py:363][0m linear2/W_0_percent_p: 0.28715
[32m[0323 02:12:30 @monitor.py:363][0m linear2/W_0_sparsity: 0.39723
[32m[0323 02:12:30 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 02:12:30 @monitor.py:363][0m linear2/Wp_0: 0.98845
[32m[0323 02:12:30 @monitor.py:363][0m linear3/W_0_percent_n: 0.33779
[32m[0323 02:12:30 @monitor.py:363][0m linear3/W_0_percent_p: 0.26768
[32m[0323 02:12:30 @monitor.py:363][0m linear3/W_0_sparsity: 0.39444
[32m[0323 02:12:30 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 02:12:30 @monitor.py:363][0m linear3/Wp_0: 0.99088
[32m[0323 02:12:30 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84942
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46385
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38156
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3447
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33617
[32m[0323 02:12:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 02:12:30 @monitor.py:363][0m train-error-top1: 0.51234
[32m[0323 02:12:30 @monitor.py:363][0m val-error-top1: 0.63693
[32m[0323 02:12:30 @monitor.py:363][0m val-utt-error: 0.24716
[32m[0323 02:12:30 @monitor.py:363][0m validation_cost: 2.6645
[32m[0323 02:12:30 @monitor.py:363][0m wd_cost: 4.8668e-09
[32m[0323 02:12:30 @group.py:42][0m Callbacks took 119.138 sec in total. InferenceRunner: 118.800sec
[32m[0323 02:12:30 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#         |18534/173481[03:00<25:04,102.97it/s] 11%|#1        |19221/173481[03:10<24:58,102.97it/s] 17%|#7        |30164/173481[06:00<30:05,79.40it/s]  18%|#7        |30888/173481[06:10<29:55,79.40it/s] 24%|##4       |42101/173481[09:00<30:17,72.27it/s] 25%|##4       |42826/173481[09:10<30:07,72.27it/s] 31%|###1      |54244/173481[12:00<28:28,69.78it/s] 32%|###1      |55031/173481[12:10<28:17,69.78it/s] 39%|###8      |67468/173481[15:00<24:41,71.57it/s] 39%|###9      |68217/173481[15:10<24:30,71.57it/s] 46%|####6     |80235/173481[18:00<21:48,71.25it/s] 47%|####6     |81043/173481[18:10<21:37,71.25it/s] 54%|#####3    |92899/173481[21:00<18:58,70.80it/s] 54%|#####4    |93702/173481[21:11<18:46,70.80it/s] 61%|######1   |105940/173481[24:00<15:43,71.61it/s] 62%|######1   |106857/173481[24:11<15:30,71.61it/s] 69%|######8   |118885/173481[27:00<12:40,71.76it/s] 69%|######9   |119772/173481[27:11<12:28,71.76it/s] 76%|#######6  |131902/173481[30:00<09:37,72.04it/s] 77%|#######6  |132861/173481[30:11<09:23,72.04it/s] 85%|########4 |147034/173481[33:00<05:40,77.59it/s] 85%|########5 |148069/173481[33:11<05:27,77.59it/s] 93%|#########3|161350/173481[36:00<02:34,78.54it/s] 94%|#########3|162267/173481[36:11<02:22,78.54it/s]100%|##########|173481/173481[38:36<00:00,74.89it/s]
[32m[0323 02:51:06 @base.py:257][0m Epoch 22 (global_step 7112721) finished, time:2316.49 sec.
[32m[0323 02:51:07 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-7112721.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.30it/s]
21
[32m[0323 02:53:02 @monitor.py:363][0m QueueInput/queue_size: 0.85093
[32m[0323 02:53:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.738
[32m[0323 02:53:02 @monitor.py:363][0m activation-summaries/output-rms: 0.036611
[32m[0323 02:53:02 @monitor.py:363][0m cross_entropy_loss: 2.0027
[32m[0323 02:53:02 @monitor.py:363][0m last_linear/W_0_percent_n: 0.72491
[32m[0323 02:53:02 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11375
[32m[0323 02:53:02 @monitor.py:363][0m last_linear/W_0_sparsity: 0.16067
[32m[0323 02:53:02 @monitor.py:363][0m last_linear/Wn_0: 0.39093
[32m[0323 02:53:02 @monitor.py:363][0m last_linear/Wp_0: 0.38747
[32m[0323 02:53:02 @monitor.py:363][0m linear0/W_0_percent_n: 0.11698
[32m[0323 02:53:02 @monitor.py:363][0m linear0/W_0_percent_p: 0.11774
[32m[0323 02:53:02 @monitor.py:363][0m linear0/W_0_sparsity: 0.76487
[32m[0323 02:53:02 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 02:53:02 @monitor.py:363][0m linear0/Wp_0: 0.96982
[32m[0323 02:53:02 @monitor.py:363][0m linear1/W_0_percent_n: 0.26942
[32m[0323 02:53:02 @monitor.py:363][0m linear1/W_0_percent_p: 0.23656
[32m[0323 02:53:02 @monitor.py:363][0m linear1/W_0_sparsity: 0.49341
[32m[0323 02:53:02 @monitor.py:363][0m linear1/Wn_0: 0.9797
[32m[0323 02:53:02 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 02:53:02 @monitor.py:363][0m linear2/W_0_percent_n: 0.31597
[32m[0323 02:53:02 @monitor.py:363][0m linear2/W_0_percent_p: 0.28766
[32m[0323 02:53:02 @monitor.py:363][0m linear2/W_0_sparsity: 0.3962
[32m[0323 02:53:02 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 02:53:02 @monitor.py:363][0m linear2/Wp_0: 0.98852
[32m[0323 02:53:02 @monitor.py:363][0m linear3/W_0_percent_n: 0.33832
[32m[0323 02:53:02 @monitor.py:363][0m linear3/W_0_percent_p: 0.26855
[32m[0323 02:53:02 @monitor.py:363][0m linear3/W_0_sparsity: 0.39292
[32m[0323 02:53:02 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 02:53:02 @monitor.py:363][0m linear3/Wp_0: 0.99088
[32m[0323 02:53:02 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84916
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46389
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38161
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34474
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3362
[32m[0323 02:53:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 02:53:02 @monitor.py:363][0m train-error-top1: 0.51064
[32m[0323 02:53:02 @monitor.py:363][0m val-error-top1: 0.63696
[32m[0323 02:53:02 @monitor.py:363][0m val-utt-error: 0.24402
[32m[0323 02:53:02 @monitor.py:363][0m validation_cost: 2.6781
[32m[0323 02:53:02 @monitor.py:363][0m wd_cost: 4.8665e-09
[32m[0323 02:53:02 @group.py:42][0m Callbacks took 115.548 sec in total. InferenceRunner: 115.280sec
[32m[0323 02:53:02 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21448/173481[03:00<21:15,119.15it/s] 13%|#3        |22621/173481[03:10<21:06,119.15it/s] 21%|##        |36379/173481[06:00<23:21,97.80it/s]  21%|##1       |37165/173481[06:10<23:13,97.80it/s] 29%|##9       |50322/173481[09:00<23:44,86.45it/s] 29%|##9       |51091/173481[09:10<23:35,86.45it/s] 37%|###6      |63761/173481[12:00<22:49,80.12it/s] 37%|###7      |64599/173481[12:10<22:38,80.12it/s] 45%|####4     |77671/173481[15:00<20:17,78.67it/s] 45%|####5     |78548/173481[15:10<20:06,78.67it/s] 53%|#####2    |91624/173481[18:00<17:28,78.09it/s] 53%|#####3    |92459/173481[18:11<17:17,78.09it/s] 61%|######    |105140/173481[21:00<14:52,76.56it/s] 61%|######1   |105978/173481[21:11<14:41,76.56it/s] 69%|######8   |119000/173481[24:00<11:49,76.78it/s] 69%|######9   |119881/173481[24:11<11:38,76.78it/s] 76%|#######5  |131369/173481[27:00<09:40,72.52it/s] 76%|#######6  |132209/173481[27:11<09:29,72.52it/s] 83%|########2 |143971/173481[30:00<06:54,71.23it/s] 83%|########3 |144702/173481[30:11<06:44,71.23it/s] 90%|######### |156808/173481[33:00<03:53,71.27it/s] 91%|######### |157720/173481[33:11<03:41,71.27it/s] 98%|#########7|169375/173481[36:00<00:58,70.53it/s] 98%|#########8|170190/173481[36:12<00:46,70.53it/s]100%|##########|173481/173481[37:00<00:00,78.14it/s]
[32m[0323 03:30:02 @base.py:257][0m Epoch 23 (global_step 7286202) finished, time:2220.23 sec.
[32m[0323 03:30:02 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-7286202.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.29it/s]
22
[32m[0323 03:31:56 @monitor.py:363][0m QueueInput/queue_size: 1.148
[32m[0323 03:31:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.727
[32m[0323 03:31:56 @monitor.py:363][0m activation-summaries/output-rms: 0.037847
[32m[0323 03:31:56 @monitor.py:363][0m cross_entropy_loss: 1.9537
[32m[0323 03:31:56 @monitor.py:363][0m last_linear/W_0_percent_n: 0.72418
[32m[0323 03:31:56 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11394
[32m[0323 03:31:56 @monitor.py:363][0m last_linear/W_0_sparsity: 0.1612
[32m[0323 03:31:56 @monitor.py:363][0m last_linear/Wn_0: 0.39096
[32m[0323 03:31:56 @monitor.py:363][0m last_linear/Wp_0: 0.38808
[32m[0323 03:31:56 @monitor.py:363][0m linear0/W_0_percent_n: 0.11722
[32m[0323 03:31:56 @monitor.py:363][0m linear0/W_0_percent_p: 0.11783
[32m[0323 03:31:56 @monitor.py:363][0m linear0/W_0_sparsity: 0.76452
[32m[0323 03:31:56 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 03:31:56 @monitor.py:363][0m linear0/Wp_0: 0.96984
[32m[0323 03:31:56 @monitor.py:363][0m linear1/W_0_percent_n: 0.26942
[32m[0323 03:31:56 @monitor.py:363][0m linear1/W_0_percent_p: 0.2366
[32m[0323 03:31:56 @monitor.py:363][0m linear1/W_0_sparsity: 0.49345
[32m[0323 03:31:56 @monitor.py:363][0m linear1/Wn_0: 0.97973
[32m[0323 03:31:56 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 03:31:56 @monitor.py:363][0m linear2/W_0_percent_n: 0.31611
[32m[0323 03:31:56 @monitor.py:363][0m linear2/W_0_percent_p: 0.28742
[32m[0323 03:31:56 @monitor.py:363][0m linear2/W_0_sparsity: 0.39625
[32m[0323 03:31:56 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 03:31:56 @monitor.py:363][0m linear2/Wp_0: 0.98855
[32m[0323 03:31:56 @monitor.py:363][0m linear3/W_0_percent_n: 0.3386
[32m[0323 03:31:56 @monitor.py:363][0m linear3/W_0_percent_p: 0.26847
[32m[0323 03:31:56 @monitor.py:363][0m linear3/W_0_sparsity: 0.39273
[32m[0323 03:31:56 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 03:31:56 @monitor.py:363][0m linear3/Wp_0: 0.99089
[32m[0323 03:31:56 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84906
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.4639
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38162
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34474
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 03:31:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 03:31:56 @monitor.py:363][0m train-error-top1: 0.50539
[32m[0323 03:31:56 @monitor.py:363][0m val-error-top1: 0.61588
[32m[0323 03:31:56 @monitor.py:363][0m val-utt-error: 0.22474
[32m[0323 03:31:56 @monitor.py:363][0m validation_cost: 2.5297
[32m[0323 03:31:56 @monitor.py:363][0m wd_cost: 9.7326e-10
[32m[0323 03:31:56 @group.py:42][0m Callbacks took 114.300 sec in total. InferenceRunner: 113.894sec
[32m[0323 03:31:56 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21058/173481[03:00<21:42,116.98it/s] 13%|#2        |22203/173481[03:10<21:33,116.98it/s] 20%|##        |34702/173481[06:00<25:08,91.98it/s]  20%|##        |35457/173481[06:10<25:00,91.98it/s] 28%|##7       |48250/173481[09:00<25:12,82.77it/s] 28%|##8       |49026/173481[09:10<25:03,82.77it/s] 36%|###5      |61900/173481[12:00<23:29,79.14it/s] 36%|###6      |62714/173481[12:10<23:19,79.14it/s] 43%|####3     |75316/173481[15:00<21:18,76.76it/s] 44%|####3     |76038/173481[15:10<21:09,76.76it/s] 51%|#####1    |88996/173481[18:00<18:26,76.37it/s] 52%|#####1    |89852/173481[18:10<18:15,76.37it/s] 60%|######    |104580/173481[21:00<14:09,81.15it/s] 61%|######    |105461/173481[21:11<13:58,81.15it/s] 70%|#######   |121952/173481[24:00<09:44,88.17it/s] 71%|#######   |123002/173481[24:11<09:32,88.17it/s] 79%|#######9  |137115/173481[27:00<07:02,86.16it/s] 80%|#######9  |138045/173481[27:11<06:51,86.16it/s] 88%|########8 |152776/173481[30:00<03:59,86.57it/s] 89%|########8 |153610/173481[30:11<03:49,86.57it/s] 96%|#########6|166948/173481[33:00<01:19,82.46it/s] 97%|#########6|167925/173481[33:11<01:07,82.46it/s]100%|##########|173481/173481[34:11<00:00,84.58it/s]
[32m[0323 04:06:07 @base.py:257][0m Epoch 24 (global_step 7459683) finished, time:2051.12 sec.
[32m[0323 04:06:08 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-7459683.
[32m[0323 04:06:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.34it/s]
23
[32m[0323 04:08:04 @monitor.py:363][0m QueueInput/queue_size: 1.0571
[32m[0323 04:08:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.769
[32m[0323 04:08:04 @monitor.py:363][0m activation-summaries/output-rms: 0.038454
[32m[0323 04:08:04 @monitor.py:363][0m cross_entropy_loss: 1.952
[32m[0323 04:08:04 @monitor.py:363][0m last_linear/W_0_percent_n: 0.72347
[32m[0323 04:08:04 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11378
[32m[0323 04:08:04 @monitor.py:363][0m last_linear/W_0_sparsity: 0.1621
[32m[0323 04:08:04 @monitor.py:363][0m last_linear/Wn_0: 0.39092
[32m[0323 04:08:04 @monitor.py:363][0m last_linear/Wp_0: 0.38859
[32m[0323 04:08:04 @monitor.py:363][0m linear0/W_0_percent_n: 0.11735
[32m[0323 04:08:04 @monitor.py:363][0m linear0/W_0_percent_p: 0.11797
[32m[0323 04:08:04 @monitor.py:363][0m linear0/W_0_sparsity: 0.76424
[32m[0323 04:08:04 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 04:08:04 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 04:08:04 @monitor.py:363][0m linear1/W_0_percent_n: 0.26967
[32m[0323 04:08:04 @monitor.py:363][0m linear1/W_0_percent_p: 0.23689
[32m[0323 04:08:04 @monitor.py:363][0m linear1/W_0_sparsity: 0.49284
[32m[0323 04:08:04 @monitor.py:363][0m linear1/Wn_0: 0.97977
[32m[0323 04:08:04 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 04:08:04 @monitor.py:363][0m linear2/W_0_percent_n: 0.31616
[32m[0323 04:08:04 @monitor.py:363][0m linear2/W_0_percent_p: 0.28727
[32m[0323 04:08:04 @monitor.py:363][0m linear2/W_0_sparsity: 0.39635
[32m[0323 04:08:04 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 04:08:04 @monitor.py:363][0m linear2/Wp_0: 0.98859
[32m[0323 04:08:04 @monitor.py:363][0m linear3/W_0_percent_n: 0.33856
[32m[0323 04:08:04 @monitor.py:363][0m linear3/W_0_percent_p: 0.26811
[32m[0323 04:08:04 @monitor.py:363][0m linear3/W_0_sparsity: 0.39312
[32m[0323 04:08:04 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 04:08:04 @monitor.py:363][0m linear3/Wp_0: 0.9909
[32m[0323 04:08:04 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84896
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46391
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38162
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34475
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 04:08:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 04:08:04 @monitor.py:363][0m train-error-top1: 0.50284
[32m[0323 04:08:04 @monitor.py:363][0m val-error-top1: 0.62023
[32m[0323 04:08:04 @monitor.py:363][0m val-utt-error: 0.22352
[32m[0323 04:08:04 @monitor.py:363][0m validation_cost: 2.5345
[32m[0323 04:08:04 @monitor.py:363][0m wd_cost: 9.7322e-10
[32m[0323 04:08:04 @group.py:42][0m Callbacks took 116.570 sec in total. InferenceRunner: 115.249sec
[32m[0323 04:08:04 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#         |18885/173481[03:00<24:33,104.92it/s] 12%|#1        |20007/173481[03:10<24:22,104.92it/s] 22%|##2       |38424/173481[06:00<21:05,106.70it/s] 23%|##2       |39566/173481[06:10<20:55,106.70it/s] 34%|###4      |59025/173481[09:00<17:16,110.44it/s] 35%|###4      |60088/173481[09:10<17:06,110.44it/s] 42%|####1     |72747/173481[12:00<18:36,90.20it/s]  42%|####2     |73584/173481[12:10<18:27,90.20it/s] 49%|####9     |85669/173481[15:00<18:18,79.94it/s] 50%|####9     |86400/173481[15:10<18:09,79.94it/s] 57%|#####6    |98361/173481[18:00<16:42,74.93it/s] 57%|#####7    |99090/173481[18:10<16:32,74.93it/s] 64%|######4   |111133/173481[21:00<14:15,72.89it/s] 65%|######4   |111931/173481[21:11<14:04,72.89it/s] 71%|#######1  |123967/173481[24:00<11:26,72.08it/s] 72%|#######1  |124788/173481[24:11<11:15,72.08it/s] 79%|#######8  |136808/173481[27:00<08:31,71.71it/s] 79%|#######9  |137548/173481[27:11<08:21,71.71it/s] 86%|########6 |149598/173481[30:00<05:34,71.38it/s] 87%|########6 |150473/173481[30:11<05:22,71.38it/s] 94%|#########3|162727/173481[33:00<02:29,72.14it/s] 94%|#########4|163584/173481[33:11<02:17,72.14it/s]100%|##########|173481/173481[35:23<00:00,81.70it/s]
[32m[0323 04:43:28 @base.py:257][0m Epoch 25 (global_step 7633164) finished, time:2123.44 sec.
[32m[0323 04:43:28 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-7633164.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.45it/s]
24
[32m[0323 04:45:22 @monitor.py:363][0m QueueInput/queue_size: 1.0343
[32m[0323 04:45:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.168
[32m[0323 04:45:22 @monitor.py:363][0m activation-summaries/output-rms: 0.037142
[32m[0323 04:45:22 @monitor.py:363][0m cross_entropy_loss: 1.9527
[32m[0323 04:45:22 @monitor.py:363][0m last_linear/W_0_percent_n: 0.68094
[32m[0323 04:45:22 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11818
[32m[0323 04:45:22 @monitor.py:363][0m last_linear/W_0_sparsity: 0.20014
[32m[0323 04:45:22 @monitor.py:363][0m last_linear/Wn_0: 0.39089
[32m[0323 04:45:22 @monitor.py:363][0m last_linear/Wp_0: 0.38896
[32m[0323 04:45:22 @monitor.py:363][0m linear0/W_0_percent_n: 0.11707
[32m[0323 04:45:22 @monitor.py:363][0m linear0/W_0_percent_p: 0.11786
[32m[0323 04:45:22 @monitor.py:363][0m linear0/W_0_sparsity: 0.76431
[32m[0323 04:45:22 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 04:45:22 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 04:45:22 @monitor.py:363][0m linear1/W_0_percent_n: 0.26951
[32m[0323 04:45:22 @monitor.py:363][0m linear1/W_0_percent_p: 0.2362
[32m[0323 04:45:22 @monitor.py:363][0m linear1/W_0_sparsity: 0.49319
[32m[0323 04:45:22 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 04:45:22 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 04:45:22 @monitor.py:363][0m linear2/W_0_percent_n: 0.3162
[32m[0323 04:45:22 @monitor.py:363][0m linear2/W_0_percent_p: 0.28778
[32m[0323 04:45:22 @monitor.py:363][0m linear2/W_0_sparsity: 0.39562
[32m[0323 04:45:22 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 04:45:22 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 04:45:22 @monitor.py:363][0m linear3/W_0_percent_n: 0.33724
[32m[0323 04:45:22 @monitor.py:363][0m linear3/W_0_percent_p: 0.26825
[32m[0323 04:45:22 @monitor.py:363][0m linear3/W_0_sparsity: 0.39413
[32m[0323 04:45:22 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 04:45:22 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 04:45:22 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84889
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33622
[32m[0323 04:45:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 04:45:22 @monitor.py:363][0m train-error-top1: 0.50451
[32m[0323 04:45:22 @monitor.py:363][0m val-error-top1: 0.60698
[32m[0323 04:45:22 @monitor.py:363][0m val-utt-error: 0.21135
[32m[0323 04:45:22 @monitor.py:363][0m validation_cost: 2.4518
[32m[0323 04:45:22 @monitor.py:363][0m wd_cost: 9.7319e-10
[32m[0323 04:45:22 @group.py:42][0m Callbacks took 114.071 sec in total. InferenceRunner: 113.774sec
[32m[0323 04:45:22 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20170/173481[03:00<22:48,112.03it/s] 12%|#2        |20873/173481[03:10<22:42,112.03it/s] 19%|#8        |32650/173481[06:00<27:24,85.65it/s]  19%|#9        |33397/173481[06:10<27:15,85.65it/s] 26%|##6       |45194/173481[09:00<27:49,76.85it/s] 26%|##6       |45950/173481[09:10<27:39,76.85it/s] 34%|###3      |58617/173481[12:00<25:17,75.69it/s] 34%|###4      |59357/173481[12:10<25:07,75.69it/s] 41%|####1     |71591/173481[15:00<22:59,73.84it/s] 42%|####1     |72399/173481[15:10<22:48,73.84it/s] 48%|####8     |83644/173481[18:00<21:19,70.22it/s] 49%|####8     |84369/173481[18:11<21:09,70.22it/s] 55%|#####4    |95179/173481[21:00<19:28,67.01it/s] 55%|#####5    |95933/173481[21:11<19:17,67.01it/s] 62%|######2   |107968/173481[24:00<15:49,68.96it/s] 63%|######2   |108801/173481[24:11<15:37,68.96it/s] 70%|######9   |120655/173481[27:00<12:37,69.71it/s] 70%|#######   |121499/173481[27:11<12:25,69.71it/s] 77%|#######7  |133732/173481[30:00<09:18,71.15it/s] 78%|#######7  |134533/173481[30:11<09:07,71.15it/s] 85%|########4 |146717/173481[33:00<06:13,71.64it/s] 85%|########5 |147555/173481[33:11<06:01,71.64it/s] 92%|#########1|159557/173481[36:00<03:14,71.48it/s] 92%|#########2|160389/173481[36:12<03:03,71.48it/s] 99%|#########9|172306/173481[39:00<00:16,71.15it/s]100%|#########9|173139/173481[39:12<00:04,71.15it/s]100%|##########|173481/173481[39:17<00:00,73.60it/s]
[32m[0323 05:24:39 @base.py:257][0m Epoch 26 (global_step 7806645) finished, time:2357.13 sec.
[32m[0323 05:24:39 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-7806645.
[32m[0323 05:24:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.61it/s]
25
[32m[0323 05:26:33 @monitor.py:363][0m QueueInput/queue_size: 0.98699
[32m[0323 05:26:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.242
[32m[0323 05:26:33 @monitor.py:363][0m activation-summaries/output-rms: 0.038117
[32m[0323 05:26:33 @monitor.py:363][0m cross_entropy_loss: 1.9033
[32m[0323 05:26:33 @monitor.py:363][0m last_linear/W_0_percent_n: 0.67803
[32m[0323 05:26:33 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11841
[32m[0323 05:26:33 @monitor.py:363][0m last_linear/W_0_sparsity: 0.20293
[32m[0323 05:26:33 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 05:26:33 @monitor.py:363][0m last_linear/Wp_0: 0.38916
[32m[0323 05:26:33 @monitor.py:363][0m linear0/W_0_percent_n: 0.11702
[32m[0323 05:26:33 @monitor.py:363][0m linear0/W_0_percent_p: 0.11781
[32m[0323 05:26:33 @monitor.py:363][0m linear0/W_0_sparsity: 0.76437
[32m[0323 05:26:33 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 05:26:33 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 05:26:33 @monitor.py:363][0m linear1/W_0_percent_n: 0.26924
[32m[0323 05:26:33 @monitor.py:363][0m linear1/W_0_percent_p: 0.23668
[32m[0323 05:26:33 @monitor.py:363][0m linear1/W_0_sparsity: 0.4929
[32m[0323 05:26:33 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 05:26:33 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 05:26:33 @monitor.py:363][0m linear2/W_0_percent_n: 0.31648
[32m[0323 05:26:33 @monitor.py:363][0m linear2/W_0_percent_p: 0.28717
[32m[0323 05:26:33 @monitor.py:363][0m linear2/W_0_sparsity: 0.39598
[32m[0323 05:26:33 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 05:26:33 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 05:26:33 @monitor.py:363][0m linear3/W_0_percent_n: 0.33657
[32m[0323 05:26:33 @monitor.py:363][0m linear3/W_0_percent_p: 0.26752
[32m[0323 05:26:33 @monitor.py:363][0m linear3/W_0_sparsity: 0.3956
[32m[0323 05:26:33 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 05:26:33 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 05:26:33 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84887
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 05:26:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 05:26:33 @monitor.py:363][0m train-error-top1: 0.49122
[32m[0323 05:26:33 @monitor.py:363][0m val-error-top1: 0.60669
[32m[0323 05:26:33 @monitor.py:363][0m val-utt-error: 0.20991
[32m[0323 05:26:33 @monitor.py:363][0m validation_cost: 2.4803
[32m[0323 05:26:33 @monitor.py:363][0m wd_cost: 1.9464e-10
[32m[0323 05:26:33 @group.py:42][0m Callbacks took 114.262 sec in total. InferenceRunner: 112.990sec
[32m[0323 05:26:33 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19711/173481[03:00<23:24,109.49it/s] 12%|#1        |20394/173481[03:10<23:18,109.49it/s] 19%|#8        |32250/173481[06:00<27:38,85.15it/s]  19%|#9        |32979/173481[06:10<27:30,85.15it/s] 26%|##5       |44981/173481[09:00<27:43,77.27it/s] 26%|##6       |45715/173481[09:10<27:33,77.27it/s] 33%|###2      |57102/173481[12:00<26:57,71.96it/s] 33%|###3      |57810/173481[12:10<26:47,71.96it/s] 40%|###9      |69367/173481[15:00<24:47,69.99it/s] 40%|####      |69942/173481[15:10<24:39,69.99it/s] 47%|####7     |82052/173481[18:00<21:41,70.23it/s] 48%|####7     |82822/173481[18:11<21:30,70.23it/s] 55%|#####5    |96052/173481[21:00<17:29,73.81it/s] 56%|#####5    |96933/173481[21:11<17:17,73.81it/s] 67%|######6   |115538/173481[24:00<11:00,87.77it/s] 67%|######7   |116921/173481[24:11<10:44,87.77it/s] 76%|#######5  |131023/173481[27:00<08:08,86.88it/s] 76%|#######5  |131724/173481[27:11<08:00,86.88it/s] 83%|########2 |143187/173481[30:00<06:38,76.02it/s] 83%|########3 |144032/173481[30:11<06:27,76.02it/s] 90%|######### |156385/173481[33:00<03:49,74.65it/s] 91%|######### |157158/173481[33:11<03:38,74.65it/s] 98%|#########7|169150/173481[36:00<00:59,72.73it/s] 98%|#########8|170052/173481[36:11<00:47,72.73it/s]100%|##########|173481/173481[36:59<00:00,78.17it/s]
[32m[0323 06:03:32 @base.py:257][0m Epoch 27 (global_step 7980126) finished, time:2219.15 sec.
[32m[0323 06:03:32 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-7980126.
[32m[0323 06:03:33 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.84it/s]
26
[32m[0323 06:05:26 @monitor.py:363][0m QueueInput/queue_size: 1.0644
[32m[0323 06:05:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.002
[32m[0323 06:05:26 @monitor.py:363][0m activation-summaries/output-rms: 0.037911
[32m[0323 06:05:26 @monitor.py:363][0m cross_entropy_loss: 1.9876
[32m[0323 06:05:26 @monitor.py:363][0m last_linear/W_0_percent_n: 0.67724
[32m[0323 06:05:26 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11852
[32m[0323 06:05:26 @monitor.py:363][0m last_linear/W_0_sparsity: 0.20359
[32m[0323 06:05:26 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 06:05:26 @monitor.py:363][0m last_linear/Wp_0: 0.38934
[32m[0323 06:05:26 @monitor.py:363][0m linear0/W_0_percent_n: 0.11702
[32m[0323 06:05:26 @monitor.py:363][0m linear0/W_0_percent_p: 0.1176
[32m[0323 06:05:26 @monitor.py:363][0m linear0/W_0_sparsity: 0.76456
[32m[0323 06:05:26 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 06:05:26 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 06:05:26 @monitor.py:363][0m linear1/W_0_percent_n: 0.26952
[32m[0323 06:05:26 @monitor.py:363][0m linear1/W_0_percent_p: 0.23606
[32m[0323 06:05:26 @monitor.py:363][0m linear1/W_0_sparsity: 0.49321
[32m[0323 06:05:26 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 06:05:26 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 06:05:26 @monitor.py:363][0m linear2/W_0_percent_n: 0.31621
[32m[0323 06:05:26 @monitor.py:363][0m linear2/W_0_percent_p: 0.2872
[32m[0323 06:05:26 @monitor.py:363][0m linear2/W_0_sparsity: 0.3962
[32m[0323 06:05:26 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 06:05:26 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 06:05:26 @monitor.py:363][0m linear3/W_0_percent_n: 0.33637
[32m[0323 06:05:26 @monitor.py:363][0m linear3/W_0_percent_p: 0.2677
[32m[0323 06:05:26 @monitor.py:363][0m linear3/W_0_sparsity: 0.39561
[32m[0323 06:05:26 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 06:05:26 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 06:05:26 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84886
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 06:05:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 06:05:26 @monitor.py:363][0m train-error-top1: 0.52122
[32m[0323 06:05:26 @monitor.py:363][0m val-error-top1: 0.60943
[32m[0323 06:05:26 @monitor.py:363][0m val-utt-error: 0.21262
[32m[0323 06:05:26 @monitor.py:363][0m validation_cost: 2.502
[32m[0323 06:05:26 @monitor.py:363][0m wd_cost: 1.9463e-10
[32m[0323 06:05:26 @group.py:42][0m Callbacks took 113.590 sec in total. InferenceRunner: 112.830sec
[32m[0323 06:05:26 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21342/173481[03:00<21:23,118.57it/s] 13%|#2        |22348/173481[03:10<21:14,118.57it/s] 20%|##        |35200/173481[06:00<24:41,93.36it/s]  21%|##        |35949/173481[06:10<24:33,93.36it/s] 28%|##7       |48229/173481[09:00<25:36,81.54it/s] 28%|##8       |49059/173481[09:10<25:25,81.54it/s] 35%|###5      |61414/173481[12:00<24:12,77.17it/s] 36%|###5      |62155/173481[12:10<24:02,77.17it/s] 43%|####3     |74616/173481[15:00<21:54,75.21it/s] 43%|####3     |75363/173481[15:10<21:44,75.21it/s] 51%|#####     |87868/173481[18:00<19:10,74.40it/s] 51%|#####1    |88647/173481[18:10<19:00,74.40it/s] 58%|#####8    |101247/173481[21:00<16:11,74.36it/s] 59%|#####8    |102073/173481[21:11<16:00,74.36it/s] 66%|######5   |114376/173481[24:00<13:22,73.64it/s] 66%|######6   |115215/173481[24:11<13:11,73.64it/s] 74%|#######3  |127708/173481[27:00<10:19,73.85it/s] 74%|#######4  |128538/173481[27:11<10:08,73.85it/s] 82%|########2 |142396/173481[30:00<06:40,77.53it/s] 83%|########2 |143438/173481[30:11<06:27,77.53it/s] 91%|#########1|157966/173481[33:00<03:09,81.77it/s] 92%|#########1|159044/173481[33:11<02:56,81.77it/s]100%|#########9|173276/173481[36:00<00:02,83.38it/s]100%|##########|173481/173481[36:02<00:00,80.21it/s]
[32m[0323 06:41:29 @base.py:257][0m Epoch 28 (global_step 8153607) finished, time:2162.79 sec.
[32m[0323 06:41:29 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-8153607.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.37it/s]
27
[32m[0323 06:43:23 @monitor.py:363][0m QueueInput/queue_size: 1.0207
[32m[0323 06:43:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.158
[32m[0323 06:43:23 @monitor.py:363][0m activation-summaries/output-rms: 0.036869
[32m[0323 06:43:23 @monitor.py:363][0m cross_entropy_loss: 1.9835
[32m[0323 06:43:23 @monitor.py:363][0m last_linear/W_0_percent_n: 0.65855
[32m[0323 06:43:23 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11928
[32m[0323 06:43:23 @monitor.py:363][0m last_linear/W_0_sparsity: 0.22207
[32m[0323 06:43:23 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 06:43:23 @monitor.py:363][0m last_linear/Wp_0: 0.3894
[32m[0323 06:43:23 @monitor.py:363][0m linear0/W_0_percent_n: 0.11624
[32m[0323 06:43:23 @monitor.py:363][0m linear0/W_0_percent_p: 0.11711
[32m[0323 06:43:23 @monitor.py:363][0m linear0/W_0_sparsity: 0.76489
[32m[0323 06:43:23 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 06:43:23 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 06:43:23 @monitor.py:363][0m linear1/W_0_percent_n: 0.26868
[32m[0323 06:43:23 @monitor.py:363][0m linear1/W_0_percent_p: 0.2353
[32m[0323 06:43:23 @monitor.py:363][0m linear1/W_0_sparsity: 0.49379
[32m[0323 06:43:23 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 06:43:23 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 06:43:23 @monitor.py:363][0m linear2/W_0_percent_n: 0.315
[32m[0323 06:43:23 @monitor.py:363][0m linear2/W_0_percent_p: 0.28681
[32m[0323 06:43:23 @monitor.py:363][0m linear2/W_0_sparsity: 0.39751
[32m[0323 06:43:23 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 06:43:23 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 06:43:23 @monitor.py:363][0m linear3/W_0_percent_n: 0.33186
[32m[0323 06:43:23 @monitor.py:363][0m linear3/W_0_percent_p: 0.26916
[32m[0323 06:43:23 @monitor.py:363][0m linear3/W_0_sparsity: 0.39849
[32m[0323 06:43:23 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 06:43:23 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 06:43:23 @monitor.py:363][0m lr: 7.6294e-09
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84885
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 06:43:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 06:43:23 @monitor.py:363][0m train-error-top1: 0.50239
[32m[0323 06:43:23 @monitor.py:363][0m val-error-top1: 0.56239
[32m[0323 06:43:23 @monitor.py:363][0m val-utt-error: 0.1486
[32m[0323 06:43:23 @monitor.py:363][0m validation_cost: 2.2011
[32m[0323 06:43:23 @monitor.py:363][0m wd_cost: 1.9463e-10
[32m[0323 06:43:23 @group.py:42][0m Callbacks took 114.157 sec in total. InferenceRunner: 113.836sec
[32m[0323 06:43:23 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21269/173481[03:00<21:28,118.16it/s] 13%|#2        |22455/173481[03:10<21:18,118.16it/s] 24%|##3       |41335/173481[06:00<19:11,114.71it/s] 24%|##4       |42235/173481[06:10<19:04,114.71it/s] 33%|###3      |57685/173481[09:00<19:02,101.38it/s] 34%|###3      |58663/173481[09:10<18:52,101.38it/s] 42%|####1     |72007/173481[12:00<18:58,89.15it/s]  42%|####1     |72798/173481[12:10<18:49,89.15it/s] 50%|####9     |85904/173481[15:00<17:38,82.75it/s] 50%|####9     |86730/173481[15:10<17:28,82.75it/s] 57%|#####7    |99180/173481[18:00<15:52,77.99it/s] 58%|#####7    |100032/173481[18:11<15:41,77.99it/s] 65%|######4   |112442/173481[21:00<13:25,75.77it/s] 65%|######5   |113241/173481[21:11<13:15,75.77it/s] 73%|#######2  |126181/173481[24:00<10:22,76.04it/s] 73%|#######3  |127044/173481[24:11<10:10,76.04it/s] 80%|#######9  |138429/173481[27:00<08:08,71.82it/s] 80%|########  |139236/173481[27:11<07:56,71.82it/s] 87%|########7 |151578/173481[30:00<05:02,72.43it/s] 88%|########7 |152340/173481[30:11<04:51,72.43it/s] 95%|#########5|165037/173481[33:00<01:54,73.57it/s] 96%|#########5|165780/173481[33:11<01:44,73.57it/s]100%|##########|173481/173481[34:56<00:00,82.75it/s]
[32m[0323 07:18:19 @base.py:257][0m Epoch 29 (global_step 8327088) finished, time:2096.48 sec.
[32m[0323 07:18:19 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-8327088.
[32m[0323 07:18:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.18it/s]
28
[32m[0323 07:20:19 @monitor.py:363][0m QueueInput/queue_size: 1.2318
[32m[0323 07:20:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.088
[32m[0323 07:20:19 @monitor.py:363][0m activation-summaries/output-rms: 0.038407
[32m[0323 07:20:19 @monitor.py:363][0m cross_entropy_loss: 1.9484
[32m[0323 07:20:19 @monitor.py:363][0m last_linear/W_0_percent_n: 0.65756
[32m[0323 07:20:19 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11933
[32m[0323 07:20:19 @monitor.py:363][0m last_linear/W_0_sparsity: 0.22298
[32m[0323 07:20:19 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 07:20:19 @monitor.py:363][0m last_linear/Wp_0: 0.3894
[32m[0323 07:20:19 @monitor.py:363][0m linear0/W_0_percent_n: 0.11621
[32m[0323 07:20:19 @monitor.py:363][0m linear0/W_0_percent_p: 0.11689
[32m[0323 07:20:19 @monitor.py:363][0m linear0/W_0_sparsity: 0.76504
[32m[0323 07:20:19 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 07:20:19 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 07:20:19 @monitor.py:363][0m linear1/W_0_percent_n: 0.26836
[32m[0323 07:20:19 @monitor.py:363][0m linear1/W_0_percent_p: 0.23432
[32m[0323 07:20:19 @monitor.py:363][0m linear1/W_0_sparsity: 0.49511
[32m[0323 07:20:19 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 07:20:19 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 07:20:19 @monitor.py:363][0m linear2/W_0_percent_n: 0.31565
[32m[0323 07:20:19 @monitor.py:363][0m linear2/W_0_percent_p: 0.28666
[32m[0323 07:20:19 @monitor.py:363][0m linear2/W_0_sparsity: 0.39696
[32m[0323 07:20:19 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 07:20:19 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 07:20:19 @monitor.py:363][0m linear3/W_0_percent_n: 0.33189
[32m[0323 07:20:19 @monitor.py:363][0m linear3/W_0_percent_p: 0.26877
[32m[0323 07:20:19 @monitor.py:363][0m linear3/W_0_sparsity: 0.39878
[32m[0323 07:20:19 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 07:20:19 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 07:20:19 @monitor.py:363][0m lr: 7.6294e-09
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84885
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 07:20:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 07:20:19 @monitor.py:363][0m train-error-top1: 0.49863
[32m[0323 07:20:19 @monitor.py:363][0m val-error-top1: 0.56447
[32m[0323 07:20:19 @monitor.py:363][0m val-utt-error: 0.16034
[32m[0323 07:20:19 @monitor.py:363][0m validation_cost: 2.2243
[32m[0323 07:20:19 @monitor.py:363][0m wd_cost: 3.8927e-11
[32m[0323 07:20:19 @group.py:42][0m Callbacks took 120.045 sec in total. InferenceRunner: 119.010sec
[32m[0323 07:20:19 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20791/173481[03:00<22:01,115.50it/s] 13%|#2        |21940/173481[03:10<21:52,115.50it/s] 21%|##1       |36942/173481[06:00<22:31,100.99it/s] 22%|##1       |37719/173481[06:10<22:24,100.99it/s] 29%|##9       |50546/173481[09:00<23:41,86.46it/s]  30%|##9       |51279/173481[09:10<23:33,86.46it/s] 37%|###6      |63749/173481[12:00<23:02,79.36it/s] 37%|###7      |64470/173481[12:10<22:53,79.36it/s] 45%|####4     |77692/173481[15:00<20:21,78.40it/s] 45%|####5     |78672/173481[15:10<20:09,78.40it/s] 56%|#####5    |96652/173481[18:00<14:14,89.89it/s] 56%|#####6    |97916/173481[18:11<14:00,89.89it/s] 65%|######4   |112579/173481[21:00<11:22,89.18it/s] 65%|######5   |113425/173481[21:11<11:13,89.18it/s] 74%|#######3  |127549/173481[24:00<08:53,86.07it/s] 74%|#######4  |128430/173481[24:11<08:43,86.07it/s] 81%|########1 |141171/173481[27:00<06:41,80.54it/s] 82%|########1 |142045/173481[27:11<06:30,80.54it/s] 89%|########9 |154521/173481[30:00<04:05,77.22it/s] 90%|########9 |155313/173481[30:11<03:55,77.22it/s] 97%|#########6|167652/173481[33:00<01:17,75.02it/s] 97%|#########7|168563/173481[33:11<01:05,75.02it/s]100%|##########|173481/173481[34:20<00:00,84.18it/s]
[32m[0323 07:54:40 @base.py:257][0m Epoch 30 (global_step 8500569) finished, time:2060.80 sec.
[32m[0323 07:54:41 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-8500569.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.80it/s]
29
[32m[0323 07:56:39 @monitor.py:363][0m QueueInput/queue_size: 1.0512
[32m[0323 07:56:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.141
[32m[0323 07:56:39 @monitor.py:363][0m activation-summaries/output-rms: 0.038389
[32m[0323 07:56:39 @monitor.py:363][0m cross_entropy_loss: 1.9089
[32m[0323 07:56:39 @monitor.py:363][0m last_linear/W_0_percent_n: 0.65692
[32m[0323 07:56:39 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11937
[32m[0323 07:56:39 @monitor.py:363][0m last_linear/W_0_sparsity: 0.22365
[32m[0323 07:56:39 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 07:56:39 @monitor.py:363][0m last_linear/Wp_0: 0.3894
[32m[0323 07:56:39 @monitor.py:363][0m linear0/W_0_percent_n: 0.11578
[32m[0323 07:56:39 @monitor.py:363][0m linear0/W_0_percent_p: 0.11669
[32m[0323 07:56:39 @monitor.py:363][0m linear0/W_0_sparsity: 0.76559
[32m[0323 07:56:39 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 07:56:39 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 07:56:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.2678
[32m[0323 07:56:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.23487
[32m[0323 07:56:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.49511
[32m[0323 07:56:39 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 07:56:39 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 07:56:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.31494
[32m[0323 07:56:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.28642
[32m[0323 07:56:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.39776
[32m[0323 07:56:39 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 07:56:39 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 07:56:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.32989
[32m[0323 07:56:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.26952
[32m[0323 07:56:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.39981
[32m[0323 07:56:39 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 07:56:39 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 07:56:39 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84884
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 07:56:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 07:56:39 @monitor.py:363][0m train-error-top1: 0.50005
[32m[0323 07:56:39 @monitor.py:363][0m val-error-top1: 0.51901
[32m[0323 07:56:39 @monitor.py:363][0m val-utt-error: 0.12252
[32m[0323 07:56:39 @monitor.py:363][0m validation_cost: 2.0021
[32m[0323 07:56:39 @monitor.py:363][0m wd_cost: 3.8927e-11
[32m[0323 07:56:39 @group.py:42][0m Callbacks took 119.275 sec in total. InferenceRunner: 118.543sec
[32m[0323 07:56:39 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14828/173481[03:00<32:05,82.37it/s]  9%|9         |15624/173481[03:10<31:56,82.37it/s] 16%|#6        |28465/173481[06:00<30:37,78.92it/s] 17%|#6        |29256/173481[06:10<30:27,78.92it/s] 24%|##4       |41887/173481[09:00<28:36,76.68it/s] 25%|##4       |42690/173481[09:10<28:25,76.68it/s] 32%|###1      |55141/173481[12:00<26:15,75.11it/s] 32%|###2      |55895/173481[12:10<26:05,75.11it/s] 39%|###9      |67875/173481[15:00<24:09,72.86it/s] 40%|###9      |68696/173481[15:10<23:58,72.86it/s] 47%|####6     |81176/173481[18:00<20:58,73.37it/s] 47%|####7     |81984/173481[18:11<20:47,73.37it/s] 54%|#####4    |93973/173481[21:00<18:21,72.21it/s] 55%|#####4    |94785/173481[21:11<18:09,72.21it/s] 62%|######1   |106697/173481[24:00<15:34,71.44it/s] 62%|######1   |107487/173481[24:11<15:23,71.44it/s] 69%|######8   |119174/173481[27:00<12:51,70.36it/s] 69%|######9   |120000/173481[27:11<12:40,70.36it/s] 76%|#######6  |131977/173481[30:00<09:46,70.74it/s] 77%|#######6  |132754/173481[30:11<09:35,70.74it/s] 83%|########3 |144439/173481[33:00<06:55,69.98it/s] 84%|########3 |145236/173481[33:11<06:43,69.98it/s] 91%|######### |157252/173481[36:00<03:49,70.57it/s] 91%|#########1|158094/173481[36:12<03:38,70.57it/s] 98%|#########8|170065/173481[39:00<00:48,70.88it/s] 99%|#########8|170940/173481[39:12<00:35,70.88it/s]100%|##########|173481/173481[39:47<00:00,72.66it/s]
[32m[0323 08:36:27 @base.py:257][0m Epoch 31 (global_step 8674050) finished, time:2387.53 sec.
[32m[0323 08:36:27 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-8674050.
[32m[0323 08:36:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.28it/s]
30
[32m[0323 08:38:27 @monitor.py:363][0m QueueInput/queue_size: 1.0481
[32m[0323 08:38:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.033
[32m[0323 08:38:27 @monitor.py:363][0m activation-summaries/output-rms: 0.038471
[32m[0323 08:38:27 @monitor.py:363][0m cross_entropy_loss: 1.9717
[32m[0323 08:38:27 @monitor.py:363][0m last_linear/W_0_percent_n: 0.65275
[32m[0323 08:38:27 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11938
[32m[0323 08:38:27 @monitor.py:363][0m last_linear/W_0_sparsity: 0.22784
[32m[0323 08:38:27 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 08:38:27 @monitor.py:363][0m last_linear/Wp_0: 0.3894
[32m[0323 08:38:27 @monitor.py:363][0m linear0/W_0_percent_n: 0.11532
[32m[0323 08:38:27 @monitor.py:363][0m linear0/W_0_percent_p: 0.11553
[32m[0323 08:38:27 @monitor.py:363][0m linear0/W_0_sparsity: 0.76617
[32m[0323 08:38:27 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 08:38:27 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 08:38:27 @monitor.py:363][0m linear1/W_0_percent_n: 0.26613
[32m[0323 08:38:27 @monitor.py:363][0m linear1/W_0_percent_p: 0.23505
[32m[0323 08:38:27 @monitor.py:363][0m linear1/W_0_sparsity: 0.49526
[32m[0323 08:38:27 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 08:38:27 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 08:38:27 @monitor.py:363][0m linear2/W_0_percent_n: 0.3137
[32m[0323 08:38:27 @monitor.py:363][0m linear2/W_0_percent_p: 0.28597
[32m[0323 08:38:27 @monitor.py:363][0m linear2/W_0_sparsity: 0.39913
[32m[0323 08:38:27 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 08:38:27 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 08:38:27 @monitor.py:363][0m linear3/W_0_percent_n: 0.32207
[32m[0323 08:38:27 @monitor.py:363][0m linear3/W_0_percent_p: 0.27522
[32m[0323 08:38:27 @monitor.py:363][0m linear3/W_0_sparsity: 0.40176
[32m[0323 08:38:27 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 08:38:27 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 08:38:27 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84884
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 08:38:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 08:38:27 @monitor.py:363][0m train-error-top1: 0.5095
[32m[0323 08:38:27 @monitor.py:363][0m val-error-top1: 0.51264
[32m[0323 08:38:27 @monitor.py:363][0m val-utt-error: 0.12363
[32m[0323 08:38:27 @monitor.py:363][0m validation_cost: 1.9858
[32m[0323 08:38:27 @monitor.py:363][0m wd_cost: 7.7853e-12
[32m[0323 08:38:27 @group.py:42][0m Callbacks took 120.405 sec in total. InferenceRunner: 119.688sec
[32m[0323 08:38:27 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20774/173481[03:00<22:03,115.41it/s] 13%|#2        |21771/173481[03:10<21:54,115.41it/s] 19%|#9        |33656/173481[06:00<26:22,88.35it/s]  20%|#9        |34372/173481[06:10<26:14,88.35it/s] 27%|##6       |46168/173481[09:00<27:16,77.80it/s] 27%|##7       |46917/173481[09:10<27:06,77.80it/s] 34%|###3      |58509/173481[12:00<26:17,72.89it/s] 34%|###4      |59245/173481[12:10<26:07,72.89it/s] 41%|####      |70738/173481[15:00<24:21,70.32it/s] 41%|####1     |71433/173481[15:10<24:11,70.32it/s] 47%|####7     |81687/173481[18:00<23:27,65.23it/s] 47%|####7     |82383/173481[18:11<23:16,65.23it/s] 54%|#####3    |93338/173481[21:00<20:33,64.98it/s] 54%|#####4    |94068/173481[21:11<20:22,64.98it/s] 61%|######1   |106295/173481[24:00<16:23,68.30it/s] 62%|######1   |107139/173481[24:11<16:11,68.30it/s] 69%|######8   |119422/173481[27:00<12:46,70.54it/s] 69%|######9   |120292/173481[27:11<12:34,70.54it/s] 77%|#######6  |132784/173481[30:00<09:22,72.33it/s] 77%|#######7  |133611/173481[30:11<09:11,72.33it/s] 84%|########4 |146208/173481[33:00<06:11,73.44it/s] 85%|########4 |147081/173481[33:11<05:59,73.44it/s] 92%|#########1|159398/173481[36:00<03:11,73.36it/s] 92%|#########2|160278/173481[36:12<02:59,73.36it/s]100%|#########9|172708/173481[39:00<00:10,73.65it/s]100%|##########|173481/173481[39:11<00:00,73.79it/s]
[32m[0323 09:17:38 @base.py:257][0m Epoch 32 (global_step 8847531) finished, time:2351.02 sec.
[32m[0323 09:17:39 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-8847531.
[32m[0323 09:17:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.99it/s]
31
[32m[0323 09:19:38 @monitor.py:363][0m QueueInput/queue_size: 0.98709
[32m[0323 09:19:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.077
[32m[0323 09:19:38 @monitor.py:363][0m activation-summaries/output-rms: 0.038547
[32m[0323 09:19:38 @monitor.py:363][0m cross_entropy_loss: 1.8553
[32m[0323 09:19:38 @monitor.py:363][0m last_linear/W_0_percent_n: 0.65249
[32m[0323 09:19:38 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11934
[32m[0323 09:19:38 @monitor.py:363][0m last_linear/W_0_sparsity: 0.22814
[32m[0323 09:19:38 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 09:19:38 @monitor.py:363][0m last_linear/Wp_0: 0.3894
[32m[0323 09:19:38 @monitor.py:363][0m linear0/W_0_percent_n: 0.11503
[32m[0323 09:19:38 @monitor.py:363][0m linear0/W_0_percent_p: 0.11543
[32m[0323 09:19:38 @monitor.py:363][0m linear0/W_0_sparsity: 0.76629
[32m[0323 09:19:38 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 09:19:38 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 09:19:38 @monitor.py:363][0m linear1/W_0_percent_n: 0.26573
[32m[0323 09:19:38 @monitor.py:363][0m linear1/W_0_percent_p: 0.23487
[32m[0323 09:19:38 @monitor.py:363][0m linear1/W_0_sparsity: 0.49515
[32m[0323 09:19:38 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 09:19:38 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 09:19:38 @monitor.py:363][0m linear2/W_0_percent_n: 0.31349
[32m[0323 09:19:38 @monitor.py:363][0m linear2/W_0_percent_p: 0.28599
[32m[0323 09:19:38 @monitor.py:363][0m linear2/W_0_sparsity: 0.39944
[32m[0323 09:19:38 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 09:19:38 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 09:19:38 @monitor.py:363][0m linear3/W_0_percent_n: 0.32109
[32m[0323 09:19:38 @monitor.py:363][0m linear3/W_0_percent_p: 0.27584
[32m[0323 09:19:38 @monitor.py:363][0m linear3/W_0_sparsity: 0.40229
[32m[0323 09:19:38 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 09:19:38 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 09:19:38 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84884
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 09:19:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 09:19:38 @monitor.py:363][0m train-error-top1: 0.48935
[32m[0323 09:19:38 @monitor.py:363][0m val-error-top1: 0.51202
[32m[0323 09:19:38 @monitor.py:363][0m val-utt-error: 0.12167
[32m[0323 09:19:38 @monitor.py:363][0m validation_cost: 1.9725
[32m[0323 09:19:38 @monitor.py:363][0m wd_cost: 7.7853e-12
[32m[0323 09:19:38 @group.py:42][0m Callbacks took 120.076 sec in total. InferenceRunner: 118.399sec
[32m[0323 09:19:38 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s] 13%|#2        |21719/173481[03:00<20:57,120.66it/s] 13%|#2        |22469/173481[03:10<20:51,120.66it/s] 20%|##        |34906/173481[06:00<25:20,91.16it/s]  21%|##        |35645/173481[06:10<25:11,91.16it/s] 28%|##7       |47926/173481[09:00<25:56,80.66it/s] 28%|##8       |48695/173481[09:10<25:47,80.66it/s] 35%|###5      |61273/173481[12:00<24:12,77.27it/s] 36%|###5      |62040/173481[12:10<24:02,77.27it/s] 43%|####2     |74544/173481[15:00<21:51,75.46it/s] 43%|####3     |75390/173481[15:10<21:39,75.46it/s] 51%|#####     |88009/173481[18:00<18:57,75.12it/s] 51%|#####1    |88760/173481[18:10<18:47,75.12it/s] 59%|#####9    |102676/173481[21:00<15:05,78.17it/s] 60%|#####9    |103958/173481[21:11<14:49,78.17it/s] 71%|#######1  |123979/173481[24:00<08:45,94.15it/s] 72%|#######1  |124848/173481[24:11<08:36,94.15it/s] 81%|########  |140179/173481[27:00<06:01,92.03it/s] 81%|########1 |141228/173481[27:11<05:50,92.03it/s] 92%|#########2|159765/173481[30:00<02:17,99.72it/s] 93%|#########2|161135/173481[30:11<02:03,99.72it/s]100%|##########|173481/173481[31:58<00:00,90.41it/s]
[32m[0323 09:51:37 @base.py:257][0m Epoch 33 (global_step 9021012) finished, time:1918.72 sec.
[32m[0323 09:51:37 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-9021012.
[32m[0323 09:51:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,159.18it/s]
32
[32m[0323 09:53:36 @monitor.py:363][0m QueueInput/queue_size: 49.563
[32m[0323 09:53:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 18.981
[32m[0323 09:53:36 @monitor.py:363][0m activation-summaries/output-rms: 0.037112
[32m[0323 09:53:36 @monitor.py:363][0m cross_entropy_loss: 1.9211
[32m[0323 09:53:36 @monitor.py:363][0m last_linear/W_0_percent_n: 0.65256
[32m[0323 09:53:36 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11934
[32m[0323 09:53:36 @monitor.py:363][0m last_linear/W_0_sparsity: 0.22804
[32m[0323 09:53:36 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 09:53:36 @monitor.py:363][0m last_linear/Wp_0: 0.3894
[32m[0323 09:53:36 @monitor.py:363][0m linear0/W_0_percent_n: 0.11492
[32m[0323 09:53:36 @monitor.py:363][0m linear0/W_0_percent_p: 0.11531
[32m[0323 09:53:36 @monitor.py:363][0m linear0/W_0_sparsity: 0.76627
[32m[0323 09:53:36 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 09:53:36 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 09:53:36 @monitor.py:363][0m linear1/W_0_percent_n: 0.26527
[32m[0323 09:53:36 @monitor.py:363][0m linear1/W_0_percent_p: 0.23492
[32m[0323 09:53:36 @monitor.py:363][0m linear1/W_0_sparsity: 0.49522
[32m[0323 09:53:36 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 09:53:36 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 09:53:36 @monitor.py:363][0m linear2/W_0_percent_n: 0.31255
[32m[0323 09:53:36 @monitor.py:363][0m linear2/W_0_percent_p: 0.28542
[32m[0323 09:53:36 @monitor.py:363][0m linear2/W_0_sparsity: 0.3997
[32m[0323 09:53:36 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 09:53:36 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 09:53:36 @monitor.py:363][0m linear3/W_0_percent_n: 0.31928
[32m[0323 09:53:36 @monitor.py:363][0m linear3/W_0_percent_p: 0.27637
[32m[0323 09:53:36 @monitor.py:363][0m linear3/W_0_sparsity: 0.40238
[32m[0323 09:53:36 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 09:53:36 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 09:53:36 @monitor.py:363][0m lr: 1.9073e-09
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84884
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 09:53:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 09:53:36 @monitor.py:363][0m train-error-top1: 0.51407
[32m[0323 09:53:36 @monitor.py:363][0m val-error-top1: 0.50207
[32m[0323 09:53:36 @monitor.py:363][0m val-utt-error: 0.11178
[32m[0323 09:53:36 @monitor.py:363][0m validation_cost: 1.9288
[32m[0323 09:53:36 @monitor.py:363][0m wd_cost: 7.7853e-12
[32m[0323 09:53:36 @group.py:42][0m Callbacks took 119.198 sec in total. InferenceRunner: 118.258sec
[32m[0323 09:53:36 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21477/173481[03:00<21:13,119.32it/s] 13%|#3        |22655/173481[03:10<21:04,119.32it/s] 24%|##4       |42467/173481[06:00<18:30,117.95it/s] 25%|##5       |43678/173481[06:10<18:20,117.95it/s] 37%|###6      |63364/173481[09:00<15:41,117.01it/s] 37%|###7      |64568/173481[09:10<15:30,117.01it/s] 46%|####5     |79198/173481[12:00<15:38,100.41it/s] 46%|####6     |79977/173481[12:10<15:31,100.41it/s] 54%|#####3    |93073/173481[15:00<15:21,87.21it/s]  54%|#####4    |93909/173481[15:10<15:12,87.21it/s] 62%|######2   |107917/173481[18:00<12:53,84.77it/s] 63%|######2   |108778/173481[18:11<12:43,84.77it/s] 71%|#######1  |123362/173481[21:00<09:47,85.28it/s] 72%|#######1  |124485/173481[21:11<09:34,85.28it/s] 80%|#######9  |138142/173481[24:00<07:02,83.67it/s] 80%|########  |139099/173481[24:11<06:50,83.67it/s] 88%|########8 |153526/173481[27:00<03:56,84.55it/s] 89%|########9 |154565/173481[27:11<03:43,84.55it/s] 97%|#########7|168911/173481[30:00<00:53,85.01it/s] 98%|#########7|169905/173481[30:11<00:42,85.01it/s]100%|##########|173481/173481[30:50<00:00,93.75it/s]
[32m[0323 10:24:27 @base.py:257][0m Epoch 34 (global_step 9194493) finished, time:1850.42 sec.
[32m[0323 10:24:27 @saver.py:84][0m Model saved to train_log/fcn2_a_32_quant_ends_True_preload/model-9194493.
[32m[0323 10:24:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.67it/s]
33
[32m[0323 10:26:24 @monitor.py:363][0m QueueInput/queue_size: 1.1911
[32m[0323 10:26:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 18.965
[32m[0323 10:26:24 @monitor.py:363][0m activation-summaries/output-rms: 0.038124
[32m[0323 10:26:24 @monitor.py:363][0m cross_entropy_loss: 1.966
[32m[0323 10:26:24 @monitor.py:363][0m last_linear/W_0_percent_n: 0.65254
[32m[0323 10:26:24 @monitor.py:363][0m last_linear/W_0_percent_p: 0.11934
[32m[0323 10:26:24 @monitor.py:363][0m last_linear/W_0_sparsity: 0.22806
[32m[0323 10:26:24 @monitor.py:363][0m last_linear/Wn_0: 0.3909
[32m[0323 10:26:24 @monitor.py:363][0m last_linear/Wp_0: 0.3894
[32m[0323 10:26:24 @monitor.py:363][0m linear0/W_0_percent_n: 0.11492
[32m[0323 10:26:24 @monitor.py:363][0m linear0/W_0_percent_p: 0.11531
[32m[0323 10:26:24 @monitor.py:363][0m linear0/W_0_sparsity: 0.76627
[32m[0323 10:26:24 @monitor.py:363][0m linear0/Wn_0: 1.0344
[32m[0323 10:26:24 @monitor.py:363][0m linear0/Wp_0: 0.96987
[32m[0323 10:26:24 @monitor.py:363][0m linear1/W_0_percent_n: 0.26527
[32m[0323 10:26:24 @monitor.py:363][0m linear1/W_0_percent_p: 0.23492
[32m[0323 10:26:24 @monitor.py:363][0m linear1/W_0_sparsity: 0.49522
[32m[0323 10:26:24 @monitor.py:363][0m linear1/Wn_0: 0.97979
[32m[0323 10:26:24 @monitor.py:363][0m linear1/Wp_0: 1.0234
[32m[0323 10:26:24 @monitor.py:363][0m linear2/W_0_percent_n: 0.31228
[32m[0323 10:26:24 @monitor.py:363][0m linear2/W_0_percent_p: 0.28542
[32m[0323 10:26:24 @monitor.py:363][0m linear2/W_0_sparsity: 0.3998
[32m[0323 10:26:24 @monitor.py:363][0m linear2/Wn_0: 1.0107
[32m[0323 10:26:24 @monitor.py:363][0m linear2/Wp_0: 0.98861
[32m[0323 10:26:24 @monitor.py:363][0m linear3/W_0_percent_n: 0.31825
[32m[0323 10:26:24 @monitor.py:363][0m linear3/W_0_percent_p: 0.2773
[32m[0323 10:26:24 @monitor.py:363][0m linear3/W_0_sparsity: 0.40252
[32m[0323 10:26:24 @monitor.py:363][0m linear3/Wn_0: 1.0083
[32m[0323 10:26:24 @monitor.py:363][0m linear3/Wp_0: 0.99091
[32m[0323 10:26:24 @monitor.py:363][0m lr: 1.9073e-09
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.84884
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.9405
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46392
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38163
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34476
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33621
[32m[0323 10:26:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 10:26:24 @monitor.py:363][0m train-error-top1: 0.51337
[32m[0323 10:26:24 @monitor.py:363][0m val-error-top1: 0.50337
[32m[0323 10:26:24 @monitor.py:363][0m val-utt-error: 0.11046
[32m[0323 10:26:24 @monitor.py:363][0m validation_cost: 1.9336
[32m[0323 10:26:24 @monitor.py:363][0m wd_cost: 1.5571e-12
[32m[0323 10:26:24 @group.py:42][0m Callbacks took 117.230 sec in total. InferenceRunner: 116.432sec
[32m[0323 10:26:24 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21146/173481[03:00<21:36,117.47it/s] 13%|#2        |22292/173481[03:10<21:27,117.47it/s] 24%|##3       |41625/173481[06:00<19:00,115.59it/s] 25%|##4       |42795/173481[06:10<18:50,115.59it/s] 35%|###5      |61537/173481[09:00<16:30,113.05it/s] 36%|###6      |62609/173481[09:10<16:20,113.05it/s] 46%|####6     |80553/173481[12:00<14:10,109.22it/s] 47%|####7     |81684/173481[12:10<14:00,109.22it/s]slurmstepd: *** JOB 82391 ON sls-sm-6 CANCELLED AT 2018-03-23T10:38:42 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 82391.0 ON sls-sm-6 CANCELLED AT 2018-03-23T10:38:42 ***
