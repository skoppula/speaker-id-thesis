sls-sm-6 2
SLURM_JOBID=334045
SLURM_TASKID=1
../dorefa/real/train_log/fcn1_w_4_a_32_quant_ends_True_preload/checkpoint
[32m[0417 14:37:37 @logger.py:74][0m Argv: ttq_run.py --model_name=fcn1 --quant_ends=True --load_ckpt=../dorefa/real/train_log/fcn1_w_4_a_32_quant_ends_True_preload/checkpoint
[32m[0417 14:37:58 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0417 14:37:58 @ttq_run.py:140][0m Using 6 threads
('whole utterance size', 75290)
[32m[0417 14:37:58 @ttq_run.py:164][0m 18822 utterances per val epoch
[32m[0417 14:37:58 @ttq_run.py:165][0m Using host: sls-sm-6
[32m[0417 14:37:58 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0417 14:37:58 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0417 14:37:59 @ttq_run.py:187][0m Using GPU: 2
[32m[0417 14:37:59 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0417 14:37:59 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0417 14:37:59 @training.py:108][0m Building graph for training tower 0 ...
[32m[0417 14:37:59 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0417 14:37:59 @ttq_run.py:71][0m Ternarizing weight linear0/W
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear0/Wp
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear0/Wn
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear0/b
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear0/bn/beta
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear0/bn/gamma
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear0/bn/mean/EMA
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear0/bn/variance/EMA
[32m[0417 14:37:59 @registry.py:130][0m linear0 output: [None, 256]
[32m[0417 14:37:59 @registry.py:122][0m linear1 input: [None, 256]
[32m[0417 14:37:59 @ttq_run.py:71][0m Ternarizing weight linear1/W
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear1/Wp
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear1/Wn
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear1/b
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear1/bn/beta
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear1/bn/gamma
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear1/bn/mean/EMA
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear1/bn/variance/EMA
[32m[0417 14:37:59 @registry.py:130][0m linear1 output: [None, 256]
[32m[0417 14:37:59 @registry.py:122][0m linear2 input: [None, 256]
[32m[0417 14:37:59 @ttq_run.py:71][0m Ternarizing weight linear2/W
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear2/Wp
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear2/Wn
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear2/b
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear2/bn/beta
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear2/bn/gamma
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear2/bn/mean/EMA
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear2/bn/variance/EMA
[32m[0417 14:37:59 @registry.py:130][0m linear2 output: [None, 256]
[32m[0417 14:37:59 @registry.py:122][0m linear3 input: [None, 256]
[32m[0417 14:37:59 @ttq_run.py:71][0m Ternarizing weight linear3/W
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear3/Wp
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear3/Wn
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear3/b
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear3/bn/beta
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear3/bn/gamma
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear3/bn/mean/EMA
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing linear3/bn/variance/EMA
[32m[0417 14:37:59 @registry.py:130][0m linear3 output: [None, 256]
[32m[0417 14:37:59 @registry.py:122][0m last_linear input: [None, 256]
[32m[0417 14:37:59 @ttq_run.py:71][0m Ternarizing weight last_linear/W
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing last_linear/Wp
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing last_linear/Wn
[32m[0417 14:37:59 @ttq_run.py:59][0m Not ternarizing last_linear/b
[32m[0417 14:37:59 @registry.py:130][0m last_linear output: [None, 255]
[32m[0417 14:37:59 @ttq_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0417 14:37:59 @regularize.py:81][0m regularize_cost() found 15 tensors.
[32m[0417 14:37:59 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear0/Wp:0, linear0/Wn:0, linear1/W:0, linear1/Wp:0, linear1/Wn:0, linear2/W:0, linear2/Wp:0, linear2/Wn:0, linear3/W:0, linear3/Wp:0, linear3/Wn:0, last_linear/W:0, last_linear/Wp:0, last_linear/Wn:0
[32m[0417 14:37:59 @ttq_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0417 14:38:00 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/Wp:0        []                1
linear0/Wn:0        []                1
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/Wp:0        []                1
linear1/Wn:0        []                1
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/Wp:0        []                1
linear2/Wn:0        []                1
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/Wp:0        []                1
linear3/Wn:0        []                1
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/Wp:0    []                1
last_linear/Wn:0    []                1
last_linear/b:0     [255]           255[36m
Total #vars=28, #params=521225, size=1.99MB[0m
[32m[0417 14:38:00 @base.py:196][0m Setup callbacks graph ...
[32m[0417 14:38:00 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0417 14:38:00 @ttq_run.py:71][0m Ternarizing weight linear0/W
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear0/Wp
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear0/Wn
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear0/b
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear0/bn/beta
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear0/bn/gamma
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear0/bn/mean/EMA
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear0/bn/variance/EMA
[32m[0417 14:38:00 @ttq_run.py:71][0m Ternarizing weight linear1/W
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear1/Wp
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear1/Wn
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear1/b
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear1/bn/beta
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear1/bn/gamma
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear1/bn/mean/EMA
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear1/bn/variance/EMA
[32m[0417 14:38:00 @ttq_run.py:71][0m Ternarizing weight linear2/W
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear2/Wp
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear2/Wn
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear2/b
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear2/bn/beta
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear2/bn/gamma
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear2/bn/mean/EMA
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear2/bn/variance/EMA
[32m[0417 14:38:00 @ttq_run.py:71][0m Ternarizing weight linear3/W
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear3/Wp
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear3/Wn
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear3/b
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear3/bn/beta
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear3/bn/gamma
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear3/bn/mean/EMA
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing linear3/bn/variance/EMA
[32m[0417 14:38:00 @ttq_run.py:71][0m Ternarizing weight last_linear/W
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing last_linear/Wp
[32m[0417 14:38:00 @ttq_run.py:59][0m Not ternarizing last_linear/Wn
[32m[0417 14:38:01 @ttq_run.py:59][0m Not ternarizing last_linear/b
[32m[0417 14:38:01 @ttq_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0417 14:38:01 @ttq_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0417 14:38:01 @collection.py:153][0m These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 59->89)
[32m[0417 14:38:01 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0417 14:38:01 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0417 14:38:01 @sessinit.py:89][0m [5m[31mWRN[0m The following variables are in the graph, but not found in the checkpoint: linear0/Wp, linear0/Wn, linear1/Wp, linear1/Wn, linear2/Wp, linear2/Wn, linear3/Wp, linear3/Wn, last_linear/Wp, last_linear/Wn
[32m[0417 14:38:01 @base.py:212][0m Creating the session ...
2018-04-17 14:38:01.976244: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-17 14:38:03.492605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:81:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-04-17 14:38:03.492666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:81:00.0, compute capability: 6.1)
[32m[0417 14:38:10 @base.py:220][0m Initializing the session ...
[32m[0417 14:38:10 @sessinit.py:116][0m Restoring checkpoint from ../dorefa/real/train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-15439809 ...
[32m[0417 14:38:11 @base.py:227][0m Graph Finalized.
[32m[0417 14:38:11 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0417 14:38:11 @steps.py:127][0m Start training with global_step=15439809
[32m[0417 14:38:16 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11665/173481[03:00<41:37,64.78it/s]  7%|7         |12351/173481[03:10<41:27,64.78it/s] 14%|#3        |23545/173481[06:00<38:13,65.38it/s] 14%|#3        |24234/173481[06:10<38:02,65.38it/s] 20%|##        |35323/173481[09:00<35:12,65.40it/s] 21%|##        |35871/173481[09:10<35:04,65.40it/s] 26%|##6       |45875/173481[12:00<34:23,61.82it/s] 27%|##6       |46398/173481[12:10<34:15,61.82it/s] 33%|###2      |56662/173481[15:00<31:59,60.86it/s] 33%|###3      |57280/173481[15:10<31:49,60.86it/s] 37%|###7      |64855/173481[18:00<34:45,52.08it/s] 38%|###7      |65106/173481[18:11<34:40,52.08it/s] 43%|####2     |74161/173481[21:00<31:54,51.89it/s] 43%|####3     |74855/173481[21:11<31:40,51.89it/s] 49%|####8     |84379/173481[24:00<27:23,54.21it/s] 49%|####8     |84929/173481[24:11<27:13,54.21it/s] 54%|#####3    |93308/173481[27:00<25:47,51.81it/s] 54%|#####4    |93936/173481[27:11<25:35,51.81it/s] 60%|#####9    |103315/173481[30:00<21:48,53.63it/s] 60%|#####9    |104010/173481[30:11<21:35,53.63it/s] 66%|######5   |114337/173481[33:00<17:14,57.18it/s] 66%|######6   |115026/173481[33:11<17:02,57.18it/s] 72%|#######2  |125173/173481[36:00<13:43,58.64it/s] 72%|#######2  |125742/173481[36:12<13:34,58.64it/s] 78%|#######8  |135763/173481[39:00<10:42,58.73it/s] 79%|#######8  |136512/173481[39:12<10:29,58.73it/s] 84%|########4 |146261/173481[42:00<07:45,58.52it/s] 85%|########4 |146968/173481[42:12<07:33,58.52it/s] 90%|######### |156839/173481[45:00<04:43,58.64it/s] 91%|######### |157595/173481[45:12<04:30,58.64it/s] 97%|#########6|168149/173481[48:00<01:27,60.66it/s] 97%|#########7|168918/173481[48:12<01:15,60.66it/s]100%|##########|173481/173481[49:31<00:00,58.39it/s]
[32m[0417 15:27:47 @base.py:257][0m Epoch 1 (global_step 15613290) finished, time:2971.22 sec.
[32m[0417 15:27:48 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-15613290.
  0%|          |0/18822[00:00<?,?it/s] 26%|##6       |4949/18822[03:00<08:24,27.49it/s] 28%|##7       |5264/18822[03:10<08:13,27.49it/s] 59%|#####9    |11150/18822[06:00<04:10,30.58it/s] 61%|######1   |11541/18822[06:10<03:58,30.58it/s]100%|#########9|18786/18822[09:00<00:01,35.54it/s]100%|##########|18822/18822[09:00<00:00,34.80it/s]
0
[32m[0417 15:36:49 @monitor.py:363][0m QueueInput/queue_size: 2.3872
[32m[0417 15:36:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0417 15:36:49 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0417 15:36:49 @monitor.py:363][0m cross_entropy_loss: 18.46
[32m[0417 15:36:49 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 15:36:49 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 15:36:49 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 15:36:49 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 15:36:49 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 15:36:49 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 15:36:49 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 15:36:49 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 15:36:49 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 15:36:49 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 15:36:49 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 15:36:49 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 15:36:49 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 15:36:49 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 15:36:49 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 15:36:49 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 15:36:49 @monitor.py:363][0m lr: 1.1642e-13
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 15:36:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 15:36:49 @monitor.py:363][0m train-error-top1: 0.9837
[32m[0417 15:36:49 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0417 15:36:49 @monitor.py:363][0m val-utt-error: 0.9737
[32m[0417 15:36:49 @monitor.py:363][0m validation_cost: 18.765
[32m[0417 15:36:49 @monitor.py:363][0m wd_cost: 3.422e-22
[32m[0417 15:36:49 @group.py:42][0m Callbacks took 541.096 sec in total. InferenceRunner: 540.862sec
[32m[0417 15:36:49 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11104/173481[03:00<43:52,61.68it/s]  7%|6         |11693/173481[03:10<43:42,61.68it/s] 12%|#2        |21320/173481[06:00<42:54,59.11it/s] 13%|#2        |21824/173481[06:10<42:45,59.11it/s] 18%|#8        |31840/173481[09:00<40:09,58.78it/s] 19%|#8        |32473/173481[09:10<39:59,58.78it/s] 24%|##4       |42350/173481[12:00<37:18,58.57it/s] 25%|##4       |42941/173481[12:10<37:08,58.57it/s] 31%|###       |53200/173481[15:00<33:44,59.41it/s] 31%|###1      |53903/173481[15:10<33:32,59.41it/s] 37%|###6      |63872/173481[18:00<30:46,59.35it/s] 37%|###7      |64537/173481[18:11<30:35,59.35it/s] 43%|####2     |74218/173481[21:00<28:19,58.39it/s] 43%|####3     |74800/173481[21:11<28:09,58.39it/s] 47%|####7     |82269/173481[24:00<30:00,50.65it/s] 48%|####7     |82809/173481[24:11<29:50,50.65it/s] 53%|#####2    |91270/173481[27:00<27:14,50.31it/s] 53%|#####2    |91855/173481[27:11<27:02,50.31it/s] 58%|#####7    |100390/173481[30:00<24:07,50.49it/s] 58%|#####8    |100992/173481[30:11<23:55,50.49it/s] 63%|######3   |109917/173481[33:00<20:29,51.68it/s] 64%|######3   |110487/173481[33:11<20:18,51.68it/s] 69%|######8   |118918/173481[36:00<17:53,50.83it/s] 69%|######8   |119473/173481[36:11<17:42,50.83it/s] 74%|#######4  |128565/173481[39:00<14:20,52.17it/s] 74%|#######4  |129177/173481[39:12<14:09,52.17it/s] 79%|#######9  |137446/173481[42:00<11:50,50.71it/s] 80%|#######9  |138100/173481[42:12<11:37,50.71it/s] 85%|########4 |147103/173481[45:00<08:25,52.14it/s] 85%|########5 |147813/173481[45:12<08:12,52.14it/s] 90%|######### |156961/173481[48:00<05:09,53.41it/s] 91%|######### |157665/173481[48:12<04:56,53.41it/s] 96%|#########6|167155/173481[51:00<01:55,54.97it/s] 97%|#########6|167844/173481[51:12<01:42,54.97it/s]100%|##########|173481/173481[52:55<00:00,54.63it/s]
[32m[0417 16:29:44 @base.py:257][0m Epoch 2 (global_step 15786771) finished, time:3175.60 sec.
[32m[0417 16:29:44 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-15786771.
[32m[0417 16:29:45 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:56<00:00,106.73it/s]
1
[32m[0417 16:32:41 @monitor.py:363][0m QueueInput/queue_size: 0.20262
[32m[0417 16:32:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.186
[32m[0417 16:32:41 @monitor.py:363][0m activation-summaries/output-rms: 0.049685
[32m[0417 16:32:41 @monitor.py:363][0m cross_entropy_loss: 18.608
[32m[0417 16:32:41 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 16:32:41 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 16:32:41 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 16:32:41 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 16:32:41 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 16:32:41 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 16:32:41 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 16:32:41 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 16:32:41 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 16:32:41 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 16:32:41 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 16:32:41 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 16:32:41 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 16:32:41 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 16:32:41 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 16:32:41 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 16:32:41 @monitor.py:363][0m lr: 1.1642e-13
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 16:32:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 16:32:41 @monitor.py:363][0m train-error-top1: 0.98565
[32m[0417 16:32:41 @monitor.py:363][0m val-error-top1: 0.98539
[32m[0417 16:32:41 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0417 16:32:41 @monitor.py:363][0m validation_cost: 18.737
[32m[0417 16:32:41 @monitor.py:363][0m wd_cost: 3.422e-22
[32m[0417 16:32:41 @group.py:42][0m Callbacks took 176.802 sec in total. InferenceRunner: 176.367sec
[32m[0417 16:32:41 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10033/173481[03:00<48:53,55.73it/s]  6%|6         |10626/173481[03:10<48:42,55.73it/s] 12%|#1        |20170/173481[06:00<45:36,56.02it/s] 12%|#1        |20790/173481[06:10<45:25,56.02it/s] 17%|#7        |29992/173481[09:00<43:15,55.28it/s] 18%|#7        |30562/173481[09:10<43:05,55.28it/s] 23%|##2       |39873/173481[12:00<40:25,55.09it/s] 23%|##3       |40482/173481[12:10<40:14,55.09it/s] 29%|##8       |50172/173481[15:00<36:36,56.13it/s] 29%|##9       |50756/173481[15:10<36:26,56.13it/s] 35%|###4      |60168/173481[18:00<33:50,55.82it/s] 35%|###5      |60839/173481[18:10<33:37,55.82it/s] 41%|####      |70404/173481[21:00<30:29,56.33it/s] 41%|####      |70949/173481[21:11<30:20,56.33it/s] 47%|####6     |80787/173481[24:00<27:06,57.00it/s] 47%|####6     |81482/173481[24:11<26:54,57.00it/s] 53%|#####2    |91688/173481[27:00<23:12,58.72it/s] 53%|#####3    |92362/173481[27:11<23:01,58.72it/s] 58%|#####7    |100538/173481[30:00<22:42,53.52it/s] 58%|#####8    |101088/173481[30:11<22:32,53.52it/s] 63%|######3   |109301/173481[33:00<20:58,50.99it/s] 63%|######3   |109887/173481[33:11<20:47,50.99it/s] 68%|######8   |118555/173481[36:00<17:52,51.19it/s] 69%|######8   |119169/173481[36:11<17:40,51.19it/s] 74%|#######3  |127855/173481[39:00<14:47,51.42it/s] 74%|#######4  |128461/173481[39:12<14:35,51.42it/s] 79%|#######9  |137208/173481[42:00<11:41,51.69it/s] 79%|#######9  |137876/173481[42:12<11:28,51.69it/s] 85%|########5 |147492/173481[45:00<07:58,54.27it/s] 85%|########5 |148284/173481[45:12<07:44,54.27it/s] 92%|#########1|159221/173481[48:00<04:00,59.21it/s] 92%|#########2|159977/173481[48:12<03:48,59.21it/s] 98%|#########7|169637/173481[51:00<01:05,58.53it/s] 98%|#########8|170340/173481[51:12<00:53,58.53it/s]100%|##########|173481/173481[52:09<00:00,55.43it/s]
[32m[0417 17:24:51 @base.py:257][0m Epoch 3 (global_step 15960252) finished, time:3129.76 sec.
[32m[0417 17:24:51 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-15960252.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:32<00:00,123.15it/s]
2
[32m[0417 17:27:24 @monitor.py:363][0m QueueInput/queue_size: 0.36511
[32m[0417 17:27:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0417 17:27:24 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0417 17:27:24 @monitor.py:363][0m cross_entropy_loss: 18.359
[32m[0417 17:27:24 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 17:27:24 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 17:27:24 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 17:27:24 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 17:27:24 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 17:27:24 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 17:27:24 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 17:27:24 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 17:27:24 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 17:27:24 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 17:27:24 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 17:27:24 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 17:27:24 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 17:27:24 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 17:27:24 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 17:27:24 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 17:27:24 @monitor.py:363][0m lr: 1.1642e-13
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 17:27:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 17:27:24 @monitor.py:363][0m train-error-top1: 0.98423
[32m[0417 17:27:24 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0417 17:27:24 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0417 17:27:24 @monitor.py:363][0m validation_cost: 18.837
[32m[0417 17:27:24 @monitor.py:363][0m wd_cost: 6.844e-23
[32m[0417 17:27:24 @group.py:42][0m Callbacks took 153.006 sec in total. InferenceRunner: 152.855sec
[32m[0417 17:27:24 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10469/173481[03:00<46:42,58.16it/s]  6%|6         |11179/173481[03:10<46:30,58.16it/s] 12%|#2        |21352/173481[06:00<42:45,59.29it/s] 13%|#2        |21931/173481[06:10<42:36,59.29it/s] 18%|#8        |32053/173481[09:00<39:42,59.37it/s] 19%|#8        |32634/173481[09:10<39:32,59.37it/s] 24%|##4       |42304/173481[12:00<37:36,58.13it/s] 25%|##4       |42910/173481[12:10<37:26,58.13it/s] 30%|###       |52335/173481[15:00<35:29,56.90it/s] 31%|###       |52930/173481[15:10<35:18,56.90it/s] 36%|###6      |62518/173481[18:00<32:35,56.74it/s] 36%|###6      |63221/173481[18:11<32:23,56.74it/s] 42%|####2     |73101/173481[21:00<28:58,57.74it/s] 42%|####2     |73707/173481[21:11<28:47,57.74it/s] 48%|####8     |83634/173481[24:00<25:45,58.13it/s] 49%|####8     |84296/173481[24:11<25:34,58.13it/s] 54%|#####4    |94265/173481[27:00<22:32,58.59it/s] 55%|#####4    |94910/173481[27:11<22:21,58.59it/s] 60%|#####9    |103520/173481[30:00<21:17,54.76it/s] 60%|#####9    |104060/173481[30:11<21:07,54.76it/s] 65%|######5   |113356/173481[33:00<18:19,54.69it/s] 66%|######5   |114014/173481[33:11<18:07,54.69it/s] 71%|#######1  |123237/173481[36:00<15:17,54.79it/s] 71%|#######1  |123829/173481[36:11<15:06,54.79it/s] 75%|#######4  |129808/173481[39:00<16:37,43.80it/s] 75%|#######4  |130053/173481[39:12<16:31,43.80it/s] 82%|########1 |141862/173481[42:00<09:57,52.95it/s] 82%|########2 |142588/173481[42:12<09:43,52.95it/s] 87%|########7 |151674/173481[45:00<06:45,53.72it/s] 88%|########7 |152366/173481[45:12<06:33,53.72it/s] 93%|#########3|161673/173481[48:00<03:36,54.61it/s] 94%|#########3|162308/173481[48:12<03:24,54.61it/s] 99%|#########8|171369/173481[51:00<00:38,54.23it/s] 99%|#########9|172008/173481[51:12<00:27,54.23it/s]100%|##########|173481/173481[51:38<00:00,55.99it/s]
[32m[0417 18:19:02 @base.py:257][0m Epoch 4 (global_step 16133733) finished, time:3098.59 sec.
[32m[0417 18:19:03 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-16133733.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:36<00:00,120.37it/s]
3
[32m[0417 18:21:39 @monitor.py:363][0m QueueInput/queue_size: 0.25166
[32m[0417 18:21:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.366
[32m[0417 18:21:39 @monitor.py:363][0m activation-summaries/output-rms: 0.050347
[32m[0417 18:21:39 @monitor.py:363][0m cross_entropy_loss: 18.655
[32m[0417 18:21:39 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 18:21:39 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 18:21:39 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 18:21:39 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 18:21:39 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 18:21:39 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 18:21:39 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 18:21:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 18:21:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 18:21:39 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 18:21:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 18:21:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 18:21:39 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 18:21:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 18:21:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 18:21:39 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 18:21:39 @monitor.py:363][0m lr: 5.8208e-14
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 18:21:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 18:21:39 @monitor.py:363][0m train-error-top1: 0.98777
[32m[0417 18:21:39 @monitor.py:363][0m val-error-top1: 0.98538
[32m[0417 18:21:39 @monitor.py:363][0m val-utt-error: 0.97498
[32m[0417 18:21:39 @monitor.py:363][0m validation_cost: 18.965
[32m[0417 18:21:39 @monitor.py:363][0m wd_cost: 6.844e-23
[32m[0417 18:21:39 @group.py:42][0m Callbacks took 156.580 sec in total. InferenceRunner: 156.388sec
[32m[0417 18:21:39 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11341/173481[03:00<42:53,62.99it/s]  7%|6         |11976/173481[03:10<42:43,62.99it/s] 13%|#2        |22187/173481[06:00<40:56,61.59it/s] 13%|#3        |22761/173481[06:10<40:47,61.59it/s] 18%|#8        |31884/173481[09:00<41:03,57.47it/s] 19%|#8        |32441/173481[09:10<40:54,57.47it/s] 24%|##4       |42084/173481[12:00<38:22,57.06it/s] 25%|##4       |42739/173481[12:10<38:11,57.06it/s] 31%|###       |53306/173481[15:00<33:36,59.59it/s] 31%|###1      |54018/173481[15:10<33:24,59.59it/s] 37%|###7      |64608/173481[18:00<29:40,61.15it/s] 38%|###7      |65304/173481[18:11<29:29,61.15it/s] 44%|####4     |76633/173481[21:00<25:16,63.85it/s] 45%|####4     |77400/173481[21:11<25:04,63.85it/s] 51%|#####     |88321/173481[24:00<22:02,64.38it/s] 51%|#####1    |89097/173481[24:11<21:50,64.38it/s] 57%|#####6    |98448/173481[27:00<20:49,60.05it/s] 57%|#####7    |99217/173481[27:11<20:36,60.05it/s] 64%|######3   |110973/173481[30:00<16:09,64.46it/s] 64%|######4   |111780/173481[30:11<15:57,64.46it/s] 71%|#######   |123025/173481[33:00<12:48,65.69it/s] 71%|#######1  |123775/173481[33:11<12:36,65.69it/s] 77%|#######7  |133912/173481[36:00<10:28,62.97it/s] 78%|#######7  |134496/173481[36:12<10:19,62.97it/s] 83%|########3 |144560/173481[39:00<07:54,61.00it/s] 84%|########3 |145313/173481[39:12<07:41,61.00it/s] 90%|########9 |155730/173481[42:00<04:48,61.52it/s] 90%|######### |156544/173481[42:12<04:35,61.52it/s] 96%|#########6|166591/173481[45:00<01:53,60.92it/s] 96%|#########6|167401/173481[45:12<01:39,60.92it/s]100%|##########|173481/173481[46:38<00:00,61.99it/s]
[32m[0417 19:08:18 @base.py:257][0m Epoch 5 (global_step 16307214) finished, time:2798.60 sec.
[32m[0417 19:08:18 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-16307214.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:09<00:00,145.33it/s]
4
[32m[0417 19:10:27 @monitor.py:363][0m QueueInput/queue_size: 0.41336
[32m[0417 19:10:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0417 19:10:27 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0417 19:10:27 @monitor.py:363][0m cross_entropy_loss: 18.84
[32m[0417 19:10:27 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 19:10:27 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 19:10:27 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 19:10:27 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 19:10:27 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 19:10:27 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 19:10:27 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 19:10:27 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 19:10:27 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 19:10:27 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 19:10:27 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 19:10:27 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 19:10:27 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 19:10:27 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 19:10:27 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 19:10:27 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 19:10:27 @monitor.py:363][0m lr: 5.8208e-14
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 19:10:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 19:10:27 @monitor.py:363][0m train-error-top1: 0.98763
[32m[0417 19:10:27 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0417 19:10:27 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0417 19:10:27 @monitor.py:363][0m validation_cost: 18.777
[32m[0417 19:10:27 @monitor.py:363][0m wd_cost: 6.844e-23
[32m[0417 19:10:27 @group.py:42][0m Callbacks took 129.698 sec in total. InferenceRunner: 129.526sec
[32m[0417 19:10:27 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12058/173481[03:00<40:10,66.97it/s]  7%|7         |12805/173481[03:10<39:59,66.97it/s] 14%|#4        |25084/173481[06:00<35:33,69.56it/s] 15%|#4        |25845/173481[06:10<35:22,69.56it/s] 22%|##1       |38157/173481[09:00<31:44,71.06it/s] 22%|##2       |38918/173481[09:10<31:33,71.06it/s] 29%|##9       |51058/173481[12:00<28:35,71.35it/s] 30%|##9       |51852/173481[12:10<28:24,71.35it/s] 37%|###6      |64050/173481[15:00<25:24,71.76it/s] 37%|###7      |64792/173481[15:10<25:14,71.76it/s] 44%|####4     |77120/173481[18:00<22:14,72.18it/s] 45%|####4     |77890/173481[18:11<22:04,72.18it/s] 52%|#####1    |89773/173481[21:00<19:35,71.22it/s] 52%|#####2    |90507/173481[21:11<19:24,71.22it/s] 59%|#####8    |102290/173481[24:00<16:51,70.37it/s] 59%|#####9    |103067/173481[24:11<16:40,70.37it/s] 66%|######6   |115158/173481[27:00<13:42,70.92it/s] 67%|######6   |115918/173481[27:11<13:31,70.92it/s] 74%|#######3  |127884/173481[30:00<10:43,70.81it/s] 74%|#######4  |128715/173481[30:11<10:32,70.81it/s] 81%|########1 |140656/173481[33:00<07:43,70.87it/s] 82%|########1 |141487/173481[33:11<07:31,70.87it/s] 88%|########8 |153238/173481[36:00<04:47,70.38it/s] 89%|########8 |153982/173481[36:12<04:37,70.38it/s] 96%|#########5|165860/173481[39:00<01:48,70.25it/s] 96%|#########6|166729/173481[39:12<01:36,70.25it/s]100%|##########|173481/173481[40:52<00:00,70.75it/s]
[32m[0417 19:51:20 @base.py:257][0m Epoch 6 (global_step 16480695) finished, time:2452.17 sec.
[32m[0417 19:51:20 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-16480695.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.36it/s]
5
[32m[0417 19:53:24 @monitor.py:363][0m QueueInput/queue_size: 0.41221
[32m[0417 19:53:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0417 19:53:24 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0417 19:53:24 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0417 19:53:24 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 19:53:24 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 19:53:24 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 19:53:24 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 19:53:24 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 19:53:24 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 19:53:24 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 19:53:24 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 19:53:24 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 19:53:24 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 19:53:24 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 19:53:24 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 19:53:24 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 19:53:24 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 19:53:24 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 19:53:24 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 19:53:24 @monitor.py:363][0m lr: 5.8208e-14
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 19:53:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 19:53:24 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0417 19:53:24 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0417 19:53:24 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0417 19:53:24 @monitor.py:363][0m validation_cost: 18.665
[32m[0417 19:53:24 @monitor.py:363][0m wd_cost: 1.3688e-23
[32m[0417 19:53:24 @group.py:42][0m Callbacks took 124.628 sec in total. InferenceRunner: 124.367sec
[32m[0417 19:53:24 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14137/173481[03:00<33:49,78.52it/s]  9%|8         |14958/173481[03:10<33:38,78.52it/s] 16%|#6        |28232/173481[06:00<30:52,78.41it/s] 17%|#6        |28934/173481[06:10<30:43,78.41it/s] 24%|##3       |41581/173481[09:00<28:50,76.23it/s] 24%|##4       |41868/173481[09:10<28:46,76.23it/s] 32%|###1      |55387/173481[12:00<25:44,76.45it/s] 32%|###2      |56162/173481[12:10<25:34,76.45it/s] 39%|###9      |68297/173481[15:00<23:41,74.01it/s] 40%|###9      |69123/173481[15:10<23:30,74.01it/s] 47%|####7     |82021/173481[18:00<20:17,75.11it/s] 48%|####7     |82800/173481[18:10<20:07,75.11it/s] 55%|#####4    |94756/173481[21:00<18:00,72.86it/s] 55%|#####5    |95519/173481[21:11<17:49,72.86it/s] 61%|######    |105463/173481[24:00<17:18,65.49it/s] 61%|######1   |106234/173481[24:11<17:06,65.49it/s] 68%|######8   |118646/173481[27:00<13:13,69.15it/s] 69%|######8   |119473/173481[27:11<13:01,69.15it/s] 76%|#######6  |131875/173481[30:00<09:43,71.25it/s] 76%|#######6  |132701/173481[30:11<09:32,71.25it/s] 84%|########3 |144889/173481[33:00<06:38,71.77it/s] 84%|########4 |145733/173481[33:11<06:26,71.77it/s] 91%|######### |157510/173481[36:00<03:45,70.93it/s] 91%|#########1|158358/173481[36:11<03:33,70.93it/s] 98%|#########7|169633/173481[39:00<00:55,69.09it/s] 98%|#########8|170598/173481[39:12<00:41,69.09it/s]100%|##########|173481/173481[39:49<00:00,72.60it/s]
[32m[0417 20:33:14 @base.py:257][0m Epoch 7 (global_step 16654176) finished, time:2389.48 sec.
[32m[0417 20:33:14 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-16654176.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.90it/s]
6
[32m[0417 20:35:13 @monitor.py:363][0m QueueInput/queue_size: 0.44314
[32m[0417 20:35:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0417 20:35:13 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0417 20:35:13 @monitor.py:363][0m cross_entropy_loss: 18.463
[32m[0417 20:35:13 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 20:35:13 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 20:35:13 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 20:35:13 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 20:35:13 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 20:35:13 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 20:35:13 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 20:35:13 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 20:35:13 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 20:35:13 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 20:35:13 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 20:35:13 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 20:35:13 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 20:35:13 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 20:35:13 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 20:35:13 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 20:35:13 @monitor.py:363][0m lr: 2.9104e-14
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 20:35:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 20:35:13 @monitor.py:363][0m train-error-top1: 0.98367
[32m[0417 20:35:13 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0417 20:35:13 @monitor.py:363][0m val-utt-error: 0.97359
[32m[0417 20:35:13 @monitor.py:363][0m validation_cost: 18.76
[32m[0417 20:35:13 @monitor.py:363][0m wd_cost: 1.3688e-23
[32m[0417 20:35:13 @group.py:42][0m Callbacks took 119.392 sec in total. InferenceRunner: 119.214sec
[32m[0417 20:35:13 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13609/173481[03:00<35:14,75.61it/s]  8%|8         |14343/173481[03:10<35:04,75.61it/s] 15%|#5        |26652/173481[06:00<33:04,74.00it/s] 16%|#5        |27387/173481[06:10<32:54,74.00it/s] 22%|##2       |38770/173481[09:00<31:50,70.50it/s] 23%|##2       |39517/173481[09:10<31:40,70.50it/s] 30%|##9       |51501/173481[12:00<28:47,70.61it/s] 30%|###       |52286/173481[12:10<28:36,70.61it/s] 37%|###7      |64288/173481[15:00<25:41,70.82it/s] 37%|###7      |65025/173481[15:10<25:31,70.82it/s] 44%|####3     |76046/173481[18:00<23:53,67.96it/s] 44%|####4     |76695/173481[18:10<23:44,67.96it/s] 51%|#####     |87850/173481[21:00<21:22,66.75it/s] 51%|#####1    |88547/173481[21:11<21:12,66.75it/s] 57%|#####7    |99544/173481[24:00<18:42,65.84it/s] 58%|#####7    |100323/173481[24:11<18:31,65.84it/s] 65%|######5   |112869/173481[27:00<14:29,69.69it/s] 66%|######5   |113741/173481[27:11<14:17,69.69it/s] 73%|#######3  |126954/173481[30:00<10:31,73.72it/s] 74%|#######3  |127866/173481[30:11<10:18,73.72it/s] 81%|########1 |141082/173481[33:00<07:06,76.03it/s] 82%|########1 |141984/173481[33:11<06:54,76.03it/s] 89%|########9 |154878/173481[36:00<04:03,76.33it/s] 90%|########9 |155791/173481[36:11<03:51,76.33it/s] 97%|#########7|168788/173481[39:00<01:01,76.80it/s] 98%|#########7|169715/173481[39:12<00:49,76.80it/s]100%|##########|173481/173481[40:01<00:00,72.24it/s]
[32m[0417 21:15:15 @base.py:257][0m Epoch 8 (global_step 16827657) finished, time:2401.60 sec.
[32m[0417 21:15:15 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-16827657.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,160.93it/s]
7
[32m[0417 21:17:12 @monitor.py:363][0m QueueInput/queue_size: 0.56027
[32m[0417 21:17:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0417 21:17:12 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0417 21:17:12 @monitor.py:363][0m cross_entropy_loss: 18.55
[32m[0417 21:17:12 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 21:17:12 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 21:17:12 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 21:17:12 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 21:17:12 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 21:17:12 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 21:17:12 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 21:17:12 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 21:17:12 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 21:17:12 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 21:17:12 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 21:17:12 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 21:17:12 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 21:17:12 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 21:17:12 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 21:17:12 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 21:17:12 @monitor.py:363][0m lr: 2.9104e-14
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 21:17:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 21:17:12 @monitor.py:363][0m train-error-top1: 0.98489
[32m[0417 21:17:12 @monitor.py:363][0m val-error-top1: 0.98542
[32m[0417 21:17:12 @monitor.py:363][0m val-utt-error: 0.97381
[32m[0417 21:17:12 @monitor.py:363][0m validation_cost: 18.682
[32m[0417 21:17:12 @monitor.py:363][0m wd_cost: 2.7376e-24
[32m[0417 21:17:12 @group.py:42][0m Callbacks took 117.112 sec in total. InferenceRunner: 116.971sec
[32m[0417 21:17:12 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12445/173481[03:00<38:49,69.13it/s]  8%|7         |13169/173481[03:10<38:39,69.13it/s] 14%|#3        |23431/173481[06:01<38:43,64.59it/s] 14%|#4        |24768/173481[06:20<38:22,64.59it/s] 21%|##        |36127/173481[09:01<33:57,67.43it/s] 22%|##1       |37519/173481[09:20<33:36,67.43it/s] 28%|##8       |49141/173481[12:01<29:42,69.77it/s] 29%|##9       |50511/173481[12:20<29:22,69.77it/s] 36%|###5      |62017/173481[15:01<26:17,70.64it/s] 36%|###6      |63318/173481[15:20<25:59,70.64it/s] 43%|####2     |73888/173481[18:01<24:20,68.21it/s] 43%|####3     |75334/173481[18:21<23:58,68.21it/s] 51%|#####     |87835/173481[21:01<19:40,72.55it/s] 51%|#####1    |89318/173481[21:21<19:20,72.55it/s] 58%|#####7    |100363/173481[24:01<17:09,71.04it/s] 59%|#####8    |101562/173481[24:21<16:52,71.04it/s] 64%|######4   |111664/173481[27:01<15:27,66.66it/s] 65%|######4   |112374/173481[27:11<15:16,66.66it/s] 71%|#######1  |124008/173481[30:01<12:11,67.60it/s] 72%|#######1  |124715/173481[30:11<12:01,67.60it/s] 78%|#######8  |136119/173481[33:01<09:13,67.44it/s] 79%|#######8  |136823/173481[33:11<09:03,67.44it/s] 85%|########4 |147422/173481[36:01<06:40,65.03it/s] 85%|########5 |148147/173481[36:11<06:29,65.03it/s] 93%|#########2|160741/173481[39:01<03:04,69.22it/s] 93%|#########3|161568/173481[39:12<02:52,69.22it/s]100%|##########|173481/173481[41:56<00:00,68.94it/s]
[32m[0417 21:59:08 @base.py:257][0m Epoch 9 (global_step 17001138) finished, time:2516.30 sec.
[32m[0417 21:59:08 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-17001138.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.70it/s]
8
[32m[0417 22:01:03 @monitor.py:363][0m QueueInput/queue_size: 0.55824
[32m[0417 22:01:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0417 22:01:03 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0417 22:01:03 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0417 22:01:03 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 22:01:03 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 22:01:03 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 22:01:03 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 22:01:03 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 22:01:03 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 22:01:03 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 22:01:03 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 22:01:03 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 22:01:03 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 22:01:03 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 22:01:03 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 22:01:03 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 22:01:03 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 22:01:03 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 22:01:03 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 22:01:03 @monitor.py:363][0m lr: 1.4552e-14
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 22:01:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 22:01:03 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0417 22:01:03 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0417 22:01:03 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0417 22:01:03 @monitor.py:363][0m validation_cost: 18.837
[32m[0417 22:01:03 @monitor.py:363][0m wd_cost: 2.7376e-24
[32m[0417 22:01:03 @group.py:42][0m Callbacks took 115.200 sec in total. InferenceRunner: 114.992sec
[32m[0417 22:01:03 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12891/173481[03:00<37:22,71.61it/s]  8%|7         |13599/173481[03:10<37:12,71.61it/s] 14%|#4        |25050/173481[06:00<35:35,69.52it/s] 15%|#4        |25738/173481[06:10<35:25,69.52it/s] 22%|##1       |37367/173481[09:00<32:53,68.97it/s] 22%|##1       |38101/173481[09:10<32:42,68.97it/s] 29%|##8       |49780/173481[12:00<29:53,68.96it/s] 29%|##9       |50544/173481[12:10<29:42,68.96it/s] 36%|###6      |62956/173481[15:00<25:56,71.01it/s] 37%|###6      |63771/173481[15:10<25:44,71.01it/s] 44%|####3     |75527/173481[18:00<23:10,70.42it/s] 44%|####4     |76335/173481[18:10<22:59,70.42it/s] 51%|#####1    |88966/173481[21:00<19:26,72.47it/s] 52%|#####1    |89782/173481[21:11<19:14,72.47it/s] 59%|#####9    |102460/173481[24:00<16:03,73.69it/s] 60%|#####9    |103271/173481[24:11<15:52,73.69it/s] 66%|######5   |114236/173481[27:00<14:14,69.31it/s] 66%|######6   |115048/173481[27:11<14:03,69.31it/s] 72%|#######2  |125674/173481[30:00<12:01,66.29it/s] 73%|#######2  |126381/173481[30:11<11:50,66.29it/s] 79%|#######8  |136430/173481[33:00<09:49,62.85it/s] 79%|#######9  |137259/173481[33:11<09:36,62.85it/s] 86%|########6 |149798/173481[36:00<05:47,68.08it/s] 87%|########6 |150816/173481[36:11<05:32,68.08it/s] 95%|#########5|165658/173481[39:00<01:41,76.81it/s] 96%|#########6|166638/173481[39:12<01:29,76.81it/s]100%|##########|173481/173481[40:37<00:00,71.17it/s]
[32m[0417 22:41:41 @base.py:257][0m Epoch 10 (global_step 17174619) finished, time:2437.47 sec.
[32m[0417 22:41:41 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-17174619.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:48<00:00,173.45it/s]
9
[32m[0417 22:43:29 @monitor.py:363][0m QueueInput/queue_size: 0.68588
[32m[0417 22:43:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0417 22:43:29 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0417 22:43:29 @monitor.py:363][0m cross_entropy_loss: 18.71
[32m[0417 22:43:29 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 22:43:29 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 22:43:29 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 22:43:29 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 22:43:29 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 22:43:29 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 22:43:29 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 22:43:29 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 22:43:29 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 22:43:29 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 22:43:29 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 22:43:29 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 22:43:29 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 22:43:29 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 22:43:29 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 22:43:29 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 22:43:29 @monitor.py:363][0m lr: 1.4552e-14
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 22:43:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 22:43:29 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0417 22:43:29 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0417 22:43:29 @monitor.py:363][0m val-utt-error: 0.97551
[32m[0417 22:43:29 @monitor.py:363][0m validation_cost: 19.032
[32m[0417 22:43:29 @monitor.py:363][0m wd_cost: 2.7376e-24
[32m[0417 22:43:29 @group.py:42][0m Callbacks took 108.692 sec in total. InferenceRunner: 108.530sec
[32m[0417 22:43:29 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14881/173481[03:00<31:58,82.67it/s]  9%|9         |15710/173481[03:10<31:48,82.67it/s] 17%|#6        |29107/173481[06:00<29:46,80.81it/s] 17%|#7        |29916/173481[06:10<29:36,80.81it/s] 25%|##5       |44169/173481[09:00<26:12,82.22it/s] 26%|##6       |45200/173481[09:10<26:00,82.22it/s] 35%|###5      |60939/173481[12:00<21:28,87.34it/s] 36%|###5      |61777/173481[12:10<21:18,87.34it/s] 43%|####2     |74329/173481[15:00<20:34,80.34it/s] 43%|####3     |75108/173481[15:10<20:24,80.34it/s] 51%|#####     |87699/173481[18:00<18:31,77.19it/s] 51%|#####     |88473/173481[18:11<18:21,77.19it/s] 58%|#####8    |101461/173481[21:00<15:37,76.82it/s] 59%|#####8    |102336/173481[21:11<15:26,76.82it/s] 66%|######6   |115165/173481[24:00<12:42,76.47it/s] 67%|######6   |116081/173481[24:11<12:30,76.47it/s] 75%|#######5  |130288/173481[27:00<08:59,80.07it/s] 76%|#######5  |131220/173481[27:11<08:47,80.07it/s] 84%|########3 |145441/173481[30:00<05:41,82.07it/s] 84%|########4 |146352/173481[30:11<05:30,82.07it/s] 91%|#########1|158223/173481[33:00<03:20,76.14it/s] 92%|#########1|159033/173481[33:11<03:09,76.14it/s]100%|#########9|172879/173481[36:00<00:07,78.69it/s]100%|##########|173481/173481[36:06<00:00,80.08it/s]
[32m[0417 23:19:36 @base.py:257][0m Epoch 11 (global_step 17348100) finished, time:2166.26 sec.
[32m[0417 23:19:36 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-17348100.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,174.94it/s]
10
[32m[0417 23:21:23 @monitor.py:363][0m QueueInput/queue_size: 2.0636
[32m[0417 23:21:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0417 23:21:23 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0417 23:21:23 @monitor.py:363][0m cross_entropy_loss: 18.838
[32m[0417 23:21:23 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0417 23:21:23 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0417 23:21:23 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0417 23:21:23 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0417 23:21:23 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0417 23:21:23 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0417 23:21:23 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0417 23:21:23 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0417 23:21:23 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0417 23:21:23 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0417 23:21:23 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0417 23:21:23 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0417 23:21:23 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0417 23:21:23 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0417 23:21:23 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0417 23:21:23 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0417 23:21:23 @monitor.py:363][0m lr: 1.4552e-14
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0417 23:21:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0417 23:21:23 @monitor.py:363][0m train-error-top1: 0.98763
[32m[0417 23:21:23 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0417 23:21:23 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0417 23:21:23 @monitor.py:363][0m validation_cost: 18.777
[32m[0417 23:21:23 @monitor.py:363][0m wd_cost: 5.4752e-25
[32m[0417 23:21:23 @group.py:42][0m Callbacks took 107.762 sec in total. InferenceRunner: 107.603sec
[32m[0417 23:21:23 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14991/173481[03:00<31:43,83.28it/s]  9%|9         |15789/173481[03:10<31:33,83.28it/s] 17%|#6        |28756/173481[06:00<30:15,79.73it/s] 17%|#7        |29589/173481[06:10<30:04,79.73it/s] 24%|##4       |42298/173481[09:00<28:14,77.41it/s] 25%|##4       |43053/173481[09:10<28:04,77.41it/s] 31%|###1      |53788/173481[12:00<28:30,69.96it/s] 31%|###1      |54579/173481[12:10<28:19,69.96it/s] 39%|###8      |66802/173481[15:00<25:00,71.11it/s] 39%|###8      |67610/173481[15:10<24:48,71.11it/s] 46%|####5     |79612/173481[18:00<21:59,71.14it/s] 46%|####6     |80383/173481[18:11<21:48,71.14it/s] 53%|#####2    |91882/173481[21:00<19:32,69.61it/s] 53%|#####3    |92620/173481[21:11<19:21,69.61it/s] 60%|#####9    |103318/173481[24:00<17:36,66.39it/s] 60%|#####9    |103808/173481[24:11<17:29,66.39it/s] 67%|######6   |115570/173481[27:00<14:21,67.21it/s] 67%|######7   |116304/173481[27:11<14:10,67.21it/s] 74%|#######4  |128441/173481[30:00<10:50,69.29it/s] 75%|#######4  |129333/173481[30:11<10:37,69.29it/s] 82%|########2 |142450/173481[33:00<07:03,73.31it/s] 83%|########2 |143275/173481[33:11<06:52,73.31it/s] 90%|######### |156898/173481[36:00<03:36,76.63it/s] 91%|######### |157803/173481[36:11<03:24,76.63it/s] 99%|#########8|170987/173481[39:00<00:32,77.44it/s] 99%|#########9|171933/173481[39:12<00:19,77.44it/s]100%|##########|173481/173481[39:32<00:00,73.12it/s]
[32m[0418 00:00:56 @base.py:257][0m Epoch 12 (global_step 17521581) finished, time:2372.45 sec.
[32m[0418 00:00:56 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-17521581.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.68it/s]
11
[32m[0418 00:02:40 @monitor.py:363][0m QueueInput/queue_size: 0.69267
[32m[0418 00:02:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0418 00:02:40 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0418 00:02:40 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0418 00:02:40 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 00:02:40 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 00:02:40 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 00:02:40 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 00:02:40 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 00:02:40 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 00:02:40 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 00:02:40 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 00:02:40 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 00:02:40 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 00:02:40 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 00:02:40 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 00:02:40 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 00:02:40 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 00:02:40 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 00:02:40 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 00:02:40 @monitor.py:363][0m lr: 7.276e-15
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 00:02:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 00:02:40 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0418 00:02:40 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 00:02:40 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0418 00:02:40 @monitor.py:363][0m validation_cost: 18.665
[32m[0418 00:02:40 @monitor.py:363][0m wd_cost: 5.4752e-25
[32m[0418 00:02:40 @group.py:42][0m Callbacks took 104.311 sec in total. InferenceRunner: 104.185sec
[32m[0418 00:02:40 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14798/173481[03:00<32:10,82.21it/s]  9%|9         |15653/173481[03:10<31:59,82.21it/s] 17%|#6        |29342/173481[06:00<29:28,81.50it/s] 17%|#7        |30192/173481[06:10<29:18,81.50it/s] 25%|##4       |43255/173481[09:00<27:21,79.33it/s] 25%|##5       |44064/173481[09:10<27:11,79.33it/s] 33%|###2      |57000/173481[12:00<24:56,77.82it/s] 33%|###3      |57810/173481[12:10<24:46,77.82it/s] 41%|####      |70477/173481[15:00<22:29,76.31it/s] 41%|####1     |71338/173481[15:10<22:18,76.31it/s] 48%|####8     |84032/173481[18:00<19:40,75.80it/s] 49%|####8     |84794/173481[18:11<19:29,75.80it/s] 56%|#####5    |96807/173481[21:00<17:25,73.31it/s] 56%|#####6    |97631/173481[21:11<17:14,73.31it/s] 63%|######3   |109707/173481[24:00<14:39,72.47it/s] 64%|######3   |110550/173481[24:11<14:28,72.47it/s] 71%|#######   |122977/173481[27:00<11:31,73.08it/s] 71%|#######1  |123804/173481[27:11<11:19,73.08it/s] 79%|#######8  |136203/173481[30:00<08:28,73.28it/s] 79%|#######9  |137077/173481[30:11<08:16,73.28it/s] 86%|########6 |149414/173481[33:00<05:28,73.33it/s] 87%|########6 |150305/173481[33:11<05:16,73.33it/s] 94%|#########3|162481/173481[36:00<02:30,72.96it/s] 94%|#########4|163360/173481[36:12<02:18,72.96it/s]100%|##########|173481/173481[38:26<00:00,75.23it/s]
[32m[0418 00:41:06 @base.py:257][0m Epoch 13 (global_step 17695062) finished, time:2306.07 sec.
[32m[0418 00:41:06 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-17695062.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,171.17it/s]
12
[32m[0418 00:42:56 @monitor.py:363][0m QueueInput/queue_size: 0.71399
[32m[0418 00:42:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0418 00:42:56 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0418 00:42:56 @monitor.py:363][0m cross_entropy_loss: 18.463
[32m[0418 00:42:56 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 00:42:56 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 00:42:56 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 00:42:56 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 00:42:56 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 00:42:56 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 00:42:56 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 00:42:56 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 00:42:56 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 00:42:56 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 00:42:56 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 00:42:56 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 00:42:56 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 00:42:56 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 00:42:56 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 00:42:56 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 00:42:56 @monitor.py:363][0m lr: 7.276e-15
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 00:42:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 00:42:56 @monitor.py:363][0m train-error-top1: 0.98367
[32m[0418 00:42:56 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 00:42:56 @monitor.py:363][0m val-utt-error: 0.97359
[32m[0418 00:42:56 @monitor.py:363][0m validation_cost: 18.76
[32m[0418 00:42:56 @monitor.py:363][0m wd_cost: 5.4752e-25
[32m[0418 00:42:56 @group.py:42][0m Callbacks took 110.138 sec in total. InferenceRunner: 109.971sec
[32m[0418 00:42:56 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13067/173481[03:00<36:49,72.59it/s]  8%|7         |13817/173481[03:10<36:39,72.59it/s] 15%|#4        |25614/173481[06:00<34:39,71.12it/s] 15%|#5        |26303/173481[06:10<34:29,71.12it/s] 22%|##1       |37832/173481[09:00<32:33,69.45it/s] 22%|##2       |38561/173481[09:10<32:22,69.45it/s] 29%|##9       |50337/173481[12:00<29:32,69.46it/s] 29%|##9       |51089/173481[12:10<29:22,69.46it/s] 37%|###6      |63334/173481[15:00<25:55,70.80it/s] 37%|###6      |64047/173481[15:10<25:45,70.80it/s] 43%|####2     |74164/173481[18:00<25:26,65.05it/s] 43%|####3     |74847/173481[18:11<25:16,65.05it/s] 49%|####9     |85660/173481[21:00<22:42,64.45it/s] 50%|####9     |86391/173481[21:11<22:31,64.45it/s] 56%|#####6    |97488/173481[24:00<19:27,65.07it/s] 57%|#####6    |98259/173481[24:11<19:15,65.07it/s] 64%|######3   |110536/173481[27:00<15:17,68.57it/s] 64%|######4   |111287/173481[27:11<15:06,68.57it/s] 71%|#######1  |123598/173481[30:00<11:47,70.51it/s] 72%|#######1  |124467/173481[30:11<11:35,70.51it/s] 79%|#######8  |136853/173481[33:00<08:28,72.04it/s] 79%|#######9  |137637/173481[33:11<08:17,72.04it/s] 86%|########6 |150052/173481[36:00<05:22,72.68it/s] 87%|########6 |150921/173481[36:12<05:10,72.68it/s] 94%|#########4|163193/173481[39:00<02:21,72.84it/s] 95%|#########4|164133/173481[39:12<02:08,72.84it/s]100%|##########|173481/173481[41:14<00:00,70.10it/s]
[32m[0418 01:24:11 @base.py:257][0m Epoch 14 (global_step 17868543) finished, time:2474.65 sec.
[32m[0418 01:24:11 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-17868543.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,158.03it/s]
13
[32m[0418 01:26:10 @monitor.py:363][0m QueueInput/queue_size: 1.4545
[32m[0418 01:26:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0418 01:26:10 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0418 01:26:10 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0418 01:26:10 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 01:26:10 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 01:26:10 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 01:26:10 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 01:26:10 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 01:26:10 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 01:26:10 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 01:26:10 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 01:26:10 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 01:26:10 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 01:26:10 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 01:26:10 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 01:26:10 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 01:26:10 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 01:26:10 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 01:26:10 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 01:26:10 @monitor.py:363][0m lr: 7.276e-15
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 01:26:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 01:26:10 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0418 01:26:10 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 01:26:10 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0418 01:26:10 @monitor.py:363][0m validation_cost: 18.675
[32m[0418 01:26:10 @monitor.py:363][0m wd_cost: 1.095e-25
[32m[0418 01:26:10 @group.py:42][0m Callbacks took 119.275 sec in total. InferenceRunner: 119.123sec
[32m[0418 01:26:10 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14244/173481[03:00<33:32,79.13it/s]  9%|8         |14975/173481[03:10<33:23,79.13it/s] 16%|#5        |27442/173481[06:00<31:58,76.12it/s] 16%|#6        |28200/173481[06:10<31:48,76.12it/s] 24%|##3       |40952/173481[09:00<29:13,75.58it/s] 24%|##4       |41724/173481[09:10<29:03,75.58it/s] 31%|###1      |54366/173481[12:00<26:27,75.05it/s] 32%|###1      |55158/173481[12:10<26:16,75.05it/s] 39%|###9      |67849/173481[15:00<23:29,74.97it/s] 40%|###9      |68685/173481[15:10<23:17,74.97it/s] 47%|####7     |81704/173481[18:00<20:08,75.96it/s] 48%|####7     |82526/173481[18:10<19:57,75.96it/s] 55%|#####4    |95275/173481[21:00<17:13,75.67it/s] 55%|#####5    |96113/173481[21:11<17:02,75.67it/s] 62%|######2   |108079/173481[24:00<14:51,73.33it/s] 63%|######2   |108853/173481[24:11<14:41,73.33it/s] 70%|######9   |120921/173481[27:00<12:06,72.32it/s] 70%|#######   |121736/173481[27:11<11:55,72.32it/s] 77%|#######7  |133771/173481[30:00<09:12,71.85it/s] 78%|#######7  |134617/173481[30:11<09:00,71.85it/s] 85%|########4 |147159/173481[33:00<06:00,73.09it/s] 85%|########5 |148024/173481[33:11<05:48,73.09it/s] 93%|#########2|160889/173481[36:00<02:48,74.65it/s] 93%|#########3|161796/173481[36:11<02:36,74.65it/s]100%|##########|173481/173481[38:43<00:00,74.66it/s]
[32m[0418 02:04:54 @base.py:257][0m Epoch 15 (global_step 18042024) finished, time:2323.61 sec.
[32m[0418 02:04:54 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-18042024.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.21it/s]
14
[32m[0418 02:06:51 @monitor.py:363][0m QueueInput/queue_size: 0.61383
[32m[0418 02:06:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0418 02:06:51 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0418 02:06:51 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0418 02:06:51 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 02:06:51 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 02:06:51 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 02:06:51 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 02:06:51 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 02:06:51 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 02:06:51 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 02:06:51 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 02:06:51 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 02:06:51 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 02:06:51 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 02:06:51 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 02:06:51 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 02:06:51 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 02:06:51 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 02:06:51 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 02:06:51 @monitor.py:363][0m lr: 3.638e-15
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 02:06:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 02:06:51 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0418 02:06:51 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0418 02:06:51 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0418 02:06:51 @monitor.py:363][0m validation_cost: 18.837
[32m[0418 02:06:51 @monitor.py:363][0m wd_cost: 1.095e-25
[32m[0418 02:06:51 @group.py:42][0m Callbacks took 117.081 sec in total. InferenceRunner: 116.770sec
[32m[0418 02:06:51 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14124/173481[03:00<33:50,78.47it/s]  9%|8         |14895/173481[03:10<33:41,78.47it/s] 16%|#5        |27290/173481[06:00<32:10,75.71it/s] 16%|#6        |28066/173481[06:10<32:00,75.71it/s] 24%|##3       |41036/173481[09:00<29:01,76.04it/s] 24%|##4       |41802/173481[09:10<28:51,76.04it/s] 32%|###1      |54731/173481[12:00<26:01,76.06it/s] 32%|###2      |55571/173481[12:10<25:50,76.06it/s] 40%|###9      |68882/173481[15:00<22:32,77.32it/s] 40%|####      |69742/173481[15:10<22:21,77.32it/s] 48%|####7     |82867/173481[18:00<19:29,77.50it/s] 48%|####8     |83701/173481[18:11<19:18,77.50it/s] 56%|#####5    |96835/173481[21:00<16:28,77.55it/s] 56%|#####6    |97713/173481[21:11<16:16,77.55it/s] 64%|######3   |111002/173481[24:00<13:19,78.12it/s] 64%|######4   |111879/173481[24:11<13:08,78.12it/s] 72%|#######1  |124491/173481[27:00<10:40,76.50it/s] 72%|#######2  |125278/173481[27:11<10:30,76.50it/s] 79%|#######9  |137554/173481[30:00<08:02,74.48it/s] 80%|#######9  |138442/173481[30:11<07:50,74.48it/s] 88%|########7 |152441/173481[33:00<04:28,78.38it/s] 89%|########8 |153535/173481[33:11<04:14,78.38it/s] 97%|#########7|169032/173481[36:00<00:52,84.72it/s] 98%|#########8|170019/173481[36:12<00:40,84.72it/s]100%|##########|173481/173481[36:54<00:00,78.34it/s]
[32m[0418 02:43:45 @base.py:257][0m Epoch 16 (global_step 18215505) finished, time:2214.38 sec.
[32m[0418 02:43:46 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-18215505.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.03it/s]
15
[32m[0418 02:45:41 @monitor.py:363][0m QueueInput/queue_size: 0.68428
[32m[0418 02:45:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0418 02:45:41 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0418 02:45:41 @monitor.py:363][0m cross_entropy_loss: 18.71
[32m[0418 02:45:41 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 02:45:41 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 02:45:41 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 02:45:41 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 02:45:41 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 02:45:41 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 02:45:41 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 02:45:41 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 02:45:41 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 02:45:41 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 02:45:41 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 02:45:41 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 02:45:41 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 02:45:41 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 02:45:41 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 02:45:41 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 02:45:41 @monitor.py:363][0m lr: 3.638e-15
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 02:45:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 02:45:41 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0418 02:45:41 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0418 02:45:41 @monitor.py:363][0m val-utt-error: 0.97551
[32m[0418 02:45:41 @monitor.py:363][0m validation_cost: 19.032
[32m[0418 02:45:41 @monitor.py:363][0m wd_cost: 1.095e-25
[32m[0418 02:45:41 @group.py:42][0m Callbacks took 115.660 sec in total. InferenceRunner: 115.468sec
[32m[0418 02:45:41 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14667/173481[03:00<32:29,81.48it/s]  9%|8         |15444/173481[03:10<32:19,81.48it/s] 17%|#6        |28870/173481[06:00<30:03,80.17it/s] 17%|#7        |29658/173481[06:10<29:53,80.17it/s] 26%|##5       |44269/173481[09:00<26:01,82.77it/s] 26%|##6       |45339/173481[09:10<25:48,82.77it/s] 36%|###6      |62569/173481[12:00<20:15,91.25it/s] 37%|###6      |63396/173481[12:10<20:06,91.25it/s] 44%|####4     |76964/173481[15:00<18:52,85.24it/s] 45%|####4     |77832/173481[15:10<18:42,85.24it/s] 53%|#####2    |91432/173481[18:00<16:31,82.73it/s] 53%|#####3    |92251/173481[18:10<16:21,82.73it/s] 61%|######    |105348/173481[21:00<14:12,79.93it/s] 61%|######1   |106209/173481[21:11<14:01,79.93it/s] 69%|######8   |119333/173481[24:00<11:27,78.80it/s] 69%|######9   |120347/173481[24:11<11:14,78.80it/s] 78%|#######7  |135085/173481[27:00<07:43,82.92it/s] 78%|#######8  |136067/173481[27:11<07:31,82.92it/s] 87%|########6 |150288/173481[30:00<04:37,83.68it/s] 87%|########7 |151108/173481[30:11<04:27,83.68it/s] 95%|#########4|164338/173481[33:00<01:53,80.77it/s] 95%|#########5|165379/173481[33:11<01:40,80.77it/s]100%|##########|173481/173481[34:39<00:00,83.41it/s]
[32m[0418 03:20:21 @base.py:257][0m Epoch 17 (global_step 18388986) finished, time:2079.75 sec.
[32m[0418 03:20:21 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-18388986.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.57it/s]
16
[32m[0418 03:22:14 @monitor.py:363][0m QueueInput/queue_size: 1.9032
[32m[0418 03:22:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0418 03:22:14 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0418 03:22:14 @monitor.py:363][0m cross_entropy_loss: 18.84
[32m[0418 03:22:14 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 03:22:14 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 03:22:14 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 03:22:14 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 03:22:14 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 03:22:14 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 03:22:14 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 03:22:14 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 03:22:14 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 03:22:14 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 03:22:14 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 03:22:14 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 03:22:14 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 03:22:14 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 03:22:14 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 03:22:14 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 03:22:14 @monitor.py:363][0m lr: 3.638e-15
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 03:22:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 03:22:14 @monitor.py:363][0m train-error-top1: 0.98763
[32m[0418 03:22:14 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 03:22:14 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0418 03:22:14 @monitor.py:363][0m validation_cost: 18.777
[32m[0418 03:22:14 @monitor.py:363][0m wd_cost: 2.1901e-26
[32m[0418 03:22:14 @group.py:42][0m Callbacks took 113.194 sec in total. InferenceRunner: 113.018sec
[32m[0418 03:22:14 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15135/173481[03:00<31:23,84.08it/s]  9%|9         |15939/173481[03:10<31:13,84.08it/s] 17%|#7        |29596/173481[06:00<29:11,82.16it/s] 18%|#7        |30440/173481[06:10<29:00,82.16it/s] 25%|##5       |43937/173481[09:00<26:41,80.90it/s] 26%|##5       |44787/173481[09:10<26:30,80.90it/s] 34%|###3      |58456/173481[12:00<23:44,80.77it/s] 34%|###4      |59309/173481[12:10<23:33,80.77it/s] 42%|####2     |73026/173481[15:00<20:42,80.86it/s] 43%|####2     |73887/173481[15:10<20:31,80.86it/s] 50%|#####     |87356/173481[18:00<17:53,80.23it/s] 51%|#####     |88251/173481[18:11<17:42,80.23it/s] 58%|#####8    |101316/173481[21:00<15:15,78.87it/s] 59%|#####8    |102225/173481[21:11<15:03,78.87it/s] 66%|######6   |115169/173481[24:00<12:28,77.90it/s] 67%|######6   |116007/173481[24:11<12:17,77.90it/s] 75%|#######4  |129442/173481[27:00<09:20,78.58it/s] 75%|#######5  |130378/173481[27:11<09:08,78.58it/s] 83%|########2 |143965/173481[30:00<06:10,79.62it/s] 84%|########3 |144935/173481[30:11<05:58,79.62it/s] 92%|#########1|158790/173481[33:00<03:01,80.97it/s] 92%|#########2|159744/173481[33:11<02:49,80.97it/s]100%|#########9|173411/173481[36:00<00:00,81.09it/s]100%|##########|173481/173481[36:01<00:00,80.27it/s]
[32m[0418 03:58:15 @base.py:257][0m Epoch 18 (global_step 18562467) finished, time:2161.31 sec.
[32m[0418 03:58:16 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-18562467.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.30it/s]
17
[32m[0418 04:00:15 @monitor.py:363][0m QueueInput/queue_size: 0.58697
[32m[0418 04:00:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0418 04:00:15 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0418 04:00:15 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0418 04:00:15 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 04:00:15 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 04:00:15 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 04:00:15 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 04:00:15 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 04:00:15 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 04:00:15 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 04:00:15 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 04:00:15 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 04:00:15 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 04:00:15 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 04:00:15 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 04:00:15 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 04:00:15 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 04:00:15 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 04:00:15 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 04:00:15 @monitor.py:363][0m lr: 1.819e-15
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 04:00:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 04:00:15 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0418 04:00:15 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 04:00:15 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0418 04:00:15 @monitor.py:363][0m validation_cost: 18.665
[32m[0418 04:00:15 @monitor.py:363][0m wd_cost: 2.1901e-26
[32m[0418 04:00:15 @group.py:42][0m Callbacks took 119.148 sec in total. InferenceRunner: 118.915sec
[32m[0418 04:00:15 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14571/173481[03:00<32:43,80.95it/s]  9%|8         |15396/173481[03:10<32:32,80.95it/s] 17%|#6        |29081/173481[06:00<29:47,80.78it/s] 17%|#7        |29899/173481[06:10<29:37,80.78it/s] 25%|##4       |42973/173481[09:00<27:33,78.93it/s] 25%|##5       |43749/173481[09:10<27:23,78.93it/s] 33%|###2      |56545/173481[12:00<25:16,77.11it/s] 33%|###3      |57354/173481[12:10<25:05,77.11it/s] 40%|####      |69986/173481[15:00<22:44,75.87it/s] 41%|####      |70848/173481[15:10<22:32,75.87it/s] 48%|####8     |83822/173481[18:00<19:34,76.36it/s] 49%|####8     |84624/173481[18:10<19:23,76.36it/s] 56%|#####5    |97013/173481[21:00<17:02,74.79it/s] 56%|#####6    |97854/173481[21:11<16:51,74.79it/s] 63%|######3   |110131/173481[24:00<14:18,73.82it/s] 64%|######3   |110976/173481[24:11<14:06,73.82it/s] 71%|#######1  |123542/173481[27:00<11:13,74.16it/s] 72%|#######1  |124374/173481[27:11<11:02,74.16it/s] 79%|#######8  |136694/173481[30:00<08:19,73.61it/s] 79%|#######9  |137557/173481[30:11<08:08,73.61it/s] 86%|########6 |149977/173481[33:00<05:18,73.70it/s] 87%|########6 |150759/173481[33:11<05:08,73.70it/s] 94%|#########4|163354/173481[36:00<02:16,74.00it/s] 95%|#########4|164269/173481[36:12<02:04,74.00it/s]100%|##########|173481/173481[38:14<00:00,75.62it/s]
[32m[0418 04:38:29 @base.py:257][0m Epoch 19 (global_step 18735948) finished, time:2294.09 sec.
[32m[0418 04:38:29 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-18735948.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.50it/s]
18
[32m[0418 04:40:23 @monitor.py:363][0m QueueInput/queue_size: 0.45804
[32m[0418 04:40:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0418 04:40:23 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0418 04:40:23 @monitor.py:363][0m cross_entropy_loss: 18.463
[32m[0418 04:40:23 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 04:40:23 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 04:40:23 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 04:40:23 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 04:40:23 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 04:40:23 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 04:40:23 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 04:40:23 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 04:40:23 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 04:40:23 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 04:40:23 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 04:40:23 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 04:40:23 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 04:40:23 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 04:40:23 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 04:40:23 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 04:40:23 @monitor.py:363][0m lr: 1.819e-15
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 04:40:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 04:40:23 @monitor.py:363][0m train-error-top1: 0.98367
[32m[0418 04:40:23 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 04:40:23 @monitor.py:363][0m val-utt-error: 0.97359
[32m[0418 04:40:23 @monitor.py:363][0m validation_cost: 18.76
[32m[0418 04:40:23 @monitor.py:363][0m wd_cost: 4.3802e-27
[32m[0418 04:40:23 @group.py:42][0m Callbacks took 113.877 sec in total. InferenceRunner: 113.745sec
[32m[0418 04:40:23 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13664/173481[03:00<35:05,75.91it/s]  8%|8         |14442/173481[03:10<34:55,75.91it/s] 16%|#5        |27177/173481[06:00<32:18,75.49it/s] 16%|#6        |27988/173481[06:10<32:07,75.49it/s] 23%|##3       |40593/173481[09:00<29:31,75.01it/s] 24%|##3       |41382/173481[09:10<29:21,75.01it/s] 31%|###1      |54153/173481[12:00<26:27,75.17it/s] 32%|###1      |54975/173481[12:10<26:16,75.17it/s] 39%|###8      |67624/173481[15:00<23:31,75.00it/s] 39%|###9      |68424/173481[15:10<23:20,75.00it/s] 46%|####6     |80185/173481[18:00<21:30,72.30it/s] 47%|####6     |80925/173481[18:11<21:20,72.30it/s] 53%|#####3    |92623/173481[21:00<19:04,70.66it/s] 54%|#####3    |93410/173481[21:11<18:53,70.66it/s] 61%|######1   |105976/173481[24:00<15:32,72.38it/s] 62%|######1   |106875/173481[24:11<15:20,72.38it/s] 69%|######8   |119555/173481[27:00<12:09,73.87it/s] 69%|######9   |120435/173481[27:11<11:58,73.87it/s] 77%|#######6  |133406/173481[30:00<08:51,75.38it/s] 77%|#######7  |134274/173481[30:11<08:40,75.38it/s] 85%|########4 |146970/173481[33:00<05:51,75.37it/s] 85%|########5 |147906/173481[33:11<05:39,75.37it/s] 93%|#########2|160859/173481[36:00<02:45,76.25it/s] 93%|#########3|161804/173481[36:12<02:33,76.25it/s]100%|##########|173481/173481[38:38<00:00,74.81it/s]
[32m[0418 05:19:02 @base.py:257][0m Epoch 20 (global_step 18909429) finished, time:2318.94 sec.
[32m[0418 05:19:02 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-18909429.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.95it/s]
19
[32m[0418 05:20:59 @monitor.py:363][0m QueueInput/queue_size: 0.78659
[32m[0418 05:20:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0418 05:20:59 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0418 05:20:59 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0418 05:20:59 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 05:20:59 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 05:20:59 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 05:20:59 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 05:20:59 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 05:20:59 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 05:20:59 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 05:20:59 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 05:20:59 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 05:20:59 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 05:20:59 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 05:20:59 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 05:20:59 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 05:20:59 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 05:20:59 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 05:20:59 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 05:20:59 @monitor.py:363][0m lr: 9.0949e-16
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 05:20:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 05:20:59 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0418 05:20:59 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 05:20:59 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0418 05:20:59 @monitor.py:363][0m validation_cost: 18.675
[32m[0418 05:20:59 @monitor.py:363][0m wd_cost: 4.3802e-27
[32m[0418 05:20:59 @group.py:42][0m Callbacks took 117.855 sec in total. InferenceRunner: 117.694sec
[32m[0418 05:20:59 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14629/173481[03:00<32:34,81.26it/s]  9%|8         |15378/173481[03:10<32:25,81.26it/s] 16%|#6        |28265/173481[06:00<30:51,78.41it/s] 17%|#6        |29082/173481[06:10<30:41,78.41it/s] 24%|##4       |42211/173481[09:00<28:04,77.93it/s] 25%|##4       |43032/173481[09:10<27:53,77.93it/s] 32%|###2      |56035/173481[12:00<25:18,77.36it/s] 33%|###2      |56832/173481[12:10<25:07,77.36it/s] 40%|####      |69553/173481[15:00<22:43,76.21it/s] 41%|####      |70274/173481[15:10<22:34,76.21it/s] 48%|####8     |83462/173481[18:00<19:33,76.74it/s] 49%|####8     |84379/173481[18:11<19:21,76.74it/s] 57%|#####6    |98773/173481[21:00<15:26,80.68it/s] 57%|#####7    |99546/173481[21:11<15:16,80.68it/s] 64%|######4   |111722/173481[24:00<13:32,76.05it/s] 65%|######4   |112578/173481[24:11<13:20,76.05it/s] 72%|#######2  |125383/173481[27:00<10:33,75.97it/s] 73%|#######2  |126372/173481[27:11<10:20,75.97it/s] 80%|########  |139189/173481[30:00<07:29,76.33it/s] 81%|########  |140094/173481[30:11<07:17,76.33it/s] 89%|########8 |153619/173481[33:00<04:14,78.20it/s] 89%|########9 |154575/173481[33:11<04:01,78.20it/s] 97%|#########6|168099/173481[36:00<01:07,79.30it/s] 97%|#########7|169037/173481[36:12<00:56,79.30it/s]100%|##########|173481/173481[37:06<00:00,77.90it/s]
[32m[0418 05:58:06 @base.py:257][0m Epoch 21 (global_step 19082910) finished, time:2226.90 sec.
[32m[0418 05:58:07 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-19082910.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.89it/s]
20
[32m[0418 06:00:04 @monitor.py:363][0m QueueInput/queue_size: 0.1828
[32m[0418 06:00:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0418 06:00:04 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0418 06:00:04 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0418 06:00:04 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 06:00:04 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 06:00:04 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 06:00:04 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 06:00:04 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 06:00:04 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 06:00:04 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 06:00:04 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 06:00:04 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 06:00:04 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 06:00:04 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 06:00:04 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 06:00:04 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 06:00:04 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 06:00:04 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 06:00:04 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 06:00:04 @monitor.py:363][0m lr: 9.0949e-16
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 06:00:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 06:00:04 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0418 06:00:04 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0418 06:00:04 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0418 06:00:04 @monitor.py:363][0m validation_cost: 18.837
[32m[0418 06:00:04 @monitor.py:363][0m wd_cost: 4.3802e-27
[32m[0418 06:00:04 @group.py:42][0m Callbacks took 117.951 sec in total. InferenceRunner: 117.733sec
[32m[0418 06:00:04 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14995/173481[03:00<31:42,83.30it/s]  9%|9         |15802/173481[03:10<31:32,83.30it/s] 17%|#7        |29862/173481[06:00<28:51,82.95it/s] 18%|#7        |30750/173481[06:10<28:40,82.95it/s] 26%|##5       |44628/173481[09:00<26:02,82.49it/s] 26%|##6       |45496/173481[09:10<25:51,82.49it/s] 34%|###4      |59648/173481[12:00<22:52,82.96it/s] 35%|###4      |60545/173481[12:10<22:41,82.96it/s] 43%|####3     |74675/173481[15:00<19:47,83.22it/s] 44%|####3     |75581/173481[15:10<19:36,83.22it/s] 52%|#####1    |89373/173481[18:00<17:00,82.43it/s] 52%|#####2    |90277/173481[18:10<16:49,82.43it/s] 60%|######    |104453/173481[21:00<13:50,83.10it/s] 61%|######    |105412/173481[21:11<13:39,83.10it/s] 69%|######8   |119485/173481[24:00<10:48,83.30it/s] 69%|######9   |120414/173481[24:11<10:37,83.30it/s] 77%|#######7  |133983/173481[27:00<08:02,81.90it/s] 78%|#######7  |134877/173481[27:11<07:51,81.90it/s] 86%|########5 |148640/173481[30:00<05:04,81.66it/s] 86%|########6 |149838/173481[30:11<04:49,81.66it/s] 96%|#########5|166055/173481[33:00<01:23,88.57it/s] 96%|#########6|167175/173481[33:11<01:11,88.57it/s]100%|##########|173481/173481[34:23<00:00,84.08it/s]
[32m[0418 06:34:28 @base.py:257][0m Epoch 22 (global_step 19256391) finished, time:2063.25 sec.
[32m[0418 06:34:28 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-19256391.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.86it/s]
21
[32m[0418 06:36:23 @monitor.py:363][0m QueueInput/queue_size: 0.68418
[32m[0418 06:36:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0418 06:36:23 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0418 06:36:23 @monitor.py:363][0m cross_entropy_loss: 18.71
[32m[0418 06:36:23 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 06:36:23 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 06:36:23 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 06:36:23 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 06:36:23 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 06:36:23 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 06:36:23 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 06:36:23 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 06:36:23 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 06:36:23 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 06:36:23 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 06:36:23 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 06:36:23 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 06:36:23 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 06:36:23 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 06:36:23 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 06:36:23 @monitor.py:363][0m lr: 9.0949e-16
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 06:36:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 06:36:23 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0418 06:36:23 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0418 06:36:23 @monitor.py:363][0m val-utt-error: 0.97551
[32m[0418 06:36:23 @monitor.py:363][0m validation_cost: 19.032
[32m[0418 06:36:23 @monitor.py:363][0m wd_cost: 8.7603e-28
[32m[0418 06:36:23 @group.py:42][0m Callbacks took 115.067 sec in total. InferenceRunner: 114.876sec
[32m[0418 06:36:23 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15656/173481[03:00<30:14,86.98it/s] 10%|9         |16514/173481[03:10<30:04,86.98it/s] 18%|#7        |30878/173481[06:00<27:42,85.75it/s] 18%|#8        |31771/173481[06:10<27:32,85.75it/s] 28%|##7       |47805/173481[09:00<23:21,89.70it/s] 28%|##8       |48945/173481[09:10<23:08,89.70it/s] 38%|###8      |66517/173481[12:00<18:30,96.30it/s] 39%|###8      |67429/173481[12:10<18:21,96.30it/s] 47%|####6     |81450/173481[15:00<17:12,89.13it/s] 48%|####7     |82418/173481[15:10<17:01,89.13it/s] 56%|#####5    |96358/173481[18:00<14:58,85.86it/s] 56%|#####6    |97268/173481[18:10<14:47,85.86it/s] 64%|######4   |111320/173481[21:00<12:15,84.47it/s] 65%|######4   |112255/173481[21:11<12:04,84.47it/s] 73%|#######3  |127059/173481[24:00<09:00,85.92it/s] 74%|#######3  |128259/173481[24:11<08:46,85.92it/s] 83%|########3 |144543/173481[27:00<05:17,91.18it/s] 84%|########3 |145577/173481[27:11<05:06,91.18it/s] 92%|#########2|159913/173481[30:00<02:33,88.19it/s] 93%|#########2|160883/173481[30:11<02:22,88.19it/s]100%|##########|173481/173481[32:25<00:00,89.18it/s]
[32m[0418 07:08:48 @base.py:257][0m Epoch 23 (global_step 19429872) finished, time:1945.39 sec.
[32m[0418 07:08:48 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-19429872.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.72it/s]
22
[32m[0418 07:10:42 @monitor.py:363][0m QueueInput/queue_size: 5.257
[32m[0418 07:10:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0418 07:10:42 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0418 07:10:42 @monitor.py:363][0m cross_entropy_loss: 18.838
[32m[0418 07:10:42 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 07:10:42 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 07:10:42 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 07:10:42 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 07:10:42 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 07:10:42 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 07:10:42 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 07:10:42 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 07:10:42 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 07:10:42 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 07:10:42 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 07:10:42 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 07:10:42 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 07:10:42 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 07:10:42 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 07:10:42 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 07:10:42 @monitor.py:363][0m lr: 4.5475e-16
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 07:10:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 07:10:42 @monitor.py:363][0m train-error-top1: 0.98762
[32m[0418 07:10:42 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0418 07:10:42 @monitor.py:363][0m val-utt-error: 0.97444
[32m[0418 07:10:42 @monitor.py:363][0m validation_cost: 18.777
[32m[0418 07:10:42 @monitor.py:363][0m wd_cost: 8.7603e-28
[32m[0418 07:10:42 @group.py:42][0m Callbacks took 113.773 sec in total. InferenceRunner: 113.592sec
[32m[0418 07:10:42 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15906/173481[03:00<29:43,88.36it/s] 10%|9         |16769/173481[03:10<29:33,88.36it/s] 18%|#8        |31554/173481[06:00<26:59,87.64it/s] 19%|#8        |32450/173481[06:10<26:49,87.64it/s] 28%|##7       |47802/173481[09:00<23:33,88.93it/s] 28%|##8       |48816/173481[09:10<23:21,88.93it/s] 38%|###8      |66072/173481[12:00<18:52,94.80it/s] 39%|###8      |67194/173481[12:10<18:41,94.80it/s] 49%|####8     |84829/173481[15:00<14:52,99.28it/s] 50%|####9     |86009/173481[15:10<14:41,99.28it/s] 60%|######    |104355/173481[18:00<11:06,103.67it/s] 61%|######    |105658/173481[18:11<10:54,103.67it/s] 72%|#######1  |124669/173481[21:00<07:31,108.07it/s] 73%|#######2  |126085/173481[21:11<07:18,108.07it/s] 85%|########4 |147056/173481[24:00<03:48,115.65it/s] 86%|########5 |148486/173481[24:11<03:36,115.65it/s] 97%|#########6|167549/173481[27:00<00:51,114.74it/s] 97%|#########7|168538/173481[27:11<00:43,114.74it/s]100%|##########|173481/173481[28:11<00:00,102.56it/s]
[32m[0418 07:38:53 @base.py:257][0m Epoch 24 (global_step 19603353) finished, time:1691.47 sec.
[32m[0418 07:38:53 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-19603353.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.07it/s]
23
[32m[0418 07:40:51 @monitor.py:363][0m QueueInput/queue_size: 0.7356
[32m[0418 07:40:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0418 07:40:51 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0418 07:40:51 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0418 07:40:51 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 07:40:51 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 07:40:51 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 07:40:51 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 07:40:51 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 07:40:51 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 07:40:51 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 07:40:51 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 07:40:51 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 07:40:51 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 07:40:51 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 07:40:51 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 07:40:51 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 07:40:51 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 07:40:51 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 07:40:51 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 07:40:51 @monitor.py:363][0m lr: 4.5475e-16
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 07:40:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 07:40:51 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0418 07:40:51 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 07:40:51 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0418 07:40:51 @monitor.py:363][0m validation_cost: 18.665
[32m[0418 07:40:51 @monitor.py:363][0m wd_cost: 8.7603e-28
[32m[0418 07:40:51 @group.py:42][0m Callbacks took 117.748 sec in total. InferenceRunner: 117.603sec
[32m[0418 07:40:51 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15745/173481[03:00<30:03,87.46it/s] 10%|9         |16587/173481[03:10<29:53,87.46it/s] 18%|#7        |31061/173481[06:00<27:31,86.26it/s] 18%|#8        |31904/173481[06:10<27:21,86.26it/s] 26%|##6       |45615/173481[09:00<25:31,83.47it/s] 27%|##6       |46446/173481[09:10<25:21,83.47it/s] 35%|###4      |60109/173481[12:00<23:03,81.96it/s] 35%|###5      |60948/173481[12:10<22:52,81.96it/s] 43%|####3     |74885/173481[15:00<20:02,82.03it/s] 44%|####3     |75806/173481[15:10<19:50,82.03it/s] 53%|#####3    |92181/173481[18:00<15:18,88.50it/s] 54%|#####3    |93216/173481[18:11<15:06,88.50it/s] 63%|######3   |109860/173481[21:00<11:23,93.10it/s] 64%|######3   |110982/173481[21:11<11:11,93.10it/s] 75%|#######5  |130514/173481[24:00<06:57,102.79it/s] 76%|#######5  |131822/173481[24:11<06:45,102.79it/s] 86%|########5 |149125/173481[27:00<03:56,103.09it/s] 87%|########6 |150270/173481[27:11<03:45,103.09it/s] 98%|#########7|169977/173481[30:00<00:32,109.09it/s] 99%|#########8|171375/173481[30:11<00:19,109.09it/s]100%|##########|173481/173481[30:28<00:00,94.87it/s] 
[32m[0418 08:11:20 @base.py:257][0m Epoch 25 (global_step 19776834) finished, time:1828.70 sec.
[32m[0418 08:11:20 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-19776834.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.12it/s]
24
[32m[0418 08:13:17 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0418 08:13:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.546
[32m[0418 08:13:17 @monitor.py:363][0m activation-summaries/output-rms: 0.049405
[32m[0418 08:13:17 @monitor.py:363][0m cross_entropy_loss: 18.426
[32m[0418 08:13:17 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 08:13:17 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 08:13:17 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 08:13:17 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 08:13:17 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 08:13:17 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 08:13:17 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 08:13:17 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 08:13:17 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 08:13:17 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 08:13:17 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 08:13:17 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 08:13:17 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 08:13:17 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 08:13:17 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 08:13:17 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 08:13:17 @monitor.py:363][0m lr: 4.5475e-16
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 08:13:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 08:13:17 @monitor.py:363][0m train-error-top1: 0.98464
[32m[0418 08:13:17 @monitor.py:363][0m val-error-top1: 0.98541
[32m[0418 08:13:17 @monitor.py:363][0m val-utt-error: 0.9737
[32m[0418 08:13:17 @monitor.py:363][0m validation_cost: 18.827
[32m[0418 08:13:17 @monitor.py:363][0m wd_cost: 1.7521e-28
[32m[0418 08:13:17 @group.py:42][0m Callbacks took 117.720 sec in total. InferenceRunner: 117.569sec
[32m[0418 08:13:17 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s] 13%|#2        |21724/173481[03:00<20:57,120.69it/s] 13%|#3        |22991/173481[03:10<20:46,120.69it/s] 24%|##3       |41257/173481[06:00<19:17,114.28it/s] 24%|##4       |42087/173481[06:10<19:09,114.28it/s] 32%|###2      |55714/173481[09:00<20:48,94.33it/s]  33%|###2      |56560/173481[09:10<20:39,94.33it/s] 40%|####      |69730/173481[12:00<20:16,85.30it/s] 41%|####      |70578/173481[12:10<20:06,85.30it/s] 48%|####7     |82418/173481[15:00<19:39,77.19it/s] 48%|####7     |83205/173481[15:10<19:29,77.19it/s] 55%|#####5    |95641/173481[18:00<17:14,75.28it/s] 56%|#####5    |96476/173481[18:11<17:02,75.28it/s] 63%|######3   |109984/173481[21:00<13:40,77.42it/s] 64%|######3   |110785/173481[21:11<13:29,77.42it/s] 71%|#######1  |124027/173481[24:00<10:36,77.71it/s] 72%|#######1  |124897/173481[24:11<10:25,77.71it/s] 80%|#######9  |137918/173481[27:00<07:39,77.44it/s] 80%|########  |138804/173481[27:11<07:27,77.44it/s] 87%|########7 |151702/173481[30:00<04:42,77.00it/s] 88%|########7 |152600/173481[30:11<04:31,77.00it/s] 96%|#########5|165747/173481[33:00<01:39,77.51it/s] 96%|#########6|166660/173481[33:11<01:28,77.51it/s]100%|##########|173481/173481[34:40<00:00,83.39it/s]
[32m[0418 08:47:58 @base.py:257][0m Epoch 26 (global_step 19950315) finished, time:2080.42 sec.
[32m[0418 08:47:58 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-19950315.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.71it/s]
25
[32m[0418 08:49:56 @monitor.py:363][0m QueueInput/queue_size: 1.0197
[32m[0418 08:49:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0418 08:49:56 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0418 08:49:56 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0418 08:49:56 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 08:49:56 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 08:49:56 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 08:49:56 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 08:49:56 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 08:49:56 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 08:49:56 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 08:49:56 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 08:49:56 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 08:49:56 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 08:49:56 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 08:49:56 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 08:49:56 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 08:49:56 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 08:49:56 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 08:49:56 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 08:49:56 @monitor.py:363][0m lr: 2.2737e-16
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 08:49:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 08:49:56 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0418 08:49:56 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 08:49:56 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0418 08:49:56 @monitor.py:363][0m validation_cost: 18.675
[32m[0418 08:49:56 @monitor.py:363][0m wd_cost: 1.7521e-28
[32m[0418 08:49:56 @group.py:42][0m Callbacks took 118.039 sec in total. InferenceRunner: 117.868sec
[32m[0418 08:49:56 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14757/173481[03:00<32:16,81.98it/s]  9%|8         |15516/173481[03:10<32:06,81.98it/s] 16%|#6        |28424/173481[06:00<30:39,78.84it/s] 17%|#6        |29238/173481[06:10<30:29,78.84it/s] 24%|##4       |42351/173481[09:00<27:59,78.10it/s] 25%|##4       |43200/173481[09:10<27:48,78.10it/s] 33%|###2      |56383/173481[12:00<25:00,78.02it/s] 33%|###2      |57221/173481[12:10<24:50,78.02it/s] 41%|####      |70345/173481[15:00<22:05,77.79it/s] 41%|####      |71120/173481[15:10<21:55,77.79it/s] 49%|####8     |84792/173481[18:00<18:42,79.01it/s] 49%|####9     |85663/173481[18:11<18:31,79.01it/s] 58%|#####7    |100251/173481[21:00<14:49,82.30it/s] 58%|#####8    |101025/173481[21:11<14:40,82.30it/s] 65%|######5   |113356/173481[24:00<12:58,77.26it/s] 66%|######5   |114222/173481[24:11<12:46,77.26it/s] 73%|#######3  |127361/173481[27:00<09:54,77.53it/s] 74%|#######3  |128370/173481[27:11<09:41,77.53it/s] 81%|########1 |141079/173481[30:00<07:01,76.83it/s] 82%|########1 |141946/173481[30:11<06:50,76.83it/s] 89%|########9 |155237/173481[33:00<03:54,77.73it/s] 90%|######### |156184/173481[33:11<03:42,77.73it/s] 98%|#########7|169450/173481[36:00<00:51,78.34it/s] 98%|#########8|170367/173481[36:12<00:39,78.34it/s]100%|##########|173481/173481[36:50<00:00,78.49it/s]
[32m[0418 09:26:46 @base.py:257][0m Epoch 27 (global_step 20123796) finished, time:2210.21 sec.
[32m[0418 09:26:46 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-20123796.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.84it/s]
26
[32m[0418 09:28:43 @monitor.py:363][0m QueueInput/queue_size: 0.23199
[32m[0418 09:28:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0418 09:28:43 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0418 09:28:43 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0418 09:28:43 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 09:28:43 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 09:28:43 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 09:28:43 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 09:28:43 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 09:28:43 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 09:28:43 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 09:28:43 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 09:28:43 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 09:28:43 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 09:28:43 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 09:28:43 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 09:28:43 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 09:28:43 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 09:28:43 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 09:28:43 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 09:28:43 @monitor.py:363][0m lr: 2.2737e-16
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 09:28:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 09:28:43 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0418 09:28:43 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0418 09:28:43 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0418 09:28:43 @monitor.py:363][0m validation_cost: 18.837
[32m[0418 09:28:43 @monitor.py:363][0m wd_cost: 1.7521e-28
[32m[0418 09:28:43 @group.py:42][0m Callbacks took 117.254 sec in total. InferenceRunner: 117.044sec
[32m[0418 09:28:43 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14895/173481[03:00<31:56,82.75it/s]  9%|9         |15708/173481[03:10<31:46,82.75it/s] 17%|#7        |29850/173481[06:00<28:52,82.91it/s] 18%|#7        |30744/173481[06:10<28:41,82.91it/s] 26%|##5       |44680/173481[09:00<25:58,82.65it/s] 26%|##6       |45570/173481[09:10<25:47,82.65it/s] 34%|###4      |59438/173481[12:00<23:05,82.31it/s] 35%|###4      |60308/173481[12:10<22:54,82.31it/s] 43%|####3     |74662/173481[15:00<19:44,83.43it/s] 44%|####3     |75573/173481[15:10<19:33,83.43it/s] 52%|#####1    |89687/173481[18:00<16:44,83.45it/s] 52%|#####2    |90579/173481[18:11<16:33,83.45it/s] 60%|######    |104749/173481[21:00<13:42,83.56it/s] 61%|######    |105679/173481[21:11<13:31,83.56it/s] 69%|######8   |119593/173481[24:00<10:49,83.01it/s] 69%|######9   |120524/173481[24:11<10:37,83.01it/s] 77%|#######6  |133395/173481[27:00<08:22,79.71it/s] 77%|#######7  |134248/173481[27:11<08:12,79.71it/s] 85%|########5 |147948/173481[30:00<05:18,80.27it/s] 86%|########5 |149080/173481[30:11<05:03,80.27it/s] 96%|#########5|165891/173481[33:00<01:25,88.93it/s] 96%|#########6|166884/173481[33:11<01:14,88.93it/s]100%|##########|173481/173481[34:24<00:00,84.05it/s]
[32m[0418 10:03:07 @base.py:257][0m Epoch 28 (global_step 20297277) finished, time:2064.01 sec.
[32m[0418 10:03:08 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-20297277.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.96it/s]
27
[32m[0418 10:05:02 @monitor.py:363][0m QueueInput/queue_size: 0.84747
[32m[0418 10:05:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0418 10:05:02 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0418 10:05:02 @monitor.py:363][0m cross_entropy_loss: 18.708
[32m[0418 10:05:02 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 10:05:02 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 10:05:02 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 10:05:02 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 10:05:02 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 10:05:02 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 10:05:02 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 10:05:02 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 10:05:02 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 10:05:02 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 10:05:02 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 10:05:02 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 10:05:02 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 10:05:02 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 10:05:02 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 10:05:02 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 10:05:02 @monitor.py:363][0m lr: 2.2737e-16
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 10:05:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 10:05:02 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0418 10:05:02 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0418 10:05:02 @monitor.py:363][0m val-utt-error: 0.97556
[32m[0418 10:05:02 @monitor.py:363][0m validation_cost: 19.031
[32m[0418 10:05:02 @monitor.py:363][0m wd_cost: 3.5041e-29
[32m[0418 10:05:02 @group.py:42][0m Callbacks took 115.006 sec in total. InferenceRunner: 114.812sec
[32m[0418 10:05:02 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15699/173481[03:00<30:09,87.21it/s] 10%|9         |16536/173481[03:10<29:59,87.21it/s] 18%|#7        |30798/173481[06:00<27:48,85.51it/s] 18%|#8        |31683/173481[06:10<27:38,85.51it/s] 27%|##7       |47355/173481[09:00<23:43,88.63it/s] 28%|##7       |48564/173481[09:10<23:29,88.63it/s] 38%|###8      |66226/173481[12:00<18:36,96.05it/s] 39%|###8      |67163/173481[12:10<18:26,96.05it/s] 47%|####6     |81153/173481[15:00<17:17,89.01it/s] 47%|####7     |82096/173481[15:10<17:06,89.01it/s] 55%|#####5    |95872/173481[18:00<15:10,85.24it/s] 56%|#####5    |96823/173481[18:10<14:59,85.24it/s] 64%|######3   |110983/173481[21:00<12:18,84.59it/s] 64%|######4   |111862/173481[21:11<12:08,84.59it/s] 73%|#######2  |126520/173481[24:00<09:09,85.44it/s] 74%|#######3  |127684/173481[24:11<08:56,85.44it/s] 83%|########2 |143578/173481[27:00<05:32,89.86it/s] 83%|########3 |144521/173481[27:11<05:22,89.86it/s] 91%|#########1|158538/173481[30:00<02:53,86.35it/s] 92%|#########1|159514/173481[30:11<02:41,86.35it/s]100%|##########|173481/173481[32:42<00:00,88.40it/s]
[32m[0418 10:37:45 @base.py:257][0m Epoch 29 (global_step 20470758) finished, time:1962.39 sec.
[32m[0418 10:37:45 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-20470758.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.51it/s]
28
[32m[0418 10:39:39 @monitor.py:363][0m QueueInput/queue_size: 0.41969
[32m[0418 10:39:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.177
[32m[0418 10:39:39 @monitor.py:363][0m activation-summaries/output-rms: 0.050108
[32m[0418 10:39:39 @monitor.py:363][0m cross_entropy_loss: 18.843
[32m[0418 10:39:39 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 10:39:39 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 10:39:39 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 10:39:39 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 10:39:39 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 10:39:39 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 10:39:39 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 10:39:39 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 10:39:39 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 10:39:39 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 10:39:39 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 10:39:39 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 10:39:39 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 10:39:39 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 10:39:39 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 10:39:39 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 10:39:39 @monitor.py:363][0m lr: 1.1369e-16
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 10:39:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 10:39:39 @monitor.py:363][0m train-error-top1: 0.98803
[32m[0418 10:39:39 @monitor.py:363][0m val-error-top1: 0.9854
[32m[0418 10:39:39 @monitor.py:363][0m val-utt-error: 0.97402
[32m[0418 10:39:39 @monitor.py:363][0m validation_cost: 18.719
[32m[0418 10:39:39 @monitor.py:363][0m wd_cost: 3.5041e-29
[32m[0418 10:39:39 @group.py:42][0m Callbacks took 113.899 sec in total. InferenceRunner: 113.736sec
[32m[0418 10:39:39 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15736/173481[03:00<30:04,87.41it/s] 10%|9         |16622/173481[03:10<29:54,87.41it/s] 18%|#8        |31266/173481[06:00<27:17,86.84it/s] 19%|#8        |32155/173481[06:10<27:07,86.84it/s] 27%|##6       |46059/173481[09:00<25:08,84.45it/s] 27%|##7       |46871/173481[09:10<24:59,84.45it/s] 35%|###5      |61046/173481[12:00<22:20,83.85it/s] 36%|###5      |62010/173481[12:10<22:09,83.85it/s] 44%|####3     |75742/173481[15:00<19:41,82.73it/s] 44%|####4     |76587/173481[15:10<19:31,82.73it/s] 52%|#####1    |89755/173481[18:00<17:23,80.22it/s] 52%|#####2    |90627/173481[18:10<17:12,80.22it/s] 60%|#####9    |103922/173481[21:00<14:35,79.45it/s] 60%|######    |104784/173481[21:11<14:24,79.45it/s] 68%|######8   |118341/173481[24:00<11:31,79.78it/s] 69%|######8   |119267/173481[24:11<11:19,79.78it/s] 77%|#######6  |133387/173481[27:00<08:11,81.64it/s] 77%|#######7  |134378/173481[27:11<07:58,81.64it/s] 86%|########5 |148838/173481[30:00<04:54,83.69it/s] 86%|########6 |149854/173481[30:11<04:42,83.69it/s] 94%|#########4|163588/173481[33:00<01:59,82.80it/s] 95%|#########4|164535/173481[33:11<01:48,82.80it/s]100%|##########|173481/173481[35:01<00:00,82.57it/s]
[32m[0418 11:14:40 @base.py:257][0m Epoch 30 (global_step 20644239) finished, time:2101.08 sec.
[32m[0418 11:14:40 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-20644239.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.26it/s]
29
[32m[0418 11:16:37 @monitor.py:363][0m QueueInput/queue_size: 0.88004
[32m[0418 11:16:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0418 11:16:37 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0418 11:16:37 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0418 11:16:37 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 11:16:37 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 11:16:37 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 11:16:37 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 11:16:37 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 11:16:37 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 11:16:37 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 11:16:37 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 11:16:37 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 11:16:37 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 11:16:37 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 11:16:37 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 11:16:37 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 11:16:37 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 11:16:37 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 11:16:37 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 11:16:37 @monitor.py:363][0m lr: 1.1369e-16
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 11:16:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 11:16:37 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0418 11:16:37 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 11:16:37 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0418 11:16:37 @monitor.py:363][0m validation_cost: 18.665
[32m[0418 11:16:37 @monitor.py:363][0m wd_cost: 7.0083e-30
[32m[0418 11:16:37 @group.py:42][0m Callbacks took 117.592 sec in total. InferenceRunner: 117.457sec
[32m[0418 11:16:37 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13701/173481[03:00<34:59,76.11it/s]  8%|8         |14424/173481[03:10<34:49,76.11it/s] 15%|#5        |26330/173481[06:00<33:35,73.02it/s] 16%|#5        |27091/173481[06:10<33:24,73.02it/s] 22%|##2       |38951/173481[09:00<31:20,71.54it/s] 23%|##2       |39594/173481[09:10<31:11,71.54it/s] 29%|##9       |50740/173481[12:00<29:54,68.38it/s] 30%|##9       |51481/173481[12:10<29:44,68.38it/s] 36%|###6      |62773/173481[15:00<27:17,67.60it/s] 37%|###6      |63470/173481[15:10<27:07,67.60it/s] 43%|####3     |75310/173481[18:00<23:50,68.61it/s] 44%|####3     |76061/173481[18:11<23:39,68.61it/s] 51%|#####     |88046/173481[21:00<20:26,69.67it/s] 51%|#####1    |88872/173481[21:11<20:14,69.67it/s] 59%|#####8    |101945/173481[24:00<16:16,73.24it/s] 59%|#####9    |102774/173481[24:11<16:05,73.24it/s] 67%|######6   |115573/173481[27:00<12:57,74.46it/s] 67%|######7   |116453/173481[27:11<12:45,74.46it/s] 74%|#######4  |129229/173481[30:00<09:48,75.15it/s] 75%|#######4  |130102/173481[30:11<09:37,75.15it/s] 82%|########2 |142859/173481[33:00<06:45,75.43it/s] 83%|########2 |143758/173481[33:11<06:34,75.43it/s] 90%|######### |156592/173481[36:00<03:42,75.85it/s] 91%|######### |157538/173481[36:12<03:30,75.85it/s] 98%|#########8|170759/173481[39:00<00:35,77.25it/s] 99%|#########8|171712/173481[39:12<00:22,77.25it/s]100%|##########|173481/173481[39:31<00:00,73.15it/s]
[32m[0418 11:56:09 @base.py:257][0m Epoch 31 (global_step 20817720) finished, time:2371.52 sec.
[32m[0418 11:56:09 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-20817720.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.98it/s]
30
[32m[0418 11:58:07 @monitor.py:363][0m QueueInput/queue_size: 0.29563
[32m[0418 11:58:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0418 11:58:07 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0418 11:58:07 @monitor.py:363][0m cross_entropy_loss: 18.463
[32m[0418 11:58:07 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 11:58:07 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 11:58:07 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 11:58:07 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 11:58:07 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 11:58:07 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 11:58:07 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 11:58:07 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 11:58:07 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 11:58:07 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 11:58:07 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 11:58:07 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 11:58:07 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 11:58:07 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 11:58:07 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 11:58:07 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 11:58:07 @monitor.py:363][0m lr: 5.6843e-17
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 11:58:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 11:58:07 @monitor.py:363][0m train-error-top1: 0.98368
[32m[0418 11:58:07 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 11:58:07 @monitor.py:363][0m val-utt-error: 0.9737
[32m[0418 11:58:07 @monitor.py:363][0m validation_cost: 18.761
[32m[0418 11:58:07 @monitor.py:363][0m wd_cost: 7.0083e-30
[32m[0418 11:58:07 @group.py:42][0m Callbacks took 117.827 sec in total. InferenceRunner: 117.669sec
[32m[0418 11:58:07 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13180/173481[03:00<36:29,73.22it/s]  8%|8         |13887/173481[03:10<36:19,73.22it/s] 15%|#5        |26164/173481[06:00<33:47,72.67it/s] 16%|#5        |26923/173481[06:10<33:36,72.67it/s] 23%|##2       |39124/173481[09:00<30:57,72.33it/s] 23%|##2       |39873/173481[09:10<30:47,72.33it/s] 30%|##9       |51993/173481[12:00<28:09,71.91it/s] 30%|###       |52689/173481[12:10<27:59,71.91it/s] 38%|###7      |65070/173481[15:00<24:59,72.28it/s] 38%|###7      |65841/173481[15:10<24:49,72.28it/s] 45%|####4     |77704/173481[18:00<22:24,71.22it/s] 45%|####5     |78459/173481[18:11<22:14,71.22it/s] 52%|#####1    |90028/173481[21:00<19:55,69.81it/s] 52%|#####2    |90801/173481[21:11<19:44,69.81it/s] 59%|#####9    |103056/173481[24:00<16:30,71.07it/s] 60%|#####9    |103843/173481[24:11<16:19,71.07it/s] 67%|######6   |116015/173481[27:00<13:23,71.53it/s] 67%|######7   |116865/173481[27:11<13:11,71.53it/s] 75%|#######4  |129595/173481[30:00<09:57,73.43it/s] 75%|#######5  |130456/173481[30:11<09:45,73.43it/s] 82%|########2 |143071/173481[33:00<06:50,74.14it/s] 83%|########2 |143989/173481[33:11<06:37,74.14it/s] 90%|######### |156746/173481[36:00<03:42,75.05it/s] 91%|######### |157665/173481[36:12<03:30,75.05it/s] 98%|#########8|170457/173481[39:00<00:39,75.60it/s] 99%|#########8|171381/173481[39:12<00:27,75.60it/s]100%|##########|173481/173481[39:39<00:00,72.90it/s]
[32m[0418 12:37:46 @base.py:257][0m Epoch 32 (global_step 20991201) finished, time:2379.61 sec.
[32m[0418 12:37:46 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-20991201.
[32m[0418 12:37:47 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.35it/s]
31
[32m[0418 12:39:45 @monitor.py:363][0m QueueInput/queue_size: 0.39889
[32m[0418 12:39:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0418 12:39:45 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0418 12:39:45 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0418 12:39:45 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 12:39:45 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 12:39:45 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 12:39:45 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 12:39:45 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 12:39:45 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 12:39:45 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 12:39:45 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 12:39:45 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 12:39:45 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 12:39:45 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 12:39:45 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 12:39:45 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 12:39:45 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 12:39:45 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 12:39:45 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 12:39:45 @monitor.py:363][0m lr: 5.6843e-17
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 12:39:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 12:39:45 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0418 12:39:45 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 12:39:45 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0418 12:39:45 @monitor.py:363][0m validation_cost: 18.675
[32m[0418 12:39:45 @monitor.py:363][0m wd_cost: 7.0083e-30
[32m[0418 12:39:45 @group.py:42][0m Callbacks took 118.544 sec in total. InferenceRunner: 117.399sec
[32m[0418 12:39:45 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13863/173481[03:00<34:32,77.02it/s]  8%|8         |14574/173481[03:10<34:23,77.02it/s] 15%|#5        |26857/173481[06:00<32:47,74.52it/s] 16%|#5        |27618/173481[06:10<32:37,74.52it/s] 23%|##3       |40237/173481[09:00<29:50,74.42it/s] 24%|##3       |41056/173481[09:10<29:39,74.42it/s] 31%|###       |53722/173481[12:00<26:43,74.67it/s] 31%|###1      |54513/173481[12:10<26:33,74.67it/s] 39%|###8      |67167/173481[15:00<23:43,74.68it/s] 39%|###9      |67963/173481[15:10<23:32,74.68it/s] 46%|####6     |80587/173481[18:00<20:45,74.61it/s] 47%|####6     |81470/173481[18:11<20:33,74.61it/s] 55%|#####5    |95685/173481[21:00<16:25,78.97it/s] 56%|#####5    |96534/173481[21:11<16:14,78.97it/s] 62%|######2   |108377/173481[24:00<14:33,74.50it/s] 63%|######2   |109173/173481[24:11<14:23,74.50it/s] 69%|######9   |120261/173481[27:00<12:40,70.01it/s] 70%|######9   |121062/173481[27:11<12:28,70.01it/s] 77%|#######6  |133161/173481[30:00<09:29,70.83it/s] 77%|#######7  |133999/173481[30:11<09:17,70.83it/s] 84%|########4 |146154/173481[33:00<06:22,71.50it/s] 85%|########4 |147080/173481[33:11<06:09,71.50it/s] 93%|#########2|160637/173481[36:00<02:49,75.71it/s] 93%|#########3|161594/173481[36:12<02:36,75.71it/s]100%|##########|173481/173481[38:42<00:00,74.70it/s]
[32m[0418 13:18:27 @base.py:257][0m Epoch 33 (global_step 21164682) finished, time:2322.47 sec.
[32m[0418 13:18:28 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-21164682.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.94it/s]
32
[32m[0418 13:20:25 @monitor.py:363][0m QueueInput/queue_size: 0.2926
[32m[0418 13:20:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0418 13:20:25 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0418 13:20:25 @monitor.py:363][0m cross_entropy_loss: 18.359
[32m[0418 13:20:25 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 13:20:25 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 13:20:25 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 13:20:25 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 13:20:25 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 13:20:25 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 13:20:25 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 13:20:25 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 13:20:25 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 13:20:25 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 13:20:25 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 13:20:25 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 13:20:25 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 13:20:25 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 13:20:25 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 13:20:25 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 13:20:25 @monitor.py:363][0m lr: 5.6843e-17
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 13:20:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 13:20:25 @monitor.py:363][0m train-error-top1: 0.98423
[32m[0418 13:20:25 @monitor.py:363][0m val-error-top1: 0.98535
[32m[0418 13:20:25 @monitor.py:363][0m val-utt-error: 0.97455
[32m[0418 13:20:25 @monitor.py:363][0m validation_cost: 18.835
[32m[0418 13:20:25 @monitor.py:363][0m wd_cost: 1.4017e-30
[32m[0418 13:20:25 @group.py:42][0m Callbacks took 117.885 sec in total. InferenceRunner: 117.703sec
[32m[0418 13:20:25 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14042/173481[03:00<34:03,78.01it/s]  9%|8         |14815/173481[03:10<33:53,78.01it/s] 16%|#6        |28055/173481[06:00<31:06,77.93it/s] 17%|#6        |28863/173481[06:10<30:55,77.93it/s] 25%|##4       |42634/173481[09:00<27:27,79.43it/s] 25%|##5       |43435/173481[09:10<27:17,79.43it/s] 33%|###2      |57011/173481[12:00<24:22,79.65it/s] 33%|###3      |57855/173481[12:10<24:11,79.65it/s] 41%|####1     |71665/173481[15:00<21:04,80.52it/s] 42%|####1     |72545/173481[15:10<20:53,80.52it/s] 50%|####9     |86393/173481[18:00<17:52,81.17it/s] 50%|#####     |87300/173481[18:11<17:41,81.17it/s] 58%|#####8    |101151/173481[21:00<14:46,81.57it/s] 59%|#####8    |102036/173481[21:11<14:35,81.57it/s] 67%|######6   |115590/173481[24:00<11:55,80.89it/s] 67%|######7   |116457/173481[24:11<11:44,80.89it/s] 74%|#######4  |129016/173481[27:00<09:32,77.60it/s] 75%|#######4  |129928/173481[27:11<09:21,77.60it/s] 82%|########2 |143082/173481[30:00<06:30,77.87it/s] 83%|########2 |143966/173481[30:11<06:19,77.87it/s] 91%|######### |157498/173481[33:00<03:22,78.96it/s] 91%|#########1|158483/173481[33:11<03:09,78.96it/s] 99%|#########8|171196/173481[36:00<00:29,77.50it/s] 99%|#########9|172047/173481[36:12<00:18,77.50it/s]100%|##########|173481/173481[36:31<00:00,79.17it/s]
[32m[0418 13:56:57 @base.py:257][0m Epoch 34 (global_step 21338163) finished, time:2191.38 sec.
[32m[0418 13:56:57 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-21338163.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.80it/s]
33
[32m[0418 13:58:52 @monitor.py:363][0m QueueInput/queue_size: 0.4096
[32m[0418 13:58:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0418 13:58:52 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0418 13:58:52 @monitor.py:363][0m cross_entropy_loss: 18.71
[32m[0418 13:58:52 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 13:58:52 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 13:58:52 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 13:58:52 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 13:58:52 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 13:58:52 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 13:58:52 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 13:58:52 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 13:58:52 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 13:58:52 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 13:58:52 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 13:58:52 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 13:58:52 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 13:58:52 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 13:58:52 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 13:58:52 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 13:58:52 @monitor.py:363][0m lr: 2.8422e-17
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 13:58:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 13:58:52 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0418 13:58:52 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0418 13:58:52 @monitor.py:363][0m val-utt-error: 0.97551
[32m[0418 13:58:52 @monitor.py:363][0m validation_cost: 19.032
[32m[0418 13:58:52 @monitor.py:363][0m wd_cost: 1.4017e-30
[32m[0418 13:58:52 @group.py:42][0m Callbacks took 115.070 sec in total. InferenceRunner: 114.924sec
[32m[0418 13:58:52 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14905/173481[03:00<31:55,82.80it/s]  9%|9         |15719/173481[03:10<31:45,82.80it/s] 17%|#6        |28916/173481[06:00<30:01,80.24it/s] 17%|#7        |29736/173481[06:10<29:51,80.24it/s] 25%|##5       |43801/173481[09:00<26:32,81.45it/s] 26%|##5       |44971/173481[09:10<26:17,81.45it/s] 36%|###6      |63239/173481[12:00<19:47,92.86it/s] 37%|###6      |64142/173481[12:10<19:37,92.86it/s] 45%|####5     |78346/173481[15:00<17:59,88.16it/s] 46%|####5     |79204/173481[15:10<17:49,88.16it/s] 54%|#####3    |93534/173481[18:00<15:27,86.23it/s] 54%|#####4    |94433/173481[18:11<15:16,86.23it/s] 62%|######2   |108403/173481[21:00<12:51,84.38it/s] 63%|######3   |109353/173481[21:11<12:40,84.38it/s] 71%|#######1  |123619/173481[24:00<09:50,84.45it/s] 72%|#######1  |124530/173481[24:11<09:39,84.45it/s] 81%|########  |139832/173481[27:00<06:26,87.17it/s] 81%|########1 |140880/173481[27:11<06:13,87.17it/s] 89%|########9 |154585/173481[30:00<03:43,84.48it/s] 90%|########9 |155529/173481[30:11<03:32,84.48it/s] 98%|#########8|170028/173481[33:00<00:40,85.13it/s] 99%|#########8|171215/173481[33:11<00:26,85.13it/s]100%|##########|173481/173481[33:35<00:00,86.08it/s]
[32m[0418 14:32:27 @base.py:257][0m Epoch 35 (global_step 21511644) finished, time:2015.31 sec.
[32m[0418 14:32:27 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-21511644.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.31it/s]
34
[32m[0418 14:34:20 @monitor.py:363][0m QueueInput/queue_size: 1.6434
[32m[0418 14:34:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0418 14:34:20 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0418 14:34:20 @monitor.py:363][0m cross_entropy_loss: 18.838
[32m[0418 14:34:20 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 14:34:20 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 14:34:20 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 14:34:20 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 14:34:20 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 14:34:20 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 14:34:20 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 14:34:20 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 14:34:20 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 14:34:20 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 14:34:20 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 14:34:20 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 14:34:20 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 14:34:20 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 14:34:20 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 14:34:20 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 14:34:20 @monitor.py:363][0m lr: 2.8422e-17
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 14:34:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 14:34:20 @monitor.py:363][0m train-error-top1: 0.98755
[32m[0418 14:34:20 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 14:34:20 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0418 14:34:20 @monitor.py:363][0m validation_cost: 18.769
[32m[0418 14:34:20 @monitor.py:363][0m wd_cost: 1.4017e-30
[32m[0418 14:34:20 @group.py:42][0m Callbacks took 112.678 sec in total. InferenceRunner: 112.511sec
[32m[0418 14:34:20 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14938/173481[03:00<31:50,82.98it/s]  9%|9         |15723/173481[03:10<31:41,82.98it/s] 17%|#7        |29605/173481[06:00<29:09,82.23it/s] 18%|#7        |30441/173481[06:10<28:59,82.23it/s] 25%|##5       |43956/173481[09:00<26:39,80.96it/s] 26%|##5       |44789/173481[09:10<26:29,80.96it/s] 33%|###3      |58059/173481[12:00<24:09,79.63it/s] 34%|###3      |58944/173481[12:10<23:58,79.63it/s] 42%|####1     |72208/173481[15:00<21:20,79.11it/s] 42%|####2     |73059/173481[15:10<21:09,79.11it/s] 50%|####9     |86392/173481[18:00<18:23,78.95it/s] 50%|#####     |87292/173481[18:11<18:11,78.95it/s] 58%|#####8    |100678/173481[21:00<15:19,79.15it/s] 59%|#####8    |101549/173481[21:11<15:08,79.15it/s] 66%|######6   |114708/173481[24:00<12:28,78.54it/s] 67%|######6   |115569/173481[24:11<12:17,78.54it/s] 74%|#######4  |129174/173481[27:00<09:17,79.44it/s] 75%|#######5  |130135/173481[27:11<09:05,79.44it/s] 83%|########3 |144012/173481[30:00<06:04,80.91it/s] 84%|########3 |144964/173481[30:11<05:52,80.91it/s] 92%|#########1|158981/173481[33:00<02:56,82.02it/s] 92%|#########2|159933/173481[33:11<02:45,82.02it/s]100%|#########9|173426/173481[36:00<00:00,81.12it/s]100%|##########|173481/173481[36:01<00:00,80.28it/s]
[32m[0418 15:10:21 @base.py:257][0m Epoch 36 (global_step 21685125) finished, time:2161.01 sec.
[32m[0418 15:10:21 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-21685125.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.46it/s]
35
[32m[0418 15:12:16 @monitor.py:363][0m QueueInput/queue_size: 0.5413
[32m[0418 15:12:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0418 15:12:16 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0418 15:12:16 @monitor.py:363][0m cross_entropy_loss: 18.398
[32m[0418 15:12:16 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 15:12:16 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 15:12:16 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 15:12:16 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 15:12:16 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 15:12:16 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 15:12:16 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 15:12:16 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 15:12:16 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 15:12:16 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 15:12:16 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 15:12:16 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 15:12:16 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 15:12:16 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 15:12:16 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 15:12:16 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 15:12:16 @monitor.py:363][0m lr: 2.8422e-17
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 15:12:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 15:12:16 @monitor.py:363][0m train-error-top1: 0.98404
[32m[0418 15:12:16 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 15:12:16 @monitor.py:363][0m val-utt-error: 0.97312
[32m[0418 15:12:16 @monitor.py:363][0m validation_cost: 18.665
[32m[0418 15:12:16 @monitor.py:363][0m wd_cost: 2.8033e-31
[32m[0418 15:12:16 @group.py:42][0m Callbacks took 115.348 sec in total. InferenceRunner: 115.163sec
[32m[0418 15:12:16 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14452/173481[03:00<33:00,80.29it/s]  9%|8         |15277/173481[03:10<32:50,80.29it/s] 16%|#5        |27613/173481[06:00<31:46,76.52it/s] 16%|#6        |28194/173481[06:10<31:38,76.52it/s] 21%|##1       |37231/173481[09:00<36:05,62.92it/s] 22%|##1       |37794/173481[09:10<35:56,62.92it/s] 27%|##7       |46867/173481[12:00<36:29,57.83it/s] 27%|##7       |47477/173481[12:10<36:18,57.83it/s] 34%|###4      |59374/173481[15:00<30:07,63.12it/s] 35%|###4      |60072/173481[15:10<29:56,63.12it/s] 41%|####1     |71243/173481[18:00<26:25,64.50it/s] 41%|####1     |71977/173481[18:11<26:13,64.50it/s] 48%|####8     |83866/173481[21:00<22:13,67.19it/s] 49%|####8     |84596/173481[21:11<22:02,67.19it/s] 55%|#####4    |94927/173481[24:00<20:23,64.19it/s] 55%|#####5    |95568/173481[24:11<20:13,64.19it/s] 61%|######1   |105882/173481[27:00<18:01,62.48it/s] 61%|######1   |106611/173481[27:11<17:50,62.48it/s] 67%|######7   |116389/173481[30:00<15:45,60.35it/s] 67%|######7   |117096/173481[30:11<15:34,60.35it/s] 73%|#######3  |127219/173481[33:00<12:47,60.26it/s] 74%|#######3  |127907/173481[33:11<12:36,60.26it/s] 80%|#######9  |138205/173481[36:00<09:41,60.64it/s] 80%|########  |138919/173481[36:12<09:29,60.64it/s] 86%|########5 |148357/173481[39:00<07:09,58.44it/s] 86%|########5 |149061/173481[39:12<06:57,58.44it/s] 92%|#########1|159408/173481[42:00<03:55,59.88it/s] 92%|#########2|160081/173481[42:12<03:43,59.88it/s] 98%|#########7|169823/173481[45:00<01:02,58.85it/s] 98%|#########8|170542/173481[45:12<00:49,58.85it/s]100%|##########|173481/173481[46:00<00:00,62.85it/s]
[32m[0418 15:58:16 @base.py:257][0m Epoch 37 (global_step 21858606) finished, time:2760.23 sec.
[32m[0418 15:58:16 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-21858606.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.60it/s]
36
[32m[0418 16:00:14 @monitor.py:363][0m QueueInput/queue_size: 0.37786
[32m[0418 16:00:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0418 16:00:14 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0418 16:00:14 @monitor.py:363][0m cross_entropy_loss: 18.463
[32m[0418 16:00:14 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 16:00:14 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 16:00:14 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 16:00:14 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 16:00:14 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 16:00:14 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 16:00:14 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 16:00:14 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 16:00:14 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 16:00:14 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 16:00:14 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 16:00:14 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 16:00:14 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 16:00:14 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 16:00:14 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 16:00:14 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 16:00:14 @monitor.py:363][0m lr: 1.4211e-17
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 16:00:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 16:00:14 @monitor.py:363][0m train-error-top1: 0.98368
[32m[0418 16:00:14 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 16:00:14 @monitor.py:363][0m val-utt-error: 0.97359
[32m[0418 16:00:14 @monitor.py:363][0m validation_cost: 18.76
[32m[0418 16:00:14 @monitor.py:363][0m wd_cost: 2.8033e-31
[32m[0418 16:00:14 @group.py:42][0m Callbacks took 117.464 sec in total. InferenceRunner: 117.208sec
[32m[0418 16:00:14 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10822/173481[03:00<45:05,60.11it/s]  7%|6         |11391/173481[03:10<44:56,60.11it/s] 12%|#2        |21578/173481[06:00<42:14,59.93it/s] 13%|#2        |22239/173481[06:10<42:03,59.93it/s] 19%|#8        |32674/173481[09:00<38:36,60.78it/s] 19%|#9        |33268/173481[09:10<38:27,60.78it/s] 25%|##5       |43903/173481[12:00<35:04,61.57it/s] 26%|##5       |44535/173481[12:10<34:54,61.57it/s] 32%|###2      |55710/173481[15:00<30:54,63.52it/s] 33%|###2      |56475/173481[15:10<30:42,63.52it/s] 39%|###8      |67594/173481[18:00<27:15,64.74it/s] 39%|###9      |68307/173481[18:11<27:04,64.74it/s] 45%|####5     |78463/173481[21:00<25:20,62.49it/s] 46%|####5     |79101/173481[21:11<25:10,62.49it/s] 51%|#####     |88168/173481[24:00<24:33,57.88it/s] 51%|#####1    |88809/173481[24:11<24:22,57.88it/s] 57%|#####6    |98742/173481[27:00<21:21,58.31it/s] 57%|#####7    |99460/173481[27:11<21:09,58.31it/s] 63%|######3   |109444/173481[30:00<18:07,58.87it/s] 63%|######3   |110116/173481[30:11<17:56,58.87it/s] 69%|######8   |119393/173481[33:00<15:48,57.01it/s] 69%|######9   |120045/173481[33:11<15:37,57.01it/s] 75%|#######4  |129725/173481[36:00<12:44,57.21it/s] 75%|#######5  |130419/173481[36:12<12:32,57.21it/s] 81%|########  |139972/173481[39:00<09:47,57.06it/s] 81%|########1 |140674/173481[39:12<09:34,57.06it/s] 87%|########6 |150376/173481[42:00<06:42,57.42it/s] 87%|########7 |151017/173481[42:12<06:31,57.42it/s] 93%|#########2|160852/173481[45:00<03:38,57.79it/s] 93%|#########3|161602/173481[45:12<03:25,57.79it/s] 99%|#########8|171371/173481[48:00<00:36,58.11it/s] 99%|#########9|172047/173481[48:12<00:24,58.11it/s]100%|##########|173481/173481[48:37<00:00,59.47it/s]
[32m[0418 16:48:51 @base.py:257][0m Epoch 38 (global_step 22032087) finished, time:2917.31 sec.
[32m[0418 16:48:51 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-22032087.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,162.04it/s]
37
[32m[0418 16:50:47 @monitor.py:363][0m QueueInput/queue_size: 0.48223
[32m[0418 16:50:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0418 16:50:47 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0418 16:50:47 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0418 16:50:47 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 16:50:47 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 16:50:47 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 16:50:47 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 16:50:47 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 16:50:47 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 16:50:47 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 16:50:47 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 16:50:47 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 16:50:47 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 16:50:47 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 16:50:47 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 16:50:47 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 16:50:47 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 16:50:47 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 16:50:47 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 16:50:47 @monitor.py:363][0m lr: 1.4211e-17
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 16:50:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 16:50:47 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0418 16:50:47 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 16:50:47 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0418 16:50:47 @monitor.py:363][0m validation_cost: 18.675
[32m[0418 16:50:47 @monitor.py:363][0m wd_cost: 2.8033e-31
[32m[0418 16:50:47 @group.py:42][0m Callbacks took 116.297 sec in total. InferenceRunner: 116.166sec
[32m[0418 16:50:47 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10759/173481[03:00<45:22,59.77it/s]  7%|6         |11329/173481[03:10<45:13,59.77it/s] 12%|#2        |20841/173481[06:00<43:59,57.83it/s] 12%|#2        |21440/173481[06:10<43:49,57.83it/s] 18%|#7        |30972/173481[09:00<41:38,57.04it/s] 18%|#8        |31572/173481[09:10<41:27,57.04it/s] 24%|##3       |41007/173481[12:00<39:09,56.39it/s] 24%|##4       |41701/173481[12:10<38:56,56.39it/s] 30%|###       |52398/173481[15:00<33:50,59.63it/s] 31%|###       |53033/173481[15:10<33:39,59.63it/s] 36%|###6      |63099/173481[18:00<30:53,59.54it/s] 37%|###6      |63747/173481[18:11<30:43,59.54it/s] 42%|####2     |73318/173481[21:00<28:43,58.12it/s] 43%|####2     |73920/173481[21:11<28:32,58.12it/s] 48%|####8     |83917/173481[24:00<25:31,58.49it/s] 49%|####8     |84606/173481[24:11<25:19,58.49it/s] 55%|#####5    |95965/173481[27:00<20:41,62.42it/s] 56%|#####5    |96762/173481[27:11<20:29,62.42it/s] 62%|######1   |106897/173481[30:00<18:01,61.56it/s] 62%|######2   |107566/173481[30:11<17:50,61.56it/s] 68%|######7   |117363/173481[33:00<15:38,59.80it/s] 68%|######8   |118005/173481[33:11<15:27,59.80it/s] 74%|#######4  |128761/173481[36:00<12:07,61.51it/s] 75%|#######4  |129430/173481[36:12<11:56,61.51it/s] 80%|#######9  |138259/173481[39:00<10:20,56.80it/s] 80%|########  |138879/173481[39:12<10:09,56.80it/s] 86%|########5 |148864/173481[42:00<07:05,57.84it/s] 86%|########6 |149765/173481[42:12<06:50,57.84it/s] 93%|#########2|161103/173481[45:00<03:18,62.51it/s] 93%|#########3|161936/173481[45:12<03:04,62.51it/s]100%|#########9|173106/173481[48:00<00:05,64.52it/s]100%|##########|173481/173481[48:06<00:00,60.10it/s]
[32m[0418 17:38:54 @base.py:257][0m Epoch 39 (global_step 22205568) finished, time:2886.35 sec.
[32m[0418 17:38:54 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-22205568.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,162.13it/s]
38
[32m[0418 17:40:50 @monitor.py:363][0m QueueInput/queue_size: 0.51023
[32m[0418 17:40:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0418 17:40:50 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0418 17:40:50 @monitor.py:363][0m cross_entropy_loss: 18.357
[32m[0418 17:40:50 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 17:40:50 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 17:40:50 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 17:40:50 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 17:40:50 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 17:40:50 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 17:40:50 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 17:40:50 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 17:40:50 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 17:40:50 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 17:40:50 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 17:40:50 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 17:40:50 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 17:40:50 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 17:40:50 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 17:40:50 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 17:40:50 @monitor.py:363][0m lr: 7.1054e-18
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 17:40:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 17:40:50 @monitor.py:363][0m train-error-top1: 0.9842
[32m[0418 17:40:50 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0418 17:40:50 @monitor.py:363][0m val-utt-error: 0.97429
[32m[0418 17:40:50 @monitor.py:363][0m validation_cost: 18.837
[32m[0418 17:40:50 @monitor.py:363][0m wd_cost: 5.6066e-32
[32m[0418 17:40:50 @group.py:42][0m Callbacks took 116.300 sec in total. InferenceRunner: 116.108sec
[32m[0418 17:40:50 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13216/173481[03:00<36:23,73.41it/s]  8%|7         |13857/173481[03:10<36:14,73.41it/s] 14%|#4        |24753/173481[06:00<36:13,68.44it/s] 15%|#4        |25514/173481[06:10<36:02,68.44it/s] 22%|##1       |37756/173481[09:00<32:11,70.28it/s] 22%|##2       |38453/173481[09:10<32:01,70.28it/s] 29%|##8       |49996/173481[12:00<29:46,69.11it/s] 29%|##9       |50709/173481[12:10<29:36,69.11it/s] 36%|###6      |62722/173481[15:00<26:24,69.88it/s] 37%|###6      |63482/173481[15:10<26:14,69.88it/s] 43%|####3     |75353/173481[18:00<23:21,70.03it/s] 44%|####3     |76053/173481[18:11<23:11,70.03it/s] 50%|#####     |87346/173481[21:00<21:01,68.28it/s] 51%|#####     |88169/173481[21:11<20:49,68.28it/s] 58%|#####7    |100057/173481[24:00<17:37,69.43it/s] 58%|#####8    |100833/173481[24:11<17:26,69.43it/s] 65%|######5   |113470/173481[27:00<13:54,71.88it/s] 66%|######5   |114333/173481[27:11<13:42,71.88it/s] 72%|#######2  |125570/173481[30:00<11:29,69.47it/s] 73%|#######2  |126361/173481[30:11<11:18,69.47it/s] 79%|#######9  |137317/173481[33:00<08:57,67.30it/s] 80%|#######9  |137993/173481[33:11<08:47,67.30it/s] 86%|########5 |148908/173481[36:00<06:13,65.81it/s] 86%|########6 |149700/173481[36:12<06:01,65.81it/s] 93%|#########2|161334/173481[39:00<03:00,67.38it/s] 93%|#########3|162129/173481[39:12<02:48,67.38it/s]100%|#########9|172966/173481[42:00<00:07,65.97it/s]100%|##########|173481/173481[42:08<00:00,68.61it/s]
[32m[0418 18:22:58 @base.py:257][0m Epoch 40 (global_step 22379049) finished, time:2528.41 sec.
[32m[0418 18:22:59 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-22379049.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.50it/s]
39
[32m[0418 18:24:54 @monitor.py:363][0m QueueInput/queue_size: 0.26716
[32m[0418 18:24:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0418 18:24:54 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0418 18:24:54 @monitor.py:363][0m cross_entropy_loss: 18.71
[32m[0418 18:24:54 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 18:24:54 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 18:24:54 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 18:24:54 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 18:24:54 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 18:24:54 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 18:24:54 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 18:24:54 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 18:24:54 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 18:24:54 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 18:24:54 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 18:24:54 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 18:24:54 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 18:24:54 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 18:24:54 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 18:24:54 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 18:24:54 @monitor.py:363][0m lr: 7.1054e-18
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 18:24:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 18:24:54 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0418 18:24:54 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0418 18:24:54 @monitor.py:363][0m val-utt-error: 0.97551
[32m[0418 18:24:54 @monitor.py:363][0m validation_cost: 19.032
[32m[0418 18:24:54 @monitor.py:363][0m wd_cost: 5.6066e-32
[32m[0418 18:24:54 @group.py:42][0m Callbacks took 115.302 sec in total. InferenceRunner: 115.131sec
[32m[0418 18:24:54 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11593/173481[03:00<41:53,64.40it/s]  7%|7         |12271/173481[03:10<41:43,64.40it/s] 14%|#3        |23455/173481[06:00<38:23,65.14it/s] 14%|#3        |24064/173481[06:10<38:13,65.14it/s] 21%|##        |36271/173481[09:00<33:36,68.03it/s] 21%|##1       |37002/173481[09:10<33:26,68.03it/s] 29%|##9       |51073/173481[12:00<27:23,74.46it/s] 30%|###       |52051/173481[12:10<27:10,74.46it/s] 39%|###8      |67532/173481[15:00<21:30,82.08it/s] 39%|###9      |68388/173481[15:10<21:20,82.08it/s] 47%|####7     |81955/173481[18:00<18:48,81.09it/s] 48%|####7     |82892/173481[18:11<18:37,81.09it/s] 55%|#####4    |95401/173481[21:00<16:44,77.76it/s] 55%|#####5    |96167/173481[21:11<16:34,77.76it/s] 62%|######2   |108145/173481[24:00<14:41,74.11it/s] 63%|######2   |108934/173481[24:11<14:31,74.11it/s] 69%|######9   |120510/173481[27:00<12:22,71.30it/s] 70%|######9   |121248/173481[27:11<12:12,71.30it/s] 77%|#######6  |133435/173481[30:00<09:19,71.55it/s] 77%|#######7  |134284/173481[30:11<09:07,71.55it/s] 84%|########4 |145745/173481[33:00<06:36,69.93it/s] 84%|########4 |146585/173481[33:11<06:24,69.93it/s] 91%|#########1|158632/173481[36:00<03:29,70.75it/s] 92%|#########1|159512/173481[36:12<03:17,70.75it/s] 99%|#########9|172445/173481[39:00<00:14,73.62it/s]100%|#########9|173478/173481[39:12<00:00,73.62it/s]100%|##########|173481/173481[39:12<00:00,73.75it/s]
[32m[0418 19:04:06 @base.py:257][0m Epoch 41 (global_step 22552530) finished, time:2352.30 sec.
[32m[0418 19:04:06 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-22552530.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.22it/s]
40
[32m[0418 19:06:00 @monitor.py:363][0m QueueInput/queue_size: 1.0415
[32m[0418 19:06:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0418 19:06:00 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0418 19:06:00 @monitor.py:363][0m cross_entropy_loss: 18.84
[32m[0418 19:06:00 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 19:06:00 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 19:06:00 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 19:06:00 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 19:06:00 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 19:06:00 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 19:06:00 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 19:06:00 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 19:06:00 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 19:06:00 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 19:06:00 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 19:06:00 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 19:06:00 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 19:06:00 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 19:06:00 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 19:06:00 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 19:06:00 @monitor.py:363][0m lr: 7.1054e-18
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 19:06:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 19:06:00 @monitor.py:363][0m train-error-top1: 0.98764
[32m[0418 19:06:00 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 19:06:00 @monitor.py:363][0m val-utt-error: 0.97444
[32m[0418 19:06:00 @monitor.py:363][0m validation_cost: 18.777
[32m[0418 19:06:00 @monitor.py:363][0m wd_cost: 5.6066e-32
[32m[0418 19:06:00 @group.py:42][0m Callbacks took 114.093 sec in total. InferenceRunner: 113.940sec
[32m[0418 19:06:00 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12964/173481[03:00<37:08,72.02it/s]  8%|7         |13724/173481[03:10<36:58,72.02it/s] 15%|#5        |26844/173481[06:00<32:48,74.48it/s] 16%|#5        |27645/173481[06:10<32:38,74.48it/s] 23%|##3       |40400/173481[09:00<29:36,74.89it/s] 24%|##3       |41228/173481[09:10<29:25,74.89it/s] 31%|###1      |54387/173481[12:00<26:01,76.27it/s] 32%|###1      |55193/173481[12:10<25:50,76.27it/s] 39%|###9      |68286/173481[15:00<22:50,76.74it/s] 40%|###9      |69133/173481[15:10<22:39,76.74it/s] 47%|####7     |81688/173481[18:00<20:14,75.58it/s] 48%|####7     |82461/173481[18:11<20:04,75.58it/s] 55%|#####5    |95526/173481[21:00<17:02,76.22it/s] 56%|#####5    |96369/173481[21:11<16:51,76.22it/s] 63%|######2   |109062/173481[24:00<14:10,75.71it/s] 63%|######3   |109902/173481[24:11<13:59,75.71it/s] 71%|#######   |122430/173481[27:00<11:20,74.98it/s] 71%|#######1  |123280/173481[27:11<11:09,74.98it/s] 79%|#######8  |136450/173481[30:00<08:04,76.40it/s] 79%|#######9  |137292/173481[30:11<07:53,76.40it/s] 87%|########6 |150293/173481[33:00<05:02,76.65it/s] 87%|########7 |151131/173481[33:11<04:51,76.65it/s] 94%|#########4|163582/173481[36:00<02:11,75.21it/s] 95%|#########4|164427/173481[36:12<02:00,75.21it/s]100%|##########|173481/173481[38:10<00:00,75.73it/s]
[32m[0418 19:44:11 @base.py:257][0m Epoch 42 (global_step 22726011) finished, time:2290.73 sec.
[32m[0418 19:44:11 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-22726011.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,160.93it/s]
41
[32m[0418 19:46:08 @monitor.py:363][0m QueueInput/queue_size: 0.83293
[32m[0418 19:46:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0418 19:46:08 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0418 19:46:08 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0418 19:46:08 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 19:46:08 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 19:46:08 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 19:46:08 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 19:46:08 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 19:46:08 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 19:46:08 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 19:46:08 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 19:46:08 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 19:46:08 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 19:46:08 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 19:46:08 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 19:46:08 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 19:46:08 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 19:46:08 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 19:46:08 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 19:46:08 @monitor.py:363][0m lr: 3.5527e-18
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 19:46:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 19:46:08 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0418 19:46:08 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 19:46:08 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0418 19:46:08 @monitor.py:363][0m validation_cost: 18.665
[32m[0418 19:46:08 @monitor.py:363][0m wd_cost: 1.1213e-32
[32m[0418 19:46:08 @group.py:42][0m Callbacks took 117.163 sec in total. InferenceRunner: 116.971sec
[32m[0418 19:46:08 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14370/173481[03:00<33:13,79.83it/s]  9%|8         |15118/173481[03:10<33:03,79.83it/s] 16%|#6        |28137/173481[06:00<31:00,78.12it/s] 17%|#6        |28858/173481[06:10<30:51,78.12it/s] 24%|##3       |41125/173481[09:00<29:24,75.01it/s] 24%|##4       |41794/173481[09:10<29:15,75.01it/s] 31%|###1      |54187/173481[12:00<26:57,73.77it/s] 32%|###1      |54909/173481[12:10<26:47,73.77it/s] 38%|###8      |66463/173481[15:00<25:09,70.87it/s] 39%|###8      |67226/173481[15:10<24:59,70.87it/s] 46%|####5     |79607/173481[18:00<21:45,71.93it/s] 46%|####6     |80497/173481[18:11<21:32,71.93it/s] 53%|#####2    |91915/173481[21:00<19:23,70.10it/s] 53%|#####3    |92730/173481[21:11<19:11,70.10it/s] 61%|######    |105823/173481[24:00<15:20,73.51it/s] 62%|######1   |106704/173481[24:11<15:08,73.51it/s] 68%|######8   |118484/173481[27:00<12:45,71.89it/s] 69%|######8   |119322/173481[27:11<12:33,71.89it/s] 75%|#######5  |130813/173481[30:00<10:08,70.14it/s] 76%|#######5  |131630/173481[30:11<09:56,70.14it/s] 83%|########2 |143390/173481[33:00<07:09,70.00it/s] 83%|########3 |144199/173481[33:11<06:58,70.00it/s] 91%|######### |157254/173481[36:00<03:41,73.34it/s] 91%|#########1|158447/173481[36:12<03:24,73.34it/s]100%|##########|173481/173481[38:36<00:00,74.89it/s]
[32m[0418 20:24:44 @base.py:257][0m Epoch 43 (global_step 22899492) finished, time:2316.38 sec.
[32m[0418 20:24:45 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-22899492.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,162.90it/s]
42
[32m[0418 20:26:40 @monitor.py:363][0m QueueInput/queue_size: 49.998
[32m[0418 20:26:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.96
[32m[0418 20:26:40 @monitor.py:363][0m activation-summaries/output-rms: 0.049677
[32m[0418 20:26:40 @monitor.py:363][0m cross_entropy_loss: 18.411
[32m[0418 20:26:40 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 20:26:40 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 20:26:40 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 20:26:40 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 20:26:40 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 20:26:40 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 20:26:40 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 20:26:40 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 20:26:40 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 20:26:40 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 20:26:40 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 20:26:40 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 20:26:40 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 20:26:40 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 20:26:40 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 20:26:40 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 20:26:40 @monitor.py:363][0m lr: 3.5527e-18
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 20:26:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 20:26:40 @monitor.py:363][0m train-error-top1: 0.98448
[32m[0418 20:26:40 @monitor.py:363][0m val-error-top1: 0.9853
[32m[0418 20:26:40 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0418 20:26:40 @monitor.py:363][0m validation_cost: 18.775
[32m[0418 20:26:40 @monitor.py:363][0m wd_cost: 1.1213e-32
[32m[0418 20:26:40 @group.py:42][0m Callbacks took 115.712 sec in total. InferenceRunner: 115.558sec
[32m[0418 20:26:40 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21419/173481[03:00<21:17,118.99it/s] 13%|#3        |22665/173481[03:10<21:07,118.99it/s] 20%|##        |35107/173481[06:00<24:51,92.79it/s]  21%|##        |35831/173481[06:10<24:43,92.79it/s] 27%|##7       |47637/173481[09:00<26:22,79.54it/s] 28%|##7       |48283/173481[09:10<26:13,79.54it/s] 34%|###4      |59528/173481[12:00<26:18,72.18it/s] 35%|###4      |60238/173481[12:10<26:08,72.18it/s] 42%|####1     |72532/173481[15:00<23:18,72.21it/s] 42%|####2     |73169/173481[15:10<23:09,72.21it/s] 48%|####8     |83614/173481[18:00<22:32,66.46it/s] 49%|####8     |84266/173481[18:11<22:22,66.46it/s] 54%|#####4    |94284/173481[21:00<21:03,62.66it/s] 55%|#####4    |94943/173481[21:11<20:53,62.66it/s] 61%|######1   |106091/173481[24:00<17:31,64.09it/s] 62%|######1   |106911/173481[24:11<17:18,64.09it/s] 69%|######8   |118889/173481[27:00<13:29,67.42it/s] 69%|######9   |119734/173481[27:11<13:17,67.42it/s] 76%|#######6  |132194/173481[30:00<09:45,70.52it/s] 77%|#######6  |133064/173481[30:11<09:33,70.52it/s] 84%|########3 |145144/173481[33:00<06:37,71.22it/s] 84%|########4 |145978/173481[33:11<06:26,71.22it/s] 91%|######### |157705/173481[36:00<03:43,70.49it/s] 91%|#########1|158563/173481[36:12<03:31,70.49it/s] 98%|#########8|170554/173481[39:00<00:41,70.93it/s] 99%|#########8|171422/173481[39:12<00:29,70.93it/s]100%|##########|173481/173481[39:42<00:00,72.82it/s]
[32m[0418 21:06:23 @base.py:257][0m Epoch 44 (global_step 23072973) finished, time:2382.36 sec.
[32m[0418 21:06:23 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-23072973.
[32m[0418 21:06:23 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.18it/s]
43
[32m[0418 21:08:20 @monitor.py:363][0m QueueInput/queue_size: 0.34891
[32m[0418 21:08:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0418 21:08:20 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0418 21:08:20 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0418 21:08:20 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 21:08:20 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 21:08:20 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 21:08:20 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 21:08:20 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 21:08:20 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 21:08:20 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 21:08:20 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 21:08:20 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 21:08:20 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 21:08:20 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 21:08:20 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 21:08:20 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 21:08:20 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 21:08:20 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 21:08:20 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 21:08:20 @monitor.py:363][0m lr: 3.5527e-18
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 21:08:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 21:08:20 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0418 21:08:20 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 21:08:20 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0418 21:08:20 @monitor.py:363][0m validation_cost: 18.675
[32m[0418 21:08:20 @monitor.py:363][0m wd_cost: 2.2429e-33
[32m[0418 21:08:20 @group.py:42][0m Callbacks took 117.401 sec in total. InferenceRunner: 116.795sec
[32m[0418 21:08:20 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12778/173481[03:00<37:43,70.99it/s]  8%|7         |13442/173481[03:10<37:34,70.99it/s] 14%|#4        |25017/173481[06:00<35:37,69.46it/s] 15%|#4        |25679/173481[06:10<35:27,69.46it/s] 22%|##1       |37309/173481[09:00<32:57,68.87it/s] 22%|##1       |38040/173481[09:10<32:46,68.87it/s] 29%|##8       |50135/173481[12:00<29:21,70.04it/s] 29%|##9       |50830/173481[12:10<29:11,70.04it/s] 36%|###5      |62431/173481[15:00<26:45,69.16it/s] 36%|###6      |63187/173481[15:10<26:34,69.16it/s] 43%|####3     |74743/173481[18:00<23:55,68.78it/s] 44%|####3     |75614/173481[18:11<23:42,68.78it/s] 51%|#####     |88195/173481[21:00<19:50,71.63it/s] 51%|#####1    |88979/173481[21:11<19:39,71.63it/s] 58%|#####8    |101347/173481[24:00<16:37,72.34it/s] 59%|#####8    |102020/173481[24:11<16:27,72.34it/s] 65%|######4   |112447/173481[27:00<15:16,66.57it/s] 65%|######5   |113208/173481[27:11<15:05,66.57it/s] 72%|#######1  |124171/173481[30:00<12:29,65.83it/s] 72%|#######2  |124917/173481[30:11<12:17,65.83it/s] 78%|#######8  |135961/173481[33:00<09:31,65.66it/s] 79%|#######8  |136746/173481[33:11<09:19,65.66it/s] 85%|########5 |147839/173481[36:00<06:29,65.83it/s] 86%|########5 |148686/173481[36:12<06:16,65.83it/s] 93%|#########2|161203/173481[39:00<02:55,69.78it/s] 93%|#########3|162138/173481[39:12<02:42,69.78it/s]100%|##########|173481/173481[41:45<00:00,69.25it/s]
[32m[0418 21:50:05 @base.py:257][0m Epoch 45 (global_step 23246454) finished, time:2505.08 sec.
[32m[0418 21:50:05 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-23246454.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,162.50it/s]
44
[32m[0418 21:52:01 @monitor.py:363][0m QueueInput/queue_size: 0.22724
[32m[0418 21:52:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0418 21:52:01 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0418 21:52:01 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0418 21:52:01 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 21:52:01 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 21:52:01 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 21:52:01 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 21:52:01 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 21:52:01 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 21:52:01 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 21:52:01 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 21:52:01 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 21:52:01 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 21:52:01 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 21:52:01 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 21:52:01 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 21:52:01 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 21:52:01 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 21:52:01 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 21:52:01 @monitor.py:363][0m lr: 1.7764e-18
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 21:52:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 21:52:01 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0418 21:52:01 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0418 21:52:01 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0418 21:52:01 @monitor.py:363][0m validation_cost: 18.837
[32m[0418 21:52:01 @monitor.py:363][0m wd_cost: 2.2429e-33
[32m[0418 21:52:01 @group.py:42][0m Callbacks took 115.982 sec in total. InferenceRunner: 115.840sec
[32m[0418 21:52:01 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14308/173481[03:00<33:22,79.48it/s]  9%|8         |14969/173481[03:10<33:14,79.48it/s] 15%|#5        |26168/173481[06:00<34:04,72.05it/s] 15%|#5        |26825/173481[06:10<33:55,72.05it/s] 22%|##2       |38716/173481[09:00<31:41,70.86it/s] 23%|##2       |39597/173481[09:10<31:29,70.86it/s] 30%|##9       |51952/173481[12:00<28:04,72.16it/s] 30%|###       |52740/173481[12:10<27:53,72.16it/s] 38%|###7      |65183/173481[15:00<24:47,72.83it/s] 38%|###8      |66021/173481[15:10<24:35,72.83it/s] 45%|####5     |78358/173481[18:00<21:42,73.00it/s] 46%|####5     |79131/173481[18:11<21:32,73.00it/s] 53%|#####2    |91699/173481[21:00<18:31,73.55it/s] 53%|#####3    |92627/173481[21:11<18:19,73.55it/s] 61%|######    |105363/173481[24:00<15:11,74.71it/s] 61%|######1   |106230/173481[24:11<15:00,74.71it/s] 68%|######8   |118395/173481[27:00<12:29,73.54it/s] 69%|######8   |119199/173481[27:11<12:18,73.54it/s] 76%|#######5  |131071/173481[30:00<09:49,71.95it/s] 76%|#######6  |131969/173481[30:11<09:36,71.95it/s] 83%|########3 |144309/173481[33:00<06:41,72.73it/s] 84%|########3 |145297/173481[33:11<06:27,72.73it/s] 91%|#########1|158585/173481[36:00<03:16,75.88it/s] 92%|#########1|159543/173481[36:12<03:03,75.88it/s] 99%|#########9|172381/173481[39:00<00:14,76.26it/s]100%|#########9|173313/173481[39:12<00:02,76.26it/s]100%|##########|173481/173481[39:14<00:00,73.68it/s]
[32m[0418 22:31:16 @base.py:257][0m Epoch 46 (global_step 23419935) finished, time:2354.62 sec.
[32m[0418 22:31:16 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-23419935.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,165.01it/s]
45
[32m[0418 22:33:10 @monitor.py:363][0m QueueInput/queue_size: 0.53537
[32m[0418 22:33:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0418 22:33:10 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0418 22:33:10 @monitor.py:363][0m cross_entropy_loss: 18.71
[32m[0418 22:33:10 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 22:33:10 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 22:33:10 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 22:33:10 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 22:33:10 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 22:33:10 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 22:33:10 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 22:33:10 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 22:33:10 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 22:33:10 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 22:33:10 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 22:33:10 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 22:33:10 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 22:33:10 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 22:33:10 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 22:33:10 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 22:33:10 @monitor.py:363][0m lr: 1.7764e-18
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 22:33:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 22:33:10 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0418 22:33:10 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0418 22:33:10 @monitor.py:363][0m val-utt-error: 0.97551
[32m[0418 22:33:10 @monitor.py:363][0m validation_cost: 19.032
[32m[0418 22:33:10 @monitor.py:363][0m wd_cost: 2.2429e-33
[32m[0418 22:33:10 @group.py:42][0m Callbacks took 114.268 sec in total. InferenceRunner: 114.082sec
[32m[0418 22:33:10 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14647/173481[03:00<32:32,81.37it/s]  9%|8         |15450/173481[03:10<32:22,81.37it/s] 16%|#6        |28537/173481[06:00<30:30,79.20it/s] 17%|#6        |29343/173481[06:10<30:19,79.20it/s] 25%|##4       |43065/173481[09:00<27:11,79.95it/s] 25%|##5       |44043/173481[09:10<26:59,79.95it/s] 35%|###5      |60973/173481[12:00<21:09,88.65it/s] 36%|###5      |61891/173481[12:10<20:58,88.65it/s] 44%|####3     |75565/173481[15:00<19:16,84.69it/s] 44%|####4     |76404/173481[15:10<19:06,84.69it/s] 52%|#####1    |89797/173481[18:00<17:03,81.78it/s] 52%|#####2    |90627/173481[18:10<16:53,81.78it/s] 60%|#####9    |103735/173481[21:00<14:37,79.51it/s] 60%|######    |104583/173481[21:11<14:26,79.51it/s] 68%|######7   |117548/173481[24:00<11:56,78.10it/s] 68%|######8   |118410/173481[24:11<11:45,78.10it/s] 77%|#######6  |132860/173481[27:00<08:18,81.43it/s] 77%|#######7  |133926/173481[27:11<08:05,81.43it/s] 85%|########4 |147443/173481[30:00<05:20,81.22it/s] 85%|########5 |148240/173481[30:11<05:10,81.22it/s] 93%|#########2|161269/173481[33:00<02:34,78.95it/s] 93%|#########3|162096/173481[33:11<02:24,78.95it/s]100%|##########|173481/173481[35:26<00:00,81.59it/s]
[32m[0418 23:08:36 @base.py:257][0m Epoch 47 (global_step 23593416) finished, time:2126.32 sec.
[32m[0418 23:08:36 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-23593416.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.42it/s]
46
[32m[0418 23:10:30 @monitor.py:363][0m QueueInput/queue_size: 2.0034
[32m[0418 23:10:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0418 23:10:30 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0418 23:10:30 @monitor.py:363][0m cross_entropy_loss: 18.841
[32m[0418 23:10:30 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 23:10:30 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 23:10:30 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 23:10:30 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 23:10:30 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 23:10:30 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 23:10:30 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 23:10:30 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 23:10:30 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 23:10:30 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 23:10:30 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 23:10:30 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 23:10:30 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 23:10:30 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 23:10:30 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 23:10:30 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 23:10:30 @monitor.py:363][0m lr: 1.7764e-18
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 23:10:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 23:10:30 @monitor.py:363][0m train-error-top1: 0.98766
[32m[0418 23:10:30 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0418 23:10:30 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0418 23:10:30 @monitor.py:363][0m validation_cost: 18.777
[32m[0418 23:10:30 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0418 23:10:30 @group.py:42][0m Callbacks took 113.990 sec in total. InferenceRunner: 113.797sec
[32m[0418 23:10:30 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14998/173481[03:00<31:42,83.31it/s]  9%|9         |15861/173481[03:10<31:31,83.31it/s] 17%|#6        |29038/173481[06:00<29:53,80.56it/s] 17%|#7        |29846/173481[06:10<29:42,80.56it/s] 25%|##4       |43156/173481[09:00<27:19,79.48it/s] 25%|##5       |43969/173481[09:10<27:09,79.48it/s] 33%|###2      |57191/173481[12:00<24:37,78.72it/s] 33%|###3      |58023/173481[12:10<24:26,78.72it/s] 41%|####      |71098/173481[15:00<21:52,77.98it/s] 41%|####1     |71832/173481[15:10<21:43,77.98it/s] 48%|####8     |83817/173481[18:00<20:09,74.13it/s] 49%|####8     |84730/173481[18:10<19:57,74.13it/s] 56%|#####6    |97659/173481[21:00<16:44,75.49it/s] 57%|#####6    |98378/173481[21:11<16:34,75.49it/s] 64%|######3   |110990/173481[24:00<13:55,74.77it/s] 64%|######4   |111632/173481[24:11<13:47,74.77it/s] 71%|#######   |122524/173481[27:00<12:18,69.00it/s] 71%|#######1  |123339/173481[27:11<12:06,69.00it/s] 74%|#######4  |129070/173481[30:00<15:32,47.63it/s] 75%|#######4  |129880/173481[30:11<15:15,47.63it/s] 82%|########2 |142666/173481[33:00<08:47,58.42it/s] 83%|########2 |143553/173481[33:11<08:32,58.42it/s] 90%|########9 |155998/173481[36:00<04:27,65.31it/s] 90%|######### |156876/173481[36:11<04:14,65.31it/s] 98%|#########7|169464/173481[39:00<00:57,69.74it/s] 98%|#########8|170323/173481[39:12<00:45,69.74it/s]100%|##########|173481/173481[39:51<00:00,72.53it/s]
[32m[0418 23:50:22 @base.py:257][0m Epoch 48 (global_step 23766897) finished, time:2391.72 sec.
[32m[0418 23:50:22 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-23766897.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.82it/s]
47
[32m[0418 23:52:17 @monitor.py:363][0m QueueInput/queue_size: 0.73083
[32m[0418 23:52:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0418 23:52:17 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0418 23:52:17 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0418 23:52:17 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0418 23:52:17 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0418 23:52:17 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0418 23:52:17 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0418 23:52:17 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0418 23:52:17 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0418 23:52:17 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0418 23:52:17 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0418 23:52:17 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0418 23:52:17 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0418 23:52:17 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0418 23:52:17 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0418 23:52:17 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0418 23:52:17 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0418 23:52:17 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0418 23:52:17 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0418 23:52:17 @monitor.py:363][0m lr: 8.8818e-19
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0418 23:52:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0418 23:52:17 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0418 23:52:17 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0418 23:52:17 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0418 23:52:17 @monitor.py:363][0m validation_cost: 18.665
[32m[0418 23:52:17 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0418 23:52:17 @group.py:42][0m Callbacks took 115.123 sec in total. InferenceRunner: 114.910sec
[32m[0418 23:52:17 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14258/173481[03:00<33:30,79.21it/s]  9%|8         |15105/173481[03:10<33:19,79.21it/s] 17%|#6        |28637/173481[06:00<30:20,79.55it/s] 17%|#6        |29368/173481[06:10<30:11,79.55it/s] 24%|##4       |42333/173481[09:00<28:06,77.78it/s] 25%|##4       |43095/173481[09:10<27:56,77.78it/s] 32%|###2      |55624/173481[12:00<25:55,75.76it/s] 33%|###2      |56387/173481[12:10<25:45,75.76it/s] 39%|###9      |68262/173481[15:00<24:03,72.88it/s] 40%|###9      |69064/173481[15:10<23:52,72.88it/s] 47%|####7     |81627/173481[18:00<20:48,73.56it/s] 47%|####7     |82366/173481[18:10<20:38,73.56it/s] 54%|#####3    |93662/173481[21:00<18:59,70.05it/s] 54%|#####4    |94450/173481[21:11<18:48,70.05it/s] 61%|######1   |106170/173481[24:00<16:04,69.77it/s] 62%|######1   |106950/173481[24:11<15:53,69.77it/s] 68%|######8   |118539/173481[27:00<13:13,69.24it/s] 69%|######8   |119356/173481[27:11<13:01,69.24it/s] 75%|#######5  |130974/173481[30:00<10:14,69.16it/s] 76%|#######5  |131792/173481[30:11<10:02,69.16it/s] 83%|########2 |143599/173481[33:00<07:09,69.64it/s] 83%|########3 |144408/173481[33:11<06:57,69.64it/s] 90%|########9 |155965/173481[36:00<04:13,69.16it/s] 90%|######### |156744/173481[36:11<04:01,69.16it/s] 97%|#########6|168075/173481[39:00<01:19,68.21it/s] 97%|#########7|168934/173481[39:12<01:06,68.21it/s]100%|##########|173481/173481[40:12<00:00,71.92it/s]
[32m[0419 00:32:29 @base.py:257][0m Epoch 49 (global_step 23940378) finished, time:2412.27 sec.
[32m[0419 00:32:29 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-23940378.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.41it/s]
48
[32m[0419 00:34:26 @monitor.py:363][0m QueueInput/queue_size: 0.39168
[32m[0419 00:34:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0419 00:34:26 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0419 00:34:26 @monitor.py:363][0m cross_entropy_loss: 18.463
[32m[0419 00:34:26 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 00:34:26 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 00:34:26 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 00:34:26 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 00:34:26 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 00:34:26 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 00:34:26 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 00:34:26 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 00:34:26 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 00:34:26 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 00:34:26 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 00:34:26 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 00:34:26 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 00:34:26 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 00:34:26 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 00:34:26 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 00:34:26 @monitor.py:363][0m lr: 8.8818e-19
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 00:34:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 00:34:26 @monitor.py:363][0m train-error-top1: 0.98367
[32m[0419 00:34:26 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0419 00:34:26 @monitor.py:363][0m val-utt-error: 0.97359
[32m[0419 00:34:26 @monitor.py:363][0m validation_cost: 18.76
[32m[0419 00:34:26 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 00:34:26 @group.py:42][0m Callbacks took 116.757 sec in total. InferenceRunner: 116.625sec
[32m[0419 00:34:26 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13144/173481[03:00<36:36,73.01it/s]  8%|8         |13906/173481[03:10<36:25,73.01it/s] 15%|#4        |25648/173481[06:00<34:36,71.19it/s] 15%|#5        |26344/173481[06:10<34:26,71.19it/s] 22%|##1       |38164/173481[09:00<32:03,70.34it/s] 22%|##2       |38853/173481[09:10<31:53,70.34it/s] 29%|##9       |50590/173481[12:00<29:23,69.67it/s] 30%|##9       |51307/173481[12:10<29:13,69.67it/s] 36%|###6      |62808/173481[15:00<26:49,68.76it/s] 37%|###6      |63557/173481[15:10<26:38,68.76it/s] 43%|####2     |73912/173481[18:00<25:31,65.02it/s] 43%|####2     |74535/173481[18:11<25:21,65.02it/s] 49%|####8     |84436/173481[21:00<24:06,61.57it/s] 49%|####9     |85106/173481[21:11<23:55,61.57it/s] 55%|#####5    |96094/173481[24:00<20:26,63.11it/s] 56%|#####5    |96807/173481[24:11<20:14,63.11it/s] 63%|######2   |108517/173481[27:00<16:25,65.93it/s] 63%|######3   |109329/173481[27:11<16:13,65.93it/s] 70%|######9   |121198/173481[30:00<12:47,68.11it/s] 70%|#######   |122013/173481[30:11<12:35,68.11it/s] 77%|#######7  |134219/173481[33:00<09:19,70.16it/s] 78%|#######7  |135047/173481[33:11<09:07,70.16it/s] 85%|########4 |147336/173481[36:00<06:05,71.49it/s] 85%|########5 |148108/173481[36:11<05:54,71.49it/s] 92%|#########2|160219/173481[39:00<03:05,71.53it/s] 93%|#########2|161152/173481[39:12<02:52,71.53it/s]100%|##########|173481/173481[41:59<00:00,68.85it/s]
[32m[0419 01:16:26 @base.py:257][0m Epoch 50 (global_step 24113859) finished, time:2519.53 sec.
[32m[0419 01:16:26 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-24113859.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.09it/s]
49
[32m[0419 01:18:21 @monitor.py:363][0m QueueInput/queue_size: 0.89355
[32m[0419 01:18:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0419 01:18:21 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0419 01:18:21 @monitor.py:363][0m cross_entropy_loss: 18.553
[32m[0419 01:18:21 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 01:18:21 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 01:18:21 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 01:18:21 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 01:18:21 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 01:18:21 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 01:18:21 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 01:18:21 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 01:18:21 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 01:18:21 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 01:18:21 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 01:18:21 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 01:18:21 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 01:18:21 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 01:18:21 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 01:18:21 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 01:18:21 @monitor.py:363][0m lr: 4.4409e-19
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 01:18:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 01:18:21 @monitor.py:363][0m train-error-top1: 0.98489
[32m[0419 01:18:21 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0419 01:18:21 @monitor.py:363][0m val-utt-error: 0.97375
[32m[0419 01:18:21 @monitor.py:363][0m validation_cost: 18.69
[32m[0419 01:18:21 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 01:18:21 @group.py:42][0m Callbacks took 115.628 sec in total. InferenceRunner: 115.425sec
[32m[0419 01:18:21 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12646/173481[03:00<38:09,70.25it/s]  8%|7         |13263/173481[03:10<38:00,70.25it/s] 14%|#4        |25074/173481[06:00<35:30,69.64it/s] 15%|#4        |25794/173481[06:10<35:20,69.64it/s] 22%|##1       |37766/173481[09:00<32:16,70.07it/s] 22%|##2       |38480/173481[09:10<32:06,70.07it/s] 29%|##9       |50684/173481[12:00<28:51,70.91it/s] 30%|##9       |51457/173481[12:10<28:40,70.91it/s] 37%|###6      |63589/173481[15:00<25:41,71.30it/s] 37%|###7      |64365/173481[15:10<25:30,71.30it/s] 44%|####4     |76471/173481[18:00<22:38,71.43it/s] 45%|####4     |77321/173481[18:11<22:26,71.43it/s] 52%|#####1    |90049/173481[21:00<18:57,73.38it/s] 52%|#####2    |90943/173481[21:11<18:44,73.38it/s] 60%|#####9    |103926/173481[24:00<15:25,75.19it/s] 60%|######    |104704/173481[24:11<15:14,75.19it/s] 68%|######7   |117267/173481[27:00<12:33,74.65it/s] 68%|######8   |118230/173481[27:11<12:20,74.65it/s] 77%|#######7  |134334/173481[30:00<07:48,83.53it/s] 78%|#######8  |135536/173481[30:11<07:34,83.53it/s] 89%|########9 |154789/173481[33:00<03:14,96.24it/s] 90%|######### |156158/173481[33:11<02:59,96.24it/s]100%|##########|173481/173481[35:31<00:00,81.39it/s]
[32m[0419 01:53:53 @base.py:257][0m Epoch 51 (global_step 24287340) finished, time:2131.40 sec.
[32m[0419 01:53:53 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-24287340.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.53it/s]
50
[32m[0419 01:55:49 @monitor.py:363][0m QueueInput/queue_size: 49.951
[32m[0419 01:55:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0419 01:55:49 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0419 01:55:49 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0419 01:55:49 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 01:55:49 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 01:55:49 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 01:55:49 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 01:55:49 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 01:55:49 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 01:55:49 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 01:55:49 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 01:55:49 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 01:55:49 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 01:55:49 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 01:55:49 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 01:55:49 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 01:55:49 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 01:55:49 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 01:55:49 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 01:55:49 @monitor.py:363][0m lr: 4.4409e-19
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 01:55:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 01:55:49 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0419 01:55:49 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0419 01:55:49 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0419 01:55:49 @monitor.py:363][0m validation_cost: 18.835
[32m[0419 01:55:49 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 01:55:49 @group.py:42][0m Callbacks took 116.714 sec in total. InferenceRunner: 116.544sec
[32m[0419 01:55:49 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s] 13%|#2        |22268/173481[03:00<20:22,123.71it/s] 14%|#3        |23553/173481[03:10<20:11,123.71it/s] 23%|##2       |39736/173481[06:00<20:29,108.77it/s] 23%|##3       |40468/173481[06:10<20:22,108.77it/s] 31%|###       |52958/173481[09:00<22:54,87.69it/s]  31%|###       |53754/173481[09:10<22:45,87.69it/s] 38%|###8      |66493/173481[12:00<22:01,80.96it/s] 39%|###8      |67337/173481[12:10<21:51,80.96it/s] 46%|####6     |80552/173481[15:00<19:28,79.51it/s] 47%|####6     |81374/173481[15:10<19:18,79.51it/s] 54%|#####4    |94484/173481[18:00<16:47,78.44it/s] 55%|#####4    |95362/173481[18:10<16:35,78.44it/s] 63%|######2   |108603/173481[21:00<13:47,78.43it/s] 63%|######3   |109461/173481[21:11<13:36,78.43it/s] 70%|#######   |122032/173481[24:00<11:12,76.47it/s] 71%|#######   |122828/173481[24:11<11:02,76.47it/s] 78%|#######7  |134925/173481[27:00<08:41,73.97it/s] 78%|#######8  |135779/173481[27:11<08:29,73.97it/s] 86%|########5 |148846/173481[30:00<05:25,75.61it/s] 86%|########6 |149692/173481[30:11<05:14,75.61it/s] 94%|#########3|162653/173481[33:00<02:22,76.16it/s] 94%|#########4|163569/173481[33:11<02:10,76.16it/s]100%|##########|173481/173481[35:24<00:00,81.64it/s]
[32m[0419 02:31:14 @base.py:257][0m Epoch 52 (global_step 24460821) finished, time:2124.88 sec.
[32m[0419 02:31:14 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-24460821.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,168.98it/s]
51
[32m[0419 02:33:06 @monitor.py:363][0m QueueInput/queue_size: 0.51061
[32m[0419 02:33:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0419 02:33:06 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0419 02:33:06 @monitor.py:363][0m cross_entropy_loss: 18.71
[32m[0419 02:33:06 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 02:33:06 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 02:33:06 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 02:33:06 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 02:33:06 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 02:33:06 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 02:33:06 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 02:33:06 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 02:33:06 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 02:33:06 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 02:33:06 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 02:33:06 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 02:33:06 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 02:33:06 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 02:33:06 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 02:33:06 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 02:33:06 @monitor.py:363][0m lr: 4.4409e-19
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 02:33:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 02:33:06 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0419 02:33:06 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0419 02:33:06 @monitor.py:363][0m val-utt-error: 0.97551
[32m[0419 02:33:06 @monitor.py:363][0m validation_cost: 19.032
[32m[0419 02:33:06 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 02:33:06 @group.py:42][0m Callbacks took 111.582 sec in total. InferenceRunner: 111.410sec
[32m[0419 02:33:06 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14174/173481[03:00<33:43,78.74it/s]  9%|8         |14928/173481[03:10<33:33,78.74it/s] 16%|#5        |27571/173481[06:00<31:46,76.51it/s] 16%|#6        |28321/173481[06:10<31:37,76.51it/s] 24%|##3       |41119/173481[09:00<29:04,75.88it/s] 24%|##4       |42132/173481[09:10<28:51,75.88it/s] 34%|###3      |58177/173481[12:00<22:48,84.28it/s] 34%|###4      |59057/173481[12:10<22:37,84.28it/s] 42%|####1     |72493/173481[15:00<20:34,81.82it/s] 42%|####2     |73264/173481[15:10<20:24,81.82it/s] 50%|####9     |86533/173481[18:00<18:08,79.86it/s] 50%|#####     |87398/173481[18:11<17:57,79.86it/s] 58%|#####8    |100830/173481[21:00<15:12,79.64it/s] 59%|#####8    |101663/173481[21:11<15:01,79.64it/s] 66%|######6   |114724/173481[24:00<12:29,78.39it/s] 67%|######6   |115632/173481[24:11<12:17,78.39it/s] 75%|#######4  |129649/173481[27:00<09:03,80.59it/s] 75%|#######5  |130519/173481[27:11<08:53,80.59it/s] 83%|########3 |144330/173481[30:00<05:59,81.07it/s] 84%|########3 |145305/173481[30:11<05:47,81.07it/s] 91%|#########1|158089/173481[33:00<03:15,78.68it/s] 92%|#########1|159076/173481[33:11<03:03,78.68it/s]100%|#########9|173096/173481[36:00<00:04,80.96it/s]100%|##########|173481/173481[36:04<00:00,80.16it/s]
[32m[0419 03:09:10 @base.py:257][0m Epoch 53 (global_step 24634302) finished, time:2164.18 sec.
[32m[0419 03:09:11 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-24634302.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.23it/s]
52
[32m[0419 03:11:05 @monitor.py:363][0m QueueInput/queue_size: 2.5127
[32m[0419 03:11:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0419 03:11:05 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0419 03:11:05 @monitor.py:363][0m cross_entropy_loss: 18.841
[32m[0419 03:11:05 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 03:11:05 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 03:11:05 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 03:11:05 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 03:11:05 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 03:11:05 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 03:11:05 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 03:11:05 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 03:11:05 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 03:11:05 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 03:11:05 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 03:11:05 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 03:11:05 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 03:11:05 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 03:11:05 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 03:11:05 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 03:11:05 @monitor.py:363][0m lr: 2.2204e-19
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 03:11:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 03:11:05 @monitor.py:363][0m train-error-top1: 0.98766
[32m[0419 03:11:05 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0419 03:11:05 @monitor.py:363][0m val-utt-error: 0.9745
[32m[0419 03:11:05 @monitor.py:363][0m validation_cost: 18.773
[32m[0419 03:11:05 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 03:11:05 @group.py:42][0m Callbacks took 114.210 sec in total. InferenceRunner: 113.927sec
[32m[0419 03:11:05 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14790/173481[03:00<32:11,82.17it/s]  9%|8         |15591/173481[03:10<32:01,82.17it/s] 17%|#6        |28724/173481[06:00<30:15,79.72it/s] 17%|#7        |29541/173481[06:10<30:05,79.72it/s] 25%|##4       |42766/173481[09:00<27:37,78.85it/s] 25%|##5       |43528/173481[09:10<27:28,78.85it/s] 33%|###2      |56815/173481[12:00<24:47,78.45it/s] 33%|###3      |57653/173481[12:10<24:36,78.45it/s] 41%|####      |70874/173481[15:00<21:50,78.28it/s] 41%|####1     |71709/173481[15:10<21:40,78.28it/s] 49%|####9     |85044/173481[18:00<18:46,78.50it/s] 50%|####9     |85889/173481[18:11<18:35,78.50it/s] 57%|#####7    |99005/173481[21:00<15:54,78.03it/s] 58%|#####7    |99872/173481[21:11<15:43,78.03it/s] 65%|######5   |112804/173481[24:00<13:04,77.34it/s] 66%|######5   |113677/173481[24:11<12:53,77.34it/s] 73%|#######3  |126690/173481[27:00<10:05,77.24it/s] 74%|#######3  |127556/173481[27:11<09:54,77.24it/s] 81%|########1 |140554/173481[30:00<07:06,77.13it/s] 82%|########1 |141457/173481[30:11<06:55,77.13it/s] 89%|########8 |154330/173481[33:00<04:09,76.83it/s] 89%|########9 |155229/173481[33:11<03:57,76.83it/s] 97%|#########6|168112/173481[36:00<01:10,76.70it/s] 97%|#########7|169031/173481[36:11<00:58,76.70it/s]100%|##########|173481/173481[37:07<00:00,77.87it/s]
[32m[0419 03:48:12 @base.py:257][0m Epoch 54 (global_step 24807783) finished, time:2227.73 sec.
[32m[0419 03:48:12 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-24807783.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.82it/s]
53
[32m[0419 03:50:10 @monitor.py:363][0m QueueInput/queue_size: 0.84059
[32m[0419 03:50:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0419 03:50:10 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0419 03:50:10 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0419 03:50:10 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 03:50:10 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 03:50:10 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 03:50:10 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 03:50:10 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 03:50:10 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 03:50:10 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 03:50:10 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 03:50:10 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 03:50:10 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 03:50:10 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 03:50:10 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 03:50:10 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 03:50:10 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 03:50:10 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 03:50:10 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 03:50:10 @monitor.py:363][0m lr: 2.2204e-19
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 03:50:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 03:50:10 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0419 03:50:10 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0419 03:50:10 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0419 03:50:10 @monitor.py:363][0m validation_cost: 18.665
[32m[0419 03:50:10 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 03:50:10 @group.py:42][0m Callbacks took 117.237 sec in total. InferenceRunner: 117.057sec
[32m[0419 03:50:10 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12606/173481[03:00<38:17,70.03it/s]  8%|7         |13200/173481[03:10<38:08,70.03it/s] 15%|#4        |25609/173481[06:00<34:39,71.12it/s] 15%|#5        |26388/173481[06:10<34:28,71.12it/s] 22%|##2       |38239/173481[09:00<31:54,70.63it/s] 22%|##2       |38907/173481[09:10<31:45,70.63it/s] 28%|##8       |49315/173481[12:00<31:28,65.76it/s] 29%|##8       |50048/173481[12:10<31:16,65.76it/s] 36%|###5      |61891/173481[15:00<27:27,67.74it/s] 36%|###6      |62564/173481[15:10<27:17,67.74it/s] 43%|####2     |74456/173481[18:00<24:00,68.76it/s] 43%|####3     |75204/173481[18:10<23:49,68.76it/s] 50%|#####     |87495/173481[21:00<20:18,70.55it/s] 51%|#####     |88243/173481[21:11<20:08,70.55it/s] 57%|#####7    |99697/173481[24:00<17:47,69.14it/s] 58%|#####7    |100464/173481[24:11<17:36,69.14it/s] 64%|######4   |111871/173481[27:00<15:01,68.38it/s] 65%|######4   |112590/173481[27:11<14:50,68.38it/s] 71%|#######1  |123842/173481[30:00<12:16,67.43it/s] 72%|#######1  |124595/173481[30:11<12:05,67.43it/s] 78%|#######7  |135181/173481[33:00<09:48,65.13it/s] 78%|#######8  |135857/173481[33:11<09:37,65.13it/s] 85%|########4 |146597/173481[36:00<06:58,64.26it/s] 85%|########4 |147366/173481[36:11<06:46,64.26it/s] 92%|#########1|158995/173481[39:00<03:37,66.49it/s] 92%|#########2|159745/173481[39:12<03:26,66.49it/s] 99%|#########8|171163/173481[42:00<00:34,67.03it/s] 99%|#########9|172019/173481[42:12<00:21,67.03it/s]100%|##########|173481/173481[42:31<00:00,68.00it/s]
[32m[0419 04:32:41 @base.py:257][0m Epoch 55 (global_step 24981264) finished, time:2551.09 sec.
[32m[0419 04:32:41 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-24981264.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.16it/s]
54
[32m[0419 04:34:38 @monitor.py:363][0m QueueInput/queue_size: 0.40369
[32m[0419 04:34:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0419 04:34:38 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0419 04:34:38 @monitor.py:363][0m cross_entropy_loss: 18.463
[32m[0419 04:34:38 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 04:34:38 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 04:34:38 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 04:34:38 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 04:34:38 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 04:34:38 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 04:34:38 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 04:34:38 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 04:34:38 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 04:34:38 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 04:34:38 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 04:34:38 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 04:34:38 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 04:34:38 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 04:34:38 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 04:34:38 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 04:34:38 @monitor.py:363][0m lr: 2.2204e-19
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 04:34:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 04:34:38 @monitor.py:363][0m train-error-top1: 0.98367
[32m[0419 04:34:38 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0419 04:34:38 @monitor.py:363][0m val-utt-error: 0.97359
[32m[0419 04:34:38 @monitor.py:363][0m validation_cost: 18.76
[32m[0419 04:34:38 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 04:34:38 @group.py:42][0m Callbacks took 116.986 sec in total. InferenceRunner: 116.807sec
[32m[0419 04:34:38 @base.py:247][0m Start Epoch 56 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11650/173481[03:00<41:41,64.71it/s]  7%|7         |12292/173481[03:10<41:31,64.71it/s] 14%|#3        |23632/173481[06:00<38:03,65.62it/s] 14%|#4        |24383/173481[06:10<37:52,65.62it/s] 20%|##        |35521/173481[09:00<34:55,65.83it/s] 21%|##        |36246/173481[09:10<34:44,65.83it/s] 27%|##7       |47514/173481[12:00<31:42,66.23it/s] 28%|##7       |48183/173481[12:10<31:31,66.23it/s] 35%|###4      |60203/173481[15:00<27:38,68.29it/s] 35%|###5      |61019/173481[15:10<27:26,68.29it/s] 43%|####2     |74130/173481[18:00<22:49,72.55it/s] 43%|####3     |74871/173481[18:11<22:39,72.55it/s] 49%|####9     |85430/173481[21:00<21:48,67.31it/s] 50%|####9     |86165/173481[21:11<21:37,67.31it/s] 56%|#####6    |97793/173481[24:00<18:33,67.99it/s] 57%|#####6    |98646/173481[24:11<18:20,67.99it/s] 64%|######3   |110636/173481[27:00<15:02,69.62it/s] 64%|######4   |111299/173481[27:11<14:53,69.62it/s] 71%|#######1  |123334/173481[30:00<11:55,70.08it/s] 72%|#######1  |124191/173481[30:11<11:43,70.08it/s] 78%|#######8  |135972/173481[33:00<08:54,70.14it/s] 79%|#######8  |136785/173481[33:11<08:43,70.14it/s] 86%|########5 |148666/173481[36:00<05:52,70.33it/s] 86%|########6 |149526/173481[36:12<05:40,70.33it/s] 93%|#########3|161676/173481[39:00<02:45,71.29it/s] 94%|#########3|162498/173481[39:12<02:34,71.29it/s]100%|##########|173481/173481[41:45<00:00,69.24it/s]
[32m[0419 05:16:23 @base.py:257][0m Epoch 56 (global_step 25154745) finished, time:2505.53 sec.
[32m[0419 05:16:23 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-25154745.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,162.69it/s]
55
[32m[0419 05:18:19 @monitor.py:363][0m QueueInput/queue_size: 0.64674
[32m[0419 05:18:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0419 05:18:19 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0419 05:18:19 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0419 05:18:19 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 05:18:19 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 05:18:19 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 05:18:19 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 05:18:19 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 05:18:19 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 05:18:19 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 05:18:19 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 05:18:19 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 05:18:19 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 05:18:19 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 05:18:19 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 05:18:19 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 05:18:19 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 05:18:19 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 05:18:19 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 05:18:19 @monitor.py:363][0m lr: 1.1102e-19
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 05:18:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 05:18:19 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0419 05:18:19 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0419 05:18:19 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0419 05:18:19 @monitor.py:363][0m validation_cost: 18.675
[32m[0419 05:18:19 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 05:18:19 @group.py:42][0m Callbacks took 115.893 sec in total. InferenceRunner: 115.710sec
[32m[0419 05:18:19 @base.py:247][0m Start Epoch 57 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13074/173481[03:00<36:48,72.63it/s]  8%|7         |13737/173481[03:10<36:39,72.63it/s] 15%|#4        |25658/173481[06:00<34:34,71.24it/s] 15%|#5        |26411/173481[06:10<34:24,71.24it/s] 22%|##2       |38694/173481[09:00<31:16,71.82it/s] 23%|##2       |39434/173481[09:10<31:06,71.82it/s] 30%|##9       |51335/173481[12:00<28:39,71.02it/s] 30%|###       |52092/173481[12:10<28:29,71.02it/s] 37%|###7      |64490/173481[15:00<25:13,72.03it/s] 38%|###7      |65251/173481[15:10<25:02,72.03it/s] 44%|####3     |76321/173481[18:00<23:33,68.73it/s] 44%|####4     |77046/173481[18:11<23:23,68.73it/s] 51%|#####1    |88981/173481[21:00<20:15,69.52it/s] 52%|#####1    |89779/173481[21:11<20:03,69.52it/s] 59%|#####9    |102891/173481[24:00<16:04,73.19it/s] 60%|#####9    |103596/173481[24:11<15:54,73.19it/s] 66%|######6   |115009/173481[27:00<13:53,70.13it/s] 67%|######6   |115800/173481[27:11<13:42,70.13it/s] 74%|#######3  |128031/173481[30:00<10:38,71.22it/s] 74%|#######4  |128852/173481[30:11<10:26,71.22it/s] 81%|########1 |140827/173481[33:00<07:38,71.15it/s] 82%|########1 |141675/173481[33:11<07:27,71.15it/s] 89%|########8 |154009/173481[36:00<04:29,72.18it/s] 89%|########9 |154940/173481[36:12<04:16,72.18it/s] 97%|#########7|168659/173481[39:00<01:03,76.51it/s] 98%|#########7|169674/173481[39:12<00:49,76.51it/s]100%|##########|173481/173481[39:59<00:00,72.31it/s]
[32m[0419 05:58:18 @base.py:257][0m Epoch 57 (global_step 25328226) finished, time:2399.23 sec.
[32m[0419 05:58:18 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-25328226.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,162.67it/s]
56
[32m[0419 06:00:14 @monitor.py:363][0m QueueInput/queue_size: 0.74466
[32m[0419 06:00:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0419 06:00:14 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0419 06:00:14 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0419 06:00:14 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 06:00:14 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 06:00:14 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 06:00:14 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 06:00:14 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 06:00:14 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 06:00:14 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 06:00:14 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 06:00:14 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 06:00:14 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 06:00:14 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 06:00:14 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 06:00:14 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 06:00:14 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 06:00:14 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 06:00:14 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 06:00:14 @monitor.py:363][0m lr: 1.1102e-19
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 06:00:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 06:00:14 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0419 06:00:14 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0419 06:00:14 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0419 06:00:14 @monitor.py:363][0m validation_cost: 18.837
[32m[0419 06:00:14 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 06:00:14 @group.py:42][0m Callbacks took 115.905 sec in total. InferenceRunner: 115.725sec
[32m[0419 06:00:14 @base.py:247][0m Start Epoch 58 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14983/173481[03:00<31:44,83.24it/s]  9%|9         |15747/173481[03:10<31:35,83.24it/s] 17%|#6        |28816/173481[06:00<30:10,79.91it/s] 17%|#7        |29642/173481[06:10<30:00,79.91it/s] 25%|##5       |43417/173481[09:00<26:55,80.51it/s] 25%|##5       |44201/173481[09:10<26:45,80.51it/s] 33%|###2      |57059/173481[12:00<24:51,78.08it/s] 33%|###3      |57953/173481[12:10<24:39,78.08it/s] 41%|####1     |71476/173481[15:00<21:30,79.07it/s] 42%|####1     |72360/173481[15:10<21:18,79.07it/s] 50%|####9     |86601/173481[18:00<17:46,81.47it/s] 50%|#####     |87500/173481[18:11<17:35,81.47it/s] 58%|#####8    |101392/173481[21:00<14:41,81.82it/s] 59%|#####8    |102261/173481[21:11<14:30,81.82it/s] 67%|######6   |115982/173481[24:00<11:46,81.43it/s] 67%|######7   |116841/173481[24:11<11:35,81.43it/s] 75%|#######4  |129477/173481[27:00<09:23,78.07it/s] 75%|#######5  |130368/173481[27:11<09:12,78.07it/s] 82%|########2 |142582/173481[30:00<06:50,75.34it/s] 83%|########2 |143469/173481[30:11<06:38,75.34it/s] 90%|######### |156310/173481[33:00<03:46,75.79it/s] 91%|######### |157265/173481[33:11<03:33,75.79it/s] 98%|#########8|170079/173481[36:00<00:44,76.14it/s] 98%|#########8|170842/173481[36:12<00:34,76.14it/s]100%|##########|173481/173481[36:53<00:00,78.39it/s]
[32m[0419 06:37:07 @base.py:257][0m Epoch 58 (global_step 25501707) finished, time:2213.03 sec.
[32m[0419 06:37:07 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-25501707.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,168.99it/s]
57
[32m[0419 06:38:59 @monitor.py:363][0m QueueInput/queue_size: 0.3493
[32m[0419 06:38:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0419 06:38:59 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0419 06:38:59 @monitor.py:363][0m cross_entropy_loss: 18.659
[32m[0419 06:38:59 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 06:38:59 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 06:38:59 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 06:38:59 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 06:38:59 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 06:38:59 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 06:38:59 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 06:38:59 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 06:38:59 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 06:38:59 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 06:38:59 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 06:38:59 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 06:38:59 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 06:38:59 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 06:38:59 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 06:38:59 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 06:38:59 @monitor.py:363][0m lr: 5.5511e-20
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 06:38:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 06:38:59 @monitor.py:363][0m train-error-top1: 0.98779
[32m[0419 06:38:59 @monitor.py:363][0m val-error-top1: 0.98539
[32m[0419 06:38:59 @monitor.py:363][0m val-utt-error: 0.97482
[32m[0419 06:38:59 @monitor.py:363][0m validation_cost: 18.971
[32m[0419 06:38:59 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 06:38:59 @group.py:42][0m Callbacks took 111.556 sec in total. InferenceRunner: 111.389sec
[32m[0419 06:38:59 @base.py:247][0m Start Epoch 59 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14323/173481[03:00<33:20,79.56it/s]  9%|8         |15041/173481[03:10<33:11,79.56it/s] 16%|#5        |27074/173481[06:00<32:33,74.95it/s] 16%|#6        |27849/173481[06:10<32:23,74.95it/s] 24%|##3       |40933/173481[09:00<29:05,75.95it/s] 24%|##4       |41931/173481[09:10<28:52,75.95it/s] 34%|###3      |58215/173481[12:00<22:39,84.81it/s] 34%|###4      |59150/173481[12:10<22:28,84.81it/s] 43%|####2     |74042/173481[15:00<19:11,86.34it/s] 43%|####3     |74852/173481[15:10<19:02,86.34it/s] 51%|#####1    |88933/173481[18:00<16:40,84.47it/s] 52%|#####1    |89827/173481[18:11<16:30,84.47it/s] 59%|#####9    |103180/173481[21:00<14:20,81.72it/s] 60%|#####9    |103999/173481[21:11<14:10,81.72it/s] 68%|######7   |117529/173481[24:00<11:33,80.70it/s] 68%|######8   |118434/173481[24:11<11:22,80.70it/s] 77%|#######6  |132967/173481[27:00<08:07,83.15it/s] 77%|#######7  |134022/173481[27:11<07:54,83.15it/s] 85%|########5 |148210/173481[30:00<05:01,83.91it/s] 86%|########6 |149208/173481[30:11<04:49,83.91it/s] 93%|#########3|161947/173481[33:00<02:24,79.93it/s] 94%|#########3|162924/173481[33:11<02:12,79.93it/s]100%|##########|173481/173481[35:18<00:00,81.88it/s]
[32m[0419 07:14:18 @base.py:257][0m Epoch 59 (global_step 25675188) finished, time:2118.74 sec.
[32m[0419 07:14:18 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-25675188.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,168.37it/s]
58
[32m[0419 07:16:09 @monitor.py:363][0m QueueInput/queue_size: 0.96476
[32m[0419 07:16:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0419 07:16:09 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0419 07:16:09 @monitor.py:363][0m cross_entropy_loss: 18.84
[32m[0419 07:16:09 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 07:16:09 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 07:16:09 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 07:16:09 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 07:16:09 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 07:16:09 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 07:16:09 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 07:16:09 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 07:16:09 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 07:16:09 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 07:16:09 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 07:16:09 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 07:16:09 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 07:16:09 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 07:16:09 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 07:16:09 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 07:16:09 @monitor.py:363][0m lr: 5.5511e-20
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 07:16:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 07:16:09 @monitor.py:363][0m train-error-top1: 0.98766
[32m[0419 07:16:09 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0419 07:16:09 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0419 07:16:09 @monitor.py:363][0m validation_cost: 18.777
[32m[0419 07:16:09 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 07:16:09 @group.py:42][0m Callbacks took 111.984 sec in total. InferenceRunner: 111.801sec
[32m[0419 07:16:09 @base.py:247][0m Start Epoch 60 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14470/173481[03:00<32:58,80.39it/s]  9%|8         |15267/173481[03:10<32:48,80.39it/s] 17%|#6        |29075/173481[06:00<29:48,80.76it/s] 17%|#7        |29941/173481[06:10<29:37,80.76it/s] 25%|##5       |43640/173481[09:00<26:46,80.83it/s] 26%|##5       |44487/173481[09:10<26:35,80.83it/s] 33%|###3      |57681/173481[12:00<24:18,79.39it/s] 34%|###3      |58545/173481[12:10<24:07,79.39it/s] 41%|####1     |71671/173481[15:00<21:36,78.54it/s] 42%|####1     |72549/173481[15:10<21:25,78.54it/s] 50%|####9     |85973/173481[18:00<18:27,78.99it/s] 50%|#####     |86919/173481[18:11<18:15,78.99it/s] 58%|#####7    |100605/173481[21:00<15:09,80.12it/s] 59%|#####8    |101488/173481[21:11<14:58,80.12it/s] 66%|######6   |114759/173481[24:00<12:19,79.37it/s] 67%|######6   |115636/173481[24:11<12:08,79.37it/s] 74%|#######4  |128736/173481[27:00<09:30,78.50it/s] 75%|#######4  |129661/173481[27:11<09:18,78.50it/s] 83%|########2 |143456/173481[30:00<06:14,80.10it/s] 83%|########3 |144379/173481[30:11<06:03,80.10it/s] 91%|######### |157468/173481[33:00<03:22,78.96it/s] 91%|#########1|158403/173481[33:11<03:10,78.96it/s] 99%|#########9|172579/173481[36:00<00:11,81.38it/s]100%|##########|173481/173481[36:09<00:00,79.97it/s]
[32m[0419 07:52:19 @base.py:257][0m Epoch 60 (global_step 25848669) finished, time:2169.45 sec.
[32m[0419 07:52:19 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-25848669.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:32<00:00,123.06it/s]
59
[32m[0419 07:54:52 @monitor.py:363][0m QueueInput/queue_size: 0.5923
[32m[0419 07:54:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0419 07:54:52 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0419 07:54:52 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0419 07:54:52 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 07:54:52 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 07:54:52 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 07:54:52 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 07:54:52 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 07:54:52 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 07:54:52 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 07:54:52 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 07:54:52 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 07:54:52 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 07:54:52 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 07:54:52 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 07:54:52 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 07:54:52 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 07:54:52 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 07:54:52 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 07:54:52 @monitor.py:363][0m lr: 5.5511e-20
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 07:54:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 07:54:52 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0419 07:54:52 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0419 07:54:52 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0419 07:54:52 @monitor.py:363][0m validation_cost: 18.665
[32m[0419 07:54:52 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 07:54:52 @group.py:42][0m Callbacks took 153.117 sec in total. InferenceRunner: 152.974sec
[32m[0419 07:54:52 @base.py:247][0m Start Epoch 61 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19555/173481[03:00<23:36,108.63it/s] 12%|#1        |20412/173481[03:10<23:29,108.63it/s] 23%|##2       |39461/173481[06:00<20:22,109.60it/s] 23%|##3       |40686/173481[06:10<20:11,109.60it/s] 35%|###4      |60485/173481[09:00<16:39,113.08it/s] 36%|###5      |61693/173481[09:10<16:28,113.08it/s] 46%|####6     |80557/173481[12:00<13:47,112.26it/s] 47%|####6     |81360/173481[12:10<13:40,112.26it/s] 54%|#####3    |92996/173481[15:00<15:40,85.55it/s]  54%|#####4    |93834/173481[15:10<15:31,85.55it/s] 61%|######    |105456/173481[18:00<14:48,76.52it/s] 61%|######1   |106248/173481[18:11<14:38,76.52it/s] 68%|######7   |117913/173481[21:00<12:44,72.68it/s] 68%|######8   |118695/173481[21:11<12:33,72.68it/s] 75%|#######5  |130741/173481[24:00<09:53,71.96it/s] 76%|#######5  |131526/173481[24:11<09:43,71.96it/s] 83%|########2 |143416/173481[27:00<07:02,71.18it/s] 83%|########3 |144232/173481[27:11<06:50,71.18it/s] 90%|########9 |156045/173481[30:00<04:06,70.67it/s] 90%|######### |156829/173481[30:11<03:55,70.67it/s] 97%|#########6|168196/173481[33:00<01:16,69.05it/s] 97%|#########7|169020/173481[33:11<01:04,69.05it/s]100%|##########|173481/173481[34:11<00:00,84.54it/s]
[32m[0419 08:29:04 @base.py:257][0m Epoch 61 (global_step 26022150) finished, time:2051.99 sec.
[32m[0419 08:29:04 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-26022150.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.75it/s]
60
[32m[0419 08:31:09 @monitor.py:363][0m QueueInput/queue_size: 0.25163
[32m[0419 08:31:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0419 08:31:09 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0419 08:31:09 @monitor.py:363][0m cross_entropy_loss: 18.463
[32m[0419 08:31:09 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 08:31:09 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 08:31:09 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 08:31:09 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 08:31:09 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 08:31:09 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 08:31:09 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 08:31:09 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 08:31:09 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 08:31:09 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 08:31:09 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 08:31:09 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 08:31:09 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 08:31:09 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 08:31:09 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 08:31:09 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 08:31:09 @monitor.py:363][0m lr: 2.7756e-20
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 08:31:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 08:31:09 @monitor.py:363][0m train-error-top1: 0.98367
[32m[0419 08:31:09 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0419 08:31:09 @monitor.py:363][0m val-utt-error: 0.97359
[32m[0419 08:31:09 @monitor.py:363][0m validation_cost: 18.76
[32m[0419 08:31:09 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 08:31:09 @group.py:42][0m Callbacks took 125.133 sec in total. InferenceRunner: 124.879sec
[32m[0419 08:31:09 @base.py:247][0m Start Epoch 62 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13600/173481[03:00<35:16,75.55it/s]  8%|8         |14373/173481[03:10<35:06,75.55it/s] 15%|#5        |26836/173481[06:00<32:47,74.53it/s] 16%|#5        |27595/173481[06:10<32:37,74.53it/s] 23%|##3       |40186/173481[09:00<29:52,74.34it/s] 24%|##3       |40959/173481[09:10<29:42,74.34it/s] 30%|###       |52474/173481[12:00<28:20,71.17it/s] 31%|###       |53188/173481[12:10<28:10,71.17it/s] 38%|###7      |65127/173481[15:00<25:32,70.73it/s] 38%|###7      |65905/173481[15:10<25:21,70.73it/s] 44%|####4     |76810/173481[18:00<23:48,67.69it/s] 45%|####4     |77506/173481[18:11<23:37,67.69it/s] 50%|#####     |87393/173481[21:00<22:48,62.93it/s] 51%|#####     |88159/173481[21:11<22:35,62.93it/s] 58%|#####7    |99754/173481[24:00<18:42,65.67it/s] 58%|#####7    |100546/173481[24:11<18:30,65.67it/s] 65%|######4   |112132/173481[27:00<15:13,67.17it/s] 65%|######5   |112930/173481[27:11<15:01,67.17it/s] 72%|#######2  |124954/173481[30:00<11:41,69.14it/s] 72%|#######2  |125760/173481[30:11<11:30,69.14it/s] 79%|#######9  |137866/173481[33:00<08:25,70.40it/s] 80%|#######9  |138724/173481[33:11<08:13,70.40it/s] 87%|########6 |150910/173481[36:00<05:16,71.42it/s] 87%|########7 |151617/173481[36:11<05:06,71.42it/s] 94%|#########3|162712/173481[39:00<02:37,68.36it/s] 94%|#########4|163480/173481[39:12<02:26,68.36it/s]100%|##########|173481/173481[41:30<00:00,69.64it/s]
[32m[0419 09:12:40 @base.py:257][0m Epoch 62 (global_step 26195631) finished, time:2490.97 sec.
[32m[0419 09:12:40 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-26195631.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.12it/s]
61
[32m[0419 09:14:41 @monitor.py:363][0m QueueInput/queue_size: 0.67807
[32m[0419 09:14:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0419 09:14:41 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0419 09:14:41 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0419 09:14:41 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 09:14:41 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 09:14:41 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 09:14:41 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 09:14:41 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 09:14:41 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 09:14:41 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 09:14:41 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 09:14:41 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 09:14:41 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 09:14:41 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 09:14:41 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 09:14:41 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 09:14:41 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 09:14:41 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 09:14:41 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 09:14:41 @monitor.py:363][0m lr: 2.7756e-20
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 09:14:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 09:14:41 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0419 09:14:41 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0419 09:14:41 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0419 09:14:41 @monitor.py:363][0m validation_cost: 18.675
[32m[0419 09:14:41 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 09:14:41 @group.py:42][0m Callbacks took 120.802 sec in total. InferenceRunner: 120.579sec
[32m[0419 09:14:41 @base.py:247][0m Start Epoch 63 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12609/173481[03:00<38:16,70.05it/s]  8%|7         |13304/173481[03:10<38:06,70.05it/s] 14%|#4        |25089/173481[06:00<35:29,69.69it/s] 15%|#4        |25827/173481[06:10<35:18,69.69it/s] 22%|##1       |37554/173481[09:00<32:36,69.47it/s] 22%|##2       |38188/173481[09:10<32:27,69.47it/s] 29%|##8       |50158/173481[12:00<29:28,69.74it/s] 29%|##9       |50913/173481[12:10<29:17,69.74it/s] 36%|###6      |63129/173481[15:00<25:56,70.88it/s] 37%|###6      |63929/173481[15:10<25:45,70.88it/s] 44%|####3     |76015/173481[18:00<22:48,71.23it/s] 44%|####4     |76810/173481[18:11<22:37,71.23it/s] 51%|#####1    |88732/173481[21:00<19:54,70.94it/s] 52%|#####1    |89508/173481[21:11<19:43,70.94it/s] 59%|#####8    |101791/173481[24:00<16:39,71.73it/s] 59%|#####9    |102492/173481[24:11<16:29,71.73it/s] 65%|######5   |113545/173481[27:00<14:36,68.36it/s] 66%|######5   |114341/173481[27:11<14:25,68.36it/s] 73%|#######2  |126184/173481[30:00<11:22,69.27it/s] 73%|#######3  |126971/173481[30:11<11:11,69.27it/s] 80%|########  |138954/173481[33:00<08:12,70.10it/s] 81%|########  |139777/173481[33:11<08:00,70.10it/s] 88%|########8 |152715/173481[36:00<04:43,73.14it/s] 89%|########8 |153635/173481[36:12<04:31,73.14it/s] 96%|#########6|167086/173481[39:00<01:23,76.34it/s] 97%|#########6|167961/173481[39:12<01:12,76.34it/s]100%|##########|173481/173481[40:25<00:00,71.53it/s]
[32m[0419 09:55:06 @base.py:257][0m Epoch 63 (global_step 26369112) finished, time:2425.25 sec.
[32m[0419 09:55:07 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-26369112.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.88it/s]
62
[32m[0419 09:57:03 @monitor.py:363][0m QueueInput/queue_size: 0.29302
[32m[0419 09:57:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0419 09:57:03 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0419 09:57:03 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0419 09:57:03 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 09:57:03 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 09:57:03 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 09:57:03 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 09:57:03 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 09:57:03 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 09:57:03 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 09:57:03 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 09:57:03 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 09:57:03 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 09:57:03 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 09:57:03 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 09:57:03 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 09:57:03 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 09:57:03 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 09:57:03 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 09:57:03 @monitor.py:363][0m lr: 2.7756e-20
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 09:57:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 09:57:03 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0419 09:57:03 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0419 09:57:03 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0419 09:57:03 @monitor.py:363][0m validation_cost: 18.837
[32m[0419 09:57:03 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 09:57:03 @group.py:42][0m Callbacks took 116.456 sec in total. InferenceRunner: 116.282sec
[32m[0419 09:57:03 @base.py:247][0m Start Epoch 64 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14556/173481[03:00<32:45,80.86it/s]  9%|8         |15243/173481[03:10<32:36,80.86it/s] 16%|#5        |27641/173481[06:00<31:44,76.56it/s] 16%|#6        |28450/173481[06:10<31:34,76.56it/s] 24%|##4       |41683/173481[09:00<28:25,77.28it/s] 24%|##4       |42396/173481[09:10<28:16,77.28it/s] 32%|###2      |55516/173481[12:00<25:30,77.06it/s] 32%|###2      |56344/173481[12:10<25:20,77.06it/s] 40%|###9      |69106/173481[15:00<22:48,76.27it/s] 40%|####      |69825/173481[15:10<22:39,76.27it/s] 48%|####7     |82417/173481[18:00<20:12,75.09it/s] 48%|####7     |83223/173481[18:11<20:01,75.09it/s] 55%|#####5    |96247/173481[21:00<16:56,75.95it/s] 56%|#####5    |97089/173481[21:11<16:45,75.95it/s] 64%|######3   |110245/173481[24:00<13:42,76.85it/s] 64%|######4   |111150/173481[24:11<13:31,76.85it/s] 71%|#######   |122992/173481[27:00<11:25,73.70it/s] 71%|#######1  |123629/173481[27:11<11:16,73.70it/s] 77%|#######7  |134177/173481[30:00<09:42,67.43it/s] 78%|#######7  |134943/173481[30:11<09:31,67.43it/s] 84%|########4 |146137/173481[33:00<06:48,66.93it/s] 85%|########4 |146936/173481[33:11<06:36,66.93it/s] 92%|#########1|159281/173481[36:00<03:23,69.84it/s] 92%|#########2|160180/173481[36:12<03:10,69.84it/s] 99%|#########9|172116/173481[39:00<00:19,70.57it/s]100%|#########9|173037/173481[39:12<00:06,70.57it/s]100%|##########|173481/173481[39:18<00:00,73.55it/s]
[32m[0419 10:36:21 @base.py:257][0m Epoch 64 (global_step 26542593) finished, time:2358.62 sec.
[32m[0419 10:36:22 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-26542593.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.74it/s]
63
[32m[0419 10:38:16 @monitor.py:363][0m QueueInput/queue_size: 0.50878
[32m[0419 10:38:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.89
[32m[0419 10:38:16 @monitor.py:363][0m activation-summaries/output-rms: 0.050126
[32m[0419 10:38:16 @monitor.py:363][0m cross_entropy_loss: 18.71
[32m[0419 10:38:16 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 10:38:16 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 10:38:16 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 10:38:16 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 10:38:16 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 10:38:16 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 10:38:16 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 10:38:16 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 10:38:16 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 10:38:16 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 10:38:16 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 10:38:16 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 10:38:16 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 10:38:16 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 10:38:16 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 10:38:16 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 10:38:16 @monitor.py:363][0m lr: 1.3878e-20
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 10:38:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 10:38:16 @monitor.py:363][0m train-error-top1: 0.98805
[32m[0419 10:38:16 @monitor.py:363][0m val-error-top1: 0.98544
[32m[0419 10:38:16 @monitor.py:363][0m val-utt-error: 0.97551
[32m[0419 10:38:16 @monitor.py:363][0m validation_cost: 19.032
[32m[0419 10:38:16 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 10:38:16 @group.py:42][0m Callbacks took 114.426 sec in total. InferenceRunner: 114.266sec
[32m[0419 10:38:16 @base.py:247][0m Start Epoch 65 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12391/173481[03:00<39:00,68.84it/s]  8%|7         |13108/173481[03:10<38:49,68.84it/s] 14%|#4        |25075/173481[06:00<35:31,69.64it/s] 15%|#4        |25788/173481[06:10<35:20,69.64it/s] 22%|##1       |37721/173481[09:00<32:20,69.95it/s] 22%|##2       |38484/173481[09:10<32:10,69.95it/s] 30%|###       |52600/173481[12:00<26:35,75.77it/s] 31%|###       |53472/173481[12:10<26:23,75.77it/s] 38%|###8      |66709/173481[15:00<23:05,77.06it/s] 39%|###8      |67482/173481[15:10<22:55,77.06it/s] 46%|####6     |79808/173481[18:00<20:51,74.85it/s] 46%|####6     |80584/173481[18:11<20:41,74.85it/s] 53%|#####3    |92780/173481[21:00<18:18,73.43it/s] 54%|#####3    |93576/173481[21:11<18:08,73.43it/s] 61%|######    |105745/173481[24:00<15:31,72.71it/s] 61%|######1   |106513/173481[24:11<15:20,72.71it/s] 68%|######8   |118502/173481[27:00<12:45,71.78it/s] 69%|######8   |119297/173481[27:11<12:34,71.78it/s] 76%|#######6  |132433/173481[30:00<09:11,74.48it/s] 77%|#######6  |133315/173481[30:11<08:59,74.48it/s] 84%|########4 |145843/173481[33:00<06:11,74.48it/s] 85%|########4 |146598/173481[33:11<06:00,74.48it/s] 91%|######### |157729/173481[36:00<03:45,70.00it/s] 91%|#########1|158508/173481[36:12<03:33,70.00it/s] 98%|#########7|169923/173481[39:00<00:51,68.85it/s] 98%|#########8|170808/173481[39:12<00:38,68.85it/s]100%|##########|173481/173481[39:41<00:00,72.85it/s]
[32m[0419 11:17:57 @base.py:257][0m Epoch 65 (global_step 26716074) finished, time:2381.49 sec.
[32m[0419 11:17:58 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-26716074.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.44it/s]
64
[32m[0419 11:19:51 @monitor.py:363][0m QueueInput/queue_size: 1.6374
[32m[0419 11:19:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.217
[32m[0419 11:19:51 @monitor.py:363][0m activation-summaries/output-rms: 0.050302
[32m[0419 11:19:51 @monitor.py:363][0m cross_entropy_loss: 18.838
[32m[0419 11:19:51 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 11:19:51 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 11:19:51 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 11:19:51 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 11:19:51 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 11:19:51 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 11:19:51 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 11:19:51 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 11:19:51 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 11:19:51 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 11:19:51 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 11:19:51 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 11:19:51 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 11:19:51 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 11:19:51 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 11:19:51 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 11:19:51 @monitor.py:363][0m lr: 1.3878e-20
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 11:19:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 11:19:51 @monitor.py:363][0m train-error-top1: 0.98764
[32m[0419 11:19:51 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0419 11:19:51 @monitor.py:363][0m val-utt-error: 0.97444
[32m[0419 11:19:51 @monitor.py:363][0m validation_cost: 18.777
[32m[0419 11:19:51 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 11:19:51 @group.py:42][0m Callbacks took 113.980 sec in total. InferenceRunner: 113.786sec
[32m[0419 11:19:51 @base.py:247][0m Start Epoch 66 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14518/173481[03:00<32:50,80.66it/s]  9%|8         |15287/173481[03:10<32:41,80.66it/s] 16%|#6        |27972/173481[06:00<31:15,77.59it/s] 17%|#6        |28766/173481[06:10<31:05,77.59it/s] 24%|##3       |41096/173481[09:00<29:21,75.18it/s] 24%|##4       |41887/173481[09:10<29:10,75.18it/s] 31%|###1      |53923/173481[12:00<27:14,73.16it/s] 32%|###1      |54691/173481[12:10<27:03,73.16it/s] 38%|###7      |65465/173481[15:00<26:20,68.34it/s] 38%|###8      |66153/173481[15:10<26:10,68.34it/s] 45%|####4     |77883/173481[18:00<23:12,68.66it/s] 45%|####5     |78583/173481[18:11<23:02,68.66it/s] 52%|#####1    |89403/173481[21:00<21:09,66.24it/s] 52%|#####2    |90236/173481[21:11<20:56,66.24it/s] 59%|#####8    |102154/173481[24:00<17:21,68.46it/s] 59%|#####9    |102938/173481[24:11<17:10,68.46it/s] 65%|######5   |113464/173481[27:00<15:15,65.52it/s] 66%|######5   |114293/173481[27:11<15:03,65.52it/s] 73%|#######2  |126317/173481[30:00<11:30,68.34it/s] 73%|#######3  |127245/173481[30:11<11:16,68.34it/s] 80%|########  |139158/173481[33:00<08:11,69.80it/s] 81%|########  |140080/173481[33:11<07:58,69.80it/s] 88%|########8 |152767/173481[36:00<04:45,72.59it/s] 89%|########8 |153675/173481[36:11<04:32,72.59it/s] 95%|#########4|164789/173481[39:00<02:04,69.57it/s] 96%|#########5|165682/173481[39:12<01:52,69.57it/s]100%|##########|173481/173481[40:52<00:00,70.74it/s]
[32m[0419 12:00:44 @base.py:257][0m Epoch 66 (global_step 26889555) finished, time:2452.21 sec.
[32m[0419 12:00:44 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-26889555.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.44it/s]
65
[32m[0419 12:02:40 @monitor.py:363][0m QueueInput/queue_size: 0.90778
[32m[0419 12:02:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.101
[32m[0419 12:02:40 @monitor.py:363][0m activation-summaries/output-rms: 0.049351
[32m[0419 12:02:40 @monitor.py:363][0m cross_entropy_loss: 18.399
[32m[0419 12:02:40 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 12:02:40 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 12:02:40 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 12:02:40 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 12:02:40 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 12:02:40 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 12:02:40 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 12:02:40 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 12:02:40 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 12:02:40 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 12:02:40 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 12:02:40 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 12:02:40 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 12:02:40 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 12:02:40 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 12:02:40 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 12:02:40 @monitor.py:363][0m lr: 1.3878e-20
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 12:02:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 12:02:40 @monitor.py:363][0m train-error-top1: 0.98403
[32m[0419 12:02:40 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0419 12:02:40 @monitor.py:363][0m val-utt-error: 0.97317
[32m[0419 12:02:40 @monitor.py:363][0m validation_cost: 18.665
[32m[0419 12:02:40 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 12:02:40 @group.py:42][0m Callbacks took 116.885 sec in total. InferenceRunner: 116.607sec
[32m[0419 12:02:40 @base.py:247][0m Start Epoch 67 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12800/173481[03:00<37:39,71.11it/s]  8%|7         |13470/173481[03:10<37:30,71.11it/s] 15%|#4        |25494/173481[06:00<34:49,70.81it/s] 15%|#5        |26130/173481[06:10<34:40,70.81it/s] 22%|##1       |37523/173481[09:00<32:57,68.76it/s] 22%|##2       |38196/173481[09:10<32:47,68.76it/s] 28%|##8       |48879/173481[12:00<31:33,65.80it/s] 29%|##8       |49568/173481[12:10<31:23,65.80it/s] 34%|###4      |59749/173481[15:00<30:06,62.97it/s] 35%|###4      |60408/173481[15:10<29:55,62.97it/s] 41%|####1     |71587/173481[18:00<26:23,64.33it/s] 42%|####1     |72306/173481[18:11<26:12,64.33it/s] 48%|####8     |84023/173481[21:00<22:22,66.62it/s] 49%|####8     |84775/173481[21:11<22:11,66.62it/s] 55%|#####5    |95899/173481[24:00<19:30,66.29it/s] 56%|#####5    |96654/173481[24:11<19:18,66.29it/s] 63%|######2   |108588/173481[27:00<15:49,68.33it/s] 63%|######3   |109482/173481[27:11<15:36,68.33it/s] 70%|######9   |121138/173481[30:00<12:38,69.02it/s] 70%|#######   |121890/173481[30:11<12:27,69.02it/s] 77%|#######6  |133048/173481[33:00<09:58,67.56it/s] 77%|#######7  |133910/173481[33:11<09:45,67.56it/s] 84%|########4 |145839/173481[36:00<06:39,69.26it/s] 85%|########4 |146717/173481[36:12<06:26,69.26it/s] 91%|#########1|158615/173481[39:00<03:32,70.11it/s] 92%|#########1|159527/173481[39:12<03:19,70.11it/s] 99%|#########8|171599/173481[42:00<00:26,71.10it/s] 99%|#########9|172541/173481[42:12<00:13,71.10it/s]100%|##########|173481/173481[42:25<00:00,68.15it/s]
[32m[0419 12:45:06 @base.py:257][0m Epoch 67 (global_step 27063036) finished, time:2545.69 sec.
[32m[0419 12:45:06 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-27063036.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.72it/s]
66
[32m[0419 12:47:01 @monitor.py:363][0m QueueInput/queue_size: 0.35646
[32m[0419 12:47:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.952
[32m[0419 12:47:01 @monitor.py:363][0m activation-summaries/output-rms: 0.049733
[32m[0419 12:47:01 @monitor.py:363][0m cross_entropy_loss: 18.462
[32m[0419 12:47:01 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 12:47:01 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 12:47:01 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 12:47:01 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 12:47:01 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 12:47:01 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 12:47:01 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 12:47:01 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 12:47:01 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 12:47:01 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 12:47:01 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 12:47:01 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 12:47:01 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 12:47:01 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 12:47:01 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 12:47:01 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 12:47:01 @monitor.py:363][0m lr: 6.9389e-21
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 12:47:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 12:47:01 @monitor.py:363][0m train-error-top1: 0.98367
[32m[0419 12:47:01 @monitor.py:363][0m val-error-top1: 0.98531
[32m[0419 12:47:01 @monitor.py:363][0m val-utt-error: 0.9737
[32m[0419 12:47:01 @monitor.py:363][0m validation_cost: 18.76
[32m[0419 12:47:01 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 12:47:01 @group.py:42][0m Callbacks took 115.154 sec in total. InferenceRunner: 114.984sec
[32m[0419 12:47:01 @base.py:247][0m Start Epoch 68 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12508/173481[03:00<38:37,69.47it/s]  8%|7         |13199/173481[03:10<38:27,69.47it/s] 14%|#3        |23553/173481[06:00<38:20,65.16it/s] 14%|#3        |24129/173481[06:10<38:11,65.16it/s] 20%|#9        |34306/173481[09:00<37:12,62.33it/s] 20%|##        |34911/173481[09:10<37:03,62.33it/s] 26%|##5       |45016/173481[12:00<35:10,60.88it/s] 26%|##6       |45639/173481[12:10<35:00,60.88it/s] 32%|###2      |55894/173481[15:00<32:19,60.64it/s] 33%|###2      |56547/173481[15:10<32:08,60.64it/s] 39%|###8      |66920/173481[18:00<29:08,60.94it/s] 39%|###9      |67763/173481[18:11<28:54,60.94it/s] 44%|####4     |77143/173481[21:00<27:18,58.80it/s] 45%|####4     |77715/173481[21:11<27:08,58.80it/s] 50%|####9     |86506/173481[24:00<26:15,55.19it/s] 50%|#####     |87153/173481[24:11<26:04,55.19it/s] 56%|#####5    |97064/173481[27:00<22:23,56.87it/s] 56%|#####6    |97698/173481[27:11<22:12,56.87it/s] 63%|######2   |108556/173481[30:00<17:59,60.14it/s] 63%|######2   |109269/173481[30:11<17:47,60.14it/s] 69%|######9   |120310/173481[33:00<14:09,62.61it/s] 70%|######9   |121074/173481[33:11<13:57,62.61it/s] 76%|#######5  |131814/173481[36:00<10:58,63.25it/s] 76%|#######6  |132586/173481[36:11<10:46,63.25it/s] 83%|########3 |143996/173481[39:00<07:30,65.39it/s] 83%|########3 |144785/173481[39:12<07:18,65.39it/s] 90%|########9 |155770/173481[42:00<04:30,65.40it/s] 90%|######### |156489/173481[42:12<04:19,65.40it/s] 97%|#########6|168221/173481[45:00<01:18,67.23it/s] 97%|#########7|169077/173481[45:12<01:05,67.23it/s]100%|##########|173481/173481[46:18<00:00,62.45it/s]
[32m[0419 13:33:19 @base.py:257][0m Epoch 68 (global_step 27236517) finished, time:2778.06 sec.
[32m[0419 13:33:20 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-27236517.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.07it/s]
67
[32m[0419 13:35:14 @monitor.py:363][0m QueueInput/queue_size: 0.51255
[32m[0419 13:35:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.081
[32m[0419 13:35:14 @monitor.py:363][0m activation-summaries/output-rms: 0.049553
[32m[0419 13:35:14 @monitor.py:363][0m cross_entropy_loss: 18.551
[32m[0419 13:35:14 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 13:35:14 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 13:35:14 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 13:35:14 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 13:35:14 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 13:35:14 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 13:35:14 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 13:35:14 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 13:35:14 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 13:35:14 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 13:35:14 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 13:35:14 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 13:35:14 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 13:35:14 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 13:35:14 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 13:35:14 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 13:35:14 @monitor.py:363][0m lr: 6.9389e-21
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 13:35:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 13:35:14 @monitor.py:363][0m train-error-top1: 0.98484
[32m[0419 13:35:14 @monitor.py:363][0m val-error-top1: 0.98543
[32m[0419 13:35:14 @monitor.py:363][0m val-utt-error: 0.97397
[32m[0419 13:35:14 @monitor.py:363][0m validation_cost: 18.675
[32m[0419 13:35:14 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 13:35:14 @group.py:42][0m Callbacks took 114.871 sec in total. InferenceRunner: 114.735sec
[32m[0419 13:35:14 @base.py:247][0m Start Epoch 69 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12265/173481[03:00<39:26,68.12it/s]  7%|7         |12864/173481[03:10<39:17,68.12it/s] 14%|#3        |23600/173481[06:00<38:10,65.44it/s] 14%|#3        |24207/173481[06:10<38:00,65.44it/s] 20%|##        |35530/173481[09:00<34:54,65.86it/s] 21%|##        |36186/173481[09:10<34:44,65.86it/s] 27%|##7       |47288/173481[12:00<32:04,65.59it/s] 28%|##7       |47934/173481[12:10<31:54,65.59it/s] 34%|###4      |59023/173481[15:00<29:10,65.39it/s] 34%|###4      |59713/173481[15:10<28:59,65.39it/s] 41%|####      |70405/173481[18:00<26:43,64.29it/s] 41%|####      |70992/173481[18:10<26:34,64.29it/s] 47%|####7     |82183/173481[21:00<23:27,64.85it/s] 48%|####7     |82833/173481[21:11<23:17,64.85it/s] 55%|#####4    |94771/173481[24:00<19:29,67.29it/s] 55%|#####5    |95532/173481[24:11<19:18,67.29it/s] 61%|######    |105150/173481[27:00<18:20,62.11it/s] 61%|######    |105804/173481[27:11<18:09,62.11it/s] 67%|######6   |115414/173481[30:00<16:16,59.46it/s] 67%|######6   |116121/173481[30:11<16:04,59.46it/s] 73%|#######2  |125897/173481[33:00<13:28,58.84it/s] 73%|#######2  |126614/173481[33:11<13:16,58.84it/s] 78%|#######8  |135456/173481[36:00<11:21,55.81it/s] 78%|#######8  |136060/173481[36:11<11:10,55.81it/s] 83%|########3 |144720/173481[39:00<08:57,53.54it/s] 84%|########3 |145285/173481[39:12<08:46,53.54it/s] 89%|########9 |154447/173481[42:00<05:53,53.79it/s] 89%|########9 |155132/173481[42:12<05:41,53.79it/s] 95%|#########4|164479/173481[45:00<02:44,54.74it/s] 95%|#########5|165252/173481[45:12<02:30,54.74it/s]100%|##########|173481/173481[47:42<00:00,60.61it/s]
[32m[0419 14:22:57 @base.py:257][0m Epoch 69 (global_step 27409998) finished, time:2862.12 sec.
[32m[0419 14:22:58 @saver.py:84][0m Model saved to train_log/fcn1_a_32_quant_ends_True_preload/model-27409998.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,166.06it/s]
68
[32m[0419 14:24:52 @monitor.py:363][0m QueueInput/queue_size: 0.47032
[32m[0419 14:24:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 70.919
[32m[0419 14:24:52 @monitor.py:363][0m activation-summaries/output-rms: 0.050358
[32m[0419 14:24:52 @monitor.py:363][0m cross_entropy_loss: 18.358
[32m[0419 14:24:52 @monitor.py:363][0m last_linear/W_0_percent_n: 0.77569
[32m[0419 14:24:52 @monitor.py:363][0m last_linear/W_0_percent_p: 0.076762
[32m[0419 14:24:52 @monitor.py:363][0m last_linear/W_0_sparsity: 0.14755
[32m[0419 14:24:52 @monitor.py:363][0m last_linear/Wn_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m last_linear/Wp_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m linear0/W_0_percent_n: 0.033934
[32m[0419 14:24:52 @monitor.py:363][0m linear0/W_0_percent_p: 0.029641
[32m[0419 14:24:52 @monitor.py:363][0m linear0/W_0_sparsity: 0.93643
[32m[0419 14:24:52 @monitor.py:363][0m linear0/Wn_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m linear0/Wp_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m linear1/W_0_percent_n: 0.41391
[32m[0419 14:24:52 @monitor.py:363][0m linear1/W_0_percent_p: 0.3902
[32m[0419 14:24:52 @monitor.py:363][0m linear1/W_0_sparsity: 0.19589
[32m[0419 14:24:52 @monitor.py:363][0m linear1/Wn_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m linear1/Wp_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m linear2/W_0_percent_n: 0.44414
[32m[0419 14:24:52 @monitor.py:363][0m linear2/W_0_percent_p: 0.42183
[32m[0419 14:24:52 @monitor.py:363][0m linear2/W_0_sparsity: 0.13403
[32m[0419 14:24:52 @monitor.py:363][0m linear2/Wn_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m linear2/Wp_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m linear3/W_0_percent_n: 0.45712
[32m[0419 14:24:52 @monitor.py:363][0m linear3/W_0_percent_p: 0.41995
[32m[0419 14:24:52 @monitor.py:363][0m linear3/W_0_sparsity: 0.12292
[32m[0419 14:24:52 @monitor.py:363][0m linear3/Wn_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m linear3/Wp_0: 1
[32m[0419 14:24:52 @monitor.py:363][0m lr: 3.4694e-21
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0419 14:24:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0419 14:24:52 @monitor.py:363][0m train-error-top1: 0.98422
[32m[0419 14:24:52 @monitor.py:363][0m val-error-top1: 0.98536
[32m[0419 14:24:52 @monitor.py:363][0m val-utt-error: 0.97434
[32m[0419 14:24:52 @monitor.py:363][0m validation_cost: 18.837
[32m[0419 14:24:52 @monitor.py:363][0m wd_cost: 2.3085e-37
[32m[0419 14:24:52 @group.py:42][0m Callbacks took 115.307 sec in total. InferenceRunner: 113.366sec
[32m[0419 14:24:52 @base.py:247][0m Start Epoch 70 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12708/173481[03:00<37:57,70.60it/s]  8%|7         |13389/173481[03:10<37:47,70.60it/s] 14%|#3        |24268/173481[06:00<36:58,67.26it/s] 14%|#4        |24999/173481[06:10<36:47,67.26it/s] 21%|##        |36220/173481[09:00<34:14,66.82it/s] 21%|##1       |36837/173481[09:10<34:05,66.82it/s] 27%|##7       |47132/173481[12:00<33:07,63.57it/s] 28%|##7       |47775/173481[12:10<32:57,63.57it/s]slurmstepd: *** STEP 334045.0 ON sls-sm-6 CANCELLED AT 2018-04-19T14:37:12 DUE TO TIME LIMIT ***
srun: error: sls-sm-6: task 0: Terminated
srun: Force Terminated job step 334045.0
