sls-tesla-0 0
SLURM_JOBID=82197
SLURM_TASKID=3
[32m[0321 12:16:35 @logger.py:74][0m Argv: drf_run.py --model_name=cnn --bitw=8 --bita=32 --quant_ends=True --load_ckpt=train_log/cnn_w_8_a_32_quant_ends_False/checkpoint
[32m[0321 12:24:51 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0321 12:24:51 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0321 12:24:51 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0321 12:24:51 @drf_run.py:166][0m Using host: sls-tesla-0
[32m[0321 12:24:51 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0321 12:24:51 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0321 12:24:51 @drf_run.py:188][0m Using GPU: 0
[32m[0321 12:24:51 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0321 12:24:51 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0321 12:24:51 @training.py:108][0m Building graph for training tower 0 ...
[32m[0321 12:24:51 @registry.py:122][0m conv0 input: [None, 50, 20, 1]
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight conv0/W
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight conv0/b
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing conv0/bn/beta
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing conv0/bn/gamma
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing conv0/bn/mean/EMA
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing conv0/bn/variance/EMA
[32m[0321 12:24:52 @registry.py:130][0m conv0 output: [None, 10, 4, 6]
[32m[0321 12:24:52 @registry.py:122][0m linear0 input: [None, 10, 4, 6]
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0321 12:24:52 @registry.py:130][0m linear0 output: [None, 256]
[32m[0321 12:24:52 @registry.py:122][0m linear1 input: [None, 256]
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0321 12:24:52 @registry.py:130][0m linear1 output: [None, 256]
[32m[0321 12:24:52 @registry.py:122][0m linear2 input: [None, 256]
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0321 12:24:52 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0321 12:24:52 @registry.py:130][0m linear2 output: [None, 256]
[32m[0321 12:24:52 @registry.py:122][0m last_linear input: [None, 256]
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0321 12:24:52 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0321 12:24:52 @registry.py:130][0m last_linear output: [None, 255]
[32m[0321 12:24:52 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0321 12:24:52 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0321 12:24:52 @regularize.py:18][0m Applying regularizer for conv0/W:0, linear0/W:0, linear1/W:0, linear2/W:0, last_linear/W:0
[32m[0321 12:24:52 @drf_run.py:123][0m Parameter count: {'mults': 265808, 'weights': 259979}
[32m[0321 12:24:54 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  ------------  -----
conv0/W:0           [5, 5, 1, 6]    150
conv0/b:0           [6]               6
conv0/bn/beta:0     [6]               6
conv0/bn/gamma:0    [6]               6
linear0/W:0         [240, 256]    61440
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=260519, size=0.99MB[0m
[32m[0321 12:24:54 @base.py:196][0m Setup callbacks graph ...
[32m[0321 12:24:55 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight conv0/W
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight conv0/b
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing conv0/bn/beta
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing conv0/bn/gamma
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing conv0/bn/mean/EMA
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing conv0/bn/variance/EMA
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0321 12:24:55 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0321 12:24:55 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0321 12:24:55 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0321 12:24:55 @drf_run.py:123][0m Parameter count: {'mults': 531616, 'weights': 519958}
[32m[0321 12:24:55 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0321 12:24:55 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0321 12:24:56 @base.py:212][0m Creating the session ...
2018-03-21 12:24:57.305604: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2
2018-03-21 12:24:58.580772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-03-21 12:24:58.581531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN Black major: 3 minor: 5 memoryClockRate(GHz): 0.98
pciBusID: 0000:06:00.0
totalMemory: 5.94GiB freeMemory: 5.86GiB
2018-03-21 12:24:58.581580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:06:00.0, compute capability: 3.5)
[32m[0321 12:25:05 @base.py:220][0m Initializing the session ...
[32m[0321 12:25:05 @sessinit.py:116][0m Restoring checkpoint from train_log/cnn_w_8_a_32_quant_ends_False/model-3643101 ...
[32m[0321 12:25:06 @base.py:227][0m Graph Finalized.
[32m[0321 12:25:06 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0321 12:25:06 @steps.py:127][0m Start training with global_step=3643101
[32m[0321 12:25:13 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8469/173481[03:00<58:27,47.05it/s]  5%|5         |8975/173481[03:10<58:16,47.05it/s] 11%|#         |19058/173481[06:00<49:13,52.28it/s] 11%|#1        |19675/173481[06:10<49:01,52.28it/s] 17%|#7        |29776/173481[09:00<43:01,55.67it/s] 17%|#7        |30219/173481[09:10<42:53,55.67it/s] 22%|##2       |38189/173481[12:00<44:22,50.82it/s] 22%|##2       |38686/173481[12:10<44:12,50.82it/s] 27%|##7       |46942/173481[15:00<42:26,49.70it/s] 27%|##7       |47449/173481[15:10<42:15,49.70it/s] 32%|###1      |55149/173481[18:00<41:28,47.56it/s] 32%|###2      |55662/173481[18:10<41:17,47.56it/s] 37%|###6      |63681/173481[21:00<38:32,47.47it/s] 37%|###7      |64197/173481[21:11<38:22,47.47it/s] 42%|####1     |72019/173481[24:00<36:03,46.89it/s] 42%|####1     |72536/173481[24:11<35:52,46.89it/s] 46%|####6     |80375/173481[27:00<33:15,46.65it/s] 47%|####6     |80915/173481[27:11<33:04,46.65it/s] 51%|#####1    |88691/173481[30:00<30:26,46.42it/s] 51%|#####1    |89215/173481[30:11<30:15,46.42it/s] 56%|#####5    |96630/173481[33:00<28:18,45.24it/s] 56%|#####5    |97144/173481[33:11<28:07,45.24it/s] 60%|######    |104827/173481[36:00<25:12,45.39it/s] 61%|######    |105285/173481[36:11<25:02,45.39it/s] 64%|######4   |111701/173481[39:00<24:49,41.47it/s] 65%|######4   |112130/173481[39:12<24:39,41.47it/s] 68%|######8   |118711/173481[42:00<22:43,40.17it/s] 69%|######8   |119209/173481[42:12<22:31,40.17it/s] 73%|#######2  |125832/173481[45:00<19:55,39.86it/s] 73%|#######2  |126313/173481[45:12<19:43,39.86it/s] 77%|#######6  |132760/173481[48:00<17:19,39.16it/s] 77%|#######6  |133244/173481[48:12<17:07,39.16it/s] 81%|########  |139836/173481[51:00<14:17,39.23it/s] 81%|########  |140349/173481[51:12<14:04,39.23it/s] 85%|########4 |146856/173481[54:00<11:20,39.11it/s] 85%|########4 |147325/173481[54:12<11:08,39.11it/s] 89%|########8 |153861/173481[57:00<08:22,39.01it/s] 89%|########8 |154343/173481[57:13<08:10,39.01it/s] 93%|#########2|160881/173481[1:00:00<05:23,39.00it/s] 93%|#########3|161386/173481[1:00:13<05:10,39.00it/s] 97%|#########6|167921/173481[1:03:00<02:22,39.05it/s] 97%|#########7|168442/173481[1:03:13<02:09,39.05it/s]100%|##########|173481/173481[1:05:25<00:00,44.19it/s]
[32m[0321 13:30:39 @base.py:257][0m Epoch 1 (global_step 3816582) finished, time:3925.77 sec.
[32m[0321 13:30:39 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_32_quant_ends_True_preload/model-3816582.
  0%|          |0/18822[00:00<?,?it/s] 59%|#####8    |11063/18822[03:00<02:06,61.46it/s] 61%|######1   |11557/18822[03:10<01:58,61.46it/s]100%|##########|18822/18822[05:03<00:00,62.09it/s]
0
[32m[0321 13:35:42 @monitor.py:363][0m QueueInput/queue_size: 3.1948
[32m[0321 13:35:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.33
[32m[0321 13:35:42 @monitor.py:363][0m activation-summaries/output-rms: 0.038782
[32m[0321 13:35:42 @monitor.py:363][0m cross_entropy_loss: 1.7135
[32m[0321 13:35:42 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/conv0/W-rms: 0.66984
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/conv0/b-rms: 0.0007292
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61038
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4143
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34091
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2999
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29484
[32m[0321 13:35:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0321 13:35:42 @monitor.py:363][0m train-error-top1: 0.45359
[32m[0321 13:35:42 @monitor.py:363][0m val-error-top1: 0.45981
[32m[0321 13:35:42 @monitor.py:363][0m val-utt-error: 0.12156
[32m[0321 13:35:42 @monitor.py:363][0m validation_cost: 1.7413
[32m[0321 13:35:42 @monitor.py:363][0m wd_cost: 5.5194e-05
[32m[0321 13:35:42 @group.py:42][0m Callbacks took 303.458 sec in total. InferenceRunner: 303.134sec
[32m[0321 13:35:42 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9755/173481[03:00<50:22,54.18it/s]  6%|5         |10276/173481[03:10<50:12,54.18it/s] 10%|9         |17012/173481[06:00<56:24,46.23it/s] 10%|#         |17402/173481[06:10<56:16,46.23it/s] 14%|#3        |24001/173481[09:00<59:01,42.20it/s] 14%|#4        |24393/173481[09:10<58:52,42.20it/s] 18%|#7        |30845/173481[12:00<59:25,40.00it/s] 18%|#8        |31229/173481[12:10<59:16,40.00it/s] 22%|##1       |37410/173481[15:00<59:26,38.15it/s] 22%|##1       |37800/173481[15:10<59:16,38.15it/s] 25%|##5       |44177/173481[18:00<56:54,37.87it/s] 26%|##5       |44566/173481[18:10<56:44,37.87it/s] 29%|##9       |51060/173481[21:00<53:37,38.05it/s] 30%|##9       |51476/173481[21:11<53:26,38.05it/s] 33%|###3      |58085/173481[24:00<49:54,38.53it/s] 34%|###3      |58519/173481[24:11<49:43,38.53it/s] 37%|###7      |64925/173481[27:00<47:17,38.26it/s] 38%|###7      |65334/173481[27:11<47:06,38.26it/s] 42%|####1     |71995/173481[30:00<43:38,38.76it/s] 42%|####1     |72441/173481[30:11<43:27,38.76it/s] 46%|####5     |79178/173481[33:00<39:58,39.32it/s] 46%|####5     |79619/173481[33:11<39:47,39.32it/s] 50%|####9     |86222/173481[36:00<37:04,39.22it/s] 50%|####9     |86675/173481[36:11<36:53,39.22it/s] 54%|#####3    |93290/173481[39:00<34:03,39.24it/s] 54%|#####4    |93756/173481[39:12<33:51,39.24it/s] 58%|#####7    |100338/173481[42:00<31:05,39.20it/s] 58%|#####8    |100799/173481[42:12<30:54,39.20it/s] 62%|######1   |107430/173481[45:00<28:00,39.30it/s] 62%|######2   |107909/173481[45:12<27:48,39.30it/s] 66%|######6   |114605/173481[48:00<24:47,39.57it/s] 66%|######6   |115068/173481[48:12<24:36,39.57it/s] 70%|######9   |121304/173481[51:00<22:40,38.36it/s] 70%|#######   |121790/173481[51:12<22:27,38.36it/s] 74%|#######3  |128147/173481[54:00<19:47,38.18it/s] 74%|#######4  |128604/173481[54:12<19:35,38.18it/s] 78%|#######7  |134824/173481[57:00<17:07,37.63it/s] 78%|#######7  |135294/173481[57:12<16:54,37.63it/s] 82%|########1 |141628/173481[1:00:00<14:04,37.71it/s] 82%|########1 |142106/173481[1:00:13<13:51,37.71it/s] 86%|########5 |148625/173481[1:03:00<10:49,38.28it/s] 86%|########5 |149107/173481[1:03:13<10:36,38.28it/s] 90%|########9 |156131/173481[1:06:00<07:14,39.92it/s] 90%|######### |156811/173481[1:06:13<06:57,39.92it/s] 95%|#########5|165468/173481[1:09:00<02:57,45.11it/s] 96%|#########5|166192/173481[1:09:13<02:41,45.11it/s]100%|#########9|173125/173481[1:12:00<00:08,43.78it/s]100%|##########|173481/173481[1:12:10<00:00,40.06it/s]
[32m[0321 14:47:52 @base.py:257][0m Epoch 2 (global_step 3990063) finished, time:4330.05 sec.
[32m[0321 14:47:52 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_32_quant_ends_True_preload/model-3990063.
[32m[0321 14:47:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 68%|######7   |12749/18822[03:00<01:25,70.83it/s] 72%|#######1  |13516/18822[03:10<01:14,70.83it/s]100%|##########|18822/18822[04:22<00:00,71.76it/s]
1
[32m[0321 14:52:15 @monitor.py:363][0m QueueInput/queue_size: 0.79229
[32m[0321 14:52:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.918
[32m[0321 14:52:15 @monitor.py:363][0m activation-summaries/output-rms: 0.038899
[32m[0321 14:52:15 @monitor.py:363][0m cross_entropy_loss: 1.7068
[32m[0321 14:52:15 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67175
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00078227
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61444
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4168
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34113
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29997
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29477
[32m[0321 14:52:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0321 14:52:15 @monitor.py:363][0m train-error-top1: 0.45448
[32m[0321 14:52:15 @monitor.py:363][0m val-error-top1: 0.45923
[32m[0321 14:52:15 @monitor.py:363][0m val-utt-error: 0.11991
[32m[0321 14:52:15 @monitor.py:363][0m validation_cost: 1.7373
[32m[0321 14:52:15 @monitor.py:363][0m wd_cost: 1.1124e-05
[32m[0321 14:52:15 @group.py:42][0m Callbacks took 262.563 sec in total. InferenceRunner: 262.292sec
[32m[0321 14:52:15 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7591/173481[03:00<1:05:33,42.17it/s]  5%|4         |8002/173481[03:10<1:05:24,42.17it/s]  9%|8         |14903/173481[06:00<1:03:52,41.38it/s]  9%|8         |15290/173481[06:10<1:03:42,41.38it/s] 13%|#2        |22124/173481[09:00<1:01:55,40.74it/s] 13%|#2        |22551/173481[09:10<1:01:45,40.74it/s] 17%|#6        |28934/173481[12:00<1:01:24,39.23it/s] 17%|#6        |29334/173481[12:10<1:01:14,39.23it/s] 21%|##        |35764/173481[15:00<59:30,38.57it/s]   21%|##        |36168/173481[15:10<59:19,38.57it/s] 24%|##4       |42446/173481[18:00<57:43,37.83it/s] 25%|##4       |42853/173481[18:10<57:32,37.83it/s] 28%|##8       |49086/173481[21:00<55:30,37.35it/s] 29%|##8       |49488/173481[21:11<55:19,37.35it/s] 32%|###2      |55886/173481[24:00<52:10,37.56it/s] 32%|###2      |56300/173481[24:11<51:59,37.56it/s] 36%|###6      |62737/173481[27:00<48:49,37.81it/s] 36%|###6      |63166/173481[27:11<48:37,37.81it/s] 40%|####      |69919/173481[30:00<44:27,38.82it/s] 41%|####      |70358/173481[30:11<44:16,38.82it/s] 45%|####4     |77254/173481[33:00<40:20,39.76it/s] 45%|####4     |77728/173481[33:11<40:08,39.76it/s] 49%|####8     |84514/173481[36:00<37:01,40.04it/s] 49%|####8     |84980/173481[36:11<36:50,40.04it/s] 53%|#####2    |91915/173481[39:00<33:30,40.57it/s] 53%|#####3    |92383/173481[39:12<33:18,40.57it/s] 57%|#####7    |99310/173481[42:00<30:16,40.82it/s] 58%|#####7    |99808/173481[42:12<30:04,40.82it/s] 61%|######1   |106574/173481[45:00<27:28,40.59it/s] 62%|######1   |107073/173481[45:12<27:16,40.59it/s] 66%|######5   |113967/173481[48:00<24:17,40.83it/s] 66%|######5   |114454/173481[48:12<24:05,40.83it/s] 70%|######9   |121160/173481[51:00<21:35,40.39it/s] 70%|#######   |121638/173481[51:12<21:23,40.39it/s] 75%|#######4  |129293/173481[54:00<17:16,42.65it/s] 75%|#######4  |129944/173481[54:12<17:00,42.65it/s] 80%|########  |138969/173481[57:00<12:05,47.56it/s] 81%|########  |139688/173481[57:12<11:50,47.56it/s] 84%|########4 |146559/173481[1:00:00<10:02,44.69it/s] 85%|########4 |147055/173481[1:00:13<09:51,44.69it/s] 89%|########8 |153719/173481[1:03:00<07:49,42.09it/s] 89%|########8 |154245/173481[1:03:13<07:37,42.09it/s] 93%|#########2|161007/173481[1:06:00<05:02,41.27it/s] 93%|#########3|161522/173481[1:06:13<04:49,41.27it/s] 97%|#########7|168357/173481[1:09:00<02:04,41.05it/s] 97%|#########7|168910/173481[1:09:13<01:51,41.05it/s][32m[0321 16:03:25 @base.py:257][0m Epoch 3 (global_step 4163544) finished, time:4270.39 sec.
100%|##########|173481/173481[1:11:10<00:00,40.62it/s]
[32m[0321 16:03:25 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_32_quant_ends_True_preload/model-4163544.
[32m[0321 16:03:26 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 69%|######9   |13043/18822[03:00<01:19,72.46it/s] 73%|#######3  |13793/18822[03:10<01:09,72.46it/s]100%|##########|18822/18822[04:17<00:00,73.15it/s]
2
[32m[0321 16:07:43 @monitor.py:363][0m QueueInput/queue_size: 0.97071
[32m[0321 16:07:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 48.488
[32m[0321 16:07:43 @monitor.py:363][0m activation-summaries/output-rms: 0.038955
[32m[0321 16:07:43 @monitor.py:363][0m cross_entropy_loss: 1.7011
[32m[0321 16:07:43 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67287
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00082993
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61794
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4189
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34134
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30004
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29473
[32m[0321 16:07:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0321 16:07:43 @monitor.py:363][0m train-error-top1: 0.45838
[32m[0321 16:07:43 @monitor.py:363][0m val-error-top1: 0.45888
[32m[0321 16:07:43 @monitor.py:363][0m val-utt-error: 0.11874
[32m[0321 16:07:43 @monitor.py:363][0m validation_cost: 1.7346
[32m[0321 16:07:43 @monitor.py:363][0m wd_cost: 1.1199e-05
[32m[0321 16:07:43 @group.py:42][0m Callbacks took 257.966 sec in total. InferenceRunner: 257.324sec
[32m[0321 16:07:43 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7653/173481[03:00<1:05:01,42.51it/s]  5%|4         |8061/173481[03:10<1:04:51,42.51it/s]  8%|8         |14726/173481[06:00<1:04:47,40.84it/s]  9%|8         |15092/173481[06:10<1:04:38,40.84it/s] 12%|#2        |21599/173481[09:00<1:04:08,39.46it/s] 13%|#2        |22012/173481[09:10<1:03:58,39.46it/s] 17%|#6        |28879/173481[12:00<1:00:19,39.95it/s] 17%|#6        |29308/173481[12:10<1:00:09,39.95it/s] 21%|##        |36303/173481[15:00<56:19,40.59it/s]   21%|##1       |36838/173481[15:10<56:06,40.59it/s] 26%|##6       |45449/173481[18:00<47:17,45.13it/s] 27%|##6       |46009/173481[18:11<47:04,45.13it/s] 32%|###1      |54765/173481[21:00<41:02,48.21it/s] 32%|###1      |55345/173481[21:11<40:50,48.21it/s] 37%|###6      |64087/173481[24:00<36:30,49.94it/s] 37%|###7      |64662/173481[24:11<36:19,49.94it/s] 42%|####2     |73304/173481[27:00<33:01,50.56it/s] 43%|####2     |73891/173481[27:11<32:49,50.56it/s] 48%|####7     |82625/173481[30:00<29:35,51.16it/s] 48%|####7     |83207/173481[30:11<29:24,51.16it/s] 52%|#####2    |90729/173481[33:00<28:47,47.90it/s] 53%|#####2    |91308/173481[33:11<28:35,47.90it/s] 57%|#####7    |99654/173481[36:00<25:15,48.72it/s] 58%|#####7    |100257/173481[36:11<25:02,48.72it/s] 63%|######2   |108905/173481[39:00<21:30,50.02it/s] 63%|######3   |109505/173481[39:12<21:18,50.02it/s] 68%|######8   |118072/173481[42:00<18:17,50.47it/s] 68%|######8   |118686/173481[42:12<18:05,50.47it/s] 73%|#######3  |127288/173481[45:00<15:08,50.83it/s] 74%|#######3  |127918/173481[45:12<14:56,50.83it/s] 79%|#######9  |137522/173481[48:00<11:09,53.67it/s] 80%|#######9  |138301/173481[48:12<10:55,53.67it/s] 86%|########5 |148741/173481[51:00<07:08,57.68it/s] 86%|########6 |149516/173481[51:12<06:55,57.68it/s] 91%|#########1|158269/173481[54:00<04:35,55.20it/s] 92%|#########1|158925/173481[54:13<04:23,55.20it/s] 97%|#########6|167488/173481[57:00<01:52,53.13it/s] 97%|#########6|168158/173481[57:13<01:40,53.13it/s]100%|##########|173481/173481[58:57<00:00,49.05it/s]
[32m[0321 17:06:40 @base.py:257][0m Epoch 4 (global_step 4337025) finished, time:3537.04 sec.
[32m[0321 17:06:40 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_32_quant_ends_True_preload/model-4337025.
[32m[0321 17:06:41 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 72%|#######2  |13580/18822[03:00<01:09,75.44it/s] 76%|#######6  |14334/18822[03:10<00:59,75.44it/s]100%|##########|18822/18822[04:11<00:00,74.90it/s]
3
[32m[0321 17:10:52 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0321 17:10:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 49.196
[32m[0321 17:10:52 @monitor.py:363][0m activation-summaries/output-rms: 0.040435
[32m[0321 17:10:52 @monitor.py:363][0m cross_entropy_loss: 1.6574
[32m[0321 17:10:52 @monitor.py:363][0m lr: 1.9531e-06
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67364
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00084723
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62013
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4203
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3415
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30008
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29469
[32m[0321 17:10:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0321 17:10:52 @monitor.py:363][0m train-error-top1: 0.43772
[32m[0321 17:10:52 @monitor.py:363][0m val-error-top1: 0.45849
[32m[0321 17:10:52 @monitor.py:363][0m val-utt-error: 0.11795
[32m[0321 17:10:52 @monitor.py:363][0m validation_cost: 1.7342
[32m[0321 17:10:52 @monitor.py:363][0m wd_cost: 2.2492e-06
[32m[0321 17:10:52 @group.py:42][0m Callbacks took 251.847 sec in total. InferenceRunner: 251.302sec
[32m[0321 17:10:52 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8886/173481[03:00<55:34,49.36it/s]  5%|5         |9389/173481[03:10<55:24,49.36it/s] 10%|9         |17318/173481[06:00<54:08,48.07it/s] 10%|#         |17791/173481[06:10<53:58,48.07it/s] 15%|#4        |25610/173481[09:00<52:23,47.04it/s] 15%|#5        |26096/173481[09:10<52:12,47.04it/s] 20%|#9        |33972/173481[12:00<49:44,46.74it/s] 20%|#9        |34503/173481[12:10<49:33,46.74it/s] 25%|##4       |42528/173481[15:00<46:18,47.13it/s] 25%|##4       |43022/173481[15:10<46:07,47.13it/s] 29%|##9       |50472/173481[18:00<44:59,45.57it/s] 29%|##9       |50913/173481[18:11<44:49,45.57it/s] 33%|###3      |57932/173481[21:00<44:22,43.41it/s] 34%|###3      |58397/173481[21:11<44:11,43.41it/s] 38%|###7      |65401/173481[24:00<42:27,42.43it/s] 38%|###7      |65883/173481[24:11<42:16,42.43it/s] 42%|####1     |72808/173481[27:00<40:09,41.78it/s] 42%|####2     |73283/173481[27:11<39:58,41.78it/s] 46%|####6     |80063/173481[30:00<37:57,41.03it/s] 46%|####6     |80519/173481[30:11<37:45,41.03it/s] 50%|#####     |86772/173481[33:00<37:00,39.06it/s] 50%|#####     |87232/173481[33:11<36:48,39.06it/s] 54%|#####4    |94178/173481[36:00<32:58,40.07it/s] 55%|#####4    |94631/173481[36:12<32:47,40.07it/s] 58%|#####8    |101362/173481[39:00<30:03,39.99it/s] 59%|#####8    |101816/173481[39:12<29:52,39.99it/s] 63%|######2   |108472/173481[42:00<27:15,39.74it/s] 63%|######2   |108949/173481[42:12<27:03,39.74it/s] 67%|######6   |115453/173481[45:00<24:38,39.26it/s] 67%|######6   |115901/173481[45:12<24:26,39.26it/s] 71%|#######   |122436/173481[48:00<21:48,39.02it/s] 71%|#######   |122912/173481[48:12<21:36,39.02it/s] 74%|#######4  |128962/173481[51:00<19:44,37.58it/s] 75%|#######4  |129406/173481[51:12<19:32,37.58it/s] 79%|#######9  |137694/173481[54:00<14:05,42.35it/s] 80%|#######9  |138381/173481[54:12<13:48,42.35it/s] 85%|########4 |146636/173481[57:00<09:47,45.72it/s] 85%|########4 |147118/173481[57:13<09:36,45.72it/s] 89%|########8 |153694/173481[1:00:00<07:48,42.21it/s] 89%|########8 |154186/173481[1:00:13<07:37,42.21it/s] 93%|#########2|160788/173481[1:03:00<05:11,40.76it/s] 93%|#########2|161301/173481[1:03:13<04:58,40.76it/s] 97%|#########6|167977/173481[1:06:00<02:16,40.35it/s] 97%|#########7|168491/173481[1:06:13<02:03,40.35it/s]100%|##########|173481/173481[1:08:21<00:00,42.30it/s]
[32m[0321 18:19:14 @base.py:257][0m Epoch 5 (global_step 4510506) finished, time:4101.45 sec.
[32m[0321 18:19:14 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_32_quant_ends_True_preload/model-4510506.
[32m[0321 18:19:14 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 67%|######7   |12641/18822[03:00<01:28,70.23it/s] 71%|#######1  |13401/18822[03:10<01:17,70.23it/s]100%|##########|18822/18822[04:32<00:00,69.04it/s]
4
[32m[0321 18:23:47 @monitor.py:363][0m QueueInput/queue_size: 0.7168
[32m[0321 18:23:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 49.388
[32m[0321 18:23:47 @monitor.py:363][0m activation-summaries/output-rms: 0.04064
[32m[0321 18:23:47 @monitor.py:363][0m cross_entropy_loss: 1.69
[32m[0321 18:23:47 @monitor.py:363][0m lr: 1.9531e-06
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67397
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086498
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62169
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4212
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3416
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30011
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29467
[32m[0321 18:23:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0321 18:23:47 @monitor.py:363][0m train-error-top1: 0.4512
[32m[0321 18:23:47 @monitor.py:363][0m val-error-top1: 0.45832
[32m[0321 18:23:47 @monitor.py:363][0m val-utt-error: 0.11922
[32m[0321 18:23:47 @monitor.py:363][0m validation_cost: 1.7339
[32m[0321 18:23:47 @monitor.py:363][0m wd_cost: 2.256e-06
[32m[0321 18:23:47 @group.py:42][0m Callbacks took 273.325 sec in total. InferenceRunner: 272.634sec
[32m[0321 18:23:47 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7493/173481[03:00<1:06:27,41.63it/s]  5%|4         |7890/173481[03:10<1:06:17,41.63it/s]  8%|8         |14583/173481[06:00<1:05:25,40.48it/s]  9%|8         |14999/173481[06:10<1:05:15,40.48it/s] 13%|#2        |21742/173481[09:00<1:03:02,40.12it/s] 13%|#2        |22160/173481[09:10<1:02:51,40.12it/s] 17%|#6        |28783/173481[12:00<1:00:53,39.61it/s] 17%|#6        |29189/173481[12:10<1:00:42,39.61it/s] 20%|##        |35445/173481[15:00<1:00:07,38.26it/s] 21%|##        |35835/173481[15:10<59:57,38.26it/s]   24%|##4       |42257/173481[18:00<57:28,38.05it/s] 25%|##4       |42667/173481[18:11<57:18,38.05it/s] 28%|##8       |49174/173481[21:00<54:10,38.24it/s] 29%|##8       |49615/173481[21:11<53:59,38.24it/s] 32%|###2      |55941/173481[24:00<51:40,37.91it/s] 32%|###2      |56365/173481[24:11<51:29,37.91it/s] 36%|###6      |62673/173481[27:00<49:03,37.65it/s] 36%|###6      |63091/173481[27:11<48:52,37.65it/s] 40%|###9      |69380/173481[30:00<46:19,37.45it/s] 40%|####      |69776/173481[30:11<46:08,37.45it/s] 44%|####3     |76106/173481[33:00<43:23,37.41it/s] 44%|####4     |76535/173481[33:11<43:11,37.41it/s] 48%|####7     |82942/173481[36:00<40:02,37.69it/s] 48%|####8     |83403/173481[36:12<39:49,37.69it/s] 52%|#####1    |89836/173481[39:00<36:41,37.99it/s] 52%|#####2    |90285/173481[39:12<36:30,37.99it/s] 56%|#####5    |96674/173481[42:00<33:41,37.99it/s] 56%|#####5    |97130/173481[42:12<33:29,37.99it/s] 60%|######    |104580/173481[45:00<28:11,40.74it/s] 61%|######    |105170/173481[45:12<27:56,40.74it/s] 65%|######5   |113311/173481[48:00<22:38,44.28it/s] 66%|######5   |113787/173481[48:12<22:28,44.28it/s] 69%|######9   |120277/173481[51:00<21:28,41.30it/s] 70%|######9   |120750/173481[51:12<21:16,41.30it/s] 73%|#######3  |127277/173481[54:00<19:13,40.06it/s] 74%|#######3  |127771/173481[54:13<19:01,40.06it/s] 77%|#######7  |134230/173481[57:00<16:38,39.33it/s] 78%|#######7  |134741/173481[57:13<16:25,39.33it/s] 81%|########1 |141041/173481[1:00:00<14:01,38.57it/s] 82%|########1 |141506/173481[1:00:13<13:49,38.57it/s] 85%|########5 |147511/173481[1:03:00<11:37,37.21it/s] 85%|########5 |148002/173481[1:03:13<11:24,37.21it/s] 89%|########8 |154159/173481[1:06:00<08:41,37.07it/s] 89%|########9 |154636/173481[1:06:13<08:28,37.07it/s] 93%|#########2|160911/173481[1:09:00<05:37,37.28it/s] 93%|#########3|161425/173481[1:09:13<05:23,37.28it/s] 97%|#########6|167722/173481[1:12:00<02:33,37.56it/s] 97%|#########6|168241/173481[1:12:14<02:19,37.56it/s]100%|##########|173481/173481[1:14:42<00:00,38.70it/s]
[32m[0321 19:38:29 @base.py:257][0m Epoch 6 (global_step 4683987) finished, time:4482.15 sec.
[32m[0321 19:38:29 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_32_quant_ends_True_preload/model-4683987.
[32m[0321 19:38:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 57%|#####6    |10720/18822[03:00<02:16,59.55it/s] 60%|######    |11322/18822[03:10<02:05,59.55it/s]100%|##########|18822/18822[05:28<00:00,57.30it/s]
5
[32m[0321 19:43:58 @monitor.py:363][0m QueueInput/queue_size: 0.61802
[32m[0321 19:43:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 49.611
[32m[0321 19:43:58 @monitor.py:363][0m activation-summaries/output-rms: 0.039401
[32m[0321 19:43:58 @monitor.py:363][0m cross_entropy_loss: 1.7024
[32m[0321 19:43:58 @monitor.py:363][0m lr: 1.9531e-06
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67421
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087265
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62322
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4221
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3417
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30014
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29466
[32m[0321 19:43:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0321 19:43:58 @monitor.py:363][0m train-error-top1: 0.45412
[32m[0321 19:43:58 @monitor.py:363][0m val-error-top1: 0.45784
[32m[0321 19:43:58 @monitor.py:363][0m val-utt-error: 0.11768
[32m[0321 19:43:58 @monitor.py:363][0m validation_cost: 1.7324
[32m[0321 19:43:58 @monitor.py:363][0m wd_cost: 2.2626e-06
[32m[0321 19:43:58 @group.py:42][0m Callbacks took 329.057 sec in total. InferenceRunner: 328.531sec
[32m[0321 19:43:58 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7246/173481[03:00<1:08:49,40.25it/s]  4%|4         |7614/173481[03:10<1:08:40,40.25it/s]  8%|8         |13920/173481[06:00<1:08:53,38.60it/s]  8%|8         |14315/173481[06:10<1:08:43,38.60it/s] 12%|#1        |20760/173481[09:00<1:06:28,38.30it/s] 12%|#2        |21171/173481[09:10<1:06:17,38.30it/s] 16%|#6        |27759/173481[12:00<1:02:56,38.59it/s] 16%|#6        |28169/173481[12:10<1:02:45,38.59it/s] 20%|#9        |34445/173481[15:00<1:01:13,37.85it/s] 20%|##        |34799/173481[15:10<1:01:04,37.85it/s] 23%|##3       |40694/173481[18:00<1:01:06,36.21it/s] 24%|##3       |41110/173481[18:11<1:00:55,36.21it/s] 27%|##7       |47370/173481[21:00<57:21,36.64it/s]   28%|##7       |47769/173481[21:11<57:11,36.64it/s] 31%|###1      |54134/173481[24:00<53:36,37.10it/s] 31%|###1      |54548/173481[24:11<53:25,37.10it/s] 36%|###5      |62055/173481[27:00<46:07,40.26it/s] 36%|###6      |62665/173481[27:11<45:52,40.26it/s] 41%|####      |70972/173481[30:00<38:27,44.42it/s] 41%|####1     |71543/173481[30:11<38:14,44.42it/s] 45%|####4     |77578/173481[33:00<39:46,40.19it/s] 45%|####4     |77969/173481[33:11<39:36,40.19it/s] 48%|####8     |83416/173481[36:00<41:49,35.89it/s] 48%|####8     |83822/173481[36:12<41:37,35.89it/s] 52%|#####1    |89450/173481[39:00<40:24,34.66it/s] 52%|#####1    |89844/173481[39:12<40:12,34.66it/s] 55%|#####5    |95500/173481[42:00<38:05,34.13it/s] 55%|#####5    |95904/173481[42:12<37:53,34.13it/s] 59%|#####8    |101821/173481[45:00<34:30,34.61it/s] 59%|#####8    |102275/173481[45:12<34:17,34.61it/s] 62%|######2   |108115/173481[48:00<31:19,34.78it/s] 63%|######2   |108565/173481[48:12<31:06,34.78it/s] 66%|######6   |114564/173481[51:00<27:49,35.30it/s] 66%|######6   |114994/173481[51:12<27:37,35.30it/s] 70%|######9   |120822/173481[54:00<25:03,35.03it/s] 70%|######9   |121258/173481[54:13<24:50,35.03it/s] 73%|#######3  |127077/173481[57:00<22:10,34.89it/s] 74%|#######3  |127523/173481[57:13<21:57,34.89it/s] 77%|#######6  |133365/173481[1:00:00<19:09,34.91it/s] 77%|#######7  |133835/173481[1:00:13<18:55,34.91it/s] 81%|########  |139842/173481[1:03:00<15:49,35.44it/s] 81%|########  |140329/173481[1:03:13<15:35,35.44it/s] 84%|########4 |146232/173481[1:06:00<12:48,35.47it/s] 85%|########4 |146699/173481[1:06:13<12:35,35.47it/s] 88%|########7 |152620/173481[1:09:00<09:48,35.47it/s] 88%|########8 |153129/173481[1:09:13<09:33,35.47it/s] 92%|#########1|159186/173481[1:12:00<06:37,35.96it/s] 92%|#########2|159673/173481[1:12:14<06:23,35.96it/s] 95%|#########5|165432/173481[1:15:00<03:47,35.32it/s] 96%|#########5|165924/173481[1:15:14<03:33,35.32it/s] 99%|#########8|171705/173481[1:18:00<00:50,35.08it/s] 99%|#########9|172179/173481[1:18:14<00:37,35.08it/s]100%|##########|173481/173481[1:18:51<00:00,36.67it/s]
[32m[0321 21:02:50 @base.py:257][0m Epoch 7 (global_step 4857468) finished, time:4731.45 sec.
[32m[0321 21:02:50 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_32_quant_ends_True_preload/model-4857468.
[32m[0321 21:02:50 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 54%|#####3    |10090/18822[03:00<02:35,56.05it/s] 57%|#####6    |10668/18822[03:10<02:25,56.05it/s]100%|##########|18822/18822[05:34<00:00,56.26it/s]
6
[32m[0321 21:08:25 @monitor.py:363][0m QueueInput/queue_size: 0.82597
[32m[0321 21:08:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 50.131
[32m[0321 21:08:25 @monitor.py:363][0m activation-summaries/output-rms: 0.039353
[32m[0321 21:08:25 @monitor.py:363][0m cross_entropy_loss: 1.6998
[32m[0321 21:08:25 @monitor.py:363][0m lr: 9.7656e-07
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67443
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087545
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62413
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4226
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34176
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30016
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29465
[32m[0321 21:08:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0321 21:08:25 @monitor.py:363][0m train-error-top1: 0.44935
[32m[0321 21:08:25 @monitor.py:363][0m val-error-top1: 0.45738
[32m[0321 21:08:25 @monitor.py:363][0m val-utt-error: 0.11848
[32m[0321 21:08:25 @monitor.py:363][0m validation_cost: 1.73
[32m[0321 21:08:25 @monitor.py:363][0m wd_cost: 4.533e-07
[32m[0321 21:08:25 @group.py:42][0m Callbacks took 334.998 sec in total. InferenceRunner: 334.588sec
[32m[0321 21:08:25 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7577/173481[03:00<1:05:41,42.09it/s]  5%|4         |8080/173481[03:10<1:05:29,42.09it/s]  9%|9         |15942/173481[06:00<59:26,44.17it/s]   9%|9         |16290/173481[06:10<59:18,44.17it/s] 13%|#2        |22429/173481[09:00<1:03:26,39.68it/s] 13%|#3        |22803/173481[09:10<1:03:17,39.68it/s] 16%|#6        |28304/173481[12:00<1:07:33,35.82it/s] 17%|#6        |28633/173481[12:10<1:07:24,35.82it/s] 20%|#9        |34246/173481[15:00<1:07:32,34.36it/s] 20%|#9        |34604/173481[15:10<1:07:22,34.36it/s] 23%|##3       |40333/173481[18:00<1:05:06,34.08it/s] 23%|##3       |40703/173481[18:10<1:04:55,34.08it/s] 27%|##6       |46516/173481[21:00<1:01:50,34.21it/s] 27%|##7       |46878/173481[21:11<1:01:40,34.21it/s] 30%|###       |52607/173481[24:00<59:12,34.03it/s]   31%|###       |52983/173481[24:11<59:01,34.03it/s] 34%|###3      |58789/173481[27:00<55:55,34.18it/s] 34%|###4      |59180/173481[27:11<55:44,34.18it/s] 37%|###7      |65029/173481[30:00<52:30,34.42it/s] 38%|###7      |65415/173481[30:11<52:19,34.42it/s] 41%|####1     |71784/173481[33:00<47:12,35.91it/s] 42%|####1     |72209/173481[33:11<47:00,35.91it/s] 45%|####5     |78366/173481[36:00<43:45,36.23it/s] 45%|####5     |78794/173481[36:11<43:33,36.23it/s] 49%|####8     |84774/173481[39:00<41:10,35.91it/s] 49%|####9     |85185/173481[39:12<40:58,35.91it/s] 53%|#####2    |91252/173481[42:00<38:07,35.95it/s] 53%|#####2    |91638/173481[42:12<37:56,35.95it/s] 56%|#####5    |97071/173481[45:00<37:24,34.04it/s] 56%|#####6    |97478/173481[45:12<37:12,34.04it/s] 59%|#####9    |102923/173481[48:00<35:21,33.26it/s] 60%|#####9    |103328/173481[48:12<35:09,33.26it/s] 63%|######2   |108654/173481[51:00<33:13,32.52it/s] 63%|######2   |109033/173481[51:12<33:01,32.52it/s] 66%|######5   |114467/173481[54:00<30:20,32.41it/s] 66%|######6   |114881/173481[54:12<30:08,32.41it/s] 69%|######9   |120299/173481[57:00<27:21,32.40it/s] 70%|######9   |120683/173481[57:13<27:09,32.40it/s] 73%|#######2  |126047/173481[1:00:00<24:34,32.16it/s] 73%|#######2  |126452/173481[1:00:13<24:22,32.16it/s] 76%|#######6  |132414/173481[1:03:00<20:19,33.69it/s] 77%|#######6  |133089/173481[1:03:13<19:58,33.69it/s] 82%|########1 |142196/173481[1:06:00<12:32,41.59it/s] 82%|########2 |142901/173481[1:06:13<12:15,41.59it/s] 87%|########6 |150427/173481[1:09:00<08:49,43.56it/s] 87%|########6 |150904/173481[1:09:13<08:38,43.56it/s] 90%|######### |156899/173481[1:12:00<07:01,39.39it/s] 91%|######### |157384/173481[1:12:14<06:48,39.39it/s] 94%|#########4|163308/173481[1:15:00<04:32,37.40it/s] 94%|#########4|163807/173481[1:15:14<04:18,37.40it/s] 98%|#########7|169825/173481[1:18:00<01:39,36.79it/s] 98%|#########8|170326/173481[1:18:14<01:25,36.79it/s]100%|##########|173481/173481[1:19:41<00:00,36.28it/s]
[32m[0321 22:28:06 @base.py:257][0m Epoch 8 (global_step 5030949) finished, time:4781.84 sec.
[32m[0321 22:28:07 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_32_quant_ends_True_preload/model-5030949.
[32m[0321 22:28:07 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 50%|####9     |9359/18822[03:00<03:02,51.99it/s] 53%|#####3    |10012/18822[03:13<02:49,51.99it/s]100%|##########|18822/18822[05:49<00:00,53.80it/s]
7
[32m[0321 22:33:57 @monitor.py:363][0m QueueInput/queue_size: 0.59427
[32m[0321 22:33:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 49.983
[32m[0321 22:33:57 @monitor.py:363][0m activation-summaries/output-rms: 0.039141
[32m[0321 22:33:57 @monitor.py:363][0m cross_entropy_loss: 1.6951
[32m[0321 22:33:57 @monitor.py:363][0m lr: 9.7656e-07
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67459
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087914
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62486
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.423
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3418
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30017
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29465
[32m[0321 22:33:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0321 22:33:57 @monitor.py:363][0m train-error-top1: 0.45497
[32m[0321 22:33:57 @monitor.py:363][0m val-error-top1: 0.45757
[32m[0321 22:33:57 @monitor.py:363][0m val-utt-error: 0.11593
[32m[0321 22:33:57 @monitor.py:363][0m validation_cost: 1.7282
[32m[0321 22:33:57 @monitor.py:363][0m wd_cost: 4.5393e-07
[32m[0321 22:33:57 @group.py:42][0m Callbacks took 350.479 sec in total. InferenceRunner: 349.882sec
[32m[0321 22:33:57 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|3         |6772/173481[03:00<1:13:52,37.61it/s]  4%|4         |7126/173481[03:10<1:13:42,37.61it/s]  8%|7         |13077/173481[06:00<1:13:42,36.27it/s]  8%|7         |13432/173481[06:10<1:13:32,36.27it/s] 11%|#1        |19228/173481[09:00<1:13:03,35.19it/s] 11%|#1        |19587/173481[09:10<1:12:53,35.19it/s] 15%|#4        |25479/173481[12:00<1:10:34,34.96it/s] 15%|#4        |25844/173481[12:10<1:10:23,34.96it/s] 18%|#8        |31674/173481[15:00<1:08:08,34.68it/s] 18%|#8        |32066/173481[15:10<1:07:57,34.68it/s] 22%|##1       |37933/173481[18:00<1:05:03,34.73it/s] 22%|##2       |38322/173481[18:11<1:04:51,34.73it/s] 25%|##5       |44226/173481[21:00<1:01:49,34.84it/s] 26%|##5       |44591/173481[21:11<1:01:39,34.84it/s] 29%|##9       |50499/173481[24:00<58:49,34.85it/s]   29%|##9       |50907/173481[24:11<58:37,34.85it/s] 33%|###2      |56914/173481[27:00<55:08,35.24it/s] 33%|###3      |57323/173481[27:11<54:56,35.24it/s] 37%|###6      |63548/173481[30:00<50:51,36.03it/s] 37%|###6      |63986/173481[30:11<50:39,36.03it/s] 41%|####1     |71193/173481[33:00<43:43,38.98it/s] 41%|####1     |71855/173481[33:11<43:27,38.98it/s] 47%|####6     |81238/173481[36:00<33:29,45.90it/s] 47%|####7     |81917/173481[36:12<33:14,45.90it/s] 51%|#####     |88191/173481[39:00<33:53,41.95it/s] 51%|#####1    |88602/173481[39:12<33:43,41.95it/s] 55%|#####4    |94634/173481[42:00<34:01,38.62it/s] 55%|#####4    |95071/173481[42:12<33:50,38.62it/s] 58%|#####8    |101127/173481[45:00<32:19,37.30it/s] 59%|#####8    |101570/173481[45:12<32:07,37.30it/s] 62%|######1   |107526/173481[48:00<30:11,36.40it/s] 62%|######2   |107966/173481[48:12<29:59,36.40it/s]slurmstepd: *** STEP 82197.0 ON sls-tesla-0 CANCELLED AT 2018-03-21T23:22:54 ***
slurmstepd: *** JOB 82197 ON sls-tesla-0 CANCELLED AT 2018-03-21T23:22:54 ***
srun: got SIGCONT
srun: forcing job termination
