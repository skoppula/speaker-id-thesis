sls-tesla-1 0
SLURM_JOBID=82332
SLURM_TASKID=1
[32m[0321 23:50:27 @logger.py:74][0m Argv: drf_run.py --model_name=fcn2 --bitw=2 --bita=2 --quant_ends=True
[32m[0321 23:50:32 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0321 23:50:32 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0321 23:50:32 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0321 23:50:32 @drf_run.py:166][0m Using host: sls-tesla-1
[32m[0321 23:50:32 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0321 23:50:32 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0321 23:50:32 @drf_run.py:188][0m Using GPU: 0
[32m[0321 23:50:32 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0321 23:50:32 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0321 23:50:32 @training.py:108][0m Building graph for training tower 0 ...
[32m[0321 23:50:32 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0321 23:50:32 @registry.py:130][0m linear0 output: [None, 504]
[32m[0321 23:50:32 @registry.py:122][0m linear1 input: [None, 504]
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0321 23:50:32 @registry.py:130][0m linear1 output: [None, 504]
[32m[0321 23:50:32 @registry.py:122][0m linear2 input: [None, 504]
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0321 23:50:32 @registry.py:130][0m linear2 output: [None, 504]
[32m[0321 23:50:32 @registry.py:122][0m linear3 input: [None, 504]
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0321 23:50:32 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0321 23:50:32 @registry.py:130][0m linear3 output: [None, 504]
[32m[0321 23:50:32 @registry.py:122][0m last_linear input: [None, 504]
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0321 23:50:32 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0321 23:50:32 @registry.py:130][0m last_linear output: [None, 255]
[32m[0321 23:50:32 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0321 23:50:33 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0321 23:50:33 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0321 23:50:33 @drf_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0321 23:50:34 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=1400871, size=5.34MB[0m
[32m[0321 23:50:34 @base.py:196][0m Setup callbacks graph ...
[32m[0321 23:50:34 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0321 23:50:34 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0321 23:50:34 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0321 23:50:34 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0321 23:50:34 @drf_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0321 23:50:34 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0321 23:50:34 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0321 23:50:35 @base.py:212][0m Creating the session ...
2018-03-21 23:50:35.650589: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-03-21 23:50:37.540550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:05:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-21 23:50:37.540601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:05:00.0, compute capability: 6.1)
[32m[0321 23:50:43 @base.py:220][0m Initializing the session ...
[32m[0321 23:50:43 @base.py:227][0m Graph Finalized.
[32m[0321 23:50:43 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0321 23:50:45 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14271/173481[03:00<33:28,79.28it/s]  9%|8         |15099/173481[03:10<33:17,79.28it/s] 17%|#6        |29218/173481[06:00<29:38,81.12it/s] 17%|#7        |30091/173481[06:10<29:27,81.12it/s] 26%|##5       |44385/173481[09:00<26:01,82.66it/s] 26%|##6       |45262/173481[09:10<25:51,82.66it/s] 34%|###4      |59717/173481[12:00<22:35,83.90it/s] 35%|###4      |60628/173481[12:10<22:25,83.90it/s] 43%|####3     |75141/173481[15:00<19:19,84.78it/s] 44%|####3     |76079/173481[15:10<19:08,84.78it/s] 52%|#####2    |90655/173481[18:00<16:08,85.48it/s] 53%|#####2    |91600/173481[18:11<15:57,85.48it/s] 59%|#####8    |101961/173481[21:00<16:27,72.41it/s] 59%|#####9    |102625/173481[21:11<16:18,72.41it/s] 65%|######4   |112487/173481[24:00<15:42,64.70it/s] 65%|######5   |113119/173481[24:11<15:32,64.70it/s] 71%|#######1  |123177/173481[27:00<13:32,61.93it/s] 71%|#######1  |123883/173481[27:11<13:20,61.93it/s] 77%|#######7  |133780/173481[30:00<10:57,60.38it/s] 77%|#######7  |134405/173481[30:11<10:47,60.38it/s] 83%|########3 |144394/173481[33:00<08:07,59.66it/s] 84%|########3 |145071/173481[33:11<07:56,59.66it/s] 89%|########8 |154152/173481[36:00<05:40,56.81it/s] 89%|########9 |154825/173481[36:12<05:28,56.81it/s] 95%|#########4|164803/173481[39:00<02:29,57.96it/s] 95%|#########5|165525/173481[39:12<02:17,57.96it/s]100%|##########|173481/173481[41:25<00:00,69.80it/s]
[32m[0322 00:32:10 @base.py:257][0m Epoch 1 (global_step 173481) finished, time:2485.50 sec.
[32m[0322 00:32:11 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:39<00:00,117.91it/s]
0
[32m[0322 00:34:51 @monitor.py:363][0m QueueInput/queue_size: 1.3578
[32m[0322 00:34:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 2.7799
[32m[0322 00:34:51 @monitor.py:363][0m activation-summaries/output-rms: 0.020976
[32m[0322 00:34:51 @monitor.py:363][0m cross_entropy_loss: 3.5524
[32m[0322 00:34:51 @monitor.py:363][0m lr: 0.001
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.097664
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.71245
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.072023
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.082267
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.072748
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.068043
[32m[0322 00:34:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 00:34:51 @monitor.py:363][0m train-error-top1: 0.79657
[32m[0322 00:34:51 @monitor.py:363][0m val-error-top1: 0.86016
[32m[0322 00:34:51 @monitor.py:363][0m val-utt-error: 0.66571
[32m[0322 00:34:51 @monitor.py:363][0m validation_cost: 4.0089
[32m[0322 00:34:51 @monitor.py:363][0m wd_cost: 0.80788
[32m[0322 00:34:51 @group.py:42][0m Callbacks took 160.342 sec in total. InferenceRunner: 159.646sec
[32m[0322 00:34:51 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10901/173481[03:00<44:44,60.56it/s]  7%|6         |11498/173481[03:10<44:34,60.56it/s] 13%|#2        |21745/173481[06:00<41:52,60.40it/s] 13%|#2        |22404/173481[06:10<41:41,60.40it/s] 19%|#8        |32165/173481[09:00<39:50,59.12it/s] 19%|#8        |32764/173481[09:10<39:40,59.12it/s] 24%|##4       |42004/173481[12:00<38:34,56.80it/s] 25%|##4       |42597/173481[12:10<38:24,56.80it/s] 30%|##9       |51732/173481[15:00<36:38,55.39it/s] 30%|###       |52339/173481[15:10<36:27,55.39it/s] 36%|###5      |61780/173481[18:00<33:29,55.60it/s] 36%|###5      |62449/173481[18:11<33:16,55.60it/s] 42%|####1     |72582/173481[21:00<29:08,57.72it/s] 42%|####2     |73289/173481[21:11<28:55,57.72it/s] 48%|####8     |83600/173481[24:00<25:13,59.41it/s] 49%|####8     |84284/173481[24:11<25:01,59.41it/s] 54%|#####4    |94335/173481[27:00<22:09,59.52it/s] 55%|#####4    |95042/173481[27:11<21:57,59.52it/s] 61%|######    |105434/173481[30:00<18:43,60.57it/s] 61%|######1   |106129/173481[30:11<18:31,60.57it/s] 67%|######7   |116520/173481[33:00<15:32,61.07it/s] 68%|######7   |117232/173481[33:11<15:21,61.07it/s] 73%|#######3  |127295/173481[36:00<12:43,60.46it/s] 74%|#######3  |128022/173481[36:12<12:31,60.46it/s] 79%|#######9  |137534/173481[39:00<10:13,58.62it/s] 80%|#######9  |138215/173481[39:12<10:01,58.62it/s] 86%|########5 |148690/173481[42:00<06:51,60.24it/s] 86%|########6 |149444/173481[42:12<06:38,60.24it/s] 92%|#########2|159875/173481[45:00<03:42,61.17it/s] 93%|#########2|160599/173481[45:12<03:30,61.17it/s] 99%|#########8|170909/173481[48:00<00:42,61.24it/s] 99%|#########8|171729/173481[48:12<00:28,61.24it/s]100%|##########|173481/173481[48:40<00:00,59.40it/s]
[32m[0322 01:23:31 @base.py:257][0m Epoch 2 (global_step 346962) finished, time:2920.51 sec.
[32m[0322 01:23:31 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-346962.
[32m[0322 01:23:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.64it/s]
1
[32m[0322 01:25:35 @monitor.py:363][0m QueueInput/queue_size: 1.045
[32m[0322 01:25:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 2.7545
[32m[0322 01:25:35 @monitor.py:363][0m activation-summaries/output-rms: 0.021001
[32m[0322 01:25:35 @monitor.py:363][0m cross_entropy_loss: 3.5559
[32m[0322 01:25:35 @monitor.py:363][0m lr: 0.001
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.095345
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.97931
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.07336
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.08434
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.073101
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.067111
[32m[0322 01:25:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 01:25:35 @monitor.py:363][0m train-error-top1: 0.79625
[32m[0322 01:25:35 @monitor.py:363][0m val-error-top1: 0.86076
[32m[0322 01:25:35 @monitor.py:363][0m val-utt-error: 0.67538
[32m[0322 01:25:35 @monitor.py:363][0m validation_cost: 4.0138
[32m[0322 01:25:35 @monitor.py:363][0m wd_cost: 0.81859
[32m[0322 01:25:35 @group.py:42][0m Callbacks took 124.050 sec in total. InferenceRunner: 123.319sec
[32m[0322 01:25:35 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12619/173481[03:00<38:14,70.10it/s]  8%|7         |13294/173481[03:10<38:04,70.10it/s] 14%|#3        |23789/173481[06:00<37:54,65.80it/s] 14%|#3        |23993/173481[06:10<37:51,65.80it/s] 19%|#9        |33049/173481[09:00<40:32,57.74it/s] 19%|#9        |33651/173481[09:10<40:21,57.74it/s] 25%|##5       |43477/173481[12:00<37:27,57.83it/s] 25%|##5       |44098/173481[12:10<37:17,57.83it/s] 31%|###1      |53989/173481[15:00<34:16,58.11it/s] 31%|###1      |54606/173481[15:10<34:05,58.11it/s] 37%|###7      |64581/173481[18:00<31:02,58.47it/s] 38%|###7      |65282/173481[18:11<30:50,58.47it/s] 43%|####3     |75014/173481[21:00<28:11,58.21it/s] 44%|####3     |75703/173481[21:11<27:59,58.21it/s] 50%|####9     |86718/173481[24:00<23:32,61.43it/s] 50%|#####     |87363/173481[24:11<23:21,61.43it/s] 57%|#####6    |98212/173481[27:00<20:02,62.61it/s] 57%|#####7    |98963/173481[27:11<19:50,62.61it/s] 63%|######3   |109851/173481[30:00<16:40,63.62it/s] 64%|######3   |110618/173481[30:11<16:28,63.62it/s] 70%|######9   |121394/173481[33:00<13:35,63.87it/s] 70%|#######   |122084/173481[33:11<13:24,63.87it/s] 77%|#######6  |132789/173481[36:00<10:40,63.57it/s] 77%|#######6  |133534/173481[36:12<10:28,63.57it/s] 83%|########3 |144666/173481[39:00<07:24,64.75it/s] 84%|########3 |145428/173481[39:12<07:13,64.75it/s] 90%|######### |156256/173481[42:00<04:26,64.57it/s] 91%|######### |157038/173481[42:12<04:14,64.57it/s] 97%|#########7|168312/173481[45:00<01:18,65.75it/s] 98%|#########7|169148/173481[45:12<01:05,65.75it/s]100%|##########|173481/173481[46:20<00:00,62.39it/s]
[32m[0322 02:11:56 @base.py:257][0m Epoch 3 (global_step 520443) finished, time:2780.73 sec.
[32m[0322 02:11:56 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-520443.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,162.55it/s]
2
[32m[0322 02:13:52 @monitor.py:363][0m QueueInput/queue_size: 1.1231
[32m[0322 02:13:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9227
[32m[0322 02:13:52 @monitor.py:363][0m activation-summaries/output-rms: 0.026791
[32m[0322 02:13:52 @monitor.py:363][0m cross_entropy_loss: 3.0274
[32m[0322 02:13:52 @monitor.py:363][0m lr: 0.0005
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.16117
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1465
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12465
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13937
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12565
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11447
[32m[0322 02:13:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 02:13:52 @monitor.py:363][0m train-error-top1: 0.71788
[32m[0322 02:13:52 @monitor.py:363][0m val-error-top1: 0.76098
[32m[0322 02:13:52 @monitor.py:363][0m val-utt-error: 0.43529
[32m[0322 02:13:52 @monitor.py:363][0m validation_cost: 3.3047
[32m[0322 02:13:52 @monitor.py:363][0m wd_cost: 0.46882
[32m[0322 02:13:52 @group.py:42][0m Callbacks took 116.074 sec in total. InferenceRunner: 115.800sec
[32m[0322 02:13:52 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12417/173481[03:00<38:54,68.98it/s]  8%|7         |13028/173481[03:10<38:46,68.98it/s] 13%|#3        |23176/173481[06:00<39:06,64.05it/s] 14%|#3        |23792/173481[06:10<38:57,64.05it/s] 20%|#9        |33853/173481[09:00<37:47,61.59it/s] 20%|#9        |34510/173481[09:10<37:36,61.59it/s] 26%|##5       |44838/173481[12:00<34:58,61.30it/s] 26%|##6       |45579/173481[12:10<34:46,61.30it/s] 33%|###2      |56563/173481[15:00<30:51,63.15it/s] 33%|###2      |57247/173481[15:10<30:40,63.15it/s] 39%|###9      |68050/173481[18:00<27:40,63.48it/s] 40%|###9      |68717/173481[18:11<27:30,63.48it/s] 46%|####5     |79515/173481[21:00<24:37,63.59it/s] 46%|####6     |80214/173481[21:11<24:26,63.59it/s] 52%|#####2    |91018/173481[24:00<21:33,63.73it/s] 53%|#####2    |91719/173481[24:11<21:22,63.73it/s] 59%|#####9    |102683/173481[27:00<18:21,64.27it/s] 60%|#####9    |103403/173481[27:11<18:10,64.27it/s] 66%|######5   |114195/173481[30:00<15:24,64.11it/s] 66%|######6   |114917/173481[30:11<15:13,64.11it/s] 72%|#######2  |125396/173481[33:00<12:41,63.15it/s] 73%|#######2  |126057/173481[33:11<12:30,63.15it/s] 79%|#######9  |137208/173481[36:00<09:23,64.36it/s] 80%|#######9  |137975/173481[36:12<09:11,64.36it/s] 86%|########5 |148686/173481[39:00<06:27,64.06it/s] 86%|########6 |149458/173481[39:12<06:15,64.06it/s] 92%|#########2|160180/173481[42:00<03:27,63.96it/s] 93%|#########2|160942/173481[42:12<03:16,63.96it/s] 99%|#########8|171354/173481[45:00<00:33,63.00it/s] 99%|#########9|172090/173481[45:12<00:22,63.00it/s]100%|##########|173481/173481[45:34<00:00,63.43it/s]
[32m[0322 02:59:27 @base.py:257][0m Epoch 4 (global_step 693924) finished, time:2734.87 sec.
[32m[0322 02:59:27 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-693924.
[32m[0322 02:59:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,162.50it/s]
3
[32m[0322 03:01:23 @monitor.py:363][0m QueueInput/queue_size: 0.83093
[32m[0322 03:01:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.667
[32m[0322 03:01:23 @monitor.py:363][0m activation-summaries/output-rms: 0.027435
[32m[0322 03:01:23 @monitor.py:363][0m cross_entropy_loss: 2.991
[32m[0322 03:01:23 @monitor.py:363][0m lr: 0.0005
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.17439
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2576
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12922
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14992
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.13642
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.12294
[32m[0322 03:01:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 03:01:23 @monitor.py:363][0m train-error-top1: 0.70143
[32m[0322 03:01:23 @monitor.py:363][0m val-error-top1: 0.75018
[32m[0322 03:01:23 @monitor.py:363][0m val-utt-error: 0.41281
[32m[0322 03:01:23 @monitor.py:363][0m validation_cost: 3.2544
[32m[0322 03:01:23 @monitor.py:363][0m wd_cost: 0.53199
[32m[0322 03:01:23 @group.py:42][0m Callbacks took 116.545 sec in total. InferenceRunner: 115.844sec
[32m[0322 03:01:23 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12018/173481[03:00<40:18,66.77it/s]  7%|7         |12680/173481[03:10<40:08,66.77it/s] 13%|#3        |23132/173481[06:00<39:03,64.15it/s] 14%|#3        |23735/173481[06:10<38:54,64.15it/s] 20%|##        |34808/173481[09:00<35:49,64.51it/s] 20%|##        |35438/173481[09:10<35:39,64.51it/s] 27%|##6       |46367/173481[12:00<32:55,64.36it/s] 27%|##7       |46987/173481[12:10<32:45,64.36it/s] 33%|###3      |57924/173481[15:00<29:57,64.28it/s] 34%|###3      |58618/173481[15:10<29:46,64.28it/s] 40%|###9      |69197/173481[18:00<27:24,63.43it/s] 40%|####      |69821/173481[18:11<27:14,63.43it/s] 46%|####6     |80533/173481[21:00<24:30,63.20it/s] 47%|####6     |81236/173481[21:11<24:19,63.20it/s] 53%|#####2    |91866/173481[24:00<21:33,63.08it/s] 53%|#####3    |92537/173481[24:11<21:23,63.08it/s] 59%|#####9    |103211/173481[27:00<18:34,63.05it/s] 60%|#####9    |103883/173481[27:11<18:23,63.05it/s] 66%|######6   |114612/173481[30:00<15:31,63.19it/s] 66%|######6   |115332/173481[30:11<15:20,63.19it/s] 73%|#######2  |126023/173481[33:00<12:29,63.29it/s] 73%|#######3  |126791/173481[33:11<12:17,63.29it/s] 79%|#######9  |137787/173481[36:00<09:15,64.31it/s] 80%|#######9  |138599/173481[36:12<09:02,64.31it/s] 86%|########6 |149552/173481[39:00<06:09,64.83it/s] 87%|########6 |150324/173481[39:12<05:57,64.83it/s] 93%|#########3|161520/173481[42:00<03:02,65.65it/s] 94%|#########3|162301/173481[42:12<02:50,65.65it/s]100%|#########9|172728/173481[45:00<00:11,63.91it/s]100%|#########9|173459/173481[45:12<00:00,63.91it/s]100%|##########|173481/173481[45:12<00:00,63.95it/s]
[32m[0322 03:46:36 @base.py:257][0m Epoch 5 (global_step 867405) finished, time:2712.93 sec.
[32m[0322 03:46:37 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-867405.
[32m[0322 03:46:37 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.12it/s]
4
[32m[0322 03:48:31 @monitor.py:363][0m QueueInput/queue_size: 0.73855
[32m[0322 03:48:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.6765
[32m[0322 03:48:31 @monitor.py:363][0m activation-summaries/output-rms: 0.029263
[32m[0322 03:48:31 @monitor.py:363][0m cross_entropy_loss: 2.9299
[32m[0322 03:48:31 @monitor.py:363][0m lr: 0.0005
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.17655
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3618
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12961
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.15163
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.13792
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.12455
[32m[0322 03:48:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 03:48:31 @monitor.py:363][0m train-error-top1: 0.69411
[32m[0322 03:48:31 @monitor.py:363][0m val-error-top1: 0.74853
[32m[0322 03:48:31 @monitor.py:363][0m val-utt-error: 0.41398
[32m[0322 03:48:31 @monitor.py:363][0m validation_cost: 3.2739
[32m[0322 03:48:31 @monitor.py:363][0m wd_cost: 0.5417
[32m[0322 03:48:31 @group.py:42][0m Callbacks took 114.631 sec in total. InferenceRunner: 114.005sec
[32m[0322 03:48:31 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14359/173481[03:00<33:14,79.77it/s]  9%|8         |15110/173481[03:10<33:05,79.77it/s] 16%|#5        |27464/173481[06:00<31:58,76.13it/s] 16%|#6        |28232/173481[06:10<31:47,76.13it/s] 23%|##3       |40414/173481[09:00<29:58,73.98it/s] 24%|##3       |41214/173481[09:10<29:47,73.98it/s] 31%|###1      |53929/173481[12:00<26:44,74.53it/s] 32%|###1      |54667/173481[12:10<26:34,74.53it/s] 39%|###9      |67740/173481[15:00<23:18,75.61it/s] 39%|###9      |68480/173481[15:10<23:08,75.61it/s] 47%|####6     |80870/173481[18:00<20:47,74.25it/s] 47%|####7     |81660/173481[18:11<20:36,74.25it/s] 54%|#####3    |93654/173481[21:00<18:19,72.60it/s] 54%|#####4    |94371/173481[21:11<18:09,72.60it/s] 62%|######1   |107015/173481[24:00<15:05,73.40it/s] 62%|######2   |107870/173481[24:11<14:53,73.40it/s] 69%|######9   |120061/173481[27:00<12:12,72.94it/s] 70%|######9   |120926/173481[27:11<12:00,72.94it/s] 76%|#######6  |132686/173481[30:00<09:30,71.51it/s] 77%|#######6  |133445/173481[30:11<09:19,71.51it/s] 83%|########3 |144841/173481[33:00<06:52,69.46it/s] 84%|########3 |145564/173481[33:11<06:41,69.46it/s] 91%|#########1|158184/173481[36:00<03:33,71.72it/s] 92%|#########1|159019/173481[36:12<03:21,71.72it/s] 99%|#########8|171296/173481[39:00<00:30,72.27it/s] 99%|#########9|172148/173481[39:12<00:18,72.27it/s]100%|##########|173481/173481[39:31<00:00,73.14it/s]
[32m[0322 04:28:03 @base.py:257][0m Epoch 6 (global_step 1040886) finished, time:2371.90 sec.
[32m[0322 04:28:03 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-1040886.
[32m[0322 04:28:04 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.05it/s]
5
[32m[0322 04:30:00 @monitor.py:363][0m QueueInput/queue_size: 1.6538
[32m[0322 04:30:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.6461
[32m[0322 04:30:00 @monitor.py:363][0m activation-summaries/output-rms: 0.03145
[32m[0322 04:30:00 @monitor.py:363][0m cross_entropy_loss: 2.6561
[32m[0322 04:30:00 @monitor.py:363][0m lr: 0.00025
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.24389
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4311
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.21424
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.21946
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20266
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18362
[32m[0322 04:30:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 04:30:00 @monitor.py:363][0m train-error-top1: 0.64592
[32m[0322 04:30:00 @monitor.py:363][0m val-error-top1: 0.69438
[32m[0322 04:30:00 @monitor.py:363][0m val-utt-error: 0.32404
[32m[0322 04:30:00 @monitor.py:363][0m validation_cost: 2.9444
[32m[0322 04:30:00 @monitor.py:363][0m wd_cost: 0.24801
[32m[0322 04:30:00 @group.py:42][0m Callbacks took 116.607 sec in total. InferenceRunner: 115.444sec
[32m[0322 04:30:00 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13125/173481[03:00<36:39,72.91it/s]  8%|7         |13809/173481[03:10<36:29,72.91it/s] 14%|#4        |24708/173481[06:00<36:16,68.36it/s] 15%|#4        |25344/173481[06:10<36:06,68.36it/s] 21%|##        |35733/173481[09:00<35:31,64.61it/s] 21%|##        |36319/173481[09:10<35:22,64.61it/s] 26%|##6       |45879/173481[12:00<35:19,60.21it/s] 27%|##6       |46509/173481[12:10<35:08,60.21it/s] 33%|###2      |56892/173481[15:00<32:01,60.69it/s] 33%|###3      |57539/173481[15:10<31:50,60.69it/s] 39%|###9      |67837/173481[18:00<28:59,60.75it/s] 40%|###9      |68525/173481[18:10<28:47,60.75it/s] 46%|####5     |79004/173481[21:00<25:39,61.39it/s] 46%|####5     |79696/173481[21:11<25:27,61.39it/s] 52%|#####2    |90830/173481[24:00<21:42,63.46it/s] 53%|#####2    |91568/173481[24:11<21:30,63.46it/s] 59%|#####9    |102511/173481[27:00<18:25,64.17it/s] 60%|#####9    |103281/173481[27:11<18:13,64.17it/s] 66%|######5   |114080/173481[30:00<15:25,64.21it/s] 66%|######6   |114774/173481[30:11<15:14,64.21it/s] 72%|#######2  |125163/173481[33:00<12:48,62.86it/s] 73%|#######2  |125854/173481[33:11<12:37,62.86it/s] 78%|#######8  |136090/173481[36:00<10:05,61.76it/s] 79%|#######8  |136803/173481[36:11<09:53,61.76it/s] 85%|########5 |148055/173481[39:00<06:37,64.02it/s] 86%|########5 |148763/173481[39:12<06:26,64.02it/s] 92%|#########2|159614/173481[42:00<03:36,64.12it/s] 92%|#########2|160360/173481[42:12<03:24,64.12it/s] 98%|#########8|170793/173481[45:00<00:42,63.09it/s] 99%|#########8|171585/173481[45:12<00:30,63.09it/s]100%|##########|173481/173481[45:42<00:00,63.27it/s]
[32m[0322 05:15:42 @base.py:257][0m Epoch 7 (global_step 1214367) finished, time:2742.12 sec.
[32m[0322 05:15:42 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-1214367.
[32m[0322 05:15:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.76it/s]
6
[32m[0322 05:17:37 @monitor.py:363][0m QueueInput/queue_size: 1.0243
[32m[0322 05:17:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.7603
[32m[0322 05:17:37 @monitor.py:363][0m activation-summaries/output-rms: 0.031581
[32m[0322 05:17:37 @monitor.py:363][0m cross_entropy_loss: 2.6954
[32m[0322 05:17:37 @monitor.py:363][0m lr: 0.00025
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.29537
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4763
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.23574
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26822
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2492
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.22206
[32m[0322 05:17:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 05:17:37 @monitor.py:363][0m train-error-top1: 0.65224
[32m[0322 05:17:37 @monitor.py:363][0m val-error-top1: 0.69438
[32m[0322 05:17:37 @monitor.py:363][0m val-utt-error: 0.32149
[32m[0322 05:17:37 @monitor.py:363][0m validation_cost: 2.9491
[32m[0322 05:17:37 @monitor.py:363][0m wd_cost: 0.34318
[32m[0322 05:17:37 @group.py:42][0m Callbacks took 115.843 sec in total. InferenceRunner: 114.944sec
[32m[0322 05:17:37 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12398/173481[03:00<38:58,68.88it/s]  8%|7         |13111/173481[03:10<38:48,68.88it/s] 14%|#4        |24349/173481[06:00<36:45,67.61it/s] 14%|#4        |24943/173481[06:10<36:37,67.61it/s] 21%|##        |35924/173481[09:00<34:47,65.91it/s] 21%|##1       |36628/173481[09:10<34:36,65.91it/s] 27%|##7       |47332/173481[12:00<32:32,64.62it/s] 28%|##7       |47898/173481[12:10<32:23,64.62it/s] 33%|###3      |58019/173481[15:00<31:05,61.88it/s] 34%|###3      |58667/173481[15:10<30:55,61.88it/s] 40%|####      |69686/173481[18:00<27:19,63.31it/s] 41%|####      |70313/173481[18:11<27:09,63.31it/s] 47%|####6     |81439/173481[21:00<23:51,64.28it/s] 47%|####7     |82103/173481[21:11<23:41,64.28it/s] 54%|#####3    |93182/173481[24:00<20:40,64.76it/s] 54%|#####4    |93920/173481[24:11<20:28,64.76it/s] 60%|######    |104539/173481[27:00<17:58,63.91it/s] 61%|######    |105191/173481[27:11<17:48,63.91it/s] 67%|######7   |116331/173481[30:00<14:43,64.70it/s] 68%|######7   |117150/173481[30:11<14:30,64.70it/s] 74%|#######4  |128481/173481[33:00<11:21,66.07it/s] 74%|#######4  |129232/173481[33:11<11:09,66.07it/s] 81%|########  |140455/173481[36:00<08:18,66.30it/s] 81%|########1 |141280/173481[36:12<08:05,66.30it/s] 88%|########8 |152838/173481[39:00<05:05,67.52it/s] 89%|########8 |153708/173481[39:12<04:52,67.52it/s] 95%|#########5|165132/173481[42:00<02:02,67.91it/s] 96%|#########5|165953/173481[42:12<01:50,67.91it/s]100%|##########|173481/173481[44:08<00:00,65.50it/s]
[32m[0322 06:01:46 @base.py:257][0m Epoch 8 (global_step 1387848) finished, time:2648.45 sec.
[32m[0322 06:01:46 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-1387848.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.10it/s]
7
[32m[0322 06:03:42 @monitor.py:363][0m QueueInput/queue_size: 1.1738
[32m[0322 06:03:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.5098
[32m[0322 06:03:42 @monitor.py:363][0m activation-summaries/output-rms: 0.031342
[32m[0322 06:03:42 @monitor.py:363][0m cross_entropy_loss: 2.6389
[32m[0322 06:03:42 @monitor.py:363][0m lr: 0.00025
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.30802
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.5205
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.23777
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2769
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25707
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.22801
[32m[0322 06:03:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 06:03:42 @monitor.py:363][0m train-error-top1: 0.64653
[32m[0322 06:03:42 @monitor.py:363][0m val-error-top1: 0.6915
[32m[0322 06:03:42 @monitor.py:363][0m val-utt-error: 0.30852
[32m[0322 06:03:42 @monitor.py:363][0m validation_cost: 2.9261
[32m[0322 06:03:42 @monitor.py:363][0m wd_cost: 0.36062
[32m[0322 06:03:42 @group.py:42][0m Callbacks took 115.721 sec in total. InferenceRunner: 115.416sec
[32m[0322 06:03:42 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13133/173481[03:00<36:38,72.95it/s]  8%|7         |13814/173481[03:10<36:28,72.95it/s] 14%|#4        |24478/173481[06:00<36:43,67.62it/s] 14%|#4        |25078/173481[06:10<36:34,67.62it/s] 21%|##1       |36509/173481[09:00<33:57,67.23it/s] 21%|##1       |37217/173481[09:10<33:46,67.23it/s] 28%|##8       |48839/173481[12:00<30:36,67.86it/s] 29%|##8       |49552/173481[12:10<30:26,67.86it/s] 35%|###5      |60868/173481[15:00<27:52,67.33it/s] 35%|###5      |61570/173481[15:10<27:42,67.33it/s] 42%|####2     |73225/173481[18:00<24:34,67.98it/s] 43%|####2     |73922/173481[18:11<24:24,67.98it/s] 49%|####9     |85038/173481[21:00<22:04,66.78it/s] 49%|####9     |85779/173481[21:11<21:53,66.78it/s] 56%|#####5    |96654/173481[24:00<19:30,65.64it/s] 56%|#####6    |97387/173481[24:11<19:19,65.64it/s] 63%|######2   |108518/173481[27:00<16:27,65.77it/s] 63%|######2   |109281/173481[27:11<16:16,65.77it/s] 70%|######9   |120875/173481[30:00<13:03,67.18it/s] 70%|#######   |121709/173481[30:11<12:50,67.18it/s] 77%|#######7  |133616/173481[33:00<09:38,68.93it/s] 78%|#######7  |134464/173481[33:11<09:26,68.93it/s] 84%|########3 |145476/173481[36:00<06:55,67.38it/s] 84%|########4 |146247/173481[36:12<06:44,67.38it/s] 91%|######### |157064/173481[39:00<04:09,65.84it/s] 91%|#########1|157895/173481[39:12<03:56,65.84it/s] 97%|#########7|168910/173481[42:00<01:09,65.82it/s] 98%|#########7|169656/173481[42:12<00:58,65.82it/s]100%|##########|173481/173481[43:12<00:00,66.91it/s]
[32m[0322 06:46:55 @base.py:257][0m Epoch 9 (global_step 1561329) finished, time:2592.95 sec.
[32m[0322 06:46:55 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-1561329.
[32m[0322 06:46:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.24it/s]
8
[32m[0322 06:48:53 @monitor.py:363][0m QueueInput/queue_size: 0.77771
[32m[0322 06:48:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.128
[32m[0322 06:48:53 @monitor.py:363][0m activation-summaries/output-rms: 0.033042
[32m[0322 06:48:53 @monitor.py:363][0m cross_entropy_loss: 2.5796
[32m[0322 06:48:53 @monitor.py:363][0m lr: 0.000125
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.35794
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.5441
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32573
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32949
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30758
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27232
[32m[0322 06:48:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 06:48:53 @monitor.py:363][0m train-error-top1: 0.62896
[32m[0322 06:48:53 @monitor.py:363][0m val-error-top1: 0.66566
[32m[0322 06:48:53 @monitor.py:363][0m val-utt-error: 0.27043
[32m[0322 06:48:53 @monitor.py:363][0m validation_cost: 2.782
[32m[0322 06:48:53 @monitor.py:363][0m wd_cost: 0.1123
[32m[0322 06:48:53 @group.py:42][0m Callbacks took 117.973 sec in total. InferenceRunner: 116.743sec
[32m[0322 06:48:53 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13674/173481[03:00<35:03,75.96it/s]  8%|8         |14369/173481[03:10<34:54,75.96it/s] 15%|#4        |25682/173481[06:00<34:40,71.03it/s] 15%|#5        |26406/173481[06:10<34:30,71.03it/s] 22%|##2       |38778/173481[09:00<31:14,71.88it/s] 23%|##2       |39511/173481[09:10<31:03,71.88it/s] 29%|##9       |51135/173481[12:00<29:02,70.23it/s] 30%|##9       |51918/173481[12:10<28:50,70.23it/s] 37%|###6      |63385/173481[15:00<26:32,69.12it/s] 37%|###6      |64134/173481[15:10<26:21,69.12it/s] 43%|####3     |75396/173481[18:00<24:04,67.90it/s] 44%|####3     |76070/173481[18:11<23:54,67.90it/s] 50%|#####     |87291/173481[21:00<21:26,66.98it/s] 51%|#####     |87991/173481[21:11<21:16,66.98it/s] 57%|#####7    |99136/173481[24:00<18:39,66.39it/s] 58%|#####7    |99856/173481[24:11<18:29,66.39it/s] 64%|######3   |110952/173481[27:00<15:47,66.01it/s] 64%|######4   |111721/173481[27:11<15:35,66.01it/s] 71%|#######1  |123420/173481[30:00<12:20,67.60it/s] 72%|#######1  |124226/173481[30:11<12:08,67.60it/s] 78%|#######8  |135677/173481[33:00<09:17,67.84it/s] 79%|#######8  |136471/173481[33:11<09:05,67.84it/s] 85%|########5 |147821/173481[36:00<06:19,67.65it/s] 86%|########5 |148640/173481[36:12<06:07,67.65it/s] 93%|#########2|160807/173481[39:00<03:01,69.82it/s] 93%|#########3|161684/173481[39:12<02:48,69.82it/s]100%|##########|173481/173481[41:57<00:00,68.90it/s]
[32m[0322 07:30:50 @base.py:257][0m Epoch 10 (global_step 1734810) finished, time:2517.80 sec.
[32m[0322 07:30:51 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-1734810.
[32m[0322 07:30:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,171.03it/s]
9
[32m[0322 07:32:42 @monitor.py:363][0m QueueInput/queue_size: 0.87662
[32m[0322 07:32:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.5303
[32m[0322 07:32:42 @monitor.py:363][0m activation-summaries/output-rms: 0.034987
[32m[0322 07:32:42 @monitor.py:363][0m cross_entropy_loss: 2.4918
[32m[0322 07:32:42 @monitor.py:363][0m lr: 0.000125
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4127
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.5627
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.37662
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.38744
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36414
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063752
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.32239
[32m[0322 07:32:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 07:32:42 @monitor.py:363][0m train-error-top1: 0.61575
[32m[0322 07:32:42 @monitor.py:363][0m val-error-top1: 0.66303
[32m[0322 07:32:42 @monitor.py:363][0m val-utt-error: 0.2717
[32m[0322 07:32:42 @monitor.py:363][0m validation_cost: 2.7853
[32m[0322 07:32:42 @monitor.py:363][0m wd_cost: 0.15327
[32m[0322 07:32:42 @group.py:42][0m Callbacks took 111.154 sec in total. InferenceRunner: 110.064sec
[32m[0322 07:32:42 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15137/173481[03:00<31:22,84.09it/s]  9%|9         |15990/173481[03:10<31:12,84.09it/s] 17%|#7        |30310/173481[06:00<28:20,84.19it/s] 18%|#7        |31180/173481[06:10<28:10,84.19it/s] 26%|##6       |45530/173481[09:00<25:16,84.37it/s] 27%|##6       |46416/173481[09:10<25:05,84.37it/s] 35%|###5      |60871/173481[12:00<22:08,84.80it/s] 36%|###5      |61792/173481[12:10<21:57,84.80it/s] 44%|####3     |76290/173481[15:00<19:00,85.23it/s] 45%|####4     |77215/173481[15:10<18:49,85.23it/s] 53%|#####2    |91565/173481[18:00<16:03,85.04it/s] 53%|#####3    |92507/173481[18:11<15:52,85.04it/s] 62%|######1   |106913/173481[21:00<13:01,85.15it/s] 62%|######2   |107867/173481[21:11<12:50,85.15it/s] 70%|#######   |122260/173481[24:00<10:01,85.20it/s] 71%|#######1  |123243/173481[24:11<09:49,85.20it/s] 79%|#######9  |137528/173481[27:00<07:02,85.01it/s] 80%|#######9  |138524/173481[27:11<06:51,85.01it/s] 88%|########8 |152799/173481[30:00<04:03,84.92it/s] 89%|########8 |153791/173481[30:11<03:51,84.92it/s] 97%|#########6|168126/173481[33:00<01:02,85.04it/s] 97%|#########7|169143/173481[33:11<00:51,85.04it/s]100%|##########|173481/173481[34:03<00:00,84.91it/s]
[32m[0322 08:06:45 @base.py:257][0m Epoch 11 (global_step 1908291) finished, time:2043.01 sec.
[32m[0322 08:06:45 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-1908291.
[32m[0322 08:06:45 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:43<00:00,114.92it/s]
10
[32m[0322 08:09:29 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0322 08:09:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.2409
[32m[0322 08:09:29 @monitor.py:363][0m activation-summaries/output-rms: 0.035719
[32m[0322 08:09:29 @monitor.py:363][0m cross_entropy_loss: 2.2696
[32m[0322 08:09:29 @monitor.py:363][0m lr: 6.25e-05
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.43583
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.58
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.37984
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4087
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.38493
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.34077
[32m[0322 08:09:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 08:09:29 @monitor.py:363][0m train-error-top1: 0.57305
[32m[0322 08:09:29 @monitor.py:363][0m val-error-top1: 0.6343
[32m[0322 08:09:29 @monitor.py:363][0m val-utt-error: 0.21841
[32m[0322 08:09:29 @monitor.py:363][0m validation_cost: 2.6358
[32m[0322 08:09:29 @monitor.py:363][0m wd_cost: 0.16535
[32m[0322 08:09:29 @group.py:42][0m Callbacks took 164.608 sec in total. InferenceRunner: 163.797sec
[32m[0322 08:09:29 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15329/173481[03:00<30:57,85.16it/s]  9%|9         |16168/173481[03:10<30:47,85.16it/s] 18%|#7        |30585/173481[06:00<28:02,84.96it/s] 18%|#8        |31459/173481[06:10<27:51,84.96it/s] 26%|##6       |45914/173481[09:00<24:59,85.06it/s] 27%|##6       |46811/173481[09:10<24:49,85.06it/s] 35%|###5      |61256/173481[12:00<21:58,85.14it/s] 36%|###5      |62153/173481[12:10<21:47,85.14it/s] 44%|####4     |76516/173481[15:00<19:01,84.96it/s] 45%|####4     |77440/173481[15:10<18:50,84.96it/s] 53%|#####2    |91745/173481[18:00<16:04,84.78it/s] 53%|#####3    |92687/173481[18:11<15:52,84.78it/s] 62%|######1   |107021/173481[21:00<13:03,84.82it/s] 62%|######2   |107974/173481[21:11<12:52,84.82it/s] 69%|######8   |119405/173481[24:00<11:51,75.96it/s] 69%|######9   |120115/173481[24:11<11:42,75.96it/s] 75%|#######5  |130675/173481[27:00<10:23,68.64it/s] 76%|#######5  |131364/173481[27:11<10:13,68.64it/s] 82%|########1 |141475/173481[30:00<08:19,64.03it/s] 82%|########1 |142229/173481[30:11<08:08,64.03it/s] 88%|########8 |152972/173481[33:00<05:20,63.95it/s] 89%|########8 |153735/173481[33:11<05:08,63.95it/s] 95%|#########4|164303/173481[36:00<02:24,63.44it/s] 95%|#########5|164963/173481[36:12<02:14,63.44it/s]100%|##########|173481/173481[38:24<00:00,75.29it/s]
[32m[0322 08:47:53 @base.py:257][0m Epoch 12 (global_step 2081772) finished, time:2304.09 sec.
[32m[0322 08:47:53 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-2081772.
[32m[0322 08:47:54 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:34<00:00,122.01it/s]
11
[32m[0322 08:50:28 @monitor.py:363][0m QueueInput/queue_size: 0.94271
[32m[0322 08:50:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.0506
[32m[0322 08:50:28 @monitor.py:363][0m activation-summaries/output-rms: 0.034226
[32m[0322 08:50:28 @monitor.py:363][0m cross_entropy_loss: 2.4827
[32m[0322 08:50:28 @monitor.py:363][0m lr: 6.25e-05
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46773
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.5877
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.43541
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44149
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.41633
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36814
[32m[0322 08:50:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 08:50:28 @monitor.py:363][0m train-error-top1: 0.609
[32m[0322 08:50:28 @monitor.py:363][0m val-error-top1: 0.65405
[32m[0322 08:50:28 @monitor.py:363][0m val-utt-error: 0.25045
[32m[0322 08:50:28 @monitor.py:363][0m validation_cost: 2.717
[32m[0322 08:50:28 @monitor.py:363][0m wd_cost: 0.04026
[32m[0322 08:50:28 @group.py:42][0m Callbacks took 155.151 sec in total. InferenceRunner: 154.282sec
[32m[0322 08:50:28 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14684/173481[03:00<32:26,81.58it/s]  9%|8         |15305/173481[03:10<32:18,81.58it/s] 15%|#5        |26289/173481[06:00<34:03,72.02it/s] 16%|#5        |26921/173481[06:10<33:54,72.02it/s] 21%|##1       |37275/173481[09:00<34:21,66.07it/s] 22%|##1       |37903/173481[09:10<34:11,66.07it/s] 28%|##7       |47965/173481[12:00<33:26,62.55it/s] 28%|##8       |48599/173481[12:10<33:16,62.55it/s] 34%|###3      |58819/173481[15:00<31:07,61.40it/s] 34%|###4      |59493/173481[15:10<30:56,61.40it/s] 40%|####      |70204/173481[18:00<27:37,62.31it/s] 41%|####      |70915/173481[18:11<27:25,62.31it/s] 47%|####7     |82114/173481[21:00<23:43,64.18it/s] 48%|####7     |82801/173481[21:11<23:32,64.18it/s] 54%|#####3    |93535/173481[24:00<20:52,63.81it/s] 54%|#####4    |94268/173481[24:11<20:41,63.81it/s]srun: error: slurm_receive_msg: Transport endpoint is not connected
srun: error: slurm_receive_msg[5.101.40.8]: Transport endpoint is not connected
 60%|######    |104934/173481[27:00<17:58,63.56it/s] 61%|######    |105647/173481[27:11<17:47,63.56it/s] 67%|######7   |116756/173481[30:00<14:38,64.60it/s] 68%|######7   |117511/173481[30:11<14:26,64.60it/s] 74%|#######3  |127755/173481[33:00<12:08,62.80it/s] 74%|#######4  |128420/173481[33:11<11:57,62.80it/s] 80%|########  |139434/173481[36:00<08:53,63.83it/s] 81%|########  |140212/173481[36:12<08:41,63.83it/s] 87%|########7 |151204/173481[39:00<05:44,64.60it/s] 88%|########7 |152020/173481[39:12<05:32,64.60it/s] 94%|#########4|163235/173481[42:00<02:35,65.70it/s] 95%|#########4|164068/173481[42:12<02:23,65.70it/s]100%|##########|173481/173481[44:35<00:00,64.84it/s]
[32m[0322 09:35:04 @base.py:257][0m Epoch 13 (global_step 2255253) finished, time:2675.38 sec.
[32m[0322 09:35:04 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-2255253.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.62it/s]
12
[32m[0322 09:36:58 @monitor.py:363][0m QueueInput/queue_size: 1.0795
[32m[0322 09:36:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.2996
[32m[0322 09:36:58 @monitor.py:363][0m activation-summaries/output-rms: 0.033956
[32m[0322 09:36:58 @monitor.py:363][0m cross_entropy_loss: 2.4591
[32m[0322 09:36:58 @monitor.py:363][0m lr: 6.25e-05
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.50353
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.5954
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.48605
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.47848
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062212
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.45234
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.40023
[32m[0322 09:36:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060877
[32m[0322 09:36:58 @monitor.py:363][0m train-error-top1: 0.60514
[32m[0322 09:36:58 @monitor.py:363][0m val-error-top1: 0.65007
[32m[0322 09:36:58 @monitor.py:363][0m val-utt-error: 0.24211
[32m[0322 09:36:58 @monitor.py:363][0m validation_cost: 2.6839
[32m[0322 09:36:58 @monitor.py:363][0m wd_cost: 0.048395
[32m[0322 09:36:58 @group.py:42][0m Callbacks took 114.590 sec in total. InferenceRunner: 114.350sec
[32m[0322 09:36:58 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11848/173481[03:00<40:55,65.82it/s]  7%|7         |12508/173481[03:10<40:45,65.82it/s] 13%|#3        |22840/173481[06:00<39:37,63.35it/s] 14%|#3        |23497/173481[06:10<39:27,63.35it/s] 20%|#9        |34267/173481[09:00<36:35,63.42it/s] 20%|##        |35007/173481[09:10<36:23,63.42it/s] 27%|##6       |46278/173481[12:00<32:36,65.02it/s] 27%|##7       |47012/173481[12:10<32:24,65.02it/s] 33%|###3      |58067/173481[15:00<29:28,65.26it/s] 34%|###3      |58794/173481[15:10<29:17,65.26it/s] 41%|####      |70515/173481[18:00<25:33,67.15it/s] 41%|####1     |71263/173481[18:11<25:22,67.15it/s] 48%|####7     |82710/173481[21:00<22:25,67.45it/s] 48%|####8     |83419/173481[21:11<22:15,67.45it/s] 54%|#####4    |94299/173481[24:00<20:01,65.88it/s] 55%|#####4    |95057/173481[24:11<19:50,65.88it/s] 61%|######1   |106243/173481[27:00<16:56,66.12it/s] 62%|######1   |106989/173481[27:11<16:45,66.12it/s] 68%|######8   |118171/173481[30:00<13:55,66.19it/s] 69%|######8   |118874/173481[30:11<13:45,66.19it/s] 75%|#######4  |129877/173481[33:00<11:04,65.60it/s] 75%|#######5  |130697/173481[33:11<10:52,65.60it/s] 82%|########1 |142068/173481[36:00<07:51,66.64it/s] 82%|########2 |142792/173481[36:12<07:40,66.64it/s] 89%|########8 |153983/173481[39:00<04:53,66.41it/s] 89%|########9 |154704/173481[39:12<04:42,66.41it/s] 96%|#########5|165685/173481[42:00<01:58,65.70it/s] 96%|#########5|166392/173481[42:12<01:47,65.70it/s]100%|##########|173481/173481[44:07<00:00,65.52it/s]
[32m[0322 10:21:06 @base.py:257][0m Epoch 14 (global_step 2428734) finished, time:2647.96 sec.
[32m[0322 10:21:07 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-2428734.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.24it/s]
13
[32m[0322 10:22:59 @monitor.py:363][0m QueueInput/queue_size: 0.84749
[32m[0322 10:22:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.7893
[32m[0322 10:22:59 @monitor.py:363][0m activation-summaries/output-rms: 0.034714
[32m[0322 10:22:59 @monitor.py:363][0m cross_entropy_loss: 2.4592
[32m[0322 10:22:59 @monitor.py:363][0m lr: 3.125e-05
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.53045
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6019
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51745
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.50546
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.479
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.42413
[32m[0322 10:22:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 10:22:59 @monitor.py:363][0m train-error-top1: 0.61108
[32m[0322 10:22:59 @monitor.py:363][0m val-error-top1: 0.64037
[32m[0322 10:22:59 @monitor.py:363][0m val-utt-error: 0.2369
[32m[0322 10:22:59 @monitor.py:363][0m validation_cost: 2.6561
[32m[0322 10:22:59 @monitor.py:363][0m wd_cost: 0.010879
[32m[0322 10:22:59 @group.py:42][0m Callbacks took 112.842 sec in total. InferenceRunner: 112.553sec
[32m[0322 10:22:59 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11422/173481[03:00<42:34,63.44it/s]  7%|6         |12056/173481[03:10<42:24,63.44it/s] 13%|#3        |22629/173481[06:00<40:00,62.84it/s] 13%|#3        |23195/173481[06:10<39:51,62.84it/s] 20%|#9        |34371/173481[09:00<36:13,64.01it/s] 20%|##        |35054/173481[09:10<36:02,64.01it/s] 27%|##6       |46298/173481[12:00<32:33,65.12it/s] 27%|##7       |46977/173481[12:10<32:22,65.12it/s] 34%|###3      |58476/173481[15:00<28:53,66.36it/s] 34%|###4      |59220/173481[15:10<28:41,66.36it/s] 41%|####      |70422/173481[18:00<25:52,66.36it/s] 41%|####1     |71138/173481[18:11<25:42,66.36it/s] 47%|####7     |82192/173481[21:00<23:05,65.87it/s] 48%|####7     |82867/173481[21:11<22:55,65.87it/s] 54%|#####4    |94143/173481[24:00<19:59,66.13it/s] 55%|#####4    |94836/173481[24:11<19:49,66.13it/s] 61%|######1   |105950/173481[27:00<17:05,65.86it/s] 62%|######1   |106717/173481[27:11<16:53,65.86it/s] 68%|######7   |117316/173481[30:00<14:31,64.47it/s] 68%|######8   |117992/173481[30:11<14:20,64.47it/s] 74%|#######3  |127872/173481[33:00<12:22,61.42it/s] 74%|#######4  |128570/173481[33:11<12:11,61.42it/s] 80%|#######9  |138658/173481[36:00<09:34,60.66it/s] 80%|########  |139370/173481[36:12<09:22,60.66it/s] 86%|########6 |149276/173481[39:00<06:44,59.81it/s] 86%|########6 |149957/173481[39:12<06:33,59.81it/s] 92%|#########2|160262/173481[42:00<03:38,60.41it/s] 93%|#########2|161028/173481[42:12<03:26,60.41it/s] 99%|#########8|171714/173481[45:00<00:28,61.97it/s] 99%|#########9|172456/173481[45:12<00:16,61.97it/s]100%|##########|173481/173481[45:32<00:00,63.50it/s]
[32m[0322 11:08:31 @base.py:257][0m Epoch 15 (global_step 2602215) finished, time:2732.07 sec.
[32m[0322 11:08:32 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-2602215.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,141.29it/s]
14
[32m[0322 11:10:45 @monitor.py:363][0m QueueInput/queue_size: 0.78781
[32m[0322 11:10:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.8379
[32m[0322 11:10:45 @monitor.py:363][0m activation-summaries/output-rms: 0.035098
[32m[0322 11:10:45 @monitor.py:363][0m cross_entropy_loss: 2.4327
[32m[0322 11:10:45 @monitor.py:363][0m lr: 3.125e-05
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5498
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6057
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.54636
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.52472
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.49779
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.44072
[32m[0322 11:10:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 11:10:45 @monitor.py:363][0m train-error-top1: 0.60567
[32m[0322 11:10:45 @monitor.py:363][0m val-error-top1: 0.64572
[32m[0322 11:10:45 @monitor.py:363][0m val-utt-error: 0.24663
[32m[0322 11:10:45 @monitor.py:363][0m validation_cost: 2.677
[32m[0322 11:10:45 @monitor.py:363][0m wd_cost: 0.011888
[32m[0322 11:10:45 @group.py:42][0m Callbacks took 133.511 sec in total. InferenceRunner: 133.232sec
[32m[0322 11:10:45 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14740/173481[03:00<32:18,81.88it/s]  9%|8         |15590/173481[03:10<32:08,81.88it/s] 17%|#7        |29856/173481[06:00<28:52,82.92it/s] 18%|#7        |30729/173481[06:10<28:41,82.92it/s] 26%|##5       |45045/173481[09:00<25:35,83.64it/s] 26%|##6       |45926/173481[09:10<25:25,83.64it/s] 35%|###4      |60312/173481[12:00<22:23,84.22it/s] 35%|###5      |61206/173481[12:10<22:13,84.22it/s] 44%|####3     |75606/173481[15:00<19:17,84.59it/s] 44%|####4     |76532/173481[15:10<19:06,84.59it/s] 52%|#####2    |90891/173481[18:00<16:14,84.75it/s] 53%|#####2    |91810/173481[18:11<16:03,84.75it/s] 60%|######    |104335/173481[21:00<14:30,79.40it/s] 60%|######    |104891/173481[21:11<14:23,79.40it/s] 65%|######5   |113601/173481[24:00<15:58,62.46it/s] 66%|######5   |114174/173481[24:11<15:49,62.46it/s] 71%|#######   |123132/173481[27:00<14:38,57.31it/s] 71%|#######1  |123736/173481[27:11<14:27,57.31it/s] 76%|#######6  |132406/173481[30:00<12:37,54.26it/s] 77%|#######6  |133000/173481[30:11<12:26,54.26it/s] 82%|########1 |141806/173481[33:00<09:55,53.22it/s] 82%|########2 |142355/173481[33:11<09:44,53.22it/s] 87%|########6 |150572/173481[36:00<07:30,50.86it/s] 87%|########7 |151153/173481[36:12<07:19,50.86it/s] 91%|#########1|158648/173481[39:00<05:11,47.67it/s] 92%|#########1|159186/173481[39:12<04:59,47.67it/s] 96%|#########6|166906/173481[42:00<02:20,46.74it/s] 97%|#########6|167470/173481[42:12<02:08,46.74it/s]100%|##########|173481/173481[44:14<00:00,65.36it/s]
[32m[0322 11:54:59 @base.py:257][0m Epoch 16 (global_step 2775696) finished, time:2654.13 sec.
[32m[0322 11:54:59 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-2775696.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13861/18822[03:00<01:04,76.99it/s] 77%|#######7  |14573/18822[03:10<00:55,76.99it/s]100%|##########|18822/18822[04:05<00:00,76.71it/s]
15
[32m[0322 11:59:05 @monitor.py:363][0m QueueInput/queue_size: 0.98571
[32m[0322 11:59:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.7959
[32m[0322 11:59:05 @monitor.py:363][0m activation-summaries/output-rms: 0.034792
[32m[0322 11:59:05 @monitor.py:363][0m cross_entropy_loss: 2.4082
[32m[0322 11:59:05 @monitor.py:363][0m lr: 3.125e-05
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56758
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6095
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.57052
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.54195
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.51459
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.45544
[32m[0322 11:59:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 11:59:05 @monitor.py:363][0m train-error-top1: 0.59629
[32m[0322 11:59:05 @monitor.py:363][0m val-error-top1: 0.64757
[32m[0322 11:59:05 @monitor.py:363][0m val-utt-error: 0.24748
[32m[0322 11:59:05 @monitor.py:363][0m validation_cost: 2.6968
[32m[0322 11:59:05 @monitor.py:363][0m wd_cost: 0.0128
[32m[0322 11:59:05 @group.py:42][0m Callbacks took 245.646 sec in total. InferenceRunner: 245.378sec
[32m[0322 11:59:05 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9386/173481[03:00<52:27,52.14it/s]  6%|5         |9894/173481[03:10<52:17,52.14it/s] 11%|#         |18635/173481[06:00<49:51,51.76it/s] 11%|#1        |19179/173481[06:10<49:41,51.76it/s] 16%|#6        |27974/173481[09:00<46:47,51.82it/s] 16%|#6        |28480/173481[09:10<46:38,51.82it/s] 21%|##1       |36779/173481[12:00<45:16,50.33it/s] 21%|##1       |37271/173481[12:10<45:06,50.33it/s] 26%|##6       |45108/173481[15:00<44:22,48.21it/s] 26%|##6       |45611/173481[15:10<44:12,48.21it/s] 31%|###       |53666/173481[18:00<41:42,47.88it/s] 31%|###1      |54224/173481[18:10<41:30,47.88it/s] 36%|###6      |62733/173481[21:00<37:35,49.09it/s] 36%|###6      |63249/173481[21:11<37:25,49.09it/s] 41%|####      |70992/173481[24:00<36:00,47.43it/s] 41%|####1     |71573/173481[24:11<35:48,47.43it/s] 46%|####6     |80520/173481[27:00<30:58,50.03it/s] 47%|####6     |81105/173481[27:11<30:46,50.03it/s] 52%|#####1    |89815/173481[30:00<27:26,50.81it/s] 52%|#####2    |90428/173481[30:11<27:14,50.81it/s] 57%|#####7    |99560/173481[33:00<23:30,52.42it/s] 58%|#####7    |100205/173481[33:11<23:17,52.42it/s] 63%|######2   |109070/173481[36:00<20:23,52.62it/s] 63%|######3   |109639/173481[36:11<20:13,52.62it/s] 68%|######7   |117665/173481[39:00<18:34,50.07it/s] 68%|######8   |118236/173481[39:12<18:23,50.07it/s] 73%|#######3  |126800/173481[42:00<15:26,50.40it/s] 73%|#######3  |127422/173481[42:12<15:13,50.40it/s] 78%|#######8  |135860/173481[45:00<12:26,50.37it/s] 79%|#######8  |136481/173481[45:12<12:14,50.37it/s] 84%|########3 |145395/173481[48:00<09:03,51.64it/s] 84%|########4 |146005/173481[48:12<08:52,51.64it/s] 89%|########8 |154140/173481[51:00<06:26,50.05it/s] 89%|########9 |154692/173481[51:12<06:15,50.05it/s] 94%|#########4|163355/173481[54:00<03:20,50.61it/s] 95%|#########4|163975/173481[54:12<03:07,50.61it/s]100%|#########9|172983/173481[57:00<00:09,52.01it/s]100%|##########|173481/173481[57:09<00:00,50.59it/s]
[32m[0322 12:56:14 @base.py:257][0m Epoch 17 (global_step 2949177) finished, time:3429.38 sec.
[32m[0322 12:56:14 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-2949177.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######7  |14509/18822[03:00<00:53,80.60it/s] 82%|########1 |15365/18822[03:10<00:42,80.60it/s]100%|##########|18822/18822[03:50<00:00,81.67it/s]
16
[32m[0322 13:00:05 @monitor.py:363][0m QueueInput/queue_size: 0.88016
[32m[0322 13:00:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.0546
[32m[0322 13:00:05 @monitor.py:363][0m activation-summaries/output-rms: 0.035342
[32m[0322 13:00:05 @monitor.py:363][0m cross_entropy_loss: 2.4269
[32m[0322 13:00:05 @monitor.py:363][0m lr: 1.5625e-05
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57991
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6121
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.58717
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.55411
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.52651
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.466
[32m[0322 13:00:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 13:00:05 @monitor.py:363][0m train-error-top1: 0.59411
[32m[0322 13:00:05 @monitor.py:363][0m val-error-top1: 0.64005
[32m[0322 13:00:05 @monitor.py:363][0m val-utt-error: 0.24269
[32m[0322 13:00:05 @monitor.py:363][0m validation_cost: 2.6447
[32m[0322 13:00:05 @monitor.py:363][0m wd_cost: 0.0026915
[32m[0322 13:00:05 @group.py:42][0m Callbacks took 230.806 sec in total. InferenceRunner: 230.468sec
[32m[0322 13:00:05 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10384/173481[03:00<47:07,57.69it/s]  6%|6         |10946/173481[03:10<46:57,57.69it/s] 12%|#1        |20297/173481[06:00<45:18,56.35it/s] 12%|#2        |20841/173481[06:10<45:08,56.35it/s] 17%|#7        |30076/173481[09:00<43:12,55.32it/s] 18%|#7        |30592/173481[09:10<43:03,55.32it/s] 24%|##4       |42248/173481[12:00<35:56,60.85it/s] 25%|##4       |43149/173481[12:10<35:41,60.85it/s] 30%|###       |52774/173481[15:00<33:44,59.64it/s] 31%|###       |53330/173481[15:10<33:34,59.64it/s] 36%|###5      |62121/173481[18:00<33:26,55.51it/s] 36%|###6      |62663/173481[18:10<33:16,55.51it/s] 41%|####1     |71693/173481[21:00<31:14,54.32it/s] 42%|####1     |72302/173481[21:11<31:02,54.32it/s] 47%|####7     |81594/173481[24:00<28:01,54.66it/s] 47%|####7     |82208/173481[24:11<27:49,54.66it/s] 53%|#####2    |91564/173481[27:00<24:48,55.02it/s] 53%|#####3    |92187/173481[27:11<24:37,55.02it/s] 58%|#####8    |101343/173481[30:00<21:59,54.67it/s] 59%|#####8    |101901/173481[30:11<21:49,54.67it/s] 64%|######4   |111042/173481[33:00<19:10,54.27it/s] 64%|######4   |111645/173481[33:11<18:59,54.27it/s] 70%|######9   |120756/173481[36:00<16:14,54.12it/s] 70%|######9   |121348/173481[36:11<16:03,54.12it/s] 75%|#######5  |130516/173481[39:00<13:13,54.17it/s] 76%|#######5  |131173/173481[39:12<13:01,54.17it/s] 81%|########  |140424/173481[42:00<10:05,54.60it/s] 81%|########1 |141082/173481[42:12<09:53,54.60it/s] 87%|########6 |150209/173481[45:00<07:07,54.48it/s] 87%|########6 |150878/173481[45:12<06:54,54.48it/s] 92%|#########2|160094/173481[48:00<04:04,54.70it/s] 93%|#########2|160770/173481[48:12<03:52,54.70it/s] 98%|#########8|170084/173481[51:00<01:01,55.09it/s] 98%|#########8|170773/173481[51:12<00:49,55.09it/s]100%|##########|173481/173481[52:01<00:00,55.57it/s]
[32m[0322 13:52:07 @base.py:257][0m Epoch 18 (global_step 3122658) finished, time:3121.85 sec.
[32m[0322 13:52:07 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-3122658.
  0%|          |0/18822[00:00<?,?it/s] 44%|####4     |8287/18822[03:00<03:48,46.03it/s] 49%|####8     |9165/18822[03:10<03:29,46.03it/s]100%|##########|18822/18822[04:36<00:00,68.19it/s]
17
[32m[0322 13:56:43 @monitor.py:363][0m QueueInput/queue_size: 0.96726
[32m[0322 13:56:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.0089
[32m[0322 13:56:43 @monitor.py:363][0m activation-summaries/output-rms: 0.035526
[32m[0322 13:56:43 @monitor.py:363][0m cross_entropy_loss: 2.4317
[32m[0322 13:56:43 @monitor.py:363][0m lr: 1.5625e-05
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58944
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6139
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.60057
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.56346
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.53567
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.47408
[32m[0322 13:56:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 13:56:43 @monitor.py:363][0m train-error-top1: 0.60001
[32m[0322 13:56:43 @monitor.py:363][0m val-error-top1: 0.64191
[32m[0322 13:56:43 @monitor.py:363][0m val-utt-error: 0.22994
[32m[0322 13:56:43 @monitor.py:363][0m validation_cost: 2.6494
[32m[0322 13:56:43 @monitor.py:363][0m wd_cost: 0.0027972
[32m[0322 13:56:43 @group.py:42][0m Callbacks took 276.349 sec in total. InferenceRunner: 276.056sec
[32m[0322 13:56:43 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14369/173481[03:00<33:13,79.82it/s]  9%|8         |14912/173481[03:10<33:06,79.82it/s] 14%|#3        |24214/173481[06:00<38:19,64.91it/s] 14%|#4        |24777/173481[06:10<38:10,64.91it/s] 20%|#9        |34021/173481[09:00<39:14,59.24it/s] 20%|#9        |34601/173481[09:10<39:04,59.24it/s] 25%|##5       |43882/173481[12:00<37:56,56.92it/s] 26%|##5       |44462/173481[12:10<37:46,56.92it/s] 31%|###1      |53793/173481[15:00<35:38,55.97it/s] 31%|###1      |54386/173481[15:10<35:27,55.97it/s] 36%|###6      |62652/173481[18:00<35:16,52.37it/s] 36%|###6      |63171/173481[18:10<35:06,52.37it/s] 42%|####1     |72324/173481[21:00<31:47,53.04it/s] 42%|####2     |72938/173481[21:11<31:35,53.04it/s] 47%|####7     |81868/173481[24:00<28:47,53.02it/s] 47%|####7     |82360/173481[24:11<28:38,53.02it/s] 52%|#####2    |91011/173481[27:00<26:29,51.89it/s] 53%|#####2    |91631/173481[27:11<26:17,51.89it/s] 58%|#####7    |100303/173481[30:00<23:34,51.75it/s] 58%|#####8    |100777/173481[30:11<23:25,51.75it/s] 62%|######2   |107583/173481[33:00<24:11,45.40it/s] 62%|######2   |108056/173481[33:11<24:01,45.40it/s] 67%|######7   |116603/173481[36:00<19:53,47.64it/s] 68%|######7   |117237/173481[36:11<19:40,47.64it/s] 73%|#######2  |126538/173481[39:00<15:18,51.13it/s] 73%|#######3  |127197/173481[39:12<15:05,51.13it/s] 77%|#######7  |134257/173481[42:00<14:00,46.64it/s] 78%|#######7  |134722/173481[42:12<13:50,46.64it/s] 82%|########2 |142649/173481[45:00<11:01,46.63it/s] 83%|########2 |143506/173481[45:12<10:42,46.63it/s] 90%|######### |156413/173481[48:00<04:54,57.93it/s] 91%|######### |157459/173481[48:12<04:36,57.93it/s] 97%|#########6|167983/173481[51:00<01:30,60.93it/s] 97%|#########7|168664/173481[51:12<01:19,60.93it/s]100%|##########|173481/173481[52:41<00:00,54.87it/s]
[32m[0322 14:49:25 @base.py:257][0m Epoch 19 (global_step 3296139) finished, time:3161.66 sec.
[32m[0322 14:49:25 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-3296139.
  0%|          |0/18822[00:00<?,?it/s] 54%|#####3    |10098/18822[03:00<02:35,56.10it/s] 57%|#####6    |10667/18822[03:10<02:25,56.10it/s]100%|##########|18822/18822[05:25<00:00,57.88it/s]
18
[32m[0322 14:54:50 @monitor.py:363][0m QueueInput/queue_size: 1.0534
[32m[0322 14:54:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.2838
[32m[0322 14:54:50 @monitor.py:363][0m activation-summaries/output-rms: 0.034618
[32m[0322 14:54:50 @monitor.py:363][0m cross_entropy_loss: 2.488
[32m[0322 14:54:50 @monitor.py:363][0m lr: 1.5625e-05
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59876
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6158
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.61335
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.57269
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.54471
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.48212
[32m[0322 14:54:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 14:54:50 @monitor.py:363][0m train-error-top1: 0.61795
[32m[0322 14:54:50 @monitor.py:363][0m val-error-top1: 0.64195
[32m[0322 14:54:50 @monitor.py:363][0m val-utt-error: 0.242
[32m[0322 14:54:50 @monitor.py:363][0m validation_cost: 2.6648
[32m[0322 14:54:50 @monitor.py:363][0m wd_cost: 0.0029017
[32m[0322 14:54:50 @group.py:42][0m Callbacks took 325.526 sec in total. InferenceRunner: 325.186sec
[32m[0322 14:54:50 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8185/173481[03:00<1:00:35,45.47it/s]  5%|4         |8611/173481[03:10<1:00:25,45.47it/s]  9%|9         |15987/173481[06:00<59:08,44.38it/s]  10%|9         |16551/173481[06:10<58:56,44.38it/s] 15%|#4        |25687/173481[09:00<50:36,48.67it/s] 15%|#5        |26205/173481[09:10<50:26,48.67it/s] 20%|#9        |34557/173481[12:00<47:16,48.97it/s] 20%|##        |35015/173481[12:10<47:07,48.97it/s] 24%|##4       |42210/173481[15:00<48:04,45.51it/s] 25%|##4       |42661/173481[15:10<47:54,45.51it/s] 29%|##8       |49452/173481[18:00<48:23,42.71it/s] 29%|##8       |49851/173481[18:10<48:14,42.71it/s] 33%|###2      |56905/173481[21:00<46:12,42.05it/s] 33%|###3      |57344/173481[21:11<46:02,42.05it/s] 37%|###7      |64561/173481[24:00<42:55,42.29it/s] 37%|###7      |64981/173481[24:11<42:45,42.29it/s] 42%|####1     |72686/173481[27:00<38:28,43.67it/s] 42%|####2     |73226/173481[27:11<38:15,43.67it/s] 48%|####7     |82694/173481[30:00<30:56,48.92it/s] 48%|####8     |83451/173481[30:11<30:40,48.92it/s] 53%|#####3    |92324/173481[33:00<26:28,51.10it/s] 53%|#####3    |92776/173481[33:11<26:19,51.10it/s] 57%|#####7    |99221/173481[36:00<28:15,43.80it/s] 57%|#####7    |99648/173481[36:11<28:05,43.80it/s] 61%|######1   |106072/173481[39:00<27:35,40.72it/s] 61%|######1   |106525/173481[39:12<27:24,40.72it/s] 66%|######5   |114077/173481[42:00<23:17,42.51it/s] 66%|######6   |114712/173481[42:12<23:02,42.51it/s] 71%|#######1  |123415/173481[45:00<17:51,46.73it/s] 72%|#######1  |124128/173481[45:12<17:36,46.73it/s] 77%|#######6  |133287/173481[48:00<13:16,50.46it/s] 77%|#######7  |133867/173481[48:12<13:05,50.46it/s] 82%|########1 |141516/173481[51:00<11:06,47.97it/s] 82%|########1 |142061/173481[51:12<10:54,47.97it/s] 86%|########6 |149849/173481[54:00<08:21,47.12it/s] 87%|########6 |150406/173481[54:12<08:09,47.12it/s] 91%|#########1|158262/173481[57:00<05:24,46.93it/s] 92%|#########1|158867/173481[57:13<05:11,46.93it/s] 96%|#########6|166887/173481[1:00:00<02:19,47.41it/s] 97%|#########6|167535/173481[1:00:13<02:05,47.41it/s]100%|##########|173481/173481[1:02:18<00:00,46.40it/s]
[32m[0322 15:57:09 @base.py:257][0m Epoch 20 (global_step 3469620) finished, time:3738.88 sec.
[32m[0322 15:57:09 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-3469620.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:59<00:00,104.65it/s]
19
[32m[0322 16:00:09 @monitor.py:363][0m QueueInput/queue_size: 0.7857
[32m[0322 16:00:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.152
[32m[0322 16:00:09 @monitor.py:363][0m activation-summaries/output-rms: 0.034958
[32m[0322 16:00:09 @monitor.py:363][0m cross_entropy_loss: 2.4206
[32m[0322 16:00:09 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60357
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6168
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.6198
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.57733
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.54928
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.48615
[32m[0322 16:00:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 16:00:09 @monitor.py:363][0m train-error-top1: 0.59557
[32m[0322 16:00:09 @monitor.py:363][0m val-error-top1: 0.63937
[32m[0322 16:00:09 @monitor.py:363][0m val-utt-error: 0.23605
[32m[0322 16:00:09 @monitor.py:363][0m validation_cost: 2.6456
[32m[0322 16:00:09 @monitor.py:363][0m wd_cost: 0.00059107
[32m[0322 16:00:09 @group.py:42][0m Callbacks took 180.142 sec in total. InferenceRunner: 179.867sec
[32m[0322 16:00:09 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11611/173481[03:00<41:49,64.50it/s]  7%|7         |12260/173481[03:10<41:39,64.50it/s] 12%|#2        |20836/173481[06:00<44:33,57.10it/s] 12%|#2        |21471/173481[06:10<44:21,57.10it/s] 18%|#8        |31316/173481[09:00<41:05,57.65it/s] 18%|#8        |31884/173481[09:10<40:55,57.65it/s] 24%|##3       |41494/173481[12:00<38:31,57.09it/s] 24%|##4       |42144/173481[12:10<38:20,57.09it/s] 30%|##9       |51448/173481[15:00<36:12,56.18it/s] 30%|##9       |51985/173481[15:10<36:02,56.18it/s] 36%|###5      |62100/173481[18:00<32:12,57.64it/s] 36%|###6      |62698/173481[18:10<32:02,57.64it/s] 41%|####1     |71412/173481[21:00<31:11,54.52it/s] 42%|####1     |72005/173481[21:11<31:01,54.52it/s] 47%|####7     |81793/173481[24:00<27:15,56.05it/s] 48%|####7     |82412/173481[24:11<27:04,56.05it/s] 53%|#####2    |91580/173481[27:00<24:43,55.20it/s] 53%|#####3    |92185/173481[27:11<24:32,55.20it/s] 58%|#####8    |101356/173481[30:00<21:57,54.75it/s] 59%|#####8    |101940/173481[30:11<21:46,54.75it/s] 64%|######3   |110851/173481[33:00<19:25,53.73it/s] 64%|######4   |111473/173481[33:11<19:14,53.73it/s] 70%|######9   |120603/173481[36:00<16:20,53.95it/s] 70%|######9   |121280/173481[36:11<16:07,53.95it/s] 76%|#######5  |131026/173481[39:00<12:40,55.85it/s] 76%|#######5  |131680/173481[39:12<12:28,55.85it/s] 82%|########1 |141694/173481[42:00<09:12,57.51it/s] 82%|########2 |142388/173481[42:12<09:00,57.51it/s] 87%|########7 |151001/173481[45:00<06:52,54.45it/s] 87%|########7 |151623/173481[45:12<06:41,54.45it/s] 93%|#########2|160531/173481[48:00<04:01,53.68it/s] 93%|#########2|161213/173481[48:12<03:48,53.68it/s] 98%|#########8|170796/173481[51:00<00:48,55.30it/s] 99%|#########8|171514/173481[51:12<00:35,55.30it/s]100%|##########|173481/173481[51:47<00:00,55.82it/s]
[32m[0322 16:51:57 @base.py:257][0m Epoch 21 (global_step 3643101) finished, time:3107.61 sec.
[32m[0322 16:51:57 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-3643101.
  0%|          |0/18822[00:00<?,?it/s] 97%|#########7|18348/18822[03:00<00:04,101.93it/s]100%|##########|18822/18822[03:05<00:00,101.61it/s]
20
[32m[0322 16:55:02 @monitor.py:363][0m QueueInput/queue_size: 0.86644
[32m[0322 16:55:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.1166
[32m[0322 16:55:02 @monitor.py:363][0m activation-summaries/output-rms: 0.034961
[32m[0322 16:55:02 @monitor.py:363][0m cross_entropy_loss: 2.4326
[32m[0322 16:55:02 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60827
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6177
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.62611
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.58195
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.55382
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.49017
[32m[0322 16:55:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 16:55:02 @monitor.py:363][0m train-error-top1: 0.59787
[32m[0322 16:55:02 @monitor.py:363][0m val-error-top1: 0.63994
[32m[0322 16:55:02 @monitor.py:363][0m val-utt-error: 0.2437
[32m[0322 16:55:02 @monitor.py:363][0m validation_cost: 2.6635
[32m[0322 16:55:02 @monitor.py:363][0m wd_cost: 0.00060172
[32m[0322 16:55:02 @group.py:42][0m Callbacks took 185.535 sec in total. InferenceRunner: 185.245sec
[32m[0322 16:55:02 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10352/173481[03:00<47:16,57.51it/s]  6%|6         |10954/173481[03:10<47:06,57.51it/s] 12%|#1        |20295/173481[06:00<45:18,56.35it/s] 12%|#2        |20843/173481[06:10<45:08,56.35it/s] 18%|#7        |30515/173481[09:00<42:07,56.56it/s] 18%|#7        |31099/173481[09:10<41:57,56.56it/s] 23%|##3       |40375/173481[12:00<39:51,55.65it/s] 24%|##3       |40974/173481[12:10<39:41,55.65it/s] 29%|##9       |50410/173481[15:00<36:49,55.69it/s] 29%|##9       |50998/173481[15:10<36:39,55.69it/s] 35%|###4      |60706/173481[18:00<33:18,56.43it/s] 35%|###5      |61283/173481[18:10<33:08,56.43it/s] 41%|####      |70611/173481[21:00<30:46,55.72it/s] 41%|####1     |71204/173481[21:10<30:35,55.72it/s] 46%|####6     |80568/173481[24:00<27:53,55.52it/s] 47%|####6     |81199/173481[24:11<27:42,55.52it/s] 50%|#####     |86962/173481[27:00<33:17,43.32it/s] 50%|#####     |87465/173481[27:11<33:05,43.32it/s] 56%|#####5    |96572/173481[30:00<26:47,47.83it/s] 56%|#####6    |97314/173481[30:11<26:32,47.83it/s] 61%|######1   |106597/173481[33:00<21:39,51.46it/s] 62%|######1   |107214/173481[33:11<21:27,51.46it/s] 68%|######7   |117952/173481[36:00<16:19,56.68it/s] 68%|######8   |118547/173481[36:11<16:09,56.68it/s] 73%|#######2  |126163/173481[39:00<15:36,50.55it/s] 73%|#######3  |126804/173481[39:11<15:23,50.55it/s] 78%|#######8  |136044/173481[42:00<11:51,52.63it/s] 79%|#######8  |136695/173481[42:11<11:38,52.63it/s] 84%|########4 |146005/173481[45:00<08:29,53.95it/s] 85%|########4 |146674/173481[45:12<08:16,53.95it/s] 90%|########9 |155650/173481[48:00<05:31,53.76it/s] 90%|######### |156319/173481[48:12<05:19,53.76it/s] 95%|#########5|165586/173481[51:00<02:24,54.47it/s] 96%|#########5|166257/173481[51:12<02:12,54.47it/s]100%|##########|173481/173481[53:24<00:00,54.14it/s]
[32m[0322 17:48:26 @base.py:257][0m Epoch 22 (global_step 3816582) finished, time:3204.18 sec.
[32m[0322 17:48:27 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-3816582.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13839/18822[03:00<01:04,76.88it/s] 79%|#######8  |14796/18822[03:10<00:52,76.88it/s]100%|##########|18822/18822[03:49<00:00,82.12it/s]
21
[32m[0322 17:52:16 @monitor.py:363][0m QueueInput/queue_size: 0.87206
[32m[0322 17:52:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.3663
[32m[0322 17:52:16 @monitor.py:363][0m activation-summaries/output-rms: 0.035085
[32m[0322 17:52:16 @monitor.py:363][0m cross_entropy_loss: 2.4117
[32m[0322 17:52:16 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61239
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6186
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.63151
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.58596
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.55776
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.49366
[32m[0322 17:52:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 17:52:16 @monitor.py:363][0m train-error-top1: 0.59413
[32m[0322 17:52:16 @monitor.py:363][0m val-error-top1: 0.63499
[32m[0322 17:52:16 @monitor.py:363][0m val-utt-error: 0.23552
[32m[0322 17:52:16 @monitor.py:363][0m validation_cost: 2.6144
[32m[0322 17:52:16 @monitor.py:363][0m wd_cost: 0.00061099
[32m[0322 17:52:16 @group.py:42][0m Callbacks took 229.500 sec in total. InferenceRunner: 229.221sec
[32m[0322 17:52:16 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10237/173481[03:00<47:50,56.87it/s]  6%|6         |10793/173481[03:10<47:40,56.87it/s] 12%|#1        |20168/173481[06:00<45:37,56.01it/s] 12%|#1        |20748/173481[06:10<45:27,56.01it/s] 18%|#7        |30399/173481[09:00<42:16,56.42it/s] 18%|#7        |30980/173481[09:10<42:05,56.42it/s] 23%|##3       |40334/173481[12:00<39:46,55.80it/s] 24%|##3       |40911/173481[12:10<39:35,55.80it/s] 29%|##8       |50149/173481[15:00<37:16,55.15it/s] 29%|##9       |50728/173481[15:10<37:05,55.15it/s] 35%|###4      |60094/173481[18:00<34:14,55.20it/s] 35%|###4      |60688/173481[18:10<34:03,55.20it/s] 40%|####      |70064/173481[21:00<31:10,55.29it/s] 41%|####      |70674/173481[21:11<30:59,55.29it/s] 48%|####7     |83206/173481[24:00<23:54,62.93it/s] 49%|####8     |84169/173481[24:11<23:39,62.93it/s] 57%|#####6    |98367/173481[27:00<17:22,72.03it/s] 57%|#####7    |98988/173481[27:11<17:14,72.03it/s] 63%|######2   |108566/173481[30:00<17:03,63.43it/s] 63%|######3   |109338/173481[30:11<16:51,63.43it/s] 69%|######8   |118870/173481[33:00<15:07,60.18it/s] 69%|######8   |119502/173481[33:11<14:56,60.18it/s] 74%|#######4  |128981/173481[36:00<12:45,58.10it/s] 75%|#######4  |129633/173481[36:11<12:34,58.10it/s] 80%|########  |139129/173481[39:00<10:00,57.23it/s] 81%|########  |139798/173481[39:11<09:48,57.23it/s] 86%|########5 |149185/173481[42:00<07:09,56.54it/s] 86%|########6 |149859/173481[42:12<06:57,56.54it/s] 92%|#########1|159319/173481[45:00<04:11,56.41it/s] 92%|#########2|159988/173481[45:12<03:59,56.41it/s] 98%|#########7|169435/173481[48:00<01:11,56.31it/s] 98%|#########8|170113/173481[48:12<00:59,56.31it/s]100%|##########|173481/173481[49:11<00:00,58.77it/s]
[32m[0322 18:41:28 @base.py:257][0m Epoch 23 (global_step 3990063) finished, time:2951.82 sec.
[32m[0322 18:41:28 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-3990063.
  0%|          |0/18822[00:00<?,?it/s] 60%|#####9    |11209/18822[03:00<02:02,62.27it/s] 63%|######2   |11830/18822[03:10<01:52,62.27it/s]100%|##########|18822/18822[05:01<00:00,62.45it/s]
22
[32m[0322 18:46:29 @monitor.py:363][0m QueueInput/queue_size: 0.73594
[32m[0322 18:46:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.3069
[32m[0322 18:46:29 @monitor.py:363][0m activation-summaries/output-rms: 0.03455
[32m[0322 18:46:29 @monitor.py:363][0m cross_entropy_loss: 2.4177
[32m[0322 18:46:29 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61459
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6191
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.63427
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.58805
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.55982
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.49548
[32m[0322 18:46:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 18:46:29 @monitor.py:363][0m train-error-top1: 0.59422
[32m[0322 18:46:29 @monitor.py:363][0m val-error-top1: 0.63703
[32m[0322 18:46:29 @monitor.py:363][0m val-utt-error: 0.22612
[32m[0322 18:46:29 @monitor.py:363][0m validation_cost: 2.62
[32m[0322 18:46:29 @monitor.py:363][0m wd_cost: 0.00012316
[32m[0322 18:46:29 @group.py:42][0m Callbacks took 301.686 sec in total. InferenceRunner: 301.384sec
[32m[0322 18:46:29 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10229/173481[03:00<47:52,56.83it/s]  6%|6         |10789/173481[03:10<47:42,56.83it/s] 12%|#1        |19988/173481[06:00<46:06,55.49it/s] 12%|#1        |20557/173481[06:10<45:55,55.49it/s] 17%|#7        |29918/173481[09:00<43:14,55.33it/s] 18%|#7        |30496/173481[09:10<43:04,55.33it/s] 24%|##3       |40912/173481[12:00<38:03,58.06it/s] 24%|##4       |41810/173481[12:10<37:47,58.06it/s] 33%|###2      |56416/173481[15:00<28:07,69.36it/s] 33%|###3      |57342/173481[15:10<27:54,69.36it/s] 41%|####      |70819/173481[18:00<23:01,74.31it/s] 41%|####1     |71654/173481[18:10<22:50,74.31it/s] 49%|####9     |85359/173481[21:00<18:58,77.41it/s] 50%|####9     |86254/173481[21:11<18:46,77.41it/s] 58%|#####7    |100298/173481[24:00<15:13,80.10it/s] 58%|#####8    |101223/173481[24:11<15:02,80.10it/s] 64%|######4   |111893/173481[27:00<14:22,71.41it/s] 65%|######4   |112606/173481[27:11<14:12,71.41it/s] 71%|#######   |122807/173481[30:00<12:52,65.58it/s] 71%|#######1  |123492/173481[30:11<12:42,65.58it/s] 77%|#######6  |133529/173481[33:00<10:39,62.43it/s] 77%|#######7  |134251/173481[33:11<10:28,62.43it/s] 83%|########3 |144503/173481[36:00<07:49,61.69it/s] 84%|########3 |145255/173481[36:11<07:37,61.69it/s] 90%|########9 |155595/173481[39:00<04:50,61.65it/s] 90%|######### |156339/173481[39:11<04:38,61.65it/s] 96%|#########6|166750/173481[42:00<01:48,61.81it/s] 96%|#########6|167397/173481[42:11<01:38,61.81it/s]100%|##########|173481/173481[43:55<00:00,65.83it/s]
[32m[0322 19:30:25 @base.py:257][0m Epoch 24 (global_step 4163544) finished, time:2635.10 sec.
[32m[0322 19:30:25 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-4163544.
  0%|          |0/18822[00:00<?,?it/s] 94%|#########4|17722/18822[03:00<00:11,98.45it/s] 99%|#########9|18707/18822[03:10<00:01,98.45it/s]100%|##########|18822/18822[03:11<00:00,98.31it/s]
23
[32m[0322 19:33:36 @monitor.py:363][0m QueueInput/queue_size: 1.08
[32m[0322 19:33:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.3381
[32m[0322 19:33:36 @monitor.py:363][0m activation-summaries/output-rms: 0.033953
[32m[0322 19:33:36 @monitor.py:363][0m cross_entropy_loss: 2.4468
[32m[0322 19:33:36 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6168
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6195
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.63701
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59016
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.5619
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.49729
[32m[0322 19:33:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 19:33:36 @monitor.py:363][0m train-error-top1: 0.60445
[32m[0322 19:33:36 @monitor.py:363][0m val-error-top1: 0.63964
[32m[0322 19:33:36 @monitor.py:363][0m val-utt-error: 0.23563
[32m[0322 19:33:36 @monitor.py:363][0m validation_cost: 2.6438
[32m[0322 19:33:36 @monitor.py:363][0m wd_cost: 0.00012413
[32m[0322 19:33:36 @group.py:42][0m Callbacks took 191.728 sec in total. InferenceRunner: 191.477sec
[32m[0322 19:33:36 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10627/173481[03:00<45:58,59.04it/s]  6%|6         |11191/173481[03:10<45:49,59.04it/s] 12%|#2        |21533/173481[06:00<42:20,59.80it/s] 13%|#2        |22413/173481[06:10<42:06,59.80it/s] 20%|##        |35199/173481[09:00<34:26,66.90it/s] 21%|##        |35864/173481[09:10<34:16,66.90it/s] 26%|##6       |45417/173481[12:00<34:45,61.42it/s] 27%|##6       |46006/173481[12:10<34:35,61.42it/s] 32%|###2      |55787/173481[15:00<32:59,59.45it/s] 33%|###2      |56394/173481[15:10<32:49,59.45it/s] 38%|###7      |65835/173481[18:00<31:09,57.58it/s] 38%|###8      |66475/173481[18:10<30:58,57.58it/s] 44%|####4     |76474/173481[21:00<27:43,58.33it/s] 44%|####4     |77141/173481[21:11<27:31,58.33it/s] 50%|#####     |87506/173481[24:00<23:58,59.77it/s] 51%|#####     |88133/173481[24:11<23:47,59.77it/s] 57%|#####6    |98291/173481[27:00<20:56,59.84it/s] 57%|#####7    |98940/173481[27:11<20:45,59.84it/s] 63%|######3   |109404/173481[30:00<17:34,60.78it/s] 63%|######3   |110106/173481[30:11<17:22,60.78it/s] 69%|######9   |120222/173481[33:00<14:41,60.43it/s] 70%|######9   |120939/173481[33:11<14:29,60.43it/s] 76%|#######5  |131348/173481[36:00<11:29,61.11it/s] 76%|#######6  |132091/173481[36:11<11:17,61.11it/s] 82%|########2 |142847/173481[39:00<08:10,62.46it/s] 83%|########2 |143551/173481[39:11<07:59,62.46it/s] 89%|########8 |153697/173481[42:00<05:22,61.35it/s] 89%|########9 |154483/173481[42:12<05:09,61.35it/s] 96%|#########6|166821/173481[45:00<01:39,66.63it/s] 97%|#########6|167821/173481[45:12<01:24,66.63it/s]100%|##########|173481/173481[46:36<00:00,62.03it/s]
[32m[0322 20:20:13 @base.py:257][0m Epoch 25 (global_step 4337025) finished, time:2796.60 sec.
[32m[0322 20:20:13 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-4337025.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.95it/s]
24
[32m[0322 20:22:07 @monitor.py:363][0m QueueInput/queue_size: 1.6261
[32m[0322 20:22:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.3976
[32m[0322 20:22:07 @monitor.py:363][0m activation-summaries/output-rms: 0.03595
[32m[0322 20:22:07 @monitor.py:363][0m cross_entropy_loss: 2.4152
[32m[0322 20:22:07 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61843
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6199
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.63895
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.5917
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56342
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.49864
[32m[0322 20:22:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 20:22:07 @monitor.py:363][0m train-error-top1: 0.59559
[32m[0322 20:22:07 @monitor.py:363][0m val-error-top1: 0.63781
[32m[0322 20:22:07 @monitor.py:363][0m val-utt-error: 0.23797
[32m[0322 20:22:07 @monitor.py:363][0m validation_cost: 2.636
[32m[0322 20:22:07 @monitor.py:363][0m wd_cost: 2.4967e-05
[32m[0322 20:22:07 @group.py:42][0m Callbacks took 113.849 sec in total. InferenceRunner: 113.433sec
[32m[0322 20:22:07 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12087/173481[03:00<40:03,67.15it/s]  7%|7         |12705/173481[03:10<39:54,67.15it/s] 14%|#3        |24008/173481[06:00<37:21,66.68it/s] 14%|#4        |24665/173481[06:10<37:11,66.68it/s] 20%|#9        |34401/173481[09:00<37:27,61.89it/s] 20%|##        |35055/173481[09:10<37:16,61.89it/s] 26%|##6       |45225/173481[12:00<35:02,61.00it/s] 26%|##6       |45845/173481[12:10<34:52,61.00it/s] 32%|###2      |56289/173481[15:00<31:53,61.23it/s] 33%|###2      |57005/173481[15:10<31:42,61.23it/s] 39%|###8      |67236/173481[18:00<29:01,61.02it/s] 39%|###9      |67871/173481[18:10<28:50,61.02it/s] 45%|####4     |77421/173481[21:00<27:15,58.72it/s] 45%|####5     |78089/173481[21:11<27:04,58.72it/s] 51%|#####     |88087/173481[24:00<24:07,58.98it/s] 51%|#####1    |88735/173481[24:11<23:56,58.98it/s] 57%|#####6    |98501/173481[27:00<21:23,58.41it/s] 57%|#####7    |99108/173481[27:11<21:13,58.41it/s] 63%|######2   |108778/173481[30:00<18:40,57.74it/s] 63%|######3   |109409/173481[30:11<18:29,57.74it/s] 69%|######8   |119132/173481[33:00<15:43,57.63it/s] 69%|######9   |119791/173481[33:11<15:31,57.63it/s] 75%|#######4  |129746/173481[36:00<12:30,58.29it/s] 75%|#######5  |130405/173481[36:11<12:19,58.29it/s] 81%|########  |140207/173481[39:00<09:31,58.20it/s] 81%|########1 |140912/173481[39:11<09:19,58.20it/s] 87%|########6 |150886/173481[42:00<06:24,58.75it/s] 87%|########7 |151565/173481[42:11<06:13,58.75it/s] 93%|#########2|161038/173481[45:00<03:36,57.55it/s] 93%|#########3|161795/173481[45:12<03:23,57.55it/s]100%|#########9|172832/173481[48:00<00:10,61.28it/s]100%|##########|173481/173481[48:11<00:00,60.00it/s]
[32m[0322 21:10:18 @base.py:257][0m Epoch 26 (global_step 4510506) finished, time:2891.23 sec.
[32m[0322 21:10:18 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:49<00:00,111.31it/s]
25
[32m[0322 21:13:07 @monitor.py:363][0m QueueInput/queue_size: 0.84391
[32m[0322 21:13:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.2427
[32m[0322 21:13:07 @monitor.py:363][0m activation-summaries/output-rms: 0.035028
[32m[0322 21:13:07 @monitor.py:363][0m cross_entropy_loss: 2.4014
[32m[0322 21:13:07 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6195
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6201
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64016
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59277
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56448
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.49958
[32m[0322 21:13:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 21:13:07 @monitor.py:363][0m train-error-top1: 0.59716
[32m[0322 21:13:07 @monitor.py:363][0m val-error-top1: 0.63609
[32m[0322 21:13:07 @monitor.py:363][0m val-utt-error: 0.23558
[32m[0322 21:13:07 @monitor.py:363][0m validation_cost: 2.6369
[32m[0322 21:13:07 @monitor.py:363][0m wd_cost: 2.506e-05
[32m[0322 21:13:07 @group.py:42][0m Callbacks took 169.380 sec in total. InferenceRunner: 169.110sec
[32m[0322 21:13:07 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11030/173481[03:00<44:11,61.27it/s]  7%|6         |11589/173481[03:10<44:02,61.27it/s] 12%|#2        |21028/173481[06:00<43:36,58.27it/s] 12%|#2        |21599/173481[06:10<43:26,58.27it/s] 18%|#7        |31055/173481[09:00<41:40,56.96it/s] 18%|#8        |31639/173481[09:10<41:30,56.96it/s] 24%|##3       |40975/173481[12:00<39:25,56.01it/s] 24%|##3       |41569/173481[12:10<39:14,56.01it/s] 29%|##9       |50908/173481[15:00<36:44,55.59it/s] 30%|##9       |51499/173481[15:10<36:34,55.59it/s] 35%|###4      |60676/173481[18:00<34:13,54.92it/s] 35%|###5      |61262/173481[18:10<34:03,54.92it/s] 41%|####      |70475/173481[21:00<31:24,54.67it/s] 41%|####      |71079/173481[21:11<31:12,54.67it/s] 46%|####6     |80368/173481[24:00<28:18,54.82it/s] 47%|####6     |80974/173481[24:11<28:07,54.82it/s] 52%|#####2    |90350/173481[27:00<25:07,55.13it/s] 52%|#####2    |90959/173481[27:11<24:56,55.13it/s] 58%|#####7    |100268/173481[30:00<22:08,55.11it/s] 58%|#####8    |100899/173481[30:11<21:56,55.11it/s] 65%|######4   |112069/173481[33:00<17:05,59.88it/s] 65%|######5   |113044/173481[33:11<16:49,59.88it/s] 73%|#######3  |127101/173481[36:00<11:04,69.75it/s] 74%|#######3  |127789/173481[36:11<10:55,69.75it/s] 79%|#######9  |137338/173481[39:00<09:36,62.65it/s] 80%|#######9  |138059/173481[39:11<09:25,62.65it/s] 85%|########5 |147623/173481[42:00<07:12,59.77it/s] 85%|########5 |148299/173481[42:12<07:01,59.77it/s] 91%|#########1|157893/173481[45:00<04:27,58.38it/s] 91%|#########1|158604/173481[45:12<04:14,58.38it/s] 97%|#########6|168038/173481[48:00<01:34,57.35it/s] 97%|#########7|168711/173481[48:12<01:23,57.35it/s]100%|##########|173481/173481[49:36<00:00,58.28it/s]
[32m[0322 22:02:44 @base.py:257][0m Epoch 27 (global_step 4683987) finished, time:2976.59 sec.
[32m[0322 22:02:45 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-4683987.
  0%|          |0/18822[00:00<?,?it/s] 57%|#####6    |10694/18822[03:00<02:16,59.41it/s] 60%|######    |11336/18822[03:10<02:06,59.41it/s]100%|##########|18822/18822[05:04<00:00,61.74it/s]
26
[32m[0322 22:07:49 @monitor.py:363][0m QueueInput/queue_size: 0.93207
[32m[0322 22:07:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.2982
[32m[0322 22:07:49 @monitor.py:363][0m activation-summaries/output-rms: 0.034713
[32m[0322 22:07:49 @monitor.py:363][0m cross_entropy_loss: 2.4484
[32m[0322 22:07:49 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62061
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6203
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64135
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59383
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56553
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50052
[32m[0322 22:07:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 22:07:49 @monitor.py:363][0m train-error-top1: 0.60205
[32m[0322 22:07:49 @monitor.py:363][0m val-error-top1: 0.63841
[32m[0322 22:07:49 @monitor.py:363][0m val-utt-error: 0.23393
[32m[0322 22:07:49 @monitor.py:363][0m validation_cost: 2.6372
[32m[0322 22:07:49 @monitor.py:363][0m wd_cost: 2.5153e-05
[32m[0322 22:07:49 @group.py:42][0m Callbacks took 305.489 sec in total. InferenceRunner: 304.862sec
[32m[0322 22:07:49 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10239/173481[03:00<47:50,56.88it/s]  6%|6         |10798/173481[03:10<47:40,56.88it/s] 11%|#1        |19849/173481[06:00<46:29,55.07it/s] 12%|#1        |20371/173481[06:10<46:20,55.07it/s] 17%|#7        |30340/173481[09:00<42:07,56.63it/s] 18%|#7        |30898/173481[09:10<41:57,56.63it/s] 23%|##3       |40407/173481[12:00<39:24,56.28it/s] 24%|##3       |40995/173481[12:10<39:14,56.28it/s] 29%|##9       |50464/173481[15:00<36:33,56.07it/s] 29%|##9       |51037/173481[15:10<36:23,56.07it/s] 35%|###4      |60339/173481[18:00<34:00,55.45it/s] 35%|###5      |60928/173481[18:10<33:49,55.45it/s] 42%|####1     |72076/173481[21:00<28:11,59.93it/s] 42%|####2     |73004/173481[21:10<27:56,59.93it/s] 50%|#####     |87463/173481[24:00<20:20,70.46it/s] 51%|#####     |88384/173481[24:11<20:07,70.46it/s] 59%|#####8    |101744/173481[27:00<16:01,74.64it/s] 59%|#####9    |102530/173481[27:11<15:50,74.64it/s] 67%|######7   |116272/173481[30:00<12:17,77.55it/s] 68%|######7   |117161/173481[30:11<12:06,77.55it/s] 75%|#######5  |130960/173481[33:00<08:54,79.52it/s] 76%|#######5  |131843/173481[33:11<08:43,79.52it/s] 82%|########2 |142349/173481[36:00<07:21,70.47it/s] 82%|########2 |143060/173481[36:11<07:11,70.47it/s] 89%|########8 |153640/173481[39:00<04:58,66.37it/s] 89%|########9 |154437/173481[39:11<04:46,66.37it/s] 95%|#########5|165417/173481[42:00<02:02,65.90it/s] 96%|#########5|166177/173481[42:11<01:50,65.90it/s]100%|##########|173481/173481[44:05<00:00,65.58it/s]
[32m[0322 22:51:55 @base.py:257][0m Epoch 28 (global_step 4857468) finished, time:2645.50 sec.
[32m[0322 22:51:55 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-4857468.
  0%|          |0/18822[00:00<?,?it/s] 97%|#########7|18332/18822[03:00<00:04,101.84it/s]100%|##########|18822/18822[03:04<00:00,101.92it/s]
27
[32m[0322 22:55:00 @monitor.py:363][0m QueueInput/queue_size: 0.9095
[32m[0322 22:55:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.6488
[32m[0322 22:55:00 @monitor.py:363][0m activation-summaries/output-rms: 0.034808
[32m[0322 22:55:00 @monitor.py:363][0m cross_entropy_loss: 2.4183
[32m[0322 22:55:00 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62122
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6205
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64192
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59438
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56608
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50101
[32m[0322 22:55:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 22:55:00 @monitor.py:363][0m train-error-top1: 0.59951
[32m[0322 22:55:00 @monitor.py:363][0m val-error-top1: 0.63406
[32m[0322 22:55:00 @monitor.py:363][0m val-utt-error: 0.22017
[32m[0322 22:55:00 @monitor.py:363][0m validation_cost: 2.6184
[32m[0322 22:55:00 @monitor.py:363][0m wd_cost: 5.0399e-06
[32m[0322 22:55:00 @group.py:42][0m Callbacks took 185.102 sec in total. InferenceRunner: 184.684sec
[32m[0322 22:55:00 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10832/173481[03:00<45:02,60.17it/s]  7%|6         |11441/173481[03:10<44:52,60.17it/s] 12%|#2        |20826/173481[06:00<44:03,57.75it/s] 12%|#2        |21393/173481[06:10<43:53,57.75it/s] 18%|#7        |30788/173481[09:00<42:04,56.52it/s] 18%|#8        |31361/173481[09:10<41:54,56.52it/s] 23%|##3       |40742/173481[12:00<39:34,55.90it/s] 24%|##3       |41322/173481[12:10<39:24,55.90it/s] 30%|###       |52750/173481[15:00<33:04,60.83it/s] 31%|###       |53658/173481[15:10<32:49,60.83it/s] 39%|###9      |68056/173481[18:00<24:46,70.92it/s] 40%|###9      |68927/173481[18:10<24:34,70.92it/s] 46%|####6     |79822/173481[21:00<22:56,68.03it/s] 46%|####6     |80549/173481[21:11<22:46,68.03it/s] 54%|#####3    |93014/173481[24:00<19:00,70.56it/s] 54%|#####4    |93867/173481[24:11<18:48,70.56it/s] 62%|######1   |107348/173481[27:00<14:43,74.82it/s] 62%|######2   |108286/173481[27:11<14:31,74.82it/s] 70%|#######   |121941/173481[30:00<11:02,77.82it/s] 71%|#######   |122873/173481[30:11<10:50,77.82it/s] 79%|#######8  |136595/173481[33:00<07:43,79.58it/s] 79%|#######9  |137523/173481[33:11<07:31,79.58it/s] 87%|########7 |151201/173481[36:00<04:37,80.35it/s] 88%|########7 |152179/173481[36:11<04:25,80.35it/s] 96%|#########5|165903/173481[39:00<01:33,81.01it/s] 96%|#########6|166879/173481[39:11<01:21,81.01it/s]100%|##########|173481/173481[40:33<00:00,71.30it/s]
[32m[0322 23:35:33 @base.py:257][0m Epoch 29 (global_step 5030949) finished, time:2433.20 sec.
[32m[0322 23:35:34 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-5030949.
[32m[0322 23:35:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 54%|#####3    |10129/18822[03:00<02:34,56.27it/s] 57%|#####7    |10748/18822[03:10<02:23,56.27it/s]100%|##########|18822/18822[04:54<00:00,64.01it/s]
28
[32m[0322 23:40:29 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0322 23:40:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.5899
[32m[0322 23:40:29 @monitor.py:363][0m activation-summaries/output-rms: 0.034369
[32m[0322 23:40:29 @monitor.py:363][0m cross_entropy_loss: 2.3386
[32m[0322 23:40:29 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62172
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6206
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64237
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59482
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56654
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50142
[32m[0322 23:40:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0322 23:40:29 @monitor.py:363][0m train-error-top1: 0.58536
[32m[0322 23:40:29 @monitor.py:363][0m val-error-top1: 0.63028
[32m[0322 23:40:29 @monitor.py:363][0m val-utt-error: 0.22702
[32m[0322 23:40:29 @monitor.py:363][0m validation_cost: 2.6102
[32m[0322 23:40:29 @monitor.py:363][0m wd_cost: 5.0475e-06
[32m[0322 23:40:29 @group.py:42][0m Callbacks took 295.672 sec in total. InferenceRunner: 294.073sec
[32m[0322 23:40:29 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15293/173481[03:00<31:01,84.96it/s]  9%|9         |16051/173481[03:10<30:52,84.96it/s] 15%|#4        |26017/173481[06:00<35:05,70.03it/s] 15%|#5        |26616/173481[06:10<34:57,70.03it/s] 21%|##1       |36936/173481[09:00<35:00,65.01it/s] 22%|##1       |37517/173481[09:10<34:51,65.01it/s] 27%|##7       |47091/173481[12:00<34:52,60.41it/s] 27%|##7       |47676/173481[12:10<34:42,60.41it/s] 33%|###3      |57331/173481[15:00<33:02,58.59it/s] 33%|###3      |58001/173481[15:10<32:50,58.59it/s] 39%|###9      |67906/173481[18:00<29:59,58.67it/s] 40%|###9      |68561/173481[18:10<29:48,58.67it/s] 46%|####6     |80549/173481[21:00<24:13,63.93it/s] 47%|####6     |81417/173481[21:11<23:59,63.93it/s] 55%|#####4    |94998/173481[24:00<18:22,71.18it/s] 55%|#####5    |95882/173481[24:11<18:10,71.18it/s] 62%|######1   |106902/173481[27:00<16:11,68.56it/s] 62%|######1   |107530/173481[27:11<16:01,68.56it/s] 67%|######7   |116797/173481[30:00<15:29,61.01it/s] 68%|######7   |117424/173481[30:11<15:18,61.01it/s] 74%|#######3  |127788/173481[33:00<12:28,61.04it/s] 74%|#######4  |128631/173481[33:11<12:14,61.04it/s] 80%|#######9  |138726/173481[36:00<09:30,60.90it/s] 80%|########  |139443/173481[36:11<09:18,60.90it/s] 86%|########5 |148887/173481[39:00<06:59,58.59it/s] 86%|########6 |149555/173481[39:11<06:48,58.59it/s] 92%|#########2|159610/173481[42:00<03:54,59.08it/s] 93%|#########2|160560/173481[42:12<03:38,59.08it/s]100%|##########|173481/173481[44:45<00:00,64.60it/s]
[32m[0323 00:25:15 @base.py:257][0m Epoch 30 (global_step 5204430) finished, time:2685.66 sec.
[32m[0323 00:25:15 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-5204430.
[32m[0323 00:25:15 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######6  |14467/18822[03:00<00:54,80.37it/s] 80%|########  |15121/18822[03:10<00:46,80.37it/s]100%|##########|18822/18822[04:07<00:00,75.99it/s]
29
[32m[0323 00:29:23 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 00:29:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.774
[32m[0323 00:29:23 @monitor.py:363][0m activation-summaries/output-rms: 0.037414
[32m[0323 00:29:23 @monitor.py:363][0m cross_entropy_loss: 2.0945
[32m[0323 00:29:23 @monitor.py:363][0m lr: 4.8828e-07
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62217
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6207
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.6428
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59527
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56699
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50183
[32m[0323 00:29:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 00:29:23 @monitor.py:363][0m train-error-top1: 0.53397
[32m[0323 00:29:23 @monitor.py:363][0m val-error-top1: 0.61475
[32m[0323 00:29:23 @monitor.py:363][0m val-utt-error: 0.19238
[32m[0323 00:29:23 @monitor.py:363][0m validation_cost: 2.5285
[32m[0323 00:29:23 @monitor.py:363][0m wd_cost: 5.0549e-06
[32m[0323 00:29:23 @group.py:42][0m Callbacks took 248.647 sec in total. InferenceRunner: 247.687sec
[32m[0323 00:29:23 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12013/173481[03:00<40:19,66.74it/s]  7%|7         |12574/173481[03:10<40:11,66.74it/s] 13%|#2        |22013/173481[06:00<41:38,60.63it/s] 13%|#3        |22572/173481[06:10<41:28,60.63it/s] 18%|#8        |32045/173481[09:00<40:35,58.08it/s] 19%|#8        |32636/173481[09:10<40:25,58.08it/s] 24%|##4       |42151/173481[12:00<38:20,57.09it/s] 25%|##4       |42801/173481[12:10<38:08,57.09it/s] 31%|###       |53473/173481[15:00<33:24,59.86it/s] 31%|###1      |54324/173481[15:10<33:10,59.86it/s] 39%|###8      |67447/173481[18:00<26:08,67.59it/s] 39%|###9      |68086/173481[18:10<25:59,67.59it/s] 46%|####6     |80526/173481[21:00<22:07,70.03it/s] 47%|####6     |81150/173481[21:11<21:58,70.03it/s] 52%|#####2    |90566/173481[24:00<22:15,62.09it/s] 53%|#####2    |91193/173481[24:11<22:05,62.09it/s] 58%|#####7    |100514/173481[27:00<20:47,58.48it/s] 58%|#####8    |101204/173481[27:11<20:35,58.48it/s] 64%|######3   |110711/173481[30:00<18:10,57.54it/s] 64%|######4   |111521/173481[30:11<17:56,57.54it/s] 70%|######9   |121317/173481[33:00<14:55,58.23it/s] 70%|#######   |121993/173481[33:11<14:44,58.23it/s] 78%|#######8  |136137/173481[36:00<09:07,68.21it/s] 79%|#######9  |137125/173481[36:11<08:52,68.21it/s] 87%|########6 |150461/173481[39:00<05:13,73.45it/s] 87%|########7 |151128/173481[39:12<05:04,73.45it/s] 93%|#########3|161371/173481[42:00<03:02,66.41it/s] 93%|#########3|162048/173481[42:12<02:52,66.41it/s] 99%|#########8|171654/173481[45:00<00:29,61.42it/s] 99%|#########9|172583/173481[45:12<00:14,61.42it/s]100%|##########|173481/173481[45:23<00:00,63.70it/s]
[32m[0323 01:14:47 @base.py:257][0m Epoch 31 (global_step 5377911) finished, time:2723.27 sec.
[32m[0323 01:14:47 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-5377911.
[32m[0323 01:14:47 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 55%|#####4    |10350/18822[03:00<02:27,57.50it/s] 58%|#####8    |10942/18822[03:10<02:17,57.50it/s]100%|##########|18822/18822[05:23<00:00,58.10it/s]
30
[32m[0323 01:20:11 @monitor.py:363][0m QueueInput/queue_size: 34.052
[32m[0323 01:20:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.6978
[32m[0323 01:20:11 @monitor.py:363][0m activation-summaries/output-rms: 0.035123
[32m[0323 01:20:11 @monitor.py:363][0m cross_entropy_loss: 2.3232
[32m[0323 01:20:11 @monitor.py:363][0m lr: 4.8828e-07
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6223
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6207
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64298
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59543
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56717
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.502
[32m[0323 01:20:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 01:20:11 @monitor.py:363][0m train-error-top1: 0.57808
[32m[0323 01:20:11 @monitor.py:363][0m val-error-top1: 0.63752
[32m[0323 01:20:11 @monitor.py:363][0m val-utt-error: 0.23488
[32m[0323 01:20:11 @monitor.py:363][0m validation_cost: 2.6359
[32m[0323 01:20:11 @monitor.py:363][0m wd_cost: 1.0115e-06
[32m[0323 01:20:11 @group.py:42][0m Callbacks took 324.976 sec in total. InferenceRunner: 323.975sec
[32m[0323 01:20:11 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13373/173481[03:00<35:55,74.29it/s]  8%|8         |14043/173481[03:10<35:46,74.29it/s] 15%|#4        |25448/173481[06:00<34:59,70.50it/s] 15%|#4        |26012/173481[06:10<34:51,70.50it/s] 23%|##2       |39321/173481[09:00<30:21,73.64it/s] 23%|##3       |40170/173481[09:10<30:10,73.64it/s] 30%|##9       |51711/173481[12:00<28:31,71.15it/s] 30%|###       |52361/173481[12:10<28:22,71.15it/s] 37%|###7      |64824/173481[15:00<25:09,71.99it/s] 38%|###7      |65703/173481[15:10<24:57,71.99it/s] 44%|####3     |76305/173481[18:00<23:56,67.64it/s] 44%|####4     |76944/173481[18:10<23:47,67.64it/s] 51%|#####     |87740/173481[21:00<21:48,65.51it/s] 51%|#####     |88415/173481[21:11<21:38,65.51it/s] 58%|#####8    |101317/173481[24:00<17:09,70.12it/s] 59%|#####8    |102242/173481[24:11<16:55,70.12it/s] 67%|######6   |116068/173481[27:00<12:39,75.57it/s] 67%|######7   |116985/173481[27:11<12:27,75.57it/s] 74%|#######4  |129010/173481[30:00<10:03,73.69it/s] 75%|#######4  |129661/173481[30:11<09:54,73.69it/s] 80%|########  |139140/173481[33:00<08:58,63.81it/s] 81%|########  |139932/173481[33:11<08:45,63.81it/s] 88%|########8 |153251/173481[36:00<04:47,70.36it/s] 89%|########8 |154054/173481[36:11<04:36,70.36it/s] 95%|#########5|164814/173481[39:00<02:09,67.16it/s] 95%|#########5|165557/173481[39:12<01:57,67.16it/s]100%|##########|173481/173481[41:08<00:00,70.27it/s]
[32m[0323 02:01:20 @base.py:257][0m Epoch 32 (global_step 5551392) finished, time:2468.84 sec.
[32m[0323 02:01:21 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-5551392.
  0%|          |0/18822[00:00<?,?it/s] 55%|#####5    |10442/18822[03:00<02:24,58.01it/s] 59%|#####8    |11020/18822[03:10<02:14,58.01it/s]100%|##########|18822/18822[04:53<00:00,64.06it/s]
31
[32m[0323 02:06:15 @monitor.py:363][0m QueueInput/queue_size: 0.66459
[32m[0323 02:06:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.7245
[32m[0323 02:06:15 @monitor.py:363][0m activation-summaries/output-rms: 0.034842
[32m[0323 02:06:15 @monitor.py:363][0m cross_entropy_loss: 2.4081
[32m[0323 02:06:15 @monitor.py:363][0m lr: 4.8828e-07
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62244
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6208
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64315
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.5956
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56735
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50217
[32m[0323 02:06:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 02:06:15 @monitor.py:363][0m train-error-top1: 0.5915
[32m[0323 02:06:15 @monitor.py:363][0m val-error-top1: 0.64141
[32m[0323 02:06:15 @monitor.py:363][0m val-utt-error: 0.24424
[32m[0323 02:06:15 @monitor.py:363][0m validation_cost: 2.6654
[32m[0323 02:06:15 @monitor.py:363][0m wd_cost: 1.0121e-06
[32m[0323 02:06:15 @group.py:42][0m Callbacks took 294.220 sec in total. InferenceRunner: 293.817sec
[32m[0323 02:06:15 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13079/173481[03:00<36:47,72.66it/s]  8%|7         |13697/173481[03:10<36:39,72.66it/s] 15%|#4        |25774/173481[06:00<34:23,71.58it/s] 15%|#5        |26358/173481[06:10<34:15,71.58it/s] 21%|##1       |36994/173481[09:00<34:08,66.63it/s] 22%|##1       |37584/173481[09:10<33:59,66.63it/s] 28%|##8       |49397/173481[12:00<30:31,67.75it/s] 29%|##8       |50170/173481[12:10<30:20,67.75it/s] 35%|###4      |60174/173481[15:00<29:42,63.56it/s] 35%|###5      |60768/173481[15:10<29:33,63.56it/s] 43%|####2     |74048/173481[18:00<23:47,69.67it/s] 43%|####3     |74969/173481[18:10<23:33,69.67it/s] 51%|#####     |88302/173481[21:00<19:09,74.12it/s] 51%|#####1    |89156/173481[21:11<18:57,74.12it/s] 59%|#####9    |102569/173481[24:00<15:25,76.61it/s] 60%|#####9    |103443/173481[24:11<15:14,76.61it/s] 66%|######5   |113642/173481[27:00<14:36,68.24it/s] 66%|######5   |114341/173481[27:11<14:26,68.24it/s] 72%|#######1  |124411/173481[30:00<12:49,63.76it/s] 72%|#######2  |125078/173481[30:11<12:39,63.76it/s] 79%|#######8  |136317/173481[33:00<09:32,64.93it/s] 79%|#######9  |137269/173481[33:11<09:17,64.93it/s] 87%|########6 |150318/173481[36:00<05:27,70.78it/s] 87%|########7 |151242/173481[36:11<05:14,70.78it/s] 95%|#########4|164393/173481[39:00<02:02,74.30it/s] 95%|#########5|165354/173481[39:12<01:49,74.30it/s]100%|##########|173481/173481[41:12<00:00,70.17it/s]
[32m[0323 02:47:27 @base.py:257][0m Epoch 33 (global_step 5724873) finished, time:2472.27 sec.
[32m[0323 02:47:27 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-5724873.
  0%|          |0/18822[00:00<?,?it/s] 47%|####7     |8932/18822[03:00<03:19,49.62it/s] 50%|#####     |9446/18822[03:10<03:08,49.62it/s] 98%|#########8|18520/18822[06:00<00:05,51.38it/s]100%|##########|18822/18822[06:05<00:00,51.56it/s]
32
[32m[0323 02:53:32 @monitor.py:363][0m QueueInput/queue_size: 0.89268
[32m[0323 02:53:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.005
[32m[0323 02:53:32 @monitor.py:363][0m activation-summaries/output-rms: 0.03574
[32m[0323 02:53:32 @monitor.py:363][0m cross_entropy_loss: 2.4349
[32m[0323 02:53:32 @monitor.py:363][0m lr: 2.4414e-07
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6225
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6208
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64328
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59572
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56748
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.5023
[32m[0323 02:53:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 02:53:32 @monitor.py:363][0m train-error-top1: 0.59966
[32m[0323 02:53:32 @monitor.py:363][0m val-error-top1: 0.6339
[32m[0323 02:53:32 @monitor.py:363][0m val-utt-error: 0.22282
[32m[0323 02:53:32 @monitor.py:363][0m validation_cost: 2.6261
[32m[0323 02:53:32 @monitor.py:363][0m wd_cost: 1.0125e-06
[32m[0323 02:53:32 @group.py:42][0m Callbacks took 365.371 sec in total. InferenceRunner: 365.055sec
[32m[0323 02:53:32 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10568/173481[03:00<46:15,58.70it/s]  6%|6         |11197/173481[03:10<46:04,58.70it/s] 14%|#4        |24924/173481[06:00<36:36,67.63it/s] 15%|#4        |25792/173481[06:10<36:23,67.63it/s] 23%|##2       |39277/173481[09:00<30:33,73.18it/s] 23%|##3       |40074/173481[09:10<30:22,73.18it/s] 29%|##9       |50933/173481[12:00<29:43,68.71it/s] 30%|##9       |51607/173481[12:10<29:33,68.71it/s] 37%|###6      |63551/173481[15:00<26:24,69.40it/s] 37%|###7      |64422/173481[15:10<26:11,69.40it/s] 45%|####5     |78156/173481[18:00<21:14,74.81it/s] 46%|####5     |79057/173481[18:10<21:02,74.81it/s] 53%|#####2    |91560/173481[21:00<18:17,74.64it/s] 53%|#####3    |92279/173481[21:11<18:07,74.64it/s] 60%|######    |104201/173481[24:00<15:57,72.36it/s] 61%|######    |105109/173481[24:11<15:44,72.36it/s] 69%|######8   |118868/173481[27:00<11:52,76.65it/s] 69%|######9   |119702/173481[27:11<11:41,76.65it/s] 77%|#######6  |133448/173481[30:00<08:28,78.76it/s] 77%|#######7  |134402/173481[30:11<08:16,78.76it/s] 84%|########4 |146199/173481[33:00<06:05,74.59it/s] 85%|########4 |146928/173481[33:11<05:55,74.59it/s] 92%|#########2|160080/173481[36:00<02:56,75.83it/s] 93%|#########2|160961/173481[36:11<02:45,75.83it/s]100%|#########9|173398/173481[39:00<00:01,74.89it/s]100%|##########|173481/173481[39:01<00:00,74.09it/s]
[32m[0323 03:32:34 @base.py:257][0m Epoch 34 (global_step 5898354) finished, time:2341.43 sec.
[32m[0323 03:32:34 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-5898354.
  0%|          |0/18822[00:00<?,?it/s] 55%|#####4    |10270/18822[03:00<02:29,57.05it/s] 58%|#####7    |10899/18822[03:10<02:18,57.05it/s]100%|##########|18822/18822[05:11<00:00,60.33it/s]
33
[32m[0323 03:37:46 @monitor.py:363][0m QueueInput/queue_size: 1.0082
[32m[0323 03:37:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.013
[32m[0323 03:37:46 @monitor.py:363][0m activation-summaries/output-rms: 0.035959
[32m[0323 03:37:46 @monitor.py:363][0m cross_entropy_loss: 2.4452
[32m[0323 03:37:46 @monitor.py:363][0m lr: 2.4414e-07
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62241
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6208
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64335
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59578
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56755
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50236
[32m[0323 03:37:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 03:37:46 @monitor.py:363][0m train-error-top1: 0.59923
[32m[0323 03:37:46 @monitor.py:363][0m val-error-top1: 0.63558
[32m[0323 03:37:46 @monitor.py:363][0m val-utt-error: 0.23074
[32m[0323 03:37:46 @monitor.py:363][0m validation_cost: 2.6335
[32m[0323 03:37:46 @monitor.py:363][0m wd_cost: 2.0254e-07
[32m[0323 03:37:46 @group.py:42][0m Callbacks took 312.360 sec in total. InferenceRunner: 311.999sec
[32m[0323 03:37:46 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14725/173481[03:00<32:20,81.80it/s]  9%|8         |15579/173481[03:10<32:10,81.80it/s] 17%|#7        |29584/173481[06:00<29:11,82.17it/s] 18%|#7        |30417/173481[06:10<29:01,82.17it/s] 25%|##5       |44208/173481[09:00<26:22,81.70it/s] 26%|##5       |44918/173481[09:10<26:13,81.70it/s] 34%|###3      |58601/173481[12:00<23:41,80.82it/s] 34%|###4      |59458/173481[12:10<23:30,80.82it/s] 42%|####1     |72331/173481[15:00<21:28,78.48it/s] 42%|####2     |73137/173481[15:10<21:18,78.48it/s] 49%|####9     |85788/173481[18:00<19:05,76.57it/s] 50%|####9     |86637/173481[18:10<18:54,76.57it/s] 57%|#####7    |99024/173481[21:00<16:32,75.02it/s] 58%|#####7    |99896/173481[21:11<16:20,75.02it/s] 65%|######5   |113210/173481[24:00<13:04,76.87it/s] 66%|######5   |114120/173481[24:11<12:52,76.87it/s] 73%|#######3  |126790/173481[27:00<10:13,76.15it/s] 74%|#######3  |127582/173481[27:11<10:02,76.15it/s] 81%|########  |140189/173481[30:00<07:22,75.28it/s] 81%|########1 |141084/173481[30:11<07:10,75.28it/s] 89%|########8 |154163/173481[33:00<04:12,76.44it/s] 89%|########9 |155048/173481[33:11<04:01,76.44it/s] 97%|#########6|167637/173481[36:00<01:17,75.64it/s] 97%|#########7|168434/173481[36:11<01:06,75.64it/s]100%|##########|173481/173481[37:18<00:00,77.49it/s]
[32m[0323 04:15:05 @base.py:257][0m Epoch 35 (global_step 6071835) finished, time:2238.63 sec.
[32m[0323 04:15:05 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-6071835.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.35it/s]
34
[32m[0323 04:17:02 @monitor.py:363][0m QueueInput/queue_size: 32.022
[32m[0323 04:17:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.927
[32m[0323 04:17:02 @monitor.py:363][0m activation-summaries/output-rms: 0.036211
[32m[0323 04:17:02 @monitor.py:363][0m cross_entropy_loss: 2.3976
[32m[0323 04:17:02 @monitor.py:363][0m lr: 2.4414e-07
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62231
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64342
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59584
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56761
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50243
[32m[0323 04:17:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 04:17:02 @monitor.py:363][0m train-error-top1: 0.60014
[32m[0323 04:17:02 @monitor.py:363][0m val-error-top1: 0.63835
[32m[0323 04:17:02 @monitor.py:363][0m val-utt-error: 0.23504
[32m[0323 04:17:02 @monitor.py:363][0m validation_cost: 2.6513
[32m[0323 04:17:02 @monitor.py:363][0m wd_cost: 2.0258e-07
[32m[0323 04:17:02 @group.py:42][0m Callbacks took 117.158 sec in total. InferenceRunner: 116.664sec
[32m[0323 04:17:02 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14208/173481[03:00<33:37,78.93it/s]  9%|8         |15002/173481[03:10<33:27,78.93it/s] 16%|#6        |28341/173481[06:00<30:43,78.72it/s] 17%|#6        |29168/173481[06:10<30:33,78.72it/s] 25%|##4       |42692/173481[09:00<27:30,79.22it/s] 25%|##5       |43532/173481[09:10<27:20,79.22it/s] 33%|###2      |57137/173481[12:00<24:19,79.73it/s] 33%|###3      |58000/173481[12:10<24:08,79.73it/s] 41%|####1     |71695/173481[15:00<21:07,80.30it/s] 42%|####1     |72567/173481[15:10<20:56,80.30it/s] 50%|####9     |86227/173481[18:00<18:03,80.51it/s] 50%|#####     |87114/173481[18:10<17:52,80.51it/s] 58%|#####8    |100801/173481[21:00<15:00,80.74it/s] 59%|#####8    |101683/173481[21:11<14:49,80.74it/s] 66%|######6   |115254/173481[24:00<12:03,80.51it/s] 67%|######6   |116155/173481[24:11<11:52,80.51it/s] 75%|#######4  |129737/173481[27:00<09:03,80.49it/s] 75%|#######5  |130655/173481[27:11<08:52,80.49it/s] 83%|########3 |144310/173481[30:00<06:01,80.72it/s] 84%|########3 |145277/173481[30:11<05:49,80.72it/s] 92%|#########1|159338/173481[33:00<02:52,82.08it/s] 92%|#########2|160317/173481[33:11<02:40,82.08it/s]100%|##########|173481/173481[35:57<00:00,80.40it/s]
[32m[0323 04:52:59 @base.py:257][0m Epoch 36 (global_step 6245316) finished, time:2157.68 sec.
[32m[0323 04:53:00 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:10<00:00,144.52it/s]
35
[32m[0323 04:55:10 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 04:55:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.5903
[32m[0323 04:55:10 @monitor.py:363][0m activation-summaries/output-rms: 0.038797
[32m[0323 04:55:10 @monitor.py:363][0m cross_entropy_loss: 2.1295
[32m[0323 04:55:10 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62217
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64346
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59587
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56764
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50246
[32m[0323 04:55:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 04:55:10 @monitor.py:363][0m train-error-top1: 0.53632
[32m[0323 04:55:10 @monitor.py:363][0m val-error-top1: 0.61664
[32m[0323 04:55:10 @monitor.py:363][0m val-utt-error: 0.19568
[32m[0323 04:55:10 @monitor.py:363][0m validation_cost: 2.5476
[32m[0323 04:55:10 @monitor.py:363][0m wd_cost: 4.0517e-08
[32m[0323 04:55:10 @group.py:42][0m Callbacks took 130.570 sec in total. InferenceRunner: 130.252sec
[32m[0323 04:55:10 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14068/173481[03:00<33:59,78.15it/s]  9%|8         |14865/173481[03:10<33:49,78.15it/s] 16%|#6        |28088/173481[06:00<31:03,78.02it/s] 17%|#6        |28887/173481[06:10<30:53,78.02it/s] 25%|##4       |42686/173481[09:00<27:24,79.53it/s] 25%|##5       |43555/173481[09:10<27:13,79.53it/s] 31%|###       |53120/173481[12:00<29:55,67.05it/s] 31%|###1      |53794/173481[12:10<29:45,67.05it/s] 37%|###6      |63845/173481[15:00<28:57,63.08it/s] 37%|###7      |64407/173481[15:10<28:49,63.08it/s] 43%|####2     |74582/173481[18:00<26:52,61.32it/s] 43%|####3     |75251/173481[18:10<26:41,61.32it/s] 49%|####9     |85434/173481[21:00<24:08,60.80it/s] 50%|####9     |86182/173481[21:11<23:55,60.80it/s] 55%|#####5    |96175/173481[24:00<21:23,60.22it/s] 56%|#####5    |96829/173481[24:11<21:12,60.22it/s] 62%|######1   |106919/173481[27:00<18:30,59.96it/s] 62%|######2   |107658/173481[27:11<18:17,59.96it/s] 68%|######7   |117460/173481[30:00<15:45,59.24it/s] 68%|######8   |118089/173481[30:11<15:35,59.24it/s] 73%|#######3  |127449/173481[33:00<13:23,57.31it/s] 74%|#######3  |128093/173481[33:11<13:12,57.31it/s] 79%|#######9  |137551/173481[36:00<10:33,56.71it/s] 80%|#######9  |138254/173481[36:11<10:21,56.71it/s] 85%|########5 |148251/173481[39:00<07:14,58.04it/s] 86%|########5 |148922/173481[39:12<07:03,58.04it/s] 91%|#########1|158605/173481[42:00<04:17,57.78it/s] 92%|#########1|159273/173481[42:12<04:05,57.78it/s] 97%|#########7|168806/173481[45:00<01:21,57.22it/s] 98%|#########7|169504/173481[45:12<01:09,57.22it/s]100%|##########|173481/173481[46:23<00:00,62.32it/s]
[32m[0323 05:41:34 @base.py:257][0m Epoch 37 (global_step 6418797) finished, time:2783.60 sec.
[32m[0323 05:41:34 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-6418797.
  0%|          |0/18822[00:00<?,?it/s] 85%|########4 |15978/18822[03:00<00:32,88.76it/s] 90%|########9 |16932/18822[03:10<00:21,88.76it/s]100%|##########|18822/18822[03:32<00:00,88.58it/s]
36
[32m[0323 05:45:06 @monitor.py:363][0m QueueInput/queue_size: 0.77993
[32m[0323 05:45:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.797
[32m[0323 05:45:06 @monitor.py:363][0m activation-summaries/output-rms: 0.035254
[32m[0323 05:45:06 @monitor.py:363][0m cross_entropy_loss: 2.4036
[32m[0323 05:45:06 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62195
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64349
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59589
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56766
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50248
[32m[0323 05:45:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 05:45:06 @monitor.py:363][0m train-error-top1: 0.58907
[32m[0323 05:45:06 @monitor.py:363][0m val-error-top1: 0.6318
[32m[0323 05:45:06 @monitor.py:363][0m val-utt-error: 0.22819
[32m[0323 05:45:06 @monitor.py:363][0m validation_cost: 2.6177
[32m[0323 05:45:06 @monitor.py:363][0m wd_cost: 4.0517e-08
[32m[0323 05:45:06 @group.py:42][0m Callbacks took 212.796 sec in total. InferenceRunner: 212.500sec
[32m[0323 05:45:06 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11639/173481[03:00<41:43,64.65it/s]  7%|7         |12213/173481[03:10<41:34,64.65it/s] 13%|#2        |22404/173481[06:00<40:31,62.13it/s] 13%|#3        |23219/173481[06:10<40:18,62.13it/s] 21%|##1       |37133/173481[09:00<32:10,70.63it/s] 22%|##1       |37965/173481[09:10<31:58,70.63it/s] 28%|##7       |47717/173481[12:00<32:39,64.17it/s] 28%|##7       |48290/173481[12:10<32:30,64.17it/s] 34%|###4      |59438/173481[15:00<29:24,64.64it/s] 35%|###4      |60039/173481[15:10<29:14,64.64it/s] 41%|####1     |71767/173481[18:00<25:29,66.51it/s] 42%|####1     |72638/173481[18:10<25:16,66.51it/s] 50%|####9     |85993/173481[21:00<20:11,72.23it/s] 50%|#####     |86935/173481[21:11<19:58,72.23it/s] 58%|#####8    |101090/173481[24:00<15:32,77.62it/s] 59%|#####8    |102042/173481[24:11<15:20,77.62it/s] 67%|######6   |115458/173481[27:00<12:17,78.70it/s] 67%|######7   |116334/173481[27:11<12:06,78.70it/s] 75%|#######4  |129403/173481[30:00<09:24,78.08it/s] 75%|#######5  |130268/173481[30:11<09:13,78.08it/s] 81%|########  |140447/173481[33:00<08:00,68.71it/s] 81%|########1 |141161/173481[33:11<07:50,68.71it/s] 87%|########7 |151252/173481[36:00<05:46,64.08it/s] 88%|########7 |151971/173481[36:11<05:35,64.08it/s] 94%|#########3|162494/173481[39:00<02:53,63.25it/s] 94%|#########4|163214/173481[39:11<02:42,63.25it/s]100%|##########|173481/173481[41:59<00:00,68.87it/s]
[32m[0323 06:27:06 @base.py:257][0m Epoch 38 (global_step 6592278) finished, time:2519.14 sec.
[32m[0323 06:27:06 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-6592278.
  0%|          |0/18822[00:00<?,?it/s] 82%|########2 |15524/18822[03:00<00:38,86.24it/s] 88%|########7 |16497/18822[03:10<00:26,86.24it/s]100%|##########|18822/18822[03:39<00:00,85.92it/s]
37
[32m[0323 06:30:45 @monitor.py:363][0m QueueInput/queue_size: 0.85923
[32m[0323 06:30:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.6815
[32m[0323 06:30:45 @monitor.py:363][0m activation-summaries/output-rms: 0.035464
[32m[0323 06:30:45 @monitor.py:363][0m cross_entropy_loss: 2.3989
[32m[0323 06:30:45 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62175
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64352
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.5959
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56768
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50249
[32m[0323 06:30:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 06:30:45 @monitor.py:363][0m train-error-top1: 0.5927
[32m[0323 06:30:45 @monitor.py:363][0m val-error-top1: 0.62851
[32m[0323 06:30:45 @monitor.py:363][0m val-utt-error: 0.20928
[32m[0323 06:30:45 @monitor.py:363][0m validation_cost: 2.5894
[32m[0323 06:30:45 @monitor.py:363][0m wd_cost: 4.0517e-08
[32m[0323 06:30:45 @group.py:42][0m Callbacks took 219.394 sec in total. InferenceRunner: 219.080sec
[32m[0323 06:30:45 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12583/173481[03:00<38:22,69.87it/s]  8%|7         |13064/173481[03:10<38:15,69.87it/s] 13%|#3        |22842/173481[06:00<39:59,62.78it/s] 13%|#3        |23391/173481[06:10<39:50,62.78it/s] 21%|##        |35918/173481[09:00<34:02,67.35it/s] 21%|##1       |36615/173481[09:10<33:52,67.35it/s] 27%|##6       |46773/173481[12:00<33:11,63.63it/s] 27%|##7       |47327/173481[12:10<33:02,63.63it/s] 35%|###4      |60320/173481[15:00<27:20,68.96it/s] 35%|###5      |61228/173481[15:10<27:07,68.96it/s] 43%|####2     |74418/173481[18:00<22:30,73.33it/s] 43%|####3     |75062/173481[18:10<22:22,73.33it/s] 49%|####9     |85769/173481[21:00<21:33,67.81it/s] 50%|####9     |86491/173481[21:11<21:22,67.81it/s] 56%|#####6    |97943/173481[24:00<18:35,67.71it/s] 57%|#####6    |98705/173481[24:11<18:24,67.71it/s] 64%|######4   |111204/173481[27:00<14:42,70.57it/s] 65%|######4   |112099/173481[27:11<14:29,70.57it/s] 73%|#######2  |125847/173481[30:00<10:30,75.58it/s] 73%|#######3  |126758/173481[30:11<10:18,75.58it/s] 80%|########  |139453/173481[33:00<07:30,75.58it/s] 81%|########  |140221/173481[33:11<07:20,75.58it/s] 88%|########8 |152923/173481[36:00<04:33,75.21it/s] 89%|########8 |153840/173481[36:11<04:21,75.21it/s] 95%|#########4|164504/173481[39:00<02:09,69.35it/s] 95%|#########5|165372/173481[39:11<01:56,69.35it/s]100%|##########|173481/173481[40:53<00:00,70.72it/s]
[32m[0323 07:11:38 @base.py:257][0m Epoch 39 (global_step 6765759) finished, time:2453.10 sec.
[32m[0323 07:11:39 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-6765759.
  0%|          |0/18822[00:00<?,?it/s] 69%|######9   |13036/18822[03:00<01:19,72.41it/s] 74%|#######3  |13884/18822[03:10<01:08,72.41it/s]100%|##########|18822/18822[04:07<00:00,76.19it/s]
38
[32m[0323 07:15:46 @monitor.py:363][0m QueueInput/queue_size: 49.996
[32m[0323 07:15:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.254
[32m[0323 07:15:46 @monitor.py:363][0m activation-summaries/output-rms: 0.036705
[32m[0323 07:15:46 @monitor.py:363][0m cross_entropy_loss: 2.1158
[32m[0323 07:15:46 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62156
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64352
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59591
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56769
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.5025
[32m[0323 07:15:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 07:15:46 @monitor.py:363][0m train-error-top1: 0.53838
[32m[0323 07:15:46 @monitor.py:363][0m val-error-top1: 0.59912
[32m[0323 07:15:46 @monitor.py:363][0m val-utt-error: 0.17171
[32m[0323 07:15:46 @monitor.py:363][0m validation_cost: 2.4429
[32m[0323 07:15:46 @monitor.py:363][0m wd_cost: 8.1031e-09
[32m[0323 07:15:46 @group.py:42][0m Callbacks took 247.545 sec in total. InferenceRunner: 247.046sec
[32m[0323 07:15:46 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10168/173481[03:00<48:11,56.49it/s]  6%|6         |11027/173481[03:10<47:56,56.49it/s] 15%|#4        |25362/173481[06:00<36:28,67.68it/s] 15%|#5        |26234/173481[06:10<36:15,67.68it/s] 23%|##2       |39833/173481[09:00<30:18,73.49it/s] 23%|##3       |40652/173481[09:10<30:07,73.49it/s] 31%|###1      |53892/173481[12:00<26:19,75.72it/s] 31%|###1      |54486/173481[12:10<26:11,75.72it/s] 39%|###9      |67951/173481[15:00<22:52,76.89it/s] 40%|###9      |68811/173481[15:10<22:41,76.89it/s] 48%|####7     |82543/173481[18:00<19:12,78.92it/s] 48%|####8     |83424/173481[18:10<19:01,78.92it/s] 56%|#####5    |97145/173481[21:00<15:54,80.01it/s] 57%|#####6    |98032/173481[21:11<15:43,80.01it/s] 64%|######4   |111621/173481[24:00<12:51,80.21it/s] 65%|######4   |112545/173481[24:11<12:39,80.21it/s] 73%|#######2  |126155/173481[27:00<09:48,80.48it/s] 73%|#######3  |127079/173481[27:11<09:36,80.48it/s] 81%|########1 |140666/173481[30:00<06:47,80.55it/s] 82%|########1 |141396/173481[30:11<06:38,80.55it/s] 88%|########7 |151998/173481[33:00<05:03,70.67it/s] 88%|########8 |152727/173481[33:11<04:53,70.67it/s] 94%|#########3|162850/173481[36:00<02:43,65.07it/s] 94%|#########4|163548/173481[36:11<02:32,65.07it/s]100%|##########|173481/173481[38:54<00:00,74.32it/s]
[32m[0323 07:54:40 @base.py:257][0m Epoch 40 (global_step 6939240) finished, time:2334.38 sec.
[32m[0323 07:54:41 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-6939240.
[32m[0323 07:54:42 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.72it/s]
39
[32m[0323 07:56:40 @monitor.py:363][0m QueueInput/queue_size: 0.95451
[32m[0323 07:56:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.3429
[32m[0323 07:56:40 @monitor.py:363][0m activation-summaries/output-rms: 0.035344
[32m[0323 07:56:40 @monitor.py:363][0m cross_entropy_loss: 2.3414
[32m[0323 07:56:40 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62138
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64353
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59592
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56769
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.5025
[32m[0323 07:56:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 07:56:40 @monitor.py:363][0m train-error-top1: 0.58141
[32m[0323 07:56:40 @monitor.py:363][0m val-error-top1: 0.61368
[32m[0323 07:56:40 @monitor.py:363][0m val-utt-error: 0.19413
[32m[0323 07:56:40 @monitor.py:363][0m validation_cost: 2.5105
[32m[0323 07:56:40 @monitor.py:363][0m wd_cost: 8.1028e-09
[32m[0323 07:56:40 @group.py:42][0m Callbacks took 120.450 sec in total. InferenceRunner: 118.601sec
[32m[0323 07:56:40 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12433/173481[03:00<38:51,69.07it/s]  8%|7         |13095/173481[03:10<38:42,69.07it/s] 14%|#3        |23791/173481[06:00<37:49,65.95it/s] 14%|#4        |24447/173481[06:10<37:39,65.95it/s] 20%|##        |34975/173481[09:00<36:04,63.98it/s] 21%|##        |35645/173481[09:10<35:54,63.98it/s] 27%|##6       |46021/173481[12:00<33:54,62.64it/s] 27%|##6       |46645/173481[12:10<33:44,62.64it/s] 33%|###2      |56641/173481[15:00<32:02,60.77it/s] 33%|###3      |57319/173481[15:10<31:51,60.77it/s] 39%|###9      |67711/173481[18:00<28:50,61.13it/s] 39%|###9      |68385/173481[18:10<28:39,61.13it/s] 45%|####5     |78366/173481[21:00<26:21,60.14it/s] 46%|####5     |79050/173481[21:11<26:10,60.14it/s] 51%|#####1    |88977/173481[24:00<23:39,59.54it/s] 52%|#####1    |89636/173481[24:11<23:28,59.54it/s] 57%|#####7    |99378/173481[27:00<21:03,58.65it/s] 58%|#####7    |100063/173481[27:11<20:51,58.65it/s] 63%|######3   |110041/173481[30:00<17:56,58.94it/s] 64%|######3   |110688/173481[30:11<17:45,58.94it/s] 69%|######9   |120425/173481[33:00<15:09,58.31it/s] 70%|######9   |121085/173481[33:11<14:58,58.31it/s] 76%|#######5  |131106/173481[36:00<12:00,58.82it/s] 76%|#######5  |131801/173481[36:11<11:48,58.82it/s] 82%|########1 |141796/173481[39:00<08:56,59.10it/s] 82%|########2 |142509/173481[39:12<08:44,59.10it/s] 88%|########7 |152371/173481[42:00<05:58,58.92it/s] 88%|########8 |153088/173481[42:12<05:46,58.92it/s] 94%|#########3|162890/173481[45:00<03:00,58.68it/s] 94%|#########4|163583/173481[45:12<02:48,58.68it/s]100%|#########9|173390/173481[48:00<00:01,58.50it/s]100%|##########|173481/173481[48:01<00:00,60.20it/s]
[32m[0323 08:44:42 @base.py:257][0m Epoch 41 (global_step 7112721) finished, time:2881.77 sec.
[32m[0323 08:44:43 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-7112721.
  0%|          |0/18822[00:00<?,?it/s] 96%|#########5|18020/18822[03:00<00:08,100.11it/s]100%|##########|18822/18822[03:07<00:00,100.54it/s]
40
[32m[0323 08:47:50 @monitor.py:363][0m QueueInput/queue_size: 0.84552
[32m[0323 08:47:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.1498
[32m[0323 08:47:50 @monitor.py:363][0m activation-summaries/output-rms: 0.035523
[32m[0323 08:47:50 @monitor.py:363][0m cross_entropy_loss: 2.2485
[32m[0323 08:47:50 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62117
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64354
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59592
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.5677
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50251
[32m[0323 08:47:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 08:47:50 @monitor.py:363][0m train-error-top1: 0.5659
[32m[0323 08:47:50 @monitor.py:363][0m val-error-top1: 0.59495
[32m[0323 08:47:50 @monitor.py:363][0m val-utt-error: 0.17565
[32m[0323 08:47:50 @monitor.py:363][0m validation_cost: 2.4194
[32m[0323 08:47:50 @monitor.py:363][0m wd_cost: 8.1024e-09
[32m[0323 08:47:50 @group.py:42][0m Callbacks took 187.580 sec in total. InferenceRunner: 187.219sec
[32m[0323 08:47:50 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13622/173481[03:00<35:12,75.67it/s]  8%|8         |14206/173481[03:10<35:04,75.67it/s] 14%|#3        |23655/173481[06:00<38:54,64.19it/s] 14%|#3        |24234/173481[06:10<38:45,64.19it/s] 21%|##1       |36681/173481[09:00<33:30,68.03it/s] 22%|##1       |37538/173481[09:10<33:18,68.03it/s] 28%|##8       |49284/173481[12:00<29:59,69.01it/s] 29%|##8       |50150/173481[12:10<29:47,69.01it/s] 35%|###5      |61081/173481[15:00<27:51,67.23it/s] 36%|###5      |61748/173481[15:10<27:41,67.23it/s] 42%|####1     |72025/173481[18:00<26:29,63.85it/s] 42%|####1     |72699/173481[18:10<26:18,63.85it/s] 48%|####7     |83045/173481[21:00<24:06,62.50it/s] 48%|####8     |83713/173481[21:11<23:56,62.50it/s] 54%|#####4    |94310/173481[24:00<21:05,62.54it/s] 55%|#####4    |94990/173481[24:11<20:55,62.54it/s] 61%|######    |105330/173481[27:00<18:21,61.87it/s] 61%|######1   |106009/173481[27:11<18:10,61.87it/s] 67%|######7   |116345/173481[30:00<15:28,61.53it/s] 67%|######7   |116989/173481[30:11<15:18,61.53it/s] 73%|#######3  |127231/173481[33:00<12:38,61.00it/s] 74%|#######3  |127924/173481[33:11<12:26,61.00it/s] 80%|#######9  |138062/173481[36:00<09:44,60.58it/s] 80%|#######9  |138752/173481[36:11<09:33,60.58it/s] 86%|########5 |149013/173481[39:00<06:43,60.71it/s] 86%|########6 |149753/173481[39:11<06:30,60.71it/s] 92%|#########2|160030/173481[42:00<03:40,60.95it/s] 93%|#########2|160757/173481[42:12<03:28,60.95it/s] 99%|#########8|171161/173481[45:00<00:37,61.39it/s] 99%|#########9|171942/173481[45:12<00:25,61.39it/s]100%|##########|173481/173481[45:36<00:00,63.39it/s]
[32m[0323 09:33:27 @base.py:257][0m Epoch 42 (global_step 7286202) finished, time:2736.93 sec.
[32m[0323 09:33:27 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-7286202.
[32m[0323 09:33:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 91%|#########1|17220/18822[03:00<00:16,95.67it/s] 97%|#########7|18314/18822[03:10<00:05,95.67it/s]100%|##########|18822/18822[03:14<00:00,96.99it/s]
41
[32m[0323 09:36:42 @monitor.py:363][0m QueueInput/queue_size: 0.80904
[32m[0323 09:36:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.1612
[32m[0323 09:36:42 @monitor.py:363][0m activation-summaries/output-rms: 0.036254
[32m[0323 09:36:42 @monitor.py:363][0m cross_entropy_loss: 2.3241
[32m[0323 09:36:42 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62111
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64354
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59592
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.5677
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50251
[32m[0323 09:36:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 09:36:42 @monitor.py:363][0m train-error-top1: 0.57645
[32m[0323 09:36:42 @monitor.py:363][0m val-error-top1: 0.59789
[32m[0323 09:36:42 @monitor.py:363][0m val-utt-error: 0.1741
[32m[0323 09:36:42 @monitor.py:363][0m validation_cost: 2.4289
[32m[0323 09:36:42 @monitor.py:363][0m wd_cost: 1.6204e-09
[32m[0323 09:36:42 @group.py:42][0m Callbacks took 195.000 sec in total. InferenceRunner: 194.064sec
[32m[0323 09:36:42 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12915/173481[03:00<37:17,71.75it/s]  8%|7         |13550/173481[03:10<37:09,71.75it/s] 14%|#3        |23518/173481[06:00<38:38,64.69it/s] 14%|#4        |24326/173481[06:10<38:25,64.69it/s] 22%|##1       |37449/173481[09:00<32:10,70.48it/s] 22%|##2       |38298/173481[09:10<31:58,70.48it/s] 28%|##8       |48734/173481[12:00<31:20,66.35it/s] 28%|##8       |49320/173481[12:10<31:11,66.35it/s] 35%|###4      |59994/173481[15:00<29:22,64.39it/s] 35%|###4      |60593/173481[15:10<29:13,64.39it/s] 42%|####2     |73143/173481[18:00<24:25,68.44it/s] 43%|####2     |74027/173481[18:10<24:13,68.44it/s] 50%|#####     |87607/173481[21:00<19:21,73.92it/s] 51%|#####1    |88540/173481[21:11<19:09,73.92it/s] 59%|#####9    |102769/173481[24:00<14:58,78.74it/s] 60%|#####9    |103683/173481[24:11<14:46,78.74it/s] 68%|######7   |117433/173481[27:00<11:39,80.08it/s] 68%|######8   |118351/173481[27:11<11:28,80.08it/s] 76%|#######6  |132076/173481[30:00<08:33,80.71it/s] 77%|#######6  |133015/173481[30:11<08:21,80.71it/s] 85%|########4 |146707/173481[33:00<05:30,80.99it/s] 85%|########5 |147654/173481[33:11<05:18,80.99it/s] 93%|#########3|161376/173481[36:00<02:29,81.24it/s] 94%|#########3|162330/173481[36:11<02:17,81.24it/s]100%|##########|173481/173481[38:29<00:00,75.13it/s]
[32m[0323 10:15:11 @base.py:257][0m Epoch 43 (global_step 7459683) finished, time:2309.05 sec.
[32m[0323 10:15:11 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_2_quant_ends_True/model-7459683.
  0%|          |0/18822[00:00<?,?it/s] 83%|########2 |15561/18822[03:00<00:37,86.45it/s] 86%|########5 |16175/18822[03:10<00:30,86.45it/s]100%|##########|18822/18822[03:53<00:00,80.52it/s]
42
[32m[0323 10:19:05 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 10:19:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 5.1845
[32m[0323 10:19:05 @monitor.py:363][0m activation-summaries/output-rms: 0.036559
[32m[0323 10:19:05 @monitor.py:363][0m cross_entropy_loss: 2.1919
[32m[0323 10:19:05 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62106
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6209
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64354
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064167
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59592
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.062211
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.5677
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.063753
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50251
[32m[0323 10:19:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.060878
[32m[0323 10:19:05 @monitor.py:363][0m train-error-top1: 0.54912
[32m[0323 10:19:05 @monitor.py:363][0m val-error-top1: 0.59535
[32m[0323 10:19:05 @monitor.py:363][0m val-utt-error: 0.1681
[32m[0323 10:19:05 @monitor.py:363][0m validation_cost: 2.422
[32m[0323 10:19:05 @monitor.py:363][0m wd_cost: 1.6204e-09
[32m[0323 10:19:05 @group.py:42][0m Callbacks took 234.179 sec in total. InferenceRunner: 233.764sec
[32m[0323 10:19:05 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14538/173481[03:00<32:47,80.76it/s]  9%|8         |15351/173481[03:10<32:37,80.76it/s] 17%|#6        |29068/173481[06:00<29:48,80.74it/s] 17%|#7        |29697/173481[06:10<29:40,80.74it/s] 23%|##2       |39283/173481[09:00<33:33,66.65it/s] 23%|##2       |39874/173481[09:10<33:24,66.65it/s] 31%|###1      |53835/173481[12:00<27:17,73.06it/s] 32%|###1      |54726/173481[12:10<27:05,73.06it/s] 39%|###9      |68329/173481[15:00<22:52,76.61it/s] 40%|###9      |69201/173481[15:10<22:41,76.61it/s] 48%|####7     |82796/173481[18:00<19:16,78.44it/s] 48%|####8     |83695/173481[18:11<19:04,78.44it/s]srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: *** STEP 82332.0 ON sls-tesla-1 CANCELLED AT 2018-03-23T10:39:48 ***
slurmstepd: *** JOB 82332 ON sls-tesla-1 CANCELLED AT 2018-03-23T10:39:48 ***
srun: got SIGCONT
srun: forcing job termination
