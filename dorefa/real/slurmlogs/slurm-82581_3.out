sls-sm-16 1
SLURM_JOBID=82584
SLURM_TASKID=3
[32m[0323 10:45:59 @logger.py:67][0m Existing log file 'train_log/lcn_w_8_a_32_quant_ends_False/log.log' backuped to 'train_log/lcn_w_8_a_32_quant_ends_False/log.log.0323-104559'
[32m[0323 10:45:59 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=8 --bita=32 --quant_ends=False
[32m[0323 10:46:18 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 10:46:18 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 10:46:18 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 10:46:18 @drf_run.py:166][0m Using host: sls-sm-16
[32m[0323 10:46:18 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 10:46:18 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 10:46:18 @drf_run.py:188][0m Using GPU: 1
[32m[0323 10:46:18 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 10:46:18 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 10:46:18 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 10:46:18 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:19 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:19 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 10:46:19 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:19 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0323 10:46:19 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 10:46:19 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0323 10:46:20 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0323 10:46:20 @base.py:196][0m Setup callbacks graph ...
[32m[0323 10:46:21 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:21 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:21 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:21 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0323 10:46:21 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 10:46:21 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0323 10:46:22 @base.py:212][0m Creating the session ...
2018-03-23 10:46:22.745806: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-23 10:46:26.180851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:03:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-03-23 10:46:26.180887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
[32m[0323 10:46:31 @base.py:220][0m Initializing the session ...
[32m[0323 10:46:31 @base.py:227][0m Graph Finalized.
[32m[0323 10:46:31 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 10:46:34 @monitor.py:251][0m Found existing JSON at train_log/lcn_w_8_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 10:46:34 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 10:46:34 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11796/173481[03:00<41:07,65.53it/s]  7%|7         |12480/173481[03:10<40:56,65.53it/s] 14%|#3        |23526/173481[06:00<38:14,65.34it/s] 14%|#3        |24156/173481[06:10<38:05,65.34it/s] 20%|#9        |34461/173481[09:00<36:48,62.96it/s] 20%|##        |35095/173481[09:10<36:38,62.96it/s] 26%|##6       |45382/173481[12:00<34:33,61.79it/s] 26%|##6       |45895/173481[12:10<34:24,61.79it/s] 32%|###2      |55851/173481[15:00<32:43,59.92it/s] 33%|###2      |56484/173481[15:10<32:32,59.92it/s] 38%|###7      |65179/173481[18:00<32:28,55.58it/s] 38%|###7      |65790/173481[18:10<32:17,55.58it/s] 43%|####3     |75216/173481[21:00<29:25,55.66it/s] 44%|####3     |75840/173481[21:11<29:14,55.66it/s] 49%|####9     |85451/173481[24:00<26:04,56.25it/s] 50%|####9     |86075/173481[24:11<25:53,56.25it/s] 55%|#####4    |94606/173481[27:00<24:36,53.42it/s] 55%|#####4    |95230/173481[27:11<24:24,53.42it/s] 61%|######    |105296/173481[30:00<20:12,56.24it/s] 61%|######1   |105995/173481[30:11<19:59,56.24it/s] 67%|######7   |116701/173481[33:00<15:52,59.59it/s] 68%|######7   |117419/173481[33:11<15:40,59.59it/s] 73%|#######3  |127247/173481[36:00<13:02,59.09it/s] 74%|#######3  |128118/173481[36:11<12:47,59.09it/s] 81%|########  |139771/173481[39:00<08:47,63.90it/s] 81%|########  |140486/173481[39:11<08:36,63.90it/s] 87%|########6 |150876/173481[42:00<06:00,62.78it/s] 87%|########7 |151590/173481[42:12<05:48,62.78it/s] 93%|#########2|161284/173481[45:00<03:22,60.20it/s] 93%|#########3|161885/173481[45:12<03:12,60.20it/s] 99%|#########8|171321/173481[48:00<00:37,57.89it/s] 99%|#########9|172241/173481[48:12<00:21,57.89it/s]100%|##########|173481/173481[48:29<00:00,59.63it/s]
[32m[0323 11:35:04 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2909.36 sec.
[32m[0323 11:35:04 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:22<00:00,131.85it/s]
0
[32m[0323 11:37:27 @monitor.py:363][0m QueueInput/queue_size: 1.0433
[32m[0323 11:37:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9843
[32m[0323 11:37:27 @monitor.py:363][0m activation-summaries/output-rms: 0.030606
[32m[0323 11:37:27 @monitor.py:363][0m cross_entropy_loss: 2.498
[32m[0323 11:37:27 @monitor.py:363][0m lr: 0.001
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.19039
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 3.8686e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.15282
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 4.1877e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.1709
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 2.1106e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.15069
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 3.2956e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.17976
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 3.3729e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14913
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 2.8403e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.17944
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 3.2707e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14762
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 1.9336e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.18378
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.0737e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.15328
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6851e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.1368
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.68856
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14471
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12276
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11705
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 11:37:27 @monitor.py:363][0m train-error-top1: 0.62603
[32m[0323 11:37:27 @monitor.py:363][0m val-error-top1: 0.67192
[32m[0323 11:37:27 @monitor.py:363][0m val-utt-error: 0.34476
[32m[0323 11:37:27 @monitor.py:363][0m validation_cost: 2.7541
[32m[0323 11:37:27 @monitor.py:363][0m wd_cost: 0.51408
[32m[0323 11:37:27 @group.py:42][0m Callbacks took 143.206 sec in total. InferenceRunner: 142.776sec
[32m[0323 11:37:27 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14181/173481[03:00<33:42,78.78it/s]  9%|8         |14983/173481[03:10<33:31,78.78it/s] 16%|#5        |27390/173481[06:00<32:04,75.92it/s] 16%|#5        |27497/173481[06:10<32:02,75.92it/s] 22%|##1       |38161/173481[09:00<33:41,66.92it/s] 22%|##2       |38778/173481[09:10<33:32,66.92it/s] 28%|##8       |49104/173481[12:00<32:32,63.71it/s] 29%|##8       |49728/173481[12:10<32:22,63.71it/s] 35%|###4      |60481/173481[15:00<29:40,63.46it/s] 35%|###5      |61137/173481[15:10<29:30,63.46it/s] 41%|####1     |71373/173481[18:00<27:28,61.95it/s] 42%|####1     |72040/173481[18:10<27:17,61.95it/s] 48%|####7     |82500/173481[21:00<24:30,61.88it/s] 48%|####7     |83179/173481[21:11<24:19,61.88it/s] 54%|#####4    |93754/173481[24:00<21:21,62.20it/s] 54%|#####4    |94451/173481[24:11<21:10,62.20it/s] 60%|######    |104640/173481[27:00<18:42,61.32it/s] 61%|######    |105505/173481[27:11<18:28,61.32it/s] 67%|######6   |116086/173481[30:00<15:19,62.44it/s] 67%|######7   |116774/173481[30:11<15:08,62.44it/s] 73%|#######3  |126941/173481[33:00<12:38,61.35it/s] 74%|#######3  |127639/173481[33:11<12:27,61.35it/s] 79%|#######8  |136464/173481[36:00<10:51,56.82it/s] 79%|#######9  |137391/173481[36:11<10:35,56.82it/s] 85%|########5 |147803/173481[39:00<07:09,59.75it/s] 86%|########5 |148488/173481[39:12<06:58,59.75it/s] 91%|#########1|158614/173481[42:00<04:08,59.90it/s] 92%|#########1|159358/173481[42:12<03:55,59.90it/s] 98%|#########7|169889/173481[45:00<00:58,61.24it/s] 98%|#########8|170659/173481[45:12<00:46,61.24it/s]100%|##########|173481/173481[46:06<00:00,62.70it/s]
[32m[0323 12:23:34 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2766.97 sec.
[32m[0323 12:23:35 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-346962.
[32m[0323 12:23:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:22<00:00,132.12it/s]
1
[32m[0323 12:25:57 @monitor.py:363][0m QueueInput/queue_size: 2.9277
[32m[0323 12:25:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.1342
[32m[0323 12:25:57 @monitor.py:363][0m activation-summaries/output-rms: 0.029811
[32m[0323 12:25:57 @monitor.py:363][0m cross_entropy_loss: 2.4755
[32m[0323 12:25:57 @monitor.py:363][0m lr: 0.001
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.18971
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 4.5248e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.15457
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.7645e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.17282
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 3.1574e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.15066
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.4499e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.17946
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.313e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14766
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.4181e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.18082
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4492e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14881
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.2247e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.18315
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.7097e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.15239
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.9741e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13802
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.97891
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14504
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.1226
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11712
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 12:25:57 @monitor.py:363][0m train-error-top1: 0.62345
[32m[0323 12:25:57 @monitor.py:363][0m val-error-top1: 0.66926
[32m[0323 12:25:57 @monitor.py:363][0m val-utt-error: 0.33482
[32m[0323 12:25:57 @monitor.py:363][0m validation_cost: 2.7346
[32m[0323 12:25:57 @monitor.py:363][0m wd_cost: 0.51688
[32m[0323 12:25:57 @group.py:42][0m Callbacks took 143.501 sec in total. InferenceRunner: 142.475sec
[32m[0323 12:25:57 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15203/173481[03:00<31:14,84.46it/s]  9%|9         |16044/173481[03:10<31:04,84.46it/s] 17%|#6        |29322/173481[06:00<29:32,81.33it/s] 17%|#7        |29919/173481[06:10<29:25,81.33it/s] 23%|##2       |39521/173481[09:00<33:25,66.79it/s] 23%|##3       |40140/173481[09:10<33:16,66.79it/s] 29%|##8       |49869/173481[12:00<33:20,61.79it/s] 29%|##9       |50497/173481[12:10<33:10,61.79it/s] 35%|###4      |60356/173481[15:00<31:26,59.97it/s] 35%|###5      |60988/173481[15:10<31:15,59.97it/s] 41%|####1     |71532/173481[18:00<27:50,61.01it/s] 42%|####1     |72223/173481[18:11<27:39,61.01it/s] 48%|####7     |83146/173481[21:00<24:00,62.72it/s] 48%|####8     |83844/173481[21:11<23:49,62.72it/s] 55%|#####4    |94679/173481[24:00<20:43,63.38it/s] 55%|#####4    |95395/173481[24:11<20:32,63.38it/s] 61%|######    |105486/173481[27:00<18:22,61.66it/s] 61%|######1   |106402/173481[27:11<18:07,61.66it/s] 68%|######7   |117560/173481[30:00<14:30,64.26it/s] 68%|######8   |118306/173481[30:11<14:18,64.26it/s] 74%|#######4  |128968/173481[33:00<11:37,63.81it/s] 75%|#######4  |129743/173481[33:11<11:25,63.81it/s] 81%|########1 |140857/173481[36:00<08:22,64.91it/s] 81%|########1 |141323/173481[36:11<08:15,64.91it/s] 88%|########8 |152750/173481[39:00<05:16,65.48it/s] 89%|########8 |153568/173481[39:12<05:04,65.48it/s] 95%|#########5|164811/173481[42:00<02:10,66.24it/s] 95%|#########5|165610/173481[42:12<01:58,66.24it/s]100%|##########|173481/173481[44:12<00:00,65.41it/s]
[32m[0323 13:10:10 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2652.10 sec.
[32m[0323 13:10:10 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-520443.
[32m[0323 13:10:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:41<00:00,116.63it/s]
2
[32m[0323 13:12:51 @monitor.py:363][0m QueueInput/queue_size: 0.92781
[32m[0323 13:12:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.9868
[32m[0323 13:12:51 @monitor.py:363][0m activation-summaries/output-rms: 0.035553
[32m[0323 13:12:51 @monitor.py:363][0m cross_entropy_loss: 2.0419
[32m[0323 13:12:51 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.25814
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.5256e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.20543
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.9418e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.23294
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0c/b-rms: 3.7864e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.19851
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.8357e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.2465
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.5693e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.19692
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.0982e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.24495
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.5217e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.19898
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.6539e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.24859
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.8969e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.20108
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.4645e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.1868
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1321
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.19006
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.1694
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16458
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 13:12:51 @monitor.py:363][0m train-error-top1: 0.52462
[32m[0323 13:12:51 @monitor.py:363][0m val-error-top1: 0.56141
[32m[0323 13:12:51 @monitor.py:363][0m val-utt-error: 0.20264
[32m[0323 13:12:51 @monitor.py:363][0m validation_cost: 2.1922
[32m[0323 13:12:51 @monitor.py:363][0m wd_cost: 0.19008
[32m[0323 13:12:51 @group.py:42][0m Callbacks took 161.884 sec in total. InferenceRunner: 161.402sec
[32m[0323 13:12:51 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14500/173481[03:00<32:53,80.55it/s]  9%|8         |15296/173481[03:10<32:43,80.55it/s] 16%|#5        |27427/173481[06:00<32:03,75.93it/s] 16%|#6        |28087/173481[06:10<31:54,75.93it/s] 23%|##2       |39063/173481[09:00<32:06,69.79it/s] 23%|##2       |39172/173481[09:10<32:04,69.79it/s] 30%|##9       |51375/173481[12:00<29:27,69.09it/s] 30%|##9       |52035/173481[12:10<29:17,69.09it/s] 36%|###6      |63276/173481[15:00<27:11,67.57it/s] 37%|###6      |64004/173481[15:10<27:00,67.57it/s] 44%|####3     |75508/173481[18:00<24:05,67.76it/s] 44%|####3     |76216/173481[18:10<23:55,67.76it/s] 50%|#####     |87368/173481[21:00<21:28,66.81it/s] 51%|#####     |88072/173481[21:11<21:18,66.81it/s] 57%|#####7    |99285/173481[24:00<18:35,66.51it/s] 58%|#####7    |99996/173481[24:11<18:24,66.51it/s] 64%|######4   |111397/173481[27:00<15:28,66.89it/s] 65%|######4   |112149/173481[27:11<15:16,66.89it/s] 71%|#######   |122768/173481[30:00<13:00,64.98it/s] 71%|#######1  |123585/173481[30:11<12:47,64.98it/s] 78%|#######7  |135194/173481[33:00<09:31,66.94it/s] 78%|#######8  |135982/173481[33:11<09:20,66.94it/s] 85%|########4 |147140/173481[36:00<06:35,66.65it/s] 85%|########5 |147897/173481[36:11<06:23,66.65it/s] 91%|######### |157604/173481[39:00<04:15,62.10it/s] 91%|#########1|158502/173481[39:12<04:01,62.10it/s] 98%|#########7|169740/173481[42:00<00:57,64.65it/s] 98%|#########8|170442/173481[42:12<00:47,64.65it/s]100%|##########|173481/173481[43:01<00:00,67.21it/s]
[32m[0323 13:55:53 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2581.32 sec.
[32m[0323 13:55:53 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-693924.
[32m[0323 13:55:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,139.47it/s]
3
[32m[0323 13:58:08 @monitor.py:363][0m QueueInput/queue_size: 0.85176
[32m[0323 13:58:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.4482
[32m[0323 13:58:08 @monitor.py:363][0m activation-summaries/output-rms: 0.035745
[32m[0323 13:58:08 @monitor.py:363][0m cross_entropy_loss: 2.001
[32m[0323 13:58:08 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.28092
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.6663e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.22362
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.9215e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.25411
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.1322e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.21679
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.2807e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.26909
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.4402e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.21804
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.2386e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.27039
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 7.2502e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21788
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.6212e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.27386
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.8176e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.22338
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.5174e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21766
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2074
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20855
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19363
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083102
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18474
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 13:58:08 @monitor.py:363][0m train-error-top1: 0.52438
[32m[0323 13:58:08 @monitor.py:363][0m val-error-top1: 0.54361
[32m[0323 13:58:08 @monitor.py:363][0m val-utt-error: 0.18728
[32m[0323 13:58:08 @monitor.py:363][0m validation_cost: 2.1134
[32m[0323 13:58:08 @monitor.py:363][0m wd_cost: 0.24168
[32m[0323 13:58:08 @group.py:42][0m Callbacks took 135.552 sec in total. InferenceRunner: 134.976sec
[32m[0323 13:58:08 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13942/173481[03:00<34:20,77.44it/s]  8%|8         |14581/173481[03:10<34:11,77.44it/s] 15%|#4        |25428/173481[06:00<35:16,69.97it/s] 15%|#5        |26086/173481[06:10<35:06,69.97it/s] 22%|##1       |37370/173481[09:00<33:18,68.11it/s] 22%|##1       |38016/173481[09:10<33:08,68.11it/s] 28%|##8       |49132/173481[12:00<31:04,66.70it/s] 29%|##8       |49822/173481[12:10<30:54,66.70it/s] 35%|###5      |60894/173481[15:00<28:25,66.01it/s] 36%|###5      |61653/173481[15:10<28:14,66.01it/s] 42%|####1     |72088/173481[18:00<26:23,64.04it/s] 42%|####1     |72807/173481[18:10<26:11,64.04it/s] 48%|####8     |83883/173481[21:00<23:03,64.77it/s] 49%|####8     |84556/173481[21:11<22:52,64.77it/s] 55%|#####4    |94875/173481[24:00<20:50,62.87it/s] 55%|#####5    |95726/173481[24:11<20:36,62.87it/s] 62%|######1   |107013/173481[27:00<17:01,65.07it/s] 62%|######2   |107736/173481[27:11<16:50,65.07it/s] 68%|######8   |118622/173481[30:00<14:06,64.77it/s] 69%|######8   |119305/173481[30:11<13:56,64.77it/s] 74%|#######4  |129207/173481[33:00<11:58,61.62it/s] 75%|#######4  |129857/173481[33:11<11:47,61.62it/s] 82%|########1 |141802/173481[36:00<08:03,65.52it/s] 82%|########2 |142551/173481[36:11<07:52,65.52it/s] 89%|########8 |153650/173481[39:00<05:01,65.67it/s] 89%|########8 |154388/173481[39:12<04:50,65.67it/s] 95%|#########5|164987/173481[42:00<02:12,64.30it/s] 96%|#########5|165720/173481[42:12<02:00,64.30it/s]100%|##########|173481/173481[44:21<00:00,65.17it/s]
[32m[0323 14:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2661.90 sec.
[32m[0323 14:42:30 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-867405.
[32m[0323 14:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:16<00:00,137.47it/s]
4
[32m[0323 14:44:48 @monitor.py:363][0m QueueInput/queue_size: 0.90221
[32m[0323 14:44:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.381
[32m[0323 14:44:48 @monitor.py:363][0m activation-summaries/output-rms: 0.03764
[32m[0323 14:44:48 @monitor.py:363][0m cross_entropy_loss: 1.9618
[32m[0323 14:44:48 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.28153
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.3361e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.22446
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.1496e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.25408
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.3754e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.21801
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.1e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.26937
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.5484e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.21868
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.066e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.26971
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 7.6137e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21792
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.6333e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.27352
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.7688e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.22369
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.8076e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.22117
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2677
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20942
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19598
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083102
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18659
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 14:44:48 @monitor.py:363][0m train-error-top1: 0.51068
[32m[0323 14:44:48 @monitor.py:363][0m val-error-top1: 0.54243
[32m[0323 14:44:48 @monitor.py:363][0m val-utt-error: 0.18962
[32m[0323 14:44:48 @monitor.py:363][0m validation_cost: 2.1099
[32m[0323 14:44:48 @monitor.py:363][0m wd_cost: 0.24633
[32m[0323 14:44:48 @group.py:42][0m Callbacks took 137.500 sec in total. InferenceRunner: 136.937sec
[32m[0323 14:44:48 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14441/173481[03:00<33:02,80.23it/s]  9%|8         |15239/173481[03:10<32:52,80.23it/s] 15%|#4        |25986/173481[06:00<34:29,71.28it/s] 15%|#5        |26780/173481[06:10<34:17,71.28it/s] 20%|#9        |33932/173481[09:00<42:39,54.52it/s] 20%|##        |34750/173481[09:10<42:24,54.52it/s] 28%|##7       |48049/173481[12:00<32:29,64.33it/s] 28%|##8       |48815/173481[12:10<32:18,64.33it/s] 36%|###5      |62106/173481[15:00<26:18,70.54it/s] 36%|###6      |62966/173481[15:10<26:06,70.54it/s] 43%|####3     |75431/173481[18:00<22:37,72.22it/s] 44%|####3     |76096/173481[18:10<22:28,72.22it/s] 52%|#####1    |89980/173481[21:00<18:14,76.28it/s] 52%|#####2    |90884/173481[21:11<18:02,76.28it/s] 60%|######    |104704/173481[24:00<14:31,78.94it/s] 61%|######    |105616/173481[24:11<14:19,78.94it/s] 67%|######6   |116186/173481[27:00<13:32,70.56it/s] 67%|######7   |116860/173481[27:11<13:22,70.56it/s] 73%|#######3  |127026/173481[30:00<11:54,64.98it/s] 74%|#######3  |127723/173481[30:11<11:44,64.98it/s] 80%|#######9  |137981/173481[33:00<09:24,62.85it/s] 80%|#######9  |138690/173481[33:11<09:13,62.85it/s] 86%|########5 |148971/173481[36:00<06:35,61.94it/s] 86%|########6 |149667/173481[36:11<06:24,61.94it/s] 92%|#########2|159608/173481[39:00<03:49,60.48it/s] 92%|#########2|160340/173481[39:12<03:37,60.48it/s] 98%|#########8|170576/173481[42:00<00:47,60.70it/s] 99%|#########8|171287/173481[42:12<00:36,60.70it/s]100%|##########|173481/173481[42:48<00:00,67.54it/s]
[32m[0323 15:27:36 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:2568.73 sec.
[32m[0323 15:27:37 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-1040886.
[32m[0323 15:27:42 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:11<00:00,143.51it/s]
5
[32m[0323 15:29:54 @monitor.py:363][0m QueueInput/queue_size: 0.82234
[32m[0323 15:29:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.459
[32m[0323 15:29:54 @monitor.py:363][0m activation-summaries/output-rms: 0.038925
[32m[0323 15:29:54 @monitor.py:363][0m cross_entropy_loss: 1.7947
[32m[0323 15:29:54 @monitor.py:363][0m lr: 0.00025
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.32278
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.4351e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.25082
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.4241e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.29426
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.538e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.24417
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3357e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3168
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8994e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.24543
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.0082e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.31547
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9288e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.24504
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.2718e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.31699
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.4212e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.25003
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 5.0742e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26238
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3084
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.23373
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2203
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083102
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.21133
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 15:29:54 @monitor.py:363][0m train-error-top1: 0.47473
[32m[0323 15:29:54 @monitor.py:363][0m val-error-top1: 0.49441
[32m[0323 15:29:54 @monitor.py:363][0m val-utt-error: 0.14132
[32m[0323 15:29:54 @monitor.py:363][0m validation_cost: 1.8867
[32m[0323 15:29:54 @monitor.py:363][0m wd_cost: 0.064352
[32m[0323 15:29:54 @group.py:42][0m Callbacks took 137.214 sec in total. InferenceRunner: 131.172sec
[32m[0323 15:29:54 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13205/173481[03:00<36:24,73.36it/s]  8%|8         |14024/173481[03:10<36:13,73.36it/s] 14%|#4        |24576/173481[06:00<36:33,67.88it/s] 15%|#4        |25182/173481[06:10<36:24,67.88it/s] 20%|##        |34951/173481[09:00<37:02,62.34it/s] 20%|##        |35519/173481[09:10<36:53,62.34it/s] 26%|##5       |44945/173481[12:00<36:28,58.73it/s] 26%|##6       |45563/173481[12:10<36:18,58.73it/s] 32%|###2      |55805/173481[15:00<32:57,59.52it/s] 33%|###2      |56514/173481[15:10<32:45,59.52it/s] 38%|###8      |66739/173481[18:00<29:35,60.12it/s] 39%|###8      |67402/173481[18:10<29:24,60.12it/s] 44%|####4     |77150/173481[21:00<27:13,58.96it/s] 45%|####4     |78047/173481[21:11<26:58,58.96it/s] 51%|#####1    |89255/173481[24:00<22:20,62.83it/s] 52%|#####1    |89954/173481[24:11<22:09,62.83it/s] 58%|#####7    |100475/173481[27:00<19:26,62.58it/s] 58%|#####8    |101205/173481[27:11<19:15,62.58it/s] 64%|######4   |111530/173481[30:00<16:40,61.92it/s] 64%|######4   |111644/173481[30:11<16:38,61.92it/s] 71%|#######   |122545/173481[33:00<13:47,61.55it/s] 71%|#######1  |123238/173481[33:11<13:36,61.55it/s] 77%|#######6  |133528/173481[36:00<10:51,61.28it/s] 77%|#######7  |134228/173481[36:11<10:40,61.28it/s] 84%|########3 |145504/173481[39:00<07:18,63.80it/s] 84%|########4 |146374/173481[39:12<07:04,63.80it/s] 91%|######### |157595/173481[42:00<04:02,65.43it/s] 91%|#########1|158354/173481[42:12<03:51,65.43it/s] 99%|#########9|171809/173481[45:00<00:23,71.57it/s]100%|#########9|172754/173481[45:12<00:10,71.57it/s]100%|##########|173481/173481[45:21<00:00,63.74it/s]
[32m[0323 16:15:15 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:2721.56 sec.
[32m[0323 16:15:16 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-1214367.
[32m[0323 16:15:16 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.05it/s]
6
[32m[0323 16:17:19 @monitor.py:363][0m QueueInput/queue_size: 5.912
[32m[0323 16:17:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 17.105
[32m[0323 16:17:19 @monitor.py:363][0m activation-summaries/output-rms: 0.039679
[32m[0323 16:17:19 @monitor.py:363][0m cross_entropy_loss: 1.7622
[32m[0323 16:17:19 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.37104
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5335e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.28754
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.4529e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.33871
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.4486e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.28197
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.2966e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3627
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7944e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.28349
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.0598e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.36188
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.8321e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.2815
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4701e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.36541
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.2446e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.28698
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9094e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31745
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3319
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26156
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25363
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.24496
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 16:17:19 @monitor.py:363][0m train-error-top1: 0.46693
[32m[0323 16:17:19 @monitor.py:363][0m val-error-top1: 0.48525
[32m[0323 16:17:19 @monitor.py:363][0m val-utt-error: 0.13521
[32m[0323 16:17:19 @monitor.py:363][0m validation_cost: 1.8487
[32m[0323 16:17:19 @monitor.py:363][0m wd_cost: 0.086946
[32m[0323 16:17:19 @group.py:42][0m Callbacks took 123.692 sec in total. InferenceRunner: 122.999sec
[32m[0323 16:17:19 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12948/173481[03:00<37:11,71.93it/s]  8%|7         |13734/173481[03:10<37:00,71.93it/s] 16%|#5        |27020/173481[06:00<32:34,74.92it/s] 16%|#6        |27839/173481[06:10<32:23,74.92it/s] 24%|##3       |41034/173481[09:00<28:54,76.36it/s] 24%|##4       |41853/173481[09:10<28:43,76.36it/s] 30%|##9       |51277/173481[12:00<31:13,65.21it/s] 30%|###       |52101/173481[12:10<31:01,65.21it/s] 36%|###6      |62669/173481[15:00<28:45,64.23it/s] 36%|###6      |63308/173481[15:10<28:35,64.23it/s] 43%|####2     |74109/173481[18:00<25:55,63.89it/s] 43%|####3     |74794/173481[18:10<25:44,63.89it/s] 49%|####9     |85407/173481[21:00<23:10,63.32it/s] 49%|####9     |85828/173481[21:11<23:04,63.32it/s] 56%|#####5    |96579/173481[24:00<20:26,62.68it/s] 56%|#####6    |97232/173481[24:11<20:16,62.68it/s] 62%|######2   |108178/173481[27:00<17:07,63.54it/s] 63%|######2   |108918/173481[27:11<16:56,63.54it/s] 69%|######9   |119733/173481[30:00<14:01,63.87it/s] 69%|######9   |120459/173481[30:11<13:50,63.87it/s] 75%|#######5  |130934/173481[33:00<11:14,63.03it/s] 76%|#######5  |131684/173481[33:11<11:03,63.03it/s] 82%|########2 |142724/173481[36:00<07:58,64.24it/s] 83%|########2 |143483/173481[36:11<07:46,64.24it/s] 89%|########9 |154530/173481[39:00<04:51,64.91it/s] 89%|########9 |155263/173481[39:12<04:40,64.91it/s] 96%|#########5|165817/173481[42:00<02:00,63.79it/s] 96%|#########6|166609/173481[42:12<01:47,63.79it/s]100%|##########|173481/173481[43:58<00:00,65.74it/s]
[32m[0323 17:01:18 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:2638.92 sec.
[32m[0323 17:01:18 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-1387848.
[32m[0323 17:01:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.29it/s]
7
[32m[0323 17:03:20 @monitor.py:363][0m QueueInput/queue_size: 1.3222
[32m[0323 17:03:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.652
[32m[0323 17:03:20 @monitor.py:363][0m activation-summaries/output-rms: 0.038702
[32m[0323 17:03:20 @monitor.py:363][0m cross_entropy_loss: 1.7269
[32m[0323 17:03:20 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.39055
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.482e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.30379
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2912e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.35577
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.3951e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.29664
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.424e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.37996
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7753e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.29866
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.827e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.38005
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.8575e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.29626
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3564e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.38486
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1989e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.30126
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.8308e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.35304
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3555
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27085
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26751
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25841
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0323 17:03:20 @monitor.py:363][0m train-error-top1: 0.4658
[32m[0323 17:03:20 @monitor.py:363][0m val-error-top1: 0.48165
[32m[0323 17:03:20 @monitor.py:363][0m val-utt-error: 0.13118
[32m[0323 17:03:20 @monitor.py:363][0m validation_cost: 1.8314
[32m[0323 17:03:20 @monitor.py:363][0m wd_cost: 0.099227
[32m[0323 17:03:20 @group.py:42][0m Callbacks took 122.559 sec in total. InferenceRunner: 122.007sec
[32m[0323 17:03:20 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13448/173481[03:00<35:42,74.70it/s]  8%|8         |14077/173481[03:10<35:34,74.70it/s] 14%|#4        |24288/173481[06:00<37:17,66.68it/s] 14%|#4        |24898/173481[06:10<37:08,66.68it/s] 21%|##        |35702/173481[09:00<35:19,65.00it/s] 21%|##        |36373/173481[09:10<35:09,65.00it/s] 27%|##7       |47420/173481[12:00<32:17,65.05it/s] 28%|##7       |48099/173481[12:10<32:07,65.05it/s] 34%|###3      |58710/173481[15:00<29:57,63.86it/s] 34%|###4      |59391/173481[15:10<29:46,63.86it/s] 41%|####      |70402/173481[18:00<26:40,64.40it/s] 41%|####      |71103/173481[18:10<26:29,64.40it/s] 47%|####7     |81955/173481[21:00<23:43,64.29it/s] 48%|####7     |82647/173481[21:11<23:32,64.29it/s] 53%|#####3    |92125/173481[24:00<22:32,60.14it/s] 54%|#####3    |92885/173481[24:11<22:20,60.14it/s] 60%|######    |104260/173481[27:00<18:08,63.57it/s] 61%|######    |105025/173481[27:11<17:56,63.57it/s] 67%|######6   |116053/173481[30:00<14:49,64.53it/s] 67%|######7   |116742/173481[30:11<14:39,64.53it/s] 73%|#######3  |127414/173481[33:00<12:01,63.81it/s] 74%|#######3  |127702/173481[33:11<11:57,63.81it/s] 80%|#######9  |138563/173481[36:00<09:15,62.86it/s] 80%|########  |139387/173481[36:11<09:02,62.86it/s] 87%|########6 |150202/173481[39:00<06:05,63.75it/s] 87%|########7 |151025/173481[39:12<05:52,63.75it/s] 93%|#########3|162152/173481[42:00<02:54,65.04it/s] 94%|#########3|162839/173481[42:12<02:43,65.04it/s] 99%|#########9|172197/173481[45:00<00:21,60.07it/s]100%|#########9|172927/173481[45:12<00:09,60.07it/s]100%|##########|173481/173481[45:22<00:00,63.73it/s]
[32m[0323 17:48:43 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:2722.11 sec.
[32m[0323 17:48:43 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-1561329.
[32m[0323 17:48:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.18it/s]
8
[32m[0323 17:50:47 @monitor.py:363][0m QueueInput/queue_size: 0.72757
[32m[0323 17:50:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 24.085
[32m[0323 17:50:47 @monitor.py:363][0m activation-summaries/output-rms: 0.039353
[32m[0323 17:50:47 @monitor.py:363][0m cross_entropy_loss: 1.6954
[32m[0323 17:50:47 @monitor.py:363][0m lr: 0.000125
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40957
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5062e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.31398
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2681e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.37599
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.4295e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.30785
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.4651e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.40006
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.9114e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.30879
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7874e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.39953
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.8173e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.30702
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4314e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.40618
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1681e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.31184
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7931e-06
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.39055
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3689
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.28126
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27712
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26761
[32m[0323 17:50:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0323 17:50:47 @monitor.py:363][0m train-error-top1: 0.45302
[32m[0323 17:50:47 @monitor.py:363][0m val-error-top1: 0.46077
[32m[0323 17:50:47 @monitor.py:363][0m val-utt-error: 0.11811
[32m[0323 17:50:47 @monitor.py:363][0m validation_cost: 1.7422
[32m[0323 17:50:47 @monitor.py:363][0m wd_cost: 0.022345
[32m[0323 17:50:47 @group.py:42][0m Callbacks took 124.855 sec in total. InferenceRunner: 124.516sec
[32m[0323 17:50:47 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13794/173481[03:00<34:43,76.63it/s]  8%|8         |14385/173481[03:10<34:36,76.63it/s] 14%|#3        |24192/173481[06:00<37:46,65.87it/s] 14%|#4        |24974/173481[06:10<37:34,65.87it/s] 21%|##        |36000/173481[09:00<34:51,65.74it/s] 21%|##1       |36622/173481[09:10<34:41,65.74it/s] 27%|##7       |47282/173481[12:00<32:46,64.17it/s] 28%|##7       |47964/173481[12:10<32:36,64.17it/s] 34%|###3      |58172/173481[15:00<30:53,62.21it/s] 34%|###3      |58281/173481[15:10<30:51,62.21it/s] 37%|###7      |64220/173481[18:00<41:44,43.63it/s] 37%|###7      |64836/173481[18:10<41:30,43.63it/s] 44%|####4     |76472/173481[21:00<30:24,53.18it/s] 45%|####4     |77211/173481[21:11<30:10,53.18it/s] 51%|#####1    |88542/173481[24:00<23:52,59.31it/s] 51%|#####1    |89287/173481[24:11<23:39,59.31it/s] 58%|#####8    |100713/173481[27:00<19:11,63.19it/s] 58%|#####8    |101486/173481[27:11<18:59,63.19it/s] 65%|######4   |112008/173481[30:00<16:16,62.97it/s] 65%|######5   |112781/173481[30:11<16:03,62.97it/s] 72%|#######1  |124537/173481[33:00<12:20,66.12it/s] 72%|#######2  |125316/173481[33:11<12:08,66.12it/s] 79%|#######8  |136946/173481[36:00<09:01,67.50it/s] 79%|#######9  |137726/173481[36:11<08:49,67.50it/s] 86%|########5 |148884/173481[39:00<06:07,66.90it/s] 86%|########6 |149856/173481[39:11<05:53,66.90it/s] 94%|#########4|163937/173481[42:00<02:08,74.34it/s] 95%|#########5|164907/173481[42:12<01:55,74.34it/s]100%|##########|173481/173481[43:54<00:00,65.85it/s]
[32m[0323 18:34:42 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:2634.65 sec.
[32m[0323 18:34:42 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-1734810.
[32m[0323 18:34:42 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:15<00:00,138.63it/s]
9
[32m[0323 18:36:58 @monitor.py:363][0m QueueInput/queue_size: 1.2337
[32m[0323 18:36:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.346
[32m[0323 18:36:58 @monitor.py:363][0m activation-summaries/output-rms: 0.041604
[32m[0323 18:36:58 @monitor.py:363][0m cross_entropy_loss: 1.6812
[32m[0323 18:36:58 @monitor.py:363][0m lr: 0.000125
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.43355
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6883e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.32883
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2652e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.39839
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.4036e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.32247
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.5561e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4223
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.791e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.32313
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.6596e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.42306
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.8187e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.32164
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4434e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.43062
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1648e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.32568
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.6958e-06
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4306
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3775
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29462
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090717
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29007
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28079
[32m[0323 18:36:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0323 18:36:58 @monitor.py:363][0m train-error-top1: 0.4519
[32m[0323 18:36:58 @monitor.py:363][0m val-error-top1: 0.45991
[32m[0323 18:36:58 @monitor.py:363][0m val-utt-error: 0.11928
[32m[0323 18:36:58 @monitor.py:363][0m validation_cost: 1.7392
[32m[0323 18:36:58 @monitor.py:363][0m wd_cost: 0.025503
[32m[0323 18:36:58 @group.py:42][0m Callbacks took 136.131 sec in total. InferenceRunner: 135.785sec
[32m[0323 18:36:58 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13563/173481[03:00<35:22,75.35it/s]  8%|8         |14386/173481[03:10<35:11,75.35it/s] 16%|#6        |28179/173481[06:00<30:58,78.17it/s] 17%|#6        |28769/173481[06:10<30:51,78.17it/s] 21%|##1       |37142/173481[09:00<37:21,60.83it/s] 22%|##1       |37660/173481[09:10<37:12,60.83it/s] 26%|##6       |45717/173481[12:00<39:51,53.43it/s] 27%|##6       |46220/173481[12:10<39:41,53.43it/s] 31%|###1      |54190/173481[15:00<39:43,50.05it/s] 32%|###1      |54760/173481[15:10<39:32,50.05it/s] 37%|###6      |63876/173481[18:00<35:13,51.86it/s] 37%|###7      |64560/173481[18:10<35:00,51.86it/s] 42%|####2     |73016/173481[21:00<32:38,51.31it/s] 42%|####2     |73560/173481[21:11<32:27,51.31it/s] 47%|####7     |82346/173481[24:00<29:27,51.56it/s] 48%|####7     |82925/173481[24:11<29:16,51.56it/s] 53%|#####2    |91726/173481[27:00<26:17,51.84it/s] 53%|#####3    |92320/173481[27:11<26:05,51.84it/s] 58%|#####7    |100255/173481[30:00<24:39,49.51it/s] 58%|#####8    |101145/173481[30:11<24:21,49.51it/s] 64%|######3   |110321/173481[33:00<20:02,52.52it/s] 64%|######4   |111116/173481[33:11<19:47,52.52it/s] 70%|#######   |121728/173481[36:00<15:01,57.44it/s] 71%|#######   |122405/173481[36:11<14:49,57.44it/s] 76%|#######6  |132666/173481[39:00<11:31,59.05it/s] 77%|#######6  |132890/173481[39:12<11:27,59.05it/s] 82%|########2 |142481/173481[42:00<09:06,56.70it/s] 83%|########2 |143188/173481[42:12<08:54,56.70it/s] 88%|########7 |152186/173481[45:00<06:25,55.27it/s] 88%|########8 |152846/173481[45:12<06:13,55.27it/s] 93%|#########3|161981/173481[48:00<03:29,54.83it/s] 94%|#########3|162579/173481[48:12<03:18,54.83it/s] 99%|#########8|170899/173481[51:00<00:49,52.06it/s] 99%|#########8|171505/173481[51:12<00:37,52.06it/s]100%|##########|173481/173481[51:51<00:00,55.75it/s]
[32m[0323 19:28:50 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3111.89 sec.
[32m[0323 19:28:50 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-1908291.
[32m[0323 19:28:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.80it/s]
10
[32m[0323 19:30:48 @monitor.py:363][0m QueueInput/queue_size: 0.67807
[32m[0323 19:30:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.352
[32m[0323 19:30:48 @monitor.py:363][0m activation-summaries/output-rms: 0.040742
[32m[0323 19:30:48 @monitor.py:363][0m cross_entropy_loss: 1.65
[32m[0323 19:30:48 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.44843
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.495e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34006
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2044e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.41352
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.4673e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.33368
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6131e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.43935
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8501e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.33428
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.5966e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.4397
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.8834e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33257
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4569e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.44893
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.186e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.33704
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7225e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46614
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3849
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30275
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2999
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29071
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 19:30:48 @monitor.py:363][0m train-error-top1: 0.4429
[32m[0323 19:30:48 @monitor.py:363][0m val-error-top1: 0.45011
[32m[0323 19:30:48 @monitor.py:363][0m val-utt-error: 0.10923
[32m[0323 19:30:48 @monitor.py:363][0m validation_cost: 1.6978
[32m[0323 19:30:48 @monitor.py:363][0m wd_cost: 0.028232
[32m[0323 19:30:48 @group.py:42][0m Callbacks took 118.144 sec in total. InferenceRunner: 117.067sec
[32m[0323 19:30:48 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12002/173481[03:00<40:21,66.67it/s]  7%|7         |12519/173481[03:10<40:14,66.67it/s] 12%|#2        |21215/173481[06:00<43:49,57.91it/s] 13%|#2        |21784/173481[06:10<43:39,57.91it/s] 18%|#7        |30574/173481[09:00<43:28,54.79it/s] 18%|#7        |31091/173481[09:10<43:18,54.79it/s] 23%|##2       |39325/173481[12:00<43:24,51.52it/s] 23%|##2       |39842/173481[12:10<43:14,51.52it/s] 28%|##7       |47930/173481[15:00<42:11,49.59it/s] 28%|##7       |48437/173481[15:10<42:01,49.59it/s] 33%|###2      |56704/173481[18:00<39:35,49.16it/s] 33%|###3      |57249/173481[18:10<39:24,49.16it/s] 38%|###7      |65788/173481[21:00<36:02,49.80it/s] 38%|###8      |66367/173481[21:10<35:50,49.80it/s] 43%|####3     |74858/173481[24:00<32:48,50.09it/s] 44%|####3     |75704/173481[24:11<32:31,50.09it/s] 49%|####8     |84728/173481[27:00<28:15,52.36it/s] 49%|####9     |85279/173481[27:11<28:04,52.36it/s] 54%|#####4    |94120/173481[30:00<25:18,52.27it/s] 55%|#####4    |94709/173481[30:11<25:07,52.27it/s] 60%|#####9    |103665/173481[33:00<22:06,52.62it/s] 60%|#####9    |103784/173481[33:11<22:04,52.62it/s] 65%|######5   |113295/173481[36:00<18:54,53.05it/s] 66%|######5   |113894/173481[36:11<18:43,53.05it/s] 71%|#######   |122715/173481[39:00<16:03,52.68it/s] 71%|#######1  |123366/173481[39:11<15:51,52.68it/s] 76%|#######6  |132113/173481[42:00<13:08,52.44it/s] 76%|#######6  |132673/173481[42:12<12:58,52.44it/s] 82%|########2 |142810/173481[45:00<09:10,55.71it/s] 83%|########2 |143544/173481[45:12<08:57,55.71it/s] 89%|########8 |154120/173481[48:00<05:27,59.06it/s] 89%|########9 |154844/173481[48:12<05:15,59.06it/s] 95%|#########4|164466/173481[51:00<02:34,58.26it/s] 95%|#########5|165322/173481[51:12<02:20,58.26it/s]100%|##########|173481/173481[53:29<00:00,54.06it/s]
[32m[0323 20:24:17 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3209.23 sec.
[32m[0323 20:24:18 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-2081772.
[32m[0323 20:24:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.84it/s]
11
[32m[0323 20:26:16 @monitor.py:363][0m QueueInput/queue_size: 0.60307
[32m[0323 20:26:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 33.32
[32m[0323 20:26:16 @monitor.py:363][0m activation-summaries/output-rms: 0.040645
[32m[0323 20:26:16 @monitor.py:363][0m cross_entropy_loss: 1.6588
[32m[0323 20:26:16 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.45751
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5209e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34491
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.1941e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.42434
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5046e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3383
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6125e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.44845
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8957e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.33888
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.6333e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.44889
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0g/b-rms: 7.0274e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33728
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4445e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.45933
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1451e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34168
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7202e-06
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.48985
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3894
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3082
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30413
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29485
[32m[0323 20:26:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0323 20:26:16 @monitor.py:363][0m train-error-top1: 0.43953
[32m[0323 20:26:16 @monitor.py:363][0m val-error-top1: 0.44809
[32m[0323 20:26:16 @monitor.py:363][0m val-utt-error: 0.10674
[32m[0323 20:26:16 @monitor.py:363][0m validation_cost: 1.6883
[32m[0323 20:26:16 @monitor.py:363][0m wd_cost: 0.005993
[32m[0323 20:26:16 @group.py:42][0m Callbacks took 119.056 sec in total. InferenceRunner: 118.514sec
[32m[0323 20:26:16 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12926/173481[03:00<37:15,71.81it/s]  8%|7         |13640/173481[03:10<37:05,71.81it/s] 15%|#5        |26264/173481[06:00<33:38,72.94it/s] 16%|#5        |26988/173481[06:10<33:28,72.94it/s] 21%|##        |35964/173481[09:00<36:58,61.98it/s] 21%|##1       |36508/173481[09:10<36:49,61.98it/s] 26%|##6       |45299/173481[12:00<37:49,56.47it/s] 26%|##6       |45859/173481[12:10<37:39,56.47it/s] 31%|###1      |54619/173481[15:00<36:40,54.02it/s] 32%|###1      |55206/173481[15:10<36:29,54.02it/s] 37%|###7      |64344/173481[18:00<33:40,54.02it/s] 37%|###7      |65031/173481[18:10<33:27,54.02it/s] 43%|####3     |75149/173481[21:00<28:49,56.86it/s] 44%|####3     |75828/173481[21:11<28:37,56.86it/s] 49%|####9     |85309/173481[24:00<25:56,56.65it/s] 50%|####9     |85948/173481[24:11<25:45,56.65it/s] 55%|#####4    |95251/173481[27:00<23:18,55.93it/s] 55%|#####5    |95892/173481[27:11<23:07,55.93it/s] 61%|######    |105120/173481[30:00<20:34,55.37it/s] 61%|######    |105719/173481[30:11<20:23,55.37it/s] 66%|######6   |115295/173481[33:00<17:20,55.94it/s] 67%|######6   |115973/173481[33:11<17:07,55.94it/s] 72%|#######1  |124645/173481[36:00<15:06,53.87it/s] 72%|#######2  |125586/173481[36:11<14:49,53.87it/s] 79%|#######8  |136339/173481[39:00<10:30,58.90it/s] 79%|#######8  |136956/173481[39:11<10:20,58.90it/s] 85%|########5 |147479/173481[42:00<07:10,60.35it/s] 85%|########5 |148163/173481[42:12<06:59,60.35it/s] 91%|#########1|158240/173481[45:00<04:13,60.06it/s] 92%|#########1|158948/173481[45:12<04:01,60.06it/s] 97%|#########7|168792/173481[48:00<01:19,59.33it/s] 98%|#########7|169531/173481[48:12<01:06,59.33it/s]100%|##########|173481/173481[49:19<00:00,58.63it/s]
[32m[0323 21:15:35 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:2959.02 sec.
[32m[0323 21:15:36 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-2255253.
[32m[0323 21:15:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.31it/s]
12
[32m[0323 21:17:30 @monitor.py:363][0m QueueInput/queue_size: 0.41202
[32m[0323 21:17:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.292
[32m[0323 21:17:30 @monitor.py:363][0m activation-summaries/output-rms: 0.040375
[32m[0323 21:17:30 @monitor.py:363][0m cross_entropy_loss: 1.6111
[32m[0323 21:17:30 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.46598
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5815e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34977
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2211e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.43347
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.529e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34267
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6454e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.45736
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7595e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34372
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.6288e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45848
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0g/b-rms: 7.0394e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34209
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4374e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.46936
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1361e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34612
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7008e-06
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.51329
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3933
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31346
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30846
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29916
[32m[0323 21:17:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 21:17:30 @monitor.py:363][0m train-error-top1: 0.44031
[32m[0323 21:17:30 @monitor.py:363][0m val-error-top1: 0.44798
[32m[0323 21:17:30 @monitor.py:363][0m val-utt-error: 0.10721
[32m[0323 21:17:30 @monitor.py:363][0m validation_cost: 1.685
[32m[0323 21:17:30 @monitor.py:363][0m wd_cost: 0.0063498
[32m[0323 21:17:30 @group.py:42][0m Callbacks took 114.462 sec in total. InferenceRunner: 113.872sec
[32m[0323 21:17:30 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12807/173481[03:00<37:38,71.15it/s]  8%|7         |13396/173481[03:10<37:30,71.15it/s] 10%|#         |18208/173481[06:00<1:01:19,42.20it/s] 11%|#         |18961/173481[06:10<1:01:01,42.20it/s] 18%|#8        |31725/173481[09:00<43:43,54.04it/s]   19%|#8        |32529/173481[09:10<43:28,54.04it/s] 25%|##5       |43983/173481[12:00<35:49,60.25it/s] 26%|##5       |44577/173481[12:10<35:39,60.25it/s] 32%|###1      |54859/173481[15:00<32:45,60.34it/s] 32%|###1      |55507/173481[15:10<32:35,60.34it/s] 38%|###8      |66285/173481[18:00<28:52,61.87it/s] 39%|###8      |67076/173481[18:10<28:39,61.87it/s] 45%|####5     |78337/173481[21:00<24:39,64.31it/s] 46%|####5     |79053/173481[21:11<24:28,64.31it/s] 52%|#####2    |90468/173481[24:00<21:01,65.81it/s] 53%|#####2    |91212/173481[24:11<20:50,65.81it/s] 59%|#####8    |101815/173481[27:00<18:32,64.40it/s] 59%|#####9    |102613/173481[27:11<18:20,64.40it/s] 66%|######5   |113957/173481[30:00<15:03,65.89it/s] 66%|######6   |114645/173481[30:11<14:52,65.89it/s] 72%|#######2  |125517/173481[33:00<12:17,65.04it/s] 73%|#######2  |126270/173481[33:11<12:05,65.04it/s] 78%|#######8  |136085/173481[36:00<10:05,61.71it/s] 79%|#######8  |136899/173481[36:11<09:52,61.71it/s] 85%|########5 |147882/173481[39:00<06:42,63.57it/s] 86%|########5 |148652/173481[39:11<06:30,63.57it/s] 92%|#########2|159627/173481[42:00<03:35,64.40it/s] 92%|#########2|160380/173481[42:12<03:23,64.40it/s] 98%|#########8|170103/173481[45:00<00:55,61.14it/s] 98%|#########8|170617/173481[45:12<00:46,61.14it/s]100%|##########|173481/173481[46:03<00:00,62.78it/s]
[32m[0323 22:03:33 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:2763.12 sec.
[32m[0323 22:03:33 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-2428734.
[32m[0323 22:03:34 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.75it/s]
13
[32m[0323 22:05:31 @monitor.py:363][0m QueueInput/queue_size: 0.46833
[32m[0323 22:05:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.149
[32m[0323 22:05:31 @monitor.py:363][0m activation-summaries/output-rms: 0.039985
[32m[0323 22:05:31 @monitor.py:363][0m cross_entropy_loss: 1.6384
[32m[0323 22:05:31 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47115
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5299e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35289
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2193e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.43969
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5827e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34587
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6185e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46226
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7168e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3467
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.6822e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46399
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9365e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34513
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4196e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.476
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1711e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34906
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7147e-06
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.53234
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3964
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31686
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31143
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30208
[32m[0323 22:05:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 22:05:31 @monitor.py:363][0m train-error-top1: 0.43411
[32m[0323 22:05:31 @monitor.py:363][0m val-error-top1: 0.44235
[32m[0323 22:05:31 @monitor.py:363][0m val-utt-error: 0.10466
[32m[0323 22:05:31 @monitor.py:363][0m validation_cost: 1.6636
[32m[0323 22:05:31 @monitor.py:363][0m wd_cost: 0.0013265
[32m[0323 22:05:31 @group.py:42][0m Callbacks took 118.407 sec in total. InferenceRunner: 117.832sec
[32m[0323 22:05:31 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14544/173481[03:00<32:47,80.80it/s]  9%|8         |15236/173481[03:10<32:38,80.80it/s] 14%|#4        |24937/173481[06:00<36:45,67.35it/s] 15%|#4        |25461/173481[06:10<36:37,67.35it/s] 20%|#9        |34377/173481[09:00<39:19,58.96it/s] 20%|##        |34994/173481[09:10<39:08,58.96it/s] 26%|##5       |44993/173481[12:00<36:18,58.97it/s] 26%|##6       |45645/173481[12:10<36:07,58.97it/s] 32%|###1      |55010/173481[15:00<34:28,57.26it/s] 32%|###1      |55455/173481[15:10<34:21,57.26it/s] 37%|###6      |63716/173481[18:00<34:53,52.44it/s] 37%|###7      |64378/173481[18:10<34:40,52.44it/s] 43%|####2     |74561/173481[21:00<29:24,56.07it/s] 43%|####3     |75173/173481[21:10<29:13,56.07it/s] 49%|####9     |85107/173481[24:00<25:42,57.30it/s] 49%|####9     |85769/173481[24:11<25:30,57.30it/s] 54%|#####4    |94322/173481[27:00<24:24,54.07it/s] 55%|#####4    |94813/173481[27:11<24:14,54.07it/s] 59%|#####9    |103107/173481[30:00<22:51,51.30it/s] 60%|#####9    |103672/173481[30:11<22:40,51.30it/s] 66%|######5   |114437/173481[33:00<17:24,56.52it/s] 66%|######6   |115098/173481[33:11<17:12,56.52it/s] 72%|#######2  |125592/173481[36:00<13:30,59.12it/s] 73%|#######2  |126227/173481[36:11<13:19,59.12it/s] 78%|#######8  |135377/173481[39:00<11:12,56.63it/s] 78%|#######8  |136020/173481[39:11<11:01,56.63it/s] 84%|########3 |145214/173481[42:00<08:28,55.62it/s] 84%|########4 |145914/173481[42:11<08:15,55.62it/s] 89%|########9 |154955/173481[45:00<05:37,54.86it/s] 90%|########9 |155760/173481[45:12<05:23,54.86it/s] 96%|#########5|165857/173481[48:00<02:12,57.57it/s] 96%|#########5|166497/173481[48:12<02:01,57.57it/s]100%|##########|173481/173481[49:59<00:00,57.83it/s]
[32m[0323 22:55:31 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:2999.61 sec.
[32m[0323 22:55:31 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-2602215.
[32m[0323 22:55:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.57it/s]
14
[32m[0323 22:57:26 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 22:57:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.712
[32m[0323 22:57:26 @monitor.py:363][0m activation-summaries/output-rms: 0.041714
[32m[0323 22:57:26 @monitor.py:363][0m cross_entropy_loss: 1.6082
[32m[0323 22:57:26 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47461
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.4932e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35423
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2538e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.44314
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5768e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34743
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6266e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46511
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7221e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34807
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.6726e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46699
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9769e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34656
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4208e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.47972
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1662e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35027
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7424e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.54482
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3985
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31884
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31271
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30332
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 22:57:26 @monitor.py:363][0m train-error-top1: 0.42551
[32m[0323 22:57:26 @monitor.py:363][0m val-error-top1: 0.44114
[32m[0323 22:57:26 @monitor.py:363][0m val-utt-error: 0.1027
[32m[0323 22:57:26 @monitor.py:363][0m validation_cost: 1.6583
[32m[0323 22:57:26 @monitor.py:363][0m wd_cost: 0.001362
[32m[0323 22:57:26 @group.py:42][0m Callbacks took 114.696 sec in total. InferenceRunner: 114.389sec
[32m[0323 22:57:26 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13087/173481[03:00<36:46,72.70it/s]  8%|7         |13827/173481[03:10<36:36,72.70it/s] 15%|#4        |25891/173481[06:00<34:12,71.91it/s] 15%|#5        |26730/173481[06:10<34:00,71.91it/s] 21%|##1       |36739/173481[09:00<34:45,65.57it/s] 22%|##1       |37320/173481[09:10<34:36,65.57it/s] 27%|##7       |47499/173481[12:00<33:34,62.54it/s] 28%|##7       |48082/173481[12:10<33:25,62.54it/s] 33%|###3      |58000/173481[15:00<31:53,60.37it/s] 34%|###3      |58683/173481[15:10<31:41,60.37it/s] 40%|###9      |68554/173481[18:00<29:23,59.49it/s] 40%|###9      |69197/173481[18:10<29:13,59.49it/s] 46%|####5     |79656/173481[21:00<25:49,60.56it/s] 46%|####6     |80465/173481[21:11<25:35,60.56it/s] 53%|#####2    |91862/173481[24:00<21:15,63.98it/s] 53%|#####3    |92738/173481[24:11<21:02,63.98it/s] 60%|######    |104144/173481[27:00<17:30,66.03it/s] 60%|######    |104916/173481[27:11<17:18,66.03it/s] 67%|######7   |116951/173481[30:00<13:45,68.49it/s] 68%|######7   |117772/173481[30:11<13:33,68.49it/s] 74%|#######4  |128531/173481[33:00<11:17,66.35it/s] 75%|#######4  |129399/173481[33:11<11:04,66.35it/s] 81%|########  |139869/173481[36:00<08:40,64.62it/s] 81%|########1 |140595/173481[36:11<08:28,64.62it/s] 87%|########6 |150586/173481[39:00<06:09,61.97it/s] 87%|########7 |151258/173481[39:11<05:58,61.97it/s] 92%|#########2|160146/173481[42:00<03:53,57.20it/s] 93%|#########2|161061/173481[42:12<03:37,57.20it/s]100%|##########|173481/173481[44:53<00:00,64.40it/s]
[32m[0323 23:42:20 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:2693.91 sec.
[32m[0323 23:42:20 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-2775696.
[32m[0323 23:42:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.10it/s]
15
[32m[0323 23:44:16 @monitor.py:363][0m QueueInput/queue_size: 0.53459
[32m[0323 23:44:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.98
[32m[0323 23:44:16 @monitor.py:363][0m activation-summaries/output-rms: 0.041361
[32m[0323 23:44:16 @monitor.py:363][0m cross_entropy_loss: 1.623
[32m[0323 23:44:16 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47659
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5117e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35562
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2567e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.446
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5554e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34878
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.5936e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46762
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6938e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34934
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.6834e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46977
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9944e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34784
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.413e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48312
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1724e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35173
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7354e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.55724
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4004
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32077
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31403
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30453
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0323 23:44:16 @monitor.py:363][0m train-error-top1: 0.43686
[32m[0323 23:44:16 @monitor.py:363][0m val-error-top1: 0.44226
[32m[0323 23:44:16 @monitor.py:363][0m val-utt-error: 0.1036
[32m[0323 23:44:16 @monitor.py:363][0m validation_cost: 1.664
[32m[0323 23:44:16 @monitor.py:363][0m wd_cost: 0.0013978
[32m[0323 23:44:16 @group.py:42][0m Callbacks took 116.130 sec in total. InferenceRunner: 115.415sec
[32m[0323 23:44:16 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14179/173481[03:00<33:42,78.77it/s]  9%|8         |14984/173481[03:10<33:32,78.77it/s] 15%|#4        |25812/173481[06:00<34:39,71.00it/s] 15%|#5        |26629/173481[06:10<34:28,71.00it/s] 22%|##2       |38859/173481[09:00<31:16,71.73it/s] 23%|##2       |39519/173481[09:10<31:07,71.73it/s] 29%|##9       |50497/173481[12:00<30:08,68.01it/s] 29%|##9       |51169/173481[12:10<29:58,68.01it/s] 36%|###5      |62337/173481[15:00<27:41,66.87it/s] 36%|###6      |63159/173481[15:10<27:29,66.87it/s] 44%|####3     |75885/173481[18:00<22:58,70.82it/s] 44%|####4     |76691/173481[18:10<22:46,70.82it/s] 52%|#####1    |89446/173481[21:00<19:11,73.01it/s] 52%|#####2    |90278/173481[21:11<18:59,73.01it/s] 59%|#####9    |102903/173481[24:00<15:55,73.87it/s] 60%|#####9    |103732/173481[24:11<15:44,73.87it/s] 66%|######6   |114765/173481[27:00<14:02,69.66it/s] 67%|######6   |115605/173481[27:11<13:50,69.66it/s] 74%|#######3  |127833/173481[30:00<10:42,71.10it/s] 74%|#######4  |128664/173481[30:11<10:30,71.10it/s] 81%|########1 |140775/173481[33:00<07:37,71.49it/s] 82%|########1 |141614/173481[33:11<07:25,71.49it/s] 89%|########8 |154049/173481[36:00<04:27,72.60it/s] 89%|########9 |155059/173481[36:11<04:13,72.60it/s] 97%|#########7|168745/173481[39:00<01:01,76.85it/s] 98%|#########7|169459/173481[39:11<00:52,76.85it/s]100%|##########|173481/173481[40:21<00:00,71.66it/s]
[32m[0324 00:24:37 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:2421.04 sec.
[32m[0324 00:24:37 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-2949177.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.38it/s]
16
[32m[0324 00:26:35 @monitor.py:363][0m QueueInput/queue_size: 0.52607
[32m[0324 00:26:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.258
[32m[0324 00:26:35 @monitor.py:363][0m activation-summaries/output-rms: 0.041064
[32m[0324 00:26:35 @monitor.py:363][0m cross_entropy_loss: 1.633
[32m[0324 00:26:35 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47829
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5176e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35641
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2467e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4483
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5597e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34941
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6159e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46918
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6795e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34998
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.6957e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47153
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9885e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.3485
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4074e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48513
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1696e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35236
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7332e-06
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56579
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4016
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32184
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31472
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30518
[32m[0324 00:26:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 00:26:35 @monitor.py:363][0m train-error-top1: 0.43169
[32m[0324 00:26:35 @monitor.py:363][0m val-error-top1: 0.43924
[32m[0324 00:26:35 @monitor.py:363][0m val-utt-error: 0.10137
[32m[0324 00:26:35 @monitor.py:363][0m validation_cost: 1.6511
[32m[0324 00:26:35 @monitor.py:363][0m wd_cost: 0.00028437
[32m[0324 00:26:35 @group.py:42][0m Callbacks took 117.636 sec in total. InferenceRunner: 117.369sec
[32m[0324 00:26:35 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13654/173481[03:00<35:07,75.85it/s]  8%|8         |14478/173481[03:10<34:56,75.85it/s] 15%|#4        |25499/173481[06:00<34:59,70.47it/s] 15%|#5        |26068/173481[06:10<34:51,70.47it/s] 20%|##        |35389/173481[09:00<37:16,61.74it/s] 21%|##        |36028/173481[09:10<37:06,61.74it/s] 26%|##6       |45352/173481[12:00<36:35,58.37it/s] 27%|##6       |46196/173481[12:10<36:20,58.37it/s] 32%|###1      |55280/173481[15:00<34:44,56.71it/s] 32%|###2      |55843/173481[15:10<34:34,56.71it/s] 38%|###7      |65378/173481[18:00<31:56,56.41it/s] 38%|###8      |66066/173481[18:10<31:44,56.41it/s] 44%|####4     |76539/173481[21:00<27:21,59.06it/s] 44%|####4     |77188/173481[21:11<27:10,59.06it/s] 50%|#####     |87513/173481[24:00<23:52,60.00it/s] 51%|#####     |88238/173481[24:11<23:40,60.00it/s] 57%|#####6    |98378/173481[27:00<20:48,60.18it/s] 57%|#####7    |99072/173481[27:11<20:36,60.18it/s] 63%|######2   |109279/173481[30:00<17:43,60.37it/s] 63%|######3   |109995/173481[30:11<17:31,60.37it/s] 70%|######9   |120764/173481[33:00<14:09,62.04it/s] 70%|#######   |121443/173481[33:11<13:58,62.04it/s] 76%|#######5  |131564/173481[36:00<11:27,61.00it/s] 76%|#######6  |132250/173481[36:11<11:15,61.00it/s] 82%|########2 |142405/173481[39:00<08:32,60.61it/s] 83%|########2 |143131/173481[39:12<08:20,60.61it/s] 88%|########8 |153514/173481[42:00<05:26,61.15it/s] 89%|########8 |154268/173481[42:12<05:14,61.15it/s] 95%|#########5|164904/173481[45:00<02:17,62.19it/s] 95%|#########5|165638/173481[45:12<02:06,62.19it/s]100%|##########|173481/173481[47:44<00:00,60.57it/s]
[32m[0324 01:14:19 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:2864.12 sec.
[32m[0324 01:14:19 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-3122658.
[32m[0324 01:14:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.99it/s]
17
[32m[0324 01:16:22 @monitor.py:363][0m QueueInput/queue_size: 0.6117
[32m[0324 01:16:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.837
[32m[0324 01:16:22 @monitor.py:363][0m activation-summaries/output-rms: 0.040759
[32m[0324 01:16:22 @monitor.py:363][0m cross_entropy_loss: 1.5789
[32m[0324 01:16:22 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47943
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5111e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35683
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2419e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.44981
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5587e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34976
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47062
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6785e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35033
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.6932e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47299
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9765e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34897
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.399e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48667
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1622e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35269
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7349e-06
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57235
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4027
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32256
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31512
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30555
[32m[0324 01:16:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086392
[32m[0324 01:16:22 @monitor.py:363][0m train-error-top1: 0.43139
[32m[0324 01:16:22 @monitor.py:363][0m val-error-top1: 0.43944
[32m[0324 01:16:22 @monitor.py:363][0m val-utt-error: 0.10073
[32m[0324 01:16:22 @monitor.py:363][0m validation_cost: 1.6496
[32m[0324 01:16:22 @monitor.py:363][0m wd_cost: 0.00028801
[32m[0324 01:16:22 @group.py:42][0m Callbacks took 123.847 sec in total. InferenceRunner: 122.242sec
[32m[0324 01:16:22 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13418/173481[03:00<35:47,74.54it/s]  8%|8         |14147/173481[03:10<35:37,74.54it/s] 15%|#4        |25523/173481[06:00<34:52,70.70it/s] 15%|#5        |26070/173481[06:10<34:44,70.70it/s] 21%|##        |36070/173481[09:00<35:44,64.08it/s] 21%|##1       |36707/173481[09:10<35:34,64.08it/s] 27%|##6       |46248/173481[12:00<35:19,60.02it/s] 27%|##6       |46727/173481[12:10<35:11,60.02it/s] 33%|###2      |57130/173481[15:00<32:11,60.23it/s] 33%|###3      |57682/173481[15:10<32:02,60.23it/s] 39%|###9      |68183/173481[18:00<28:51,60.80it/s] 40%|###9      |68807/173481[18:10<28:41,60.80it/s] 45%|####5     |78778/173481[21:00<26:23,59.81it/s] 46%|####5     |79370/173481[21:11<26:13,59.81it/s] 51%|#####1    |88844/173481[24:00<24:24,57.80it/s] 52%|#####1    |89438/173481[24:11<24:14,57.80it/s] 57%|#####6    |98671/173481[27:00<22:12,56.15it/s] 57%|#####7    |99296/173481[27:11<22:01,56.15it/s] 63%|######2   |109148/173481[30:00<18:45,57.15it/s] 63%|######3   |109815/173481[30:11<18:33,57.15it/s] 69%|######9   |119921/173481[33:00<15:16,58.47it/s] 70%|######9   |120593/173481[33:11<15:04,58.47it/s] 75%|#######4  |130093/173481[36:00<12:34,57.47it/s] 75%|#######5  |130738/173481[36:11<12:23,57.47it/s] 81%|########1 |140731/173481[39:00<09:21,58.27it/s] 82%|########1 |141485/173481[39:11<09:09,58.27it/s] 88%|########7 |151883/173481[42:00<05:59,60.06it/s] 88%|########7 |152642/173481[42:12<05:46,60.06it/s] 94%|#########4|163343/173481[45:00<02:44,61.81it/s] 95%|#########4|164092/173481[45:12<02:31,61.81it/s]100%|##########|173481/173481[47:51<00:00,60.42it/s]
[32m[0324 02:04:14 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:2871.22 sec.
[32m[0324 02:04:14 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-3296139.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.71it/s]
18
[32m[0324 02:06:39 @monitor.py:363][0m QueueInput/queue_size: 0.90417
[32m[0324 02:06:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 42.479
[32m[0324 02:06:39 @monitor.py:363][0m activation-summaries/output-rms: 0.040215
[32m[0324 02:06:39 @monitor.py:363][0m cross_entropy_loss: 1.6249
[32m[0324 02:06:39 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48027
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5314e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35723
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2498e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45134
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5475e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35012
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47145
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6762e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35067
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7034e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47397
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9849e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34929
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3878e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48806
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1512e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35302
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7494e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57901
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4037
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32325
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31553
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30592
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 02:06:39 @monitor.py:363][0m train-error-top1: 0.43165
[32m[0324 02:06:39 @monitor.py:363][0m val-error-top1: 0.4388
[32m[0324 02:06:39 @monitor.py:363][0m val-utt-error: 0.10339
[32m[0324 02:06:39 @monitor.py:363][0m validation_cost: 1.6481
[32m[0324 02:06:39 @monitor.py:363][0m wd_cost: 0.0002917
[32m[0324 02:06:39 @group.py:42][0m Callbacks took 145.327 sec in total. InferenceRunner: 145.117sec
[32m[0324 02:06:39 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13930/173481[03:00<34:21,77.39it/s]  8%|8         |14676/173481[03:10<34:12,77.39it/s] 14%|#4        |24857/173481[06:00<36:24,68.03it/s] 15%|#4        |25450/173481[06:10<36:15,68.03it/s] 21%|##        |36421/173481[09:00<34:34,66.08it/s] 21%|##1       |37033/173481[09:10<34:24,66.08it/s] 27%|##7       |47153/173481[12:00<33:35,62.69it/s] 28%|##7       |47821/173481[12:10<33:24,62.69it/s] 34%|###4      |59373/173481[15:00<29:10,65.18it/s] 35%|###4      |60121/173481[15:10<28:59,65.18it/s] 42%|####1     |72057/173481[18:00<24:58,67.70it/s] 42%|####1     |72251/173481[18:10<24:55,67.70it/s] 49%|####8     |84275/173481[21:00<21:55,67.79it/s] 49%|####9     |85067/173481[21:11<21:44,67.79it/s] 56%|#####6    |97285/173481[24:00<18:09,69.96it/s] 57%|#####6    |98062/173481[24:11<17:58,69.96it/s] 64%|######3   |110168/173481[27:00<14:54,70.76it/s] 64%|######3   |110972/173481[27:11<14:43,70.76it/s] 71%|#######   |122898/173481[30:00<11:55,70.74it/s] 71%|#######1  |123714/173481[30:11<11:43,70.74it/s] 77%|#######7  |134396/173481[33:00<09:42,67.13it/s] 78%|#######7  |135188/173481[33:11<09:30,67.13it/s] 86%|########5 |148397/173481[36:00<05:48,72.07it/s] 86%|########6 |149380/173481[36:11<05:34,72.07it/s] 94%|#########3|162712/173481[39:00<02:22,75.61it/s] 94%|#########4|163651/173481[39:12<02:10,75.61it/s]100%|##########|173481/173481[41:15<00:00,70.08it/s]
[32m[0324 02:47:55 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:2475.49 sec.
[32m[0324 02:47:55 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-3469620.
[32m[0324 02:47:55 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.66it/s]
19
[32m[0324 02:49:54 @monitor.py:363][0m QueueInput/queue_size: 1.4227
[32m[0324 02:49:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.1
[32m[0324 02:49:54 @monitor.py:363][0m activation-summaries/output-rms: 0.042218
[32m[0324 02:49:54 @monitor.py:363][0m cross_entropy_loss: 1.6162
[32m[0324 02:49:54 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48081
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5307e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35734
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2477e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45192
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5518e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35038
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6122e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47183
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6726e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35084
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7047e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47438
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9952e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.3494
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3897e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48874
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1521e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35312
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7432e-06
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58262
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4042
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32353
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31567
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30604
[32m[0324 02:49:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 02:49:54 @monitor.py:363][0m train-error-top1: 0.43449
[32m[0324 02:49:54 @monitor.py:363][0m val-error-top1: 0.43817
[32m[0324 02:49:54 @monitor.py:363][0m val-utt-error: 0.10233
[32m[0324 02:49:54 @monitor.py:363][0m validation_cost: 1.6453
[32m[0324 02:49:54 @monitor.py:363][0m wd_cost: 5.8729e-05
[32m[0324 02:49:54 @group.py:42][0m Callbacks took 119.123 sec in total. InferenceRunner: 118.650sec
[32m[0324 02:49:54 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13748/173481[03:00<34:51,76.37it/s]  8%|8         |14395/173481[03:10<34:42,76.37it/s] 15%|#5        |26335/173481[06:00<33:35,73.01it/s] 16%|#5        |27186/173481[06:10<33:23,73.01it/s] 24%|##3       |40990/173481[09:00<28:41,76.98it/s] 24%|##4       |41835/173481[09:10<28:30,76.98it/s] 32%|###1      |55479/173481[12:00<24:59,78.70it/s] 32%|###2      |56335/173481[12:10<24:48,78.70it/s] 40%|####      |70037/173481[15:00<21:36,79.77it/s] 41%|####      |70915/173481[15:10<21:25,79.77it/s] 47%|####7     |82211/173481[18:00<20:46,73.20it/s] 48%|####7     |83099/173481[18:10<20:34,73.20it/s] 54%|#####4    |93821/173481[21:00<19:21,68.57it/s] 54%|#####4    |94540/173481[21:11<19:11,68.57it/s] 60%|######    |104871/173481[24:00<17:39,64.78it/s] 61%|######    |105551/173481[24:11<17:28,64.78it/s] 67%|######6   |115974/173481[27:00<15:10,63.19it/s] 67%|######7   |116655/173481[27:11<14:59,63.19it/s] 73%|#######3  |127196/173481[30:00<12:17,62.77it/s] 74%|#######3  |127885/173481[30:11<12:06,62.77it/s] 80%|#######9  |138150/173481[33:00<09:31,61.79it/s] 80%|########  |138873/173481[33:11<09:20,61.79it/s] 86%|########6 |149196/173481[36:00<06:34,61.57it/s] 86%|########6 |149870/173481[36:11<06:23,61.57it/s] 92%|#########2|159887/173481[39:00<03:44,60.46it/s] 93%|#########2|160675/173481[39:12<03:31,60.46it/s] 99%|#########9|172563/173481[42:00<00:14,65.06it/s]100%|#########9|173391/173481[42:12<00:01,65.06it/s]100%|##########|173481/173481[42:13<00:00,68.47it/s]
[32m[0324 03:32:07 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:2533.71 sec.
[32m[0324 03:32:08 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-3643101.
[32m[0324 03:32:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.33it/s]
20
[32m[0324 03:34:07 @monitor.py:363][0m QueueInput/queue_size: 1.033
[32m[0324 03:34:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.488
[32m[0324 03:34:07 @monitor.py:363][0m activation-summaries/output-rms: 0.041563
[32m[0324 03:34:07 @monitor.py:363][0m cross_entropy_loss: 1.6109
[32m[0324 03:34:07 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48113
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5404e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35748
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.244e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45241
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5568e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35049
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6136e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47213
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6677e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35101
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7026e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47478
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9915e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34952
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3854e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48927
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1577e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3533
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7455e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5861
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4048
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3238
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3158
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30613
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 03:34:07 @monitor.py:363][0m train-error-top1: 0.43089
[32m[0324 03:34:07 @monitor.py:363][0m val-error-top1: 0.43814
[32m[0324 03:34:07 @monitor.py:363][0m val-utt-error: 0.10121
[32m[0324 03:34:07 @monitor.py:363][0m validation_cost: 1.6461
[32m[0324 03:34:07 @monitor.py:363][0m wd_cost: 5.9102e-05
[32m[0324 03:34:07 @group.py:42][0m Callbacks took 120.089 sec in total. InferenceRunner: 118.898sec
[32m[0324 03:34:07 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12550/173481[03:00<38:28,69.72it/s]  8%|7         |13299/173481[03:10<38:17,69.72it/s] 15%|#4        |25688/173481[06:00<34:32,71.32it/s] 15%|#5        |26424/173481[06:10<34:22,71.32it/s] 21%|##1       |36528/173481[09:00<34:57,65.30it/s] 21%|##1       |37154/173481[09:10<34:47,65.30it/s] 27%|##6       |46814/173481[12:00<34:38,60.95it/s] 27%|##7       |47449/173481[12:10<34:27,60.95it/s] 34%|###3      |58370/173481[15:00<30:40,62.53it/s] 34%|###4      |59129/173481[15:10<30:28,62.53it/s] 41%|####      |70305/173481[18:00<26:43,64.36it/s] 41%|####      |70963/173481[18:10<26:32,64.36it/s] 47%|####6     |81290/173481[21:00<24:31,62.64it/s] 47%|####7     |81961/173481[21:11<24:20,62.64it/s] 53%|#####3    |92415/173481[24:00<21:42,62.22it/s] 54%|#####3    |93094/173481[24:11<21:31,62.22it/s] 60%|#####9    |103748/173481[27:00<18:34,62.59it/s] 60%|######    |104460/173481[27:11<18:22,62.59it/s] 66%|######6   |114898/173481[30:00<15:40,62.26it/s] 67%|######6   |115819/173481[30:11<15:26,62.26it/s] 73%|#######3  |126908/173481[33:00<12:03,64.41it/s] 74%|#######3  |127629/173481[33:11<11:51,64.41it/s] 80%|#######9  |138088/173481[36:00<09:19,63.24it/s] 80%|########  |138794/173481[36:11<09:08,63.24it/s] 86%|########6 |149405/173481[39:00<06:21,63.05it/s] 87%|########6 |150161/173481[39:11<06:09,63.05it/s] 93%|#########2|160808/173481[42:00<03:20,63.20it/s] 93%|#########3|161531/173481[42:12<03:09,63.20it/s] 99%|#########9|171885/173481[45:00<00:25,62.36it/s]100%|#########9|172836/173481[45:12<00:10,62.36it/s]100%|##########|173481/173481[45:21<00:00,63.73it/s]
[32m[0324 04:19:29 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:2721.96 sec.
[32m[0324 04:19:30 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-3816582.
[32m[0324 04:19:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,158.16it/s]
21
[32m[0324 04:21:29 @monitor.py:363][0m QueueInput/queue_size: 0.76397
[32m[0324 04:21:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.125
[32m[0324 04:21:29 @monitor.py:363][0m activation-summaries/output-rms: 0.04121
[32m[0324 04:21:29 @monitor.py:363][0m cross_entropy_loss: 1.6259
[32m[0324 04:21:29 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48151
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5417e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35761
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2389e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45282
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5627e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35054
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.618e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4724
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6772e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35107
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7034e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47517
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9885e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34959
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3906e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48971
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.158e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35335
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7487e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58916
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4052
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32403
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3159
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30622
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 04:21:29 @monitor.py:363][0m train-error-top1: 0.43066
[32m[0324 04:21:29 @monitor.py:363][0m val-error-top1: 0.43728
[32m[0324 04:21:29 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0324 04:21:29 @monitor.py:363][0m validation_cost: 1.6422
[32m[0324 04:21:29 @monitor.py:363][0m wd_cost: 5.9432e-05
[32m[0324 04:21:29 @group.py:42][0m Callbacks took 119.879 sec in total. InferenceRunner: 119.018sec
[32m[0324 04:21:29 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14205/173481[03:00<33:38,78.91it/s]  9%|8         |14997/173481[03:10<33:28,78.91it/s] 16%|#6        |27890/173481[06:00<31:20,77.44it/s] 16%|#6        |28473/173481[06:10<31:12,77.44it/s] 22%|##2       |38885/173481[09:00<32:50,68.29it/s] 23%|##2       |39558/173481[09:10<32:40,68.29it/s] 29%|##8       |49576/173481[12:00<32:30,63.53it/s] 29%|##8       |50194/173481[12:10<32:20,63.53it/s] 35%|###4      |60344/173481[15:00<30:36,61.61it/s] 35%|###5      |60973/173481[15:10<30:26,61.61it/s] 42%|####1     |72099/173481[18:00<26:38,63.40it/s] 42%|####1     |72858/173481[18:10<26:26,63.40it/s] 48%|####8     |83819/173481[21:00<23:15,64.24it/s] 49%|####8     |84507/173481[21:11<23:05,64.24it/s] 55%|#####5    |95458/173481[24:00<20:10,64.45it/s] 55%|#####5    |96193/173481[24:11<19:59,64.45it/s] 62%|######1   |106955/173481[27:00<17:16,64.16it/s] 62%|######2   |107764/173481[27:11<17:04,64.16it/s] 69%|######8   |119569/173481[30:00<13:24,66.98it/s] 69%|######9   |120383/173481[30:11<13:12,66.98it/s] 76%|#######6  |132114/173481[33:00<10:05,68.31it/s] 77%|#######6  |132911/173481[33:11<09:53,68.31it/s] 83%|########3 |144633/173481[36:00<06:58,68.92it/s] 84%|########3 |145622/173481[36:11<06:44,68.92it/s] 90%|######### |156904/173481[39:00<04:02,68.47it/s] 91%|######### |157023/173481[39:12<04:00,68.47it/s] 97%|#########7|169059/173481[42:00<01:05,67.99it/s] 98%|#########7|169828/173481[42:12<00:53,67.99it/s]100%|##########|173481/173481[43:08<00:00,67.01it/s]
[32m[0324 05:04:38 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:2588.78 sec.
[32m[0324 05:04:38 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-3990063.
[32m[0324 05:04:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.81it/s]
22
[32m[0324 05:06:36 @monitor.py:363][0m QueueInput/queue_size: 0.64253
[32m[0324 05:06:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.127
[32m[0324 05:06:36 @monitor.py:363][0m activation-summaries/output-rms: 0.040804
[32m[0324 05:06:36 @monitor.py:363][0m cross_entropy_loss: 1.5732
[32m[0324 05:06:36 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48169
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5391e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35763
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2396e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45309
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5619e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35057
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6175e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47266
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6697e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35108
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7054e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47543
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9889e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34966
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3892e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49004
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1611e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35338
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7476e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59093
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4054
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32413
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31595
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30626
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 05:06:36 @monitor.py:363][0m train-error-top1: 0.43104
[32m[0324 05:06:36 @monitor.py:363][0m val-error-top1: 0.4374
[32m[0324 05:06:36 @monitor.py:363][0m val-utt-error: 0.09983
[32m[0324 05:06:36 @monitor.py:363][0m validation_cost: 1.6415
[32m[0324 05:06:36 @monitor.py:363][0m wd_cost: 1.1924e-05
[32m[0324 05:06:36 @group.py:42][0m Callbacks took 118.342 sec in total. InferenceRunner: 117.793sec
[32m[0324 05:06:36 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14738/173481[03:00<32:18,81.87it/s]  9%|8         |15562/173481[03:10<32:08,81.87it/s] 15%|#5        |26149/173481[06:00<34:21,71.46it/s] 15%|#5        |26870/173481[06:10<34:11,71.46it/s] 22%|##1       |38042/173481[09:00<32:52,68.66it/s] 22%|##2       |38896/173481[09:10<32:40,68.66it/s] 29%|##9       |50568/173481[12:00<29:38,69.12it/s] 30%|##9       |51287/173481[12:10<29:27,69.12it/s] 36%|###6      |62800/173481[15:00<26:55,68.53it/s] 37%|###6      |63562/173481[15:10<26:43,68.53it/s] 44%|####3     |76317/173481[18:00<22:35,71.66it/s] 44%|####4     |77185/173481[18:10<22:23,71.66it/s] 51%|#####1    |88911/173481[21:00<19:54,70.80it/s] 52%|#####1    |89777/173481[21:11<19:42,70.80it/s] 59%|#####8    |101774/173481[24:00<16:48,71.13it/s] 59%|#####9    |102638/173481[24:11<16:35,71.13it/s] 67%|######6   |115618/173481[27:00<13:02,73.91it/s] 67%|######7   |116482/173481[27:11<12:51,73.91it/s] 74%|#######3  |128030/173481[30:00<10:37,71.34it/s] 74%|#######4  |128822/173481[30:11<10:25,71.34it/s] 81%|########  |140358/173481[33:00<07:53,69.88it/s] 81%|########1 |141169/173481[33:11<07:42,69.88it/s] 89%|########8 |153832/173481[36:00<04:31,72.28it/s] 89%|########9 |154861/173481[36:11<04:17,72.28it/s] 97%|#########7|168428/173481[39:00<01:06,76.43it/s] 98%|#########7|169445/173481[39:12<00:52,76.43it/s]100%|##########|173481/173481[39:58<00:00,72.32it/s]
[32m[0324 05:46:35 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:2398.80 sec.
[32m[0324 05:46:35 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-4163544.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.20it/s]
23
[32m[0324 05:48:36 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 05:48:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.55
[32m[0324 05:48:36 @monitor.py:363][0m activation-summaries/output-rms: 0.041291
[32m[0324 05:48:36 @monitor.py:363][0m cross_entropy_loss: 1.6269
[32m[0324 05:48:36 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48182
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5426e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.3577
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45342
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.563e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35061
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6147e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47284
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6626e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35111
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7067e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47562
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9912e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34969
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3903e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49031
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1583e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35341
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7447e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59266
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4057
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32424
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.316
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30629
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 05:48:36 @monitor.py:363][0m train-error-top1: 0.4398
[32m[0324 05:48:36 @monitor.py:363][0m val-error-top1: 0.43676
[32m[0324 05:48:36 @monitor.py:363][0m val-utt-error: 0.10217
[32m[0324 05:48:36 @monitor.py:363][0m validation_cost: 1.6404
[32m[0324 05:48:36 @monitor.py:363][0m wd_cost: 1.1961e-05
[32m[0324 05:48:36 @group.py:42][0m Callbacks took 120.645 sec in total. InferenceRunner: 120.517sec
[32m[0324 05:48:36 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15943/173481[03:00<29:38,88.57it/s] 10%|9         |16838/173481[03:10<29:28,88.57it/s] 18%|#8        |31827/173481[06:00<26:42,88.40it/s] 19%|#8        |32615/173481[06:10<26:33,88.40it/s] 27%|##6       |46497/173481[09:00<24:58,84.73it/s] 27%|##6       |46606/173481[09:10<24:57,84.73it/s] 33%|###3      |57666/173481[12:00<26:56,71.64it/s] 34%|###3      |58433/173481[12:10<26:45,71.64it/s] 42%|####2     |73561/173481[15:00<21:03,79.10it/s] 43%|####2     |74518/173481[15:10<20:51,79.10it/s] 52%|#####1    |89876/173481[18:00<16:29,84.48it/s] 52%|#####2    |90886/173481[18:10<16:17,84.48it/s] 61%|######1   |106110/173481[21:00<12:52,87.24it/s] 62%|######1   |107091/173481[21:11<12:41,87.24it/s] 70%|#######   |122009/173481[24:00<09:46,87.78it/s] 71%|#######   |122721/173481[24:11<09:38,87.78it/s] 79%|#######8  |136597/173481[27:00<07:17,84.28it/s] 79%|#######9  |137590/173481[27:11<07:05,84.28it/s] 88%|########8 |152839/173481[30:00<03:56,87.15it/s] 89%|########8 |153901/173481[30:11<03:44,87.15it/s] 97%|#########6|168113/173481[33:00<01:02,85.99it/s] 97%|#########7|169062/173481[33:11<00:51,85.99it/s]100%|##########|173481/173481[34:05<00:00,84.81it/s]
[32m[0324 06:22:41 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:2045.48 sec.
[32m[0324 06:22:42 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-4337025.
[32m[0324 06:22:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.21it/s]
24
[32m[0324 06:24:37 @monitor.py:363][0m QueueInput/queue_size: 0.56867
[32m[0324 06:24:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.584
[32m[0324 06:24:37 @monitor.py:363][0m activation-summaries/output-rms: 0.042256
[32m[0324 06:24:37 @monitor.py:363][0m cross_entropy_loss: 1.6117
[32m[0324 06:24:37 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48194
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5412e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35769
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.238e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45363
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5621e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35068
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6136e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47292
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6631e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35113
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7069e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47572
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9867e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34969
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3929e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49052
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1568e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35342
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7461e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59379
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4058
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31602
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30631
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 06:24:37 @monitor.py:363][0m train-error-top1: 0.43657
[32m[0324 06:24:37 @monitor.py:363][0m val-error-top1: 0.43725
[32m[0324 06:24:37 @monitor.py:363][0m val-utt-error: 0.10116
[32m[0324 06:24:37 @monitor.py:363][0m validation_cost: 1.642
[32m[0324 06:24:37 @monitor.py:363][0m wd_cost: 2.397e-06
[32m[0324 06:24:37 @group.py:42][0m Callbacks took 115.904 sec in total. InferenceRunner: 114.639sec
[32m[0324 06:24:37 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14030/173481[03:00<34:05,77.94it/s]  9%|8         |14851/173481[03:10<33:55,77.94it/s] 17%|#6        |28958/173481[06:00<29:58,80.36it/s] 17%|#7        |29788/173481[06:10<29:48,80.36it/s] 26%|##5       |44376/173481[09:00<25:56,82.92it/s] 26%|##6       |45267/173481[09:10<25:46,82.92it/s] 35%|###5      |60724/173481[12:00<21:40,86.69it/s] 36%|###5      |61615/173481[12:10<21:30,86.69it/s] 43%|####3     |75254/173481[15:00<19:34,83.60it/s] 44%|####3     |76110/173481[15:10<19:24,83.60it/s] 51%|#####     |88446/173481[18:00<18:08,78.10it/s] 51%|#####1    |89315/173481[18:10<17:57,78.10it/s] 58%|#####8    |100701/173481[21:00<16:40,72.75it/s] 58%|#####8    |101415/173481[21:11<16:30,72.75it/s] 65%|######4   |112508/173481[24:00<14:43,68.98it/s] 65%|######5   |113260/173481[24:11<14:32,68.98it/s] 72%|#######1  |124486/173481[27:00<12:03,67.74it/s] 72%|#######2  |125246/173481[27:11<11:52,67.74it/s] 78%|#######8  |136113/173481[30:00<09:25,66.13it/s] 79%|#######8  |136640/173481[30:11<09:17,66.13it/s] 85%|########5 |147675/173481[33:00<06:36,65.17it/s] 86%|########5 |148423/173481[33:11<06:24,65.17it/s] 92%|#########1|158968/173481[36:00<03:47,63.93it/s] 92%|#########2|159723/173481[36:11<03:35,63.93it/s] 99%|#########9|171871/173481[39:00<00:23,67.58it/s]100%|#########9|172680/173481[39:12<00:11,67.58it/s]100%|##########|173481/173481[39:23<00:00,73.39it/s]
[32m[0324 07:04:01 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:2363.98 sec.
[32m[0324 07:04:01 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.40it/s]
25
[32m[0324 07:06:03 @monitor.py:363][0m QueueInput/queue_size: 0.76948
[32m[0324 07:06:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.612
[32m[0324 07:06:03 @monitor.py:363][0m activation-summaries/output-rms: 0.041609
[32m[0324 07:06:03 @monitor.py:363][0m cross_entropy_loss: 1.6043
[32m[0324 07:06:03 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48202
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5415e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35771
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2375e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45372
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5614e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35069
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6145e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47298
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6646e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35115
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7082e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47579
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.985e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34971
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3936e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49064
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1562e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35346
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7464e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59467
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.406
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32436
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31604
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30632
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 07:06:03 @monitor.py:363][0m train-error-top1: 0.43035
[32m[0324 07:06:03 @monitor.py:363][0m val-error-top1: 0.43726
[32m[0324 07:06:03 @monitor.py:363][0m val-utt-error: 0.10142
[32m[0324 07:06:03 @monitor.py:363][0m validation_cost: 1.6422
[32m[0324 07:06:03 @monitor.py:363][0m wd_cost: 2.4008e-06
[32m[0324 07:06:03 @group.py:42][0m Callbacks took 121.356 sec in total. InferenceRunner: 121.135sec
[32m[0324 07:06:03 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12475/173481[03:00<38:43,69.30it/s]  8%|7         |13220/173481[03:10<38:32,69.30it/s] 15%|#4        |25575/173481[06:00<34:43,71.00it/s] 15%|#5        |26311/173481[06:10<34:32,71.00it/s] 22%|##1       |37523/173481[09:00<33:01,68.61it/s] 22%|##1       |38128/173481[09:10<32:52,68.61it/s] 28%|##7       |48143/173481[12:00<32:55,63.44it/s] 28%|##8       |48795/173481[12:10<32:45,63.44it/s] 34%|###4      |59370/173481[15:00<30:14,62.90it/s] 35%|###4      |60054/173481[15:10<30:03,62.90it/s] 41%|####      |70359/173481[18:00<27:44,61.96it/s] 41%|####      |71061/173481[18:10<27:33,61.96it/s] 47%|####7     |81847/173481[21:00<24:17,62.88it/s] 48%|####7     |82552/173481[21:11<24:06,62.88it/s] 54%|#####3    |93570/173481[24:00<20:49,63.98it/s] 54%|#####4    |94318/173481[24:11<20:37,63.98it/s] 61%|######    |105061/173481[27:00<17:50,63.91it/s] 61%|######    |105804/173481[27:11<17:38,63.91it/s] 67%|######7   |116800/173481[30:00<14:38,64.55it/s] 68%|######7   |117534/173481[30:11<14:26,64.55it/s] 74%|#######3  |127857/173481[33:00<12:04,62.95it/s] 74%|#######4  |128584/173481[33:11<11:53,62.95it/s] 80%|#######9  |138611/173481[36:00<09:28,61.31it/s] 80%|########  |139339/173481[36:11<09:16,61.31it/s] 86%|########6 |149450/173481[39:00<06:35,60.74it/s] 87%|########6 |150195/173481[39:12<06:23,60.74it/s] 93%|#########2|160818/173481[42:00<03:24,61.93it/s] 93%|#########3|161597/173481[42:12<03:11,61.93it/s] 99%|#########8|171481/173481[45:00<00:33,60.55it/s] 99%|#########9|172375/173481[45:12<00:18,60.55it/s]100%|##########|173481/173481[45:27<00:00,63.61it/s]
[32m[0324 07:51:30 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:2727.37 sec.
[32m[0324 07:51:30 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:23<00:00,130.75it/s]
26
[32m[0324 07:53:54 @monitor.py:363][0m QueueInput/queue_size: 0.98401
[32m[0324 07:53:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.009
[32m[0324 07:53:54 @monitor.py:363][0m activation-summaries/output-rms: 0.04125
[32m[0324 07:53:54 @monitor.py:363][0m cross_entropy_loss: 1.6228
[32m[0324 07:53:54 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48212
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5407e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35773
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2389e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4538
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5617e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35067
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6131e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47303
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6642e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35116
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7083e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47588
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9845e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34972
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3944e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49072
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1549e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35346
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7459e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59557
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4061
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3244
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31606
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30633
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 07:53:54 @monitor.py:363][0m train-error-top1: 0.43224
[32m[0324 07:53:54 @monitor.py:363][0m val-error-top1: 0.43674
[32m[0324 07:53:54 @monitor.py:363][0m val-utt-error: 0.099192
[32m[0324 07:53:54 @monitor.py:363][0m validation_cost: 1.6403
[32m[0324 07:53:54 @monitor.py:363][0m wd_cost: 2.4046e-06
[32m[0324 07:53:54 @group.py:42][0m Callbacks took 144.262 sec in total. InferenceRunner: 143.968sec
[32m[0324 07:53:54 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13714/173481[03:00<34:57,76.18it/s]  8%|8         |14455/173481[03:10<34:47,76.18it/s] 15%|#5        |26798/173481[06:00<32:51,74.39it/s] 16%|#5        |27530/173481[06:10<32:41,74.39it/s] 23%|##2       |39657/173481[09:00<30:36,72.89it/s] 23%|##3       |40399/173481[09:10<30:25,72.89it/s] 29%|##9       |51091/173481[12:00<30:02,67.88it/s] 30%|##9       |51751/173481[12:10<29:53,67.88it/s] 36%|###5      |61901/173481[15:00<29:10,63.73it/s] 36%|###6      |62594/173481[15:10<28:59,63.73it/s] 43%|####2     |73754/173481[18:00<25:39,64.77it/s] 43%|####2     |74483/173481[18:10<25:28,64.77it/s] 49%|####9     |85713/173481[21:00<22:18,65.59it/s] 50%|####9     |86458/173481[21:11<22:06,65.59it/s] 56%|#####6    |97350/173481[24:00<19:29,65.12it/s] 57%|#####6    |98039/173481[24:11<19:18,65.12it/s] 63%|######2   |108599/173481[27:00<16:57,63.77it/s] 63%|######2   |109287/173481[27:11<16:46,63.77it/s] 70%|######9   |120744/173481[30:00<13:24,65.57it/s] 70%|######9   |121428/173481[30:11<13:13,65.57it/s] 76%|#######6  |132049/173481[33:00<10:45,64.15it/s] 77%|#######6  |132784/173481[33:11<10:34,64.15it/s] 83%|########2 |143691/173481[36:00<07:42,64.41it/s] 83%|########3 |144474/173481[36:11<07:30,64.41it/s] 89%|########9 |154569/173481[39:00<05:03,62.36it/s] 90%|########9 |155551/173481[39:11<04:47,62.36it/s] 96%|#########6|167296/173481[42:00<01:33,66.27it/s] 97%|#########6|168073/173481[42:12<01:21,66.27it/s]100%|##########|173481/173481[43:34<00:00,66.36it/s]
[32m[0324 08:37:28 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:2614.15 sec.
[32m[0324 08:37:29 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-4857468.
[32m[0324 08:37:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.28it/s]
27
[32m[0324 08:39:37 @monitor.py:363][0m QueueInput/queue_size: 0.72051
[32m[0324 08:39:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.862
[32m[0324 08:39:37 @monitor.py:363][0m activation-summaries/output-rms: 0.040855
[32m[0324 08:39:37 @monitor.py:363][0m cross_entropy_loss: 1.5712
[32m[0324 08:39:37 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48218
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35773
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2392e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45386
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5605e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35067
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6137e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4731
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6632e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35116
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7085e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47594
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9846e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34974
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3955e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49082
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1548e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35347
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7468e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59611
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4062
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32443
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31607
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30634
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 08:39:37 @monitor.py:363][0m train-error-top1: 0.4298
[32m[0324 08:39:37 @monitor.py:363][0m val-error-top1: 0.43684
[32m[0324 08:39:37 @monitor.py:363][0m val-utt-error: 0.098449
[32m[0324 08:39:37 @monitor.py:363][0m validation_cost: 1.6391
[32m[0324 08:39:37 @monitor.py:363][0m wd_cost: 4.8136e-07
[32m[0324 08:39:37 @group.py:42][0m Callbacks took 128.229 sec in total. InferenceRunner: 127.809sec
[32m[0324 08:39:37 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14518/173481[03:00<32:50,80.65it/s]  9%|8         |15139/173481[03:10<32:43,80.65it/s] 15%|#4        |25383/173481[06:00<35:45,69.04it/s] 15%|#4        |26007/173481[06:10<35:36,69.04it/s] 21%|##1       |36931/173481[09:00<34:13,66.51it/s] 22%|##1       |37644/173481[09:10<34:02,66.51it/s] 28%|##8       |48857/173481[12:00<31:17,66.38it/s] 29%|##8       |49612/173481[12:10<31:06,66.38it/s] 35%|###4      |60454/173481[15:00<28:48,65.39it/s] 35%|###5      |61148/173481[15:10<28:37,65.39it/s] 42%|####1     |72384/173481[18:00<25:35,65.83it/s] 42%|####2     |73122/173481[18:10<25:24,65.83it/s] 48%|####8     |83429/173481[21:00<23:37,63.52it/s] 49%|####8     |84332/173481[21:11<23:23,63.52it/s] 55%|#####5    |96064/173481[24:00<19:20,66.69it/s] 56%|#####5    |96812/173481[24:11<19:09,66.69it/s] 62%|######2   |108103/173481[27:00<16:18,66.78it/s] 63%|######2   |108849/173481[27:11<16:07,66.78it/s] 69%|######9   |120118/173481[30:00<13:19,66.77it/s] 70%|######9   |120908/173481[30:11<13:07,66.77it/s] 76%|#######6  |132138/173481[33:00<10:19,66.77it/s] 77%|#######6  |132887/173481[33:11<10:07,66.77it/s] 83%|########3 |144112/173481[36:00<07:20,66.65it/s] 84%|########3 |145045/173481[36:11<07:06,66.65it/s] 90%|######### |156373/173481[39:00<04:13,67.37it/s] 91%|######### |157136/173481[39:11<04:02,67.37it/s] 97%|#########7|168388/173481[42:00<01:15,67.06it/s] 98%|#########7|169210/173481[42:12<01:03,67.06it/s]100%|##########|173481/173481[43:19<00:00,66.74it/s]
[32m[0324 09:22:56 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:2599.22 sec.
[32m[0324 09:22:56 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-5030949.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:10<00:00,144.29it/s]
28
[32m[0324 09:25:06 @monitor.py:363][0m QueueInput/queue_size: 0.68971
[32m[0324 09:25:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.772
[32m[0324 09:25:06 @monitor.py:363][0m activation-summaries/output-rms: 0.040438
[32m[0324 09:25:06 @monitor.py:363][0m cross_entropy_loss: 1.6141
[32m[0324 09:25:06 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48221
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5407e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35775
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2395e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45393
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5609e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35068
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6141e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47315
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6639e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35116
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7085e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47599
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9844e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34974
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3957e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49089
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1552e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35347
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7457e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59655
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4063
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32445
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31608
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30635
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 09:25:06 @monitor.py:363][0m train-error-top1: 0.4298
[32m[0324 09:25:06 @monitor.py:363][0m val-error-top1: 0.43637
[32m[0324 09:25:06 @monitor.py:363][0m val-utt-error: 0.10089
[32m[0324 09:25:06 @monitor.py:363][0m validation_cost: 1.6374
[32m[0324 09:25:06 @monitor.py:363][0m wd_cost: 4.8174e-07
[32m[0324 09:25:06 @group.py:42][0m Callbacks took 130.637 sec in total. InferenceRunner: 130.453sec
[32m[0324 09:25:06 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12947/173481[03:00<37:15,71.82it/s]  8%|8         |14401/173481[03:20<36:55,71.82it/s] 15%|#5        |26297/173481[06:00<33:37,72.97it/s] 16%|#5        |27033/173481[06:10<33:27,72.97it/s] 23%|##2       |39397/173481[09:00<30:40,72.87it/s] 23%|##3       |40141/173481[09:10<30:29,72.87it/s] 30%|###       |52582/173481[12:00<27:34,73.06it/s] 31%|###       |53316/173481[12:10<27:24,73.06it/s] 38%|###7      |65519/173481[15:00<24:50,72.46it/s] 38%|###8      |66267/173481[15:10<24:39,72.46it/s] 45%|####4     |77840/173481[18:00<22:38,70.39it/s] 45%|####5     |78750/173481[18:10<22:25,70.39it/s] 54%|#####3    |93130/173481[21:00<17:23,76.99it/s] 54%|#####4    |94039/173481[21:11<17:11,76.99it/s] 62%|######2   |108391/173481[24:00<13:26,80.70it/s] 63%|######3   |109312/173481[24:11<13:15,80.70it/s] 71%|#######1  |123631/173481[27:00<10:03,82.63it/s] 72%|#######1  |124571/173481[27:11<09:51,82.63it/s] 80%|#######9  |138122/173481[30:00<07:13,81.54it/s] 80%|#######9  |138502/173481[30:11<07:08,81.54it/s] 87%|########6 |150563/173481[33:00<05:06,74.81it/s] 87%|########7 |151281/173481[33:11<04:56,74.81it/s] 93%|#########3|161822/173481[36:00<02:51,68.13it/s] 94%|#########3|162546/173481[36:11<02:40,68.13it/s]100%|#########9|172794/173481[39:00<00:10,64.34it/s]100%|#########9|173451/173481[39:12<00:00,64.34it/s]100%|##########|173481/173481[39:12<00:00,73.74it/s]
[32m[0324 10:04:19 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:2352.55 sec.
[32m[0324 10:04:19 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-5204430.
[32m[0324 10:04:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,140.71it/s]
29
[32m[0324 10:06:34 @monitor.py:363][0m QueueInput/queue_size: 0.97681
[32m[0324 10:06:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.023
[32m[0324 10:06:34 @monitor.py:363][0m activation-summaries/output-rms: 0.042239
[32m[0324 10:06:34 @monitor.py:363][0m cross_entropy_loss: 1.6101
[32m[0324 10:06:34 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48224
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.541e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35774
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.454
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5609e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6147e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47318
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6647e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35117
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7084e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47604
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9837e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34974
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3968e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49095
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1553e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35347
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7457e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59697
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4063
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32447
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31608
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30635
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 10:06:34 @monitor.py:363][0m train-error-top1: 0.43522
[32m[0324 10:06:34 @monitor.py:363][0m val-error-top1: 0.43701
[32m[0324 10:06:34 @monitor.py:363][0m val-utt-error: 0.10041
[32m[0324 10:06:34 @monitor.py:363][0m validation_cost: 1.6405
[32m[0324 10:06:34 @monitor.py:363][0m wd_cost: 4.821e-07
[32m[0324 10:06:34 @group.py:42][0m Callbacks took 134.544 sec in total. InferenceRunner: 133.781sec
[32m[0324 10:06:34 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13503/173481[03:00<35:32,75.01it/s]  8%|8         |14291/173481[03:10<35:22,75.01it/s] 16%|#5        |27369/173481[06:00<32:02,76.01it/s] 16%|#6        |28041/173481[06:10<31:53,76.01it/s] 22%|##2       |38291/173481[09:00<33:23,67.47it/s] 22%|##2       |38913/173481[09:10<33:14,67.47it/s] 28%|##8       |49394/173481[12:00<32:05,64.45it/s] 29%|##8       |50027/173481[12:10<31:55,64.45it/s] 35%|###4      |60506/173481[15:00<29:51,63.06it/s] 35%|###5      |61120/173481[15:10<29:41,63.06it/s] 41%|####1     |71410/173481[18:00<27:31,61.79it/s] 42%|####1     |72035/173481[18:10<27:21,61.79it/s] 48%|####7     |82935/173481[21:00<23:59,62.89it/s] 48%|####8     |83625/173481[21:11<23:48,62.89it/s] 54%|#####4    |94276/173481[24:00<20:58,62.94it/s] 55%|#####4    |95008/173481[24:11<20:46,62.94it/s] 61%|######    |105569/173481[27:00<18:00,62.84it/s] 61%|######1   |106284/173481[27:11<17:49,62.84it/s] 67%|######7   |116291/173481[30:00<15:35,61.16it/s] 67%|######7   |117045/173481[30:11<15:22,61.16it/s] 74%|#######3  |128081/173481[33:00<11:57,63.25it/s] 74%|#######4  |128851/173481[33:11<11:45,63.25it/s] 80%|########  |139376/173481[36:00<09:01,62.99it/s] 81%|########  |140083/173481[36:11<08:50,62.99it/s] 87%|########6 |150281/173481[39:00<06:15,61.76it/s] 87%|########7 |151000/173481[39:12<06:04,61.76it/s] 93%|#########2|161221/173481[42:00<03:20,61.26it/s] 93%|#########3|161971/173481[42:12<03:07,61.26it/s]100%|#########9|173002/173481[45:00<00:07,63.29it/s]100%|##########|173481/173481[45:06<00:00,64.09it/s]
[32m[0324 10:51:41 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:2706.95 sec.
[32m[0324 10:51:41 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-5377911.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,128.98it/s]
30
[32m[0324 10:54:07 @monitor.py:363][0m QueueInput/queue_size: 0.7346
[32m[0324 10:54:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.949
[32m[0324 10:54:07 @monitor.py:363][0m activation-summaries/output-rms: 0.041616
[32m[0324 10:54:07 @monitor.py:363][0m cross_entropy_loss: 1.6042
[32m[0324 10:54:07 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48227
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5408e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35775
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2389e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45402
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5606e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6147e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47319
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35117
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7082e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47605
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9837e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34974
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3968e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49098
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1556e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35347
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7458e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59716
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32448
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30635
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 10:54:07 @monitor.py:363][0m train-error-top1: 0.43146
[32m[0324 10:54:07 @monitor.py:363][0m val-error-top1: 0.43693
[32m[0324 10:54:07 @monitor.py:363][0m val-utt-error: 0.10105
[32m[0324 10:54:07 @monitor.py:363][0m validation_cost: 1.6414
[32m[0324 10:54:07 @monitor.py:363][0m wd_cost: 9.645e-08
[32m[0324 10:54:07 @group.py:42][0m Callbacks took 146.112 sec in total. InferenceRunner: 145.946sec
[32m[0324 10:54:07 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11890/173481[03:00<40:46,66.05it/s]  7%|7         |12521/173481[03:10<40:36,66.05it/s] 13%|#3        |22805/173481[06:00<39:43,63.22it/s] 13%|#3        |23390/173481[06:10<39:33,63.22it/s] 20%|##        |35034/173481[09:00<35:13,65.50it/s] 21%|##        |35693/173481[09:10<35:03,65.50it/s] 27%|##7       |47063/173481[12:00<31:51,66.15it/s] 28%|##7       |47779/173481[12:10<31:40,66.15it/s] 34%|###4      |59111/173481[15:00<28:38,66.54it/s] 35%|###4      |59859/173481[15:10<28:27,66.54it/s] 41%|####1     |71220/173481[18:00<25:28,66.90it/s] 41%|####1     |71915/173481[18:10<25:18,66.90it/s] 48%|####7     |82676/173481[21:00<23:12,65.23it/s] 48%|####8     |83389/173481[21:11<23:01,65.23it/s] 54%|#####4    |94145/173481[24:00<20:30,64.46it/s] 55%|#####4    |94849/173481[24:11<20:19,64.46it/s] 61%|######1   |106568/173481[27:00<16:43,66.66it/s] 62%|######1   |107536/173481[27:11<16:29,66.66it/s] 70%|#######   |121921/173481[30:00<11:28,74.83it/s] 71%|#######   |122940/173481[30:11<11:15,74.83it/s] 78%|#######8  |135356/173481[33:00<08:30,74.74it/s] 78%|#######8  |135959/173481[33:11<08:22,74.74it/s] 84%|########3 |145668/173481[36:00<07:08,64.86it/s] 84%|########4 |146398/173481[36:11<06:57,64.86it/s] 91%|######### |157154/173481[39:00<04:13,64.33it/s] 91%|#########1|158162/173481[39:12<03:58,64.33it/s] 97%|#########7|168790/173481[42:00<01:12,64.48it/s] 98%|#########7|169600/173481[42:12<01:00,64.48it/s]100%|##########|173481/173481[43:15<00:00,66.85it/s]
[32m[0324 11:37:22 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:2595.08 sec.
[32m[0324 11:37:22 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.05it/s]
31
[32m[0324 11:39:48 @monitor.py:363][0m QueueInput/queue_size: 1.1271
[32m[0324 11:39:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.276
[32m[0324 11:39:48 @monitor.py:363][0m activation-summaries/output-rms: 0.041272
[32m[0324 11:39:48 @monitor.py:363][0m cross_entropy_loss: 1.6211
[32m[0324 11:39:48 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48229
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5408e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35775
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2387e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45404
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5604e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6149e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4732
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35117
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7077e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47607
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34974
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3969e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49099
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1554e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35347
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7457e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59733
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32449
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 11:39:48 @monitor.py:363][0m train-error-top1: 0.43044
[32m[0324 11:39:48 @monitor.py:363][0m val-error-top1: 0.43644
[32m[0324 11:39:48 @monitor.py:363][0m val-utt-error: 0.098449
[32m[0324 11:39:48 @monitor.py:363][0m validation_cost: 1.6387
[32m[0324 11:39:48 @monitor.py:363][0m wd_cost: 9.648e-08
[32m[0324 11:39:48 @group.py:42][0m Callbacks took 146.047 sec in total. InferenceRunner: 145.869sec
[32m[0324 11:39:48 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13941/173481[03:00<34:19,77.45it/s]  8%|8         |14739/173481[03:10<34:09,77.45it/s] 16%|#5        |27399/173481[06:00<32:00,76.08it/s] 16%|#6        |28154/173481[06:10<31:50,76.08it/s] 22%|##2       |38364/173481[09:00<33:17,67.65it/s] 22%|##2       |38999/173481[09:10<33:07,67.65it/s] 28%|##8       |48972/173481[12:00<32:56,62.99it/s] 29%|##8       |49590/173481[12:10<32:46,62.99it/s] 34%|###4      |59424/173481[15:00<31:27,60.43it/s] 35%|###4      |60070/173481[15:10<31:16,60.43it/s] 41%|####      |70626/173481[18:00<27:57,61.32it/s] 41%|####1     |71255/173481[18:10<27:47,61.32it/s] 47%|####7     |82187/173481[21:00<24:15,62.74it/s] 48%|####7     |82989/173481[21:11<24:02,62.74it/s] 54%|#####4    |94246/173481[24:00<20:22,64.79it/s] 55%|#####4    |95048/173481[24:11<20:10,64.79it/s] 61%|######    |105534/173481[27:00<17:46,63.73it/s] 61%|######1   |106230/173481[27:11<17:35,63.73it/s] 68%|######7   |117265/173481[30:00<14:32,64.44it/s] 68%|######8   |117978/173481[30:11<14:21,64.44it/s] 74%|#######4  |128402/173481[33:00<11:54,63.13it/s] 74%|#######4  |129033/173481[33:11<11:44,63.13it/s] 80%|#######9  |138200/173481[36:00<10:03,58.46it/s] 80%|########  |138953/173481[36:11<09:50,58.46it/s] 85%|########5 |148009/173481[39:00<07:31,56.40it/s] 86%|########5 |148670/173481[39:12<07:19,56.40it/s] 91%|######### |157864/173481[42:00<04:41,55.56it/s] 91%|#########1|158443/173481[42:12<04:30,55.56it/s] 95%|#########5|165303/173481[45:00<02:52,47.40it/s] 96%|#########5|165753/173481[45:12<02:43,47.40it/s] 99%|#########9|172606/173481[48:00<00:20,43.72it/s]100%|#########9|173059/173481[48:12<00:09,43.72it/s]100%|##########|173481/173481[48:23<00:00,59.75it/s]
[32m[0324 12:28:11 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:2903.58 sec.
[32m[0324 12:28:12 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-5724873.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:55<00:00,107.16it/s]
32
[32m[0324 12:31:07 @monitor.py:363][0m QueueInput/queue_size: 0.52738
[32m[0324 12:31:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.069
[32m[0324 12:31:07 @monitor.py:363][0m activation-summaries/output-rms: 0.040848
[32m[0324 12:31:07 @monitor.py:363][0m cross_entropy_loss: 1.5701
[32m[0324 12:31:07 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48232
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5404e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35775
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2389e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45406
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5605e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6149e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47322
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.665e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35117
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7077e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47608
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9834e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3969e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49102
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59744
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 12:31:07 @monitor.py:363][0m train-error-top1: 0.43062
[32m[0324 12:31:07 @monitor.py:363][0m val-error-top1: 0.43689
[32m[0324 12:31:07 @monitor.py:363][0m val-utt-error: 0.099086
[32m[0324 12:31:07 @monitor.py:363][0m validation_cost: 1.6388
[32m[0324 12:31:07 @monitor.py:363][0m wd_cost: 9.65e-08
[32m[0324 12:31:07 @group.py:42][0m Callbacks took 175.889 sec in total. InferenceRunner: 175.669sec
[32m[0324 12:31:07 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7765/173481[03:00<1:04:01,43.14it/s]  5%|4         |8152/173481[03:10<1:03:52,43.14it/s]  9%|8         |15268/173481[06:00<1:02:11,42.40it/s]  9%|9         |15657/173481[06:10<1:02:02,42.40it/s] 13%|#3        |22638/173481[09:00<1:00:21,41.66it/s] 13%|#3        |23094/173481[09:10<1:00:10,41.66it/s] 17%|#7        |30268/173481[12:00<56:48,42.02it/s]   18%|#7        |30706/173481[12:10<56:38,42.02it/s] 22%|##1       |37533/173481[15:00<55:03,41.16it/s] 22%|##1       |37917/173481[15:10<54:53,41.16it/s] 25%|##5       |43675/173481[18:00<57:59,37.31it/s] 25%|##5       |44050/173481[18:10<57:49,37.31it/s] 29%|##8       |49547/173481[21:00<59:20,34.81it/s] 29%|##8       |49867/173481[21:11<59:11,34.81it/s] 32%|###1      |55218/173481[24:00<59:35,33.07it/s] 32%|###2      |55577/173481[24:11<59:25,33.07it/s] 35%|###5      |61329/173481[27:00<55:47,33.50it/s] 36%|###5      |61697/173481[27:11<55:36,33.50it/s] 39%|###9      |67707/173481[30:00<51:11,34.44it/s] 39%|###9      |68119/173481[30:11<50:59,34.44it/s] 43%|####3     |75092/173481[33:00<43:47,37.45it/s] 44%|####3     |75574/173481[33:11<43:34,37.45it/s] 48%|####7     |82973/173481[36:00<37:22,40.37it/s] 48%|####8     |83502/173481[36:11<37:09,40.37it/s] 52%|#####2    |91066/173481[39:00<32:17,42.54it/s] 53%|#####2    |91607/173481[39:12<32:04,42.54it/s] 57%|#####7    |99454/173481[42:00<27:44,44.48it/s] 58%|#####7    |100033/173481[42:12<27:31,44.48it/s] 63%|######2   |108523/173481[45:00<22:55,47.24it/s] 63%|######2   |109112/173481[45:12<22:42,47.24it/s] 68%|######7   |117889/173481[48:00<18:42,49.52it/s] 68%|######8   |118463/173481[48:12<18:31,49.52it/s] 73%|#######3  |127338/173481[51:00<15:05,50.96it/s] 74%|#######3  |128015/173481[51:12<14:52,50.96it/s] 79%|#######8  |136893/173481[54:00<11:43,52.00it/s] 79%|#######9  |137576/173481[54:12<11:30,52.00it/s] 84%|########4 |146423/173481[57:00<08:35,52.47it/s] 85%|########4 |147089/173481[57:13<08:23,52.47it/s] 90%|########9 |155833/173481[1:00:00<05:36,52.37it/s] 90%|######### |156512/173481[1:00:13<05:24,52.37it/s] 95%|#########5|165089/173481[1:03:00<02:41,51.89it/s] 96%|#########5|165757/173481[1:03:13<02:28,51.89it/s]100%|##########|173481/173481[1:05:45<00:00,43.97it/s]
[32m[0324 13:36:53 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:3945.36 sec.
[32m[0324 13:36:53 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:26<00:00,128.40it/s]
33
[32m[0324 13:39:19 @monitor.py:363][0m QueueInput/queue_size: 0.78887
[32m[0324 13:39:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.929
[32m[0324 13:39:19 @monitor.py:363][0m activation-summaries/output-rms: 0.040423
[32m[0324 13:39:19 @monitor.py:363][0m cross_entropy_loss: 1.6135
[32m[0324 13:39:19 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48232
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5407e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2389e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45408
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5606e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6149e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47323
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.665e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35117
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7078e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.4761
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9832e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49103
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1552e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7459e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59743
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 13:39:19 @monitor.py:363][0m train-error-top1: 0.4294
[32m[0324 13:39:19 @monitor.py:363][0m val-error-top1: 0.43628
[32m[0324 13:39:19 @monitor.py:363][0m val-utt-error: 0.10036
[32m[0324 13:39:19 @monitor.py:363][0m validation_cost: 1.637
[32m[0324 13:39:19 @monitor.py:363][0m wd_cost: 1.93e-08
[32m[0324 13:39:19 @group.py:42][0m Callbacks took 146.771 sec in total. InferenceRunner: 146.607sec
[32m[0324 13:39:19 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9912/173481[03:00<49:30,55.06it/s]  6%|6         |10461/173481[03:10<49:20,55.06it/s] 11%|#1        |19553/173481[06:00<47:14,54.30it/s] 12%|#1        |20108/173481[06:10<47:04,54.30it/s] 17%|#6        |29175/173481[09:00<44:38,53.87it/s] 17%|#7        |29753/173481[09:10<44:27,53.87it/s] 23%|##2       |39062/173481[12:00<41:11,54.39it/s] 23%|##2       |39626/173481[12:10<41:00,54.39it/s] 28%|##8       |48949/173481[15:00<37:58,54.66it/s] 29%|##8       |49521/173481[15:10<37:47,54.66it/s] 34%|###3      |58722/173481[18:00<35:06,54.47it/s] 34%|###4      |59301/173481[18:10<34:56,54.47it/s] 39%|###9      |68277/173481[21:00<32:36,53.76it/s] 40%|###9      |68855/173481[21:11<32:26,53.76it/s] 44%|####4     |76847/173481[24:00<31:53,50.50it/s] 45%|####4     |77401/173481[24:11<31:42,50.50it/s] 49%|####9     |85800/173481[27:00<29:09,50.12it/s] 50%|####9     |86171/173481[27:11<29:02,50.12it/s] 55%|#####4    |94784/173481[30:00<26:13,50.01it/s] 55%|#####4    |95341/173481[30:11<26:02,50.01it/s] 60%|#####9    |103662/173481[33:00<23:25,49.66it/s] 60%|######    |104251/173481[33:11<23:14,49.66it/s] 65%|######4   |112136/173481[36:00<21:09,48.33it/s] 65%|######4   |112726/173481[36:11<20:56,48.33it/s] 70%|#######   |122107/173481[39:00<16:35,51.62it/s] 71%|#######   |122804/173481[39:12<16:21,51.62it/s] 76%|#######6  |132287/173481[42:00<12:43,53.97it/s] 77%|#######6  |132936/173481[42:12<12:31,53.97it/s] 82%|########2 |142488/173481[45:00<09:20,55.29it/s] 83%|########2 |143161/173481[45:12<09:08,55.29it/s] 88%|########8 |152732/173481[48:00<06:09,56.08it/s] 88%|########8 |153433/173481[48:12<05:57,56.08it/s] 94%|#########3|162987/173481[51:00<03:05,56.52it/s] 94%|#########4|163561/173481[51:12<02:55,56.52it/s]100%|#########9|173090/173481[54:00<00:06,56.32it/s]100%|##########|173481/173481[54:07<00:00,53.41it/s]
[32m[0324 14:33:27 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:3247.92 sec.
[32m[0324 14:33:27 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-6071835.
[32m[0324 14:33:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:23<00:00,131.38it/s]
34
[32m[0324 14:35:51 @monitor.py:363][0m QueueInput/queue_size: 0.66224
[32m[0324 14:35:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.137
[32m[0324 14:35:51 @monitor.py:363][0m activation-summaries/output-rms: 0.042241
[32m[0324 14:35:51 @monitor.py:363][0m cross_entropy_loss: 1.6092
[32m[0324 14:35:51 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5405e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35775
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.239e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4541
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6149e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47324
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6651e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47611
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9832e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3972e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49104
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1553e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59742
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3161
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 14:35:51 @monitor.py:363][0m train-error-top1: 0.43295
[32m[0324 14:35:51 @monitor.py:363][0m val-error-top1: 0.43688
[32m[0324 14:35:51 @monitor.py:363][0m val-utt-error: 0.10073
[32m[0324 14:35:51 @monitor.py:363][0m validation_cost: 1.6405
[32m[0324 14:35:51 @monitor.py:363][0m wd_cost: 1.93e-08
[32m[0324 14:35:51 @group.py:42][0m Callbacks took 143.891 sec in total. InferenceRunner: 143.277sec
[32m[0324 14:35:51 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9980/173481[03:00<49:09,55.44it/s]  6%|6         |10530/173481[03:10<48:59,55.44it/s] 11%|#1        |19488/173481[06:00<47:26,54.10it/s] 12%|#1        |20022/173481[06:10<47:16,54.10it/s] 17%|#6        |28919/173481[09:00<45:15,53.23it/s] 17%|#6        |29440/173481[09:10<45:05,53.23it/s] 22%|##1       |37948/173481[12:00<43:44,51.65it/s] 22%|##2       |38470/173481[12:10<43:33,51.65it/s] 27%|##6       |46206/173481[15:00<43:39,48.59it/s] 27%|##6       |46685/173481[15:10<43:29,48.59it/s] 31%|###1      |54276/173481[18:00<42:36,46.63it/s] 32%|###1      |54785/173481[18:10<42:25,46.63it/s] 36%|###6      |62495/173481[21:00<40:05,46.14it/s] 36%|###6      |63010/173481[21:11<39:54,46.14it/s] 41%|####      |70679/173481[24:00<37:24,45.80it/s] 41%|####1     |71150/173481[24:11<37:14,45.80it/s] 45%|####5     |78366/173481[27:00<35:52,44.19it/s] 45%|####5     |78855/173481[27:11<35:41,44.19it/s] 50%|####9     |86396/173481[30:00<32:41,44.39it/s] 50%|#####     |86905/173481[30:11<32:30,44.39it/s] 55%|#####4    |94735/173481[33:00<28:56,45.34it/s] 55%|#####4    |95232/173481[33:11<28:45,45.34it/s] 59%|#####9    |102660/173481[36:00<26:25,44.67it/s] 59%|#####9    |103165/173481[36:11<26:13,44.67it/s] 64%|######3   |110580/173481[39:00<23:38,44.33it/s] 64%|######4   |111118/173481[39:12<23:26,44.33it/s] 69%|######8   |118991/173481[42:00<19:57,45.50it/s] 69%|######8   |119555/173481[42:12<19:45,45.50it/s] 74%|#######3  |127666/173481[45:00<16:18,46.81it/s] 74%|#######3  |128240/173481[45:12<16:06,46.81it/s] 78%|#######8  |135988/173481[48:00<13:26,46.52it/s] 79%|#######8  |136515/173481[48:12<13:14,46.52it/s] 83%|########3 |144326/173481[51:00<10:28,46.38it/s] 83%|########3 |144465/173481[51:12<10:25,46.38it/s] 88%|########8 |152696/173481[54:00<07:27,46.44it/s] 88%|########8 |153346/173481[54:12<07:13,46.44it/s] 93%|#########3|162201/173481[57:00<03:48,49.41it/s] 94%|#########3|162843/173481[57:12<03:35,49.41it/s] 99%|#########8|171421/173481[1:00:00<00:40,50.30it/s] 99%|#########9|172020/173481[1:00:13<00:29,50.30it/s]100%|##########|173481/173481[1:00:42<00:00,47.62it/s]
[32m[0324 15:36:34 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:3642.71 sec.
[32m[0324 15:36:34 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:08<00:00,146.01it/s]
35
[32m[0324 15:38:43 @monitor.py:363][0m QueueInput/queue_size: 0.7123
[32m[0324 15:38:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.04
[32m[0324 15:38:43 @monitor.py:363][0m activation-summaries/output-rms: 0.041625
[32m[0324 15:38:43 @monitor.py:363][0m cross_entropy_loss: 1.6029
[32m[0324 15:38:43 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48234
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5407e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4541
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6149e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47324
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.665e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7078e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47611
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9832e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3972e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1553e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59731
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3161
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 15:38:43 @monitor.py:363][0m train-error-top1: 0.43044
[32m[0324 15:38:43 @monitor.py:363][0m val-error-top1: 0.43687
[32m[0324 15:38:43 @monitor.py:363][0m val-utt-error: 0.10148
[32m[0324 15:38:43 @monitor.py:363][0m validation_cost: 1.641
[32m[0324 15:38:43 @monitor.py:363][0m wd_cost: 3.8592e-09
[32m[0324 15:38:43 @group.py:42][0m Callbacks took 129.130 sec in total. InferenceRunner: 128.924sec
[32m[0324 15:38:43 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8103/173481[03:00<1:01:13,45.01it/s]  5%|4         |8587/173481[03:10<1:01:03,45.01it/s] 10%|9         |16685/173481[06:00<56:26,46.30it/s]  10%|9         |17185/173481[06:10<56:15,46.30it/s] 15%|#4        |25247/173481[09:00<52:38,46.93it/s] 15%|#4        |25754/173481[09:10<52:28,46.93it/s] 19%|#9        |33650/173481[12:00<49:47,46.80it/s] 20%|#9        |34144/173481[12:10<49:37,46.80it/s] 24%|##4       |41696/173481[15:00<48:01,45.73it/s] 24%|##4       |42192/173481[15:10<47:51,45.73it/s] 28%|##8       |49055/173481[18:00<48:08,43.08it/s] 29%|##8       |49524/173481[18:10<47:57,43.08it/s] 33%|###3      |57346/173481[21:00<43:28,44.52it/s] 33%|###3      |57835/173481[21:11<43:17,44.52it/s] 38%|###7      |65096/173481[24:00<41:15,43.78it/s] 38%|###7      |65569/173481[24:11<41:05,43.78it/s] 42%|####2     |73225/173481[27:00<37:35,44.45it/s] 42%|####2     |73713/173481[27:11<37:24,44.45it/s] 46%|####6     |80510/173481[30:00<36:34,42.37it/s] 47%|####6     |80994/173481[30:11<36:22,42.37it/s] 51%|#####     |88275/173481[33:00<33:13,42.74it/s] 51%|#####1    |88534/173481[33:11<33:07,42.74it/s] 55%|#####5    |95668/173481[36:00<30:57,41.89it/s] 55%|#####5    |96163/173481[36:11<30:45,41.89it/s] 59%|#####9    |103074/173481[39:00<28:16,41.51it/s] 60%|#####9    |103534/173481[39:12<28:04,41.51it/s] 63%|######3   |109950/173481[42:00<26:36,39.78it/s] 64%|######3   |110382/173481[42:12<26:26,39.78it/s] 67%|######7   |116335/173481[45:00<25:23,37.50it/s] 67%|######7   |116803/173481[45:12<25:11,37.50it/s] 71%|#######   |122383/173481[48:00<24:01,35.44it/s] 71%|#######   |122829/173481[48:12<23:49,35.44it/s] 74%|#######4  |128965/173481[51:00<20:36,35.99it/s] 75%|#######4  |129349/173481[51:12<20:26,35.99it/s] 78%|#######8  |135543/173481[54:00<17:26,36.27it/s] 78%|#######8  |135999/173481[54:12<17:13,36.27it/s] 82%|########1 |142111/173481[57:01<14:22,36.38it/s] 82%|########2 |142614/173481[57:13<14:08,36.38it/s] 86%|########6 |149322/173481[1:00:01<10:33,38.13it/s] 86%|########6 |149780/173481[1:00:13<10:21,38.13it/s] 90%|######### |156642/173481[1:03:01<07:07,39.36it/s] 91%|######### |157149/173481[1:03:13<06:54,39.36it/s] 95%|#########4|164090/173481[1:06:01<03:52,40.33it/s] 95%|#########4|164608/173481[1:06:13<03:39,40.33it/s] 98%|#########8|170780/173481[1:09:01<01:09,38.68it/s] 99%|#########8|171304/173481[1:09:13<00:56,38.68it/s]100%|##########|173481/173481[1:10:07<00:00,41.23it/s]
[32m[0324 16:48:51 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:4207.63 sec.
[32m[0324 16:48:51 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s] 73%|#######2  |13708/18822[03:00<01:07,76.15it/s] 77%|#######6  |14485/18822[03:10<00:56,76.15it/s]100%|##########|18822/18822[04:08<00:00,75.89it/s]
36
[32m[0324 16:52:59 @monitor.py:363][0m QueueInput/queue_size: 0.70886
[32m[0324 16:52:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.333
[32m[0324 16:52:59 @monitor.py:363][0m activation-summaries/output-rms: 0.041266
[32m[0324 16:52:59 @monitor.py:363][0m cross_entropy_loss: 1.6197
[32m[0324 16:52:59 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48234
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5407e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4541
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6149e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47324
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7078e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9832e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1553e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59714
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3161
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 16:52:59 @monitor.py:363][0m train-error-top1: 0.42982
[32m[0324 16:52:59 @monitor.py:363][0m val-error-top1: 0.43633
[32m[0324 16:52:59 @monitor.py:363][0m val-utt-error: 0.098874
[32m[0324 16:52:59 @monitor.py:363][0m validation_cost: 1.6384
[32m[0324 16:52:59 @monitor.py:363][0m wd_cost: 3.8581e-09
[32m[0324 16:52:59 @group.py:42][0m Callbacks took 248.444 sec in total. InferenceRunner: 248.047sec
[32m[0324 16:52:59 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |7840/173481[03:00<1:03:23,43.55it/s]  5%|4         |8248/173481[03:10<1:03:13,43.55it/s]  9%|8         |15291/173481[06:00<1:02:06,42.45it/s]  9%|9         |15748/173481[06:10<1:01:56,42.45it/s] 13%|#3        |22862/173481[09:00<59:24,42.25it/s]   13%|#3        |23214/173481[09:10<59:16,42.25it/s] 17%|#7        |29509/173481[12:00<1:00:53,39.41it/s] 17%|#7        |29951/173481[12:10<1:00:42,39.41it/s] 21%|##        |35969/173481[15:00<1:01:02,37.55it/s] 21%|##        |36328/173481[15:10<1:00:52,37.55it/s] 25%|##4       |42884/173481[18:00<57:18,37.98it/s]   25%|##4       |43286/173481[18:10<57:08,37.98it/s] 29%|##8       |49663/173481[21:00<54:34,37.82it/s] 29%|##8       |50088/173481[21:11<54:23,37.82it/s] 33%|###2      |56798/173481[24:00<50:14,38.70it/s] 33%|###2      |57240/173481[24:11<50:03,38.70it/s] 37%|###6      |63939/173481[27:00<46:35,39.18it/s] 37%|###7      |64359/173481[27:11<46:25,39.18it/s] 41%|####      |71069/173481[30:00<43:19,39.40it/s] 41%|####1     |71546/173481[30:11<43:07,39.40it/s] 45%|####5     |78197/173481[33:00<40:12,39.50it/s] 45%|####5     |78678/173481[33:11<40:00,39.50it/s] 49%|####8     |84675/173481[36:00<39:18,37.66it/s] 49%|####9     |85128/173481[36:12<39:06,37.66it/s] 53%|#####2    |91604/173481[39:00<35:50,38.07it/s] 53%|#####3    |92032/173481[39:12<35:39,38.07it/s] 57%|#####6    |98354/173481[42:00<33:08,37.78it/s] 57%|#####6    |98829/173481[42:12<32:55,37.78it/s] 60%|######    |104914/173481[45:00<30:48,37.10it/s] 61%|######    |105400/173481[45:12<30:35,37.10it/s] 65%|######5   |112791/173481[48:00<25:11,40.16it/s] 65%|######5   |113346/173481[48:12<24:57,40.16it/s] 70%|######9   |120906/173481[51:00<20:37,42.48it/s] 70%|######9   |121431/173481[51:12<20:25,42.48it/s] 74%|#######3  |128330/173481[54:00<17:58,41.85it/s] 74%|#######4  |128892/173481[54:12<17:45,41.85it/s] 79%|#######8  |136490/173481[57:00<14:09,43.52it/s] 79%|#######9  |137084/173481[57:13<13:56,43.52it/s] 83%|########3 |144334/173481[1:00:00<11:09,43.55it/s] 84%|########3 |144918/173481[1:00:13<10:55,43.55it/s] 88%|########7 |152229/173481[1:03:00<08:06,43.70it/s] 88%|########8 |152770/173481[1:03:13<07:53,43.70it/s] 92%|#########2|160215/173481[1:06:00<05:01,44.03it/s] 93%|#########2|160811/173481[1:06:13<04:47,44.03it/s] 97%|#########7|169081/173481[1:09:00<01:34,46.50it/s] 98%|#########7|169729/173481[1:09:13<01:20,46.50it/s]100%|##########|173481/173481[1:10:49<00:00,40.83it/s]
[32m[0324 18:03:48 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:4249.04 sec.
[32m[0324 18:03:48 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-6592278.
  0%|          |0/18822[00:00<?,?it/s] 90%|######### |16999/18822[03:00<00:19,94.44it/s] 96%|#########6|18094/18822[03:10<00:07,94.44it/s]100%|##########|18822/18822[03:17<00:00,95.11it/s]
37
[32m[0324 18:07:06 @monitor.py:363][0m QueueInput/queue_size: 0.74177
[32m[0324 18:07:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.098
[32m[0324 18:07:06 @monitor.py:363][0m activation-summaries/output-rms: 0.04083
[32m[0324 18:07:06 @monitor.py:363][0m cross_entropy_loss: 1.5701
[32m[0324 18:07:06 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48234
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47324
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7078e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1552e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59697
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3161
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 18:07:06 @monitor.py:363][0m train-error-top1: 0.42912
[32m[0324 18:07:06 @monitor.py:363][0m val-error-top1: 0.43676
[32m[0324 18:07:06 @monitor.py:363][0m val-utt-error: 0.098821
[32m[0324 18:07:06 @monitor.py:363][0m validation_cost: 1.6383
[32m[0324 18:07:06 @monitor.py:363][0m wd_cost: 3.8571e-09
[32m[0324 18:07:06 @group.py:42][0m Callbacks took 198.187 sec in total. InferenceRunner: 197.935sec
[32m[0324 18:07:06 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9158/173481[03:00<53:49,50.88it/s]  6%|5         |9634/173481[03:10<53:40,50.88it/s] 10%|#         |17553/173481[06:00<53:24,48.66it/s] 10%|#         |18033/173481[06:10<53:14,48.66it/s] 15%|#4        |25781/173481[09:00<52:13,47.14it/s] 15%|#5        |26305/173481[09:10<52:02,47.14it/s] 20%|#9        |34272/173481[12:00<49:12,47.16it/s] 20%|##        |34817/173481[12:10<49:00,47.16it/s] 24%|##4       |41649/173481[15:00<50:06,43.85it/s] 24%|##4       |42160/173481[15:10<49:54,43.85it/s] 29%|##8       |49906/173481[18:00<45:55,44.84it/s] 29%|##9       |50440/173481[18:10<45:44,44.84it/s] 34%|###3      |58143/173481[21:00<42:26,45.29it/s] 34%|###3      |58674/173481[21:11<42:15,45.29it/s] 38%|###8      |66413/173481[24:00<39:07,45.61it/s] 39%|###8      |66882/173481[24:11<38:57,45.61it/s] 42%|####2     |73566/173481[27:00<39:12,42.47it/s] 43%|####2     |74000/173481[27:11<39:02,42.47it/s] 47%|####6     |80843/173481[30:00<37:16,41.42it/s] 47%|####6     |81304/173481[30:11<37:05,41.42it/s] 50%|#####     |87403/173481[33:00<37:00,38.77it/s] 51%|#####     |87861/173481[33:11<36:48,38.77it/s] 55%|#####4    |94885/173481[36:00<32:39,40.12it/s] 55%|#####5    |95449/173481[36:11<32:25,40.12it/s] 60%|#####9    |103613/173481[39:00<26:31,43.90it/s] 60%|######    |104202/173481[39:12<26:18,43.90it/s] 65%|######4   |112313/173481[42:00<22:09,46.01it/s] 65%|######5   |112885/173481[42:12<21:56,46.01it/s] 70%|######9   |120973/173481[45:00<18:37,46.99it/s] 70%|#######   |121552/173481[45:12<18:25,46.99it/s] 74%|#######4  |129218/173481[48:00<15:54,46.38it/s] 75%|#######4  |129766/173481[48:12<15:42,46.38it/s] 79%|#######8  |136698/173481[51:00<13:59,43.84it/s] 79%|#######9  |137306/173481[51:12<13:45,43.84it/s] 84%|########3 |145014/173481[54:00<10:32,44.99it/s] 84%|########3 |145592/173481[54:12<10:19,44.99it/s] 89%|########8 |153823/173481[57:00<06:59,46.88it/s] 89%|########9 |154413/173481[57:13<06:46,46.88it/s] 94%|#########3|162688/173481[1:00:00<03:44,48.03it/s] 94%|#########4|163292/173481[1:00:13<03:32,48.03it/s] 99%|#########8|171085/173481[1:03:00<00:50,47.33it/s] 99%|#########8|171657/173481[1:03:13<00:38,47.33it/s]100%|##########|173481/173481[1:03:56<00:00,45.22it/s]
[32m[0324 19:11:02 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:3836.04 sec.
[32m[0324 19:11:03 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14790/18822[03:00<00:49,82.13it/s] 79%|#######8  |14853/18822[03:10<00:48,82.13it/s]100%|##########|18822/18822[04:06<00:00,76.48it/s]
38
[32m[0324 19:15:09 @monitor.py:363][0m QueueInput/queue_size: 1.0152
[32m[0324 19:15:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.934
[32m[0324 19:15:09 @monitor.py:363][0m activation-summaries/output-rms: 0.040432
[32m[0324 19:15:09 @monitor.py:363][0m cross_entropy_loss: 1.611
[32m[0324 19:15:09 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48234
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47324
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7078e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3972e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59671
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3161
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 19:15:09 @monitor.py:363][0m train-error-top1: 0.42894
[32m[0324 19:15:09 @monitor.py:363][0m val-error-top1: 0.43616
[32m[0324 19:15:09 @monitor.py:363][0m val-utt-error: 0.099936
[32m[0324 19:15:09 @monitor.py:363][0m validation_cost: 1.636
[32m[0324 19:15:09 @monitor.py:363][0m wd_cost: 7.7108e-10
[32m[0324 19:15:09 @group.py:42][0m Callbacks took 246.316 sec in total. InferenceRunner: 246.125sec
[32m[0324 19:15:09 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9001/173481[03:00<54:49,50.00it/s]  5%|5         |9443/173481[03:10<54:40,50.00it/s] 10%|#         |17506/173481[06:00<53:30,48.59it/s] 10%|#         |18015/173481[06:10<53:19,48.59it/s] 15%|#4        |25988/173481[09:00<51:22,47.84it/s] 15%|#5        |26504/173481[09:10<51:12,47.84it/s] 20%|##        |34718/173481[12:00<48:00,48.17it/s] 20%|##        |35238/173481[12:10<47:50,48.17it/s] 25%|##4       |43335/173481[15:00<45:10,48.02it/s] 25%|##5       |43814/173481[15:10<45:00,48.02it/s] 29%|##9       |50572/173481[18:00<46:49,43.76it/s] 29%|##9       |50996/173481[18:10<46:39,43.76it/s] 34%|###3      |58387/173481[21:00<44:01,43.58it/s] 34%|###3      |58856/173481[21:11<43:50,43.58it/s] 38%|###8      |66103/173481[24:00<41:24,43.22it/s] 38%|###8      |66551/173481[24:11<41:14,43.22it/s] 42%|####2     |73632/173481[27:00<39:08,42.51it/s] 43%|####2     |74108/173481[27:11<38:57,42.51it/s] 47%|####6     |81139/173481[30:00<36:33,42.10it/s] 47%|####7     |81613/173481[30:11<36:22,42.10it/s] 51%|#####     |88217/173481[33:00<34:57,40.66it/s] 51%|#####1    |88706/173481[33:11<34:45,40.66it/s] 55%|#####4    |95018/173481[36:00<33:23,39.17it/s] 55%|#####5    |95507/173481[36:11<33:10,39.17it/s] 59%|#####9    |102577/173481[39:00<29:09,40.52it/s] 59%|#####9    |103108/173481[39:12<28:56,40.52it/s] 64%|######3   |110577/173481[42:00<24:43,42.39it/s] 64%|######4   |111122/173481[42:12<24:31,42.39it/s] 69%|######8   |119596/173481[45:00<19:33,45.92it/s] 69%|######9   |120257/173481[45:12<19:18,45.92it/s] 74%|#######4  |128439/173481[48:00<15:48,47.47it/s] 74%|#######4  |129041/173481[48:12<15:36,47.47it/s] 79%|#######9  |137389/173481[51:00<12:23,48.57it/s] 80%|#######9  |137961/173481[51:12<12:11,48.57it/s] 84%|########3 |145487/173481[54:00<09:59,46.71it/s] 84%|########4 |146109/173481[54:12<09:46,46.71it/s] 89%|########9 |154557/173481[57:00<06:30,48.48it/s] 89%|########9 |155231/173481[57:13<06:16,48.48it/s] 94%|#########4|163369/173481[1:00:00<03:27,48.72it/s] 95%|#########4|163944/173481[1:00:13<03:15,48.72it/s] 99%|#########8|171606/173481[1:03:00<00:39,47.19it/s] 99%|#########9|172250/173481[1:03:13<00:26,47.19it/s]100%|##########|173481/173481[1:03:39<00:00,45.42it/s]
[32m[0324 20:18:49 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:3819.82 sec.
[32m[0324 20:18:49 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-6939240.
[32m[0324 20:18:50 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 83%|########3 |15672/18822[03:00<00:36,87.06it/s] 88%|########7 |16485/18822[03:10<00:26,87.06it/s]100%|##########|18822/18822[03:37<00:00,86.46it/s]
39
[32m[0324 20:22:27 @monitor.py:363][0m QueueInput/queue_size: 0.80712
[32m[0324 20:22:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.104
[32m[0324 20:22:27 @monitor.py:363][0m activation-summaries/output-rms: 0.042219
[32m[0324 20:22:27 @monitor.py:363][0m cross_entropy_loss: 1.609
[32m[0324 20:22:27 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47324
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59645
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3161
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 20:22:27 @monitor.py:363][0m train-error-top1: 0.43313
[32m[0324 20:22:27 @monitor.py:363][0m val-error-top1: 0.43682
[32m[0324 20:22:27 @monitor.py:363][0m val-utt-error: 0.10111
[32m[0324 20:22:27 @monitor.py:363][0m validation_cost: 1.6398
[32m[0324 20:22:27 @monitor.py:363][0m wd_cost: 7.7074e-10
[32m[0324 20:22:27 @group.py:42][0m Callbacks took 218.828 sec in total. InferenceRunner: 217.722sec
[32m[0324 20:22:27 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8199/173481[03:00<1:00:28,45.55it/s]  5%|4         |8620/173481[03:10<1:00:19,45.55it/s] 10%|9         |16481/173481[06:00<57:09,45.78it/s]  10%|9         |16950/173481[06:10<56:59,45.78it/s] 14%|#3        |23912/173481[09:00<57:25,43.41it/s] 14%|#4        |24382/173481[09:10<57:14,43.41it/s] 18%|#8        |31453/173481[12:00<55:31,42.64it/s] 18%|#8        |31883/173481[12:10<55:20,42.64it/s] 22%|##2       |38680/173481[15:00<54:19,41.36it/s] 23%|##2       |39125/173481[15:10<54:08,41.36it/s] 26%|##6       |45908/173481[18:00<52:10,40.75it/s] 27%|##6       |46364/173481[18:11<51:59,40.75it/s] 30%|###       |52556/173481[21:00<52:01,38.74it/s] 31%|###       |53001/173481[21:11<51:49,38.74it/s] 34%|###4      |59748/173481[24:00<48:11,39.34it/s] 35%|###4      |60210/173481[24:11<47:59,39.34it/s] 39%|###8      |66946/173481[27:00<44:46,39.66it/s] 39%|###8      |67395/173481[27:11<44:35,39.66it/s] 43%|####2     |73857/173481[30:00<42:33,39.01it/s] 43%|####2     |74325/173481[30:11<42:21,39.01it/s] 47%|####6     |80952/173481[33:00<39:19,39.21it/s] 47%|####6     |81457/173481[33:11<39:06,39.21it/s] 51%|#####     |88362/173481[36:00<35:19,40.17it/s] 51%|#####1    |88875/173481[36:11<35:06,40.17it/s] 55%|#####5    |96001/173481[39:00<31:17,41.27it/s] 56%|#####5    |96600/173481[39:12<31:02,41.27it/s] 60%|######    |104276/173481[42:00<26:31,43.49it/s] 60%|######    |104869/173481[42:12<26:17,43.49it/s] 65%|######5   |112948/173481[45:00<22:04,45.71it/s] 65%|######5   |113550/173481[45:12<21:51,45.71it/s] 70%|#######   |121652/173481[48:00<18:22,47.00it/s] 70%|#######   |122237/173481[48:12<18:10,47.00it/s] 75%|#######4  |129729/173481[51:00<15:53,45.91it/s] 75%|#######5  |130352/173481[51:12<15:39,45.91it/s] 80%|#######9  |138022/173481[54:00<12:51,45.99it/s] 80%|#######9  |138622/173481[54:12<12:38,45.99it/s] 84%|########3 |145056/173481[57:00<11:12,42.24it/s] 84%|########3 |145194/173481[57:13<11:09,42.24it/s] 88%|########8 |152746/173481[1:00:00<08:08,42.47it/s] 88%|########8 |153370/173481[1:00:13<07:53,42.47it/s] 93%|#########2|161019/173481[1:03:00<04:42,44.15it/s] 93%|#########3|161605/173481[1:03:13<04:29,44.15it/s] 98%|#########7|169151/173481[1:06:00<01:36,44.65it/s] 98%|#########7|169770/173481[1:06:13<01:23,44.65it/s]100%|##########|173481/173481[1:07:42<00:00,42.70it/s]
[32m[0324 21:30:10 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:4062.73 sec.
[32m[0324 21:30:10 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######8  |14696/18822[03:00<00:50,81.64it/s] 83%|########2 |15614/18822[03:10<00:39,81.64it/s]100%|##########|18822/18822[03:48<00:00,82.25it/s]
40
[32m[0324 21:33:59 @monitor.py:363][0m QueueInput/queue_size: 0.81726
[32m[0324 21:33:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.986
[32m[0324 21:33:59 @monitor.py:363][0m activation-summaries/output-rms: 0.041582
[32m[0324 21:33:59 @monitor.py:363][0m cross_entropy_loss: 1.6027
[32m[0324 21:33:59 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5962
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3161
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 21:33:59 @monitor.py:363][0m train-error-top1: 0.43243
[32m[0324 21:33:59 @monitor.py:363][0m val-error-top1: 0.43686
[32m[0324 21:33:59 @monitor.py:363][0m val-utt-error: 0.10201
[32m[0324 21:33:59 @monitor.py:363][0m validation_cost: 1.6407
[32m[0324 21:33:59 @monitor.py:363][0m wd_cost: 7.7042e-10
[32m[0324 21:33:59 @group.py:42][0m Callbacks took 229.290 sec in total. InferenceRunner: 228.872sec
[32m[0324 21:33:59 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7485/173481[03:00<1:06:37,41.52it/s]  5%|4         |8089/173481[03:20<1:06:23,41.52it/s]  9%|8         |14760/173481[06:00<1:04:35,40.96it/s]  9%|8         |15164/173481[06:10<1:04:25,40.96it/s] 13%|#2        |22195/173481[09:00<1:01:18,41.12it/s] 13%|#3        |22646/173481[09:10<1:01:07,41.12it/s] 17%|#7        |29877/173481[12:00<57:08,41.89it/s]   17%|#7        |30310/173481[12:10<56:58,41.89it/s] 22%|##1       |37455/173481[15:00<53:59,41.99it/s] 22%|##1       |37879/173481[15:10<53:49,41.99it/s] 26%|##5       |44777/173481[18:00<51:54,41.32it/s] 26%|##6       |45203/173481[18:10<51:44,41.32it/s] 30%|##9       |51375/173481[21:00<52:23,38.84it/s] 30%|##9       |51812/173481[21:11<52:12,38.84it/s] 34%|###3      |58755/173481[24:00<47:56,39.88it/s] 34%|###4      |59190/173481[24:11<47:45,39.88it/s] 38%|###8      |66690/173481[27:00<42:30,41.88it/s] 39%|###8      |67194/173481[27:11<42:18,41.88it/s] 44%|####3     |75831/173481[30:00<35:27,45.90it/s] 44%|####4     |76414/173481[30:11<35:14,45.90it/s] 49%|####9     |85473/173481[33:00<29:40,49.44it/s] 50%|####9     |86094/173481[33:11<29:27,49.44it/s] 55%|#####4    |95154/173481[36:00<25:20,51.52it/s] 55%|#####5    |95794/173481[36:11<25:07,51.52it/s] 60%|#####9    |104045/173481[39:01<23:00,50.28it/s] 60%|######    |104214/173481[39:12<22:57,50.28it/s] 66%|######6   |114929/173481[42:01<17:46,54.90it/s] 67%|######6   |115518/173481[42:12<17:35,54.90it/s] 72%|#######1  |124624/173481[45:01<14:58,54.37it/s] 72%|#######2  |125222/173481[45:12<14:47,54.37it/s] 77%|#######7  |134251/173481[48:01<12:07,53.92it/s] 78%|#######7  |134848/173481[48:12<11:56,53.92it/s] 83%|########3 |144038/173481[51:01<09:03,54.15it/s] 83%|########3 |144652/173481[51:12<08:52,54.15it/s] 89%|########8 |153791/173481[54:01<06:03,54.16it/s] 89%|########8 |154384/173481[54:12<05:52,54.16it/s] 94%|#########3|162773/173481[57:01<03:26,51.94it/s] 94%|#########4|163247/173481[57:13<03:17,51.94it/s] 99%|#########9|171789/173481[1:00:01<00:33,51.00it/s] 99%|#########9|172390/173481[1:00:13<00:21,51.00it/s][32m[0324 22:34:33 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3633.83 sec.
100%|##########|173481/173481[1:00:33<00:00,47.74it/s]
[32m[0324 22:34:34 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-7286202.
  0%|          |0/18822[00:00<?,?it/s] 84%|########4 |15821/18822[03:00<00:34,87.89it/s] 89%|########9 |16780/18822[03:10<00:23,87.89it/s]100%|##########|18822/18822[03:33<00:00,88.03it/s]
41
[32m[0324 22:38:07 @monitor.py:363][0m QueueInput/queue_size: 0.9685
[32m[0324 22:38:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.266
[32m[0324 22:38:07 @monitor.py:363][0m activation-summaries/output-rms: 0.041227
[32m[0324 22:38:07 @monitor.py:363][0m cross_entropy_loss: 1.6197
[32m[0324 22:38:07 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3507
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59604
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 22:38:07 @monitor.py:363][0m train-error-top1: 0.42921
[32m[0324 22:38:07 @monitor.py:363][0m val-error-top1: 0.43628
[32m[0324 22:38:07 @monitor.py:363][0m val-utt-error: 0.098927
[32m[0324 22:38:07 @monitor.py:363][0m validation_cost: 1.638
[32m[0324 22:38:07 @monitor.py:363][0m wd_cost: 1.5404e-10
[32m[0324 22:38:07 @group.py:42][0m Callbacks took 214.086 sec in total. InferenceRunner: 213.846sec
[32m[0324 22:38:07 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9403/173481[03:00<52:21,52.23it/s]  6%|5         |9928/173481[03:10<52:11,52.23it/s] 11%|#         |18714/173481[06:00<49:37,51.98it/s] 11%|#1        |19244/173481[06:10<49:27,51.98it/s] 16%|#6        |27931/173481[09:00<47:01,51.59it/s] 16%|#6        |28466/173481[09:10<46:51,51.59it/s] 21%|##        |36234/173481[12:00<46:57,48.70it/s] 21%|##1       |36766/173481[12:10<46:47,48.70it/s] 26%|##6       |45544/173481[15:00<42:30,50.17it/s] 27%|##6       |46133/173481[15:10<42:18,50.17it/s] 32%|###1      |54930/173481[18:00<38:38,51.14it/s] 32%|###1      |55501/173481[18:10<38:27,51.14it/s] 37%|###7      |64567/173481[21:00<34:42,52.31it/s] 38%|###7      |65142/173481[21:11<34:31,52.31it/s] 43%|####3     |74705/173481[24:00<30:21,54.24it/s] 43%|####3     |75284/173481[24:11<30:10,54.24it/s] 49%|####8     |84436/173481[27:00<27:24,54.15it/s] 49%|####9     |85042/173481[27:11<27:13,54.15it/s] 54%|#####4    |94515/173481[30:00<23:54,55.06it/s] 55%|#####4    |94648/173481[30:11<23:51,55.06it/s] 60%|#####9    |103894/173481[33:00<21:39,53.54it/s] 60%|######    |104563/173481[33:11<21:27,53.54it/s] 65%|######5   |113374/173481[36:00<18:52,53.08it/s] 66%|######5   |114003/173481[36:11<18:40,53.08it/s] 71%|#######   |123101/173481[39:00<15:40,53.55it/s] 71%|#######1  |123777/173481[39:12<15:28,53.55it/s] 77%|#######6  |133110/173481[42:00<12:19,54.56it/s] 77%|#######7  |133822/173481[42:12<12:06,54.56it/s] 82%|########2 |143059/173481[45:00<09:14,54.91it/s] 83%|########2 |143899/173481[45:12<08:58,54.91it/s] 89%|########8 |153993/173481[48:00<05:37,57.68it/s] 89%|########9 |154645/173481[48:12<05:26,57.68it/s] 94%|#########4|163243/173481[51:00<03:08,54.35it/s] 95%|#########4|163984/173481[51:12<02:54,54.35it/s] 98%|#########8|170776/173481[54:00<00:57,47.29it/s] 99%|#########8|171120/173481[54:12<00:49,47.29it/s]100%|##########|173481/173481[55:21<00:00,52.22it/s]
[32m[0324 23:33:29 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3321.93 sec.
[32m[0324 23:33:30 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######4  |13993/18822[03:00<01:02,77.74it/s] 79%|#######8  |14800/18822[03:10<00:51,77.74it/s]100%|##########|18822/18822[03:56<00:00,79.47it/s]
42
[32m[0324 23:37:27 @monitor.py:363][0m QueueInput/queue_size: 0.76915
[32m[0324 23:37:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.018
[32m[0324 23:37:27 @monitor.py:363][0m activation-summaries/output-rms: 0.040795
[32m[0324 23:37:27 @monitor.py:363][0m cross_entropy_loss: 1.5691
[32m[0324 23:37:27 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59588
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0324 23:37:27 @monitor.py:363][0m train-error-top1: 0.42696
[32m[0324 23:37:27 @monitor.py:363][0m val-error-top1: 0.43675
[32m[0324 23:37:27 @monitor.py:363][0m val-utt-error: 0.098874
[32m[0324 23:37:27 @monitor.py:363][0m validation_cost: 1.6381
[32m[0324 23:37:27 @monitor.py:363][0m wd_cost: 1.54e-10
[32m[0324 23:37:27 @group.py:42][0m Callbacks took 237.422 sec in total. InferenceRunner: 236.863sec
[32m[0324 23:37:27 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |6965/173481[03:00<1:11:43,38.69it/s]  4%|4         |7322/173481[03:10<1:11:34,38.69it/s]  8%|7         |13283/173481[06:00<1:12:32,36.81it/s]  8%|7         |13662/173481[06:10<1:12:21,36.81it/s] 11%|#1        |19213/173481[09:00<1:13:57,34.76it/s] 11%|#1        |19592/173481[09:10<1:13:46,34.76it/s] 15%|#4        |25403/173481[12:00<1:11:23,34.57it/s] 15%|#4        |25761/173481[12:10<1:11:13,34.57it/s] 18%|#8        |32045/173481[15:00<1:06:02,35.70it/s] 19%|#8        |32364/173481[15:10<1:05:53,35.70it/s] 23%|##2       |39378/173481[18:00<58:44,38.05it/s]   23%|##3       |39907/173481[18:11<58:30,38.05it/s] 27%|##7       |47664/173481[21:00<50:19,41.66it/s] 28%|##7       |48168/173481[21:11<50:07,41.66it/s] 32%|###2      |55888/173481[24:00<44:59,43.56it/s] 33%|###2      |56412/173481[24:11<44:47,43.56it/s] 37%|###6      |63568/173481[27:00<42:29,43.11it/s] 37%|###6      |64047/173481[27:11<42:18,43.11it/s] 41%|####1     |71599/173481[30:00<38:43,43.85it/s] 42%|####1     |72065/173481[30:11<38:32,43.85it/s] 46%|####5     |79535/173481[33:00<35:36,43.97it/s] 46%|####6     |80152/173481[33:11<35:22,43.97it/s] 51%|#####     |88320/173481[36:00<30:40,46.26it/s] 51%|#####1    |88907/173481[36:11<30:28,46.26it/s] 56%|#####5    |97118/173481[39:00<26:46,47.53it/s] 56%|#####6    |97662/173481[39:12<26:35,47.53it/s] 61%|######1   |106103/173481[42:00<23:03,48.69it/s] 62%|######1   |106693/173481[42:12<22:51,48.69it/s] 66%|######5   |114416/173481[45:00<20:46,47.40it/s] 66%|######6   |115071/173481[45:12<20:32,47.40it/s] 71%|#######1  |123853/173481[48:00<16:36,49.79it/s] 72%|#######1  |124510/173481[48:12<16:23,49.79it/s] 77%|#######6  |133154/173481[51:00<13:15,50.71it/s] 77%|#######7  |133667/173481[51:12<13:05,50.71it/s] 81%|########  |140170/173481[54:00<12:35,44.08it/s] 81%|########1 |140646/173481[54:12<12:24,44.08it/s] 85%|########4 |147051/173481[57:00<10:45,40.94it/s] 85%|########5 |147840/173481[57:13<10:26,40.94it/s] 91%|#########1|157945/173481[1:00:00<05:18,48.84it/s] 92%|#########1|158737/173481[1:00:13<05:01,48.84it/s] 97%|#########7|169098/173481[1:03:00<01:20,54.62it/s] 98%|#########7|169874/173481[1:03:13<01:06,54.62it/s]100%|##########|173481/173481[1:04:21<00:00,44.93it/s]
[32m[0325 00:41:48 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3861.29 sec.
[32m[0325 00:41:48 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-7633164.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:27<00:00,127.65it/s]
43
[32m[0325 00:44:16 @monitor.py:363][0m QueueInput/queue_size: 0.95287
[32m[0325 00:44:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.859
[32m[0325 00:44:16 @monitor.py:363][0m activation-summaries/output-rms: 0.040425
[32m[0325 00:44:16 @monitor.py:363][0m cross_entropy_loss: 1.613
[32m[0325 00:44:16 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59578
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 00:44:16 @monitor.py:363][0m train-error-top1: 0.43066
[32m[0325 00:44:16 @monitor.py:363][0m val-error-top1: 0.43618
[32m[0325 00:44:16 @monitor.py:363][0m val-utt-error: 0.099989
[32m[0325 00:44:16 @monitor.py:363][0m validation_cost: 1.6362
[32m[0325 00:44:16 @monitor.py:363][0m wd_cost: 1.5398e-10
[32m[0325 00:44:16 @group.py:42][0m Callbacks took 147.925 sec in total. InferenceRunner: 147.458sec
[32m[0325 00:44:16 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10132/173481[03:00<48:22,56.28it/s]  6%|5         |10286/173481[03:10<48:19,56.28it/s] 12%|#1        |19962/173481[06:00<46:09,55.43it/s] 12%|#1        |20549/173481[06:10<45:58,55.43it/s] 18%|#7        |31032/173481[09:00<40:42,58.31it/s] 18%|#8        |31731/173481[09:10<40:30,58.31it/s] 25%|##4       |42631/173481[12:00<35:37,61.22it/s] 25%|##4       |43255/173481[12:10<35:27,61.22it/s] 31%|###1      |54181/173481[15:00<31:43,62.66it/s] 32%|###1      |54909/173481[15:10<31:32,62.66it/s] 37%|###7      |64363/173481[18:00<30:35,59.46it/s] 37%|###7      |65037/173481[18:10<30:23,59.46it/s] 44%|####3     |75487/173481[21:00<26:57,60.60it/s] 44%|####3     |76161/173481[21:11<26:45,60.60it/s] 50%|####9     |86147/173481[24:00<24:18,59.90it/s] 50%|#####     |86824/173481[24:11<24:06,59.90it/s] 55%|#####4    |94553/173481[27:00<25:03,52.48it/s] 55%|#####4    |95109/173481[27:11<24:53,52.48it/s] 59%|#####9    |103153/173481[30:00<23:26,50.02it/s] 60%|#####9    |103708/173481[30:11<23:14,50.02it/s] 64%|######4   |111153/173481[33:00<22:04,47.06it/s] 64%|######4   |111701/173481[33:11<21:52,47.06it/s] 69%|######9   |120054/173481[36:00<18:27,48.23it/s] 70%|######9   |120608/173481[36:11<18:16,48.23it/s] 74%|#######4  |128765/173481[39:00<15:25,48.31it/s] 75%|#######4  |129306/173481[39:12<15:14,48.31it/s] 79%|#######9  |137244/173481[42:00<12:39,47.70it/s] 79%|#######9  |137797/173481[42:12<12:28,47.70it/s] 84%|########3 |145063/173481[45:00<10:24,45.47it/s] 84%|########3 |145633/173481[45:12<10:12,45.47it/s] 89%|########8 |153594/173481[48:00<07:08,46.41it/s] 89%|########8 |154099/173481[48:12<06:57,46.41it/s] 93%|#########3|161394/173481[51:00<04:29,44.81it/s] 93%|#########3|161576/173481[51:12<04:25,44.81it/s] 97%|#########6|167677/173481[54:00<02:27,39.24it/s] 97%|#########6|168176/173481[54:12<02:15,39.24it/s]100%|##########|173481/173481[56:21<00:00,51.30it/s]
[32m[0325 01:40:37 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:3381.40 sec.
[32m[0325 01:40:38 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-7806645.
  0%|          |0/18822[00:00<?,?it/s] 75%|#######4  |14074/18822[03:00<01:00,78.18it/s] 79%|#######8  |14834/18822[03:10<00:51,78.18it/s]100%|##########|18822/18822[03:58<00:00,79.00it/s]
44
[32m[0325 01:44:37 @monitor.py:363][0m QueueInput/queue_size: 0.84051
[32m[0325 01:44:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.04
[32m[0325 01:44:37 @monitor.py:363][0m activation-summaries/output-rms: 0.042234
[32m[0325 01:44:37 @monitor.py:363][0m cross_entropy_loss: 1.6082
[32m[0325 01:44:37 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59575
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 01:44:37 @monitor.py:363][0m train-error-top1: 0.43405
[32m[0325 01:44:37 @monitor.py:363][0m val-error-top1: 0.43677
[32m[0325 01:44:37 @monitor.py:363][0m val-utt-error: 0.10079
[32m[0325 01:44:37 @monitor.py:363][0m validation_cost: 1.6394
[32m[0325 01:44:37 @monitor.py:363][0m wd_cost: 3.0794e-11
[32m[0325 01:44:37 @group.py:42][0m Callbacks took 239.306 sec in total. InferenceRunner: 238.272sec
[32m[0325 01:44:37 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9492/173481[03:00<51:49,52.73it/s]  6%|5         |10002/173481[03:10<51:40,52.73it/s] 11%|#         |18597/173481[06:00<49:59,51.63it/s] 11%|#1        |19142/173481[06:10<49:49,51.63it/s] 15%|#5        |26726/173481[09:00<50:46,48.18it/s] 16%|#5        |27212/173481[09:10<50:36,48.18it/s] 20%|##        |35123/173481[12:00<48:39,47.40it/s] 21%|##        |35640/173481[12:10<48:28,47.40it/s] 25%|##4       |42563/173481[15:00<49:25,44.15it/s] 25%|##4       |43026/173481[15:10<49:14,44.15it/s] 29%|##9       |50621/173481[18:00<46:03,44.45it/s] 29%|##9       |51124/173481[18:11<45:52,44.45it/s] 34%|###3      |58938/173481[21:00<42:07,45.31it/s] 34%|###4      |59457/173481[21:11<41:56,45.31it/s] 39%|###8      |67201/173481[24:00<38:50,45.60it/s] 39%|###8      |67581/173481[24:11<38:42,45.60it/s] 43%|####3     |75176/173481[27:00<36:27,44.94it/s] 44%|####3     |75668/173481[27:11<36:16,44.94it/s] 48%|####7     |83115/173481[30:00<33:49,44.52it/s] 48%|####8     |83603/173481[30:11<33:38,44.52it/s] 53%|#####2    |91093/173481[33:00<30:54,44.42it/s] 53%|#####2    |91610/173481[33:11<30:43,44.42it/s] 57%|#####6    |98336/173481[36:00<29:39,42.22it/s] 57%|#####6    |98834/173481[36:11<29:27,42.22it/s] 61%|######1   |106134/173481[39:00<26:14,42.77it/s] 61%|######1   |106675/173481[39:12<26:02,42.77it/s] 66%|######5   |113635/173481[42:00<23:37,42.21it/s] 66%|######5   |114047/173481[42:12<23:28,42.21it/s] 69%|######9   |120427/173481[45:00<22:11,39.85it/s] 70%|######9   |120910/173481[45:12<21:59,39.85it/s] 73%|#######3  |127361/173481[48:00<19:37,39.17it/s] 74%|#######3  |127855/173481[48:12<19:24,39.17it/s] 78%|#######7  |134478/173481[51:00<16:31,39.35it/s] 78%|#######7  |134987/173481[51:13<16:18,39.35it/s] 82%|########1 |141461/173481[54:00<13:39,39.07it/s] 82%|########1 |141990/173481[54:13<13:26,39.07it/s] 85%|########5 |147731/173481[57:00<11:40,36.78it/s] 85%|########5 |148230/173481[57:13<11:26,36.78it/s] 89%|########9 |154431/173481[1:00:00<08:34,37.00it/s] 89%|########9 |154925/173481[1:00:13<08:21,37.00it/s] 93%|#########2|161176/173481[1:03:00<05:30,37.23it/s] 93%|#########3|161667/173481[1:03:13<05:17,37.23it/s] 97%|#########6|168233/173481[1:06:00<02:17,38.19it/s] 97%|#########7|168775/173481[1:06:13<02:03,38.19it/s]100%|##########|173481/173481[1:08:07<00:00,42.45it/s]
[32m[0325 02:52:44 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:4087.03 sec.
[32m[0325 02:52:45 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-7980126.
  0%|          |0/18822[00:00<?,?it/s] 72%|#######2  |13565/18822[03:00<01:09,75.36it/s] 76%|#######6  |14350/18822[03:10<00:59,75.36it/s]100%|##########|18822/18822[04:07<00:00,76.10it/s]
45
[32m[0325 02:56:53 @monitor.py:363][0m QueueInput/queue_size: 0.77017
[32m[0325 02:56:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.935
[32m[0325 02:56:53 @monitor.py:363][0m activation-summaries/output-rms: 0.041546
[32m[0325 02:56:53 @monitor.py:363][0m cross_entropy_loss: 1.6026
[32m[0325 02:56:53 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59572
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 02:56:53 @monitor.py:363][0m train-error-top1: 0.43079
[32m[0325 02:56:53 @monitor.py:363][0m val-error-top1: 0.43685
[32m[0325 02:56:53 @monitor.py:363][0m val-utt-error: 0.10196
[32m[0325 02:56:53 @monitor.py:363][0m validation_cost: 1.6406
[32m[0325 02:56:53 @monitor.py:363][0m wd_cost: 3.0792e-11
[32m[0325 02:56:53 @group.py:42][0m Callbacks took 248.983 sec in total. InferenceRunner: 247.744sec
[32m[0325 02:56:53 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |7880/173481[03:00<1:03:02,43.78it/s]  5%|4         |8321/173481[03:10<1:02:52,43.78it/s]  9%|8         |15342/173481[06:00<1:01:53,42.58it/s]  9%|9         |15804/173481[06:10<1:01:42,42.58it/s] 14%|#3        |23542/173481[09:00<56:46,44.02it/s]   14%|#3        |24045/173481[09:10<56:34,44.02it/s] 18%|#8        |31832/173481[12:00<52:26,45.01it/s] 19%|#8        |32319/173481[12:10<52:16,45.01it/s] 23%|##2       |39770/173481[15:00<50:01,44.55it/s] 23%|##3       |40235/173481[15:10<49:50,44.55it/s] 28%|##7       |47726/173481[18:00<47:13,44.38it/s] 28%|##7       |48212/173481[18:10<47:02,44.38it/s] 32%|###2      |55990/173481[21:00<43:23,45.13it/s] 33%|###2      |56528/173481[21:11<43:11,45.13it/s] 37%|###6      |63866/173481[24:00<41:07,44.43it/s] 37%|###7      |64320/173481[24:11<40:56,44.43it/s] 41%|####1     |71904/173481[27:00<38:00,44.54it/s] 42%|####1     |72376/173481[27:11<37:49,44.54it/s] 45%|####4     |77875/173481[30:00<41:54,38.02it/s] 45%|####5     |78411/173481[30:11<41:40,38.02it/s] 50%|####9     |85924/173481[33:00<35:30,41.10it/s] 50%|####9     |86487/173481[33:11<35:16,41.10it/s] 54%|#####4    |94073/173481[36:00<30:43,43.08it/s] 55%|#####4    |94606/173481[36:11<30:30,43.08it/s] 59%|#####8    |101996/173481[39:00<27:21,43.54it/s] 59%|#####9    |102516/173481[39:12<27:09,43.54it/s] 63%|######3   |109320/173481[42:00<25:25,42.06it/s] 63%|######3   |109812/173481[42:12<25:13,42.06it/s] 67%|######7   |116732/173481[45:00<22:43,41.61it/s] 68%|######7   |117223/173481[45:12<22:31,41.61it/s] 72%|#######1  |124069/173481[48:00<19:59,41.18it/s] 72%|#######1  |124517/173481[48:12<19:48,41.18it/s] 76%|#######5  |131266/173481[51:00<17:20,40.57it/s] 76%|#######5  |131819/173481[51:12<17:06,40.57it/s] 80%|#######9  |138430/173481[54:00<14:32,40.18it/s] 80%|########  |138973/173481[54:12<14:18,40.18it/s] 84%|########4 |146358/173481[57:00<10:45,42.02it/s] 85%|########4 |146924/173481[57:13<10:31,42.02it/s] 89%|########8 |154206/173481[1:00:00<07:30,42.80it/s] 89%|########9 |154743/173481[1:00:13<07:17,42.80it/s] 93%|#########3|161790/173481[1:03:00<04:35,42.46it/s] 94%|#########3|162310/173481[1:03:13<04:23,42.46it/s] 98%|#########7|169499/173481[1:06:00<01:33,42.64it/s] 98%|#########8|170050/173481[1:06:13<01:20,42.64it/s]100%|##########|173481/173481[1:07:36<00:00,42.76it/s]
[32m[0325 04:04:29 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:4056.62 sec.
[32m[0325 04:04:30 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-8153607.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######4  |13962/18822[03:00<01:02,77.56it/s] 79%|#######8  |14815/18822[03:10<00:51,77.56it/s]100%|##########|18822/18822[04:00<00:00,78.32it/s]
46
[32m[0325 04:08:31 @monitor.py:363][0m QueueInput/queue_size: 0.90418
[32m[0325 04:08:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.223
[32m[0325 04:08:31 @monitor.py:363][0m activation-summaries/output-rms: 0.04124
[32m[0325 04:08:31 @monitor.py:363][0m cross_entropy_loss: 1.6199
[32m[0325 04:08:31 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59571
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 04:08:31 @monitor.py:363][0m train-error-top1: 0.42939
[32m[0325 04:08:31 @monitor.py:363][0m val-error-top1: 0.4363
[32m[0325 04:08:31 @monitor.py:363][0m val-utt-error: 0.097917
[32m[0325 04:08:31 @monitor.py:363][0m validation_cost: 1.6379
[32m[0325 04:08:31 @monitor.py:363][0m wd_cost: 3.0792e-11
[32m[0325 04:08:31 @group.py:42][0m Callbacks took 241.449 sec in total. InferenceRunner: 240.335sec
[32m[0325 04:08:31 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7239/173481[03:00<1:08:53,40.21it/s]  4%|4         |7682/173481[03:10<1:08:42,40.21it/s]  9%|8         |14794/173481[06:00<1:04:23,41.07it/s]  9%|8         |15262/173481[06:10<1:04:12,41.07it/s] 13%|#2        |22290/173481[09:00<1:00:56,41.35it/s] 13%|#3        |22796/173481[09:10<1:00:43,41.35it/s] 17%|#6        |29367/173481[12:00<59:35,40.31it/s]   17%|#7        |29852/173481[12:10<59:23,40.31it/s] 21%|##1       |37201/173481[15:00<54:16,41.85it/s] 22%|##1       |37690/173481[15:10<54:04,41.85it/s] 26%|##5       |44867/173481[18:00<50:46,42.22it/s] 26%|##6       |45358/173481[18:11<50:34,42.22it/s] 30%|###       |52831/173481[21:00<46:32,43.21it/s] 31%|###       |53342/173481[21:11<46:20,43.21it/s] 35%|###4      |60519/173481[24:00<43:51,42.93it/s] 35%|###4      |60623/173481[24:11<43:48,42.93it/s] 39%|###9      |67731/173481[27:00<42:31,41.45it/s] 39%|###9      |68246/173481[27:11<42:18,41.45it/s] 44%|####3     |75563/173481[30:00<38:26,42.45it/s] 44%|####3     |76078/173481[30:11<38:14,42.45it/s] 48%|####8     |83604/173481[33:00<34:24,43.53it/s] 48%|####8     |84106/173481[33:11<34:12,43.53it/s] 53%|#####2    |91609/173481[36:00<31:01,43.99it/s] 53%|#####3    |92043/173481[36:12<30:51,43.99it/s] 57%|#####7    |99516/173481[39:00<28:02,43.96it/s] 58%|#####7    |100048/173481[39:12<27:50,43.96it/s] 62%|######1   |107459/173481[42:00<24:59,44.04it/s] 62%|######2   |108033/173481[42:12<24:46,44.04it/s] 67%|######6   |115436/173481[45:00<21:53,44.18it/s] 67%|######6   |115989/173481[45:12<21:41,44.18it/s] 71%|#######   |122361/173481[48:00<20:42,41.13it/s] 71%|#######   |122904/173481[48:12<20:29,41.13it/s] 75%|#######5  |130710/173481[51:00<16:21,43.60it/s] 76%|#######5  |131258/173481[51:12<16:08,43.60it/s] 80%|########  |139137/173481[54:00<12:40,45.15it/s] 81%|########  |139677/173481[54:12<12:28,45.15it/s] 85%|########4 |147166/173481[57:00<09:46,44.88it/s] 85%|########5 |147710/173481[57:13<09:34,44.88it/s] 90%|########9 |155544/173481[1:00:00<06:32,45.69it/s] 90%|########9 |156081/173481[1:00:13<06:20,45.69it/s] 94%|#########4|163805/173481[1:03:00<03:31,45.79it/s] 95%|#########4|164422/173481[1:03:13<03:17,45.79it/s] 99%|#########8|171655/173481[1:06:00<00:40,44.67it/s] 99%|#########9|172278/173481[1:06:13<00:26,44.67it/s][32m[0325 05:15:13 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:4001.83 sec.
100%|##########|173481/173481[1:06:41<00:00,43.35it/s]
[32m[0325 05:15:13 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-8327088.
  0%|          |0/18822[00:00<?,?it/s] 65%|######5   |12244/18822[03:00<01:36,68.02it/s] 69%|######9   |13061/18822[03:10<01:24,68.02it/s]100%|##########|18822/18822[04:22<00:00,71.57it/s]
47
[32m[0325 05:19:36 @monitor.py:363][0m QueueInput/queue_size: 6.2495
[32m[0325 05:19:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.998
[32m[0325 05:19:36 @monitor.py:363][0m activation-summaries/output-rms: 0.040797
[32m[0325 05:19:36 @monitor.py:363][0m cross_entropy_loss: 1.5688
[32m[0325 05:19:36 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 05:19:36 @monitor.py:363][0m train-error-top1: 0.42628
[32m[0325 05:19:36 @monitor.py:363][0m val-error-top1: 0.43674
[32m[0325 05:19:36 @monitor.py:363][0m val-utt-error: 0.098395
[32m[0325 05:19:36 @monitor.py:363][0m validation_cost: 1.6381
[32m[0325 05:19:36 @monitor.py:363][0m wd_cost: 6.1583e-12
[32m[0325 05:19:36 @group.py:42][0m Callbacks took 263.336 sec in total. InferenceRunner: 263.017sec
[32m[0325 05:19:36 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8667/173481[03:00<57:03,48.15it/s]  5%|5         |9157/173481[03:10<56:52,48.15it/s]  9%|9         |16427/173481[06:00<57:32,45.49it/s] 10%|9         |16872/173481[06:10<57:22,45.49it/s] 14%|#3        |24128/173481[09:00<56:27,44.09it/s] 14%|#4        |24613/173481[09:10<56:16,44.09it/s] 18%|#7        |30924/173481[12:00<58:24,40.68it/s] 18%|#8        |31405/173481[12:10<58:12,40.68it/s] 23%|##2       |39050/173481[15:00<52:21,42.79it/s] 23%|##2       |39582/173481[15:10<52:08,42.79it/s] 27%|##7       |47434/173481[18:00<47:05,44.60it/s] 28%|##7       |47991/173481[18:10<46:53,44.60it/s] 32%|###1      |54984/173481[21:00<45:40,43.23it/s] 32%|###1      |55506/173481[21:11<45:28,43.23it/s] 37%|###7      |64444/173481[24:00<38:18,47.44it/s] 38%|###7      |65067/173481[24:11<38:05,47.44it/s] 42%|####2     |73585/173481[27:00<33:56,49.05it/s] 43%|####2     |74017/173481[27:11<33:47,49.05it/s] 48%|####7     |82763/173481[30:00<30:14,50.00it/s] 48%|####8     |83322/173481[30:11<30:03,50.00it/s] 53%|#####2    |91774/173481[33:00<27:13,50.03it/s] 53%|#####3    |92352/173481[33:11<27:01,50.03it/s] 58%|#####7    |100582/173481[36:00<24:33,49.47it/s] 58%|#####8    |101229/173481[36:11<24:20,49.47it/s] 63%|######3   |110073/173481[39:00<20:42,51.05it/s] 64%|######3   |110676/173481[39:12<20:30,51.05it/s] 68%|######8   |118558/173481[42:00<18:40,49.01it/s] 69%|######8   |119143/173481[42:12<18:28,49.01it/s] 73%|#######3  |126937/173481[45:00<16:14,47.75it/s] 74%|#######3  |127587/173481[45:12<16:01,47.75it/s] 78%|#######8  |136073/173481[48:00<12:40,49.20it/s] 79%|#######8  |136705/173481[48:12<12:27,49.20it/s] 84%|########3 |145110/173481[51:00<09:30,49.70it/s] 84%|########4 |145727/173481[51:12<09:18,49.70it/s] 89%|########8 |154050/173481[54:00<06:31,49.68it/s] 89%|########9 |154687/173481[54:12<06:18,49.68it/s] 94%|#########3|163068/173481[57:00<03:28,49.88it/s] 94%|#########4|163726/173481[57:13<03:15,49.88it/s] 99%|#########9|171908/173481[1:00:00<00:31,49.49it/s] 99%|#########9|172482/173481[1:00:13<00:20,49.49it/s][32m[0325 06:20:31 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:3654.86 sec.
100%|##########|173481/173481[1:00:54<00:00,47.47it/s]
[32m[0325 06:20:31 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-8500569.
  0%|          |0/18822[00:00<?,?it/s] 81%|########1 |15271/18822[03:00<00:41,84.84it/s] 86%|########5 |16115/18822[03:10<00:31,84.84it/s]100%|##########|18822/18822[03:39<00:00,85.73it/s]
48
[32m[0325 06:24:11 @monitor.py:363][0m QueueInput/queue_size: 0.90673
[32m[0325 06:24:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.843
[32m[0325 06:24:11 @monitor.py:363][0m activation-summaries/output-rms: 0.040377
[32m[0325 06:24:11 @monitor.py:363][0m cross_entropy_loss: 1.6123
[32m[0325 06:24:11 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 06:24:11 @monitor.py:363][0m train-error-top1: 0.43074
[32m[0325 06:24:11 @monitor.py:363][0m val-error-top1: 0.43615
[32m[0325 06:24:11 @monitor.py:363][0m val-utt-error: 0.10041
[32m[0325 06:24:11 @monitor.py:363][0m validation_cost: 1.6359
[32m[0325 06:24:11 @monitor.py:363][0m wd_cost: 6.1583e-12
[32m[0325 06:24:11 @group.py:42][0m Callbacks took 220.008 sec in total. InferenceRunner: 219.565sec
[32m[0325 06:24:11 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10034/173481[03:00<48:52,55.74it/s]  6%|6         |10545/173481[03:10<48:42,55.74it/s] 11%|#1        |19185/173481[06:00<48:21,53.18it/s] 11%|#1        |19770/173481[06:10<48:10,53.18it/s] 17%|#6        |29145/173481[09:00<44:21,54.23it/s] 17%|#7        |29713/173481[09:10<44:10,54.23it/s] 22%|##2       |38835/173481[12:00<41:31,54.03it/s] 23%|##2       |39423/173481[12:10<41:21,54.03it/s] 27%|##7       |47473/173481[15:00<41:19,50.83it/s] 28%|##7       |48014/173481[15:10<41:08,50.83it/s] 33%|###2      |56959/173481[18:00<37:31,51.75it/s] 33%|###3      |57581/173481[18:11<37:19,51.75it/s] 39%|###9      |68462/173481[21:00<30:36,57.19it/s] 40%|###9      |69090/173481[21:11<30:25,57.19it/s] 46%|####5     |79769/173481[24:00<26:05,59.87it/s] 46%|####6     |80506/173481[24:11<25:53,59.87it/s] 53%|#####2    |91701/173481[27:00<21:39,62.91it/s] 53%|#####3    |92411/173481[27:11<21:28,62.91it/s] 59%|#####8    |101864/173481[30:00<20:03,59.51it/s] 59%|#####9    |102461/173481[30:11<19:53,59.51it/s] 64%|######3   |110326/173481[33:00<20:02,52.53it/s] 64%|######3   |110997/173481[33:11<19:49,52.53it/s] 69%|######9   |120265/173481[36:00<16:28,53.84it/s] 70%|######9   |120951/173481[36:11<16:15,53.84it/s] 75%|#######4  |129750/173481[39:00<13:41,53.26it/s] 75%|#######5  |130360/173481[39:12<13:29,53.26it/s] 80%|########  |139046/173481[42:00<10:56,52.44it/s] 81%|########  |139736/173481[42:12<10:43,52.44it/s] 86%|########5 |148390/173481[45:00<08:00,52.17it/s] 86%|########5 |149039/173481[45:12<07:48,52.17it/s] 91%|######### |157733/173481[48:00<05:02,52.04it/s] 91%|#########1|158408/173481[48:12<04:49,52.04it/s] 96%|#########5|166057/173481[51:00<02:31,48.97it/s] 96%|#########6|166677/173481[51:12<02:18,48.97it/s][32m[0325 07:17:44 @base.py:257][0m Epoch 51 (global_step 8674050) finished, time:3213.53 sec.
100%|##########|173481/173481[53:33<00:00,53.98it/s]
[32m[0325 07:17:45 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-8674050.
[32m[0325 07:17:46 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 85%|########5 |16019/18822[03:00<00:31,88.99it/s] 91%|######### |17045/18822[03:10<00:19,88.99it/s]100%|##########|18822/18822[03:29<00:00,89.95it/s]
49
[32m[0325 07:21:15 @monitor.py:363][0m QueueInput/queue_size: 0.67041
[32m[0325 07:21:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.029
[32m[0325 07:21:15 @monitor.py:363][0m activation-summaries/output-rms: 0.042201
[32m[0325 07:21:15 @monitor.py:363][0m cross_entropy_loss: 1.608
[32m[0325 07:21:15 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 07:21:15 @monitor.py:363][0m train-error-top1: 0.43335
[32m[0325 07:21:15 @monitor.py:363][0m val-error-top1: 0.43675
[32m[0325 07:21:15 @monitor.py:363][0m val-utt-error: 0.10031
[32m[0325 07:21:15 @monitor.py:363][0m validation_cost: 1.6393
[32m[0325 07:21:15 @monitor.py:363][0m wd_cost: 1.2317e-12
[32m[0325 07:21:15 @group.py:42][0m Callbacks took 210.677 sec in total. InferenceRunner: 209.301sec
[32m[0325 07:21:15 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9779/173481[03:00<50:13,54.33it/s]  6%|5         |10305/173481[03:10<50:03,54.33it/s] 11%|#         |18954/173481[06:00<48:58,52.60it/s] 11%|#1        |19470/173481[06:10<48:48,52.60it/s] 16%|#6        |27877/173481[09:00<47:32,51.04it/s] 16%|#6        |28405/173481[09:10<47:22,51.04it/s] 21%|##        |36126/173481[12:00<47:24,48.29it/s] 21%|##1       |36635/173481[12:10<47:13,48.29it/s] 26%|##6       |45269/173481[15:00<43:09,49.51it/s] 26%|##6       |45901/173481[15:10<42:56,49.51it/s] 32%|###1      |54910/173481[18:00<38:24,51.45it/s] 32%|###2      |55628/173481[18:10<38:10,51.45it/s] 38%|###7      |65106/173481[21:00<33:29,53.92it/s] 38%|###7      |65700/173481[21:11<33:18,53.92it/s] 43%|####3     |74989/173481[24:00<30:10,54.41it/s] 44%|####3     |75620/173481[24:11<29:58,54.41it/s] 49%|####8     |84936/173481[27:00<26:54,54.83it/s] 49%|####9     |85575/173481[27:11<26:43,54.83it/s] 54%|#####4    |93725/173481[30:00<25:44,51.65it/s] 54%|#####4    |94327/173481[30:11<25:32,51.65it/s] 60%|#####9    |103472/173481[33:00<22:04,52.87it/s] 60%|#####9    |104066/173481[33:11<21:52,52.87it/s] 65%|######5   |112769/173481[36:00<19:21,52.25it/s] 65%|######5   |113395/173481[36:11<19:09,52.25it/s] 71%|#######   |122413/173481[39:00<16:05,52.91it/s] 71%|#######   |123039/173481[39:12<15:53,52.91it/s] 76%|#######6  |132025/173481[42:00<12:59,53.15it/s] 76%|#######6  |132655/173481[42:12<12:48,53.15it/s] 82%|########1 |141571/173481[45:00<10:01,53.09it/s] 82%|########1 |142225/173481[45:12<09:48,53.09it/s] 87%|########6 |150423/173481[48:00<07:31,51.06it/s] 87%|########7 |151099/173481[48:12<07:18,51.06it/s] 92%|#########2|160096/173481[51:00<04:15,52.36it/s] 93%|#########2|160775/173481[51:12<04:02,52.36it/s] 98%|#########7|169346/173481[54:00<01:19,51.87it/s] 98%|#########8|170025/173481[54:12<01:06,51.87it/s]100%|##########|173481/173481[55:19<00:00,52.26it/s]
[32m[0325 08:16:34 @base.py:257][0m Epoch 52 (global_step 8847531) finished, time:3319.32 sec.
[32m[0325 08:16:36 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-8847531.
  0%|          |0/18822[00:00<?,?it/s] 87%|########7 |16396/18822[03:00<00:26,91.09it/s] 93%|#########3|17553/18822[03:10<00:13,91.09it/s]100%|##########|18822/18822[03:23<00:00,92.30it/s]
50
[32m[0325 08:20:00 @monitor.py:363][0m QueueInput/queue_size: 0.68466
[32m[0325 08:20:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.929
[32m[0325 08:20:00 @monitor.py:363][0m activation-summaries/output-rms: 0.041568
[32m[0325 08:20:00 @monitor.py:363][0m cross_entropy_loss: 1.601
[32m[0325 08:20:00 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 08:20:00 @monitor.py:363][0m train-error-top1: 0.43142
[32m[0325 08:20:00 @monitor.py:363][0m val-error-top1: 0.43685
[32m[0325 08:20:00 @monitor.py:363][0m val-utt-error: 0.10105
[32m[0325 08:20:00 @monitor.py:363][0m validation_cost: 1.6405
[32m[0325 08:20:00 @monitor.py:363][0m wd_cost: 1.2317e-12
[32m[0325 08:20:00 @group.py:42][0m Callbacks took 205.182 sec in total. InferenceRunner: 203.954sec
[32m[0325 08:20:00 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9671/173481[03:00<50:48,53.73it/s]  6%|5         |10165/173481[03:10<50:39,53.73it/s] 11%|#         |18802/173481[06:00<49:24,52.18it/s] 11%|#1        |19344/173481[06:10<49:13,52.18it/s] 16%|#5        |27029/173481[09:00<50:05,48.73it/s] 16%|#5        |27519/173481[09:10<49:55,48.73it/s] 21%|##        |36046/173481[12:00<46:22,49.40it/s] 21%|##1       |36571/173481[12:10<46:11,49.40it/s] 26%|##5       |45000/173481[15:00<43:11,49.57it/s] 26%|##6       |45539/173481[15:10<43:01,49.57it/s] 31%|###1      |53954/173481[18:00<40:07,49.66it/s] 31%|###1      |54491/173481[18:11<39:56,49.66it/s] 36%|###6      |63015/173481[21:00<36:49,49.99it/s] 37%|###6      |63569/173481[21:11<36:38,49.99it/s] 41%|####1     |71849/173481[24:00<34:11,49.53it/s] 42%|####1     |72295/173481[24:11<34:02,49.53it/s] 46%|####5     |79678/173481[27:00<33:45,46.32it/s] 46%|####6     |80226/173481[27:11<33:33,46.32it/s] 51%|#####     |88000/173481[30:00<30:47,46.27it/s] 51%|#####1    |88568/173481[30:11<30:35,46.27it/s] 55%|#####5    |96110/173481[33:00<28:14,45.65it/s] 56%|#####5    |96564/173481[33:11<28:05,45.65it/s] 61%|######    |105148/173481[36:00<23:48,47.82it/s] 61%|######    |105730/173481[36:12<23:36,47.82it/s] 66%|######5   |114463/173481[39:00<19:47,49.71it/s] 66%|######6   |115072/173481[39:12<19:35,49.71it/s] 71%|#######1  |123260/173481[42:00<17:00,49.24it/s] 71%|#######1  |123364/173481[42:12<16:57,49.24it/s] 76%|#######5  |131465/173481[45:00<14:47,47.34it/s] 76%|#######6  |132062/173481[45:12<14:34,47.34it/s] 81%|########  |140296/173481[48:00<11:28,48.18it/s] 81%|########1 |140844/173481[48:12<11:17,48.18it/s] 86%|########5 |148877/173481[51:00<08:33,47.93it/s] 86%|########6 |149477/173481[51:12<08:20,47.93it/s] 91%|######### |157847/173481[54:00<05:19,48.86it/s] 91%|#########1|158499/173481[54:12<05:06,48.86it/s] 97%|#########6|167701/173481[57:00<01:51,51.63it/s] 97%|#########7|168483/173481[57:13<01:36,51.63it/s]100%|##########|173481/173481[58:44<00:00,49.22it/s]
[32m[0325 09:18:44 @base.py:257][0m Epoch 53 (global_step 9021012) finished, time:3524.65 sec.
[32m[0325 09:18:44 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-9021012.
  0%|          |0/18822[00:00<?,?it/s] 80%|########  |15129/18822[03:00<00:43,84.05it/s] 85%|########5 |16075/18822[03:10<00:32,84.05it/s]100%|##########|18822/18822[03:37<00:00,86.36it/s]
51
[32m[0325 09:22:22 @monitor.py:363][0m QueueInput/queue_size: 0.77253
[32m[0325 09:22:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.219
[32m[0325 09:22:22 @monitor.py:363][0m activation-summaries/output-rms: 0.041236
[32m[0325 09:22:22 @monitor.py:363][0m cross_entropy_loss: 1.6192
[32m[0325 09:22:22 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 09:22:22 @monitor.py:363][0m train-error-top1: 0.42979
[32m[0325 09:22:22 @monitor.py:363][0m val-error-top1: 0.43632
[32m[0325 09:22:22 @monitor.py:363][0m val-utt-error: 0.098927
[32m[0325 09:22:22 @monitor.py:363][0m validation_cost: 1.6378
[32m[0325 09:22:22 @monitor.py:363][0m wd_cost: 1.2317e-12
[32m[0325 09:22:22 @group.py:42][0m Callbacks took 218.111 sec in total. InferenceRunner: 217.967sec
[32m[0325 09:22:22 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10492/173481[03:00<46:36,58.29it/s]  6%|6         |10883/173481[03:10<46:29,58.29it/s] 11%|#         |18797/173481[06:00<50:03,51.50it/s] 11%|#1        |19326/173481[06:10<49:53,51.50it/s] 16%|#5        |27634/173481[09:00<48:21,50.27it/s] 16%|#6        |28144/173481[09:10<48:11,50.27it/s] 21%|##        |36024/173481[12:00<47:21,48.37it/s] 21%|##1       |36601/173481[12:10<47:10,48.37it/s] 26%|##5       |44574/173481[15:00<44:49,47.93it/s] 26%|##5       |45030/173481[15:10<44:40,47.93it/s] 30%|##9       |51946/173481[18:00<45:51,44.17it/s] 30%|###       |52448/173481[18:10<45:40,44.17it/s] 35%|###4      |60229/173481[21:00<41:52,45.07it/s] 35%|###5      |60753/173481[21:11<41:41,45.07it/s] 40%|###9      |68704/173481[24:00<37:55,46.05it/s] 40%|###9      |69237/173481[24:11<37:43,46.05it/s] 44%|####4     |76964/173481[27:00<34:59,45.97it/s] 45%|####4     |77518/173481[27:11<34:47,45.97it/s] 49%|####9     |85625/173481[30:00<31:08,47.02it/s] 50%|####9     |86166/173481[30:11<30:57,47.02it/s] 54%|#####4    |93744/173481[33:00<28:51,46.04it/s] 54%|#####4    |94103/173481[33:11<28:44,46.04it/s] 58%|#####8    |101289/173481[36:00<27:25,43.88it/s] 59%|#####8    |101828/173481[36:11<27:13,43.88it/s] 63%|######3   |109581/173481[39:00<23:41,44.94it/s] 63%|######3   |110137/173481[39:12<23:29,44.94it/s] 68%|######7   |117840/173481[42:00<20:25,45.41it/s] 68%|######8   |118413/173481[42:12<20:12,45.41it/s] 73%|#######2  |126146/173481[45:00<17:14,45.77it/s] 73%|#######3  |126712/173481[45:12<17:01,45.77it/s] 77%|#######7  |133909/173481[48:00<14:51,44.41it/s] 78%|#######7  |134543/173481[48:12<14:36,44.41it/s] 83%|########2 |143264/173481[51:00<10:30,47.89it/s] 83%|########2 |143919/173481[51:12<10:17,47.89it/s] 88%|########7 |152440/173481[54:00<07:06,49.39it/s] 88%|########8 |153098/173481[54:12<06:52,49.39it/s] 93%|#########3|161838/173481[57:00<03:49,50.76it/s] 94%|#########3|162520/173481[57:13<03:35,50.76it/s] 99%|#########8|171171/173481[1:00:00<00:45,51.30it/s] 99%|#########9|171873/173481[1:00:13<00:31,51.30it/s]100%|##########|173481/173481[1:00:44<00:00,47.60it/s]
[32m[0325 10:23:07 @base.py:257][0m Epoch 54 (global_step 9194493) finished, time:3644.56 sec.
[32m[0325 10:23:07 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_32_quant_ends_False/model-9194493.
  0%|          |0/18822[00:00<?,?it/s] 87%|########6 |16300/18822[03:00<00:27,90.55it/s] 93%|#########2|17440/18822[03:10<00:15,90.55it/s]100%|##########|18822/18822[03:24<00:00,91.94it/s]
52
[32m[0325 10:26:32 @monitor.py:363][0m QueueInput/queue_size: 0.67694
[32m[0325 10:26:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.997
[32m[0325 10:26:32 @monitor.py:363][0m activation-summaries/output-rms: 0.040784
[32m[0325 10:26:32 @monitor.py:363][0m cross_entropy_loss: 1.5693
[32m[0325 10:26:32 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.5406e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2391e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.5607e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.615e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6649e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7079e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9833e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3971e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1551e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.746e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0325 10:26:32 @monitor.py:363][0m train-error-top1: 0.42733
[32m[0325 10:26:32 @monitor.py:363][0m val-error-top1: 0.43669
[32m[0325 10:26:32 @monitor.py:363][0m val-utt-error: 0.098927
[32m[0325 10:26:32 @monitor.py:363][0m validation_cost: 1.6379
[32m[0325 10:26:32 @monitor.py:363][0m wd_cost: 2.4633e-13
[32m[0325 10:26:32 @group.py:42][0m Callbacks took 205.442 sec in total. InferenceRunner: 204.885sec
[32m[0325 10:26:32 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11479/173481[03:00<42:20,63.77it/s]  7%|7         |12219/173481[03:10<42:08,63.77it/s] 13%|#3        |22935/173481[06:00<39:23,63.71it/s] 14%|#3        |23528/173481[06:10<39:13,63.71it/s] 20%|#9        |34365/173481[09:00<36:27,63.60it/s] 20%|##        |35008/173481[09:10<36:17,63.60it/s] 26%|##6       |45488/173481[12:00<34:01,62.68it/s] 27%|##6       |46202/173481[12:10<33:50,62.68it/s] 33%|###2      |56706/173481[15:00<31:08,62.50it/s] 33%|###3      |57320/173481[15:10<30:58,62.50it/s] 38%|###8      |66142/173481[18:00<31:22,57.02it/s] 38%|###8      |66742/173481[18:11<31:11,57.02it/s]slurmstepd: *** STEP 82584.0 ON sls-sm-16 CANCELLED AT 2018-03-25T10:45:36 DUE TO TIME LIMIT ***
srun: error: sls-sm-16: task 0: Terminated
srun: Force Terminated job step 82584.0
