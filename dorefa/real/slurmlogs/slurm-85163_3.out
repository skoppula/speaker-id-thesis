sls-sm-6 0
SLURM_JOBID=85166
SLURM_TASKID=3
[32m[0328 12:10:37 @logger.py:67][0m Existing log file 'train_log/lcn_w_8_a_8_quant_ends_True_preload/log.log' backuped to 'train_log/lcn_w_8_a_8_quant_ends_True_preload/log.log.0328-121037'
[32m[0328 12:10:37 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=8 --bita=8 --quant_ends=True --load_ckpt=train_log/lcn_w_8_a_32_quant_ends_False/checkpoint
[32m[0328 12:10:42 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 12:10:42 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 12:10:43 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 12:10:43 @drf_run.py:166][0m Using host: sls-sm-6
[32m[0328 12:10:43 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 12:10:43 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 12:10:43 @drf_run.py:188][0m Using GPU: 0
[32m[0328 12:10:43 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 12:10:43 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 12:10:43 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 12:10:43 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0a/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0a/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0b/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0b/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0c/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0c/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0d/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0d/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0e/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0e/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0f/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0f/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0g/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0g/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0h/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0h/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0i/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0i/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0j/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0j/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 12:10:43 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 12:10:43 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 12:10:43 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 12:10:44 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 12:10:44 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 12:10:44 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 12:10:44 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 12:10:44 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0328 12:10:44 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 12:10:44 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0328 12:10:47 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0328 12:10:47 @base.py:196][0m Setup callbacks graph ...
[32m[0328 12:10:47 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0a/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0a/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0b/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0b/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0c/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0c/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0d/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0d/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0e/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0e/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0f/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0f/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0g/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0g/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0h/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0h/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0i/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0i/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0j/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0j/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 12:10:48 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 12:10:48 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0328 12:10:48 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 12:10:48 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0328 12:10:50 @base.py:212][0m Creating the session ...
2018-03-28 12:10:51.180603: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-28 12:10:54.241497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:02:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-28 12:10:54.241541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
[32m[0328 12:10:56 @base.py:220][0m Initializing the session ...
[32m[0328 12:10:56 @sessinit.py:116][0m Restoring checkpoint from train_log/lcn_w_8_a_32_quant_ends_False/model-9194493 ...
[32m[0328 12:10:57 @base.py:227][0m Graph Finalized.
[32m[0328 12:10:57 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 12:10:57 @steps.py:127][0m Start training with global_step=9194493
[32m[0328 12:11:00 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8706/173481[03:00<56:47,48.36it/s]  5%|5         |9210/173481[03:10<56:36,48.36it/s] 10%|#         |17487/173481[06:00<53:31,48.57it/s] 10%|#         |17982/173481[06:10<53:21,48.57it/s] 15%|#5        |26417/173481[09:00<49:56,49.09it/s] 16%|#5        |26942/173481[09:10<49:45,49.09it/s] 20%|##        |35350/173481[12:00<46:38,49.35it/s] 21%|##        |35875/173481[12:10<46:28,49.35it/s] 26%|##5       |44298/173481[15:00<43:28,49.53it/s] 26%|##5       |44847/173481[15:10<43:17,49.53it/s] 31%|###       |53419/173481[18:00<39:56,50.09it/s] 31%|###1      |53953/173481[18:10<39:46,50.09it/s] 36%|###6      |62500/173481[21:00<36:47,50.27it/s] 36%|###6      |63047/173481[21:11<36:36,50.27it/s] 41%|####1     |71473/173481[24:00<33:57,50.06it/s] 42%|####1     |72039/173481[24:11<33:46,50.06it/s] 46%|####6     |80521/173481[27:00<30:53,50.16it/s] 47%|####6     |81095/173481[27:11<30:41,50.16it/s] 52%|#####1    |89578/173481[30:00<27:50,50.24it/s] 52%|#####1    |90162/173481[30:11<27:38,50.24it/s] 57%|#####6    |98633/173481[33:00<24:48,50.27it/s] 57%|#####7    |99219/173481[33:11<24:37,50.27it/s] 62%|######2   |107724/173481[36:00<21:45,50.39it/s] 62%|######2   |108319/173481[36:11<21:33,50.39it/s] 67%|######7   |116811/173481[39:00<18:43,50.43it/s] 68%|######7   |117418/173481[39:12<18:31,50.43it/s] 73%|#######2  |125909/173481[42:00<15:42,50.49it/s] 73%|#######2  |126520/173481[42:12<15:30,50.49it/s] 78%|#######7  |135017/173481[45:00<12:41,50.54it/s] 78%|#######8  |135636/173481[45:12<12:28,50.54it/s] 83%|########3 |144098/173481[48:00<09:41,50.49it/s] 83%|########3 |144731/173481[48:12<09:29,50.49it/s] 88%|########8 |153173/173481[51:00<06:42,50.45it/s] 89%|########8 |153818/173481[51:12<06:29,50.45it/s] 94%|#########3|162358/173481[54:00<03:39,50.74it/s] 94%|#########3|162998/173481[54:12<03:26,50.74it/s] 99%|#########8|171474/173481[57:00<00:39,50.69it/s] 99%|#########9|172122/173481[57:13<00:26,50.69it/s]100%|##########|173481/173481[57:41<00:00,50.12it/s]
[32m[0328 13:08:41 @base.py:257][0m Epoch 1 (global_step 9367974) finished, time:3461.06 sec.
[32m[0328 13:08:42 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-9367974.
  0%|          |0/18822[00:00<?,?it/s] 62%|######1   |11635/18822[03:00<01:51,64.64it/s] 65%|######5   |12322/18822[03:10<01:40,64.64it/s]100%|##########|18822/18822[04:48<00:00,65.27it/s]
0
[32m[0328 13:13:30 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 13:13:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.622
[32m[0328 13:13:30 @monitor.py:363][0m activation-summaries/output-rms: 0.016966
[32m[0328 13:13:30 @monitor.py:363][0m cross_entropy_loss: 6.9685
[32m[0328 13:13:30 @monitor.py:363][0m lr: 1.9073e-09
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6076e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.2656e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.62e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6279e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7801e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.7935e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9934e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.3899e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1048e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7774e-06
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 13:13:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 13:13:30 @monitor.py:363][0m train-error-top1: 0.99231
[32m[0328 13:13:30 @monitor.py:363][0m val-error-top1: 0.99146
[32m[0328 13:13:30 @monitor.py:363][0m val-utt-error: 0.98566
[32m[0328 13:13:30 @monitor.py:363][0m validation_cost: 7.0085
[32m[0328 13:13:30 @monitor.py:363][0m wd_cost: 2.4633e-13
[32m[0328 13:13:30 @group.py:42][0m Callbacks took 288.798 sec in total. InferenceRunner: 288.412sec
[32m[0328 13:13:30 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9031/173481[03:00<54:37,50.17it/s]  5%|5         |9537/173481[03:10<54:27,50.17it/s] 10%|#         |18079/173481[06:00<51:34,50.22it/s] 11%|#         |18597/173481[06:10<51:24,50.22it/s] 16%|#5        |27115/173481[09:00<48:35,50.21it/s] 16%|#5        |27634/173481[09:10<48:24,50.21it/s] 21%|##        |36128/173481[12:00<45:39,50.14it/s] 21%|##1       |36660/173481[12:10<45:28,50.14it/s] 26%|##6       |45186/173481[15:00<42:34,50.23it/s] 26%|##6       |45726/173481[15:10<42:23,50.23it/s] 31%|###1      |54128/173481[18:00<39:49,49.95it/s] 32%|###1      |54669/173481[18:10<39:38,49.95it/s] 36%|###6      |63147/173481[21:00<36:45,50.02it/s] 37%|###6      |63690/173481[21:11<36:34,50.02it/s] 42%|####1     |72086/173481[24:00<33:54,49.84it/s] 42%|####1     |72632/173481[24:11<33:43,49.84it/s] 47%|####6     |81004/173481[27:00<31:01,49.69it/s] 47%|####7     |81556/173481[27:11<30:49,49.69it/s] 52%|#####1    |89967/173481[30:00<27:58,49.74it/s] 52%|#####2    |90523/173481[30:11<27:47,49.74it/s] 57%|#####6    |98872/173481[33:00<25:04,49.60it/s] 57%|#####7    |99450/173481[33:11<24:52,49.60it/s] 62%|######2   |107815/173481[36:00<22:02,49.64it/s] 62%|######2   |108410/173481[36:11<21:50,49.64it/s] 67%|######7   |116767/173481[39:00<19:01,49.69it/s] 68%|######7   |117359/173481[39:12<18:49,49.69it/s] 72%|#######2  |125726/173481[42:00<16:00,49.73it/s] 73%|#######2  |126333/173481[42:12<15:48,49.73it/s] 78%|#######7  |134836/173481[45:00<12:50,50.16it/s] 78%|#######8  |135474/173481[45:12<12:37,50.16it/s] 83%|########3 |144147/173481[48:00<09:35,50.93it/s] 83%|########3 |144802/173481[48:12<09:23,50.93it/s] 88%|########8 |153446/173481[51:00<06:30,51.29it/s] 89%|########8 |154089/173481[51:12<06:18,51.29it/s] 94%|#########3|162763/173481[54:00<03:28,51.53it/s] 94%|#########4|163399/173481[54:12<03:15,51.53it/s] 99%|#########9|172044/173481[57:00<00:27,51.54it/s]100%|#########9|172694/173481[57:12<00:15,51.54it/s]100%|##########|173481/173481[57:28<00:00,50.31it/s]
[32m[0328 14:10:59 @base.py:257][0m Epoch 2 (global_step 9541455) finished, time:3448.36 sec.
[32m[0328 14:10:59 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-9541455.
[32m[0328 14:10:59 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########9|18648/18822[03:00<00:01,103.60it/s]100%|##########|18822/18822[03:01<00:00,103.64it/s]
1
[32m[0328 14:14:01 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 14:14:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.41
[32m[0328 14:14:01 @monitor.py:363][0m activation-summaries/output-rms: 0.016927
[32m[0328 14:14:01 @monitor.py:363][0m cross_entropy_loss: 6.9643
[32m[0328 14:14:01 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6041e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3077e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6674e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6498e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8392e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.8641e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9869e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4308e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.0705e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.856e-06
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 14:14:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 14:14:01 @monitor.py:363][0m train-error-top1: 0.99023
[32m[0328 14:14:01 @monitor.py:363][0m val-error-top1: 0.99152
[32m[0328 14:14:01 @monitor.py:363][0m val-utt-error: 0.98773
[32m[0328 14:14:01 @monitor.py:363][0m validation_cost: 7.0108
[32m[0328 14:14:01 @monitor.py:363][0m wd_cost: 2.4633e-13
[32m[0328 14:14:01 @group.py:42][0m Callbacks took 181.900 sec in total. InferenceRunner: 181.617sec
[32m[0328 14:14:01 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9293/173481[03:00<53:00,51.63it/s]  6%|5         |9825/173481[03:10<52:49,51.63it/s] 11%|#         |18618/173481[06:00<49:54,51.71it/s] 11%|#1        |19153/173481[06:10<49:44,51.71it/s] 16%|#6        |27981/173481[09:00<46:45,51.86it/s] 16%|#6        |28519/173481[09:10<46:35,51.86it/s] 22%|##1       |37358/173481[12:00<43:38,51.98it/s] 22%|##1       |37915/173481[12:10<43:28,51.98it/s] 27%|##6       |46713/173481[15:00<40:39,51.97it/s] 27%|##7       |47275/173481[15:10<40:28,51.97it/s] 32%|###2      |56069/173481[18:00<37:39,51.98it/s] 33%|###2      |56632/173481[18:10<37:28,51.98it/s] 38%|###7      |65500/173481[21:00<34:29,52.18it/s] 38%|###8      |66076/173481[21:11<34:18,52.18it/s] 43%|####3     |74870/173481[24:00<31:32,52.12it/s] 43%|####3     |75446/173481[24:11<31:21,52.12it/s] 49%|####8     |84255/173481[27:00<28:31,52.13it/s] 49%|####8     |84844/173481[27:11<28:20,52.13it/s] 54%|#####3    |93621/173481[30:00<25:33,52.08it/s] 54%|#####4    |94204/173481[30:11<25:22,52.08it/s] 59%|#####9    |102950/173481[33:00<22:37,51.95it/s] 60%|#####9    |103553/173481[33:11<22:26,51.95it/s] 65%|######4   |112252/173481[36:00<19:41,51.81it/s] 65%|######5   |112864/173481[36:11<19:29,51.81it/s] 70%|#######   |121654/173481[39:00<16:36,52.02it/s] 70%|#######   |122254/173481[39:12<16:24,52.02it/s] 76%|#######5  |130998/173481[42:00<13:37,51.97it/s] 76%|#######5  |131641/173481[42:12<13:25,51.97it/s] 81%|########  |140405/173481[45:00<10:34,52.11it/s] 81%|########1 |141053/173481[45:12<10:22,52.11it/s] 86%|########6 |149750/173481[48:00<07:36,52.01it/s] 87%|########6 |150390/173481[48:12<07:23,52.01it/s] 92%|#########1|159110/173481[51:00<04:36,52.01it/s] 92%|#########2|159766/173481[51:12<04:23,52.01it/s] 97%|#########7|168458/173481[54:00<01:36,51.97it/s] 97%|#########7|169113/173481[54:12<01:24,51.97it/s]100%|##########|173481/173481[55:36<00:00,52.00it/s]
[32m[0328 15:09:37 @base.py:257][0m Epoch 3 (global_step 9714936) finished, time:3336.36 sec.
[32m[0328 15:09:37 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-9714936.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########7|18363/18822[03:00<00:04,102.02it/s]100%|##########|18822/18822[03:04<00:00,102.05it/s]
2
[32m[0328 15:12:42 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 15:12:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.528
[32m[0328 15:12:42 @monitor.py:363][0m activation-summaries/output-rms: 0.016836
[32m[0328 15:12:42 @monitor.py:363][0m cross_entropy_loss: 6.9815
[32m[0328 15:12:42 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6246e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3064e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6535e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6594e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8466e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.875e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9984e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.4956e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1016e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.8615e-06
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 15:12:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 15:12:42 @monitor.py:363][0m train-error-top1: 0.9945
[32m[0328 15:12:42 @monitor.py:363][0m val-error-top1: 0.99147
[32m[0328 15:12:42 @monitor.py:363][0m val-utt-error: 0.9864
[32m[0328 15:12:42 @monitor.py:363][0m validation_cost: 7.0109
[32m[0328 15:12:42 @monitor.py:363][0m wd_cost: 4.9266e-14
[32m[0328 15:12:42 @group.py:42][0m Callbacks took 184.629 sec in total. InferenceRunner: 184.450sec
[32m[0328 15:12:42 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9339/173481[03:00<52:43,51.88it/s]  6%|5         |9858/173481[03:10<52:33,51.88it/s] 11%|#         |18681/173481[06:00<49:43,51.89it/s] 11%|#1        |19206/173481[06:10<49:33,51.89it/s] 16%|#6        |28016/173481[09:00<46:44,51.87it/s] 16%|#6        |28565/173481[09:10<46:33,51.87it/s] 22%|##1       |37357/173481[12:00<43:43,51.88it/s] 22%|##1       |37904/173481[12:10<43:33,51.88it/s] 27%|##6       |46699/173481[15:00<40:43,51.89it/s] 27%|##7       |47261/173481[15:10<40:32,51.89it/s] 32%|###2      |56054/173481[18:00<37:41,51.93it/s] 33%|###2      |56620/173481[18:10<37:30,51.93it/s] 38%|###7      |65403/173481[21:00<34:41,51.93it/s] 38%|###8      |65975/173481[21:11<34:30,51.93it/s] 43%|####3     |74757/173481[24:00<31:40,51.95it/s] 43%|####3     |75333/173481[24:11<31:29,51.95it/s] 48%|####8     |84109/173481[27:00<28:40,51.95it/s] 49%|####8     |84701/173481[27:11<28:28,51.95it/s] 54%|#####3    |93502/173481[30:00<25:36,52.06it/s] 54%|#####4    |94084/173481[30:11<25:24,52.06it/s] 59%|#####9    |102858/173481[33:00<22:37,52.02it/s] 60%|#####9    |103458/173481[33:11<22:26,52.02it/s] 65%|######4   |112215/173481[36:00<19:38,52.00it/s] 65%|######5   |112820/173481[36:11<19:26,52.00it/s] 70%|#######   |121536/173481[39:00<16:41,51.89it/s] 70%|#######   |122152/173481[39:12<16:29,51.89it/s] 75%|#######5  |130877/173481[42:00<13:41,51.89it/s] 76%|#######5  |131497/173481[42:12<13:29,51.89it/s] 81%|########  |140239/173481[45:00<10:39,51.95it/s] 81%|########1 |140886/173481[45:12<10:27,51.95it/s] 86%|########6 |149607/173481[48:00<07:39,52.00it/s] 87%|########6 |150244/173481[48:12<07:26,52.00it/s] 92%|#########1|158967/173481[51:00<04:39,52.00it/s] 92%|#########2|159606/173481[51:12<04:26,52.00it/s] 97%|#########6|168235/173481[54:00<01:41,51.74it/s] 97%|#########7|168901/173481[54:12<01:28,51.74it/s]100%|##########|173481/173481[55:41<00:00,51.91it/s]
[32m[0328 16:08:23 @base.py:257][0m Epoch 4 (global_step 9888417) finished, time:3341.66 sec.
[32m[0328 16:08:23 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:53<00:00,108.31it/s]
3
[32m[0328 16:11:17 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 16:11:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.466
[32m[0328 16:11:17 @monitor.py:363][0m activation-summaries/output-rms: 0.017002
[32m[0328 16:11:17 @monitor.py:363][0m cross_entropy_loss: 6.9455
[32m[0328 16:11:17 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.604e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3148e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6423e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6695e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8519e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.8934e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.98e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5623e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1316e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.8848e-06
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 16:11:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 16:11:17 @monitor.py:363][0m train-error-top1: 0.99237
[32m[0328 16:11:17 @monitor.py:363][0m val-error-top1: 0.99151
[32m[0328 16:11:17 @monitor.py:363][0m val-utt-error: 0.98767
[32m[0328 16:11:17 @monitor.py:363][0m validation_cost: 7.005
[32m[0328 16:11:17 @monitor.py:363][0m wd_cost: 4.9266e-14
[32m[0328 16:11:17 @group.py:42][0m Callbacks took 174.009 sec in total. InferenceRunner: 173.787sec
[32m[0328 16:11:17 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9307/173481[03:00<52:55,51.70it/s]  6%|5         |9834/173481[03:10<52:45,51.70it/s] 11%|#         |18584/173481[06:00<50:00,51.62it/s] 11%|#1        |19114/173481[06:10<49:50,51.62it/s] 16%|#6        |27878/173481[09:00<47:00,51.62it/s] 16%|#6        |28410/173481[09:10<46:50,51.62it/s] 21%|##1       |37178/173481[12:00<43:59,51.64it/s] 22%|##1       |37725/173481[12:10<43:48,51.64it/s] 27%|##6       |46447/173481[15:00<41:03,51.57it/s] 27%|##7       |47006/173481[15:10<40:52,51.57it/s] 32%|###2      |55721/173481[18:00<38:04,51.54it/s] 32%|###2      |56285/173481[18:10<37:53,51.54it/s] 37%|###7      |64954/173481[21:00<35:10,51.42it/s] 38%|###7      |65523/173481[21:11<34:59,51.42it/s] 43%|####2     |74221/173481[24:00<32:09,51.45it/s] 43%|####3     |74790/173481[24:11<31:58,51.45it/s] 48%|####8     |83495/173481[27:00<29:07,51.48it/s] 48%|####8     |84082/173481[27:11<28:56,51.48it/s] 54%|#####3    |92849/173481[30:00<25:58,51.72it/s] 54%|#####3    |93435/173481[30:11<25:47,51.72it/s] 59%|#####8    |102090/173481[33:00<23:05,51.53it/s] 59%|#####9    |102686/173481[33:11<22:53,51.53it/s] 64%|######4   |111361/173481[36:00<20:05,51.52it/s] 65%|######4   |111954/173481[36:11<19:54,51.52it/s] 70%|######9   |120644/173481[39:00<17:05,51.54it/s] 70%|######9   |121262/173481[39:12<16:53,51.54it/s] 75%|#######4  |129993/173481[42:00<14:00,51.74it/s] 75%|#######5  |130614/173481[42:12<13:48,51.74it/s] 80%|########  |139278/173481[45:00<11:02,51.66it/s] 81%|########  |139913/173481[45:12<10:49,51.66it/s] 86%|########5 |148590/173481[48:00<08:01,51.70it/s] 86%|########6 |149223/173481[48:12<07:49,51.70it/s] 91%|######### |157850/173481[51:00<05:03,51.57it/s] 91%|#########1|158492/173481[51:12<04:50,51.57it/s] 96%|#########6|167196/173481[54:00<02:01,51.74it/s] 97%|#########6|167861/173481[54:12<01:48,51.74it/s]100%|##########|173481/173481[56:00<00:00,51.62it/s]
[32m[0328 17:07:18 @base.py:257][0m Epoch 5 (global_step 10061898) finished, time:3360.91 sec.
[32m[0328 17:07:18 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-10061898.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:50<00:00,110.43it/s]
4
[32m[0328 17:10:09 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 17:10:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.537
[32m[0328 17:10:09 @monitor.py:363][0m activation-summaries/output-rms: 0.016628
[32m[0328 17:10:09 @monitor.py:363][0m cross_entropy_loss: 6.9794
[32m[0328 17:10:09 @monitor.py:363][0m lr: 4.7684e-10
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6206e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3181e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6539e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6651e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8487e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.8931e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9607e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5421e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1498e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9076e-06
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 17:10:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 17:10:09 @monitor.py:363][0m train-error-top1: 0.99075
[32m[0328 17:10:09 @monitor.py:363][0m val-error-top1: 0.99147
[32m[0328 17:10:09 @monitor.py:363][0m val-utt-error: 0.98773
[32m[0328 17:10:09 @monitor.py:363][0m validation_cost: 6.991
[32m[0328 17:10:09 @monitor.py:363][0m wd_cost: 4.9266e-14
[32m[0328 17:10:09 @group.py:42][0m Callbacks took 170.722 sec in total. InferenceRunner: 170.465sec
[32m[0328 17:10:09 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9328/173481[03:00<52:47,51.82it/s]  6%|5         |9848/173481[03:10<52:37,51.82it/s] 11%|#         |18677/173481[06:00<49:43,51.88it/s] 11%|#1        |19202/173481[06:10<49:33,51.88it/s] 16%|#6        |27942/173481[09:00<46:56,51.67it/s] 16%|#6        |28492/173481[09:10<46:45,51.67it/s] 21%|##1       |37231/173481[12:00<43:58,51.64it/s] 22%|##1       |37780/173481[12:10<43:48,51.64it/s] 27%|##6       |46424/173481[15:00<41:14,51.35it/s] 27%|##7       |46984/173481[15:10<41:03,51.35it/s] 32%|###2      |55701/173481[18:00<38:09,51.44it/s] 32%|###2      |56278/173481[18:10<37:58,51.44it/s] 37%|###7      |64992/173481[21:00<35:05,51.53it/s] 38%|###7      |65566/173481[21:11<34:54,51.53it/s] 43%|####2     |74302/173481[24:00<32:01,51.63it/s] 43%|####3     |74887/173481[24:11<31:49,51.63it/s] 48%|####8     |83604/173481[27:00<29:00,51.65it/s] 49%|####8     |84185/173481[27:11<28:48,51.65it/s] 54%|#####3    |92889/173481[30:00<26:01,51.61it/s] 54%|#####3    |93489/173481[30:11<25:49,51.61it/s] 59%|#####8    |102150/173481[33:00<23:04,51.53it/s] 59%|#####9    |102755/173481[33:11<22:52,51.53it/s] 64%|######4   |111427/173481[36:00<20:04,51.53it/s] 65%|######4   |112038/173481[36:11<19:52,51.53it/s] 70%|######9   |120732/173481[39:00<17:02,51.61it/s] 70%|######9   |121357/173481[39:12<16:49,51.61it/s] 75%|#######4  |130042/173481[42:00<14:00,51.67it/s] 75%|#######5  |130656/173481[42:12<13:48,51.67it/s] 80%|########  |139295/173481[45:00<11:03,51.54it/s] 81%|########  |139928/173481[45:12<10:51,51.54it/s] 86%|########5 |148531/173481[48:00<08:05,51.42it/s] 86%|########5 |149158/173481[48:12<07:53,51.42it/s] 91%|######### |157807/173481[51:00<05:04,51.48it/s] 91%|#########1|158448/173481[51:12<04:52,51.48it/s] 96%|#########6|167074/173481[54:00<02:04,51.48it/s] 97%|#########6|167734/173481[54:12<01:51,51.48it/s]100%|##########|173481/173481[56:04<00:00,51.57it/s]
[32m[0328 18:06:13 @base.py:257][0m Epoch 6 (global_step 10235379) finished, time:3364.21 sec.
[32m[0328 18:06:13 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-10235379.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:49<00:00,111.32it/s]
5
[32m[0328 18:09:02 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 18:09:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.621
[32m[0328 18:09:02 @monitor.py:363][0m activation-summaries/output-rms: 0.016939
[32m[0328 18:09:02 @monitor.py:363][0m cross_entropy_loss: 6.963
[32m[0328 18:09:02 @monitor.py:363][0m lr: 4.7684e-10
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.628e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3163e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.652e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6654e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8442e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9077e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9666e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5393e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1561e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9039e-06
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 18:09:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 18:09:02 @monitor.py:363][0m train-error-top1: 0.99224
[32m[0328 18:09:02 @monitor.py:363][0m val-error-top1: 0.99145
[32m[0328 18:09:02 @monitor.py:363][0m val-utt-error: 0.9856
[32m[0328 18:09:02 @monitor.py:363][0m validation_cost: 7.0026
[32m[0328 18:09:02 @monitor.py:363][0m wd_cost: 9.8533e-15
[32m[0328 18:09:02 @group.py:42][0m Callbacks took 169.324 sec in total. InferenceRunner: 169.091sec
[32m[0328 18:09:02 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9418/173481[03:00<52:15,52.32it/s]  6%|5         |9945/173481[03:10<52:05,52.32it/s] 11%|#         |18728/173481[06:00<49:35,52.02it/s] 11%|#1        |19252/173481[06:10<49:25,52.02it/s] 16%|#6        |28068/173481[09:00<46:38,51.95it/s] 16%|#6        |28604/173481[09:10<46:28,51.95it/s] 22%|##1       |37429/173481[12:00<43:37,51.98it/s] 22%|##1       |37991/173481[12:10<43:26,51.98it/s] 27%|##7       |46954/173481[15:00<40:12,52.44it/s] 27%|##7       |47505/173481[15:10<40:02,52.44it/s] 32%|###2      |56265/173481[18:00<37:30,52.08it/s] 33%|###2      |56857/173481[18:10<37:19,52.08it/s] 38%|###8      |65984/173481[21:00<33:47,53.02it/s] 38%|###8      |66584/173481[21:11<33:36,53.02it/s] 44%|####3     |75679/173481[24:00<30:30,53.44it/s] 44%|####3     |76265/173481[24:11<30:19,53.44it/s] 49%|####9     |85185/173481[27:00<27:42,53.12it/s] 49%|####9     |85788/173481[27:11<27:30,53.12it/s] 55%|#####4    |94633/173481[30:00<24:53,52.80it/s] 55%|#####4    |95237/173481[30:11<24:41,52.80it/s] 60%|######    |104098/173481[33:00<21:56,52.69it/s] 60%|######    |104706/173481[33:11<21:45,52.69it/s] 65%|######5   |113608/173481[36:00<18:54,52.76it/s] 66%|######5   |114221/173481[36:11<18:43,52.76it/s] 71%|#######   |123074/173481[39:00<15:56,52.67it/s] 71%|#######1  |123707/173481[39:12<15:44,52.67it/s] 76%|#######6  |132549/173481[42:00<12:57,52.66it/s] 77%|#######6  |133177/173481[42:12<12:45,52.66it/s] 82%|########1 |141993/173481[45:00<09:59,52.56it/s] 82%|########2 |142625/173481[45:12<09:47,52.56it/s] 87%|########7 |151454/173481[48:00<06:59,52.56it/s] 88%|########7 |152111/173481[48:12<06:46,52.56it/s] 93%|#########2|160953/173481[51:00<03:57,52.66it/s] 93%|#########3|161613/173481[51:12<03:45,52.66it/s] 98%|#########8|170511/173481[54:00<00:56,52.88it/s] 99%|#########8|171180/173481[54:12<00:43,52.88it/s]100%|##########|173481/173481[54:56<00:00,52.63it/s]
[32m[0328 19:03:59 @base.py:257][0m Epoch 7 (global_step 10408860) finished, time:3296.32 sec.
[32m[0328 19:03:59 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-10408860.
[32m[0328 19:03:59 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 90%|########9 |16856/18822[03:00<00:20,93.64it/s] 95%|#########4|17815/18822[03:10<00:10,93.64it/s]100%|##########|18822/18822[03:20<00:00,93.67it/s]
6
[32m[0328 19:07:20 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 19:07:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.568
[32m[0328 19:07:20 @monitor.py:363][0m activation-summaries/output-rms: 0.016802
[32m[0328 19:07:20 @monitor.py:363][0m cross_entropy_loss: 6.949
[32m[0328 19:07:20 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6291e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3254e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6557e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6726e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9209e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9614e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5385e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1514e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9128e-06
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 19:07:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 19:07:20 @monitor.py:363][0m train-error-top1: 0.99137
[32m[0328 19:07:20 @monitor.py:363][0m val-error-top1: 0.99147
[32m[0328 19:07:20 @monitor.py:363][0m val-utt-error: 0.98778
[32m[0328 19:07:20 @monitor.py:363][0m validation_cost: 7.0094
[32m[0328 19:07:20 @monitor.py:363][0m wd_cost: 9.8533e-15
[32m[0328 19:07:20 @group.py:42][0m Callbacks took 201.323 sec in total. InferenceRunner: 200.955sec
[32m[0328 19:07:20 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9511/173481[03:00<51:43,52.84it/s]  6%|5         |10053/173481[03:10<51:33,52.84it/s] 11%|#         |18981/173481[06:00<48:50,52.72it/s] 11%|#1        |19528/173481[06:10<48:40,52.72it/s] 16%|#6        |28567/173481[09:00<45:34,52.99it/s] 17%|#6        |29148/173481[09:10<45:23,52.99it/s] 22%|##2       |38397/173481[12:00<41:51,53.79it/s] 22%|##2       |38966/173481[12:10<41:40,53.79it/s] 28%|##7       |47845/173481[15:00<39:24,53.13it/s] 28%|##7       |48406/173481[15:10<39:14,53.13it/s] 32%|###2      |55860/173481[18:00<40:27,48.45it/s] 32%|###2      |56361/173481[18:11<40:17,48.45it/s] 38%|###7      |65143/173481[21:00<36:08,49.96it/s] 38%|###7      |65738/173481[21:11<35:56,49.96it/s] 42%|####2     |73236/173481[24:00<35:18,47.33it/s] 43%|####2     |73795/173481[24:11<35:06,47.33it/s] 48%|####7     |82413/173481[27:00<30:55,49.09it/s] 48%|####7     |82985/173481[27:11<30:43,49.09it/s] 52%|#####2    |90940/173481[30:00<28:31,48.21it/s] 53%|#####2    |91501/173481[30:11<28:20,48.21it/s] 58%|#####7    |100212/173481[33:00<24:31,49.81it/s] 58%|#####8    |100846/173481[33:11<24:18,49.81it/s] 63%|######3   |109700/173481[36:00<20:45,51.22it/s] 64%|######3   |110327/173481[36:12<20:33,51.22it/s] 69%|######8   |119114/173481[39:00<17:30,51.75it/s] 69%|######9   |119769/173481[39:12<17:17,51.75it/s] 74%|#######4  |128520/173481[42:00<14:24,52.00it/s] 74%|#######4  |129173/173481[42:12<14:12,52.00it/s] 80%|#######9  |138051/173481[45:00<11:15,52.47it/s] 80%|#######9  |138702/173481[45:12<11:02,52.47it/s] 85%|########5 |147495/173481[48:00<08:15,52.47it/s] 85%|########5 |148154/173481[48:12<08:02,52.47it/s] 91%|######### |157001/173481[51:00<05:13,52.64it/s] 91%|######### |157660/173481[51:12<05:00,52.64it/s] 96%|#########5|166419/173481[54:00<02:14,52.48it/s] 96%|#########6|167100/173481[54:13<02:01,52.48it/s]100%|##########|173481/173481[56:15<00:00,51.40it/s]
[32m[0328 20:03:35 @base.py:257][0m Epoch 8 (global_step 10582341) finished, time:3375.10 sec.
[32m[0328 20:03:35 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 89%|########9 |16795/18822[03:00<00:21,93.30it/s] 94%|#########4|17746/18822[03:10<00:11,93.30it/s]100%|##########|18822/18822[03:21<00:00,93.31it/s]
7
[32m[0328 20:06:57 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 20:06:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.491
[32m[0328 20:06:57 @monitor.py:363][0m activation-summaries/output-rms: 0.016453
[32m[0328 20:06:57 @monitor.py:363][0m cross_entropy_loss: 6.9568
[32m[0328 20:06:57 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6369e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3277e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6596e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6725e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8432e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9229e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9655e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.533e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1424e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9207e-06
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 20:06:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 20:06:57 @monitor.py:363][0m train-error-top1: 0.99027
[32m[0328 20:06:57 @monitor.py:363][0m val-error-top1: 0.9915
[32m[0328 20:06:57 @monitor.py:363][0m val-utt-error: 0.98677
[32m[0328 20:06:57 @monitor.py:363][0m validation_cost: 7.0098
[32m[0328 20:06:57 @monitor.py:363][0m wd_cost: 1.9707e-15
[32m[0328 20:06:57 @group.py:42][0m Callbacks took 201.960 sec in total. InferenceRunner: 201.720sec
[32m[0328 20:06:57 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9549/173481[03:00<51:30,53.05it/s]  6%|5         |10083/173481[03:10<51:20,53.05it/s] 11%|#         |19003/173481[06:00<48:46,52.78it/s] 11%|#1        |19550/173481[06:10<48:36,52.78it/s] 17%|#6        |28638/173481[09:00<45:25,53.15it/s] 17%|#6        |29190/173481[09:10<45:14,53.15it/s] 22%|##1       |38136/173481[12:00<42:35,52.96it/s] 22%|##2       |38687/173481[12:10<42:25,52.96it/s] 27%|##7       |47604/173481[15:00<39:45,52.78it/s] 28%|##7       |48186/173481[15:10<39:34,52.78it/s] 33%|###2      |57111/173481[18:00<36:44,52.80it/s] 33%|###3      |57695/173481[18:10<36:33,52.80it/s] 38%|###8      |66626/173481[21:00<33:42,52.83it/s] 39%|###8      |67207/173481[21:11<33:31,52.83it/s] 44%|####3     |76114/173481[24:00<30:45,52.77it/s] 44%|####4     |76701/173481[24:11<30:34,52.77it/s] 49%|####9     |85672/173481[27:00<27:38,52.93it/s] 50%|####9     |86287/173481[27:11<27:27,52.93it/s] 55%|#####4    |95214/173481[30:00<24:37,52.97it/s] 55%|#####5    |95822/173481[30:11<24:26,52.97it/s] 60%|######    |104728/173481[33:00<21:39,52.91it/s] 61%|######    |105333/173481[33:11<21:27,52.91it/s] 66%|######5   |114276/173481[36:00<18:37,52.98it/s] 66%|######6   |114896/173481[36:11<18:25,52.98it/s] 71%|#######1  |123773/173481[39:00<15:40,52.87it/s] 72%|#######1  |124400/173481[39:12<15:28,52.87it/s] 77%|#######6  |133273/173481[42:00<12:41,52.82it/s] 77%|#######7  |133910/173481[42:12<12:29,52.82it/s] 82%|########2 |142777/173481[45:00<09:41,52.81it/s] 83%|########2 |143426/173481[45:12<09:29,52.81it/s] 88%|########7 |152256/173481[48:00<06:42,52.73it/s] 88%|########8 |152895/173481[48:12<06:30,52.73it/s] 93%|#########3|161706/173481[51:00<03:43,52.62it/s] 94%|#########3|162364/173481[51:12<03:31,52.62it/s] 99%|#########8|171217/173481[54:00<00:42,52.73it/s] 99%|#########9|171885/173481[54:12<00:30,52.73it/s]100%|##########|173481/173481[54:43<00:00,52.84it/s]
[32m[0328 21:01:41 @base.py:257][0m Epoch 9 (global_step 10755822) finished, time:3283.43 sec.
[32m[0328 21:01:41 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-10755822.
  0%|          |0/18822[00:00<?,?it/s] 87%|########7 |16416/18822[03:00<00:26,91.20it/s] 92%|#########2|17333/18822[03:10<00:16,91.20it/s]100%|##########|18822/18822[03:26<00:00,91.22it/s]
8
[32m[0328 21:05:07 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 21:05:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.509
[32m[0328 21:05:07 @monitor.py:363][0m activation-summaries/output-rms: 0.017245
[32m[0328 21:05:07 @monitor.py:363][0m cross_entropy_loss: 6.9777
[32m[0328 21:05:07 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6459e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3279e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6561e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6745e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8392e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9246e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9641e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5321e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1357e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9251e-06
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 21:05:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 21:05:07 @monitor.py:363][0m train-error-top1: 0.98979
[32m[0328 21:05:07 @monitor.py:363][0m val-error-top1: 0.99141
[32m[0328 21:05:07 @monitor.py:363][0m val-utt-error: 0.98629
[32m[0328 21:05:07 @monitor.py:363][0m validation_cost: 7.0014
[32m[0328 21:05:07 @monitor.py:363][0m wd_cost: 1.9707e-15
[32m[0328 21:05:07 @group.py:42][0m Callbacks took 206.596 sec in total. InferenceRunner: 206.348sec
[32m[0328 21:05:07 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9511/173481[03:00<51:43,52.84it/s]  6%|5         |10065/173481[03:10<51:32,52.84it/s] 11%|#         |19021/173481[06:00<48:43,52.83it/s] 11%|#1        |19570/173481[06:10<48:33,52.83it/s] 16%|#6        |28462/173481[09:00<45:54,52.64it/s] 17%|#6        |29002/173481[09:10<45:44,52.64it/s] 22%|##1       |37945/173481[12:00<42:53,52.66it/s] 22%|##2       |38500/173481[12:10<42:43,52.66it/s] 27%|##7       |47424/173481[15:00<39:53,52.66it/s] 28%|##7       |48002/173481[15:10<39:42,52.66it/s] 33%|###2      |57145/173481[18:00<36:21,53.32it/s] 33%|###3      |57722/173481[18:10<36:10,53.32it/s] 38%|###8      |66674/173481[21:00<33:30,53.13it/s] 39%|###8      |67259/173481[21:11<33:19,53.13it/s] 43%|####3     |74883/173481[24:00<33:28,49.08it/s] 44%|####3     |75492/173481[24:11<33:16,49.08it/s] 49%|####8     |84485/173481[27:00<29:00,51.12it/s] 49%|####9     |85078/173481[27:11<28:49,51.12it/s] 54%|#####4    |94030/173481[30:00<25:26,52.06it/s] 55%|#####4    |94635/173481[30:11<25:14,52.06it/s] 60%|#####9    |103471/173481[33:00<22:19,52.25it/s] 60%|#####9    |104085/173481[33:11<22:08,52.25it/s] 65%|######5   |112882/173481[36:00<19:19,52.27it/s] 65%|######5   |113509/173481[36:11<19:07,52.27it/s] 71%|#######   |122362/173481[39:00<16:14,52.47it/s] 71%|#######   |123007/173481[39:12<16:02,52.47it/s] 76%|#######6  |131856/173481[42:00<13:11,52.60it/s] 76%|#######6  |132495/173481[42:12<12:59,52.60it/s] 81%|########1 |141362/173481[45:00<10:09,52.70it/s] 82%|########1 |141995/173481[45:12<09:57,52.70it/s] 87%|########6 |150808/173481[48:00<07:11,52.59it/s] 87%|########7 |151454/173481[48:12<06:58,52.59it/s] 92%|#########2|160247/173481[51:00<04:12,52.51it/s] 93%|#########2|160907/173481[51:12<03:59,52.51it/s] 98%|#########7|169716/173481[54:00<01:11,52.56it/s] 98%|#########8|170376/173481[54:12<00:59,52.56it/s]100%|##########|173481/173481[55:11<00:00,52.39it/s]
[32m[0328 22:00:19 @base.py:257][0m Epoch 10 (global_step 10929303) finished, time:3311.59 sec.
[32m[0328 22:00:19 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-10929303.
[32m[0328 22:00:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 86%|########6 |16202/18822[03:00<00:29,90.01it/s] 91%|######### |17127/18822[03:10<00:18,90.01it/s]100%|##########|18822/18822[03:28<00:00,90.23it/s]
9
[32m[0328 22:03:48 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 22:03:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.412
[32m[0328 22:03:48 @monitor.py:363][0m activation-summaries/output-rms: 0.016744
[32m[0328 22:03:48 @monitor.py:363][0m cross_entropy_loss: 6.9258
[32m[0328 22:03:48 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6527e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3247e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6565e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6734e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8435e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9181e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9643e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5427e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1416e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9281e-06
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 22:03:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 22:03:48 @monitor.py:363][0m train-error-top1: 0.99142
[32m[0328 22:03:48 @monitor.py:363][0m val-error-top1: 0.99156
[32m[0328 22:03:48 @monitor.py:363][0m val-utt-error: 0.98778
[32m[0328 22:03:48 @monitor.py:363][0m validation_cost: 7.017
[32m[0328 22:03:48 @monitor.py:363][0m wd_cost: 1.9707e-15
[32m[0328 22:03:48 @group.py:42][0m Callbacks took 208.943 sec in total. InferenceRunner: 208.609sec
[32m[0328 22:03:48 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9578/173481[03:00<51:20,53.21it/s]  6%|5         |10120/173481[03:10<51:10,53.21it/s] 11%|#1        |19109/173481[06:00<48:28,53.08it/s] 11%|#1        |19644/173481[06:10<48:18,53.08it/s] 16%|#6        |28558/173481[09:00<45:45,52.78it/s] 17%|#6        |29098/173481[09:10<45:35,52.78it/s] 22%|##1       |38029/173481[12:00<42:50,52.70it/s] 22%|##2       |38586/173481[12:10<42:39,52.70it/s] 27%|##7       |47482/173481[15:00<39:55,52.61it/s] 28%|##7       |48035/173481[15:10<39:44,52.61it/s] 33%|###2      |57026/173481[18:00<36:45,52.81it/s] 33%|###3      |57597/173481[18:10<36:34,52.81it/s] 38%|###8      |66469/173481[21:00<33:53,52.63it/s] 39%|###8      |67049/173481[21:11<33:42,52.63it/s] 44%|####3     |75910/173481[24:00<30:57,52.54it/s] 44%|####4     |76491/173481[24:11<30:46,52.54it/s] 49%|####9     |85381/173481[27:00<27:55,52.58it/s] 50%|####9     |85971/173481[27:11<27:44,52.58it/s] 55%|#####4    |94779/173481[30:00<25:02,52.39it/s] 55%|#####4    |95399/173481[30:11<24:50,52.39it/s] 60%|######    |104308/173481[33:00<21:53,52.66it/s] 60%|######    |104911/173481[33:11<21:42,52.66it/s] 66%|######5   |113848/173481[36:00<18:48,52.83it/s] 66%|######5   |114465/173481[36:11<18:37,52.83it/s] 71%|#######1  |123307/173481[39:00<15:52,52.69it/s] 71%|#######1  |123944/173481[39:12<15:40,52.69it/s] 77%|#######6  |132806/173481[42:00<12:51,52.73it/s] 77%|#######6  |133437/173481[42:12<12:39,52.73it/s] 82%|########2 |142327/173481[45:00<09:49,52.81it/s] 82%|########2 |142960/173481[45:12<09:37,52.81it/s] 88%|########7 |151809/173481[48:00<06:50,52.74it/s] 88%|########7 |152460/173481[48:12<06:38,52.74it/s] 93%|#########3|161354/173481[51:00<03:49,52.88it/s] 93%|#########3|162003/173481[51:12<03:37,52.88it/s] 98%|#########8|170877/173481[54:00<00:49,52.89it/s] 99%|#########8|171542/173481[54:12<00:36,52.89it/s]100%|##########|173481/173481[54:49<00:00,52.74it/s]
[32m[0328 22:58:37 @base.py:257][0m Epoch 11 (global_step 11102784) finished, time:3289.45 sec.
[32m[0328 22:58:37 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s] 94%|#########4|17706/18822[03:00<00:11,98.37it/s] 99%|#########9|18715/18822[03:10<00:01,98.37it/s]100%|##########|18822/18822[03:11<00:00,98.43it/s]
10
[32m[0328 23:01:49 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 23:01:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.475
[32m[0328 23:01:49 @monitor.py:363][0m activation-summaries/output-rms: 0.016654
[32m[0328 23:01:49 @monitor.py:363][0m cross_entropy_loss: 6.9115
[32m[0328 23:01:49 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6558e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3234e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6563e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6723e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8454e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9202e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9654e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5418e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1419e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9269e-06
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0328 23:01:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0328 23:01:49 @monitor.py:363][0m train-error-top1: 0.99334
[32m[0328 23:01:49 @monitor.py:363][0m val-error-top1: 0.99138
[32m[0328 23:01:49 @monitor.py:363][0m val-utt-error: 0.98688
[32m[0328 23:01:49 @monitor.py:363][0m validation_cost: 6.9955
[32m[0328 23:01:49 @monitor.py:363][0m wd_cost: 3.9413e-16
[32m[0328 23:01:49 @group.py:42][0m Callbacks took 191.423 sec in total. InferenceRunner: 191.233sec
[32m[0328 23:01:49 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9588/173481[03:00<51:16,53.27it/s]  6%|5         |10125/173481[03:10<51:06,53.27it/s] 11%|#1        |19155/173481[06:00<48:20,53.21it/s] 11%|#1        |19714/173481[06:10<48:10,53.21it/s] 17%|#6        |28647/173481[09:00<45:34,52.97it/s] 17%|#6        |29201/173481[09:10<45:23,52.97it/s] 22%|##2       |38202/173481[12:00<42:31,53.02it/s] 22%|##2       |38618/173481[12:10<42:23,53.02it/s] 26%|##5       |44733/173481[15:00<49:48,43.08it/s] 26%|##6       |45144/173481[15:10<49:38,43.08it/s] 31%|###       |53074/173481[18:00<44:56,44.65it/s] 31%|###       |53656/173481[18:10<44:43,44.65it/s] 36%|###6      |62603/173481[21:00<38:08,48.44it/s] 36%|###6      |63171/173481[21:11<37:57,48.44it/s] 42%|####1     |71999/173481[24:00<33:39,50.25it/s] 42%|####1     |72593/173481[24:11<33:27,50.25it/s] 47%|####6     |81510/173481[27:00<29:45,51.51it/s] 47%|####7     |81984/173481[27:11<29:36,51.51it/s] 52%|#####1    |89373/173481[30:00<29:39,47.28it/s] 52%|#####1    |90017/173481[30:11<29:25,47.28it/s] 57%|#####7    |99164/173481[33:00<24:29,50.58it/s] 58%|#####7    |99780/173481[33:11<24:17,50.58it/s] 63%|######2   |108656/173481[36:00<20:55,51.63it/s] 63%|######2   |109283/173481[36:11<20:43,51.63it/s] 68%|######7   |117895/173481[39:00<17:59,51.47it/s] 68%|######8   |118427/173481[39:12<17:49,51.47it/s] 73%|#######2  |126255/173481[42:00<16:07,48.83it/s] 73%|#######3  |126895/173481[42:12<15:54,48.83it/s] 78%|#######8  |135938/173481[45:00<12:13,51.19it/s] 79%|#######8  |136585/173481[45:12<12:00,51.19it/s] 84%|########3 |145465/173481[48:00<08:58,52.04it/s] 84%|########4 |146134/173481[48:12<08:45,52.04it/s] 89%|########9 |154957/173481[51:00<05:53,52.39it/s] 90%|########9 |155620/173481[51:12<05:40,52.39it/s] 95%|#########4|164354/173481[54:00<02:54,52.29it/s] 95%|#########5|165001/173481[54:12<02:42,52.29it/s]100%|##########|173481/173481[56:56<00:00,50.77it/s]
[32m[0328 23:58:45 @base.py:257][0m Epoch 12 (global_step 11276265) finished, time:3416.97 sec.
[32m[0328 23:58:46 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-11276265.
[32m[0328 23:58:46 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 83%|########3 |15716/18822[03:00<00:35,87.31it/s] 88%|########8 |16645/18822[03:10<00:24,87.31it/s]100%|##########|18822/18822[03:34<00:00,87.92it/s]
11
[32m[0329 00:02:20 @monitor.py:363][0m QueueInput/queue_size: 1.262
[32m[0329 00:02:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.409
[32m[0329 00:02:20 @monitor.py:363][0m activation-summaries/output-rms: 0.016893
[32m[0329 00:02:20 @monitor.py:363][0m cross_entropy_loss: 6.9614
[32m[0329 00:02:20 @monitor.py:363][0m lr: 1.1921e-10
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6577e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3222e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6585e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6744e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8451e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9195e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9643e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5431e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1443e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9243e-06
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 00:02:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 00:02:20 @monitor.py:363][0m train-error-top1: 0.99031
[32m[0329 00:02:20 @monitor.py:363][0m val-error-top1: 0.9915
[32m[0329 00:02:20 @monitor.py:363][0m val-utt-error: 0.98746
[32m[0329 00:02:20 @monitor.py:363][0m validation_cost: 7.008
[32m[0329 00:02:20 @monitor.py:363][0m wd_cost: 3.9413e-16
[32m[0329 00:02:20 @group.py:42][0m Callbacks took 214.580 sec in total. InferenceRunner: 214.094sec
[32m[0329 00:02:20 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9402/173481[03:00<52:21,52.23it/s]  6%|5         |9929/173481[03:10<52:11,52.23it/s] 11%|#         |18853/173481[06:00<49:12,52.37it/s] 11%|#1        |19390/173481[06:10<49:02,52.37it/s] 16%|#6        |28271/173481[09:00<46:14,52.34it/s] 17%|#6        |28829/173481[09:10<46:03,52.34it/s] 22%|##1       |37729/173481[12:00<43:08,52.44it/s] 22%|##2       |38280/173481[12:10<42:58,52.44it/s] 27%|##6       |46569/173481[15:00<41:42,50.72it/s] 27%|##7       |47033/173481[15:10<41:33,50.72it/s] 32%|###1      |54964/173481[18:00<40:39,48.59it/s] 32%|###1      |55455/173481[18:10<40:29,48.59it/s] 37%|###6      |63533/173481[21:00<38:06,48.09it/s] 37%|###6      |64131/173481[21:11<37:53,48.09it/s] 42%|####2     |73253/173481[24:00<32:50,50.87it/s] 43%|####2     |73818/173481[24:11<32:38,50.87it/s] 48%|####7     |82435/173481[27:00<29:47,50.94it/s] 48%|####7     |82943/173481[27:11<29:37,50.94it/s] 53%|#####2    |91314/173481[30:00<27:19,50.12it/s] 53%|#####2    |91912/173481[30:11<27:07,50.12it/s] 58%|#####8    |100672/173481[33:00<23:46,51.04it/s] 58%|#####8    |101246/173481[33:11<23:35,51.04it/s] 63%|######3   |110014/173481[36:00<20:33,51.46it/s] 64%|######3   |110621/173481[36:11<20:21,51.46it/s] 69%|######8   |119258/173481[39:00<17:34,51.41it/s] 69%|######9   |119838/173481[39:11<17:23,51.41it/s] 74%|#######3  |128046/173481[42:00<15:07,50.08it/s] 74%|#######4  |128607/173481[42:12<14:56,50.08it/s] 79%|#######8  |136886/173481[45:00<12:17,49.59it/s] 79%|#######9  |137466/173481[45:12<12:06,49.59it/s] 84%|########3 |145633/173481[48:00<09:27,49.08it/s] 84%|########4 |146236/173481[48:12<09:15,49.08it/s] 89%|########8 |154359/173481[51:00<06:32,48.78it/s] 89%|########9 |154969/173481[51:12<06:19,48.78it/s] 94%|#########4|163120/173481[54:00<03:32,48.72it/s] 94%|#########4|163730/173481[54:12<03:20,48.72it/s] 99%|#########9|171999/173481[57:00<00:30,49.02it/s]100%|#########9|172640/173481[57:12<00:17,49.02it/s]100%|##########|173481/173481[57:29<00:00,50.29it/s]
[32m[0329 00:59:50 @base.py:257][0m Epoch 13 (global_step 11449746) finished, time:3449.66 sec.
[32m[0329 00:59:50 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######9  |14893/18822[03:00<00:47,82.73it/s] 84%|########4 |15872/18822[03:10<00:35,82.73it/s]100%|##########|18822/18822[03:41<00:00,85.04it/s]
12
[32m[0329 01:03:31 @monitor.py:363][0m QueueInput/queue_size: 39.809
[32m[0329 01:03:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.526
[32m[0329 01:03:31 @monitor.py:363][0m activation-summaries/output-rms: 0.016813
[32m[0329 01:03:31 @monitor.py:363][0m cross_entropy_loss: 6.9804
[32m[0329 01:03:31 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6582e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3222e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.661e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6752e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8467e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.921e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9635e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5459e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1462e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9243e-06
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 01:03:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 01:03:31 @monitor.py:363][0m train-error-top1: 0.99438
[32m[0329 01:03:31 @monitor.py:363][0m val-error-top1: 0.99147
[32m[0329 01:03:31 @monitor.py:363][0m val-utt-error: 0.9872
[32m[0329 01:03:31 @monitor.py:363][0m validation_cost: 7.0092
[32m[0329 01:03:31 @monitor.py:363][0m wd_cost: 3.9413e-16
[32m[0329 01:03:31 @group.py:42][0m Callbacks took 221.687 sec in total. InferenceRunner: 221.347sec
[32m[0329 01:03:31 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9166/173481[03:00<53:46,50.92it/s]  6%|5         |9685/173481[03:10<53:36,50.92it/s] 11%|#         |18231/173481[06:00<51:05,50.64it/s] 11%|#         |18753/173481[06:10<50:55,50.64it/s] 16%|#5        |27238/173481[09:00<48:25,50.33it/s] 16%|#6        |27773/173481[09:10<48:14,50.33it/s] 21%|##        |36372/173481[12:00<45:13,50.54it/s] 21%|##1       |36907/173481[12:10<45:02,50.54it/s] 26%|##6       |45503/173481[15:00<42:07,50.63it/s] 27%|##6       |46038/173481[15:10<41:57,50.63it/s] 31%|###1      |54627/173481[18:00<39:06,50.66it/s] 32%|###1      |55180/173481[18:10<38:55,50.66it/s] 37%|###6      |63864/173481[21:00<35:50,50.98it/s] 37%|###7      |64449/173481[21:11<35:38,50.98it/s] 42%|####2     |72980/173481[24:00<32:57,50.81it/s] 42%|####2     |73513/173481[24:11<32:47,50.81it/s] 47%|####7     |81799/173481[27:00<30:37,49.88it/s] 47%|####7     |82342/173481[27:11<30:26,49.88it/s] 52%|#####2    |90583/173481[30:00<28:00,49.33it/s] 53%|#####2    |91137/173481[30:11<27:49,49.33it/s] 57%|#####7    |99529/173481[33:00<24:53,49.52it/s] 58%|#####7    |100113/173481[33:11<24:41,49.52it/s] 63%|######2   |108460/173481[36:00<21:51,49.57it/s] 63%|######2   |109027/173481[36:11<21:40,49.57it/s] 68%|######7   |117260/173481[39:00<19:02,49.22it/s] 68%|######7   |117851/173481[39:12<18:50,49.22it/s] 73%|#######2  |125957/173481[42:00<16:14,48.77it/s] 73%|#######2  |126541/173481[42:12<16:02,48.77it/s] 78%|#######7  |134696/173481[45:00<13:17,48.66it/s] 78%|#######7  |135287/173481[45:12<13:04,48.66it/s] 83%|########2 |143490/173481[48:00<10:15,48.75it/s] 83%|########3 |144089/173481[48:12<10:02,48.75it/s] 88%|########7 |152335/173481[51:00<07:12,48.94it/s] 88%|########8 |152958/173481[51:12<06:59,48.94it/s] 93%|#########3|161482/173481[54:00<04:00,49.86it/s] 93%|#########3|162150/173481[54:12<03:47,49.86it/s] 98%|#########8|170707/173481[57:00<00:54,50.55it/s] 99%|#########8|171359/173481[57:12<00:41,50.55it/s]100%|##########|173481/173481[57:53<00:00,49.95it/s]
[32m[0329 02:01:25 @base.py:257][0m Epoch 14 (global_step 11623227) finished, time:3473.21 sec.
[32m[0329 02:01:25 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-11623227.
  0%|          |0/18822[00:00<?,?it/s] 90%|######### |17000/18822[03:00<00:19,94.44it/s] 97%|#########6|18207/18822[03:10<00:06,94.44it/s]100%|##########|18822/18822[03:16<00:00,95.76it/s]
13
[32m[0329 02:04:42 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 02:04:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.449
[32m[0329 02:04:42 @monitor.py:363][0m activation-summaries/output-rms: 0.01716
[32m[0329 02:04:42 @monitor.py:363][0m cross_entropy_loss: 6.9994
[32m[0329 02:04:42 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6573e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3228e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6607e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6744e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.848e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9227e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9652e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5466e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1429e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9243e-06
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 02:04:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 02:04:42 @monitor.py:363][0m train-error-top1: 0.99079
[32m[0329 02:04:42 @monitor.py:363][0m val-error-top1: 0.99148
[32m[0329 02:04:42 @monitor.py:363][0m val-utt-error: 0.98698
[32m[0329 02:04:42 @monitor.py:363][0m validation_cost: 7.0039
[32m[0329 02:04:42 @monitor.py:363][0m wd_cost: 7.8826e-17
[32m[0329 02:04:42 @group.py:42][0m Callbacks took 196.886 sec in total. InferenceRunner: 196.565sec
[32m[0329 02:04:42 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9329/173481[03:00<52:47,51.83it/s]  6%|5         |9847/173481[03:10<52:37,51.83it/s] 11%|#         |18627/173481[06:00<49:52,51.74it/s] 11%|#1        |19163/173481[06:10<49:42,51.74it/s] 16%|#6        |27966/173481[09:00<46:48,51.81it/s] 16%|#6        |28487/173481[09:10<46:38,51.81it/s] 21%|##1       |36962/173481[12:00<44:43,50.88it/s] 22%|##1       |37501/173481[12:10<44:32,50.88it/s] 27%|##6       |46166/173481[15:00<41:36,51.00it/s] 27%|##6       |46728/173481[15:10<41:25,51.00it/s] 32%|###1      |55336/173481[18:00<38:37,50.97it/s] 32%|###2      |55890/173481[18:10<38:26,50.97it/s] 37%|###7      |64622/173481[21:00<35:23,51.28it/s] 38%|###7      |65182/173481[21:11<35:12,51.28it/s] 43%|####2     |73911/173481[24:00<32:15,51.44it/s] 43%|####2     |74490/173481[24:11<32:04,51.44it/s] 48%|####7     |83226/173481[27:00<29:09,51.59it/s] 48%|####8     |83807/173481[27:11<28:58,51.59it/s] 53%|#####3    |92531/173481[30:00<26:07,51.64it/s] 54%|#####3    |93091/173481[30:11<25:56,51.64it/s] 58%|#####8    |101239/173481[33:00<24:06,49.96it/s] 59%|#####8    |101814/173481[33:11<23:54,49.96it/s] 63%|######3   |109978/173481[36:00<21:29,49.24it/s] 64%|######3   |110556/173481[36:11<21:17,49.24it/s] 68%|######8   |118613/173481[39:00<18:49,48.60it/s] 69%|######8   |119188/173481[39:12<18:37,48.60it/s] 73%|#######3  |127202/173481[42:00<16:01,48.14it/s] 74%|#######3  |127769/173481[42:12<15:49,48.14it/s] 78%|#######8  |135725/173481[45:00<13:10,47.74it/s] 79%|#######8  |136311/173481[45:12<12:58,47.74it/s] 83%|########3 |144758/173481[48:00<09:47,48.93it/s] 84%|########3 |145355/173481[48:12<09:34,48.93it/s] 88%|########8 |153425/173481[51:00<06:53,48.54it/s] 89%|########8 |154026/173481[51:12<06:40,48.54it/s] 93%|#########3|162151/173481[54:00<03:53,48.50it/s] 94%|#########3|162817/173481[54:12<03:39,48.50it/s] 99%|#########8|171467/173481[57:00<00:40,50.08it/s] 99%|#########9|172137/173481[57:13<00:26,50.08it/s]100%|##########|173481/173481[57:38<00:00,50.16it/s]
[32m[0329 03:02:20 @base.py:257][0m Epoch 15 (global_step 11796708) finished, time:3458.59 sec.
[32m[0329 03:02:20 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s] 82%|########2 |15464/18822[03:00<00:39,85.91it/s] 87%|########7 |16435/18822[03:10<00:27,85.91it/s]100%|##########|18822/18822[03:33<00:00,88.03it/s]
14
[32m[0329 03:05:54 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 03:05:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.412
[32m[0329 03:05:54 @monitor.py:363][0m activation-summaries/output-rms: 0.016742
[32m[0329 03:05:54 @monitor.py:363][0m cross_entropy_loss: 6.9258
[32m[0329 03:05:54 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6572e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3225e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6621e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6753e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8484e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9234e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9647e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5477e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1438e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9245e-06
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 03:05:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 03:05:54 @monitor.py:363][0m train-error-top1: 0.9914
[32m[0329 03:05:54 @monitor.py:363][0m val-error-top1: 0.99155
[32m[0329 03:05:54 @monitor.py:363][0m val-utt-error: 0.98767
[32m[0329 03:05:54 @monitor.py:363][0m validation_cost: 7.017
[32m[0329 03:05:54 @monitor.py:363][0m wd_cost: 7.8826e-17
[32m[0329 03:05:54 @group.py:42][0m Callbacks took 214.086 sec in total. InferenceRunner: 213.812sec
[32m[0329 03:05:54 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9353/173481[03:00<52:38,51.96it/s]  6%|5         |9863/173481[03:10<52:29,51.96it/s] 11%|#         |18460/173481[06:00<50:23,51.26it/s] 11%|#         |18989/173481[06:10<50:13,51.26it/s] 16%|#5        |27602/173481[09:00<47:38,51.03it/s] 16%|#6        |28136/173481[09:10<47:28,51.03it/s] 21%|##1       |36905/173481[12:00<44:19,51.35it/s] 22%|##1       |37403/173481[12:10<44:09,51.35it/s] 26%|##6       |45927/173481[15:00<41:54,50.73it/s] 27%|##6       |46472/173481[15:10<41:43,50.73it/s] 32%|###1      |55035/173481[18:00<38:57,50.66it/s] 32%|###2      |55596/173481[18:10<38:46,50.66it/s] 37%|###7      |64261/173481[21:00<35:43,50.95it/s] 37%|###7      |64819/173481[21:11<35:32,50.95it/s] 42%|####2     |73481/173481[24:00<32:37,51.09it/s] 43%|####2     |74053/173481[24:11<32:26,51.09it/s] 47%|####7     |82321/173481[27:00<30:20,50.07it/s] 48%|####7     |82860/173481[27:11<30:09,50.07it/s] 52%|#####2    |90987/173481[30:00<28:00,49.09it/s] 53%|#####2    |91530/173481[30:11<27:49,49.09it/s] 57%|#####7    |99437/173481[33:00<25:42,47.99it/s] 58%|#####7    |99980/173481[33:11<25:31,47.99it/s] 62%|######2   |107908/173481[36:00<22:59,47.52it/s] 63%|######2   |108460/173481[36:11<22:48,47.52it/s] 67%|######7   |116363/173481[39:00<20:09,47.24it/s] 67%|######7   |116919/173481[39:12<19:57,47.24it/s] 72%|#######1  |124836/173481[42:00<17:11,47.16it/s] 72%|#######2  |125405/173481[42:12<16:59,47.16it/s] 77%|#######6  |133283/173481[45:00<14:14,47.04it/s] 77%|#######7  |133856/173481[45:12<14:02,47.04it/s] 82%|########1 |141908/173481[48:00<11:05,47.47it/s] 82%|########2 |142538/173481[48:12<10:51,47.47it/s] 87%|########6 |150274/173481[51:00<08:14,46.97it/s] 87%|########6 |150864/173481[51:12<08:01,46.97it/s] 91%|#########1|158575/173481[54:00<05:20,46.54it/s] 92%|#########1|159164/173481[54:12<05:07,46.54it/s] 96%|#########6|166915/173481[57:00<02:21,46.43it/s] 97%|#########6|167505/173481[57:12<02:08,46.43it/s]100%|##########|173481/173481[59:23<00:00,48.68it/s]
[32m[0329 04:05:18 @base.py:257][0m Epoch 16 (global_step 11970189) finished, time:3563.43 sec.
[32m[0329 04:05:18 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s] 76%|#######5  |14223/18822[03:00<00:58,79.02it/s] 80%|########  |15110/18822[03:10<00:46,79.02it/s]100%|##########|18822/18822[03:55<00:00,79.97it/s]
15
[32m[0329 04:09:13 @monitor.py:363][0m QueueInput/queue_size: 1.1786
[32m[0329 04:09:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.621
[32m[0329 04:09:13 @monitor.py:363][0m activation-summaries/output-rms: 0.016936
[32m[0329 04:09:13 @monitor.py:363][0m cross_entropy_loss: 6.9628
[32m[0329 04:09:13 @monitor.py:363][0m lr: 2.9802e-11
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6562e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.323e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6621e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6745e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8475e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9227e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9638e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5473e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1446e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9235e-06
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 04:09:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 04:09:13 @monitor.py:363][0m train-error-top1: 0.99224
[32m[0329 04:09:13 @monitor.py:363][0m val-error-top1: 0.99145
[32m[0329 04:09:13 @monitor.py:363][0m val-utt-error: 0.98539
[32m[0329 04:09:13 @monitor.py:363][0m validation_cost: 7.0024
[32m[0329 04:09:13 @monitor.py:363][0m wd_cost: 7.8826e-17
[32m[0329 04:09:13 @group.py:42][0m Callbacks took 235.628 sec in total. InferenceRunner: 235.387sec
[32m[0329 04:09:13 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9397/173481[03:00<52:23,52.20it/s]  6%|5         |9924/173481[03:10<52:13,52.20it/s] 10%|#         |17880/173481[06:00<52:21,49.53it/s] 11%|#         |18423/173481[06:10<52:10,49.53it/s] 16%|#5        |27235/173481[09:00<48:03,50.72it/s] 16%|#6        |27762/173481[09:10<47:53,50.72it/s] 21%|##        |36386/173481[12:00<44:59,50.78it/s] 21%|##1       |36923/173481[12:10<44:49,50.78it/s] 26%|##6       |45533/173481[15:00<41:58,50.80it/s] 27%|##6       |46060/173481[15:10<41:48,50.80it/s] 31%|###1      |54525/173481[18:00<39:21,50.37it/s] 32%|###1      |55057/173481[18:10<39:11,50.37it/s] 37%|###6      |63629/173481[21:00<36:16,50.47it/s] 37%|###6      |64183/173481[21:11<36:05,50.47it/s] 42%|####1     |72759/173481[24:00<33:10,50.60it/s] 42%|####2     |73328/173481[24:11<32:59,50.60it/s] 47%|####7     |81976/173481[27:00<29:57,50.90it/s] 48%|####7     |82539/173481[27:11<29:46,50.90it/s] 53%|#####2    |91124/173481[30:00<26:59,50.86it/s] 53%|#####2    |91705/173481[30:11<26:47,50.86it/s] 58%|#####7    |100209/173481[33:00<24:06,50.66it/s] 58%|#####8    |100760/173481[33:11<23:55,50.66it/s] 63%|######2   |108700/173481[36:00<22:06,48.85it/s] 63%|######2   |109247/173481[36:11<21:54,48.85it/s] 68%|######7   |117205/173481[39:00<19:31,48.03it/s] 68%|######7   |117776/173481[39:12<19:19,48.03it/s] 72%|#######2  |125725/173481[42:00<16:41,47.68it/s] 73%|#######2  |126288/173481[42:12<16:29,47.68it/s] 77%|#######7  |134255/173481[45:00<13:45,47.53it/s] 78%|#######7  |134824/173481[45:12<13:33,47.53it/s] 82%|########2 |142737/173481[48:00<10:49,47.32it/s] 83%|########2 |143331/173481[48:12<10:37,47.32it/s] 87%|########7 |151350/173481[51:00<07:45,47.58it/s] 88%|########7 |151961/173481[51:12<07:32,47.58it/s] 92%|#########2|160099/173481[54:00<04:38,48.09it/s] 93%|#########2|160709/173481[54:12<04:25,48.09it/s] 97%|#########7|168812/173481[57:00<01:36,48.24it/s] 98%|#########7|169413/173481[57:12<01:24,48.24it/s]100%|##########|173481/173481[58:36<00:00,49.34it/s]
[32m[0329 05:07:50 @base.py:257][0m Epoch 17 (global_step 12143670) finished, time:3516.39 sec.
[32m[0329 05:07:50 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-12143670.
  0%|          |0/18822[00:00<?,?it/s] 71%|#######   |13336/18822[03:00<01:14,74.09it/s] 75%|#######4  |14085/18822[03:10<01:03,74.09it/s]100%|##########|18822/18822[04:11<00:00,74.75it/s]
16
[32m[0329 05:12:02 @monitor.py:363][0m QueueInput/queue_size: 1.8057
[32m[0329 05:12:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.409
[32m[0329 05:12:02 @monitor.py:363][0m activation-summaries/output-rms: 0.016894
[32m[0329 05:12:02 @monitor.py:363][0m cross_entropy_loss: 6.9614
[32m[0329 05:12:02 @monitor.py:363][0m lr: 2.9802e-11
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6574e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3231e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6614e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6739e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8472e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9235e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9641e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5477e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1458e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9239e-06
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 05:12:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 05:12:02 @monitor.py:363][0m train-error-top1: 0.99031
[32m[0329 05:12:02 @monitor.py:363][0m val-error-top1: 0.9915
[32m[0329 05:12:02 @monitor.py:363][0m val-utt-error: 0.98746
[32m[0329 05:12:02 @monitor.py:363][0m validation_cost: 7.008
[32m[0329 05:12:02 @monitor.py:363][0m wd_cost: 1.5765e-17
[32m[0329 05:12:02 @group.py:42][0m Callbacks took 252.148 sec in total. InferenceRunner: 251.826sec
[32m[0329 05:12:02 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9298/173481[03:00<52:58,51.65it/s]  6%|5         |9820/173481[03:10<52:48,51.65it/s] 11%|#         |18765/173481[06:00<49:28,52.12it/s] 11%|#1        |19268/173481[06:10<49:18,52.12it/s] 16%|#5        |27741/173481[09:00<47:39,50.97it/s] 16%|#6        |28300/173481[09:10<47:28,50.97it/s] 21%|##1       |37055/173481[12:00<44:16,51.35it/s] 22%|##1       |37610/173481[12:10<44:05,51.35it/s] 26%|##6       |45903/173481[15:00<42:19,50.23it/s] 27%|##6       |46387/173481[15:10<42:10,50.23it/s] 31%|###1      |54614/173481[18:00<40:11,49.29it/s] 32%|###1      |55162/173481[18:10<40:00,49.29it/s] 37%|###6      |63662/173481[21:00<36:46,49.77it/s] 37%|###7      |64244/173481[21:11<36:34,49.77it/s] 42%|####1     |72525/173481[24:00<33:59,49.50it/s] 42%|####2     |73058/173481[24:11<33:48,49.50it/s] 47%|####6     |81111/173481[27:00<31:41,48.58it/s] 47%|####7     |81653/173481[27:11<31:30,48.58it/s] 52%|#####1    |89680/173481[30:00<29:02,48.09it/s] 52%|#####2    |90246/173481[30:11<28:50,48.09it/s] 57%|#####6    |98259/173481[33:00<26:11,47.87it/s] 57%|#####6    |98823/173481[33:11<25:59,47.87it/s] 62%|######1   |106796/173481[36:00<23:19,47.65it/s] 62%|######1   |107373/173481[36:11<23:07,47.65it/s] 67%|######6   |115514/173481[39:00<20:06,48.04it/s] 67%|######6   |116071/173481[39:12<19:55,48.04it/s] 72%|#######1  |124118/173481[42:00<17:10,47.92it/s] 72%|#######1  |124714/173481[42:12<16:57,47.92it/s] 77%|#######6  |132857/173481[45:00<14:02,48.23it/s] 77%|#######6  |133420/173481[45:12<13:50,48.23it/s] 82%|########1 |141857/173481[48:00<10:44,49.10it/s] 82%|########2 |142484/173481[48:12<10:31,49.10it/s] 87%|########7 |151023/173481[51:00<07:29,49.99it/s] 87%|########7 |151679/173481[51:12<07:16,49.99it/s] 92%|#########2|160364/173481[54:00<04:17,50.92it/s] 93%|#########2|161031/173481[54:12<04:04,50.92it/s] 98%|#########7|169532/173481[57:00<01:17,50.93it/s] 98%|#########8|170183/173481[57:13<01:04,50.93it/s]100%|##########|173481/173481[58:18<00:00,49.59it/s]
[32m[0329 06:10:20 @base.py:257][0m Epoch 18 (global_step 12317151) finished, time:3498.12 sec.
[32m[0329 06:10:20 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######7  |14629/18822[03:00<00:51,81.27it/s] 82%|########1 |15405/18822[03:10<00:42,81.27it/s]100%|##########|18822/18822[03:50<00:00,81.72it/s]
17
[32m[0329 06:14:10 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 06:14:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.49
[32m[0329 06:14:10 @monitor.py:363][0m activation-summaries/output-rms: 0.01645
[32m[0329 06:14:10 @monitor.py:363][0m cross_entropy_loss: 6.9546
[32m[0329 06:14:10 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6566e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3233e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6622e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6743e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8477e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9238e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.964e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5478e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1466e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9231e-06
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 06:14:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 06:14:10 @monitor.py:363][0m train-error-top1: 0.99111
[32m[0329 06:14:10 @monitor.py:363][0m val-error-top1: 0.99151
[32m[0329 06:14:10 @monitor.py:363][0m val-utt-error: 0.98751
[32m[0329 06:14:10 @monitor.py:363][0m validation_cost: 7.0085
[32m[0329 06:14:10 @monitor.py:363][0m wd_cost: 1.5765e-17
[32m[0329 06:14:10 @group.py:42][0m Callbacks took 230.557 sec in total. InferenceRunner: 230.324sec
[32m[0329 06:14:10 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9273/173481[03:00<53:07,51.51it/s]  6%|5         |9814/173481[03:10<52:57,51.51it/s] 10%|#         |17984/173481[06:00<51:55,49.90it/s] 11%|#         |18454/173481[06:10<51:46,49.90it/s] 15%|#5        |26419/173481[09:00<50:42,48.33it/s] 16%|#5        |26930/173481[09:10<50:32,48.33it/s] 20%|##        |35030/173481[12:00<47:59,48.08it/s] 21%|##        |35600/173481[12:10<47:47,48.08it/s] 26%|##5       |44477/173481[15:00<42:50,50.19it/s] 26%|##5       |45028/173481[15:10<42:39,50.19it/s] 31%|###       |53743/173481[18:00<39:15,50.82it/s] 31%|###1      |54306/173481[18:10<39:04,50.82it/s] 36%|###6      |63028/173481[21:00<35:57,51.20it/s] 37%|###6      |63586/173481[21:11<35:46,51.20it/s] 42%|####1     |72092/173481[24:00<33:16,50.77it/s] 42%|####1     |72648/173481[24:11<33:06,50.77it/s] 47%|####6     |81397/173481[27:00<29:57,51.23it/s] 47%|####7     |82006/173481[27:11<29:45,51.23it/s] 52%|#####1    |90088/173481[30:00<27:57,49.71it/s] 52%|#####2    |90632/173481[30:11<27:46,49.71it/s] 57%|#####6    |98881/173481[33:00<25:13,49.28it/s] 57%|#####7    |99450/173481[33:11<25:02,49.28it/s] 62%|######2   |108013/173481[36:00<21:49,49.99it/s] 63%|######2   |108623/173481[36:11<21:37,49.99it/s] 68%|######7   |117396/173481[39:00<18:18,51.04it/s] 68%|######8   |118003/173481[39:11<18:07,51.04it/s] 73%|#######3  |126745/173481[42:00<15:07,51.48it/s] 73%|#######3  |127365/173481[42:12<14:55,51.48it/s] 78%|#######8  |136075/173481[45:00<12:04,51.66it/s] 79%|#######8  |136702/173481[45:12<11:51,51.66it/s] 84%|########3 |145341/173481[48:00<09:05,51.56it/s] 84%|########4 |145956/173481[48:12<08:53,51.56it/s] 89%|########8 |154156/173481[51:00<06:24,50.23it/s] 89%|########9 |154771/173481[51:12<06:12,50.23it/s] 94%|#########3|162950/173481[54:00<03:32,49.53it/s] 94%|#########4|163577/173481[54:12<03:19,49.53it/s] 99%|#########8|171651/173481[57:00<00:37,48.93it/s] 99%|#########9|172278/173481[57:12<00:24,48.93it/s]100%|##########|173481/173481[57:37<00:00,50.17it/s]
[32m[0329 07:11:48 @base.py:257][0m Epoch 19 (global_step 12490632) finished, time:3457.83 sec.
[32m[0329 07:11:48 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-12490632.
  0%|          |0/18822[00:00<?,?it/s] 70%|######9   |13164/18822[03:00<01:17,73.13it/s] 74%|#######3  |13928/18822[03:10<01:06,73.13it/s]100%|##########|18822/18822[04:14<00:00,74.06it/s]
18
[32m[0329 07:16:03 @monitor.py:363][0m QueueInput/queue_size: 1.2618
[32m[0329 07:16:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.464
[32m[0329 07:16:03 @monitor.py:363][0m activation-summaries/output-rms: 0.017002
[32m[0329 07:16:03 @monitor.py:363][0m cross_entropy_loss: 6.9445
[32m[0329 07:16:03 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6558e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3233e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6617e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6744e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8481e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9237e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9641e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5483e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1467e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9231e-06
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 07:16:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 07:16:03 @monitor.py:363][0m train-error-top1: 0.99235
[32m[0329 07:16:03 @monitor.py:363][0m val-error-top1: 0.9915
[32m[0329 07:16:03 @monitor.py:363][0m val-utt-error: 0.98773
[32m[0329 07:16:03 @monitor.py:363][0m validation_cost: 7.0043
[32m[0329 07:16:03 @monitor.py:363][0m wd_cost: 3.153e-18
[32m[0329 07:16:03 @group.py:42][0m Callbacks took 254.411 sec in total. InferenceRunner: 254.149sec
[32m[0329 07:16:03 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9231/173481[03:00<53:22,51.28it/s]  6%|5         |9758/173481[03:10<53:12,51.28it/s] 11%|#         |18445/173481[06:00<50:26,51.23it/s] 11%|#         |18968/173481[06:10<50:15,51.23it/s] 16%|#5        |27608/173481[09:00<47:36,51.07it/s] 16%|#6        |28137/173481[09:10<47:26,51.07it/s] 21%|##1       |36913/173481[12:00<44:18,51.38it/s] 22%|##1       |37475/173481[12:10<44:07,51.38it/s] 26%|##6       |45845/173481[15:00<42:08,50.48it/s] 27%|##6       |46354/173481[15:10<41:58,50.48it/s] 32%|###1      |54996/173481[18:00<38:58,50.66it/s] 32%|###2      |55561/173481[18:10<38:47,50.66it/s] 37%|###7      |64410/173481[21:00<35:19,51.46it/s] 37%|###7      |64987/173481[21:11<35:08,51.46it/s] 43%|####2     |73768/173481[24:00<32:07,51.72it/s] 43%|####2     |74322/173481[24:11<31:57,51.72it/s] 48%|####7     |82794/173481[27:00<29:40,50.92it/s] 48%|####8     |83353/173481[27:11<29:30,50.92it/s] 53%|#####2    |91898/173481[30:00<26:47,50.75it/s] 53%|#####3    |92491/173481[30:11<26:35,50.75it/s] 58%|#####8    |101196/173481[33:00<23:31,51.20it/s] 59%|#####8    |101761/173481[33:11<23:20,51.20it/s] 63%|######3   |109852/173481[36:00<21:23,49.59it/s] 64%|######3   |110421/173481[36:11<21:11,49.59it/s] 68%|######8   |118619/173481[39:00<18:36,49.14it/s] 69%|######8   |119224/173481[39:12<18:24,49.14it/s] 74%|#######3  |127999/173481[42:00<14:59,50.58it/s] 74%|#######4  |128621/173481[42:12<14:46,50.58it/s] 79%|#######8  |136955/173481[45:00<12:08,50.16it/s] 79%|#######9  |137584/173481[45:12<11:55,50.16it/s] 84%|########3 |145642/173481[48:00<09:25,49.19it/s] 84%|########4 |146224/173481[48:12<09:14,49.19it/s] 89%|########9 |154448/173481[51:00<06:27,49.06it/s] 89%|########9 |155108/173481[51:12<06:14,49.06it/s] 94%|#########4|163410/173481[54:00<03:23,49.42it/s] 95%|#########4|164004/173481[54:12<03:11,49.42it/s] 99%|#########9|172034/173481[57:00<00:29,48.65it/s]100%|#########9|172634/173481[57:12<00:17,48.65it/s]100%|##########|173481/173481[57:31<00:00,50.26it/s]
[32m[0329 08:13:34 @base.py:257][0m Epoch 20 (global_step 12664113) finished, time:3451.66 sec.
[32m[0329 08:13:35 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s] 69%|######9   |13002/18822[03:00<01:20,72.23it/s] 73%|#######3  |13744/18822[03:10<01:10,72.23it/s]100%|##########|18822/18822[04:17<00:00,73.09it/s]
19
[32m[0329 08:17:52 @monitor.py:363][0m QueueInput/queue_size: 1.4981
[32m[0329 08:17:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.537
[32m[0329 08:17:52 @monitor.py:363][0m activation-summaries/output-rms: 0.016626
[32m[0329 08:17:52 @monitor.py:363][0m cross_entropy_loss: 6.9791
[32m[0329 08:17:52 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6566e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3231e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6622e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6741e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8481e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9238e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.964e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5478e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1464e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9234e-06
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 08:17:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 08:17:52 @monitor.py:363][0m train-error-top1: 0.99058
[32m[0329 08:17:52 @monitor.py:363][0m val-error-top1: 0.99147
[32m[0329 08:17:52 @monitor.py:363][0m val-utt-error: 0.98783
[32m[0329 08:17:52 @monitor.py:363][0m validation_cost: 6.9906
[32m[0329 08:17:52 @monitor.py:363][0m wd_cost: 3.153e-18
[32m[0329 08:17:52 @group.py:42][0m Callbacks took 257.735 sec in total. InferenceRunner: 257.526sec
[32m[0329 08:17:52 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9146/173481[03:00<53:54,50.81it/s]  6%|5         |9663/173481[03:10<53:44,50.81it/s] 11%|#         |18234/173481[06:00<51:05,50.65it/s] 11%|#         |18750/173481[06:10<50:55,50.65it/s] 16%|#5        |27250/173481[09:00<48:23,50.36it/s] 16%|#6        |27782/173481[09:10<48:12,50.36it/s] 21%|##        |36331/173481[12:00<45:20,50.41it/s] 21%|##1       |36867/173481[12:10<45:10,50.41it/s] 26%|##6       |45535/173481[15:00<42:00,50.77it/s] 27%|##6       |46091/173481[15:10<41:49,50.77it/s] 32%|###1      |54665/173481[18:00<39:01,50.74it/s] 32%|###1      |55217/173481[18:10<38:50,50.74it/s] 37%|###6      |63835/173481[21:00<35:56,50.84it/s] 37%|###7      |64392/173481[21:11<35:45,50.84it/s] 42%|####2     |73018/173481[24:00<32:52,50.93it/s] 42%|####2     |73579/173481[24:11<32:41,50.93it/s] 47%|####7     |82084/173481[27:00<30:04,50.64it/s] 48%|####7     |82645/173481[27:11<29:53,50.64it/s] 52%|#####2    |91073/173481[30:00<27:18,50.29it/s] 53%|#####2    |91644/173481[30:11<27:07,50.29it/s] 58%|#####7    |99995/173481[33:00<24:31,49.92it/s] 58%|#####7    |100571/173481[33:11<24:20,49.92it/s] 63%|######2   |109044/173481[36:00<21:26,50.10it/s] 63%|######3   |109621/173481[36:11<21:14,50.10it/s] 68%|######8   |118096/173481[39:00<18:23,50.19it/s] 68%|######8   |118685/173481[39:12<18:11,50.19it/s] 73%|#######3  |127041/173481[42:00<15:29,49.94it/s] 74%|#######3  |127643/173481[42:12<15:17,49.94it/s] 78%|#######8  |136099/173481[45:00<12:25,50.13it/s] 79%|#######8  |136713/173481[45:12<12:13,50.13it/s] 84%|########3 |145107/173481[48:00<09:26,50.08it/s] 84%|########3 |145716/173481[48:12<09:14,50.08it/s] 89%|########8 |154069/173481[51:00<06:28,49.94it/s] 89%|########9 |154682/173481[51:12<06:16,49.94it/s] 94%|#########4|163089/173481[54:00<03:27,50.02it/s] 94%|#########4|163735/173481[54:12<03:14,50.02it/s] 99%|#########9|172137/173481[57:00<00:26,50.14it/s]100%|#########9|172791/173481[57:12<00:13,50.14it/s]100%|##########|173481/173481[57:26<00:00,50.34it/s]
[32m[0329 09:15:18 @base.py:257][0m Epoch 21 (global_step 12837594) finished, time:3446.28 sec.
[32m[0329 09:15:19 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s] 70%|#######   |13254/18822[03:00<01:15,73.63it/s] 75%|#######4  |14033/18822[03:10<01:05,73.63it/s]100%|##########|18822/18822[04:13<00:00,74.22it/s]
20
[32m[0329 09:19:32 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 09:19:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.433
[32m[0329 09:19:32 @monitor.py:363][0m activation-summaries/output-rms: 0.016274
[32m[0329 09:19:32 @monitor.py:363][0m cross_entropy_loss: 6.9391
[32m[0329 09:19:32 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6563e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3233e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.662e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6739e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.848e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9237e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9638e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5477e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1463e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9232e-06
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 09:19:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 09:19:32 @monitor.py:363][0m train-error-top1: 0.99197
[32m[0329 09:19:32 @monitor.py:363][0m val-error-top1: 0.99143
[32m[0329 09:19:32 @monitor.py:363][0m val-utt-error: 0.98688
[32m[0329 09:19:32 @monitor.py:363][0m validation_cost: 7.0097
[32m[0329 09:19:32 @monitor.py:363][0m wd_cost: 3.153e-18
[32m[0329 09:19:32 @group.py:42][0m Callbacks took 253.874 sec in total. InferenceRunner: 253.620sec
[32m[0329 09:19:32 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9070/173481[03:00<54:22,50.39it/s]  6%|5         |9578/173481[03:10<54:12,50.39it/s] 10%|#         |18182/173481[06:00<51:14,50.50it/s] 11%|#         |18705/173481[06:10<51:04,50.50it/s] 16%|#5        |27347/173481[09:00<48:01,50.71it/s] 16%|#6        |27844/173481[09:10<47:52,50.71it/s] 21%|##        |35617/173481[12:00<47:39,48.21it/s] 21%|##        |36086/173481[12:10<47:30,48.21it/s] 25%|##5       |43699/173481[15:00<46:31,46.49it/s] 25%|##5       |44189/173481[15:10<46:20,46.49it/s] 30%|##9       |51950/173481[18:00<43:52,46.16it/s] 30%|###       |52458/173481[18:10<43:41,46.16it/s] 35%|###4      |60493/173481[21:00<40:14,46.80it/s] 35%|###5      |61007/173481[21:11<40:03,46.80it/s] 40%|###9      |68847/173481[24:00<37:25,46.60it/s] 40%|###9      |69387/173481[24:11<37:13,46.60it/s] 45%|####4     |77937/173481[27:00<32:51,48.47it/s] 45%|####5     |78517/173481[27:11<32:39,48.47it/s] 50%|#####     |87212/173481[30:00<28:47,49.95it/s] 51%|#####     |87792/173481[30:11<28:35,49.95it/s] 55%|#####5    |96236/173481[33:00<25:43,50.04it/s] 56%|#####5    |96823/173481[33:11<25:31,50.04it/s] 61%|######    |105425/173481[36:00<22:26,50.54it/s] 61%|######1   |106061/173481[36:11<22:13,50.54it/s] 66%|######5   |113955/173481[39:00<20:16,48.91it/s] 66%|######6   |114509/173481[39:12<20:05,48.91it/s] 70%|#######   |122295/173481[42:00<17:55,47.59it/s] 71%|#######   |122865/173481[42:12<17:43,47.59it/s] 76%|#######5  |131121/173481[45:00<14:37,48.30it/s] 76%|#######5  |131784/173481[45:12<14:23,48.30it/s] 81%|########1 |140653/173481[48:00<10:49,50.52it/s] 81%|########1 |141308/173481[48:12<10:36,50.52it/s] 87%|########6 |150083/173481[51:00<07:34,51.44it/s] 87%|########6 |150733/173481[51:12<07:22,51.44it/s] 92%|#########1|159527/173481[54:00<04:28,51.94it/s] 92%|#########2|160190/173481[54:12<04:15,51.94it/s] 97%|#########7|169066/173481[57:00<01:24,52.46it/s] 98%|#########7|169763/173481[57:13<01:10,52.46it/s]100%|##########|173481/173481[58:30<00:00,49.42it/s]
[32m[0329 10:18:02 @base.py:257][0m Epoch 22 (global_step 13011075) finished, time:3510.14 sec.
[32m[0329 10:18:03 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-13011075.
  0%|          |0/18822[00:00<?,?it/s] 65%|######4   |12204/18822[03:00<01:37,67.80it/s] 69%|######8   |12936/18822[03:10<01:26,67.80it/s]100%|##########|18822/18822[04:32<00:00,68.98it/s]
21
[32m[0329 10:22:36 @monitor.py:363][0m QueueInput/queue_size: 1.3565
[32m[0329 10:22:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.409
[32m[0329 10:22:36 @monitor.py:363][0m activation-summaries/output-rms: 0.016894
[32m[0329 10:22:36 @monitor.py:363][0m cross_entropy_loss: 6.9614
[32m[0329 10:22:36 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6563e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3234e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6619e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6738e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8483e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9238e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.964e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5477e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1464e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.923e-06
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 10:22:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 10:22:36 @monitor.py:363][0m train-error-top1: 0.99031
[32m[0329 10:22:36 @monitor.py:363][0m val-error-top1: 0.9915
[32m[0329 10:22:36 @monitor.py:363][0m val-utt-error: 0.98746
[32m[0329 10:22:36 @monitor.py:363][0m validation_cost: 7.008
[32m[0329 10:22:36 @monitor.py:363][0m wd_cost: 6.3061e-19
[32m[0329 10:22:36 @group.py:42][0m Callbacks took 273.656 sec in total. InferenceRunner: 272.879sec
[32m[0329 10:22:36 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9453/173481[03:00<52:03,52.52it/s]  6%|5         |9983/173481[03:10<51:53,52.52it/s] 11%|#         |18893/173481[06:00<49:05,52.48it/s] 11%|#1        |19427/173481[06:10<48:55,52.48it/s] 16%|#6        |28350/173481[09:00<46:03,52.51it/s] 17%|#6        |28896/173481[09:10<45:53,52.51it/s] 22%|##1       |37727/173481[12:00<43:15,52.30it/s] 22%|##2       |38282/173481[12:10<43:05,52.30it/s] 27%|##7       |47053/173481[15:00<40:28,52.05it/s] 27%|##7       |47616/173481[15:10<40:18,52.05it/s] 33%|###2      |56511/173481[18:00<37:16,52.30it/s] 33%|###2      |57084/173481[18:10<37:05,52.30it/s] 38%|###8      |66010/173481[21:00<34:05,52.53it/s] 38%|###8      |66599/173481[21:11<33:54,52.53it/s] 44%|####3     |75534/173481[24:00<30:57,52.72it/s] 44%|####3     |76119/173481[24:11<30:46,52.72it/s] 49%|####9     |85008/173481[27:00<27:59,52.67it/s] 49%|####9     |85596/173481[27:11<27:48,52.67it/s] 54%|#####4    |94495/173481[30:00<24:59,52.69it/s] 55%|#####4    |95098/173481[30:11<24:47,52.69it/s] 60%|#####9    |103958/173481[33:00<22:01,52.63it/s] 60%|######    |104560/173481[33:11<21:49,52.63it/s] 65%|######5   |113439/173481[36:00<19:00,52.65it/s] 66%|######5   |114056/173481[36:11<18:48,52.65it/s] 71%|#######   |122902/173481[39:00<16:01,52.61it/s] 71%|#######1  |123532/173481[39:11<15:49,52.61it/s] 76%|#######6  |132333/173481[42:00<13:03,52.50it/s] 77%|#######6  |132959/173481[42:12<12:51,52.50it/s] 82%|########1 |141758/173481[45:00<10:05,52.43it/s] 82%|########2 |142397/173481[45:12<09:52,52.43it/s] 87%|########7 |151118/173481[48:00<07:08,52.21it/s] 87%|########7 |151756/173481[48:12<06:56,52.21it/s] 93%|#########2|160512/173481[51:00<04:08,52.20it/s] 93%|#########2|161162/173481[51:12<03:56,52.20it/s] 98%|#########7|169985/173481[54:00<01:06,52.41it/s] 98%|#########8|170639/173481[54:12<00:54,52.41it/s]100%|##########|173481/173481[55:07<00:00,52.46it/s]
[32m[0329 11:17:43 @base.py:257][0m Epoch 23 (global_step 13184556) finished, time:3307.23 sec.
[32m[0329 11:17:43 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s] 68%|######8   |12826/18822[03:00<01:24,71.25it/s] 72%|#######2  |13571/18822[03:10<01:13,71.25it/s]100%|##########|18822/18822[04:21<00:00,71.94it/s]
22
[32m[0329 11:22:05 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 11:22:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.436
[32m[0329 11:22:05 @monitor.py:363][0m activation-summaries/output-rms: 0.016987
[32m[0329 11:22:05 @monitor.py:363][0m cross_entropy_loss: 6.9531
[32m[0329 11:22:05 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6561e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3234e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6617e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.6738e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8482e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.924e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9639e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5479e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1464e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9227e-06
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 11:22:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 11:22:05 @monitor.py:363][0m train-error-top1: 0.99006
[32m[0329 11:22:05 @monitor.py:363][0m val-error-top1: 0.99142
[32m[0329 11:22:05 @monitor.py:363][0m val-utt-error: 0.98799
[32m[0329 11:22:05 @monitor.py:363][0m validation_cost: 7.0068
[32m[0329 11:22:05 @monitor.py:363][0m wd_cost: 6.3061e-19
[32m[0329 11:22:05 @group.py:42][0m Callbacks took 261.931 sec in total. InferenceRunner: 261.655sec
[32m[0329 11:22:05 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9487/173481[03:00<51:51,52.70it/s]  6%|5         |10022/173481[03:10<51:41,52.70it/s] 11%|#         |18957/173481[06:00<48:54,52.66it/s] 11%|#1        |19501/173481[06:10<48:44,52.66it/s] 16%|#6        |28416/173481[09:00<45:57,52.60it/s] 17%|#6        |28968/173481[09:10<45:47,52.60it/s] 22%|##1       |37910/173481[12:00<42:53,52.67it/s] 22%|##2       |38468/173481[12:10<42:43,52.67it/s] 27%|##7       |47391/173481[15:00<39:53,52.67it/s] 28%|##7       |47965/173481[15:10<39:43,52.67it/s] 33%|###2      |56885/173481[18:00<36:52,52.71it/s] 33%|###3      |57455/173481[18:10<36:41,52.71it/s] 38%|###8      |66382/173481[21:00<33:51,52.73it/s] 39%|###8      |66961/173481[21:11<33:40,52.73it/s] 44%|####4     |76393/173481[24:00<29:53,54.13it/s] 44%|####4     |76990/173481[24:11<29:42,54.13it/s] 49%|####9     |85873/173481[27:00<27:20,53.39it/s] 50%|####9     |86461/173481[27:11<27:09,53.39it/s] 55%|#####4    |95315/173481[30:00<24:37,52.92it/s] 55%|#####5    |95916/173481[30:11<24:25,52.92it/s] 60%|######    |104791/173481[33:00<21:41,52.78it/s] 61%|######    |105399/173481[33:11<21:29,52.78it/s] 66%|######5   |114219/173481[36:00<18:47,52.58it/s] 66%|######6   |114835/173481[36:11<18:35,52.58it/s] 71%|#######1  |123697/173481[39:00<15:46,52.61it/s] 72%|#######1  |124321/173481[39:12<15:34,52.61it/s] 77%|#######6  |133150/173481[42:00<12:47,52.57it/s] 77%|#######7  |133775/173481[42:12<12:35,52.57it/s] 82%|########2 |142629/173481[45:00<09:46,52.61it/s] 83%|########2 |143261/173481[45:12<09:34,52.61it/s] 88%|########7 |152093/173481[48:00<06:46,52.59it/s] 88%|########8 |152742/173481[48:12<06:34,52.59it/s] 93%|#########3|161562/173481[51:00<03:46,52.60it/s] 94%|#########3|162219/173481[51:12<03:34,52.60it/s] 98%|#########8|170779/173481[54:00<00:52,51.89it/s] 99%|#########8|171352/173481[54:12<00:41,51.89it/s]100%|##########|173481/173481[54:57<00:00,52.61it/s]
[32m[0329 12:17:03 @base.py:257][0m Epoch 24 (global_step 13358037) finished, time:3297.71 sec.
[32m[0329 12:17:03 @saver.py:84][0m Model saved to train_log/lcn_w_8_a_8_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s] 64%|######4   |12087/18822[03:00<01:40,67.15it/s] 68%|######7   |12751/18822[03:10<01:30,67.15it/s]100%|##########|18822/18822[04:28<00:00,70.13it/s]
23
[32m[0329 12:21:32 @monitor.py:363][0m QueueInput/queue_size: 1.3592
[32m[0329 12:21:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.464
[32m[0329 12:21:32 @monitor.py:363][0m activation-summaries/output-rms: 0.017002
[32m[0329 12:21:32 @monitor.py:363][0m cross_entropy_loss: 6.9445
[32m[0329 12:21:32 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48235
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.6559e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35776
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0b/b-rms: 6.3234e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45411
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.6616e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35071
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.674e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47325
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8483e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35118
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9239e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47612
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.9639e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34975
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5478e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49105
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.1466e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35348
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9226e-06
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5957
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4064
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3245
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090718
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31609
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083103
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30636
[32m[0329 12:21:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086393
[32m[0329 12:21:32 @monitor.py:363][0m train-error-top1: 0.99235
[32m[0329 12:21:32 @monitor.py:363][0m val-error-top1: 0.9915
[32m[0329 12:21:32 @monitor.py:363][0m val-utt-error: 0.98773
[32m[0329 12:21:32 @monitor.py:363][0m validation_cost: 7.0043
[32m[0329 12:21:32 @monitor.py:363][0m wd_cost: 6.3061e-19
[32m[0329 12:21:32 @group.py:42][0m Callbacks took 268.671 sec in total. InferenceRunner: 268.400sec
[32m[0329 12:21:32 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9321/173481[03:00<52:50,51.78it/s]  6%|5         |9841/173481[03:10<52:40,51.78it/s] 11%|#         |18893/173481[06:00<49:06,52.47it/s] 11%|#1        |19385/173481[06:10<48:56,52.47it/s] 16%|#5        |27120/173481[09:00<49:55,48.85it/s] 16%|#5        |27603/173481[09:10<49:46,48.85it/s] 21%|##        |35652/173481[12:00<47:44,48.11it/s] 21%|##        |36167/173481[12:10<47:34,48.11it/s] 25%|##5       |44085/173481[15:00<45:25,47.47it/s] 26%|##5       |44587/173481[15:10<45:15,47.47it/s]slurmstepd: *** STEP 85166.0 ON sls-sm-6 CANCELLED AT 2018-03-29T12:39:10 ***
slurmstepd: *** JOB 85166 ON sls-sm-6 CANCELLED AT 2018-03-29T12:39:10 ***
srun: got SIGCONT
srun: forcing job termination
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
