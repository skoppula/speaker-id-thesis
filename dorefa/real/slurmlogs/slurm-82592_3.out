sls-tesla-1 1
SLURM_JOBID=82595
SLURM_TASKID=3
[32m[0323 10:57:37 @logger.py:67][0m Existing log file 'train_log/fcn1_w_8_a_32_quant_ends_False/log.log' backuped to 'train_log/fcn1_w_8_a_32_quant_ends_False/log.log.0323-105737'
[32m[0323 10:57:37 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=8 --bita=32 --quant_ends=False
[32m[0323 10:57:44 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 10:57:44 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 10:57:45 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 10:57:45 @drf_run.py:166][0m Using host: sls-tesla-1
[32m[0323 10:57:45 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 10:57:45 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 10:57:45 @drf_run.py:188][0m Using GPU: 1
[32m[0323 10:57:45 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 10:57:45 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 10:57:45 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 10:57:45 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0323 10:57:45 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0323 10:57:45 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0323 10:57:45 @registry.py:130][0m linear0 output: [None, 256]
[32m[0323 10:57:45 @registry.py:122][0m linear1 input: [None, 256]
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:57:45 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 10:57:45 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:57:45 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 10:57:45 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:57:45 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 10:57:45 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 10:57:45 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:57:45 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:57:45 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 10:57:45 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:57:45 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0323 10:57:45 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 10:57:45 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0323 10:57:46 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0323 10:57:46 @base.py:196][0m Setup callbacks graph ...
[32m[0323 10:57:46 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 10:57:46 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0323 10:57:46 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0323 10:57:46 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:57:46 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:57:46 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:57:46 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:57:46 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:57:46 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:57:46 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:57:47 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:57:47 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:57:47 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:57:47 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:57:47 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:57:47 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:57:47 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:57:47 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0323 10:57:47 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 10:57:47 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0323 10:57:47 @base.py:212][0m Creating the session ...
2018-03-23 10:57:47.769432: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-03-23 10:57:50.110136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:42:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-23 10:57:50.110188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:42:00.0, compute capability: 6.1)
[32m[0323 10:57:55 @base.py:220][0m Initializing the session ...
[32m[0323 10:57:55 @base.py:227][0m Graph Finalized.
[32m[0323 10:57:55 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 10:57:57 @monitor.py:251][0m Found existing JSON at train_log/fcn1_w_8_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 10:57:57 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 10:57:57 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16254/173481[03:00<29:01,90.30it/s] 10%|9         |17195/173481[03:10<28:50,90.30it/s] 19%|#9        |32970/173481[06:00<25:34,91.56it/s] 20%|#9        |33938/173481[06:10<25:24,91.56it/s] 29%|##8       |49933/173481[09:00<22:10,92.88it/s] 29%|##9       |50929/173481[09:10<21:59,92.88it/s] 39%|###8      |66900/173481[12:00<18:59,93.56it/s] 39%|###9      |67907/173481[12:10<18:48,93.56it/s] 48%|####8     |83714/173481[15:00<16:00,93.49it/s] 49%|####8     |84728/173481[15:10<15:49,93.49it/s] 58%|#####7    |100375/173481[18:00<13:05,93.02it/s] 58%|#####8    |101385/173481[18:10<12:55,93.02it/s] 66%|######5   |114366/173481[21:00<11:38,84.67it/s] 66%|######6   |115050/173481[21:11<11:30,84.67it/s] 73%|#######2  |125836/173481[24:00<10:55,72.71it/s] 73%|#######2  |126610/173481[24:11<10:44,72.71it/s] 79%|#######9  |137429/173481[27:00<08:47,68.31it/s] 80%|#######9  |138173/173481[27:11<08:36,68.31it/s] 86%|########5 |148651/173481[30:00<06:20,65.19it/s] 86%|########6 |149326/173481[30:11<06:10,65.19it/s] 92%|#########1|158997/173481[33:00<03:57,61.09it/s] 92%|#########2|159680/173481[33:11<03:45,61.09it/s] 98%|#########8|170157/173481[36:00<00:54,61.54it/s] 99%|#########8|170892/173481[36:11<00:42,61.54it/s]100%|##########|173481/173481[36:53<00:00,78.36it/s]
[32m[0323 11:34:51 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2213.86 sec.
[32m[0323 11:34:51 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.31it/s]
0
[32m[0323 11:36:59 @monitor.py:363][0m QueueInput/queue_size: 0.69638
[32m[0323 11:36:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.796
[32m[0323 11:36:59 @monitor.py:363][0m activation-summaries/output-rms: 0.027912
[32m[0323 11:36:59 @monitor.py:363][0m cross_entropy_loss: 2.6357
[32m[0323 11:36:59 @monitor.py:363][0m lr: 0.001
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13529
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.66544
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.097608
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13175
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11832
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11195
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 11:36:59 @monitor.py:363][0m train-error-top1: 0.65168
[32m[0323 11:36:59 @monitor.py:363][0m val-error-top1: 0.7104
[32m[0323 11:36:59 @monitor.py:363][0m val-utt-error: 0.38301
[32m[0323 11:36:59 @monitor.py:363][0m validation_cost: 2.9595
[32m[0323 11:36:59 @monitor.py:363][0m wd_cost: 0.65118
[32m[0323 11:36:59 @group.py:42][0m Callbacks took 128.084 sec in total. InferenceRunner: 127.784sec
[32m[0323 11:36:59 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14421/173481[03:00<33:05,80.12it/s]  9%|8         |15144/173481[03:10<32:56,80.12it/s] 15%|#5        |26235/173481[06:00<34:00,72.15it/s] 15%|#5        |26856/173481[06:10<33:52,72.15it/s] 21%|##1       |36563/173481[09:00<35:42,63.92it/s] 21%|##1       |37124/173481[09:10<35:33,63.92it/s] 27%|##7       |47425/173481[12:00<33:50,62.08it/s] 28%|##7       |48044/173481[12:10<33:40,62.08it/s] 34%|###3      |58645/173481[15:00<30:46,62.20it/s] 34%|###4      |59340/173481[15:10<30:34,62.20it/s] 40%|####      |69562/173481[18:00<28:12,61.42it/s] 40%|####      |70255/173481[18:11<28:00,61.42it/s] 47%|####6     |80774/173481[21:00<24:58,61.85it/s] 47%|####6     |81444/173481[21:11<24:48,61.85it/s] 53%|#####2    |91943/173481[24:00<21:56,61.95it/s] 53%|#####3    |92634/173481[24:11<21:45,61.95it/s] 59%|#####9    |103059/173481[27:00<18:58,61.85it/s] 60%|#####9    |103791/173481[27:11<18:46,61.85it/s] 66%|######5   |114442/173481[30:00<15:44,62.54it/s] 66%|######6   |115104/173481[30:11<15:33,62.54it/s] 72%|#######2  |125260/173481[33:00<13:06,61.29it/s] 73%|#######2  |125909/173481[33:11<12:56,61.29it/s] 78%|#######8  |135693/173481[36:00<10:34,59.58it/s] 79%|#######8  |136330/173481[36:12<10:23,59.58it/s] 84%|########4 |146103/173481[39:00<07:46,58.69it/s] 85%|########4 |146856/173481[39:12<07:33,58.69it/s] 90%|######### |156890/173481[42:00<04:39,59.30it/s] 91%|######### |157624/173481[42:12<04:27,59.30it/s] 97%|#########6|168123/173481[45:00<01:28,60.81it/s] 97%|#########7|168884/173481[45:12<01:15,60.81it/s]100%|##########|173481/173481[46:27<00:00,62.25it/s]
[32m[0323 12:23:26 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2787.04 sec.
[32m[0323 12:23:26 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-346962.
[32m[0323 12:23:26 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.06it/s]
1
[32m[0323 12:25:11 @monitor.py:363][0m QueueInput/queue_size: 0.53144
[32m[0323 12:25:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9491
[32m[0323 12:25:11 @monitor.py:363][0m activation-summaries/output-rms: 0.029041
[32m[0323 12:25:11 @monitor.py:363][0m cross_entropy_loss: 2.6374
[32m[0323 12:25:11 @monitor.py:363][0m lr: 0.001
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13597
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.88087
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.097556
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13229
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11753
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11105
[32m[0323 12:25:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 12:25:11 @monitor.py:363][0m train-error-top1: 0.63983
[32m[0323 12:25:11 @monitor.py:363][0m val-error-top1: 0.7009
[32m[0323 12:25:11 @monitor.py:363][0m val-utt-error: 0.3701
[32m[0323 12:25:11 @monitor.py:363][0m validation_cost: 2.9296
[32m[0323 12:25:11 @monitor.py:363][0m wd_cost: 0.65031
[32m[0323 12:25:11 @group.py:42][0m Callbacks took 105.308 sec in total. InferenceRunner: 104.543sec
[32m[0323 12:25:11 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14434/173481[03:00<33:03,80.17it/s]  9%|8         |15358/173481[03:10<32:52,80.17it/s] 15%|#5        |26681/173481[06:00<33:14,73.61it/s] 16%|#5        |27263/173481[06:10<33:06,73.61it/s] 21%|##1       |36867/173481[09:00<35:35,63.99it/s] 22%|##1       |37468/173481[09:10<35:25,63.99it/s] 27%|##7       |47184/173481[12:00<34:48,60.46it/s] 28%|##7       |47803/173481[12:10<34:38,60.46it/s] 33%|###3      |57627/173481[15:00<32:36,59.21it/s] 34%|###3      |58228/173481[15:10<32:26,59.21it/s] 40%|###9      |68596/173481[18:00<29:06,60.06it/s] 40%|###9      |69334/173481[18:10<28:53,60.06it/s] 46%|####6     |80129/173481[21:00<25:05,62.00it/s] 47%|####6     |80873/173481[21:11<24:53,62.00it/s] 53%|#####2    |91755/173481[24:00<21:31,63.27it/s] 53%|#####3    |92429/173481[24:11<21:21,63.27it/s] 60%|#####9    |103238/173481[27:00<18:25,63.53it/s] 60%|#####9    |103912/173481[27:11<18:15,63.53it/s] 66%|######6   |114578/173481[30:00<15:31,63.26it/s] 66%|######6   |115328/173481[30:11<15:19,63.26it/s] 73%|#######2  |125911/173481[33:00<12:33,63.11it/s] 73%|#######3  |126667/173481[33:11<12:21,63.11it/s] 79%|#######9  |137809/173481[36:00<09:12,64.56it/s] 80%|#######9  |138576/173481[36:11<09:00,64.56it/s] 86%|########6 |149634/173481[39:00<06:06,65.12it/s] 87%|########6 |150427/173481[39:12<05:54,65.12it/s] 93%|#########3|161724/173481[42:00<02:57,66.12it/s] 94%|#########3|162500/173481[42:12<02:46,66.12it/s]100%|##########|173481/173481[44:58<00:00,64.29it/s]
[32m[0323 13:10:10 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2698.60 sec.
[32m[0323 13:10:10 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-520443.
[32m[0323 13:10:11 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,188.71it/s]
2
[32m[0323 13:11:50 @monitor.py:363][0m QueueInput/queue_size: 0.35161
[32m[0323 13:11:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.812
[32m[0323 13:11:50 @monitor.py:363][0m activation-summaries/output-rms: 0.03498
[32m[0323 13:11:50 @monitor.py:363][0m cross_entropy_loss: 2.082
[32m[0323 13:11:50 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.18593
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.98075
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.14187
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.17806
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.16507
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.15871
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086387
[32m[0323 13:11:50 @monitor.py:363][0m train-error-top1: 0.53582
[32m[0323 13:11:50 @monitor.py:363][0m val-error-top1: 0.57771
[32m[0323 13:11:50 @monitor.py:363][0m val-utt-error: 0.20896
[32m[0323 13:11:50 @monitor.py:363][0m validation_cost: 2.2727
[32m[0323 13:11:50 @monitor.py:363][0m wd_cost: 0.25844
[32m[0323 13:11:50 @group.py:42][0m Callbacks took 100.804 sec in total. InferenceRunner: 99.754sec
[32m[0323 13:11:50 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12244/173481[03:00<39:30,68.02it/s]  7%|7         |12906/173481[03:10<39:20,68.02it/s] 14%|#3        |23548/173481[06:00<38:15,65.30it/s] 14%|#3        |24161/173481[06:10<38:06,65.30it/s] 20%|##        |35223/173481[09:00<35:24,65.08it/s] 21%|##        |35913/173481[09:10<35:13,65.08it/s] 27%|##7       |47212/173481[12:00<31:58,65.83it/s] 28%|##7       |47941/173481[12:10<31:46,65.83it/s] 34%|###4      |59163/173481[15:00<28:49,66.10it/s] 35%|###4      |59875/173481[15:10<28:38,66.10it/s] 41%|####1     |71359/173481[18:00<25:26,66.92it/s] 42%|####1     |72052/173481[18:10<25:15,66.92it/s] 48%|####8     |83313/173481[21:00<22:32,66.66it/s] 48%|####8     |84027/173481[21:11<22:21,66.66it/s] 55%|#####4    |95175/173481[24:00<19:41,66.28it/s] 55%|#####5    |95920/173481[24:11<19:30,66.28it/s] 62%|######1   |107265/173481[27:00<16:32,66.72it/s] 62%|######2   |108027/173481[27:11<16:21,66.72it/s] 69%|######8   |119117/173481[30:00<13:40,66.28it/s] 69%|######9   |119847/173481[30:11<13:29,66.28it/s] 76%|#######5  |131019/173481[33:00<10:41,66.20it/s] 76%|#######5  |131799/173481[33:11<10:29,66.20it/s] 83%|########2 |143195/173481[36:00<07:32,66.91it/s] 83%|########2 |143879/173481[36:11<07:22,66.91it/s] 89%|########9 |154748/173481[39:00<04:45,65.51it/s] 90%|########9 |155447/173481[39:12<04:35,65.51it/s] 96%|#########5|166207/173481[42:00<01:52,64.57it/s] 96%|#########6|166912/173481[42:12<01:41,64.57it/s]100%|##########|173481/173481[44:02<00:00,65.65it/s]
[32m[0323 13:55:53 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2642.40 sec.
[32m[0323 13:55:53 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-693924.
[32m[0323 13:55:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,194.85it/s]
3
[32m[0323 13:57:30 @monitor.py:363][0m QueueInput/queue_size: 0.58023
[32m[0323 13:57:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.4121
[32m[0323 13:57:30 @monitor.py:363][0m activation-summaries/output-rms: 0.036247
[32m[0323 13:57:30 @monitor.py:363][0m cross_entropy_loss: 2.0098
[32m[0323 13:57:30 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21685
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0496
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.14952
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20159
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19215
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18174
[32m[0323 13:57:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 13:57:30 @monitor.py:363][0m train-error-top1: 0.51976
[32m[0323 13:57:30 @monitor.py:363][0m val-error-top1: 0.55325
[32m[0323 13:57:30 @monitor.py:363][0m val-utt-error: 0.18744
[32m[0323 13:57:30 @monitor.py:363][0m validation_cost: 2.1515
[32m[0323 13:57:30 @monitor.py:363][0m wd_cost: 0.32081
[32m[0323 13:57:30 @group.py:42][0m Callbacks took 97.370 sec in total. InferenceRunner: 96.611sec
[32m[0323 13:57:30 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11778/173481[03:00<41:11,65.43it/s]  7%|7         |12441/173481[03:10<41:01,65.43it/s] 13%|#3        |22949/173481[06:00<39:23,63.70it/s] 14%|#3        |23571/173481[06:10<39:13,63.70it/s] 20%|##        |34882/173481[09:00<35:33,64.97it/s] 21%|##        |35566/173481[09:10<35:22,64.97it/s] 27%|##6       |46667/173481[12:00<32:24,65.21it/s] 27%|##7       |47316/173481[12:10<32:14,65.21it/s] 34%|###3      |58442/173481[15:00<29:21,65.31it/s] 34%|###4      |59141/173481[15:10<29:10,65.31it/s] 40%|####      |69937/173481[18:00<26:43,64.58it/s] 41%|####      |70557/173481[18:11<26:33,64.58it/s] 47%|####6     |81388/173481[21:00<23:56,64.09it/s] 47%|####7     |82129/173481[21:11<23:45,64.09it/s] 54%|#####3    |92987/173481[24:00<20:52,64.26it/s] 54%|#####4    |93702/173481[24:11<20:41,64.26it/s] 60%|######    |104567/173481[27:00<17:51,64.29it/s] 61%|######    |105286/173481[27:11<17:40,64.29it/s] 67%|######6   |116122/173481[30:00<14:52,64.24it/s] 67%|######7   |116863/173481[30:11<14:41,64.24it/s] 74%|#######3  |127674/173481[33:00<11:53,64.21it/s] 74%|#######4  |128433/173481[33:11<11:41,64.21it/s] 80%|########  |139272/173481[36:00<08:51,64.32it/s] 81%|########  |140036/173481[36:11<08:40,64.32it/s] 87%|########7 |151152/173481[39:00<05:42,65.15it/s] 88%|########7 |151934/173481[39:12<05:30,65.15it/s] 94%|#########3|162653/173481[42:00<02:47,64.51it/s] 94%|#########4|163398/173481[42:12<02:36,64.51it/s]100%|##########|173481/173481[45:00<00:00,64.25it/s]
[32m[0323 14:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2700.09 sec.
[32m[0323 14:42:30 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-867405.
[32m[0323 14:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,192.87it/s]
4
[32m[0323 14:44:08 @monitor.py:363][0m QueueInput/queue_size: 0.51568
[32m[0323 14:44:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.3681
[32m[0323 14:44:08 @monitor.py:363][0m activation-summaries/output-rms: 0.037355
[32m[0323 14:44:08 @monitor.py:363][0m cross_entropy_loss: 1.9475
[32m[0323 14:44:08 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.22047
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1035
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.15081
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20373
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19529
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18433
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 14:44:08 @monitor.py:363][0m train-error-top1: 0.50598
[32m[0323 14:44:08 @monitor.py:363][0m val-error-top1: 0.54648
[32m[0323 14:44:08 @monitor.py:363][0m val-utt-error: 0.1817
[32m[0323 14:44:08 @monitor.py:363][0m validation_cost: 2.1259
[32m[0323 14:44:08 @monitor.py:363][0m wd_cost: 0.32883
[32m[0323 14:44:08 @group.py:42][0m Callbacks took 98.131 sec in total. InferenceRunner: 97.608sec
[32m[0323 14:44:08 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12750/173481[03:00<37:49,70.83it/s]  8%|7         |13417/173481[03:10<37:39,70.83it/s] 14%|#4        |24541/173481[06:00<36:28,68.06it/s] 15%|#4        |25207/173481[06:10<36:18,68.06it/s] 21%|##        |35582/173481[09:00<35:37,64.53it/s] 21%|##        |36216/173481[09:10<35:27,64.53it/s] 29%|##8       |49609/173481[12:00<29:14,70.59it/s] 29%|##9       |50467/173481[12:10<29:02,70.59it/s] 37%|###7      |64592/173481[15:00<23:45,76.40it/s] 38%|###7      |65494/173481[15:10<23:33,76.40it/s] 46%|####5     |79166/173481[18:00<19:59,78.61it/s] 46%|####6     |80031/173481[18:11<19:48,78.61it/s] 53%|#####3    |92071/173481[21:00<18:05,74.99it/s] 53%|#####3    |92754/173481[21:11<17:56,74.99it/s] 59%|#####9    |103045/173481[24:00<17:27,67.26it/s] 60%|#####9    |103696/173481[24:11<17:17,67.26it/s] 66%|######5   |113832/173481[27:00<15:41,63.38it/s] 66%|######6   |114530/173481[27:11<15:30,63.38it/s] 72%|#######1  |124592/173481[30:00<13:14,61.52it/s] 72%|#######2  |125314/173481[30:11<13:02,61.52it/s] 78%|#######8  |135646/173481[33:00<10:15,61.47it/s] 79%|#######8  |136360/173481[33:11<10:03,61.47it/s] 85%|########4 |146603/173481[36:00<07:19,61.17it/s] 85%|########4 |147317/173481[36:12<07:07,61.17it/s] 91%|######### |157196/173481[39:00<04:31,59.98it/s] 91%|#########1|157935/173481[39:12<04:19,59.98it/s] 97%|#########6|168169/173481[42:00<01:27,60.47it/s] 97%|#########7|168919/173481[42:12<01:15,60.47it/s]100%|##########|173481/173481[43:28<00:00,66.52it/s]
[32m[0323 15:27:36 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:2608.12 sec.
[32m[0323 15:27:37 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-1040886.
[32m[0323 15:27:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,189.43it/s]
5
[32m[0323 15:29:17 @monitor.py:363][0m QueueInput/queue_size: 0.64979
[32m[0323 15:29:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.609
[32m[0323 15:29:17 @monitor.py:363][0m activation-summaries/output-rms: 0.039282
[32m[0323 15:29:17 @monitor.py:363][0m cross_entropy_loss: 1.7562
[32m[0323 15:29:17 @monitor.py:363][0m lr: 0.00025
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26203
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1349
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.18997
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.22709
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21936
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20872
[32m[0323 15:29:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086387
[32m[0323 15:29:17 @monitor.py:363][0m train-error-top1: 0.46608
[32m[0323 15:29:17 @monitor.py:363][0m val-error-top1: 0.48474
[32m[0323 15:29:17 @monitor.py:363][0m val-utt-error: 0.13314
[32m[0323 15:29:17 @monitor.py:363][0m validation_cost: 1.8434
[32m[0323 15:29:17 @monitor.py:363][0m wd_cost: 0.092429
[32m[0323 15:29:17 @group.py:42][0m Callbacks took 100.591 sec in total. InferenceRunner: 99.375sec
[32m[0323 15:29:17 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11261/173481[03:00<43:13,62.56it/s]  7%|6         |11889/173481[03:10<43:03,62.56it/s] 13%|#2        |22291/173481[06:00<40:42,61.91it/s] 13%|#3        |22924/173481[06:10<40:31,61.91it/s] 19%|#9        |32962/173481[09:00<38:40,60.57it/s] 19%|#9        |33549/173481[09:10<38:30,60.57it/s] 25%|##4       |42835/173481[12:00<37:49,57.56it/s] 25%|##5       |43429/173481[12:10<37:39,57.56it/s] 31%|###       |53500/173481[15:00<34:14,58.39it/s] 31%|###1      |54190/173481[15:10<34:02,58.39it/s] 37%|###7      |64540/173481[18:00<30:21,59.82it/s] 38%|###7      |65198/173481[18:11<30:10,59.82it/s] 44%|####3     |75762/173481[21:00<26:40,61.05it/s] 44%|####4     |76438/173481[21:11<26:29,61.05it/s] 50%|#####     |86900/173481[24:00<23:28,61.46it/s] 50%|#####     |87604/173481[24:11<23:17,61.46it/s] 57%|#####6    |98232/173481[27:00<20:09,62.20it/s] 57%|#####7    |98929/173481[27:11<19:58,62.20it/s] 63%|######3   |109358/173481[30:00<17:14,62.00it/s] 63%|######3   |110067/173481[30:11<17:02,62.00it/s] 69%|######9   |120270/173481[33:00<14:28,61.30it/s] 70%|######9   |120981/173481[33:11<14:16,61.30it/s] 76%|#######5  |131145/173481[36:00<11:35,60.85it/s] 76%|#######6  |131954/173481[36:11<11:22,60.85it/s] 82%|########2 |142650/173481[39:00<08:14,62.34it/s] 83%|########2 |143551/173481[39:12<08:00,62.34it/s] 89%|########9 |155223/173481[42:00<04:37,65.88it/s] 90%|########9 |155964/173481[42:12<04:25,65.88it/s] 99%|#########8|170913/173481[45:00<00:34,75.04it/s] 99%|#########9|172101/173481[45:12<00:18,75.04it/s]100%|##########|173481/173481[45:26<00:00,63.63it/s]
[32m[0323 16:14:43 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:2726.35 sec.
[32m[0323 16:14:44 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-1214367.
[32m[0323 16:14:44 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,196.04it/s]
6
[32m[0323 16:16:20 @monitor.py:363][0m QueueInput/queue_size: 36.395
[32m[0323 16:16:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 17.394
[32m[0323 16:16:20 @monitor.py:363][0m activation-summaries/output-rms: 0.039911
[32m[0323 16:16:20 @monitor.py:363][0m cross_entropy_loss: 1.7419
[32m[0323 16:16:20 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31756
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1514
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.21578
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.25839
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25259
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.24241
[32m[0323 16:16:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086387
[32m[0323 16:16:20 @monitor.py:363][0m train-error-top1: 0.45973
[32m[0323 16:16:20 @monitor.py:363][0m val-error-top1: 0.47294
[32m[0323 16:16:20 @monitor.py:363][0m val-utt-error: 0.12156
[32m[0323 16:16:20 @monitor.py:363][0m validation_cost: 1.7877
[32m[0323 16:16:20 @monitor.py:363][0m wd_cost: 0.12364
[32m[0323 16:16:20 @group.py:42][0m Callbacks took 97.029 sec in total. InferenceRunner: 96.023sec
[32m[0323 16:16:20 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17344/173481[03:00<27:00,96.35it/s] 10%|#         |17903/173481[03:10<26:54,96.35it/s] 16%|#6        |27808/173481[06:00<33:28,72.51it/s] 16%|#6        |28363/173481[06:10<33:21,72.51it/s] 22%|##2       |38177/173481[09:00<35:07,64.21it/s] 22%|##2       |38793/173481[09:10<34:57,64.21it/s] 28%|##8       |48785/173481[12:00<33:49,61.46it/s] 28%|##8       |49410/173481[12:10<33:38,61.46it/s] 34%|###4      |59251/173481[15:00<31:51,59.75it/s] 35%|###4      |59893/173481[15:10<31:40,59.75it/s] 41%|####      |70374/173481[18:00<28:17,60.75it/s] 41%|####      |71088/173481[18:11<28:05,60.75it/s] 47%|####7     |81785/173481[21:00<24:37,62.05it/s] 48%|####7     |82468/173481[21:11<24:26,62.05it/s] 54%|#####3    |92966/173481[24:00<21:36,62.08it/s] 54%|#####4    |93682/173481[24:11<21:25,62.08it/s] 60%|######    |104362/173481[27:00<18:22,62.69it/s] 61%|######    |105085/173481[27:11<18:11,62.69it/s] 67%|######6   |115986/173481[30:00<15:03,63.62it/s] 67%|######7   |116708/173481[30:11<14:52,63.62it/s] 73%|#######3  |127244/173481[33:00<12:13,63.07it/s] 74%|#######3  |128023/173481[33:11<12:00,63.07it/s] 80%|#######9  |138703/173481[36:00<09:08,63.36it/s] 80%|########  |139519/173481[36:12<08:55,63.36it/s] 87%|########6 |150719/173481[39:00<05:50,65.01it/s] 87%|########7 |151479/173481[39:12<05:38,65.01it/s] 93%|#########3|162093/173481[42:00<02:57,64.08it/s] 94%|#########3|162803/173481[42:12<02:46,64.08it/s]100%|##########|173481/173481[44:57<00:00,64.31it/s]
[32m[0323 17:01:18 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:2697.40 sec.
[32m[0323 17:01:18 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-1387848.
[32m[0323 17:01:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.52it/s]
7
[32m[0323 17:02:56 @monitor.py:363][0m QueueInput/queue_size: 0.58361
[32m[0323 17:02:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.961
[32m[0323 17:02:56 @monitor.py:363][0m activation-summaries/output-rms: 0.040234
[32m[0323 17:02:56 @monitor.py:363][0m cross_entropy_loss: 1.6937
[32m[0323 17:02:56 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.35172
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1673
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.22149
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26998
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26575
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25533
[32m[0323 17:02:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 17:02:56 @monitor.py:363][0m train-error-top1: 0.44918
[32m[0323 17:02:56 @monitor.py:363][0m val-error-top1: 0.46926
[32m[0323 17:02:56 @monitor.py:363][0m val-utt-error: 0.12023
[32m[0323 17:02:56 @monitor.py:363][0m validation_cost: 1.7705
[32m[0323 17:02:56 @monitor.py:363][0m wd_cost: 0.13725
[32m[0323 17:02:56 @group.py:42][0m Callbacks took 97.912 sec in total. InferenceRunner: 97.274sec
[32m[0323 17:02:56 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11923/173481[03:00<40:39,66.23it/s]  7%|7         |12543/173481[03:10<40:30,66.23it/s] 13%|#3        |22763/173481[06:00<39:49,63.08it/s] 13%|#3        |23417/173481[06:10<39:39,63.08it/s] 20%|#9        |34098/173481[09:00<36:51,63.02it/s] 20%|##        |34796/173481[09:10<36:40,63.02it/s] 26%|##6       |45798/173481[12:00<33:15,63.99it/s] 27%|##6       |46487/173481[12:10<33:04,63.99it/s] 33%|###2      |57132/173481[15:00<30:33,63.47it/s] 33%|###3      |57799/173481[15:10<30:22,63.47it/s] 40%|###9      |68813/173481[18:00<27:11,64.17it/s] 40%|####      |69537/173481[18:11<26:59,64.17it/s] 46%|####6     |80399/173481[21:00<24:08,64.27it/s] 47%|####6     |81102/173481[21:11<23:57,64.27it/s] 53%|#####2    |91523/173481[24:00<21:40,63.00it/s] 53%|#####3    |92180/173481[24:11<21:30,63.00it/s] 59%|#####9    |102963/173481[27:00<18:34,63.28it/s] 60%|#####9    |103668/173481[27:11<18:23,63.28it/s] 66%|######5   |114474/173481[30:00<15:27,63.61it/s] 66%|######6   |115207/173481[30:11<15:16,63.61it/s] 73%|#######2  |125843/173481[33:00<12:31,63.38it/s] 73%|#######2  |126601/173481[33:11<12:19,63.38it/s] 79%|#######9  |137126/173481[36:00<09:36,63.03it/s] 79%|#######9  |137861/173481[36:12<09:25,63.03it/s] 86%|########5 |148623/173481[39:00<06:31,63.44it/s] 86%|########6 |149392/173481[39:12<06:19,63.44it/s] 93%|#########2|160558/173481[42:00<03:19,64.83it/s] 93%|#########3|161389/173481[42:12<03:06,64.83it/s] 98%|#########8|170818/173481[45:00<00:43,60.66it/s] 99%|#########8|171497/173481[45:12<00:32,60.66it/s]100%|##########|173481/173481[45:46<00:00,63.16it/s]
[32m[0323 17:48:42 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:2746.72 sec.
[32m[0323 17:48:43 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-1561329.
[32m[0323 17:48:44 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.52it/s]
8
[32m[0323 17:50:21 @monitor.py:363][0m QueueInput/queue_size: 0.52744
[32m[0323 17:50:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 24.835
[32m[0323 17:50:21 @monitor.py:363][0m activation-summaries/output-rms: 0.040736
[32m[0323 17:50:21 @monitor.py:363][0m cross_entropy_loss: 1.5737
[32m[0323 17:50:21 @monitor.py:363][0m lr: 0.000125
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.39015
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1765
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/linear0/W-rms: 0.24516
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.28072
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27556
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26483
[32m[0323 17:50:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 17:50:21 @monitor.py:363][0m train-error-top1: 0.41725
[32m[0323 17:50:21 @monitor.py:363][0m val-error-top1: 0.44155
[32m[0323 17:50:21 @monitor.py:363][0m val-utt-error: 0.10546
[32m[0323 17:50:21 @monitor.py:363][0m validation_cost: 1.6545
[32m[0323 17:50:21 @monitor.py:363][0m wd_cost: 0.032047
[32m[0323 17:50:21 @group.py:42][0m Callbacks took 98.532 sec in total. InferenceRunner: 97.275sec
[32m[0323 17:50:21 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12167/173481[03:00<39:46,67.58it/s]  7%|7         |12806/173481[03:10<39:37,67.58it/s] 13%|#3        |22947/173481[06:00<39:30,63.50it/s] 14%|#3        |23541/173481[06:10<39:21,63.50it/s] 20%|#9        |34399/173481[09:00<36:28,63.56it/s] 20%|##        |35046/173481[09:10<36:18,63.56it/s] 26%|##6       |45707/173481[12:00<33:42,63.18it/s] 27%|##6       |46343/173481[12:10<33:32,63.18it/s] 33%|###2      |57071/173481[15:00<30:43,63.15it/s] 33%|###3      |57762/173481[15:10<30:32,63.15it/s] 39%|###9      |67982/173481[18:00<28:25,61.86it/s] 40%|###9      |68649/173481[18:11<28:14,61.86it/s] 46%|####5     |79107/173481[21:00<25:26,61.83it/s] 46%|####6     |79804/173481[21:11<25:15,61.83it/s] 52%|#####2    |90417/173481[24:00<22:12,62.32it/s] 53%|#####2    |91115/173481[24:11<22:01,62.32it/s] 58%|#####8    |101281/173481[27:00<19:37,61.32it/s] 59%|#####8    |101940/173481[27:11<19:26,61.32it/s] 64%|######4   |111892/173481[30:00<17:04,60.11it/s] 65%|######4   |112591/173481[30:11<16:53,60.11it/s] 71%|#######1  |123950/173481[33:00<13:01,63.36it/s] 72%|#######1  |124801/173481[33:11<12:48,63.36it/s] 79%|#######8  |136884/173481[36:00<09:03,67.34it/s] 79%|#######9  |137811/173481[36:11<08:49,67.34it/s] 87%|########7 |151073/173481[39:00<05:08,72.63it/s] 88%|########7 |151993/173481[39:12<04:55,72.63it/s] 95%|#########5|165156/173481[42:00<01:50,75.33it/s] 96%|#########5|166116/173481[42:12<01:37,75.33it/s]100%|##########|173481/173481[43:56<00:00,65.79it/s]
[32m[0323 18:34:18 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:2636.72 sec.
[32m[0323 18:34:18 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-1734810.
[32m[0323 18:34:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,196.76it/s]
9
[32m[0323 18:35:54 @monitor.py:363][0m QueueInput/queue_size: 0.41542
[32m[0323 18:35:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.277
[32m[0323 18:35:54 @monitor.py:363][0m activation-summaries/output-rms: 0.041924
[32m[0323 18:35:54 @monitor.py:363][0m cross_entropy_loss: 1.5488
[32m[0323 18:35:54 @monitor.py:363][0m lr: 0.000125
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.42977
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1824
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2693
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29391
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2886
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27781
[32m[0323 18:35:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 18:35:54 @monitor.py:363][0m train-error-top1: 0.413
[32m[0323 18:35:54 @monitor.py:363][0m val-error-top1: 0.43856
[32m[0323 18:35:54 @monitor.py:363][0m val-utt-error: 0.10424
[32m[0323 18:35:54 @monitor.py:363][0m validation_cost: 1.6444
[32m[0323 18:35:54 @monitor.py:363][0m wd_cost: 0.03744
[32m[0323 18:35:54 @group.py:42][0m Callbacks took 96.618 sec in total. InferenceRunner: 95.677sec
[32m[0323 18:35:54 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11845/173481[03:00<40:56,65.80it/s]  7%|7         |12629/173481[03:10<40:44,65.80it/s] 14%|#4        |24423/173481[06:00<36:39,67.78it/s] 14%|#4        |25001/173481[06:10<36:30,67.78it/s] 20%|#9        |34106/173481[09:00<38:43,59.98it/s] 20%|#9        |34611/173481[09:10<38:35,59.98it/s] 25%|##4       |42636/173481[12:00<41:11,52.94it/s] 25%|##4       |43150/173481[12:10<41:01,52.94it/s] 30%|##9       |51251/173481[15:00<40:31,50.27it/s] 30%|##9       |51735/173481[15:10<40:21,50.27it/s] 35%|###4      |60201/173481[18:00<37:46,49.98it/s] 35%|###5      |60842/173481[18:11<37:33,49.98it/s] 40%|####      |70026/173481[21:00<33:02,52.17it/s] 41%|####      |70520/173481[21:11<32:53,52.17it/s] 46%|####5     |79081/173481[24:00<30:43,51.22it/s] 46%|####5     |79625/173481[24:11<30:32,51.22it/s] 51%|#####     |88288/173481[27:00<27:44,51.18it/s] 51%|#####1    |88870/173481[27:11<27:33,51.18it/s] 56%|#####6    |97606/173481[30:00<24:34,51.47it/s] 57%|#####6    |98192/173481[30:11<24:22,51.47it/s] 61%|######1   |106606/173481[33:00<21:58,50.72it/s] 62%|######1   |107185/173481[33:11<21:47,50.72it/s] 68%|######7   |117931/173481[36:00<16:29,56.16it/s] 68%|######8   |118620/173481[36:12<16:16,56.16it/s] 74%|#######4  |128656/173481[39:00<12:55,57.81it/s] 75%|#######4  |129400/173481[39:12<12:42,57.81it/s] 80%|########  |138943/173481[42:00<10:00,57.48it/s] 80%|########  |139625/173481[42:12<09:49,57.48it/s] 86%|########5 |148716/173481[45:00<07:23,55.84it/s] 86%|########6 |149370/173481[45:12<07:11,55.84it/s] 91%|#########1|158536/173481[48:00<04:30,55.18it/s] 92%|#########1|159220/173481[48:12<04:18,55.18it/s] 97%|#########6|167726/173481[51:00<01:48,53.03it/s] 97%|#########7|168340/173481[51:12<01:36,53.03it/s]100%|##########|173481/173481[52:55<00:00,54.63it/s]
[32m[0323 19:28:50 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3175.71 sec.
[32m[0323 19:28:50 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-1908291.
[32m[0323 19:28:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,192.20it/s]
10
[32m[0323 19:30:29 @monitor.py:363][0m QueueInput/queue_size: 0.65111
[32m[0323 19:30:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.349
[32m[0323 19:30:29 @monitor.py:363][0m activation-summaries/output-rms: 0.041453
[32m[0323 19:30:29 @monitor.py:363][0m cross_entropy_loss: 1.539
[32m[0323 19:30:29 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46509
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1879
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28423
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30286
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29829
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28776
[32m[0323 19:30:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 19:30:29 @monitor.py:363][0m train-error-top1: 0.41385
[32m[0323 19:30:29 @monitor.py:363][0m val-error-top1: 0.42642
[32m[0323 19:30:29 @monitor.py:363][0m val-utt-error: 0.096005
[32m[0323 19:30:29 @monitor.py:363][0m validation_cost: 1.5902
[32m[0323 19:30:29 @monitor.py:363][0m wd_cost: 0.041656
[32m[0323 19:30:29 @group.py:42][0m Callbacks took 98.762 sec in total. InferenceRunner: 97.943sec
[32m[0323 19:30:29 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10951/173481[03:00<44:31,60.84it/s]  7%|6         |11519/173481[03:10<44:22,60.84it/s] 12%|#1        |20167/173481[06:00<45:57,55.60it/s] 12%|#1        |20719/173481[06:10<45:47,55.60it/s] 17%|#7        |29571/173481[09:00<44:31,53.87it/s] 17%|#7        |30129/173481[09:10<44:21,53.87it/s] 22%|##2       |38384/173481[12:00<43:53,51.30it/s] 22%|##2       |38899/173481[12:10<43:43,51.30it/s] 27%|##7       |47005/173481[15:00<42:33,49.53it/s] 27%|##7       |47509/173481[15:10<42:23,49.53it/s] 32%|###2      |55710/173481[18:00<40:06,48.94it/s] 32%|###2      |56254/173481[18:11<39:55,48.94it/s] 37%|###7      |64800/173481[21:00<36:27,49.69it/s] 38%|###7      |65369/173481[21:11<36:15,49.69it/s] 43%|####2     |74150/173481[24:00<32:35,50.79it/s] 43%|####3     |74750/173481[24:11<32:23,50.79it/s] 48%|####8     |83686/173481[27:00<28:51,51.86it/s] 49%|####8     |84296/173481[27:11<28:39,51.86it/s] 54%|#####3    |93089/173481[30:00<25:44,52.05it/s] 54%|#####4    |93706/173481[30:11<25:32,52.05it/s] 59%|#####9    |102735/173481[33:00<22:20,52.79it/s] 60%|#####9    |103364/173481[33:11<22:08,52.79it/s] 65%|######4   |112270/173481[36:00<19:17,52.88it/s] 65%|######5   |112892/173481[36:12<19:05,52.88it/s] 70%|#######   |121660/173481[39:00<16:26,52.52it/s] 71%|#######   |122309/173481[39:12<16:14,52.52it/s] 76%|#######5  |131120/173481[42:00<13:26,52.53it/s] 76%|#######5  |131754/173481[42:12<13:14,52.53it/s] 82%|########1 |141625/173481[45:00<09:36,55.29it/s] 82%|########2 |142389/173481[45:12<09:22,55.29it/s] 88%|########8 |152900/173481[48:00<05:50,58.72it/s] 89%|########8 |153679/173481[48:12<05:37,58.72it/s] 94%|#########4|163180/173481[51:00<02:57,57.90it/s] 95%|#########4|164061/173481[51:12<02:42,57.90it/s]100%|##########|173481/173481[53:01<00:00,54.53it/s]
[32m[0323 20:23:30 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3181.26 sec.
[32m[0323 20:23:30 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-2081772.
[32m[0323 20:23:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.26it/s]
11
[32m[0323 20:25:08 @monitor.py:363][0m QueueInput/queue_size: 1.1368
[32m[0323 20:25:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 34.485
[32m[0323 20:25:08 @monitor.py:363][0m activation-summaries/output-rms: 0.042063
[32m[0323 20:25:08 @monitor.py:363][0m cross_entropy_loss: 1.5522
[32m[0323 20:25:08 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.48893
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1911
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29658
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.308
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30251
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29181
[32m[0323 20:25:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 20:25:08 @monitor.py:363][0m train-error-top1: 0.41607
[32m[0323 20:25:08 @monitor.py:363][0m val-error-top1: 0.42289
[32m[0323 20:25:08 @monitor.py:363][0m val-utt-error: 0.093614
[32m[0323 20:25:08 @monitor.py:363][0m validation_cost: 1.5741
[32m[0323 20:25:08 @monitor.py:363][0m wd_cost: 0.0089468
[32m[0323 20:25:08 @group.py:42][0m Callbacks took 98.099 sec in total. InferenceRunner: 97.405sec
[32m[0323 20:25:08 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12659/173481[03:00<38:07,70.30it/s]  8%|7         |13343/173481[03:10<37:57,70.30it/s] 14%|#3        |23739/173481[06:00<38:01,65.63it/s] 14%|#3        |24238/173481[06:10<37:53,65.63it/s] 19%|#8        |32584/173481[09:00<41:47,56.19it/s] 19%|#9        |33083/173481[09:10<41:38,56.19it/s] 24%|##4       |41734/173481[12:00<41:08,53.37it/s] 24%|##4       |42269/173481[12:10<40:58,53.37it/s] 29%|##9       |50934/173481[15:00<39:07,52.21it/s] 30%|##9       |51494/173481[15:10<38:56,52.21it/s] 35%|###4      |60544/173481[18:00<35:39,52.79it/s] 35%|###5      |61141/173481[18:11<35:28,52.79it/s] 41%|####      |70931/173481[21:00<30:59,55.14it/s] 41%|####1     |71623/173481[21:11<30:47,55.14it/s] 47%|####7     |81569/173481[24:00<26:51,57.04it/s] 47%|####7     |82191/173481[24:11<26:40,57.04it/s] 53%|#####2    |91582/173481[27:00<24:13,56.33it/s] 53%|#####3    |92107/173481[27:11<24:04,56.33it/s] 58%|#####8    |101452/173481[30:00<21:36,55.57it/s] 59%|#####8    |102004/173481[30:11<21:26,55.57it/s] 64%|######4   |111392/173481[33:00<18:40,55.39it/s] 65%|######4   |112048/173481[33:11<18:29,55.39it/s] 70%|#######   |121636/173481[36:00<15:23,56.14it/s] 70%|#######   |122295/173481[36:11<15:11,56.14it/s] 76%|#######6  |131959/173481[39:00<12:11,56.74it/s] 77%|#######6  |132728/173481[39:12<11:58,56.74it/s] 83%|########2 |143215/173481[42:00<08:28,59.49it/s] 83%|########2 |143930/173481[42:12<08:16,59.49it/s] 89%|########8 |154283/173481[45:00<05:17,60.47it/s] 89%|########9 |155028/173481[45:12<05:05,60.47it/s] 95%|#########4|164714/173481[48:00<02:28,59.14it/s] 95%|#########5|165417/173481[48:12<02:16,59.14it/s]100%|##########|173481/173481[50:27<00:00,57.31it/s]
[32m[0323 21:15:35 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3027.32 sec.
[32m[0323 21:15:36 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-2255253.
[32m[0323 21:15:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.28it/s]
12
[32m[0323 21:17:13 @monitor.py:363][0m QueueInput/queue_size: 0.45179
[32m[0323 21:17:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.583
[32m[0323 21:17:13 @monitor.py:363][0m activation-summaries/output-rms: 0.042326
[32m[0323 21:17:13 @monitor.py:363][0m cross_entropy_loss: 1.5447
[32m[0323 21:17:13 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.51228
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1946
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.30744
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31307
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30687
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29599
[32m[0323 21:17:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 21:17:13 @monitor.py:363][0m train-error-top1: 0.42395
[32m[0323 21:17:13 @monitor.py:363][0m val-error-top1: 0.42224
[32m[0323 21:17:13 @monitor.py:363][0m val-utt-error: 0.093986
[32m[0323 21:17:13 @monitor.py:363][0m validation_cost: 1.5704
[32m[0323 21:17:13 @monitor.py:363][0m wd_cost: 0.0095465
[32m[0323 21:17:13 @group.py:42][0m Callbacks took 97.742 sec in total. InferenceRunner: 97.392sec
[32m[0323 21:17:13 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11780/173481[03:00<41:10,65.44it/s]  7%|7         |12402/173481[03:10<41:01,65.44it/s] 12%|#2        |21089/173481[06:00<43:57,57.77it/s] 13%|#2        |21697/173481[06:10<43:47,57.77it/s] 18%|#8        |31772/173481[09:00<40:20,58.55it/s] 19%|#8        |32444/173481[09:10<40:08,58.55it/s] 25%|##4       |42883/173481[12:00<36:13,60.09it/s] 25%|##5       |43587/173481[12:10<36:01,60.09it/s] 31%|###1      |53898/173481[15:00<32:52,60.64it/s] 31%|###1      |54497/173481[15:10<32:42,60.64it/s] 38%|###7      |65301/173481[18:00<29:05,61.96it/s] 38%|###8      |66032/173481[18:10<28:54,61.96it/s] 45%|####4     |77257/173481[21:00<25:00,64.11it/s] 45%|####4     |77962/173481[21:11<24:49,64.11it/s] 51%|#####1    |89296/173481[24:00<21:25,65.47it/s] 52%|#####1    |90108/173481[24:11<21:13,65.47it/s] 58%|#####8    |101329/173481[27:00<18:10,66.15it/s] 59%|#####8    |102065/173481[27:11<17:59,66.15it/s] 65%|######5   |112839/173481[30:00<15:32,65.03it/s] 65%|######5   |113599/173481[30:11<15:20,65.03it/s] 72%|#######1  |124464/173481[33:00<12:36,64.80it/s] 72%|#######2  |125204/173481[33:11<12:24,64.80it/s] 78%|#######8  |136100/173481[36:00<09:37,64.72it/s] 79%|#######8  |136803/173481[36:11<09:26,64.72it/s] 85%|########4 |146834/173481[39:00<07:09,62.07it/s] 85%|########5 |147576/173481[39:11<06:57,62.07it/s] 91%|#########1|158523/173481[42:00<03:55,63.47it/s] 92%|#########1|159301/173481[42:12<03:43,63.47it/s] 98%|#########7|169267/173481[45:00<01:08,61.52it/s] 98%|#########7|169882/173481[45:12<00:58,61.52it/s]100%|##########|173481/173481[46:15<00:00,62.50it/s]
[32m[0323 22:03:29 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:2775.63 sec.
[32m[0323 22:03:29 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-2428734.
[32m[0323 22:03:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:43<00:00,182.17it/s]
13
[32m[0323 22:05:13 @monitor.py:363][0m QueueInput/queue_size: 0.43105
[32m[0323 22:05:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.738
[32m[0323 22:05:13 @monitor.py:363][0m activation-summaries/output-rms: 0.042236
[32m[0323 22:05:13 @monitor.py:363][0m cross_entropy_loss: 1.4733
[32m[0323 22:05:13 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.53115
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1972
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.31493
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31649
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30981
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29885
[32m[0323 22:05:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 22:05:13 @monitor.py:363][0m train-error-top1: 0.39752
[32m[0323 22:05:13 @monitor.py:363][0m val-error-top1: 0.41589
[32m[0323 22:05:13 @monitor.py:363][0m val-utt-error: 0.091436
[32m[0323 22:05:13 @monitor.py:363][0m validation_cost: 1.5463
[32m[0323 22:05:13 @monitor.py:363][0m wd_cost: 0.0020005
[32m[0323 22:05:13 @group.py:42][0m Callbacks took 103.770 sec in total. InferenceRunner: 103.332sec
[32m[0323 22:05:13 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13261/173481[03:00<36:14,73.67it/s]  8%|8         |13983/173481[03:10<36:05,73.67it/s] 14%|#3        |23982/173481[06:00<37:49,65.86it/s] 14%|#4        |24516/173481[06:10<37:41,65.86it/s] 19%|#9        |33277/173481[09:00<40:21,57.89it/s] 20%|#9        |33900/173481[09:10<40:11,57.89it/s] 25%|##5       |43832/173481[12:00<37:05,58.26it/s] 26%|##5       |44481/173481[12:10<36:54,58.26it/s] 31%|###1      |54150/173481[15:00<34:25,57.78it/s] 31%|###1      |54641/173481[15:10<34:16,57.78it/s] 36%|###6      |62532/173481[18:00<35:51,51.56it/s] 36%|###6      |63221/173481[18:10<35:38,51.56it/s] 42%|####2     |73492/173481[21:00<29:50,55.83it/s] 43%|####2     |74122/173481[21:11<29:39,55.83it/s] 48%|####8     |83988/173481[24:00<26:08,57.04it/s] 49%|####8     |84656/173481[24:11<25:57,57.04it/s] 54%|#####3    |93455/173481[27:00<24:22,54.73it/s] 54%|#####4    |93996/173481[27:11<24:12,54.73it/s] 59%|#####8    |102100/173481[30:00<23:15,51.16it/s] 59%|#####9    |102708/173481[30:11<23:03,51.16it/s] 65%|######5   |113293/173481[33:00<17:52,56.13it/s] 66%|######5   |113986/173481[33:11<17:39,56.13it/s] 72%|#######1  |124607/173481[36:00<13:44,59.30it/s] 72%|#######2  |125226/173481[36:11<13:33,59.30it/s] 77%|#######7  |134310/173481[39:00<11:33,56.47it/s] 78%|#######7  |134976/173481[39:12<11:21,56.47it/s] 83%|########3 |144147/173481[42:00<08:48,55.54it/s] 83%|########3 |144809/173481[42:12<08:36,55.54it/s] 89%|########9 |154797/173481[45:00<05:26,57.28it/s] 90%|########9 |155476/173481[45:12<05:14,57.28it/s] 95%|#########5|164912/173481[48:00<02:31,56.72it/s] 95%|#########5|165537/173481[48:12<02:20,56.72it/s]100%|##########|173481/173481[50:21<00:00,57.41it/s]
[32m[0323 22:55:35 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3021.98 sec.
[32m[0323 22:55:35 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-2602215.
[32m[0323 22:55:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,192.36it/s]
14
[32m[0323 22:57:13 @monitor.py:363][0m QueueInput/queue_size: 0.59696
[32m[0323 22:57:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.337
[32m[0323 22:57:13 @monitor.py:363][0m activation-summaries/output-rms: 0.04333
[32m[0323 22:57:13 @monitor.py:363][0m cross_entropy_loss: 1.473
[32m[0323 22:57:13 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.54374
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1987
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3196
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31841
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31118
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3001
[32m[0323 22:57:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 22:57:13 @monitor.py:363][0m train-error-top1: 0.39963
[32m[0323 22:57:13 @monitor.py:363][0m val-error-top1: 0.41576
[32m[0323 22:57:13 @monitor.py:363][0m val-utt-error: 0.090479
[32m[0323 22:57:13 @monitor.py:363][0m validation_cost: 1.5451
[32m[0323 22:57:13 @monitor.py:363][0m wd_cost: 0.0020589
[32m[0323 22:57:13 @group.py:42][0m Callbacks took 98.383 sec in total. InferenceRunner: 97.862sec
[32m[0323 22:57:13 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13021/173481[03:00<36:58,72.33it/s]  8%|7         |13625/173481[03:10<36:50,72.33it/s] 14%|#4        |24911/173481[06:00<35:51,69.05it/s] 15%|#4        |25615/173481[06:10<35:41,69.05it/s] 21%|##        |36001/173481[09:00<35:11,65.12it/s] 21%|##1       |36610/173481[09:10<35:01,65.12it/s] 27%|##6       |46716/173481[12:00<33:58,62.19it/s] 27%|##7       |47370/173481[12:10<33:47,62.19it/s] 33%|###2      |57241/173481[15:00<32:08,60.27it/s] 33%|###3      |57870/173481[15:10<31:58,60.27it/s] 39%|###9      |67822/173481[18:00<29:35,59.51it/s] 39%|###9      |68455/173481[18:10<29:24,59.51it/s] 45%|####5     |78826/173481[21:00<26:09,60.31it/s] 46%|####5     |79556/173481[21:11<25:57,60.31it/s] 53%|#####2    |91341/173481[24:00<21:11,64.59it/s] 53%|#####3    |92126/173481[24:11<20:59,64.59it/s] 60%|#####9    |103328/173481[27:00<17:49,65.58it/s] 60%|#####9    |104055/173481[27:11<17:38,65.58it/s] 67%|######6   |116116/173481[30:00<14:01,68.20it/s] 67%|######7   |116865/173481[30:11<13:50,68.20it/s] 74%|#######3  |128053/173481[33:00<11:15,67.24it/s] 74%|#######4  |128784/173481[33:11<11:04,67.24it/s] 80%|########  |139111/173481[36:00<08:55,64.21it/s] 81%|########  |139825/173481[36:11<08:44,64.21it/s] 86%|########6 |149831/173481[39:00<06:22,61.79it/s] 87%|########6 |150543/173481[39:12<06:11,61.79it/s] 92%|#########2|160191/173481[42:00<03:43,59.59it/s] 93%|#########2|161039/173481[42:12<03:28,59.59it/s]100%|##########|173481/173481[44:58<00:00,64.30it/s]
[32m[0323 23:42:11 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:2698.07 sec.
[32m[0323 23:42:11 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-2775696.
[32m[0323 23:42:12 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,184.17it/s]
15
[32m[0323 23:43:54 @monitor.py:363][0m QueueInput/queue_size: 0.54511
[32m[0323 23:43:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.578
[32m[0323 23:43:54 @monitor.py:363][0m activation-summaries/output-rms: 0.042158
[32m[0323 23:43:54 @monitor.py:363][0m cross_entropy_loss: 1.4858
[32m[0323 23:43:54 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5563
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2002
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32382
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32027
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31253
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3013
[32m[0323 23:43:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0323 23:43:54 @monitor.py:363][0m train-error-top1: 0.40293
[32m[0323 23:43:54 @monitor.py:363][0m val-error-top1: 0.41405
[32m[0323 23:43:54 @monitor.py:363][0m val-utt-error: 0.088992
[32m[0323 23:43:54 @monitor.py:363][0m validation_cost: 1.5387
[32m[0323 23:43:54 @monitor.py:363][0m wd_cost: 0.0021158
[32m[0323 23:43:54 @group.py:42][0m Callbacks took 102.794 sec in total. InferenceRunner: 102.210sec
[32m[0323 23:43:54 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12965/173481[03:00<37:08,72.02it/s]  8%|7         |13609/173481[03:10<36:59,72.02it/s] 14%|#4        |25130/173481[06:00<35:27,69.72it/s] 15%|#4        |25794/173481[06:10<35:18,69.72it/s] 22%|##1       |37375/173481[09:00<32:56,68.86it/s] 22%|##1       |38092/173481[09:10<32:46,68.86it/s] 28%|##8       |49030/173481[12:00<31:04,66.74it/s] 29%|##8       |49724/173481[12:10<30:54,66.74it/s] 36%|###6      |62848/173481[15:00<25:49,71.40it/s] 37%|###6      |63651/173481[15:10<25:38,71.40it/s] 45%|####4     |77967/173481[18:00<20:37,77.19it/s] 45%|####5     |78861/173481[18:10<20:25,77.19it/s] 53%|#####2    |91919/173481[21:00<17:34,77.35it/s] 53%|#####3    |92609/173481[21:11<17:25,77.35it/s] 61%|######    |105568/173481[24:00<14:46,76.58it/s] 61%|######1   |106462/173481[24:11<14:35,76.58it/s] 69%|######8   |119631/173481[27:00<11:36,77.35it/s] 70%|######9   |120582/173481[27:11<11:23,77.35it/s] 77%|#######6  |133035/173481[30:00<08:53,75.88it/s] 77%|#######7  |133759/173481[30:11<08:43,75.88it/s] 83%|########3 |144705/173481[33:00<06:51,69.91it/s] 84%|########3 |145449/173481[33:11<06:40,69.91it/s] 90%|########9 |156035/173481[36:00<04:23,66.24it/s] 90%|######### |156774/173481[36:11<04:12,66.24it/s] 97%|#########6|167435/173481[39:00<01:33,64.74it/s] 97%|#########6|168139/173481[39:12<01:22,64.74it/s]100%|##########|173481/173481[40:43<00:00,71.01it/s]
[32m[0324 00:24:37 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:2443.02 sec.
[32m[0324 00:24:37 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-2949177.
[32m[0324 00:24:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,168.03it/s]
16
[32m[0324 00:26:30 @monitor.py:363][0m QueueInput/queue_size: 0.58085
[32m[0324 00:26:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 42.835
[32m[0324 00:26:30 @monitor.py:363][0m activation-summaries/output-rms: 0.042752
[32m[0324 00:26:30 @monitor.py:363][0m cross_entropy_loss: 1.5072
[32m[0324 00:26:30 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56479
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.201
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32642
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32132
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31323
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30192
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 00:26:30 @monitor.py:363][0m train-error-top1: 0.40611
[32m[0324 00:26:30 @monitor.py:363][0m val-error-top1: 0.41097
[32m[0324 00:26:30 @monitor.py:363][0m val-utt-error: 0.086335
[32m[0324 00:26:30 @monitor.py:363][0m validation_cost: 1.5255
[32m[0324 00:26:30 @monitor.py:363][0m wd_cost: 0.00043053
[32m[0324 00:26:30 @group.py:42][0m Callbacks took 113.111 sec in total. InferenceRunner: 112.028sec
[32m[0324 00:26:30 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13731/173481[03:00<34:54,76.28it/s]  8%|8         |14368/173481[03:10<34:45,76.28it/s] 15%|#4        |25254/173481[06:00<35:29,69.59it/s] 15%|#4        |25841/173481[06:10<35:21,69.59it/s] 20%|##        |35131/173481[09:00<37:34,61.36it/s] 21%|##        |35746/173481[09:10<37:24,61.36it/s] 26%|##6       |45402/173481[12:00<36:05,59.13it/s] 27%|##6       |45984/173481[12:10<35:56,59.13it/s] 32%|###1      |55029/173481[15:00<35:09,56.16it/s] 32%|###2      |55608/173481[15:10<34:58,56.16it/s] 38%|###7      |65129/173481[18:00<32:10,56.13it/s] 38%|###7      |65783/173481[18:11<31:58,56.13it/s] 44%|####3     |76269/173481[21:00<27:31,58.87it/s] 44%|####4     |76926/173481[21:11<27:20,58.87it/s] 50%|#####     |87223/173481[24:00<24:01,59.84it/s] 51%|#####     |87945/173481[24:11<23:49,59.84it/s] 57%|#####6    |98133/173481[27:00<20:51,60.22it/s] 57%|#####6    |98808/173481[27:11<20:39,60.22it/s] 63%|######2   |108989/173481[30:00<17:50,60.27it/s] 63%|######3   |109728/173481[30:11<17:37,60.27it/s] 69%|######9   |120504/173481[33:00<14:13,62.06it/s] 70%|######9   |121148/173481[33:11<14:03,62.06it/s] 76%|#######5  |131264/173481[36:00<11:33,60.89it/s] 76%|#######6  |131993/173481[36:11<11:21,60.89it/s] 82%|########1 |142118/173481[39:00<08:37,60.60it/s] 82%|########2 |142869/173481[39:12<08:25,60.60it/s] 88%|########8 |153225/173481[42:00<05:31,61.14it/s] 89%|########8 |153978/173481[42:12<05:18,61.14it/s] 95%|#########4|164619/173481[45:00<02:22,62.20it/s] 95%|#########5|165363/173481[45:12<02:10,62.20it/s]100%|##########|173481/173481[47:26<00:00,60.94it/s]
[32m[0324 01:13:57 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:2846.59 sec.
[32m[0324 01:13:57 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-3122658.
[32m[0324 01:13:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.21it/s]
17
[32m[0324 01:15:42 @monitor.py:363][0m QueueInput/queue_size: 0.62166
[32m[0324 01:15:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.546
[32m[0324 01:15:42 @monitor.py:363][0m activation-summaries/output-rms: 0.04271
[32m[0324 01:15:42 @monitor.py:363][0m cross_entropy_loss: 1.5099
[32m[0324 01:15:42 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57138
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.202
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32816
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32202
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31363
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30227
[32m[0324 01:15:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 01:15:42 @monitor.py:363][0m train-error-top1: 0.4178
[32m[0324 01:15:42 @monitor.py:363][0m val-error-top1: 0.41098
[32m[0324 01:15:42 @monitor.py:363][0m val-utt-error: 0.086813
[32m[0324 01:15:42 @monitor.py:363][0m validation_cost: 1.5246
[32m[0324 01:15:42 @monitor.py:363][0m wd_cost: 0.0004359
[32m[0324 01:15:42 @group.py:42][0m Callbacks took 105.286 sec in total. InferenceRunner: 104.461sec
[32m[0324 01:15:42 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13332/173481[03:00<36:02,74.07it/s]  8%|8         |13987/173481[03:10<35:53,74.07it/s] 14%|#3        |23554/173481[06:00<38:52,64.29it/s] 14%|#3        |24053/173481[06:10<38:44,64.29it/s] 19%|#9        |33573/173481[09:00<39:05,59.66it/s] 20%|#9        |34231/173481[09:10<38:54,59.66it/s] 26%|##5       |44366/173481[12:00<35:58,59.81it/s] 26%|##5       |45059/173481[12:10<35:47,59.81it/s] 32%|###1      |55063/173481[15:00<33:06,59.61it/s] 32%|###2      |55597/173481[15:10<32:57,59.61it/s] 38%|###7      |65598/173481[18:00<30:26,59.06it/s] 38%|###8      |66295/173481[18:11<30:14,59.06it/s] 44%|####4     |76438/173481[21:00<27:07,59.63it/s] 44%|####4     |77102/173481[21:11<26:56,59.63it/s] 50%|####9     |86593/173481[24:00<24:58,57.98it/s] 50%|#####     |87202/173481[24:11<24:48,57.98it/s] 56%|#####5    |96352/173481[27:00<22:56,56.03it/s] 56%|#####5    |97005/173481[27:11<22:44,56.03it/s] 62%|######1   |106726/173481[30:00<19:34,56.82it/s] 62%|######1   |107399/173481[30:11<19:22,56.82it/s] 68%|######7   |117534/173481[33:00<15:58,58.39it/s] 68%|######8   |118226/173481[33:11<15:46,58.39it/s] 74%|#######3  |127843/173481[36:00<13:09,57.82it/s] 74%|#######4  |128522/173481[36:12<12:57,57.82it/s] 80%|#######9  |138238/173481[39:00<10:09,57.78it/s] 80%|########  |138959/173481[39:12<09:57,57.78it/s] 86%|########6 |149333/173481[42:00<06:44,59.64it/s] 87%|########6 |150096/173481[42:12<06:32,59.64it/s] 93%|#########2|160704/173481[45:00<03:28,61.35it/s] 93%|#########3|161516/173481[45:12<03:15,61.35it/s] 99%|#########8|171563/173481[48:00<00:31,60.83it/s] 99%|#########9|172312/173481[48:12<00:19,60.83it/s]100%|##########|173481/173481[48:31<00:00,59.58it/s]
[32m[0324 02:04:14 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:2911.77 sec.
[32m[0324 02:04:14 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-3296139.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.67it/s]
18
[32m[0324 02:06:12 @monitor.py:363][0m QueueInput/queue_size: 0.62145
[32m[0324 02:06:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.487
[32m[0324 02:06:12 @monitor.py:363][0m activation-summaries/output-rms: 0.042529
[32m[0324 02:06:12 @monitor.py:363][0m cross_entropy_loss: 1.4538
[32m[0324 02:06:12 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57799
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2029
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32985
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32271
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31402
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30261
[32m[0324 02:06:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 02:06:12 @monitor.py:363][0m train-error-top1: 0.39485
[32m[0324 02:06:12 @monitor.py:363][0m val-error-top1: 0.41062
[32m[0324 02:06:12 @monitor.py:363][0m val-utt-error: 0.088035
[32m[0324 02:06:12 @monitor.py:363][0m validation_cost: 1.5238
[32m[0324 02:06:12 @monitor.py:363][0m wd_cost: 0.00044129
[32m[0324 02:06:12 @group.py:42][0m Callbacks took 118.165 sec in total. InferenceRunner: 117.896sec
[32m[0324 02:06:12 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12432/173481[03:00<38:52,69.05it/s]  8%|7         |13021/173481[03:10<38:43,69.05it/s] 13%|#3        |23204/173481[06:00<39:03,64.12it/s] 14%|#3        |23822/173481[06:10<38:54,64.12it/s] 20%|##        |34732/173481[09:00<36:05,64.08it/s] 20%|##        |35395/173481[09:10<35:55,64.08it/s] 26%|##6       |45517/173481[12:00<34:26,61.92it/s] 27%|##6       |46180/173481[12:10<34:15,61.92it/s] 33%|###3      |57472/173481[15:00<30:10,64.08it/s] 34%|###3      |58245/173481[15:10<29:58,64.08it/s] 41%|####      |70773/173481[18:00<24:56,68.64it/s] 41%|####1     |71685/173481[18:10<24:43,68.64it/s] 48%|####8     |83993/173481[21:00<21:01,70.96it/s] 49%|####8     |84928/173481[21:11<20:47,70.96it/s] 58%|#####7    |100486/173481[24:00<15:12,79.98it/s] 59%|#####8    |101536/173481[24:11<14:59,79.98it/s] 68%|######7   |117383/173481[27:00<10:49,86.37it/s] 68%|######8   |118440/173481[27:11<10:37,86.37it/s] 77%|#######7  |134270/173481[30:00<07:15,89.94it/s] 78%|#######8  |135326/173481[30:11<07:04,89.94it/s] 87%|########7 |151033/173481[33:00<04:05,91.50it/s] 88%|########7 |152113/173481[33:11<03:53,91.50it/s] 97%|#########6|167574/173481[36:00<01:04,91.70it/s] 97%|#########7|168677/173481[36:12<00:52,91.70it/s]100%|##########|173481/173481[37:03<00:00,78.01it/s]
[32m[0324 02:43:16 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:2223.72 sec.
[32m[0324 02:43:16 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-3469620.
[32m[0324 02:43:16 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,189.86it/s]
19
[32m[0324 02:44:55 @monitor.py:363][0m QueueInput/queue_size: 0.47561
[32m[0324 02:44:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.973
[32m[0324 02:44:55 @monitor.py:363][0m activation-summaries/output-rms: 0.043581
[32m[0324 02:44:55 @monitor.py:363][0m cross_entropy_loss: 1.4536
[32m[0324 02:44:55 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58156
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2032
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33066
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32301
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31417
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30273
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 02:44:55 @monitor.py:363][0m train-error-top1: 0.39647
[32m[0324 02:44:55 @monitor.py:363][0m val-error-top1: 0.40997
[32m[0324 02:44:55 @monitor.py:363][0m val-utt-error: 0.088088
[32m[0324 02:44:55 @monitor.py:363][0m validation_cost: 1.5203
[32m[0324 02:44:55 @monitor.py:363][0m wd_cost: 8.8807e-05
[32m[0324 02:44:55 @group.py:42][0m Callbacks took 99.549 sec in total. InferenceRunner: 99.147sec
[32m[0324 02:44:55 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11776/173481[03:00<41:11,65.42it/s]  7%|7         |12375/173481[03:10<41:02,65.42it/s] 13%|#2        |22185/173481[06:00<41:04,61.39it/s] 13%|#3        |22771/173481[06:10<40:54,61.39it/s] 19%|#8        |32644/173481[09:00<39:19,59.70it/s] 19%|#9        |33294/173481[09:10<39:08,59.70it/s] 25%|##5       |43541/173481[12:00<36:01,60.11it/s] 25%|##5       |44180/173481[12:10<35:51,60.11it/s] 31%|###1      |54026/173481[15:00<33:39,59.16it/s] 32%|###1      |54675/173481[15:10<33:28,59.16it/s] 37%|###7      |64791/173481[18:00<30:27,59.48it/s] 38%|###7      |65404/173481[18:11<30:17,59.48it/s] 43%|####3     |75340/173481[21:00<27:42,59.04it/s] 44%|####3     |76051/173481[21:11<27:30,59.04it/s] 50%|####9     |86444/173481[24:00<24:02,60.33it/s] 50%|#####     |87111/173481[24:11<23:51,60.33it/s] 56%|#####6    |97701/173481[27:00<20:34,61.41it/s] 57%|#####6    |98402/173481[27:11<20:22,61.41it/s] 63%|######2   |108619/173481[30:00<17:42,61.03it/s] 63%|######3   |109328/173481[30:11<17:31,61.03it/s] 69%|######9   |119831/173481[33:00<14:30,61.65it/s] 69%|######9   |120541/173481[33:11<14:18,61.65it/s] 75%|#######5  |130920/173481[36:00<11:30,61.63it/s] 76%|#######5  |131630/173481[36:12<11:19,61.63it/s] 82%|########1 |142041/173481[39:00<08:29,61.70it/s] 82%|########2 |142761/173481[39:12<08:17,61.70it/s] 88%|########8 |152826/173481[42:00<05:39,60.80it/s] 89%|########8 |153546/173481[42:12<05:27,60.80it/s] 95%|#########4|164427/173481[45:00<02:24,62.57it/s] 95%|#########5|165372/173481[45:12<02:09,62.57it/s]100%|##########|173481/173481[47:12<00:00,61.25it/s]
[32m[0324 03:32:07 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:2832.28 sec.
[32m[0324 03:32:08 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-3643101.
[32m[0324 03:32:08 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,194.28it/s]
20
[32m[0324 03:33:45 @monitor.py:363][0m QueueInput/queue_size: 0.58616
[32m[0324 03:33:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.314
[32m[0324 03:33:45 @monitor.py:363][0m activation-summaries/output-rms: 0.042383
[32m[0324 03:33:45 @monitor.py:363][0m cross_entropy_loss: 1.4634
[32m[0324 03:33:45 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58502
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2037
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33139
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32328
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3143
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30282
[32m[0324 03:33:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 03:33:45 @monitor.py:363][0m train-error-top1: 0.39577
[32m[0324 03:33:45 @monitor.py:363][0m val-error-top1: 0.40879
[32m[0324 03:33:45 @monitor.py:363][0m val-utt-error: 0.085857
[32m[0324 03:33:45 @monitor.py:363][0m validation_cost: 1.5168
[32m[0324 03:33:45 @monitor.py:363][0m wd_cost: 8.9329e-05
[32m[0324 03:33:45 @group.py:42][0m Callbacks took 97.539 sec in total. InferenceRunner: 96.895sec
[32m[0324 03:33:45 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12916/173481[03:00<37:18,71.74it/s]  8%|7         |13559/173481[03:10<37:09,71.74it/s] 14%|#4        |24667/173481[06:00<36:16,68.36it/s] 15%|#4        |25314/173481[06:10<36:07,68.36it/s] 20%|##        |35230/173481[09:00<36:29,63.14it/s] 21%|##        |35824/173481[09:10<36:20,63.14it/s] 26%|##6       |45525/173481[12:00<35:31,60.02it/s] 27%|##6       |46119/173481[12:10<35:22,60.02it/s] 33%|###2      |56911/173481[15:00<31:32,61.59it/s] 33%|###3      |57549/173481[15:10<31:22,61.59it/s] 40%|###9      |68912/173481[18:00<27:13,64.03it/s] 40%|####      |69595/173481[18:11<27:02,64.03it/s] 46%|####6     |79915/173481[21:00<24:56,62.54it/s] 46%|####6     |80574/173481[21:11<24:45,62.54it/s] 53%|#####2    |91098/173481[24:00<22:01,62.33it/s] 53%|#####2    |91756/173481[24:11<21:51,62.33it/s] 59%|#####8    |102279/173481[27:00<19:04,62.23it/s] 59%|#####9    |103010/173481[27:11<18:52,62.23it/s] 66%|######5   |114265/173481[30:00<15:20,64.33it/s] 66%|######6   |114963/173481[30:11<15:09,64.33it/s] 72%|#######2  |125484/173481[33:00<12:38,63.31it/s] 73%|#######2  |126214/173481[33:11<12:26,63.31it/s] 79%|#######8  |136710/173481[36:00<09:45,62.83it/s] 79%|#######9  |137434/173481[36:12<09:33,62.83it/s] 85%|########5 |147971/173481[39:00<06:46,62.70it/s] 86%|########5 |148729/173481[39:12<06:34,62.70it/s] 92%|#########1|159395/173481[42:00<03:43,63.07it/s] 92%|#########2|160149/173481[42:12<03:31,63.07it/s] 98%|#########8|170590/173481[45:00<00:46,62.62it/s] 99%|#########8|171414/173481[45:12<00:33,62.62it/s]100%|##########|173481/173481[45:44<00:00,63.21it/s]
[32m[0324 04:19:29 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:2744.46 sec.
[32m[0324 04:19:30 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-3816582.
[32m[0324 04:19:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.76it/s]
21
[32m[0324 04:21:07 @monitor.py:363][0m QueueInput/queue_size: 0.76813
[32m[0324 04:21:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.896
[32m[0324 04:21:07 @monitor.py:363][0m activation-summaries/output-rms: 0.042846
[32m[0324 04:21:07 @monitor.py:363][0m cross_entropy_loss: 1.4925
[32m[0324 04:21:07 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58805
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.204
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33203
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32351
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31441
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3029
[32m[0324 04:21:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 04:21:07 @monitor.py:363][0m train-error-top1: 0.40457
[32m[0324 04:21:07 @monitor.py:363][0m val-error-top1: 0.40838
[32m[0324 04:21:07 @monitor.py:363][0m val-utt-error: 0.086069
[32m[0324 04:21:07 @monitor.py:363][0m validation_cost: 1.5135
[32m[0324 04:21:07 @monitor.py:363][0m wd_cost: 8.9788e-05
[32m[0324 04:21:07 @group.py:42][0m Callbacks took 98.024 sec in total. InferenceRunner: 97.152sec
[32m[0324 04:21:07 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14221/173481[03:00<33:35,79.00it/s]  9%|8         |14908/173481[03:10<33:27,79.00it/s] 15%|#5        |26549/173481[06:00<33:22,73.37it/s] 16%|#5        |27183/173481[06:10<33:14,73.37it/s] 22%|##1       |37535/173481[09:00<34:00,66.63it/s] 22%|##1       |38163/173481[09:10<33:50,66.63it/s] 28%|##7       |48265/173481[12:00<33:09,62.93it/s] 28%|##8       |48904/173481[12:10<32:59,62.93it/s] 34%|###4      |59014/173481[15:00<31:08,61.27it/s] 34%|###4      |59680/173481[15:10<30:57,61.27it/s] 41%|####      |70604/173481[18:00<27:18,62.78it/s] 41%|####1     |71334/173481[18:10<27:07,62.78it/s] 48%|####7     |82425/173481[21:00<23:38,64.19it/s] 48%|####7     |83114/173481[21:11<23:27,64.19it/s] 54%|#####4    |94129/173481[24:00<20:28,64.60it/s] 55%|#####4    |94793/173481[24:11<20:18,64.60it/s] 61%|######    |105703/173481[27:00<17:31,64.45it/s] 61%|######1   |106538/173481[27:11<17:18,64.45it/s] 69%|######8   |119304/173481[30:00<12:58,69.56it/s] 69%|######9   |120155/173481[30:11<12:46,69.56it/s] 76%|#######5  |131719/173481[33:00<10:02,69.26it/s] 76%|#######6  |132483/173481[33:11<09:51,69.26it/s] 83%|########2 |143594/173481[36:00<07:22,67.58it/s] 83%|########3 |144399/173481[36:11<07:10,67.58it/s] 90%|########9 |155483/173481[39:00<04:29,66.80it/s] 90%|######### |156253/173481[39:12<04:17,66.80it/s] 97%|#########6|167555/173481[42:00<01:28,66.93it/s] 97%|#########7|168381/173481[42:12<01:16,66.93it/s]100%|##########|173481/173481[43:30<00:00,66.45it/s]
[32m[0324 05:04:38 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:2610.70 sec.
[32m[0324 05:04:38 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-3990063.
[32m[0324 05:04:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:43<00:00,181.11it/s]
22
[32m[0324 05:06:23 @monitor.py:363][0m QueueInput/queue_size: 0.62333
[32m[0324 05:06:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.992
[32m[0324 05:06:23 @monitor.py:363][0m activation-summaries/output-rms: 0.042895
[32m[0324 05:06:23 @monitor.py:363][0m cross_entropy_loss: 1.4982
[32m[0324 05:06:23 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58981
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2042
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33236
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32362
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31445
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30294
[32m[0324 05:06:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 05:06:23 @monitor.py:363][0m train-error-top1: 0.41383
[32m[0324 05:06:23 @monitor.py:363][0m val-error-top1: 0.40817
[32m[0324 05:06:23 @monitor.py:363][0m val-utt-error: 0.085751
[32m[0324 05:06:23 @monitor.py:363][0m validation_cost: 1.513
[32m[0324 05:06:23 @monitor.py:363][0m wd_cost: 1.8009e-05
[32m[0324 05:06:23 @group.py:42][0m Callbacks took 105.375 sec in total. InferenceRunner: 103.947sec
[32m[0324 05:06:23 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14178/173481[03:00<33:42,78.76it/s]  9%|8         |14887/173481[03:10<33:33,78.76it/s] 15%|#4        |25278/173481[06:00<35:42,69.17it/s] 15%|#4        |25963/173481[06:10<35:32,69.17it/s] 22%|##1       |37433/173481[09:00<33:10,68.34it/s] 22%|##2       |38177/173481[09:10<32:59,68.34it/s] 29%|##8       |49728/173481[12:00<30:11,68.31it/s] 29%|##9       |50424/173481[12:10<30:01,68.31it/s] 36%|###5      |61887/173481[15:00<27:22,67.93it/s] 36%|###6      |62662/173481[15:10<27:11,67.93it/s] 43%|####3     |75328/173481[18:00<22:59,71.14it/s] 44%|####3     |76170/173481[18:11<22:47,71.14it/s] 51%|#####1    |89307/173481[21:00<18:53,74.25it/s] 52%|#####1    |90173/173481[21:11<18:41,74.25it/s] 59%|#####8    |102254/173481[24:00<16:14,73.07it/s] 59%|#####9    |103080/173481[24:11<16:03,73.07it/s] 66%|######6   |114788/173481[27:00<13:43,71.31it/s] 67%|######6   |115577/173481[27:11<13:32,71.31it/s] 73%|#######3  |127158/173481[30:00<11:01,69.99it/s] 74%|#######3  |127942/173481[30:11<10:50,69.99it/s] 80%|########  |139493/173481[33:00<08:10,69.25it/s] 81%|########  |140277/173481[33:11<07:59,69.25it/s] 88%|########7 |152534/173481[36:00<04:55,70.81it/s] 88%|########8 |153392/173481[36:11<04:43,70.81it/s] 96%|#########6|166862/173481[39:00<01:28,74.95it/s] 97%|#########6|167774/173481[39:12<01:16,74.95it/s]100%|##########|173481/173481[40:27<00:00,71.48it/s]
[32m[0324 05:46:51 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:2427.05 sec.
[32m[0324 05:46:51 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-4163544.
[32m[0324 05:46:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.32it/s]
23
[32m[0324 05:48:31 @monitor.py:363][0m QueueInput/queue_size: 0.49637
[32m[0324 05:48:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.358
[32m[0324 05:48:31 @monitor.py:363][0m activation-summaries/output-rms: 0.04269
[32m[0324 05:48:31 @monitor.py:363][0m cross_entropy_loss: 1.4422
[32m[0324 05:48:31 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59159
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2044
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33269
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32374
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31449
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30297
[32m[0324 05:48:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 05:48:31 @monitor.py:363][0m train-error-top1: 0.39528
[32m[0324 05:48:31 @monitor.py:363][0m val-error-top1: 0.40785
[32m[0324 05:48:31 @monitor.py:363][0m val-utt-error: 0.085751
[32m[0324 05:48:31 @monitor.py:363][0m validation_cost: 1.5136
[32m[0324 05:48:31 @monitor.py:363][0m wd_cost: 1.806e-05
[32m[0324 05:48:31 @group.py:42][0m Callbacks took 100.216 sec in total. InferenceRunner: 98.907sec
[32m[0324 05:48:31 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16349/173481[03:00<28:50,90.83it/s] 10%|9         |17277/173481[03:10<28:39,90.83it/s] 19%|#8        |32771/173481[06:00<25:45,91.03it/s] 19%|#9        |33701/173481[06:10<25:35,91.03it/s] 28%|##8       |49402/173481[09:00<22:33,91.71it/s] 29%|##9       |50387/173481[09:10<22:22,91.71it/s] 38%|###8      |66230/173481[12:00<19:18,92.59it/s] 39%|###8      |67239/173481[12:10<19:07,92.59it/s] 48%|####7     |82993/173481[15:00<16:14,92.85it/s] 48%|####8     |84012/173481[15:10<16:03,92.85it/s] 57%|#####7    |99425/173481[18:00<13:24,92.06it/s] 58%|#####7    |100453/173481[18:11<13:13,92.06it/s] 67%|######6   |116097/173481[21:00<10:21,92.34it/s] 68%|######7   |117136/173481[21:11<10:10,92.34it/s] 76%|#######6  |132693/173481[24:00<07:22,92.27it/s] 77%|#######7  |133737/173481[24:11<07:10,92.27it/s] 86%|########6 |149246/173481[27:00<04:23,92.11it/s] 87%|########6 |150296/173481[27:11<04:11,92.11it/s] 96%|#########5|165768/173481[30:00<01:23,91.95it/s] 96%|#########6|166842/173481[30:11<01:12,91.95it/s]100%|##########|173481/173481[31:23<00:00,92.12it/s]
[32m[0324 06:19:54 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:1883.19 sec.
[32m[0324 06:19:54 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-4337025.
[32m[0324 06:19:55 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,192.01it/s]
24
[32m[0324 06:21:33 @monitor.py:363][0m QueueInput/queue_size: 5.6012
[32m[0324 06:21:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.532
[32m[0324 06:21:33 @monitor.py:363][0m activation-summaries/output-rms: 0.04365
[32m[0324 06:21:33 @monitor.py:363][0m cross_entropy_loss: 1.448
[32m[0324 06:21:33 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5929
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2045
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33293
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32382
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31452
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30299
[32m[0324 06:21:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 06:21:33 @monitor.py:363][0m train-error-top1: 0.39617
[32m[0324 06:21:33 @monitor.py:363][0m val-error-top1: 0.40869
[32m[0324 06:21:33 @monitor.py:363][0m val-utt-error: 0.087557
[32m[0324 06:21:33 @monitor.py:363][0m validation_cost: 1.5143
[32m[0324 06:21:33 @monitor.py:363][0m wd_cost: 3.6196e-06
[32m[0324 06:21:33 @group.py:42][0m Callbacks took 99.003 sec in total. InferenceRunner: 98.036sec
[32m[0324 06:21:33 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16969/173481[03:00<27:40,94.27it/s] 10%|#         |17924/173481[03:10<27:30,94.27it/s] 17%|#7        |30276/173481[06:00<28:48,82.86it/s] 18%|#7        |30935/173481[06:10<28:40,82.86it/s] 24%|##4       |41721/173481[09:00<30:31,71.95it/s] 24%|##4       |42405/173481[09:10<30:21,71.95it/s] 31%|###       |53276/173481[12:00<29:31,67.85it/s] 31%|###1      |53955/173481[12:10<29:21,67.85it/s] 38%|###7      |65370/173481[15:00<26:41,67.52it/s] 38%|###8      |66050/173481[15:10<26:31,67.52it/s] 44%|####4     |76769/173481[18:00<24:39,65.35it/s] 45%|####4     |77471/173481[18:10<24:29,65.35it/s] 51%|#####1    |88632/173481[21:00<21:32,65.63it/s] 52%|#####1    |89350/173481[21:11<21:21,65.63it/s] 58%|#####7    |100434/173481[24:00<18:33,65.60it/s] 58%|#####8    |101132/173481[24:11<18:22,65.60it/s] 65%|######4   |112215/173481[27:00<15:35,65.52it/s] 65%|######5   |112983/173481[27:11<15:23,65.52it/s] 72%|#######1  |124201/173481[30:00<12:26,66.05it/s] 72%|#######2  |124971/173481[30:11<12:14,66.05it/s] 78%|#######8  |135851/173481[33:00<09:35,65.37it/s] 79%|#######8  |136590/173481[33:11<09:24,65.37it/s] 85%|########4 |147411/173481[36:00<06:42,64.79it/s] 85%|########5 |148149/173481[36:11<06:30,64.79it/s] 91%|#########1|158706/173481[39:00<03:51,63.75it/s] 92%|#########1|159445/173481[39:12<03:40,63.75it/s] 99%|#########8|171588/173481[42:00<00:28,67.43it/s] 99%|#########9|172407/173481[42:12<00:15,67.43it/s]100%|##########|173481/173481[42:28<00:00,68.08it/s]
[32m[0324 07:04:01 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:2548.29 sec.
[32m[0324 07:04:01 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,196.40it/s]
25
[32m[0324 07:05:37 @monitor.py:363][0m QueueInput/queue_size: 0.56145
[32m[0324 07:05:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.54
[32m[0324 07:05:37 @monitor.py:363][0m activation-summaries/output-rms: 0.042378
[32m[0324 07:05:37 @monitor.py:363][0m cross_entropy_loss: 1.4561
[32m[0324 07:05:37 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5938
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2046
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33309
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32388
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31454
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.303
[32m[0324 07:05:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 07:05:37 @monitor.py:363][0m train-error-top1: 0.39296
[32m[0324 07:05:37 @monitor.py:363][0m val-error-top1: 0.40757
[32m[0324 07:05:37 @monitor.py:363][0m val-utt-error: 0.085751
[32m[0324 07:05:37 @monitor.py:363][0m validation_cost: 1.5124
[32m[0324 07:05:37 @monitor.py:363][0m wd_cost: 3.6247e-06
[32m[0324 07:05:37 @group.py:42][0m Callbacks took 96.064 sec in total. InferenceRunner: 95.849sec
[32m[0324 07:05:37 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13030/173481[03:00<36:57,72.36it/s]  8%|7         |13626/173481[03:10<36:49,72.36it/s] 14%|#4        |25023/173481[06:00<35:39,69.38it/s] 15%|#4        |25689/173481[06:10<35:30,69.38it/s] 21%|##        |36000/173481[09:00<35:18,64.90it/s] 21%|##1       |36624/173481[09:10<35:08,64.90it/s] 27%|##6       |46659/173481[12:00<34:07,61.93it/s] 27%|##7       |47279/173481[12:10<33:57,61.93it/s] 33%|###3      |57809/173481[15:00<31:07,61.93it/s] 34%|###3      |58484/173481[15:10<30:56,61.93it/s] 40%|###9      |68755/173481[18:00<28:26,61.36it/s] 40%|####      |69434/173481[18:10<28:15,61.36it/s] 46%|####6     |80230/173481[21:00<24:51,62.53it/s] 47%|####6     |80929/173481[21:11<24:40,62.53it/s] 53%|#####2    |91924/173481[24:00<21:19,63.72it/s] 53%|#####3    |92629/173481[24:11<21:08,63.72it/s] 60%|#####9    |103505/173481[27:00<18:12,64.03it/s] 60%|######    |104239/173481[27:11<18:01,64.03it/s] 66%|######6   |115258/173481[30:00<15:00,64.65it/s] 67%|######6   |115956/173481[30:11<14:49,64.65it/s] 73%|#######2  |126205/173481[33:00<12:34,62.67it/s] 73%|#######3  |126964/173481[33:11<12:22,62.67it/s] 79%|#######9  |137130/173481[36:00<09:49,61.66it/s] 79%|#######9  |137833/173481[36:11<09:38,61.66it/s] 85%|########5 |147935/173481[39:00<06:59,60.83it/s] 86%|########5 |148649/173481[39:12<06:48,60.83it/s] 92%|#########1|159232/173481[42:00<03:50,61.78it/s] 92%|#########2|159966/173481[42:12<03:38,61.78it/s] 98%|#########8|170666/173481[45:00<00:44,62.64it/s] 99%|#########8|171420/173481[45:12<00:32,62.64it/s]100%|##########|173481/173481[45:43<00:00,63.23it/s]
[32m[0324 07:51:21 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:2743.52 sec.
[32m[0324 07:51:21 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-4683987.
[32m[0324 07:51:21 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.39it/s]
26
[32m[0324 07:53:29 @monitor.py:363][0m QueueInput/queue_size: 0.39317
[32m[0324 07:53:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.865
[32m[0324 07:53:29 @monitor.py:363][0m activation-summaries/output-rms: 0.042889
[32m[0324 07:53:29 @monitor.py:363][0m cross_entropy_loss: 1.4881
[32m[0324 07:53:29 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59469
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2048
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33325
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32393
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31456
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30301
[32m[0324 07:53:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 07:53:29 @monitor.py:363][0m train-error-top1: 0.40288
[32m[0324 07:53:29 @monitor.py:363][0m val-error-top1: 0.40767
[32m[0324 07:53:29 @monitor.py:363][0m val-utt-error: 0.085485
[32m[0324 07:53:29 @monitor.py:363][0m validation_cost: 1.5113
[32m[0324 07:53:29 @monitor.py:363][0m wd_cost: 3.6298e-06
[32m[0324 07:53:29 @group.py:42][0m Callbacks took 128.197 sec in total. InferenceRunner: 127.715sec
[32m[0324 07:53:29 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16011/173481[03:00<29:30,88.94it/s] 10%|9         |16763/173481[03:10<29:21,88.94it/s] 16%|#6        |28179/173481[06:00<31:31,76.81it/s] 17%|#6        |28773/173481[06:10<31:24,76.81it/s] 22%|##2       |38918/173481[09:00<33:23,67.16it/s] 23%|##2       |39570/173481[09:10<33:14,67.16it/s] 29%|##8       |49604/173481[12:00<32:45,63.02it/s] 29%|##8       |50246/173481[12:10<32:35,63.02it/s] 35%|###4      |60389/173481[15:00<30:41,61.42it/s] 35%|###5      |61025/173481[15:10<30:30,61.42it/s] 42%|####1     |72093/173481[18:00<26:44,63.17it/s] 42%|####1     |72827/173481[18:10<26:33,63.17it/s] 48%|####8     |84079/173481[21:00<22:58,64.83it/s] 49%|####8     |84768/173481[21:11<22:48,64.83it/s] 55%|#####5    |95771/173481[24:00<19:57,64.89it/s] 56%|#####5    |96497/173481[24:11<19:46,64.89it/s] 62%|######1   |106980/173481[27:00<17:26,63.56it/s] 62%|######2   |107715/173481[27:11<17:14,63.56it/s] 69%|######8   |119122/173481[30:00<13:50,65.45it/s] 69%|######9   |119918/173481[30:11<13:38,65.45it/s] 75%|#######5  |130445/173481[33:00<11:10,64.15it/s] 76%|#######5  |131159/173481[33:11<10:59,64.15it/s] 82%|########1 |142054/173481[36:00<08:08,64.32it/s] 82%|########2 |142821/173481[36:11<07:56,64.32it/s] 89%|########8 |153811/173481[39:00<05:03,64.81it/s] 89%|########9 |154593/173481[39:12<04:51,64.81it/s] 95%|#########5|165630/173481[42:00<02:00,65.23it/s] 96%|#########5|166423/173481[42:12<01:48,65.23it/s]100%|##########|173481/173481[43:59<00:00,65.73it/s]
[32m[0324 08:37:28 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:2639.34 sec.
[32m[0324 08:37:29 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-4857468.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,171.26it/s]
27
[32m[0324 08:39:19 @monitor.py:363][0m QueueInput/queue_size: 0.53709
[32m[0324 08:39:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.777
[32m[0324 08:39:19 @monitor.py:363][0m activation-summaries/output-rms: 0.042914
[32m[0324 08:39:19 @monitor.py:363][0m cross_entropy_loss: 1.4957
[32m[0324 08:39:19 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59521
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2048
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33334
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32396
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31456
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30301
[32m[0324 08:39:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 08:39:19 @monitor.py:363][0m train-error-top1: 0.41618
[32m[0324 08:39:19 @monitor.py:363][0m val-error-top1: 0.40748
[32m[0324 08:39:19 @monitor.py:363][0m val-utt-error: 0.085485
[32m[0324 08:39:19 @monitor.py:363][0m validation_cost: 1.5105
[32m[0324 08:39:19 @monitor.py:363][0m wd_cost: 7.2655e-07
[32m[0324 08:39:19 @group.py:42][0m Callbacks took 110.240 sec in total. InferenceRunner: 109.921sec
[32m[0324 08:39:19 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13312/173481[03:00<36:05,73.95it/s]  8%|8         |13977/173481[03:10<35:56,73.95it/s] 14%|#4        |24291/173481[06:00<37:11,66.85it/s] 14%|#4        |24907/173481[06:10<37:02,66.85it/s] 21%|##        |35733/173481[09:00<35:13,65.16it/s] 21%|##1       |36434/173481[09:10<35:03,65.16it/s] 28%|##7       |47708/173481[12:00<31:50,65.84it/s] 28%|##7       |48392/173481[12:10<31:39,65.84it/s] 34%|###4      |59238/173481[15:00<29:19,64.93it/s] 35%|###4      |59967/173481[15:10<29:08,64.93it/s] 41%|####1     |71192/173481[18:00<25:57,65.66it/s] 41%|####1     |71917/173481[18:11<25:46,65.66it/s] 48%|####7     |83178/173481[21:00<22:45,66.12it/s] 48%|####8     |83855/173481[21:11<22:35,66.12it/s] 55%|#####4    |94918/173481[24:00<19:56,65.66it/s] 55%|#####5    |95627/173481[24:11<19:45,65.66it/s] 62%|######1   |106903/173481[27:00<16:47,66.11it/s] 62%|######2   |107665/173481[27:11<16:35,66.11it/s] 69%|######8   |118939/173481[30:00<13:40,66.49it/s] 69%|######9   |119723/173481[30:11<13:28,66.49it/s] 75%|#######5  |130918/173481[33:00<10:39,66.52it/s] 76%|#######5  |131717/173481[33:11<10:27,66.52it/s] 82%|########2 |142939/173481[36:00<07:38,66.65it/s] 83%|########2 |143763/173481[36:12<07:25,66.65it/s] 89%|########9 |155176/173481[39:00<04:31,67.31it/s] 90%|########9 |155986/173481[39:12<04:19,67.31it/s] 96%|#########6|167218/173481[42:00<01:33,67.09it/s] 97%|#########6|168032/173481[42:12<01:21,67.09it/s]100%|##########|173481/173481[43:37<00:00,66.28it/s]
[32m[0324 09:22:56 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:2617.23 sec.
[32m[0324 09:22:56 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-5030949.
[32m[0324 09:22:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,166.02it/s]
28
[32m[0324 09:24:50 @monitor.py:363][0m QueueInput/queue_size: 0.46677
[32m[0324 09:24:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.953
[32m[0324 09:24:50 @monitor.py:363][0m activation-summaries/output-rms: 0.042766
[32m[0324 09:24:50 @monitor.py:363][0m cross_entropy_loss: 1.4388
[32m[0324 09:24:50 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59564
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33342
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32398
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31457
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 09:24:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 09:24:50 @monitor.py:363][0m train-error-top1: 0.39647
[32m[0324 09:24:50 @monitor.py:363][0m val-error-top1: 0.40711
[32m[0324 09:24:50 @monitor.py:363][0m val-utt-error: 0.085538
[32m[0324 09:24:50 @monitor.py:363][0m validation_cost: 1.5109
[32m[0324 09:24:50 @monitor.py:363][0m wd_cost: 7.2704e-07
[32m[0324 09:24:50 @group.py:42][0m Callbacks took 114.000 sec in total. InferenceRunner: 113.390sec
[32m[0324 09:24:50 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15312/173481[03:00<30:59,85.07it/s]  9%|9         |16249/173481[03:10<30:48,85.07it/s] 18%|#8        |31287/173481[06:00<27:17,86.86it/s] 18%|#8        |32012/173481[06:10<27:08,86.86it/s] 25%|##5       |43674/173481[09:00<28:10,76.79it/s] 26%|##5       |44415/173481[09:10<28:00,76.79it/s] 32%|###2      |56094/173481[12:00<26:55,72.68it/s] 33%|###2      |56808/173481[12:10<26:45,72.68it/s] 40%|###9      |69018/173481[15:00<24:06,72.24it/s] 40%|####      |69762/173481[15:10<23:55,72.24it/s] 47%|####7     |82093/173481[18:00<21:01,72.44it/s] 48%|####7     |82893/173481[18:11<20:50,72.44it/s] 55%|#####4    |95255/173481[21:00<17:54,72.78it/s] 55%|#####5    |96005/173481[21:11<17:44,72.78it/s] 62%|######2   |108026/173481[24:00<15:10,71.85it/s] 63%|######2   |108834/173481[24:11<14:59,71.85it/s] 70%|######9   |121025/173481[27:00<12:08,72.03it/s] 70%|#######   |121784/173481[27:11<11:57,72.03it/s] 77%|#######6  |133554/173481[30:00<09:23,70.80it/s] 77%|#######7  |134388/173481[30:11<09:12,70.80it/s] 84%|########4 |146261/173481[33:00<06:25,70.70it/s] 85%|########4 |147120/173481[33:11<06:12,70.70it/s] 92%|#########1|158744/173481[36:00<03:30,70.02it/s] 92%|#########1|159564/173481[36:12<03:18,70.02it/s] 99%|#########9|171754/173481[39:00<00:24,71.13it/s] 99%|#########9|172498/173481[39:12<00:13,71.13it/s]100%|##########|173481/173481[39:29<00:00,73.22it/s]
[32m[0324 10:04:19 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:2369.24 sec.
[32m[0324 10:04:19 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-5204430.
[32m[0324 10:04:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 89%|########9 |16819/18822[03:00<00:21,93.44it/s] 94%|#########3|17634/18822[03:10<00:12,93.44it/s]100%|##########|18822/18822[03:25<00:00,91.75it/s]
29
[32m[0324 10:07:45 @monitor.py:363][0m QueueInput/queue_size: 1.6127
[32m[0324 10:07:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.002
[32m[0324 10:07:45 @monitor.py:363][0m activation-summaries/output-rms: 0.043678
[32m[0324 10:07:45 @monitor.py:363][0m cross_entropy_loss: 1.4462
[32m[0324 10:07:45 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59597
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33349
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32401
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31458
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 10:07:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 10:07:45 @monitor.py:363][0m train-error-top1: 0.39254
[32m[0324 10:07:45 @monitor.py:363][0m val-error-top1: 0.40823
[32m[0324 10:07:45 @monitor.py:363][0m val-utt-error: 0.087026
[32m[0324 10:07:45 @monitor.py:363][0m validation_cost: 1.5124
[32m[0324 10:07:45 @monitor.py:363][0m wd_cost: 7.2745e-07
[32m[0324 10:07:45 @group.py:42][0m Callbacks took 205.649 sec in total. InferenceRunner: 205.164sec
[32m[0324 10:07:45 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12874/173481[03:00<37:25,71.52it/s]  8%|7         |13519/173481[03:10<37:16,71.52it/s] 14%|#4        |24953/173481[06:00<35:45,69.24it/s] 15%|#4        |25583/173481[06:10<35:36,69.24it/s] 22%|##1       |37436/173481[09:00<32:43,69.29it/s] 22%|##1       |38120/173481[09:10<32:33,69.29it/s] 29%|##8       |50271/173481[12:00<29:13,70.28it/s] 29%|##9       |51156/173481[12:10<29:00,70.28it/s] 36%|###6      |63102/173481[15:00<25:59,70.78it/s] 37%|###6      |63910/173481[15:10<25:48,70.78it/s] 44%|####3     |75757/173481[18:00<23:05,70.54it/s] 44%|####4     |76454/173481[18:10<22:55,70.54it/s] 50%|#####     |87341/173481[21:00<21:19,67.30it/s] 51%|#####     |88070/173481[21:11<21:09,67.30it/s] 57%|#####6    |98800/173481[24:00<19:01,65.43it/s] 57%|#####7    |99540/173481[24:11<18:50,65.43it/s] 63%|######3   |110106/173481[27:00<16:28,64.08it/s] 64%|######3   |110752/173481[27:11<16:18,64.08it/s] 70%|#######   |121511/173481[30:00<13:35,63.72it/s] 70%|#######   |122255/173481[30:11<13:23,63.72it/s] 76%|#######6  |132686/173481[33:00<10:48,62.89it/s] 77%|#######6  |133403/173481[33:11<10:37,62.89it/s] 83%|########2 |143766/173481[36:00<07:57,62.21it/s] 83%|########3 |144457/173481[36:11<07:46,62.21it/s] 89%|########9 |154504/173481[39:00<05:11,60.91it/s] 89%|########9 |155222/173481[39:12<04:59,60.91it/s] 96%|#########5|166080/173481[42:00<01:58,62.56it/s] 96%|#########6|166868/173481[42:12<01:45,62.56it/s]100%|##########|173481/173481[43:53<00:00,65.88it/s]
[32m[0324 10:51:38 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:2633.38 sec.
[32m[0324 10:51:38 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-5377911.
  0%|          |0/18822[00:00<?,?it/s] 95%|#########5|17906/18822[03:00<00:09,99.48it/s] 99%|#########9|18685/18822[03:10<00:01,99.48it/s]100%|##########|18822/18822[03:11<00:00,98.12it/s]
30
[32m[0324 10:54:50 @monitor.py:363][0m QueueInput/queue_size: 1.6506
[32m[0324 10:54:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.907
[32m[0324 10:54:50 @monitor.py:363][0m activation-summaries/output-rms: 0.042415
[32m[0324 10:54:50 @monitor.py:363][0m cross_entropy_loss: 1.4547
[32m[0324 10:54:50 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59611
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33352
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32402
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31458
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 10:54:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 10:54:50 @monitor.py:363][0m train-error-top1: 0.39141
[32m[0324 10:54:50 @monitor.py:363][0m val-error-top1: 0.40713
[32m[0324 10:54:50 @monitor.py:363][0m val-utt-error: 0.086016
[32m[0324 10:54:50 @monitor.py:363][0m validation_cost: 1.5106
[32m[0324 10:54:50 @monitor.py:363][0m wd_cost: 1.4553e-07
[32m[0324 10:54:50 @group.py:42][0m Callbacks took 192.260 sec in total. InferenceRunner: 191.926sec
[32m[0324 10:54:50 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12633/173481[03:00<38:11,70.18it/s]  8%|7         |13476/173481[03:10<37:59,70.18it/s] 15%|#4        |25185/173481[06:00<35:19,69.95it/s] 15%|#4        |25900/173481[06:10<35:09,69.95it/s] 22%|##1       |37748/173481[09:00<32:22,69.87it/s] 22%|##2       |38414/173481[09:10<32:13,69.87it/s] 29%|##8       |50272/173481[12:00<29:27,69.72it/s] 29%|##9       |51069/173481[12:10<29:15,69.72it/s] 36%|###6      |63093/173481[15:00<26:06,70.46it/s] 37%|###6      |63843/173481[15:10<25:55,70.46it/s] 43%|####2     |74285/173481[18:00<25:01,66.06it/s] 43%|####3     |74931/173481[18:11<24:51,66.06it/s] 49%|####9     |85405/173481[21:00<22:59,63.85it/s] 50%|####9     |86114/173481[21:11<22:48,63.85it/s] 56%|#####5    |96759/173481[24:00<20:09,63.46it/s] 56%|#####6    |97440/173481[24:11<19:58,63.46it/s] 63%|######2   |108680/173481[27:00<16:39,64.81it/s] 63%|######3   |109488/173481[27:11<16:27,64.81it/s] 70%|######9   |120613/173481[30:00<13:26,65.54it/s] 70%|######9   |121372/173481[30:11<13:15,65.54it/s] 76%|#######6  |132424/173481[33:00<10:26,65.58it/s] 77%|#######6  |133329/173481[33:11<10:12,65.58it/s] 84%|########3 |144873/173481[36:00<07:04,67.32it/s] 84%|########3 |145722/173481[36:11<06:52,67.32it/s] 92%|#########1|158803/173481[39:00<03:23,72.00it/s] 92%|#########2|160026/173481[39:13<03:06,72.00it/s] 99%|#########8|171548/173481[42:00<00:27,71.40it/s] 99%|#########9|172420/173481[42:13<00:14,71.40it/s]100%|##########|173481/173481[42:31<00:00,68.00it/s]
[32m[0324 11:37:22 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:2551.18 sec.
[32m[0324 11:37:22 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s] 87%|########6 |16361/18822[03:00<00:27,90.89it/s] 91%|#########1|17188/18822[03:10<00:17,90.89it/s]100%|##########|18822/18822[03:31<00:00,88.97it/s]
31
[32m[0324 11:40:53 @monitor.py:363][0m QueueInput/queue_size: 1.0471
[32m[0324 11:40:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.137
[32m[0324 11:40:53 @monitor.py:363][0m activation-summaries/output-rms: 0.042897
[32m[0324 11:40:53 @monitor.py:363][0m cross_entropy_loss: 1.4846
[32m[0324 11:40:53 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59626
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.205
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33356
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32403
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31458
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 11:40:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 11:40:53 @monitor.py:363][0m train-error-top1: 0.40339
[32m[0324 11:40:53 @monitor.py:363][0m val-error-top1: 0.40733
[32m[0324 11:40:53 @monitor.py:363][0m val-utt-error: 0.085379
[32m[0324 11:40:53 @monitor.py:363][0m validation_cost: 1.5094
[32m[0324 11:40:53 @monitor.py:363][0m wd_cost: 1.4556e-07
[32m[0324 11:40:53 @group.py:42][0m Callbacks took 211.817 sec in total. InferenceRunner: 211.567sec
[32m[0324 11:40:53 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12563/173481[03:00<38:25,69.79it/s]  8%|7         |13183/173481[03:10<38:16,69.79it/s] 14%|#4        |24936/173481[06:00<35:44,69.26it/s] 15%|#4        |25715/173481[06:10<35:33,69.26it/s] 22%|##1       |37358/173481[09:00<32:48,69.13it/s] 22%|##1       |38078/173481[09:10<32:38,69.13it/s] 29%|##8       |49991/173481[12:00<29:32,69.65it/s] 29%|##9       |50811/173481[12:10<29:21,69.65it/s] 36%|###6      |62578/173481[15:00<26:29,69.79it/s] 37%|###6      |63368/173481[15:10<26:17,69.79it/s] 43%|####3     |75231/173481[18:00<23:22,70.04it/s] 44%|####3     |75872/173481[18:11<23:13,70.04it/s] 50%|#####     |86814/173481[21:00<21:32,67.07it/s] 50%|#####     |87600/173481[21:11<21:20,67.07it/s] 57%|#####6    |98422/173481[24:00<19:01,65.75it/s] 57%|#####7    |99136/173481[24:11<18:50,65.75it/s] 63%|######3   |109578/173481[27:00<16:41,63.81it/s] 64%|######3   |110321/173481[27:11<16:29,63.81it/s] 70%|#######   |121790/173481[30:00<13:06,65.76it/s] 71%|#######   |122652/173481[30:11<12:52,65.76it/s] 78%|#######7  |134914/173481[33:00<09:17,69.15it/s] 78%|#######8  |135843/173481[33:11<09:04,69.15it/s] 85%|########5 |147865/173481[36:00<06:03,70.52it/s] 86%|########5 |148674/173481[36:12<05:51,70.52it/s] 93%|#########2|160861/173481[39:00<02:56,71.35it/s] 93%|#########3|161706/173481[39:12<02:45,71.35it/s] 99%|#########9|172406/173481[42:00<00:15,67.55it/s]100%|#########9|173180/173481[42:12<00:04,67.55it/s]100%|##########|173481/173481[42:17<00:00,68.38it/s]
[32m[0324 12:23:11 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:2537.17 sec.
[32m[0324 12:23:11 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-5724873.
  0%|          |0/18822[00:00<?,?it/s] 89%|########9 |16786/18822[03:00<00:21,93.25it/s] 93%|#########3|17582/18822[03:10<00:13,93.25it/s]100%|##########|18822/18822[03:24<00:00,92.23it/s]
32
[32m[0324 12:26:35 @monitor.py:363][0m QueueInput/queue_size: 20.209
[32m[0324 12:26:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.987
[32m[0324 12:26:35 @monitor.py:363][0m activation-summaries/output-rms: 0.042924
[32m[0324 12:26:35 @monitor.py:363][0m cross_entropy_loss: 1.4936
[32m[0324 12:26:35 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59634
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.205
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33359
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 12:26:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 12:26:35 @monitor.py:363][0m train-error-top1: 0.41408
[32m[0324 12:26:35 @monitor.py:363][0m val-error-top1: 0.40729
[32m[0324 12:26:35 @monitor.py:363][0m val-utt-error: 0.085432
[32m[0324 12:26:35 @monitor.py:363][0m validation_cost: 1.5094
[32m[0324 12:26:35 @monitor.py:363][0m wd_cost: 1.4559e-07
[32m[0324 12:26:35 @group.py:42][0m Callbacks took 204.352 sec in total. InferenceRunner: 204.158sec
[32m[0324 12:26:35 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12556/173481[03:00<38:27,69.75it/s]  8%|7         |13199/173481[03:10<38:17,69.75it/s] 14%|#4        |25097/173481[06:00<35:28,69.71it/s] 15%|#4        |25930/173481[06:10<35:16,69.71it/s] 22%|##1       |37705/173481[09:00<32:23,69.87it/s] 22%|##2       |38394/173481[09:10<32:13,69.87it/s] 29%|##8       |50126/173481[12:00<29:36,69.44it/s] 29%|##9       |50905/173481[12:10<29:25,69.44it/s] 36%|###5      |62404/173481[15:00<26:54,68.82it/s] 36%|###6      |63167/173481[15:10<26:42,68.82it/s] 43%|####3     |75171/173481[18:00<23:27,69.85it/s] 44%|####3     |75842/173481[18:10<23:17,69.85it/s] 53%|#####3    |92120/173481[21:00<16:54,80.21it/s] 54%|#####3    |93092/173481[21:11<16:42,80.21it/s] 60%|######    |104204/173481[24:00<15:47,73.09it/s] 61%|######    |104976/173481[24:11<15:37,73.09it/s] 67%|######6   |115779/173481[27:00<14:03,68.41it/s] 67%|######7   |116488/173481[27:11<13:53,68.41it/s] 73%|#######3  |126882/173481[30:00<11:58,64.87it/s] 74%|#######3  |127582/173481[30:11<11:47,64.87it/s] 80%|########  |138798/173481[33:00<08:49,65.53it/s] 80%|########  |139572/173481[33:11<08:37,65.53it/s] 87%|########6 |150562/173481[36:00<05:50,65.44it/s] 87%|########7 |151422/173481[36:11<05:37,65.44it/s] 93%|#########3|162193/173481[39:00<02:53,65.02it/s] 94%|#########3|162942/173481[39:12<02:42,65.02it/s]100%|#########9|173183/173481[42:00<00:04,62.97it/s]100%|##########|173481/173481[42:05<00:00,68.70it/s]
[32m[0324 13:08:40 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:2525.36 sec.
[32m[0324 13:08:40 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,171.39it/s]
33
[32m[0324 13:10:30 @monitor.py:363][0m QueueInput/queue_size: 0.66456
[32m[0324 13:10:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.111
[32m[0324 13:10:30 @monitor.py:363][0m activation-summaries/output-rms: 0.042817
[32m[0324 13:10:30 @monitor.py:363][0m cross_entropy_loss: 1.4378
[32m[0324 13:10:30 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59631
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3336
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 13:10:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 13:10:30 @monitor.py:363][0m train-error-top1: 0.39668
[32m[0324 13:10:30 @monitor.py:363][0m val-error-top1: 0.40691
[32m[0324 13:10:30 @monitor.py:363][0m val-utt-error: 0.085591
[32m[0324 13:10:30 @monitor.py:363][0m validation_cost: 1.5105
[32m[0324 13:10:30 @monitor.py:363][0m wd_cost: 2.9118e-08
[32m[0324 13:10:30 @group.py:42][0m Callbacks took 110.031 sec in total. InferenceRunner: 109.835sec
[32m[0324 13:10:30 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16053/173481[03:00<29:25,89.18it/s] 10%|9         |16913/173481[03:10<29:15,89.18it/s] 18%|#8        |31269/173481[06:00<27:18,86.79it/s] 18%|#8        |31919/173481[06:10<27:11,86.79it/s] 25%|##4       |42837/173481[09:00<29:29,73.84it/s] 25%|##5       |43521/173481[09:10<29:19,73.84it/s] 32%|###1      |55398/173481[12:00<27:25,71.75it/s] 32%|###2      |56200/173481[12:10<27:14,71.75it/s] 40%|####      |69901/173481[15:00<22:44,75.91it/s] 41%|####      |70861/173481[15:10<22:31,75.91it/s] 50%|####9     |85946/173481[18:00<17:47,81.99it/s] 50%|#####     |86908/173481[18:10<17:35,81.99it/s] 59%|#####8    |102016/173481[21:00<13:56,85.48it/s] 59%|#####9    |102986/173481[21:10<13:44,85.48it/s] 66%|######6   |115047/173481[24:00<12:25,78.39it/s] 67%|######6   |115736/173481[24:11<12:16,78.39it/s] 73%|#######2  |126343/173481[27:00<11:16,69.71it/s] 73%|#######3  |127054/173481[27:11<11:06,69.71it/s] 80%|#######9  |138122/173481[30:00<08:43,67.50it/s] 80%|########  |138816/173481[30:11<08:33,67.50it/s] 86%|########6 |149531/173481[33:00<06:06,65.38it/s] 87%|########6 |150251/173481[33:11<05:55,65.38it/s] 93%|#########2|160995/173481[36:00<03:13,64.52it/s] 93%|#########3|161712/173481[36:11<03:02,64.52it/s] 99%|#########9|172265/173481[39:00<00:19,63.55it/s]100%|#########9|172987/173481[39:11<00:07,63.55it/s]100%|##########|173481/173481[39:20<00:00,73.51it/s]
[32m[0324 13:49:50 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:2360.03 sec.
[32m[0324 13:49:51 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-6071835.
[32m[0324 13:49:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,182.88it/s]
34
[32m[0324 13:51:34 @monitor.py:363][0m QueueInput/queue_size: 0.57263
[32m[0324 13:51:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.115
[32m[0324 13:51:34 @monitor.py:363][0m activation-summaries/output-rms: 0.043674
[32m[0324 13:51:34 @monitor.py:363][0m cross_entropy_loss: 1.4459
[32m[0324 13:51:34 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59629
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33362
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32405
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30303
[32m[0324 13:51:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 13:51:34 @monitor.py:363][0m train-error-top1: 0.39438
[32m[0324 13:51:34 @monitor.py:363][0m val-error-top1: 0.40824
[32m[0324 13:51:34 @monitor.py:363][0m val-utt-error: 0.086388
[32m[0324 13:51:34 @monitor.py:363][0m validation_cost: 1.5122
[32m[0324 13:51:34 @monitor.py:363][0m wd_cost: 2.9118e-08
[32m[0324 13:51:34 @group.py:42][0m Callbacks took 103.883 sec in total. InferenceRunner: 102.933sec
[32m[0324 13:51:34 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12783/173481[03:00<37:42,71.01it/s]  8%|7         |13460/173481[03:10<37:33,71.01it/s] 14%|#3        |24213/173481[06:00<37:06,67.05it/s] 14%|#4        |24850/173481[06:10<36:56,67.05it/s] 20%|#9        |34496/173481[09:00<37:33,61.68it/s] 20%|##        |35016/173481[09:10<37:24,61.68it/s] 25%|##5       |43661/173481[12:00<38:47,55.78it/s] 25%|##5       |44220/173481[12:10<38:37,55.78it/s] 30%|###       |52833/173481[15:00<37:45,53.26it/s] 31%|###       |53361/173481[15:10<37:35,53.26it/s] 36%|###6      |62941/173481[18:00<33:41,54.67it/s] 37%|###6      |63616/173481[18:10<33:29,54.67it/s] 43%|####2     |73899/173481[21:00<28:48,57.61it/s] 43%|####2     |74545/173481[21:11<28:37,57.61it/s] 49%|####9     |85526/173481[24:00<24:04,60.90it/s] 50%|####9     |86201/173481[24:11<23:53,60.90it/s] 56%|#####5    |97131/173481[27:00<20:19,62.63it/s] 56%|#####6    |97865/173481[27:11<20:07,62.63it/s] 62%|######2   |108346/173481[30:00<17:22,62.46it/s] 63%|######2   |109090/173481[30:11<17:10,62.46it/s] 69%|######9   |119936/173481[33:00<14:04,63.41it/s] 70%|######9   |120683/173481[33:11<13:52,63.41it/s] 76%|#######5  |131216/173481[36:00<11:10,63.03it/s] 76%|#######6  |131935/173481[36:11<10:59,63.03it/s] 82%|########2 |142361/173481[39:00<08:18,62.47it/s] 82%|########2 |143081/173481[39:11<08:06,62.47it/s] 88%|########8 |153159/173481[42:00<05:32,61.20it/s] 89%|########8 |153880/173481[42:12<05:20,61.20it/s] 95%|#########5|164919/173481[45:00<02:15,63.20it/s] 96%|#########5|165816/173481[45:12<02:01,63.20it/s]100%|##########|173481/173481[47:08<00:00,61.33it/s]
[32m[0324 14:38:43 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:2828.64 sec.
[32m[0324 14:38:43 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,186.03it/s]
35
[32m[0324 14:40:24 @monitor.py:363][0m QueueInput/queue_size: 0.70455
[32m[0324 14:40:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.995
[32m[0324 14:40:24 @monitor.py:363][0m activation-summaries/output-rms: 0.0424
[32m[0324 14:40:24 @monitor.py:363][0m cross_entropy_loss: 1.454
[32m[0324 14:40:24 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59618
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33362
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32405
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30303
[32m[0324 14:40:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 14:40:24 @monitor.py:363][0m train-error-top1: 0.39159
[32m[0324 14:40:24 @monitor.py:363][0m val-error-top1: 0.40701
[32m[0324 14:40:24 @monitor.py:363][0m val-utt-error: 0.085273
[32m[0324 14:40:24 @monitor.py:363][0m validation_cost: 1.5099
[32m[0324 14:40:24 @monitor.py:363][0m wd_cost: 5.8231e-09
[32m[0324 14:40:24 @group.py:42][0m Callbacks took 101.446 sec in total. InferenceRunner: 101.189sec
[32m[0324 14:40:24 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13482/173481[03:00<35:36,74.90it/s]  8%|8         |14184/173481[03:10<35:26,74.90it/s] 15%|#4        |25170/173481[06:00<35:32,69.56it/s] 15%|#4        |25764/173481[06:10<35:23,69.56it/s] 20%|##        |35551/173481[09:00<36:27,63.06it/s] 21%|##        |36142/173481[09:10<36:17,63.06it/s] 26%|##6       |45957/173481[12:00<35:14,60.32it/s] 27%|##6       |46579/173481[12:10<35:03,60.32it/s] 33%|###2      |56555/173481[15:00<32:42,59.58it/s] 33%|###2      |57189/173481[15:10<32:31,59.58it/s] 39%|###8      |67195/173481[18:00<29:51,59.34it/s] 39%|###9      |67840/173481[18:10<29:40,59.34it/s] 45%|####4     |78020/173481[21:00<26:38,59.74it/s] 45%|####5     |78664/173481[21:10<26:27,59.74it/s] 51%|#####1    |89096/173481[24:00<23:12,60.62it/s] 52%|#####1    |89744/173481[24:11<23:01,60.62it/s] 58%|#####7    |100141/173481[27:00<20:02,60.99it/s] 58%|#####8    |100869/173481[27:11<19:50,60.99it/s] 64%|######4   |111695/173481[30:00<16:27,62.54it/s] 65%|######4   |112386/173481[30:11<16:16,62.54it/s] 71%|#######   |122476/173481[33:00<13:53,61.19it/s] 71%|#######   |123149/173481[33:11<13:42,61.19it/s] 77%|#######6  |133233/173481[36:00<11:05,60.47it/s] 77%|#######7  |133899/173481[36:11<10:54,60.47it/s] 83%|########2 |143715/173481[39:00<08:21,59.32it/s] 83%|########3 |144431/173481[39:11<08:09,59.32it/s] 89%|########9 |154750/173481[42:00<05:10,60.30it/s] 90%|########9 |155442/173481[42:11<04:59,60.30it/s] 95%|#########5|165511/173481[45:00<02:12,60.04it/s] 96%|#########5|166235/173481[45:12<02:00,60.04it/s]100%|##########|173481/173481[47:13<00:00,61.22it/s]
[32m[0324 15:27:38 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:2833.91 sec.
[32m[0324 15:27:38 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:43<00:00,182.66it/s]
36
[32m[0324 15:29:22 @monitor.py:363][0m QueueInput/queue_size: 0.76836
[32m[0324 15:29:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.193
[32m[0324 15:29:22 @monitor.py:363][0m activation-summaries/output-rms: 0.042894
[32m[0324 15:29:22 @monitor.py:363][0m cross_entropy_loss: 1.4839
[32m[0324 15:29:22 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59601
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2048
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32405
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30303
[32m[0324 15:29:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 15:29:22 @monitor.py:363][0m train-error-top1: 0.40361
[32m[0324 15:29:22 @monitor.py:363][0m val-error-top1: 0.40718
[32m[0324 15:29:22 @monitor.py:363][0m val-utt-error: 0.085007
[32m[0324 15:29:22 @monitor.py:363][0m validation_cost: 1.5087
[32m[0324 15:29:22 @monitor.py:363][0m wd_cost: 5.822e-09
[32m[0324 15:29:22 @group.py:42][0m Callbacks took 103.302 sec in total. InferenceRunner: 103.058sec
[32m[0324 15:29:22 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14997/173481[03:00<31:42,83.32it/s]  9%|9         |15653/173481[03:10<31:34,83.32it/s] 16%|#5        |26915/173481[06:00<33:06,73.78it/s] 16%|#5        |27503/173481[06:10<32:58,73.78it/s] 22%|##1       |37499/173481[09:00<34:37,65.44it/s] 22%|##1       |38133/173481[09:10<34:28,65.44it/s] 28%|##7       |48097/173481[12:00<33:42,61.99it/s] 28%|##8       |48708/173481[12:10<33:32,61.99it/s] 34%|###3      |58418/173481[15:00<32:11,59.57it/s] 34%|###4      |59049/173481[15:10<32:00,59.57it/s] 40%|###9      |69125/173481[18:00<29:13,59.53it/s] 40%|####      |69840/173481[18:10<29:01,59.53it/s] 47%|####6     |80854/173481[21:00<24:48,62.21it/s] 47%|####7     |81578/173481[21:11<24:37,62.21it/s] 53%|#####3    |92324/173481[24:00<21:29,62.95it/s] 54%|#####3    |93020/173481[24:11<21:18,62.95it/s] 60%|#####9    |103313/173481[27:00<18:51,61.99it/s] 60%|#####9    |103993/173481[27:11<18:41,61.99it/s] 66%|######6   |114810/173481[30:00<15:32,62.91it/s] 67%|######6   |115733/173481[30:11<15:17,62.91it/s] 73%|#######2  |126559/173481[33:00<12:12,64.06it/s] 73%|#######3  |127291/173481[33:11<12:01,64.06it/s] 80%|#######9  |137926/173481[36:00<09:19,63.60it/s] 80%|#######9  |138633/173481[36:11<09:07,63.60it/s] 86%|########6 |149284/173481[39:00<06:21,63.35it/s] 86%|########6 |150038/173481[39:11<06:10,63.35it/s] 93%|#########3|162101/173481[42:00<02:49,67.05it/s] 94%|#########4|163390/173481[42:12<02:30,67.05it/s]100%|##########|173481/173481[44:43<00:00,64.66it/s]
[32m[0324 16:14:05 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:2683.11 sec.
[32m[0324 16:14:05 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-6592278.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.27it/s]
37
[32m[0324 16:15:50 @monitor.py:363][0m QueueInput/queue_size: 0.56592
[32m[0324 16:15:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.02
[32m[0324 16:15:50 @monitor.py:363][0m activation-summaries/output-rms: 0.042893
[32m[0324 16:15:50 @monitor.py:363][0m cross_entropy_loss: 1.4939
[32m[0324 16:15:50 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59585
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2048
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32405
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 16:15:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 16:15:50 @monitor.py:363][0m train-error-top1: 0.41426
[32m[0324 16:15:50 @monitor.py:363][0m val-error-top1: 0.40728
[32m[0324 16:15:50 @monitor.py:363][0m val-utt-error: 0.085432
[32m[0324 16:15:50 @monitor.py:363][0m validation_cost: 1.5093
[32m[0324 16:15:50 @monitor.py:363][0m wd_cost: 5.821e-09
[32m[0324 16:15:50 @group.py:42][0m Callbacks took 105.230 sec in total. InferenceRunner: 105.005sec
[32m[0324 16:15:50 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12037/173481[03:00<40:14,66.87it/s]  7%|7         |12603/173481[03:10<40:05,66.87it/s] 13%|#3        |22697/173481[06:00<40:00,62.81it/s] 13%|#3        |23277/173481[06:10<39:51,62.81it/s] 19%|#8        |32802/173481[09:00<39:32,59.29it/s] 19%|#9        |33318/173481[09:10<39:24,59.29it/s] 25%|##5       |43473/173481[12:00<36:32,59.28it/s] 25%|##5       |44176/173481[12:10<36:21,59.28it/s] 31%|###1      |54215/173481[15:00<33:25,59.48it/s] 32%|###1      |54817/173481[15:10<33:15,59.48it/s] 37%|###7      |64498/173481[18:00<31:10,58.28it/s] 38%|###7      |65244/173481[18:11<30:57,58.28it/s] 44%|####3     |75573/173481[21:00<27:15,59.86it/s] 44%|####3     |76177/173481[21:11<27:05,59.86it/s] 50%|####9     |85952/173481[24:00<24:50,58.74it/s] 50%|####9     |86612/173481[24:11<24:38,58.74it/s] 55%|#####5    |96110/173481[27:00<22:24,57.56it/s] 56%|#####5    |96764/173481[27:11<22:12,57.56it/s] 61%|######1   |106423/173481[30:00<19:27,57.42it/s] 62%|######1   |107080/173481[30:11<19:16,57.42it/s] 67%|######7   |116556/173481[33:00<16:41,56.85it/s] 68%|######7   |117227/173481[33:11<16:29,56.85it/s] 73%|#######3  |127207/173481[36:00<13:18,57.99it/s] 74%|#######3  |127898/173481[36:12<13:06,57.99it/s] 79%|#######9  |137660/173481[39:00<10:17,58.03it/s] 80%|#######9  |138372/173481[39:12<10:05,58.03it/s] 85%|########5 |147927/173481[42:00<07:24,57.53it/s] 86%|########5 |148664/173481[42:12<07:11,57.53it/s] 91%|#########1|158032/173481[45:00<04:31,56.82it/s] 91%|#########1|158726/173481[45:12<04:19,56.82it/s] 97%|#########6|168104/173481[48:00<01:35,56.38it/s] 97%|#########7|168812/173481[48:12<01:22,56.38it/s]100%|##########|173481/173481[49:40<00:00,58.21it/s]
[32m[0324 17:05:30 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:2980.42 sec.
[32m[0324 17:05:30 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s] 80%|########  |15095/18822[03:00<00:44,83.85it/s] 85%|########4 |15978/18822[03:10<00:33,83.85it/s]100%|##########|18822/18822[03:40<00:00,85.41it/s]
38
[32m[0324 17:09:11 @monitor.py:363][0m QueueInput/queue_size: 0.66565
[32m[0324 17:09:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.109
[32m[0324 17:09:11 @monitor.py:363][0m activation-summaries/output-rms: 0.042788
[32m[0324 17:09:11 @monitor.py:363][0m cross_entropy_loss: 1.4375
[32m[0324 17:09:11 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59563
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2048
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32405
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 17:09:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 17:09:11 @monitor.py:363][0m train-error-top1: 0.39553
[32m[0324 17:09:11 @monitor.py:363][0m val-error-top1: 0.40695
[32m[0324 17:09:11 @monitor.py:363][0m val-utt-error: 0.085963
[32m[0324 17:09:11 @monitor.py:363][0m validation_cost: 1.5101
[32m[0324 17:09:11 @monitor.py:363][0m wd_cost: 1.1639e-09
[32m[0324 17:09:11 @group.py:42][0m Callbacks took 220.527 sec in total. InferenceRunner: 220.386sec
[32m[0324 17:09:11 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11051/173481[03:00<44:05,61.39it/s]  7%|6         |11682/173481[03:10<43:55,61.39it/s] 13%|#2        |22148/173481[06:00<40:59,61.52it/s] 13%|#3        |22753/173481[06:10<40:50,61.52it/s] 19%|#8        |32933/173481[09:00<38:35,60.71it/s] 19%|#9        |33623/173481[09:10<38:23,60.71it/s] 26%|##5       |44275/173481[12:00<34:49,61.84it/s] 26%|##5       |44422/173481[12:31<34:47,61.84it/s] 31%|###1      |54360/173481[15:00<33:46,58.79it/s] 32%|###1      |55137/173481[15:12<33:33,58.79it/s] 38%|###8      |66378/173481[18:00<28:33,62.52it/s] 39%|###8      |67111/173481[18:12<28:21,62.52it/s] 44%|####4     |76883/173481[21:00<26:40,60.37it/s] 45%|####4     |77606/173481[21:12<26:28,60.37it/s] 50%|#####     |87421/173481[24:00<24:07,59.44it/s] 51%|#####     |88152/173481[24:12<23:55,59.44it/s] 56%|#####6    |97908/173481[27:00<21:24,58.84it/s] 57%|#####6    |98636/173481[27:12<21:11,58.84it/s] 62%|######2   |108258/173481[30:00<18:41,58.16it/s] 63%|######2   |109013/173481[30:12<18:28,58.16it/s] 68%|######8   |118717/173481[33:00<15:42,58.13it/s] 69%|######8   |119486/173481[33:13<15:28,58.13it/s] 74%|#######4  |129120/173481[36:00<12:45,57.96it/s] 75%|#######4  |129884/173481[36:13<12:32,57.96it/s] 80%|########  |139534/173481[39:00<09:46,57.91it/s] 81%|########  |140303/173481[39:13<09:32,57.91it/s] 86%|########6 |150022/173481[42:00<06:43,58.08it/s] 87%|########6 |150792/173481[42:13<06:30,58.08it/s] 93%|#########2|160831/173481[45:00<03:34,59.05it/s] 93%|#########3|161647/173481[45:13<03:20,59.05it/s] 99%|#########8|171299/173481[48:00<00:37,58.59it/s] 99%|#########9|172111/173481[48:13<00:23,58.59it/s]100%|##########|173481/173481[48:38<00:00,59.45it/s]
[32m[0324 17:57:49 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:2918.18 sec.
[32m[0324 17:57:50 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-6939240.
  0%|          |0/18822[00:00<?,?it/s] 90%|######### |17001/18822[03:00<00:19,94.45it/s] 95%|#########4|17798/18822[03:10<00:10,94.45it/s]100%|##########|18822/18822[03:21<00:00,93.32it/s]
39
[32m[0324 18:01:11 @monitor.py:363][0m QueueInput/queue_size: 0.76815
[32m[0324 18:01:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.088
[32m[0324 18:01:11 @monitor.py:363][0m activation-summaries/output-rms: 0.04364
[32m[0324 18:01:11 @monitor.py:363][0m cross_entropy_loss: 1.4453
[32m[0324 18:01:11 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59539
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2048
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32405
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 18:01:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 18:01:11 @monitor.py:363][0m train-error-top1: 0.39337
[32m[0324 18:01:11 @monitor.py:363][0m val-error-top1: 0.40809
[32m[0324 18:01:11 @monitor.py:363][0m val-utt-error: 0.08676
[32m[0324 18:01:11 @monitor.py:363][0m validation_cost: 1.5116
[32m[0324 18:01:11 @monitor.py:363][0m wd_cost: 1.1636e-09
[32m[0324 18:01:11 @group.py:42][0m Callbacks took 202.425 sec in total. InferenceRunner: 201.773sec
[32m[0324 18:01:11 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11701/173481[03:00<41:28,65.00it/s]  7%|7         |12351/173481[03:11<41:18,65.00it/s] 14%|#3        |23922/173481[06:00<37:31,66.41it/s] 14%|#4        |24717/173481[06:11<37:19,66.41it/s] 21%|##        |35775/173481[09:00<34:42,66.13it/s] 21%|##1       |36442/173481[09:11<34:32,66.13it/s] 26%|##6       |45841/173481[12:00<35:06,60.60it/s] 27%|##6       |46431/173481[12:11<34:56,60.60it/s] 32%|###1      |55013/173481[15:00<35:40,55.36it/s] 32%|###2      |55689/173481[15:11<35:27,55.36it/s] 38%|###7      |65468/173481[18:00<31:45,56.69it/s] 38%|###8      |66188/173481[18:12<31:32,56.69it/s] 43%|####3     |75178/173481[21:00<29:38,55.28it/s] 44%|####3     |75850/173481[21:12<29:26,55.28it/s] 49%|####8     |84921/173481[24:00<26:59,54.70it/s] 49%|####9     |85528/173481[24:12<26:48,54.70it/s] 54%|#####4    |94091/173481[27:00<25:04,52.75it/s] 55%|#####4    |94732/173481[27:12<24:52,52.75it/s] 60%|#####9    |103251/173481[30:00<22:35,51.80it/s] 60%|#####9    |103958/173481[30:12<22:22,51.80it/s] 65%|######5   |112775/173481[33:00<19:19,52.35it/s] 65%|######5   |113383/173481[33:12<19:07,52.35it/s] 70%|#######   |122191/173481[36:00<16:20,52.33it/s] 71%|#######   |122886/173481[36:13<16:06,52.33it/s] 76%|#######5  |131311/173481[39:00<13:39,51.48it/s] 76%|#######6  |131956/173481[39:13<13:26,51.48it/s] 81%|########1 |140665/173481[42:00<10:34,51.72it/s] 81%|########1 |141324/173481[42:13<10:21,51.72it/s] 86%|########6 |149891/173481[45:00<07:38,51.48it/s] 87%|########6 |150629/173481[45:13<07:23,51.48it/s] 92%|#########2|159696/173481[48:00<04:20,52.93it/s] 92%|#########2|160405/173481[48:13<04:07,52.93it/s] 98%|#########7|169476/173481[51:00<01:14,53.62it/s] 98%|#########8|170225/173481[51:13<01:00,53.62it/s]100%|##########|173481/173481[52:13<00:00,55.37it/s]
[32m[0324 18:53:25 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:3133.03 sec.
[32m[0324 18:53:25 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########9|18695/18822[03:00<00:01,103.86it/s]100%|##########|18822/18822[03:00<00:00,104.14it/s]
40
[32m[0324 18:56:26 @monitor.py:363][0m QueueInput/queue_size: 0.85106
[32m[0324 18:56:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.95
[32m[0324 18:56:26 @monitor.py:363][0m activation-summaries/output-rms: 0.042385
[32m[0324 18:56:26 @monitor.py:363][0m cross_entropy_loss: 1.4538
[32m[0324 18:56:26 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59515
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 18:56:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 18:56:26 @monitor.py:363][0m train-error-top1: 0.39077
[32m[0324 18:56:26 @monitor.py:363][0m val-error-top1: 0.40697
[32m[0324 18:56:26 @monitor.py:363][0m val-utt-error: 0.085698
[32m[0324 18:56:26 @monitor.py:363][0m validation_cost: 1.5097
[32m[0324 18:56:26 @monitor.py:363][0m wd_cost: 1.1633e-09
[32m[0324 18:56:26 @group.py:42][0m Callbacks took 181.114 sec in total. InferenceRunner: 180.800sec
[32m[0324 18:56:26 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11745/173481[03:00<41:18,65.25it/s]  7%|7         |12299/173481[03:10<41:10,65.25it/s] 12%|#2        |21499/173481[06:00<42:46,59.21it/s] 13%|#2        |22054/173481[06:10<42:37,59.21it/s] 18%|#8        |31385/173481[09:00<41:33,56.98it/s] 18%|#8        |31924/173481[09:10<41:24,56.98it/s] 23%|##2       |39847/173481[12:00<43:13,51.52it/s] 23%|##3       |40332/173481[12:10<43:04,51.52it/s] 28%|##7       |48181/173481[15:00<42:49,48.77it/s] 28%|##8       |48694/173481[15:10<42:38,48.77it/s] 33%|###2      |57057/173481[18:00<39:34,49.04it/s] 33%|###3      |57609/173481[18:11<39:22,49.04it/s] 38%|###8      |66492/173481[21:00<35:11,50.67it/s] 39%|###8      |67106/173481[21:11<34:59,50.67it/s] 44%|####4     |76460/173481[24:00<30:33,52.91it/s] 44%|####4     |77052/173481[24:11<30:22,52.91it/s] 50%|####9     |86280/173481[27:00<27:03,53.72it/s] 50%|#####     |86899/173481[27:11<26:51,53.72it/s] 55%|#####5    |96269/173481[30:00<23:34,54.59it/s] 56%|#####5    |96909/173481[30:11<23:22,54.59it/s] 61%|######1   |106239/173481[33:00<20:22,54.99it/s] 62%|######1   |106885/173481[33:11<20:11,54.99it/s] 67%|######6   |115764/173481[36:00<17:50,53.93it/s] 67%|######7   |116331/173481[36:12<17:39,53.93it/s] 72%|#######1  |124888/173481[39:00<15:29,52.26it/s] 72%|#######2  |125484/173481[39:12<15:18,52.26it/s] 77%|#######7  |133875/173481[42:00<12:55,51.06it/s] 78%|#######7  |134479/173481[42:12<12:43,51.06it/s] 82%|########2 |142765/173481[45:00<10:11,50.20it/s] 83%|########2 |143385/173481[45:12<09:59,50.20it/s] 87%|########7 |151728/173481[48:00<07:15,49.99it/s] 88%|########7 |152366/173481[48:12<07:02,49.99it/s] 93%|#########2|160768/173481[51:00<04:13,50.11it/s] 93%|#########3|161371/173481[51:12<04:01,50.11it/s] 98%|#########7|169599/173481[54:00<01:18,49.58it/s] 98%|#########8|170224/173481[54:12<01:05,49.58it/s]100%|##########|173481/173481[55:15<00:00,52.32it/s]
[32m[0324 19:51:42 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3315.78 sec.
[32m[0324 19:51:42 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-7286202.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########8|18493/18822[03:00<00:03,102.74it/s]100%|##########|18822/18822[03:03<00:00,102.59it/s]
41
[32m[0324 19:54:45 @monitor.py:363][0m QueueInput/queue_size: 0.87849
[32m[0324 19:54:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.134
[32m[0324 19:54:45 @monitor.py:363][0m activation-summaries/output-rms: 0.04284
[32m[0324 19:54:45 @monitor.py:363][0m cross_entropy_loss: 1.4835
[32m[0324 19:54:45 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.595
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 19:54:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 19:54:45 @monitor.py:363][0m train-error-top1: 0.40362
[32m[0324 19:54:45 @monitor.py:363][0m val-error-top1: 0.40715
[32m[0324 19:54:45 @monitor.py:363][0m val-utt-error: 0.084741
[32m[0324 19:54:45 @monitor.py:363][0m validation_cost: 1.5083
[32m[0324 19:54:45 @monitor.py:363][0m wd_cost: 2.3262e-10
[32m[0324 19:54:45 @group.py:42][0m Callbacks took 183.812 sec in total. InferenceRunner: 183.541sec
[32m[0324 19:54:45 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10534/173481[03:00<46:25,58.50it/s]  6%|6         |11043/173481[03:10<46:16,58.50it/s] 11%|#1        |19948/173481[06:00<46:20,55.23it/s] 12%|#1        |20472/173481[06:10<46:10,55.23it/s] 16%|#6        |28197/173481[09:00<48:20,50.09it/s] 17%|#6        |28631/173481[09:10<48:11,50.09it/s] 21%|##        |36239/173481[12:00<48:26,47.23it/s] 21%|##1       |36713/173481[12:10<48:16,47.23it/s] 26%|##5       |44449/173481[15:00<46:20,46.40it/s] 26%|##5       |44940/173481[15:10<46:10,46.40it/s] 30%|###       |52824/173481[18:00<43:16,46.46it/s] 31%|###       |53331/173481[18:10<43:05,46.46it/s] 35%|###5      |61323/173481[21:00<39:54,46.84it/s] 36%|###5      |61829/173481[21:11<39:43,46.84it/s] 41%|####      |70389/173481[24:00<35:24,48.53it/s] 41%|####      |70988/173481[24:11<35:11,48.53it/s] 46%|####6     |79964/173481[27:00<30:42,50.76it/s] 46%|####6     |80553/173481[27:11<30:30,50.76it/s] 51%|#####1    |88989/173481[30:00<27:54,50.44it/s] 52%|#####1    |89558/173481[30:11<27:43,50.44it/s] 56%|#####6    |97996/173481[33:00<25:02,50.24it/s] 57%|#####6    |98583/173481[33:11<24:50,50.24it/s] 62%|######1   |106889/173481[36:00<22:16,49.81it/s] 62%|######1   |107535/173481[36:11<22:03,49.81it/s] 67%|######6   |115974/173481[39:00<19:07,50.13it/s] 67%|######7   |116538/173481[39:12<18:55,50.13it/s] 72%|#######2  |124969/173481[42:00<16:09,50.04it/s] 72%|#######2  |125598/173481[42:12<15:56,50.04it/s] 77%|#######7  |134322/173481[45:00<12:48,50.98it/s] 78%|#######7  |135031/173481[45:12<12:34,50.98it/s] 83%|########2 |143932/173481[48:00<09:26,52.16it/s] 83%|########3 |144604/173481[48:12<09:13,52.16it/s] 88%|########8 |153449/173481[51:00<06:21,52.51it/s] 89%|########8 |154108/173481[51:12<06:08,52.51it/s] 94%|#########3|162864/173481[54:00<03:22,52.41it/s] 94%|#########4|163543/173481[54:12<03:09,52.41it/s] 99%|#########9|172374/173481[57:00<00:21,52.61it/s]100%|#########9|173033/173481[57:13<00:08,52.61it/s]100%|##########|173481/173481[57:22<00:00,50.39it/s]
[32m[0324 20:52:08 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3442.72 sec.
[32m[0324 20:52:08 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########9|18704/18822[03:00<00:01,103.91it/s]100%|##########|18822/18822[03:00<00:00,103.99it/s]
42
[32m[0324 20:55:09 @monitor.py:363][0m QueueInput/queue_size: 1.6865
[32m[0324 20:55:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.942
[32m[0324 20:55:09 @monitor.py:363][0m activation-summaries/output-rms: 0.042871
[32m[0324 20:55:09 @monitor.py:363][0m cross_entropy_loss: 1.4934
[32m[0324 20:55:09 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59485
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 20:55:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 20:55:09 @monitor.py:363][0m train-error-top1: 0.41416
[32m[0324 20:55:09 @monitor.py:363][0m val-error-top1: 0.40725
[32m[0324 20:55:09 @monitor.py:363][0m val-utt-error: 0.085591
[32m[0324 20:55:09 @monitor.py:363][0m validation_cost: 1.509
[32m[0324 20:55:09 @monitor.py:363][0m wd_cost: 2.3259e-10
[32m[0324 20:55:09 @group.py:42][0m Callbacks took 181.388 sec in total. InferenceRunner: 181.001sec
[32m[0324 20:55:09 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11523/173481[03:00<42:10,64.01it/s]  7%|6         |12052/173481[03:10<42:02,64.01it/s] 12%|#1        |20329/173481[06:00<46:01,55.46it/s] 12%|#1        |20803/173481[06:10<45:53,55.46it/s] 17%|#7        |29949/173481[09:00<43:57,54.43it/s] 18%|#7        |30510/173481[09:10<43:46,54.43it/s] 23%|##2       |39858/173481[12:00<40:41,54.73it/s] 23%|##3       |40468/173481[12:10<40:30,54.73it/s] 29%|##8       |49979/173481[15:00<37:06,55.47it/s] 29%|##9       |50567/173481[15:10<36:55,55.47it/s] 35%|###4      |60228/173481[18:00<33:35,56.19it/s] 35%|###5      |60880/173481[18:10<33:23,56.19it/s] 41%|####      |70865/173481[21:00<29:41,57.61it/s] 41%|####1     |71531/173481[21:11<29:29,57.61it/s] 47%|####6     |81279/173481[24:00<26:37,57.73it/s] 47%|####7     |81927/173481[24:11<26:25,57.73it/s] 53%|#####2    |91706/173481[27:00<23:34,57.83it/s] 53%|#####3    |92349/173481[27:11<23:22,57.83it/s] 59%|#####8    |102173/173481[30:00<20:29,57.99it/s] 59%|#####9    |102883/173481[30:11<20:17,57.99it/s] 65%|######4   |112652/173481[33:00<17:26,58.10it/s] 65%|######5   |113357/173481[33:11<17:14,58.10it/s] 71%|#######1  |123188/173481[36:00<14:22,58.31it/s] 71%|#######1  |123875/173481[36:11<14:10,58.31it/s] 77%|#######7  |133982/173481[39:00<11:08,59.13it/s] 78%|#######7  |134742/173481[39:12<10:55,59.13it/s] 83%|########3 |144488/173481[42:00<08:13,58.74it/s] 84%|########3 |145179/173481[42:12<08:01,58.74it/s] 89%|########9 |155013/173481[45:00<05:15,58.60it/s] 90%|########9 |155734/173481[45:12<05:02,58.60it/s] 95%|#########5|165065/173481[48:00<02:27,57.19it/s] 96%|#########5|165738/173481[48:12<02:15,57.19it/s]100%|##########|173481/173481[50:36<00:00,57.14it/s]
[32m[0324 21:45:45 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3036.04 sec.
[32m[0324 21:45:46 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-7633164.
  0%|          |0/18822[00:00<?,?it/s] 96%|#########5|17983/18822[03:00<00:08,99.90it/s]100%|##########|18822/18822[03:08<00:00,99.60it/s]
43
[32m[0324 21:48:55 @monitor.py:363][0m QueueInput/queue_size: 0.56099
[32m[0324 21:48:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.037
[32m[0324 21:48:55 @monitor.py:363][0m activation-summaries/output-rms: 0.042769
[32m[0324 21:48:55 @monitor.py:363][0m cross_entropy_loss: 1.4377
[32m[0324 21:48:55 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59475
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 21:48:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 21:48:55 @monitor.py:363][0m train-error-top1: 0.39519
[32m[0324 21:48:55 @monitor.py:363][0m val-error-top1: 0.40689
[32m[0324 21:48:55 @monitor.py:363][0m val-utt-error: 0.08591
[32m[0324 21:48:55 @monitor.py:363][0m validation_cost: 1.5098
[32m[0324 21:48:55 @monitor.py:363][0m wd_cost: 2.3256e-10
[32m[0324 21:48:55 @group.py:42][0m Callbacks took 189.297 sec in total. InferenceRunner: 189.015sec
[32m[0324 21:48:55 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12469/173481[03:00<38:44,69.27it/s]  8%|7         |13089/173481[03:10<38:35,69.27it/s] 13%|#3        |22804/173481[06:00<39:59,62.79it/s] 13%|#3        |23266/173481[06:10<39:52,62.79it/s] 19%|#8        |32802/173481[09:00<39:46,58.94it/s] 19%|#9        |33448/173481[09:10<39:35,58.94it/s] 25%|##5       |43785/173481[12:00<36:03,59.96it/s] 26%|##5       |44428/173481[12:10<35:52,59.96it/s] 31%|###1      |54417/173481[15:00<33:20,59.51it/s] 32%|###1      |55072/173481[15:10<33:09,59.51it/s] 38%|###7      |65182/173481[18:00<30:15,59.66it/s] 38%|###7      |65848/173481[18:10<30:04,59.66it/s] 44%|####3     |75855/173481[21:00<27:21,59.47it/s] 44%|####4     |76489/173481[21:11<27:10,59.47it/s] 50%|####9     |86675/173481[24:00<24:11,59.79it/s] 50%|#####     |87297/173481[24:11<24:01,59.79it/s] 56%|#####6    |97422/173481[27:00<21:13,59.75it/s] 57%|#####6    |98146/173481[27:11<21:00,59.75it/s] 62%|######2   |108314/173481[30:00<18:03,60.12it/s] 63%|######2   |108969/173481[30:11<17:52,60.12it/s] 68%|######8   |118807/173481[33:00<15:23,59.19it/s] 69%|######8   |119529/173481[33:11<15:11,59.19it/s] 75%|#######4  |129567/173481[36:00<12:18,59.48it/s] 75%|#######5  |130282/173481[36:11<12:06,59.48it/s] 81%|########  |140234/173481[39:00<09:19,59.37it/s] 81%|########1 |140961/173481[39:12<09:07,59.37it/s] 87%|########7 |151061/173481[42:00<06:15,59.76it/s] 87%|########7 |151769/173481[42:12<06:03,59.76it/s] 93%|#########3|161738/173481[45:00<03:17,59.54it/s] 94%|#########3|162467/173481[45:12<03:04,59.54it/s] 99%|#########9|172485/173481[48:00<00:16,59.62it/s]100%|#########9|173141/173481[48:12<00:05,59.62it/s]100%|##########|173481/173481[48:18<00:00,59.86it/s]
[32m[0324 22:37:13 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:2898.36 sec.
[32m[0324 22:37:13 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-7806645.
[32m[0324 22:37:14 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########9|18692/18822[03:00<00:01,103.84it/s]100%|##########|18822/18822[03:01<00:00,103.77it/s]
44
[32m[0324 22:40:15 @monitor.py:363][0m QueueInput/queue_size: 0.68482
[32m[0324 22:40:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.025
[32m[0324 22:40:15 @monitor.py:363][0m activation-summaries/output-rms: 0.043612
[32m[0324 22:40:15 @monitor.py:363][0m cross_entropy_loss: 1.4437
[32m[0324 22:40:15 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59472
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 22:40:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 22:40:15 @monitor.py:363][0m train-error-top1: 0.39382
[32m[0324 22:40:15 @monitor.py:363][0m val-error-top1: 0.40808
[32m[0324 22:40:15 @monitor.py:363][0m val-utt-error: 0.086282
[32m[0324 22:40:15 @monitor.py:363][0m validation_cost: 1.5112
[32m[0324 22:40:15 @monitor.py:363][0m wd_cost: 4.6511e-11
[32m[0324 22:40:15 @group.py:42][0m Callbacks took 181.939 sec in total. InferenceRunner: 181.420sec
[32m[0324 22:40:15 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12261/173481[03:00<39:26,68.11it/s]  7%|7         |12980/173481[03:10<39:16,68.11it/s] 13%|#3        |23213/173481[06:00<38:57,64.27it/s] 14%|#3        |23810/173481[06:10<38:48,64.27it/s] 19%|#9        |33417/173481[09:00<38:44,60.24it/s] 20%|#9        |34020/173481[09:10<38:34,60.24it/s] 25%|##4       |43307/173481[12:00<37:45,57.47it/s] 25%|##5       |43914/173481[12:10<37:34,57.47it/s] 31%|###       |53400/173481[15:00<35:15,56.76it/s] 31%|###1      |53995/173481[15:10<35:05,56.76it/s] 37%|###6      |63908/173481[18:00<31:43,57.56it/s] 37%|###7      |64562/173481[18:10<31:32,57.56it/s] 43%|####2     |74026/173481[21:00<29:08,56.87it/s] 43%|####3     |74651/173481[21:11<28:57,56.87it/s] 49%|####8     |84151/173481[24:00<26:19,56.56it/s] 49%|####8     |84817/173481[24:11<26:07,56.56it/s] 54%|#####4    |94221/173481[27:00<23:29,56.25it/s] 55%|#####4    |94861/173481[27:11<23:17,56.25it/s] 60%|######    |104173/173481[30:00<20:42,55.76it/s] 60%|######    |104802/173481[30:11<20:31,55.76it/s] 66%|######5   |114233/173481[33:00<17:41,55.82it/s] 66%|######6   |114888/173481[33:11<17:29,55.82it/s] 72%|#######1  |124301/173481[36:00<14:40,55.87it/s] 72%|#######2  |124974/173481[36:12<14:28,55.87it/s] 78%|#######7  |134537/173481[39:00<11:30,56.36it/s] 78%|#######7  |135237/173481[39:12<11:18,56.36it/s] 84%|########3 |144941/173481[42:00<08:20,57.07it/s] 84%|########3 |145639/173481[42:12<08:07,57.07it/s] 89%|########9 |155014/173481[45:00<05:26,56.51it/s] 90%|########9 |155706/173481[45:12<05:14,56.51it/s] 95%|#########5|164949/173481[48:00<02:32,55.84it/s] 95%|#########5|165651/173481[48:12<02:20,55.84it/s]100%|##########|173481/173481[50:35<00:00,57.16it/s]
[32m[0324 23:30:50 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:3035.01 sec.
[32m[0324 23:30:51 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-7980126.
  0%|          |0/18822[00:00<?,?it/s] 91%|#########1|17142/18822[03:00<00:17,95.23it/s] 96%|#########6|18117/18822[03:10<00:07,95.23it/s]100%|##########|18822/18822[03:17<00:00,95.36it/s]
45
[32m[0324 23:34:08 @monitor.py:363][0m QueueInput/queue_size: 0.72352
[32m[0324 23:34:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.894
[32m[0324 23:34:08 @monitor.py:363][0m activation-summaries/output-rms: 0.042358
[32m[0324 23:34:08 @monitor.py:363][0m cross_entropy_loss: 1.4527
[32m[0324 23:34:08 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59469
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0324 23:34:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0324 23:34:08 @monitor.py:363][0m train-error-top1: 0.38906
[32m[0324 23:34:08 @monitor.py:363][0m val-error-top1: 0.40689
[32m[0324 23:34:08 @monitor.py:363][0m val-utt-error: 0.085113
[32m[0324 23:34:08 @monitor.py:363][0m validation_cost: 1.5094
[32m[0324 23:34:08 @monitor.py:363][0m wd_cost: 4.6509e-11
[32m[0324 23:34:08 @group.py:42][0m Callbacks took 198.018 sec in total. InferenceRunner: 197.393sec
[32m[0324 23:34:08 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12227/173481[03:00<39:33,67.93it/s]  7%|7         |12915/173481[03:10<39:23,67.93it/s] 13%|#3        |23256/173481[06:00<38:51,64.43it/s] 14%|#3        |23795/173481[06:10<38:43,64.43it/s] 19%|#8        |32940/173481[09:00<39:56,58.63it/s] 19%|#9        |33473/173481[09:10<39:47,58.63it/s] 24%|##4       |41924/173481[12:00<40:39,53.92it/s] 24%|##4       |42471/173481[12:10<40:29,53.92it/s] 30%|##9       |51344/173481[15:00<38:19,53.11it/s] 30%|##9       |51927/173481[15:10<38:08,53.11it/s] 35%|###5      |61456/173481[18:00<34:11,54.60it/s] 36%|###5      |62064/173481[18:10<34:00,54.60it/s] 41%|####1     |71251/173481[21:00<31:15,54.51it/s] 41%|####1     |71891/173481[21:11<31:03,54.51it/s] 47%|####6     |81402/173481[24:00<27:41,55.44it/s] 47%|####7     |82023/173481[24:11<27:29,55.44it/s] 53%|#####2    |91548/173481[27:00<24:25,55.90it/s] 53%|#####3    |92195/173481[27:11<24:14,55.90it/s] 59%|#####8    |101531/173481[30:00<21:32,55.68it/s] 59%|#####8    |102193/173481[30:11<21:20,55.68it/s] 64%|######4   |111634/173481[33:00<18:26,55.90it/s] 65%|######4   |112304/173481[33:11<18:14,55.90it/s] 70%|#######   |121621/173481[36:00<15:31,55.69it/s] 70%|#######   |122296/173481[36:11<15:19,55.69it/s] 76%|#######5  |131475/173481[39:00<12:40,55.21it/s] 76%|#######6  |132135/173481[39:12<12:28,55.21it/s] 82%|########1 |141421/173481[42:00<09:40,55.23it/s] 82%|########1 |142126/173481[42:12<09:27,55.23it/s] 87%|########7 |151468/173481[45:00<06:36,55.52it/s] 88%|########7 |152196/173481[45:12<06:23,55.52it/s] 93%|#########3|161484/173481[48:00<03:35,55.58it/s] 93%|#########3|162122/173481[48:12<03:24,55.58it/s] 99%|#########8|171721/173481[51:00<00:31,56.22it/s] 99%|#########9|172434/173481[51:12<00:18,56.22it/s]100%|##########|173481/173481[51:30<00:00,56.13it/s]
[32m[0325 00:25:39 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:3090.81 sec.
[32m[0325 00:25:39 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-8153607.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.39it/s]
46
[32m[0325 00:27:39 @monitor.py:363][0m QueueInput/queue_size: 0.75744
[32m[0325 00:27:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.096
[32m[0325 00:27:39 @monitor.py:363][0m activation-summaries/output-rms: 0.042857
[32m[0325 00:27:39 @monitor.py:363][0m cross_entropy_loss: 1.4834
[32m[0325 00:27:39 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59469
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 00:27:39 @monitor.py:363][0m train-error-top1: 0.40486
[32m[0325 00:27:39 @monitor.py:363][0m val-error-top1: 0.407
[32m[0325 00:27:39 @monitor.py:363][0m val-utt-error: 0.084263
[32m[0325 00:27:39 @monitor.py:363][0m validation_cost: 1.5081
[32m[0325 00:27:39 @monitor.py:363][0m wd_cost: 4.6509e-11
[32m[0325 00:27:39 @group.py:42][0m Callbacks took 119.993 sec in total. InferenceRunner: 119.602sec
[32m[0325 00:27:39 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12599/173481[03:00<38:18,69.98it/s]  8%|7         |13196/173481[03:10<38:10,69.98it/s] 13%|#3        |23299/173481[06:00<38:56,64.28it/s] 14%|#3        |23837/173481[06:10<38:47,64.28it/s] 19%|#8        |32544/173481[09:00<41:08,57.09it/s] 19%|#9        |33088/173481[09:10<40:59,57.09it/s] 24%|##4       |42199/173481[12:00<39:33,55.31it/s] 25%|##4       |42748/173481[12:10<39:23,55.31it/s] 30%|##9       |51954/173481[15:00<37:00,54.74it/s] 30%|###       |52543/173481[15:10<36:49,54.74it/s] 36%|###5      |62307/173481[18:00<33:01,56.09it/s] 36%|###6      |62948/173481[18:10<32:50,56.09it/s] 42%|####2     |73244/173481[21:00<28:38,58.33it/s] 43%|####2     |73943/173481[21:11<28:26,58.33it/s] 49%|####8     |84299/173481[24:00<24:50,59.83it/s] 49%|####8     |84968/173481[24:11<24:39,59.83it/s] 55%|#####4    |95194/173481[27:00<21:41,60.17it/s] 55%|#####5    |95915/173481[27:11<21:29,60.17it/s] 61%|######1   |106312/173481[30:00<18:21,60.96it/s] 62%|######1   |107028/173481[30:11<18:10,60.96it/s] 68%|######7   |117499/173481[33:00<15:09,61.53it/s] 68%|######8   |118203/173481[33:11<14:58,61.53it/s] 74%|#######4  |128504/173481[36:00<12:13,61.33it/s] 74%|#######4  |129205/173481[36:11<12:01,61.33it/s] 81%|########  |139814/173481[39:00<09:02,62.07it/s] 81%|########1 |140548/173481[39:12<08:50,62.07it/s] 87%|########7 |151000/173481[42:00<06:01,62.10it/s] 87%|########7 |151733/173481[42:12<05:50,62.10it/s] 93%|#########3|161514/173481[45:00<03:18,60.20it/s] 94%|#########3|162215/173481[45:12<03:07,60.20it/s] 99%|#########9|172419/173481[48:00<00:17,60.39it/s]100%|#########9|173106/173481[48:12<00:06,60.39it/s]100%|##########|173481/173481[48:18<00:00,59.84it/s][32m[0325 01:15:58 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:2898.99 sec.

[32m[0325 01:15:58 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-8327088.
  0%|          |0/18822[00:00<?,?it/s] 69%|######8   |12923/18822[03:00<01:22,71.79it/s] 73%|#######3  |13747/18822[03:10<01:10,71.79it/s]100%|##########|18822/18822[04:21<00:00,72.11it/s]
47
[32m[0325 01:20:19 @monitor.py:363][0m QueueInput/queue_size: 11.188
[32m[0325 01:20:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.002
[32m[0325 01:20:19 @monitor.py:363][0m activation-summaries/output-rms: 0.0438
[32m[0325 01:20:19 @monitor.py:363][0m cross_entropy_loss: 1.4895
[32m[0325 01:20:19 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 01:20:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 01:20:19 @monitor.py:363][0m train-error-top1: 0.41301
[32m[0325 01:20:19 @monitor.py:363][0m val-error-top1: 0.40635
[32m[0325 01:20:19 @monitor.py:363][0m val-utt-error: 0.084422
[32m[0325 01:20:19 @monitor.py:363][0m validation_cost: 1.5056
[32m[0325 01:20:19 @monitor.py:363][0m wd_cost: 9.3017e-12
[32m[0325 01:20:19 @group.py:42][0m Callbacks took 261.419 sec in total. InferenceRunner: 261.049sec
[32m[0325 01:20:19 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10914/173481[03:00<44:41,60.63it/s]  7%|6         |11513/173481[03:10<44:31,60.63it/s] 13%|#2        |22057/173481[06:00<41:11,61.26it/s] 13%|#3        |22789/173481[06:10<40:59,61.26it/s] 20%|##        |35424/173481[09:00<34:16,67.14it/s] 21%|##        |36370/173481[09:10<34:02,67.14it/s] 28%|##8       |49309/173481[12:00<28:49,71.79it/s] 29%|##8       |49912/173481[12:10<28:41,71.79it/s] 34%|###4      |59032/173481[15:00<30:56,61.64it/s] 34%|###4      |59580/173481[15:10<30:47,61.64it/s] 40%|###9      |68756/173481[18:00<30:18,57.58it/s] 40%|###9      |69350/173481[18:11<30:08,57.58it/s] 45%|####5     |78365/173481[21:00<28:36,55.40it/s] 46%|####5     |78958/173481[21:11<28:26,55.40it/s] 51%|#####     |88291/173481[24:00<25:41,55.27it/s] 51%|#####1    |88953/173481[24:11<25:29,55.27it/s] 56%|#####6    |98003/173481[27:00<23:02,54.60it/s] 57%|#####6    |98647/173481[27:11<22:50,54.60it/s] 62%|######2   |108074/173481[30:00<19:43,55.27it/s] 63%|######2   |108764/173481[30:11<19:30,55.27it/s] 68%|######7   |117744/173481[33:00<17:03,54.48it/s] 68%|######8   |118412/173481[33:12<16:50,54.48it/s] 74%|#######3  |127924/173481[36:00<13:40,55.50it/s] 74%|#######4  |128658/173481[36:12<13:27,55.50it/s] 79%|#######9  |137703/173481[39:00<10:51,54.91it/s] 80%|#######9  |138373/173481[39:12<10:39,54.91it/s] 85%|########5 |147713/173481[42:00<07:46,55.25it/s] 86%|########5 |148569/173481[42:12<07:30,55.25it/s] 91%|######### |157499/173481[45:00<04:51,54.81it/s] 91%|#########1|158163/173481[45:12<04:39,54.81it/s] 97%|#########6|167478/173481[48:00<01:48,55.12it/s] 97%|#########7|168312/173481[48:13<01:33,55.12it/s]100%|##########|173481/173481[49:48<00:00,58.05it/s]
[32m[0325 02:10:08 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:2988.62 sec.
[32m[0325 02:10:09 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-8500569.
[32m[0325 02:10:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 72%|#######2  |13575/18822[03:00<01:09,75.41it/s] 76%|#######5  |14303/18822[03:10<00:59,75.41it/s]100%|##########|18822/18822[04:12<00:00,74.62it/s]
48
[32m[0325 02:14:22 @monitor.py:363][0m QueueInput/queue_size: 49.834
[32m[0325 02:14:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.74
[32m[0325 02:14:22 @monitor.py:363][0m activation-summaries/output-rms: 0.043009
[32m[0325 02:14:22 @monitor.py:363][0m cross_entropy_loss: 1.4579
[32m[0325 02:14:22 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 02:14:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 02:14:22 @monitor.py:363][0m train-error-top1: 0.40017
[32m[0325 02:14:22 @monitor.py:363][0m val-error-top1: 0.40532
[32m[0325 02:14:22 @monitor.py:363][0m val-utt-error: 0.084263
[32m[0325 02:14:22 @monitor.py:363][0m validation_cost: 1.5019
[32m[0325 02:14:22 @monitor.py:363][0m wd_cost: 9.3017e-12
[32m[0325 02:14:22 @group.py:42][0m Callbacks took 253.795 sec in total. InferenceRunner: 252.282sec
[32m[0325 02:14:22 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9642/173481[03:00<50:59,53.56it/s]  6%|5         |10171/173481[03:10<50:49,53.56it/s] 11%|#1        |19508/173481[06:00<47:22,54.18it/s] 12%|#1        |20033/173481[06:10<47:12,54.18it/s] 17%|#6        |29455/173481[09:00<43:52,54.71it/s] 17%|#7        |30008/173481[09:10<43:42,54.71it/s] 23%|##2       |39472/173481[12:00<40:28,55.18it/s] 23%|##3       |40014/173481[12:10<40:18,55.18it/s] 28%|##8       |49278/173481[15:00<37:45,54.82it/s] 29%|##8       |49885/173481[15:10<37:34,54.82it/s] 34%|###4      |59381/173481[18:00<34:17,55.47it/s] 35%|###4      |59952/173481[18:11<34:06,55.47it/s] 40%|###9      |69302/173481[21:00<31:24,55.29it/s] 40%|####      |69958/173481[21:11<31:12,55.29it/s] 46%|####6     |80490/173481[24:00<26:29,58.52it/s] 47%|####7     |81828/173481[24:11<26:06,58.52it/s] 56%|#####6    |97533/173481[27:00<17:29,72.33it/s] 57%|#####6    |98438/173481[27:11<17:17,72.33it/s] 65%|######5   |112962/173481[30:00<12:51,78.45it/s] 66%|######5   |114011/173481[30:11<12:38,78.45it/s] 72%|#######1  |124527/173481[33:00<11:32,70.64it/s] 72%|#######2  |125206/173481[33:12<11:23,70.64it/s] 78%|#######7  |134807/173481[36:00<10:12,63.15it/s] 78%|#######8  |135521/173481[36:12<10:01,63.15it/s] 84%|########4 |145732/173481[39:00<07:28,61.90it/s] 84%|########4 |146506/173481[39:12<07:15,61.90it/s] 91%|######### |157217/173481[42:00<04:18,62.83it/s] 91%|#########1|157979/173481[42:12<04:06,62.83it/s] 97%|#########6|167697/173481[45:00<01:35,60.43it/s] 97%|#########7|168377/173481[45:12<01:24,60.43it/s]100%|##########|173481/173481[46:39<00:00,61.96it/s]
[32m[0325 03:01:02 @base.py:257][0m Epoch 51 (global_step 8674050) finished, time:2799.97 sec.
[32m[0325 03:01:02 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-8674050.
[32m[0325 03:01:03 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,188.73it/s]
49
[32m[0325 03:02:42 @monitor.py:363][0m QueueInput/queue_size: 0.56442
[32m[0325 03:02:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.01
[32m[0325 03:02:42 @monitor.py:363][0m activation-summaries/output-rms: 0.043619
[32m[0325 03:02:42 @monitor.py:363][0m cross_entropy_loss: 1.4431
[32m[0325 03:02:42 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 03:02:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 03:02:42 @monitor.py:363][0m train-error-top1: 0.39503
[32m[0325 03:02:42 @monitor.py:363][0m val-error-top1: 0.40804
[32m[0325 03:02:42 @monitor.py:363][0m val-utt-error: 0.086866
[32m[0325 03:02:42 @monitor.py:363][0m validation_cost: 1.5111
[32m[0325 03:02:42 @monitor.py:363][0m wd_cost: 1.8603e-12
[32m[0325 03:02:42 @group.py:42][0m Callbacks took 100.700 sec in total. InferenceRunner: 99.745sec
[32m[0325 03:02:42 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11448/173481[03:00<42:27,63.60it/s]  7%|6         |12070/173481[03:10<42:18,63.60it/s] 13%|#3        |22627/173481[06:00<40:00,62.84it/s] 13%|#3        |23273/173481[06:10<39:50,62.84it/s] 19%|#9        |33509/173481[09:00<37:51,61.62it/s] 20%|#9        |34117/173481[09:10<37:41,61.62it/s] 26%|##5       |44261/173481[12:00<35:30,60.66it/s] 26%|##5       |44882/173481[12:10<35:20,60.66it/s] 32%|###1      |54990/173481[15:00<32:50,60.13it/s] 32%|###2      |55640/173481[15:10<32:39,60.13it/s] 38%|###8      |66321/173481[18:00<29:02,61.50it/s] 39%|###8      |67020/173481[18:10<28:50,61.50it/s] 44%|####4     |76988/173481[21:00<26:38,60.36it/s] 45%|####4     |77600/173481[21:11<26:28,60.36it/s] 50%|#####     |87405/173481[24:00<24:16,59.09it/s] 51%|#####     |88076/173481[24:11<24:05,59.09it/s] 57%|#####6    |98032/173481[27:00<21:17,59.06it/s] 57%|#####6    |98709/173481[27:11<21:05,59.06it/s] 63%|######2   |108702/173481[30:00<18:14,59.17it/s] 63%|######3   |109380/173481[30:11<18:03,59.17it/s] 69%|######8   |119192/173481[33:00<15:24,58.72it/s] 69%|######9   |119865/173481[33:11<15:13,58.72it/s] 75%|#######4  |129741/173481[36:00<12:25,58.66it/s] 75%|#######5  |130417/173481[36:11<12:14,58.66it/s] 81%|########  |140451/173481[39:00<09:19,59.08it/s] 81%|########1 |141196/173481[39:12<09:06,59.08it/s] 87%|########7 |151096/173481[42:00<06:18,59.09it/s] 87%|########7 |151751/173481[42:12<06:07,59.09it/s] 93%|#########3|161490/173481[45:00<03:25,58.41it/s] 93%|#########3|162171/173481[45:12<03:13,58.41it/s] 99%|#########9|172002/173481[48:00<00:25,58.40it/s]100%|#########9|172709/173481[48:12<00:13,58.40it/s]100%|##########|173481/173481[48:25<00:00,59.71it/s]
[32m[0325 03:51:08 @base.py:257][0m Epoch 52 (global_step 8847531) finished, time:2905.52 sec.
[32m[0325 03:51:08 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-8847531.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.60it/s]
50
[32m[0325 03:52:47 @monitor.py:363][0m QueueInput/queue_size: 0.5888
[32m[0325 03:52:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.889
[32m[0325 03:52:47 @monitor.py:363][0m activation-summaries/output-rms: 0.042363
[32m[0325 03:52:47 @monitor.py:363][0m cross_entropy_loss: 1.4529
[32m[0325 03:52:47 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 03:52:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 03:52:47 @monitor.py:363][0m train-error-top1: 0.39124
[32m[0325 03:52:47 @monitor.py:363][0m val-error-top1: 0.40692
[32m[0325 03:52:47 @monitor.py:363][0m val-utt-error: 0.085273
[32m[0325 03:52:47 @monitor.py:363][0m validation_cost: 1.5094
[32m[0325 03:52:47 @monitor.py:363][0m wd_cost: 1.8603e-12
[32m[0325 03:52:47 @group.py:42][0m Callbacks took 99.103 sec in total. InferenceRunner: 98.763sec
[32m[0325 03:52:47 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10778/173481[03:00<45:17,59.88it/s]  7%|6         |11377/173481[03:10<45:07,59.88it/s] 12%|#2        |21382/173481[06:00<42:41,59.39it/s] 13%|#2        |21994/173481[06:10<42:30,59.39it/s] 18%|#8        |31813/173481[09:00<40:15,58.66it/s] 19%|#8        |32394/173481[09:10<40:05,58.66it/s] 24%|##3       |41605/173481[12:00<38:56,56.45it/s] 24%|##4       |42194/173481[12:10<38:45,56.45it/s] 30%|##9       |51645/173481[15:00<36:11,56.11it/s] 30%|###       |52241/173481[15:10<36:00,56.11it/s] 36%|###5      |61940/173481[18:00<32:49,56.64it/s] 36%|###6      |62564/173481[18:10<32:38,56.64it/s] 42%|####1     |72302/173481[21:00<29:31,57.10it/s] 42%|####2     |72939/173481[21:11<29:20,57.10it/s] 48%|####7     |82866/173481[24:00<26:05,57.88it/s] 48%|####8     |83508/173481[24:11<25:54,57.88it/s] 54%|#####3    |93550/173481[27:00<22:43,58.61it/s] 54%|#####4    |94214/173481[27:11<22:32,58.61it/s] 60%|######    |104145/173481[30:00<19:40,58.73it/s] 60%|######    |104819/173481[30:11<19:29,58.73it/s] 66%|######6   |114830/173481[33:00<16:33,59.04it/s] 67%|######6   |115486/173481[33:11<16:22,59.04it/s] 72%|#######2  |125255/173481[36:00<13:44,58.46it/s] 73%|#######2  |125879/173481[36:11<13:34,58.46it/s] 78%|#######8  |135734/173481[39:00<10:47,58.34it/s] 79%|#######8  |136409/173481[39:11<10:35,58.34it/s] 84%|########4 |146389/173481[42:00<07:41,58.76it/s] 85%|########4 |147094/173481[42:11<07:29,58.76it/s] 91%|######### |157330/173481[45:00<04:30,59.75it/s] 91%|#########1|158016/173481[45:12<04:18,59.75it/s] 97%|#########6|167867/173481[48:00<01:34,59.14it/s] 97%|#########7|168564/173481[48:12<01:23,59.14it/s]100%|##########|173481/173481[49:38<00:00,58.24it/s]
[32m[0325 04:42:26 @base.py:257][0m Epoch 53 (global_step 9021012) finished, time:2978.73 sec.
[32m[0325 04:42:26 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-9021012.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,188.33it/s]
51
[32m[0325 04:44:06 @monitor.py:363][0m QueueInput/queue_size: 0.43608
[32m[0325 04:44:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.092
[32m[0325 04:44:06 @monitor.py:363][0m activation-summaries/output-rms: 0.042882
[32m[0325 04:44:06 @monitor.py:363][0m cross_entropy_loss: 1.4836
[32m[0325 04:44:06 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 04:44:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 04:44:06 @monitor.py:363][0m train-error-top1: 0.40498
[32m[0325 04:44:06 @monitor.py:363][0m val-error-top1: 0.40708
[32m[0325 04:44:06 @monitor.py:363][0m val-utt-error: 0.084422
[32m[0325 04:44:06 @monitor.py:363][0m validation_cost: 1.5083
[32m[0325 04:44:06 @monitor.py:363][0m wd_cost: 1.8603e-12
[32m[0325 04:44:06 @group.py:42][0m Callbacks took 100.215 sec in total. InferenceRunner: 99.962sec
[32m[0325 04:44:06 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11194/173481[03:00<43:30,62.18it/s]  7%|6         |11794/173481[03:10<43:20,62.18it/s] 13%|#2        |22289/173481[06:00<40:42,61.90it/s] 13%|#3        |22924/173481[06:10<40:32,61.90it/s] 19%|#8        |32376/173481[09:00<39:58,58.82it/s] 19%|#9        |32988/173481[09:10<39:48,58.82it/s] 25%|##4       |42514/173481[12:00<37:55,57.54it/s] 25%|##4       |43073/173481[12:10<37:46,57.54it/s] 30%|###       |52905/173481[15:00<34:52,57.64it/s] 31%|###       |53518/173481[15:10<34:41,57.64it/s] 37%|###6      |63625/173481[18:00<31:15,58.58it/s] 37%|###7      |64314/173481[18:10<31:03,58.58it/s] 43%|####3     |74740/173481[21:00<27:22,60.12it/s] 43%|####3     |75356/173481[21:11<27:12,60.12it/s] 50%|####9     |86004/173481[24:00<23:46,61.32it/s] 50%|####9     |86718/173481[24:11<23:34,61.32it/s] 56%|#####6    |97299/173481[27:00<20:28,62.02it/s] 56%|#####6    |98013/173481[27:11<20:16,62.02it/s] 63%|######2   |108485/173481[30:00<17:26,62.08it/s] 63%|######2   |109178/173481[30:11<17:15,62.08it/s] 69%|######9   |120099/173481[33:00<14:03,63.28it/s] 70%|######9   |120808/173481[33:11<13:52,63.28it/s] 76%|#######5  |131334/173481[36:00<11:10,62.84it/s] 76%|#######6  |132070/173481[36:11<10:58,62.84it/s] 82%|########2 |142954/173481[39:00<07:59,63.68it/s] 83%|########2 |143706/173481[39:11<07:47,63.68it/s] 89%|########9 |154919/173481[42:00<04:45,65.04it/s] 90%|########9 |155856/173481[42:12<04:30,65.04it/s] 98%|#########8|170500/173481[45:00<00:40,74.27it/s] 99%|#########8|171594/173481[45:12<00:25,74.27it/s]100%|##########|173481/173481[45:33<00:00,63.47it/s]
[32m[0325 05:29:39 @base.py:257][0m Epoch 54 (global_step 9194493) finished, time:2733.36 sec.
[32m[0325 05:29:40 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-9194493.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,192.29it/s]
52
[32m[0325 05:31:18 @monitor.py:363][0m QueueInput/queue_size: 0.32256
[32m[0325 05:31:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.909
[32m[0325 05:31:18 @monitor.py:363][0m activation-summaries/output-rms: 0.042857
[32m[0325 05:31:18 @monitor.py:363][0m cross_entropy_loss: 1.4928
[32m[0325 05:31:18 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 05:31:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 05:31:18 @monitor.py:363][0m train-error-top1: 0.41403
[32m[0325 05:31:18 @monitor.py:363][0m val-error-top1: 0.40715
[32m[0325 05:31:18 @monitor.py:363][0m val-utt-error: 0.08506
[32m[0325 05:31:18 @monitor.py:363][0m validation_cost: 1.5086
[32m[0325 05:31:18 @monitor.py:363][0m wd_cost: 3.7207e-13
[32m[0325 05:31:18 @group.py:42][0m Callbacks took 98.299 sec in total. InferenceRunner: 97.896sec
[32m[0325 05:31:18 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#         |18354/173481[03:00<25:21,101.96it/s] 11%|#1        |19308/173481[03:10<25:12,101.96it/s] 20%|##        |35433/173481[06:00<23:24,98.29it/s]  21%|##        |36384/173481[06:10<23:14,98.29it/s] 30%|###       |52898/173481[09:00<20:34,97.66it/s] 31%|###1      |53856/173481[09:10<20:24,97.66it/s] 38%|###7      |65087/173481[12:00<22:35,79.97it/s] 38%|###7      |65757/173481[12:10<22:26,79.97it/s] 44%|####3     |76288/173481[15:00<23:08,69.99it/s] 44%|####4     |76956/173481[15:10<22:59,69.99it/s] 51%|#####     |87738/173481[18:00<21:26,66.64it/s] 51%|#####     |88427/173481[18:10<21:16,66.64it/s] 57%|#####7    |99371/173481[21:00<18:49,65.62it/s] 58%|#####7    |100049/173481[21:11<18:39,65.62it/s] 64%|######3   |110413/173481[24:00<16:34,63.40it/s] 64%|######4   |111078/173481[24:11<16:24,63.40it/s] 70%|######9   |121398/173481[27:00<13:57,62.19it/s] 70%|#######   |122072/173481[27:11<13:46,62.19it/s] 77%|#######6  |132799/173481[30:00<10:48,62.76it/s] 77%|#######6  |133472/173481[30:11<10:37,62.76it/s] 83%|########2 |143654/173481[33:00<08:04,61.51it/s] 83%|########3 |144362/173481[33:11<07:53,61.51it/s] 89%|########9 |154467/173481[36:00<05:12,60.78it/s] 89%|########9 |155111/173481[36:11<05:02,60.78it/s] 95%|#########5|165508/173481[39:00<02:10,61.05it/s] 96%|#########5|166230/173481[39:11<01:58,61.05it/s]100%|##########|173481/173481[41:18<00:00,70.00it/s]
[32m[0325 06:12:36 @base.py:257][0m Epoch 55 (global_step 9367974) finished, time:2478.26 sec.
[32m[0325 06:12:36 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-9367974.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,191.50it/s]
53
[32m[0325 06:14:14 @monitor.py:363][0m QueueInput/queue_size: 0.28942
[32m[0325 06:14:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.022
[32m[0325 06:14:14 @monitor.py:363][0m activation-summaries/output-rms: 0.042772
[32m[0325 06:14:14 @monitor.py:363][0m cross_entropy_loss: 1.4375
[32m[0325 06:14:14 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 06:14:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 06:14:14 @monitor.py:363][0m train-error-top1: 0.39614
[32m[0325 06:14:14 @monitor.py:363][0m val-error-top1: 0.40688
[32m[0325 06:14:14 @monitor.py:363][0m val-utt-error: 0.085591
[32m[0325 06:14:14 @monitor.py:363][0m validation_cost: 1.5096
[32m[0325 06:14:14 @monitor.py:363][0m wd_cost: 3.7207e-13
[32m[0325 06:14:14 @group.py:42][0m Callbacks took 98.488 sec in total. InferenceRunner: 98.298sec
[32m[0325 06:14:14 @base.py:247][0m Start Epoch 56 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11344/173481[03:00<42:52,63.02it/s]  7%|6         |11966/173481[03:10<42:42,63.02it/s] 13%|#2        |21953/173481[06:00<41:27,60.91it/s] 13%|#2        |22514/173481[06:10<41:18,60.91it/s] 19%|#9        |33462/173481[09:00<37:24,62.38it/s] 20%|#9        |34128/173481[09:10<37:13,62.38it/s] 26%|##6       |45268/173481[12:00<33:25,63.94it/s] 26%|##6       |45965/173481[12:10<33:14,63.94it/s] 33%|###3      |57492/173481[15:00<29:21,65.87it/s] 34%|###3      |58154/173481[15:10<29:10,65.87it/s] 40%|###9      |68757/173481[18:00<27:11,64.18it/s] 40%|###9      |69371/173481[18:10<27:02,64.18it/s] 47%|####6     |80707/173481[21:00<23:41,65.26it/s] 47%|####6     |81452/173481[21:10<23:30,65.26it/s] 54%|#####3    |93017/173481[24:00<20:04,66.78it/s] 54%|#####4    |93741/173481[24:11<19:53,66.78it/s] 61%|######    |105327/173481[27:00<16:48,67.57it/s] 61%|######1   |106020/173481[27:11<16:38,67.57it/s] 68%|######7   |117552/173481[30:00<13:45,67.74it/s] 68%|######8   |118291/173481[30:11<13:34,67.74it/s] 75%|#######4  |129338/173481[33:00<11:02,66.59it/s] 75%|#######4  |130071/173481[33:11<10:51,66.59it/s] 81%|########1 |140707/173481[36:00<08:25,64.83it/s] 82%|########1 |141474/173481[36:11<08:13,64.83it/s] 88%|########8 |153072/173481[39:00<05:05,66.70it/s] 89%|########8 |153796/173481[39:11<04:55,66.70it/s] 95%|#########5|164947/173481[42:00<02:08,66.33it/s] 95%|#########5|165557/173481[42:11<01:59,66.33it/s]100%|##########|173481/173481[44:27<00:00,65.04it/s]
[32m[0325 06:58:42 @base.py:257][0m Epoch 56 (global_step 9541455) finished, time:2667.22 sec.
[32m[0325 06:58:42 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-9541455.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,191.19it/s]
54
[32m[0325 07:00:20 @monitor.py:363][0m QueueInput/queue_size: 0.49847
[32m[0325 07:00:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.013
[32m[0325 07:00:20 @monitor.py:363][0m activation-summaries/output-rms: 0.043618
[32m[0325 07:00:20 @monitor.py:363][0m cross_entropy_loss: 1.4434
[32m[0325 07:00:20 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 07:00:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 07:00:20 @monitor.py:363][0m train-error-top1: 0.39785
[32m[0325 07:00:20 @monitor.py:363][0m val-error-top1: 0.40803
[32m[0325 07:00:20 @monitor.py:363][0m val-utt-error: 0.086495
[32m[0325 07:00:20 @monitor.py:363][0m validation_cost: 1.5111
[32m[0325 07:00:20 @monitor.py:363][0m wd_cost: 3.7207e-13
[32m[0325 07:00:20 @group.py:42][0m Callbacks took 98.653 sec in total. InferenceRunner: 98.462sec
[32m[0325 07:00:20 @base.py:247][0m Start Epoch 57 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12416/173481[03:00<38:55,68.97it/s]  8%|7         |13115/173481[03:10<38:45,68.97it/s] 14%|#4        |24489/173481[06:00<36:30,68.01it/s] 15%|#4        |25167/173481[06:10<36:20,68.01it/s] 21%|##        |36025/173481[09:00<34:43,65.99it/s] 21%|##1       |36653/173481[09:10<34:33,65.99it/s] 27%|##7       |46921/173481[12:00<33:24,63.13it/s] 27%|##7       |47556/173481[12:10<33:14,63.13it/s] 33%|###3      |57461/173481[15:00<31:49,60.76it/s] 34%|###3      |58132/173481[15:10<31:38,60.76it/s] 40%|###9      |68586/173481[18:00<28:32,61.27it/s] 40%|###9      |69239/173481[18:10<28:21,61.27it/s] 46%|####5     |79311/173481[21:00<25:58,60.41it/s] 46%|####6     |79977/173481[21:11<25:47,60.41it/s] 52%|#####1    |90111/173481[24:00<23:04,60.21it/s] 52%|#####2    |90795/173481[24:11<22:53,60.21it/s] 58%|#####8    |100796/173481[27:00<20:15,59.78it/s] 58%|#####8    |101460/173481[27:11<20:04,59.78it/s] 64%|######4   |111506/173481[30:00<17:19,59.63it/s] 65%|######4   |112175/173481[30:11<17:08,59.63it/s] 70%|#######   |122266/173481[33:00<14:17,59.70it/s] 71%|#######   |122940/173481[33:11<14:06,59.70it/s] 77%|#######6  |133131/173481[36:00<11:12,60.03it/s] 77%|#######7  |133805/173481[36:11<11:00,60.03it/s] 83%|########3 |144106/173481[39:00<08:05,60.49it/s] 83%|########3 |144770/173481[39:11<07:54,60.49it/s] 89%|########9 |154666/173481[42:00<05:15,59.56it/s] 90%|########9 |155355/173481[42:12<05:04,59.56it/s] 95%|#########5|165413/173481[45:00<02:15,59.63it/s] 96%|#########5|166100/173481[45:12<02:03,59.63it/s]100%|##########|173481/173481[47:12<00:00,61.25it/s]
[32m[0325 07:47:33 @base.py:257][0m Epoch 57 (global_step 9714936) finished, time:2832.30 sec.
[32m[0325 07:47:33 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-9714936.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,194.11it/s]
55
[32m[0325 07:49:10 @monitor.py:363][0m QueueInput/queue_size: 0.44845
[32m[0325 07:49:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.89
[32m[0325 07:49:10 @monitor.py:363][0m activation-summaries/output-rms: 0.042377
[32m[0325 07:49:10 @monitor.py:363][0m cross_entropy_loss: 1.4533
[32m[0325 07:49:10 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 07:49:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 07:49:10 @monitor.py:363][0m train-error-top1: 0.39052
[32m[0325 07:49:10 @monitor.py:363][0m val-error-top1: 0.40693
[32m[0325 07:49:10 @monitor.py:363][0m val-utt-error: 0.085485
[32m[0325 07:49:10 @monitor.py:363][0m validation_cost: 1.5093
[32m[0325 07:49:10 @monitor.py:363][0m wd_cost: 7.4414e-14
[32m[0325 07:49:10 @group.py:42][0m Callbacks took 97.467 sec in total. InferenceRunner: 96.978sec
[32m[0325 07:49:10 @base.py:247][0m Start Epoch 58 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11572/173481[03:00<41:58,64.29it/s]  7%|7         |12289/173481[03:10<41:47,64.29it/s] 13%|#3        |22680/173481[06:00<39:54,62.97it/s] 13%|#3        |23314/173481[06:10<39:44,62.97it/s] 19%|#9        |33395/173481[09:00<38:09,61.19it/s] 20%|#9        |33975/173481[09:10<37:59,61.19it/s] 25%|##4       |43320/173481[12:00<37:23,58.01it/s] 25%|##5       |43905/173481[12:10<37:13,58.01it/s] 31%|###       |53520/173481[15:00<34:52,57.32it/s] 31%|###1      |54151/173481[15:10<34:41,57.32it/s] 37%|###6      |64085/173481[18:00<31:26,58.00it/s] 37%|###7      |64674/173481[18:10<31:16,58.00it/s] 43%|####2     |74575/173481[21:00<28:21,58.14it/s] 43%|####3     |75204/173481[21:11<28:10,58.14it/s] 49%|####9     |85165/173481[24:00<25:10,58.47it/s] 49%|####9     |85754/173481[24:11<25:00,58.47it/s] 55%|#####5    |95881/173481[27:00<21:55,59.00it/s] 56%|#####5    |96566/173481[27:11<21:43,59.00it/s] 61%|######1   |106610/173481[30:00<18:47,59.30it/s] 62%|######1   |107284/173481[30:11<18:36,59.30it/s] 67%|######7   |116985/173481[33:00<16:06,58.45it/s] 68%|######7   |117663/173481[33:11<15:54,58.45it/s] 73%|#######3  |127174/173481[36:00<13:25,57.51it/s] 74%|#######3  |127839/173481[36:11<13:13,57.51it/s] 79%|#######9  |137365/173481[39:00<10:32,57.06it/s] 80%|#######9  |138031/173481[39:11<10:21,57.06it/s] 85%|########5 |147823/173481[42:00<07:25,57.57it/s] 86%|########5 |148509/173481[42:12<07:13,57.57it/s] 91%|#########1|158408/173481[45:00<04:19,58.18it/s] 92%|#########1|159104/173481[45:12<04:07,58.18it/s] 97%|#########7|168827/173481[48:00<01:20,58.03it/s] 98%|#########7|169554/173481[48:12<01:07,58.03it/s]100%|##########|173481/173481[49:20<00:00,58.60it/s]
[32m[0325 08:38:30 @base.py:257][0m Epoch 58 (global_step 9888417) finished, time:2960.33 sec.
[32m[0325 08:38:31 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,192.30it/s]
56
[32m[0325 08:40:08 @monitor.py:363][0m QueueInput/queue_size: 0.36462
[32m[0325 08:40:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.09
[32m[0325 08:40:08 @monitor.py:363][0m activation-summaries/output-rms: 0.042887
[32m[0325 08:40:08 @monitor.py:363][0m cross_entropy_loss: 1.4833
[32m[0325 08:40:08 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 08:40:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 08:40:08 @monitor.py:363][0m train-error-top1: 0.40402
[32m[0325 08:40:08 @monitor.py:363][0m val-error-top1: 0.40713
[32m[0325 08:40:08 @monitor.py:363][0m val-utt-error: 0.084794
[32m[0325 08:40:08 @monitor.py:363][0m validation_cost: 1.5083
[32m[0325 08:40:08 @monitor.py:363][0m wd_cost: 7.4414e-14
[32m[0325 08:40:08 @group.py:42][0m Callbacks took 98.030 sec in total. InferenceRunner: 97.893sec
[32m[0325 08:40:08 @base.py:247][0m Start Epoch 59 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11389/173481[03:00<42:42,63.27it/s]  7%|6         |12026/173481[03:10<42:32,63.27it/s] 13%|#2        |22415/173481[06:00<40:27,62.24it/s] 13%|#3        |23069/173481[06:10<40:16,62.24it/s] 19%|#8        |32112/173481[09:00<40:47,57.75it/s] 19%|#8        |32686/173481[09:10<40:37,57.75it/s] 24%|##4       |42024/173481[12:00<38:51,56.37it/s] 25%|##4       |42603/173481[12:10<38:41,56.37it/s] 30%|##9       |51920/173481[15:00<36:23,55.66it/s] 30%|###       |52513/173481[15:10<36:13,55.66it/s] 36%|###5      |61959/173481[18:00<33:21,55.71it/s] 36%|###6      |62608/173481[18:10<33:10,55.71it/s] 42%|####1     |72778/173481[21:00<29:01,57.82it/s] 42%|####2     |73413/173481[21:11<28:50,57.82it/s] 48%|####8     |83596/173481[24:00<25:25,58.94it/s] 49%|####8     |84253/173481[24:11<25:13,58.94it/s] 54%|#####4    |94511/173481[27:00<22:01,59.78it/s] 55%|#####4    |95157/173481[27:11<21:50,59.78it/s] 61%|######    |105164/173481[30:00<19:08,59.47it/s] 61%|######    |105820/173481[30:11<18:57,59.47it/s] 67%|######7   |116304/173481[33:00<15:42,60.65it/s] 67%|######7   |117018/173481[33:11<15:30,60.65it/s] 73%|#######3  |127135/173481[36:00<12:47,60.41it/s] 74%|#######3  |127846/173481[36:11<12:35,60.41it/s] 80%|#######9  |138285/173481[39:00<09:35,61.17it/s] 80%|########  |139029/173481[39:11<09:23,61.17it/s] 86%|########6 |149643/173481[42:00<06:23,62.12it/s] 87%|########6 |150394/173481[42:11<06:11,62.12it/s] 93%|#########2|161220/173481[45:00<03:14,63.20it/s] 93%|#########3|161993/173481[45:12<03:01,63.20it/s]100%|#########9|172892/173481[48:00<00:09,64.01it/s]100%|##########|173481/173481[48:09<00:00,60.03it/s]
[32m[0325 09:28:18 @base.py:257][0m Epoch 59 (global_step 10061898) finished, time:2889.81 sec.
[32m[0325 09:28:18 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-10061898.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,194.93it/s]
57
[32m[0325 09:29:55 @monitor.py:363][0m QueueInput/queue_size: 0.4599
[32m[0325 09:29:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.912
[32m[0325 09:29:55 @monitor.py:363][0m activation-summaries/output-rms: 0.042856
[32m[0325 09:29:55 @monitor.py:363][0m cross_entropy_loss: 1.4927
[32m[0325 09:29:55 @monitor.py:363][0m lr: 4.7684e-10
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 09:29:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 09:29:55 @monitor.py:363][0m train-error-top1: 0.41405
[32m[0325 09:29:55 @monitor.py:363][0m val-error-top1: 0.40717
[32m[0325 09:29:55 @monitor.py:363][0m val-utt-error: 0.084848
[32m[0325 09:29:55 @monitor.py:363][0m validation_cost: 1.5086
[32m[0325 09:29:55 @monitor.py:363][0m wd_cost: 7.4414e-14
[32m[0325 09:29:55 @group.py:42][0m Callbacks took 96.837 sec in total. InferenceRunner: 96.570sec
[32m[0325 09:29:55 @base.py:247][0m Start Epoch 60 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12503/173481[03:00<38:37,69.45it/s]  8%|7         |13147/173481[03:10<38:28,69.45it/s] 14%|#3        |23568/173481[06:00<38:18,65.21it/s] 14%|#3        |24158/173481[06:10<38:09,65.21it/s] 20%|##        |35053/173481[09:00<35:46,64.50it/s] 21%|##        |35749/173481[09:10<35:35,64.50it/s] 27%|##7       |47316/173481[12:00<31:43,66.26it/s] 28%|##7       |48043/173481[12:10<31:33,66.26it/s] 34%|###3      |58850/173481[15:00<29:19,65.15it/s] 34%|###4      |59497/173481[15:10<29:09,65.15it/s] 40%|####      |70073/173481[18:00<27:02,63.72it/s] 41%|####      |70777/173481[18:10<26:51,63.72it/s] 47%|####6     |81363/173481[21:00<24:17,63.21it/s] 47%|####7     |82060/173481[21:10<24:06,63.21it/s] 53%|#####3    |92684/173481[24:00<21:21,63.05it/s] 54%|#####3    |93382/173481[24:11<21:10,63.05it/s] 60%|#####9    |104060/173481[27:00<18:19,63.12it/s] 60%|######    |104767/173481[27:11<18:08,63.12it/s] 66%|######6   |115360/173481[30:00<15:23,62.95it/s] 67%|######6   |116055/173481[30:11<15:12,62.95it/s] 73%|#######2  |126607/173481[33:00<12:27,62.71it/s] 73%|#######3  |127332/173481[33:11<12:15,62.71it/s] 80%|#######9  |138048/173481[36:00<09:21,63.13it/s] 80%|#######9  |138707/173481[36:11<09:10,63.13it/s] 86%|########5 |148683/173481[39:00<06:46,61.04it/s] 86%|########6 |149382/173481[39:11<06:34,61.04it/s] 92%|#########2|159954/173481[42:00<03:38,61.82it/s] 93%|#########2|160721/173481[42:12<03:26,61.82it/s] 99%|#########8|170908/173481[45:00<00:41,61.33it/s] 99%|#########8|171562/173481[45:12<00:31,61.33it/s]100%|##########|173481/173481[45:43<00:00,63.23it/s]
[32m[0325 10:15:39 @base.py:257][0m Epoch 60 (global_step 10235379) finished, time:2743.71 sec.
[32m[0325 10:15:39 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-10235379.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,194.70it/s]
58
[32m[0325 10:17:16 @monitor.py:363][0m QueueInput/queue_size: 0.68605
[32m[0325 10:17:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.022
[32m[0325 10:17:16 @monitor.py:363][0m activation-summaries/output-rms: 0.042771
[32m[0325 10:17:16 @monitor.py:363][0m cross_entropy_loss: 1.4375
[32m[0325 10:17:16 @monitor.py:363][0m lr: 4.7684e-10
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 10:17:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 10:17:16 @monitor.py:363][0m train-error-top1: 0.39573
[32m[0325 10:17:16 @monitor.py:363][0m val-error-top1: 0.40691
[32m[0325 10:17:16 @monitor.py:363][0m val-utt-error: 0.085751
[32m[0325 10:17:16 @monitor.py:363][0m validation_cost: 1.5096
[32m[0325 10:17:16 @monitor.py:363][0m wd_cost: 1.4883e-14
[32m[0325 10:17:16 @group.py:42][0m Callbacks took 97.124 sec in total. InferenceRunner: 96.683sec
[32m[0325 10:17:16 @base.py:247][0m Start Epoch 61 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14472/173481[03:00<32:57,80.40it/s]  9%|8         |15211/173481[03:10<32:48,80.40it/s] 16%|#6        |28559/173481[06:00<30:27,79.31it/s] 17%|#6        |29422/173481[06:10<30:16,79.31it/s] 25%|##4       |42833/173481[09:00<27:27,79.31it/s] 25%|##5       |43611/173481[09:10<27:17,79.31it/s] 33%|###2      |56489/173481[12:00<25:08,77.55it/s] 33%|###3      |57308/173481[12:10<24:58,77.55it/s] 41%|####      |70412/173481[15:00<22:10,77.45it/s] 41%|####1     |71242/173481[15:10<22:00,77.45it/s] 49%|####8     |84239/173481[18:00<19:17,77.13it/s] 49%|####9     |85128/173481[18:10<19:05,77.13it/s] 57%|#####7    |98982/173481[21:00<15:37,79.45it/s] 58%|#####7    |99941/173481[21:11<15:25,79.45it/s] 66%|######6   |114514/173481[24:00<11:52,82.72it/s] 67%|######6   |115451/173481[24:11<11:41,82.72it/s] 75%|#######4  |129545/173481[27:00<08:48,83.11it/s] 75%|#######5  |130448/173481[27:11<08:37,83.11it/s] 82%|########2 |142362/173481[30:00<06:45,76.70it/s] 82%|########2 |143079/173481[30:11<06:36,76.70it/s] 89%|########9 |155133/173481[33:00<04:08,73.71it/s] 90%|########9 |155955/173481[33:11<03:57,73.71it/s] 96%|#########6|166822/173481[36:00<01:36,69.04it/s] 96%|#########6|167368/173481[36:11<01:28,69.04it/s]100%|##########|173481/173481[37:53<00:00,76.31it/s]
[32m[0325 10:55:09 @base.py:257][0m Epoch 61 (global_step 10408860) finished, time:2273.27 sec.
[32m[0325 10:55:09 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_False/model-10408860.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,197.20it/s]
59
[32m[0325 10:56:45 @monitor.py:363][0m QueueInput/queue_size: 0.60177
[32m[0325 10:56:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.012
[32m[0325 10:56:45 @monitor.py:363][0m activation-summaries/output-rms: 0.04361
[32m[0325 10:56:45 @monitor.py:363][0m cross_entropy_loss: 1.4435
[32m[0325 10:56:45 @monitor.py:363][0m lr: 2.3842e-10
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0325 10:56:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0325 10:56:45 @monitor.py:363][0m train-error-top1: 0.39708
[32m[0325 10:56:45 @monitor.py:363][0m val-error-top1: 0.40803
[32m[0325 10:56:45 @monitor.py:363][0m val-utt-error: 0.086654
[32m[0325 10:56:45 @monitor.py:363][0m validation_cost: 1.5111
[32m[0325 10:56:45 @monitor.py:363][0m wd_cost: 1.4883e-14
[32m[0325 10:56:45 @group.py:42][0m Callbacks took 95.636 sec in total. InferenceRunner: 95.457sec
[32m[0325 10:56:45 @base.py:247][0m Start Epoch 62 ...
  0%|          |0/173481[00:00<?,?it/s]slurmstepd: *** STEP 82595.0 ON sls-tesla-1 CANCELLED AT 2018-03-25T10:57:36 DUE TO TIME LIMIT ***
srun: error: sls-tesla-1: task 0: Terminated
srun: Force Terminated job step 82595.0
