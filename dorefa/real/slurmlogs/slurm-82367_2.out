sls-titanx-1 2
SLURM_JOBID=82369
SLURM_TASKID=2
[32m[0322 11:10:00 @logger.py:74][0m Argv: drf_run.py --model_name=fcn2 --bitw=8 --bita=8 --quant_ends=True --load_ckpt=train_log/fcn2_w_8_a_32_quant_ends_True/checkpoint
[32m[0322 11:11:56 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0322 11:11:56 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0322 11:11:57 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0322 11:11:57 @drf_run.py:166][0m Using host: sls-titanx-1
[32m[0322 11:11:57 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0322 11:11:57 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0322 11:11:57 @drf_run.py:188][0m Using GPU: 2
[32m[0322 11:11:57 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0322 11:11:57 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0322 11:11:57 @training.py:108][0m Building graph for training tower 0 ...
[32m[0322 11:11:57 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear0 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear1 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear1 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear2 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear2 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear3 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear3 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m last_linear input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 11:11:57 @registry.py:130][0m last_linear output: [None, 255]
[32m[0322 11:11:57 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:11:57 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0322 11:11:57 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0322 11:11:57 @drf_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0322 11:11:58 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=1400871, size=5.34MB[0m
[32m[0322 11:11:58 @base.py:196][0m Setup callbacks graph ...
[32m[0322 11:11:58 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 11:11:59 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:11:59 @drf_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0322 11:11:59 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0322 11:11:59 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0322 11:11:59 @base.py:212][0m Creating the session ...
2018-03-22 11:12:00.090329: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-22 11:12:07.582573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:08:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-22 11:12:07.582646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:08:00.0, compute capability: 6.1)
[32m[0322 11:12:08 @base.py:220][0m Initializing the session ...
[32m[0322 11:12:08 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn2_w_8_a_32_quant_ends_True/model-3296139 ...
[32m[0322 11:12:09 @base.py:227][0m Graph Finalized.
[32m[0322 11:12:09 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0322 11:12:09 @steps.py:127][0m Start training with global_step=3296139
[32m[0322 11:12:12 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#         |18426/173481[03:00<25:14,102.36it/s] 11%|#1        |19475/173481[03:10<25:04,102.36it/s] 21%|##1       |37080/173481[06:00<22:04,102.99it/s] 22%|##1       |38143/173481[06:10<21:54,102.99it/s] 32%|###2      |55746/173481[09:00<18:59,103.34it/s] 33%|###2      |56820/173481[09:10<18:48,103.34it/s] 43%|####2     |74447/173481[12:00<15:55,103.62it/s] 44%|####3     |75525/173481[12:10<15:45,103.62it/s] 53%|#####2    |91261/173481[15:00<13:56,98.24it/s]  53%|#####2    |91795/173481[15:10<13:51,98.24it/s] 58%|#####7    |99902/173481[18:00<19:00,64.49it/s] 58%|#####7    |100410/173481[18:10<18:52,64.49it/s] 63%|######2   |108768/173481[21:00<19:18,55.85it/s] 63%|######3   |109360/173481[21:11<19:08,55.85it/s] 68%|######8   |118021/173481[24:00<17:16,53.53it/s] 68%|######8   |118641/173481[24:11<17:04,53.53it/s] 74%|#######3  |127596/173481[27:00<14:19,53.36it/s] 74%|#######3  |128185/173481[27:11<14:08,53.36it/s] 79%|#######8  |136993/173481[30:00<11:31,52.78it/s] 79%|#######9  |137565/173481[30:11<11:20,52.78it/s] 84%|########4 |146151/173481[33:00<08:47,51.81it/s] 85%|########4 |146700/173481[33:11<08:36,51.81it/s] 89%|########9 |154575/173481[36:00<06:24,49.18it/s] 89%|########9 |155065/173481[36:11<06:14,49.18it/s] 94%|#########3|162644/173481[39:00<03:51,46.90it/s] 94%|#########4|163220/173481[39:11<03:38,46.90it/s] 99%|#########8|171103/173481[42:00<00:50,46.95it/s] 99%|#########8|171679/173481[42:12<00:38,46.95it/s]100%|##########|173481/173481[42:47<00:00,67.56it/s]
[32m[0322 11:54:59 @base.py:257][0m Epoch 1 (global_step 3469620) finished, time:2567.88 sec.
[32m[0322 11:55:00 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-3469620.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14809/18822[03:00<00:48,82.27it/s] 83%|########2 |15542/18822[03:10<00:39,82.27it/s]100%|##########|18822/18822[03:54<00:00,80.25it/s]
0
[32m[0322 11:58:55 @monitor.py:363][0m QueueInput/queue_size: 1.7445
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.355
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/output-rms: 0.011026
[32m[0322 11:58:55 @monitor.py:363][0m cross_entropy_loss: 4.2786
[32m[0322 11:58:55 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.64797
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2472
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.26803
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26398
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26413
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26298
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 11:58:55 @monitor.py:363][0m train-error-top1: 0.91125
[32m[0322 11:58:55 @monitor.py:363][0m val-error-top1: 0.91396
[32m[0322 11:58:55 @monitor.py:363][0m val-utt-error: 0.69196
[32m[0322 11:58:55 @monitor.py:363][0m validation_cost: 4.2873
[32m[0322 11:58:55 @monitor.py:363][0m wd_cost: 0.00018324
[32m[0322 11:58:55 @group.py:42][0m Callbacks took 235.180 sec in total. InferenceRunner: 234.548sec
[32m[0322 11:58:55 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8901/173481[03:00<55:28,49.45it/s]  5%|5         |9399/173481[03:10<55:18,49.45it/s] 10%|#         |18123/173481[06:00<51:27,50.33it/s] 11%|#         |18659/173481[06:10<51:16,50.33it/s] 16%|#5        |27455/173481[09:00<47:39,51.07it/s] 16%|#6        |28001/173481[09:10<47:28,51.07it/s] 21%|##        |36305/173481[12:00<45:38,50.10it/s] 21%|##1       |36811/173481[12:10<45:28,50.10it/s] 26%|##5       |44645/173481[15:00<44:36,48.14it/s] 26%|##6       |45149/173481[15:10<44:25,48.14it/s] 31%|###       |53196/173481[18:00<41:55,47.82it/s] 31%|###       |53717/173481[18:10<41:44,47.82it/s] 36%|###5      |62205/173481[21:00<37:55,48.91it/s] 36%|###6      |62791/173481[21:11<37:43,48.91it/s] 41%|####      |70506/173481[24:00<36:09,47.47it/s] 41%|####      |71058/173481[24:11<35:57,47.47it/s] 46%|####6     |79975/173481[27:00<31:13,49.90it/s] 46%|####6     |80584/173481[27:11<31:01,49.90it/s] 51%|#####1    |89314/173481[30:00<27:34,50.87it/s] 52%|#####1    |89899/173481[30:11<27:22,50.87it/s] 57%|#####7    |99124/173481[33:00<23:33,52.62it/s] 57%|#####7    |99699/173481[33:11<23:22,52.62it/s] 63%|######2   |108571/173481[36:00<20:35,52.55it/s] 63%|######2   |109159/173481[36:11<20:23,52.55it/s] 68%|######7   |117185/173481[39:00<18:44,50.08it/s] 68%|######7   |117744/173481[39:11<18:32,50.08it/s] 73%|#######2  |126310/173481[42:00<15:36,50.38it/s] 73%|#######3  |126904/173481[42:12<15:24,50.38it/s] 78%|#######8  |135394/173481[45:00<12:35,50.42it/s] 78%|#######8  |136076/173481[45:12<12:21,50.42it/s] 84%|########3 |144926/173481[48:00<09:12,51.65it/s] 84%|########3 |145509/173481[48:12<09:01,51.65it/s] 89%|########8 |153685/173481[51:00<06:35,50.11it/s] 89%|########8 |154241/173481[51:12<06:23,50.11it/s] 94%|#########3|162855/173481[54:00<03:30,50.52it/s] 94%|#########4|163479/173481[54:12<03:17,50.52it/s]100%|#########9|172640/173481[57:00<00:16,52.36it/s]100%|#########9|173417/173481[57:12<00:01,52.36it/s]100%|##########|173481/173481[57:13<00:00,50.52it/s]
[32m[0322 12:56:09 @base.py:257][0m Epoch 2 (global_step 3643101) finished, time:3433.91 sec.
[32m[0322 12:56:09 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-3643101.
[32m[0322 12:56:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,162.41it/s]
1
[32m[0322 12:58:06 @monitor.py:363][0m QueueInput/queue_size: 0.27323
[32m[0322 12:58:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.536
[32m[0322 12:58:06 @monitor.py:363][0m activation-summaries/output-rms: 0.015283
[32m[0322 12:58:06 @monitor.py:363][0m cross_entropy_loss: 3.7189
[32m[0322 12:58:06 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.65507
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2463
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.26876
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26438
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26439
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26542
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 12:58:06 @monitor.py:363][0m train-error-top1: 0.83448
[32m[0322 12:58:06 @monitor.py:363][0m val-error-top1: 0.84592
[32m[0322 12:58:06 @monitor.py:363][0m val-utt-error: 0.51259
[32m[0322 12:58:06 @monitor.py:363][0m validation_cost: 3.7451
[32m[0322 12:58:06 @monitor.py:363][0m wd_cost: 0.00018555
[32m[0322 12:58:06 @group.py:42][0m Callbacks took 117.757 sec in total. InferenceRunner: 115.909sec
[32m[0322 12:58:06 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9835/173481[03:00<49:55,54.64it/s]  6%|5         |10388/173481[03:10<49:45,54.64it/s] 12%|#1        |20004/173481[06:00<46:02,55.55it/s] 12%|#1        |20628/173481[06:10<45:51,55.55it/s] 17%|#6        |28874/173481[09:00<46:09,52.22it/s] 17%|#6        |29373/173481[09:10<45:59,52.22it/s] 22%|##1       |37864/173481[12:00<44:16,51.05it/s] 22%|##2       |38420/173481[12:10<44:05,51.05it/s] 27%|##6       |46580/173481[15:00<42:33,49.70it/s] 27%|##7       |47093/173481[15:10<42:22,49.70it/s] 32%|###2      |55952/173481[18:00<38:31,50.86it/s] 33%|###2      |56538/173481[18:10<38:19,50.86it/s] 38%|###7      |65179/173481[21:00<35:21,51.06it/s] 38%|###7      |65755/173481[21:10<35:09,51.06it/s] 44%|####3     |75498/173481[24:00<30:14,54.01it/s] 44%|####3     |76163/173481[24:11<30:01,54.01it/s] 49%|####9     |85654/173481[27:00<26:31,55.19it/s] 50%|####9     |86252/173481[27:11<26:20,55.19it/s] 55%|#####4    |95212/173481[30:00<24:06,54.12it/s] 55%|#####5    |95795/173481[30:11<23:55,54.12it/s] 60%|######    |104583/173481[33:00<21:38,53.07it/s] 61%|######    |105178/173481[33:11<21:27,53.07it/s] 66%|######5   |114354/173481[36:00<18:21,53.67it/s] 66%|######6   |114973/173481[36:11<18:10,53.67it/s] 71%|#######1  |124014/173481[39:00<15:21,53.66it/s] 72%|#######1  |124686/173481[39:11<15:09,53.66it/s] 77%|#######7  |134424/173481[42:00<11:41,55.67it/s] 78%|#######7  |135163/173481[42:11<11:28,55.67it/s] 83%|########3 |144703/173481[45:00<08:30,56.38it/s] 84%|########3 |145362/173481[45:12<08:18,56.38it/s] 89%|########9 |154873/173481[48:00<05:29,56.44it/s] 90%|########9 |155548/173481[48:12<05:17,56.44it/s] 95%|#########4|164784/173481[51:00<02:36,55.73it/s] 95%|#########5|165263/173481[51:12<02:27,55.73it/s]100%|##########|173481/173481[53:39<00:00,53.89it/s]
[32m[0322 13:51:46 @base.py:257][0m Epoch 3 (global_step 3816582) finished, time:3219.33 sec.
[32m[0322 13:51:46 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-3816582.
[32m[0322 13:51:47 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.24it/s]
2
[32m[0322 13:53:34 @monitor.py:363][0m QueueInput/queue_size: 0.4973
[32m[0322 13:53:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.03
[32m[0322 13:53:34 @monitor.py:363][0m activation-summaries/output-rms: 0.017887
[32m[0322 13:53:34 @monitor.py:363][0m cross_entropy_loss: 3.4181
[32m[0322 13:53:34 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.66282
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2458
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2696
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26481
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26472
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26676
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 13:53:34 @monitor.py:363][0m train-error-top1: 0.79301
[32m[0322 13:53:34 @monitor.py:363][0m val-error-top1: 0.79905
[32m[0322 13:53:34 @monitor.py:363][0m val-utt-error: 0.41579
[32m[0322 13:53:34 @monitor.py:363][0m validation_cost: 3.4393
[32m[0322 13:53:34 @monitor.py:363][0m wd_cost: 0.00018788
[32m[0322 13:53:34 @group.py:42][0m Callbacks took 108.503 sec in total. InferenceRunner: 106.812sec
[32m[0322 13:53:34 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10053/173481[03:00<48:46,55.84it/s]  6%|6         |10509/173481[03:10<48:38,55.84it/s] 11%|#1        |19369/173481[06:00<47:48,53.72it/s] 11%|#1        |19912/173481[06:10<47:38,53.72it/s] 17%|#7        |30058/173481[09:00<42:23,56.40it/s] 18%|#7        |30677/173481[09:10<42:12,56.40it/s] 24%|##3       |40823/173481[12:00<38:05,58.04it/s] 24%|##3       |41446/173481[12:10<37:54,58.04it/s] 29%|##9       |51085/173481[15:00<35:27,57.52it/s] 30%|##9       |51672/173481[15:10<35:17,57.52it/s] 35%|###5      |60987/173481[18:00<33:20,56.24it/s] 35%|###5      |61566/173481[18:10<33:10,56.24it/s] 41%|####      |71071/173481[21:00<30:24,56.13it/s] 41%|####1     |71739/173481[21:11<30:12,56.13it/s] 47%|####7     |81773/173481[24:00<26:28,57.74it/s] 48%|####7     |82466/173481[24:11<26:16,57.74it/s] 53%|#####3    |92099/173481[27:00<23:34,57.55it/s] 53%|#####3    |92735/173481[27:11<23:22,57.55it/s] 59%|#####9    |102738/173481[30:00<20:13,58.29it/s] 60%|#####9    |103405/173481[30:11<20:02,58.29it/s] 65%|######5   |113041/173481[33:00<17:26,57.76it/s] 66%|######5   |113644/173481[33:11<17:16,57.76it/s] 71%|#######1  |123691/173481[36:00<14:11,58.45it/s] 72%|#######1  |124337/173481[36:11<14:00,58.45it/s] 78%|#######7  |134601/173481[39:00<10:53,59.51it/s] 78%|#######7  |135282/173481[39:11<10:41,59.51it/s] 84%|########3 |145308/173481[42:00<07:53,59.49it/s] 84%|########4 |145923/173481[42:12<07:43,59.49it/s] 89%|########9 |155088/173481[45:00<05:23,56.79it/s] 90%|########9 |155778/173481[45:12<05:11,56.79it/s] 96%|#########5|165838/173481[48:00<02:11,58.22it/s] 96%|#########5|166454/173481[48:12<02:00,58.22it/s]100%|##########|173481/173481[50:27<00:00,57.31it/s]
[32m[0322 14:44:01 @base.py:257][0m Epoch 4 (global_step 3990063) finished, time:3027.21 sec.
[32m[0322 14:44:02 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-3990063.
[32m[0322 14:44:03 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,177.17it/s]
3
[32m[0322 14:45:49 @monitor.py:363][0m QueueInput/queue_size: 0.44118
[32m[0322 14:45:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.71
[32m[0322 14:45:49 @monitor.py:363][0m activation-summaries/output-rms: 0.01942
[32m[0322 14:45:49 @monitor.py:363][0m cross_entropy_loss: 3.3094
[32m[0322 14:45:49 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.66762
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2456
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2701
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26509
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26494
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26734
[32m[0322 14:45:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 14:45:49 @monitor.py:363][0m train-error-top1: 0.78202
[32m[0322 14:45:49 @monitor.py:363][0m val-error-top1: 0.77703
[32m[0322 14:45:49 @monitor.py:363][0m val-utt-error: 0.38051
[32m[0322 14:45:49 @monitor.py:363][0m validation_cost: 3.3056
[32m[0322 14:45:49 @monitor.py:363][0m wd_cost: 3.7859e-05
[32m[0322 14:45:49 @group.py:42][0m Callbacks took 108.092 sec in total. InferenceRunner: 106.251sec
[32m[0322 14:45:49 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10527/173481[03:00<46:26,58.47it/s]  6%|6         |11041/173481[03:10<46:18,58.47it/s] 12%|#1        |20052/173481[06:00<46:02,55.54it/s] 12%|#1        |20559/173481[06:10<45:53,55.54it/s] 17%|#7        |29737/173481[09:00<43:50,54.65it/s] 17%|#7        |30321/173481[09:10<43:39,54.65it/s] 23%|##3       |40344/173481[12:00<39:07,56.71it/s] 24%|##3       |40976/173481[12:10<38:56,56.71it/s] 29%|##9       |51017/173481[15:00<35:12,57.97it/s] 30%|##9       |51615/173481[15:10<35:02,57.97it/s] 36%|###5      |61754/173481[18:00<31:40,58.80it/s] 36%|###5      |62411/173481[18:10<31:29,58.80it/s] 42%|####1     |72477/173481[21:00<28:26,59.18it/s] 42%|####2     |73131/173481[21:11<28:15,59.18it/s] 48%|####7     |82902/173481[24:00<25:47,58.54it/s] 48%|####8     |83576/173481[24:11<25:35,58.54it/s] 54%|#####3    |93112/173481[27:00<23:15,57.61it/s] 54%|#####4    |93731/173481[27:11<23:04,57.61it/s] 60%|#####9    |103409/173481[30:00<20:20,57.41it/s] 60%|#####9    |104086/173481[30:11<20:08,57.41it/s] 66%|######5   |113852/173481[33:00<17:13,57.71it/s] 66%|######6   |114501/173481[33:11<17:02,57.71it/s] 72%|#######1  |124107/173481[36:00<14:21,57.33it/s] 72%|#######1  |124749/173481[36:11<14:10,57.33it/s] 77%|#######7  |134099/173481[39:00<11:38,56.40it/s] 78%|#######7  |134791/173481[39:12<11:25,56.40it/s] 83%|########3 |144363/173481[42:00<08:33,56.71it/s] 84%|########3 |145057/173481[42:12<08:21,56.71it/s] 89%|########9 |154787/173481[45:00<05:26,57.30it/s] 90%|########9 |155366/173481[45:12<05:16,57.30it/s] 95%|#########4|164393/173481[48:00<02:44,55.26it/s] 95%|#########5|165020/173481[48:12<02:33,55.26it/s]100%|##########|173481/173481[50:47<00:00,56.93it/s]
[32m[0322 15:36:37 @base.py:257][0m Epoch 5 (global_step 4163544) finished, time:3047.28 sec.
[32m[0322 15:36:37 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-4163544.
[32m[0322 15:36:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.51it/s]
4
[32m[0322 15:38:33 @monitor.py:363][0m QueueInput/queue_size: 0.86809
[32m[0322 15:38:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.417
[32m[0322 15:38:33 @monitor.py:363][0m activation-summaries/output-rms: 0.020753
[32m[0322 15:38:33 @monitor.py:363][0m cross_entropy_loss: 3.1621
[32m[0322 15:38:33 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67252
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2453
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27063
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26539
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26519
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26786
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 15:38:33 @monitor.py:363][0m train-error-top1: 0.75522
[32m[0322 15:38:33 @monitor.py:363][0m val-error-top1: 0.75856
[32m[0322 15:38:33 @monitor.py:363][0m val-utt-error: 0.35145
[32m[0322 15:38:33 @monitor.py:363][0m validation_cost: 3.2004
[32m[0322 15:38:33 @monitor.py:363][0m wd_cost: 3.815e-05
[32m[0322 15:38:33 @group.py:42][0m Callbacks took 116.228 sec in total. InferenceRunner: 114.425sec
[32m[0322 15:38:33 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10433/173481[03:00<46:53,57.96it/s]  6%|6         |10980/173481[03:10<46:43,57.96it/s] 11%|#1        |19886/173481[06:00<46:27,55.10it/s] 12%|#1        |20475/173481[06:10<46:16,55.10it/s] 17%|#7        |29731/173481[09:00<43:38,54.90it/s] 17%|#7        |30285/173481[09:10<43:28,54.90it/s] 23%|##2       |39761/173481[12:00<40:18,55.30it/s] 23%|##3       |40365/173481[12:10<40:07,55.30it/s] 29%|##8       |49941/173481[15:00<36:49,55.92it/s] 29%|##9       |50525/173481[15:10<36:38,55.92it/s] 35%|###4      |60091/173481[18:00<33:39,56.15it/s] 35%|###4      |60681/173481[18:10<33:28,56.15it/s] 40%|####      |69907/173481[21:00<31:11,55.33it/s] 41%|####      |70503/173481[21:11<31:01,55.33it/s] 46%|####5     |79606/173481[24:00<28:39,54.59it/s] 46%|####6     |80241/173481[24:11<28:27,54.59it/s] 52%|#####1    |89536/173481[27:00<25:29,54.88it/s] 52%|#####1    |90141/173481[27:11<25:18,54.88it/s] 57%|#####7    |99086/173481[30:00<22:59,53.94it/s] 57%|#####7    |99727/173481[30:11<22:47,53.94it/s] 62%|######2   |108345/173481[33:00<20:36,52.66it/s] 63%|######2   |109000/173481[33:11<20:24,52.66it/s] 68%|######8   |118248/173481[36:00<17:06,53.81it/s] 68%|######8   |118801/173481[36:11<16:56,53.81it/s] 74%|#######3  |128311/173481[39:00<13:43,54.84it/s] 74%|#######4  |129006/173481[39:12<13:31,54.84it/s] 80%|#######9  |138281/173481[42:00<10:38,55.11it/s] 80%|########  |138953/173481[42:12<10:26,55.11it/s] 86%|########5 |148616/173481[45:00<07:22,56.24it/s] 86%|########6 |149285/173481[45:12<07:10,56.24it/s] 91%|#########1|158110/173481[48:00<04:42,54.44it/s] 91%|#########1|158730/173481[48:12<04:30,54.44it/s] 97%|#########6|167661/173481[51:00<01:48,53.74it/s] 97%|#########7|168340/173481[51:12<01:35,53.74it/s]100%|##########|173481/173481[52:48<00:00,54.76it/s]
[32m[0322 16:31:21 @base.py:257][0m Epoch 6 (global_step 4337025) finished, time:3168.23 sec.
[32m[0322 16:31:22 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-4337025.
[32m[0322 16:31:23 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,175.85it/s]
5
[32m[0322 16:33:10 @monitor.py:363][0m QueueInput/queue_size: 0.36248
[32m[0322 16:33:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.33
[32m[0322 16:33:10 @monitor.py:363][0m activation-summaries/output-rms: 0.021227
[32m[0322 16:33:10 @monitor.py:363][0m cross_entropy_loss: 3.0939
[32m[0322 16:33:10 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67618
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2452
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27104
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26564
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2654
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26819
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 16:33:10 @monitor.py:363][0m train-error-top1: 0.74733
[32m[0322 16:33:10 @monitor.py:363][0m val-error-top1: 0.74529
[32m[0322 16:33:10 @monitor.py:363][0m val-utt-error: 0.33275
[32m[0322 16:33:10 @monitor.py:363][0m validation_cost: 3.1225
[32m[0322 16:33:10 @monitor.py:363][0m wd_cost: 7.6735e-06
[32m[0322 16:33:10 @group.py:42][0m Callbacks took 108.920 sec in total. InferenceRunner: 107.043sec
[32m[0322 16:33:10 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10005/173481[03:00<49:02,55.57it/s]  6%|6         |10559/173481[03:10<48:52,55.57it/s] 11%|#1        |19830/173481[06:00<46:30,55.07it/s] 12%|#1        |20364/173481[06:10<46:20,55.07it/s] 17%|#7        |30017/173481[09:00<42:50,55.82it/s] 18%|#7        |30604/173481[09:10<42:39,55.82it/s] 22%|##2       |38386/173481[12:00<44:22,50.73it/s] 22%|##2       |38847/173481[12:10<44:13,50.73it/s] 27%|##7       |47275/173481[15:00<42:01,50.04it/s] 28%|##7       |47864/173481[15:10<41:50,50.04it/s] 33%|###2      |57170/173481[18:00<37:00,52.39it/s] 33%|###3      |57727/173481[18:10<36:49,52.39it/s] 38%|###8      |66761/173481[21:00<33:39,52.83it/s] 39%|###8      |67315/173481[21:11<33:29,52.83it/s] 44%|####4     |76811/173481[24:00<29:40,54.29it/s] 45%|####4     |77396/173481[24:11<29:29,54.29it/s] 50%|####9     |86017/173481[27:00<27:40,52.67it/s] 50%|####9     |86634/173481[27:11<27:28,52.67it/s] 55%|#####5    |96090/173481[30:00<23:46,54.26it/s] 56%|#####5    |96728/173481[30:11<23:34,54.26it/s] 61%|######1   |106201/173481[33:00<20:18,55.20it/s] 62%|######1   |106842/173481[33:11<20:07,55.20it/s] 67%|######6   |115874/173481[36:00<17:37,54.46it/s] 67%|######7   |116499/173481[36:11<17:26,54.46it/s] 72%|#######2  |125427/173481[39:00<14:53,53.76it/s] 73%|#######2  |125982/173481[39:12<14:43,53.76it/s] 78%|#######7  |134520/173481[42:00<12:28,52.08it/s] 78%|#######7  |135101/173481[42:12<12:16,52.08it/s] 83%|########3 |144168/173481[45:00<09:14,52.83it/s] 83%|########3 |144819/173481[45:12<09:02,52.83it/s] 87%|########7 |151513/173481[48:00<07:57,46.04it/s] 87%|########7 |151709/173481[48:12<07:52,46.04it/s] 93%|#########2|160634/173481[51:00<04:26,48.25it/s] 93%|#########2|161288/173481[51:12<04:12,48.25it/s] 98%|#########8|170420/173481[54:00<00:59,51.12it/s] 99%|#########8|171174/173481[54:12<00:45,51.12it/s]100%|##########|173481/173481[54:53<00:00,52.68it/s]
[32m[0322 17:28:03 @base.py:257][0m Epoch 7 (global_step 4510506) finished, time:3293.32 sec.
[32m[0322 17:28:04 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-4510506.
[32m[0322 17:28:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.81it/s]
6
[32m[0322 17:29:52 @monitor.py:363][0m QueueInput/queue_size: 0.39097
[32m[0322 17:29:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.527
[32m[0322 17:29:52 @monitor.py:363][0m activation-summaries/output-rms: 0.020833
[32m[0322 17:29:52 @monitor.py:363][0m cross_entropy_loss: 3.0452
[32m[0322 17:29:52 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67865
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2452
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27133
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2658
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26554
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2684
[32m[0322 17:29:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 17:29:52 @monitor.py:363][0m train-error-top1: 0.72704
[32m[0322 17:29:52 @monitor.py:363][0m val-error-top1: 0.73829
[32m[0322 17:29:52 @monitor.py:363][0m val-utt-error: 0.32249
[32m[0322 17:29:52 @monitor.py:363][0m validation_cost: 3.0814
[32m[0322 17:29:52 @monitor.py:363][0m wd_cost: 7.7031e-06
[32m[0322 17:29:52 @group.py:42][0m Callbacks took 108.173 sec in total. InferenceRunner: 106.467sec
[32m[0322 17:29:52 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10994/173481[03:00<44:20,61.08it/s]  7%|6         |11598/173481[03:10<44:10,61.08it/s] 12%|#2        |21631/173481[06:00<42:07,60.07it/s] 13%|#2        |22235/173481[06:10<41:57,60.07it/s] 18%|#8        |31574/173481[09:00<41:05,57.55it/s] 19%|#8        |32163/173481[09:10<40:55,57.55it/s] 24%|##4       |41764/173481[12:00<38:28,57.07it/s] 24%|##4       |42369/173481[12:10<38:17,57.07it/s] 30%|###       |52248/173481[15:00<35:02,57.65it/s] 30%|###       |52840/173481[15:10<34:52,57.65it/s] 36%|###5      |62362/173481[18:00<32:32,56.91it/s] 36%|###6      |62983/173481[18:10<32:21,56.91it/s] 42%|####1     |72529/173481[21:00<29:40,56.69it/s] 42%|####2     |73050/173481[21:11<29:31,56.69it/s] 48%|####7     |82470/173481[24:00<27:06,55.95it/s] 48%|####7     |83027/173481[24:11<26:56,55.95it/s] 54%|#####3    |92873/173481[27:00<23:37,56.85it/s] 54%|#####3    |93541/173481[27:11<23:26,56.85it/s] 60%|#####9    |103569/173481[30:00<20:03,58.11it/s] 60%|######    |104178/173481[30:11<19:52,58.11it/s] 66%|######6   |114619/173481[33:00<16:25,59.70it/s] 67%|######6   |115368/173481[33:11<16:13,59.70it/s] 72%|#######2  |125369/173481[36:00<13:25,59.71it/s] 73%|#######2  |126089/173481[36:11<13:13,59.71it/s] 78%|#######8  |135984/173481[39:00<10:31,59.34it/s] 79%|#######8  |136718/173481[39:11<10:19,59.34it/s] 85%|########4 |146747/173481[42:00<07:28,59.56it/s] 85%|########4 |147423/173481[42:12<07:17,59.56it/s] 91%|######### |157481/173481[45:00<04:28,59.59it/s] 91%|#########1|158192/173481[45:12<04:16,59.59it/s] 97%|#########7|168316/173481[48:00<01:26,59.89it/s] 97%|#########7|169101/173481[48:12<01:13,59.89it/s]100%|##########|173481/173481[49:26<00:00,58.48it/s]
[32m[0322 18:19:18 @base.py:257][0m Epoch 8 (global_step 4683987) finished, time:2966.37 sec.
[32m[0322 18:19:19 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-4683987.
[32m[0322 18:19:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.20it/s]
7
[32m[0322 18:21:07 @monitor.py:363][0m QueueInput/queue_size: 0.50106
[32m[0322 18:21:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.968
[32m[0322 18:21:07 @monitor.py:363][0m activation-summaries/output-rms: 0.022025
[32m[0322 18:21:07 @monitor.py:363][0m cross_entropy_loss: 3.0213
[32m[0322 18:21:07 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6811
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2452
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27162
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26597
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26569
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2686
[32m[0322 18:21:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 18:21:07 @monitor.py:363][0m train-error-top1: 0.72852
[32m[0322 18:21:07 @monitor.py:363][0m val-error-top1: 0.73013
[32m[0322 18:21:07 @monitor.py:363][0m val-utt-error: 0.30698
[32m[0322 18:21:07 @monitor.py:363][0m validation_cost: 3.0361
[32m[0322 18:21:07 @monitor.py:363][0m wd_cost: 7.7327e-06
[32m[0322 18:21:07 @group.py:42][0m Callbacks took 108.966 sec in total. InferenceRunner: 106.840sec
[32m[0322 18:21:07 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11384/173481[03:00<42:43,63.24it/s]  7%|6         |11986/173481[03:10<42:33,63.24it/s] 12%|#2        |21392/173481[06:00<42:50,59.17it/s] 13%|#2        |21950/173481[06:10<42:40,59.17it/s] 18%|#7        |30872/173481[09:00<42:39,55.73it/s] 18%|#8        |31472/173481[09:10<42:28,55.73it/s] 24%|##3       |41428/173481[12:00<38:30,57.14it/s] 24%|##4       |42053/173481[12:10<38:20,57.14it/s] 30%|###       |52278/173481[15:00<34:25,58.67it/s] 31%|###       |52965/173481[15:10<34:14,58.67it/s] 36%|###5      |62107/173481[18:00<32:49,56.56it/s] 36%|###6      |62698/173481[18:10<32:38,56.56it/s] 42%|####1     |72812/173481[21:00<28:56,57.98it/s] 42%|####2     |73508/173481[21:11<28:44,57.98it/s] 48%|####8     |83648/173481[24:00<25:20,59.06it/s] 49%|####8     |84352/173481[24:11<25:09,59.06it/s] 55%|#####4    |94778/173481[27:00<21:42,60.42it/s] 55%|#####5    |95451/173481[27:11<21:31,60.42it/s] 61%|######    |105743/173481[30:00<18:36,60.66it/s] 61%|######1   |106461/173481[30:11<18:24,60.66it/s] 67%|######7   |116908/173481[33:00<15:22,61.33it/s] 68%|######7   |117644/173481[33:11<15:10,61.33it/s] 74%|#######3  |127613/173481[36:00<12:39,60.38it/s] 74%|#######3  |128337/173481[36:11<12:27,60.38it/s] 80%|#######9  |138417/173481[39:00<09:42,60.20it/s] 80%|########  |139128/173481[39:12<09:30,60.20it/s] 86%|########5 |148869/173481[42:00<06:56,59.11it/s] 86%|########6 |149510/173481[42:12<06:45,59.11it/s] 92%|#########1|159408/173481[45:00<03:59,58.82it/s] 92%|#########2|160124/173481[45:12<03:47,58.82it/s] 98%|#########7|169508/173481[48:00<01:09,57.43it/s] 98%|#########8|170142/173481[48:12<00:58,57.43it/s]100%|##########|173481/173481[49:15<00:00,58.69it/s]
[32m[0322 19:10:23 @base.py:257][0m Epoch 9 (global_step 4857468) finished, time:2955.81 sec.
[32m[0322 19:10:24 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-4857468.
[32m[0322 19:10:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,178.09it/s]
8
[32m[0322 19:12:10 @monitor.py:363][0m QueueInput/queue_size: 0.33137
[32m[0322 19:12:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.08
[32m[0322 19:12:10 @monitor.py:363][0m activation-summaries/output-rms: 0.022369
[32m[0322 19:12:10 @monitor.py:363][0m cross_entropy_loss: 3.0065
[32m[0322 19:12:10 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68257
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2452
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27179
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26608
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26579
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26871
[32m[0322 19:12:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 19:12:10 @monitor.py:363][0m train-error-top1: 0.72305
[32m[0322 19:12:10 @monitor.py:363][0m val-error-top1: 0.72513
[32m[0322 19:12:10 @monitor.py:363][0m val-utt-error: 0.30204
[32m[0322 19:12:10 @monitor.py:363][0m validation_cost: 3.01
[32m[0322 19:12:10 @monitor.py:363][0m wd_cost: 1.5501e-06
[32m[0322 19:12:10 @group.py:42][0m Callbacks took 107.334 sec in total. InferenceRunner: 105.699sec
[32m[0322 19:12:10 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10247/173481[03:00<47:48,56.90it/s]  6%|6         |10763/173481[03:10<47:39,56.90it/s] 12%|#1        |20364/173481[06:00<45:07,56.55it/s] 12%|#2        |20875/173481[06:10<44:58,56.55it/s] 18%|#7        |30507/173481[09:00<42:12,56.45it/s] 18%|#7        |31120/173481[09:10<42:02,56.45it/s] 25%|##5       |43620/173481[12:00<34:01,63.61it/s] 26%|##5       |44528/173481[12:10<33:47,63.61it/s] 34%|###3      |58693/173481[15:00<26:27,72.30it/s] 34%|###4      |59659/173481[15:10<26:14,72.30it/s] 42%|####2     |73695/173481[18:00<21:28,77.42it/s] 43%|####2     |74541/173481[18:10<21:17,77.42it/s] 51%|#####     |88472/173481[21:00<17:47,79.67it/s] 52%|#####1    |89411/173481[21:11<17:35,79.67it/s] 60%|#####9    |103983/173481[24:00<13:59,82.79it/s] 60%|######    |104863/173481[24:11<13:48,82.79it/s] 68%|######8   |118235/173481[27:00<11:22,80.94it/s] 69%|######8   |119107/173481[27:11<11:11,80.94it/s] 76%|#######5  |131826/173481[30:00<08:53,78.13it/s] 76%|#######6  |132642/173481[30:11<08:42,78.13it/s] 83%|########3 |144537/173481[33:00<06:30,74.17it/s] 84%|########3 |145426/173481[33:11<06:18,74.17it/s] 91%|######### |157660/173481[36:00<03:35,73.53it/s] 91%|#########1|158510/173481[36:11<03:23,73.53it/s] 98%|#########7|169692/173481[39:00<00:54,70.02it/s] 98%|#########8|170401/173481[39:12<00:43,70.02it/s]100%|##########|173481/173481[40:06<00:00,72.10it/s]
[32m[0322 19:52:16 @base.py:257][0m Epoch 10 (global_step 5030949) finished, time:2406.19 sec.
[32m[0322 19:52:17 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-5030949.
[32m[0322 19:52:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.33it/s]
9
[32m[0322 19:54:20 @monitor.py:363][0m QueueInput/queue_size: 0.34058
[32m[0322 19:54:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.094
[32m[0322 19:54:20 @monitor.py:363][0m activation-summaries/output-rms: 0.022754
[32m[0322 19:54:20 @monitor.py:363][0m cross_entropy_loss: 2.9488
[32m[0322 19:54:20 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68376
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2451
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27194
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26617
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26587
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2688
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 19:54:20 @monitor.py:363][0m train-error-top1: 0.71623
[32m[0322 19:54:20 @monitor.py:363][0m val-error-top1: 0.72211
[32m[0322 19:54:20 @monitor.py:363][0m val-utt-error: 0.29901
[32m[0322 19:54:20 @monitor.py:363][0m validation_cost: 2.9961
[32m[0322 19:54:20 @monitor.py:363][0m wd_cost: 1.553e-06
[32m[0322 19:54:20 @group.py:42][0m Callbacks took 123.512 sec in total. InferenceRunner: 121.979sec
[32m[0322 19:54:20 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10666/173481[03:00<45:47,59.25it/s]  6%|6         |11205/173481[03:10<45:38,59.25it/s] 12%|#1        |20534/173481[06:00<44:45,56.95it/s] 12%|#2        |21111/173481[06:10<44:35,56.95it/s] 17%|#7        |29964/173481[09:00<43:49,54.57it/s] 18%|#7        |30521/173481[09:10<43:39,54.57it/s] 23%|##3       |40323/173481[12:00<39:36,56.02it/s] 24%|##3       |40905/173481[12:10<39:26,56.02it/s] 29%|##9       |51031/173481[15:00<35:22,57.70it/s] 30%|##9       |51615/173481[15:10<35:12,57.70it/s] 36%|###5      |61800/173481[18:00<31:41,58.74it/s] 36%|###5      |62397/173481[18:10<31:30,58.74it/s] 42%|####1     |72155/173481[21:00<29:03,58.13it/s] 42%|####1     |72775/173481[21:11<28:52,58.13it/s] 48%|####7     |82556/173481[24:00<26:08,57.95it/s] 48%|####7     |83247/173481[24:11<25:57,57.95it/s] 53%|#####3    |92664/173481[27:00<23:36,57.04it/s] 54%|#####3    |93328/173481[27:11<23:25,57.04it/s] 59%|#####9    |102917/173481[30:00<20:37,57.00it/s] 60%|#####9    |103558/173481[30:11<20:26,57.00it/s] 65%|######5   |113296/173481[33:00<17:29,57.33it/s] 66%|######5   |114015/173481[33:11<17:17,57.33it/s] 71%|#######1  |123651/173481[36:00<14:27,57.42it/s] 72%|#######1  |124364/173481[36:11<14:15,57.42it/s] 77%|#######7  |133901/173481[39:00<11:32,57.18it/s] 78%|#######7  |134625/173481[39:11<11:19,57.18it/s] 83%|########3 |144719/173481[42:00<08:10,58.60it/s] 84%|########3 |145414/173481[42:12<07:58,58.60it/s] 89%|########9 |155098/173481[45:00<05:16,58.13it/s] 90%|########9 |155785/173481[45:12<05:04,58.13it/s] 95%|#########5|165341/173481[48:00<02:21,57.51it/s] 96%|#########5|166000/173481[48:12<02:10,57.51it/s]100%|##########|173481/173481[50:21<00:00,57.41it/s]
[32m[0322 20:44:41 @base.py:257][0m Epoch 11 (global_step 5204430) finished, time:3021.64 sec.
[32m[0322 20:44:42 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-5204430.
[32m[0322 20:44:44 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.31it/s]
10
[32m[0322 20:46:31 @monitor.py:363][0m QueueInput/queue_size: 0.47932
[32m[0322 20:46:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.087
[32m[0322 20:46:31 @monitor.py:363][0m activation-summaries/output-rms: 0.023066
[32m[0322 20:46:31 @monitor.py:363][0m cross_entropy_loss: 2.9344
[32m[0322 20:46:31 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68492
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2451
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27207
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26625
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26594
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26889
[32m[0322 20:46:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 20:46:31 @monitor.py:363][0m train-error-top1: 0.72044
[32m[0322 20:46:31 @monitor.py:363][0m val-error-top1: 0.71821
[32m[0322 20:46:31 @monitor.py:363][0m val-utt-error: 0.29402
[32m[0322 20:46:31 @monitor.py:363][0m validation_cost: 2.9729
[32m[0322 20:46:31 @monitor.py:363][0m wd_cost: 1.5558e-06
[32m[0322 20:46:31 @group.py:42][0m Callbacks took 109.451 sec in total. InferenceRunner: 106.764sec
[32m[0322 20:46:31 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10875/173481[03:00<44:51,60.41it/s]  7%|6         |11404/173481[03:10<44:42,60.41it/s] 12%|#2        |21323/173481[06:00<42:50,59.20it/s] 13%|#2        |21969/173481[06:10<42:39,59.20it/s] 18%|#8        |31568/173481[09:00<40:45,58.04it/s] 19%|#8        |32149/173481[09:10<40:35,58.04it/s] 24%|##3       |41175/173481[12:00<39:39,55.60it/s] 24%|##4       |41695/173481[12:10<39:30,55.60it/s] 29%|##9       |50923/173481[15:00<37:13,54.86it/s] 30%|##9       |51490/173481[15:10<37:03,54.86it/s] 35%|###5      |61104/173481[18:00<33:37,55.70it/s] 36%|###5      |61708/173481[18:10<33:26,55.70it/s] 41%|####      |70870/173481[21:00<31:06,54.96it/s] 41%|####1     |71521/173481[21:11<30:55,54.96it/s] 47%|####6     |81235/173481[24:00<27:20,56.24it/s] 47%|####7     |81889/173481[24:11<27:08,56.24it/s] 53%|#####2    |91375/173481[27:00<24:18,56.28it/s] 53%|#####3    |92024/173481[27:11<24:07,56.28it/s] 59%|#####8    |101700/173481[30:00<21:03,56.81it/s] 59%|#####8    |102334/173481[30:11<20:52,56.81it/s] 65%|######4   |111964/173481[33:00<18:00,56.92it/s] 65%|######4   |112606/173481[33:11<17:49,56.92it/s] 70%|#######   |121906/173481[36:00<15:19,56.06it/s] 71%|#######   |122541/173481[36:11<15:08,56.06it/s] 76%|#######6  |131848/173481[39:00<12:28,55.64it/s] 76%|#######6  |132511/173481[39:11<12:16,55.64it/s] 82%|########1 |141920/173481[42:00<09:25,55.79it/s] 82%|########2 |142578/173481[42:12<09:13,55.79it/s] 88%|########7 |152324/173481[45:00<06:12,56.78it/s] 88%|########8 |153049/173481[45:12<05:59,56.78it/s] 94%|#########4|163238/173481[48:00<02:54,58.64it/s] 95%|#########4|163976/173481[48:12<02:42,58.64it/s]100%|##########|173481/173481[50:47<00:00,56.93it/s]
[32m[0322 21:37:18 @base.py:257][0m Epoch 12 (global_step 5377911) finished, time:3047.10 sec.
[32m[0322 21:37:19 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-5377911.
[32m[0322 21:37:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:48<00:00,173.99it/s]
11
[32m[0322 21:39:08 @monitor.py:363][0m QueueInput/queue_size: 0.36644
[32m[0322 21:39:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.383
[32m[0322 21:39:08 @monitor.py:363][0m activation-summaries/output-rms: 0.022305
[32m[0322 21:39:08 @monitor.py:363][0m cross_entropy_loss: 2.9196
[32m[0322 21:39:08 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6855
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2451
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27215
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26629
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26598
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26893
[32m[0322 21:39:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 21:39:08 @monitor.py:363][0m train-error-top1: 0.70532
[32m[0322 21:39:08 @monitor.py:363][0m val-error-top1: 0.71758
[32m[0322 21:39:08 @monitor.py:363][0m val-utt-error: 0.2903
[32m[0322 21:39:08 @monitor.py:363][0m validation_cost: 2.9672
[32m[0322 21:39:08 @monitor.py:363][0m wd_cost: 3.1145e-07
[32m[0322 21:39:08 @group.py:42][0m Callbacks took 110.384 sec in total. InferenceRunner: 108.189sec
[32m[0322 21:39:08 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11609/173481[03:00<41:50,64.49it/s]  7%|7         |12213/173481[03:10<41:40,64.49it/s] 13%|#3        |22824/173481[06:00<39:37,63.38it/s] 14%|#3        |23468/173481[06:10<39:27,63.38it/s] 19%|#8        |32791/173481[09:00<39:40,59.10it/s] 19%|#9        |33370/173481[09:10<39:30,59.10it/s] 25%|##4       |43181/173481[12:00<37:11,58.40it/s] 25%|##5       |43803/173481[12:10<37:00,58.40it/s] 31%|###       |53455/173481[15:00<34:39,57.73it/s] 31%|###1      |54043/173481[15:10<34:28,57.73it/s] 37%|###6      |63822/173481[18:00<31:41,57.66it/s] 37%|###7      |64503/173481[18:10<31:30,57.66it/s] 43%|####3     |75194/173481[21:00<27:10,60.29it/s] 44%|####3     |75911/173481[21:11<26:58,60.29it/s] 50%|####9     |86624/173481[24:00<23:24,61.85it/s] 50%|#####     |87313/173481[24:11<23:13,61.85it/s] 57%|#####6    |98119/173481[27:00<19:59,62.84it/s] 57%|#####6    |98779/173481[27:11<19:48,62.84it/s] 63%|######2   |108905/173481[30:00<17:32,61.34it/s] 63%|######3   |109623/173481[30:11<17:20,61.34it/s] 70%|######9   |121148/173481[33:00<13:31,64.51it/s] 70%|#######   |121953/173481[33:11<13:18,64.51it/s] 79%|#######8  |136314/173481[36:00<08:28,73.07it/s] 79%|#######9  |137320/173481[36:11<08:14,73.07it/s] 88%|########8 |153165/173481[39:00<04:07,82.08it/s] 89%|########8 |154292/173481[39:12<03:53,82.08it/s] 97%|#########6|168205/173481[42:00<01:03,82.81it/s] 97%|#########7|169009/173481[42:12<00:54,82.81it/s]100%|##########|173481/173481[43:22<00:00,66.66it/s]
[32m[0322 22:22:31 @base.py:257][0m Epoch 13 (global_step 5551392) finished, time:2602.29 sec.
[32m[0322 22:22:32 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-5551392.
[32m[0322 22:22:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,171.75it/s]
12
[32m[0322 22:24:22 @monitor.py:363][0m QueueInput/queue_size: 0.43609
[32m[0322 22:24:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.848
[32m[0322 22:24:22 @monitor.py:363][0m activation-summaries/output-rms: 0.023092
[32m[0322 22:24:22 @monitor.py:363][0m cross_entropy_loss: 2.9346
[32m[0322 22:24:22 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68607
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27222
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26634
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26602
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26897
[32m[0322 22:24:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 22:24:22 @monitor.py:363][0m train-error-top1: 0.71002
[32m[0322 22:24:22 @monitor.py:363][0m val-error-top1: 0.71523
[32m[0322 22:24:22 @monitor.py:363][0m val-utt-error: 0.28637
[32m[0322 22:24:22 @monitor.py:363][0m validation_cost: 2.9543
[32m[0322 22:24:22 @monitor.py:363][0m wd_cost: 3.1173e-07
[32m[0322 22:24:22 @group.py:42][0m Callbacks took 111.415 sec in total. InferenceRunner: 109.603sec
[32m[0322 22:24:22 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11813/173481[03:00<41:03,65.63it/s]  7%|7         |12412/173481[03:10<40:54,65.63it/s] 13%|#2        |22253/173481[06:00<40:56,61.57it/s] 13%|#3        |22879/173481[06:10<40:45,61.57it/s] 19%|#9        |33388/173481[09:00<37:50,61.71it/s] 20%|#9        |34000/173481[09:10<37:40,61.71it/s] 26%|##5       |44938/173481[12:00<34:03,62.91it/s] 26%|##6       |45632/173481[12:10<33:52,62.91it/s] 32%|###2      |56198/173481[15:00<31:09,62.73it/s] 33%|###2      |56840/173481[15:10<30:59,62.73it/s] 39%|###8      |67440/173481[18:00<28:14,62.59it/s] 39%|###9      |68140/173481[18:10<28:03,62.59it/s] 45%|####5     |78313/173481[21:00<25:48,61.47it/s] 46%|####5     |78980/173481[21:11<25:37,61.47it/s] 52%|#####1    |89598/173481[24:00<22:31,62.07it/s] 52%|#####2    |90307/173481[24:11<22:19,62.07it/s] 58%|#####8    |101184/173481[27:00<19:03,63.20it/s] 59%|#####8    |101831/173481[27:11<18:53,63.20it/s] 65%|######4   |112453/173481[30:00<16:10,62.90it/s] 65%|######5   |113181/173481[30:11<15:58,62.90it/s] 71%|#######1  |123919/173481[33:00<13:03,63.29it/s] 72%|#######1  |124662/173481[33:11<12:51,63.29it/s] 78%|#######8  |135646/173481[36:00<09:49,64.21it/s] 79%|#######8  |136417/173481[36:11<09:37,64.21it/s] 85%|########4 |147194/173481[39:00<06:49,64.18it/s] 85%|########5 |147937/173481[39:12<06:37,64.18it/s] 91%|#########1|158638/173481[42:00<03:52,63.87it/s] 92%|#########1|159428/173481[42:12<03:40,63.87it/s] 98%|#########7|169753/173481[45:00<00:59,62.79it/s] 98%|#########8|170436/173481[45:12<00:48,62.79it/s]100%|##########|173481/173481[46:03<00:00,62.78it/s]
[32m[0322 23:10:25 @base.py:257][0m Epoch 14 (global_step 5724873) finished, time:2763.42 sec.
[32m[0322 23:10:26 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-5724873.
[32m[0322 23:10:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,177.07it/s]
13
[32m[0322 23:12:14 @monitor.py:363][0m QueueInput/queue_size: 0.45347
[32m[0322 23:12:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.048
[32m[0322 23:12:14 @monitor.py:363][0m activation-summaries/output-rms: 0.023127
[32m[0322 23:12:14 @monitor.py:363][0m cross_entropy_loss: 2.9379
[32m[0322 23:12:14 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68651
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27228
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26637
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26606
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26901
[32m[0322 23:12:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 23:12:14 @monitor.py:363][0m train-error-top1: 0.70727
[32m[0322 23:12:14 @monitor.py:363][0m val-error-top1: 0.71332
[32m[0322 23:12:14 @monitor.py:363][0m val-utt-error: 0.286
[32m[0322 23:12:14 @monitor.py:363][0m validation_cost: 2.9458
[32m[0322 23:12:14 @monitor.py:363][0m wd_cost: 3.1195e-07
[32m[0322 23:12:14 @group.py:42][0m Callbacks took 108.274 sec in total. InferenceRunner: 106.306sec
[32m[0322 23:12:14 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10927/173481[03:00<44:38,60.69it/s]  7%|6         |11481/173481[03:10<44:29,60.69it/s] 13%|#2        |21892/173481[06:00<41:33,60.80it/s] 13%|#2        |22391/173481[06:10<41:25,60.80it/s] 19%|#8        |32592/173481[09:00<39:04,60.10it/s] 19%|#9        |33248/173481[09:10<38:53,60.10it/s] 26%|##5       |44329/173481[12:00<34:24,62.55it/s] 26%|##5       |45045/173481[12:10<34:13,62.55it/s] 32%|###2      |56225/173481[15:00<30:24,64.27it/s] 33%|###2      |56960/173481[15:10<30:12,64.27it/s] 39%|###9      |67880/173481[18:00<27:17,64.51it/s] 40%|###9      |68567/173481[18:10<27:06,64.51it/s] 46%|####5     |79524/173481[21:00<24:14,64.60it/s] 46%|####6     |80266/173481[21:11<24:02,64.60it/s] 53%|#####2    |91332/173481[24:00<21:02,65.09it/s] 53%|#####3    |92071/173481[24:11<20:50,65.09it/s] 60%|#####9    |103914/173481[27:00<17:11,67.41it/s] 60%|######    |104791/173481[27:11<16:58,67.41it/s] 68%|######7   |117861/173481[30:00<12:51,72.09it/s] 69%|######8   |118846/173481[30:11<12:37,72.09it/s] 77%|#######6  |132768/173481[33:00<08:48,77.08it/s] 77%|#######7  |133735/173481[33:11<08:35,77.08it/s] 85%|########4 |146955/173481[36:00<05:40,77.94it/s] 85%|########5 |147851/173481[36:11<05:28,77.94it/s] 92%|#########1|159187/173481[39:00<03:16,72.60it/s] 92%|#########2|159979/173481[39:12<03:05,72.60it/s]100%|#########9|172827/173481[42:00<00:08,74.15it/s]100%|##########|173481/173481[42:08<00:00,68.61it/s]
[32m[0322 23:54:22 @base.py:257][0m Epoch 15 (global_step 5898354) finished, time:2528.42 sec.
[32m[0322 23:54:23 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-5898354.
[32m[0322 23:54:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,172.40it/s]
14
[32m[0322 23:56:13 @monitor.py:363][0m QueueInput/queue_size: 0.87931
[32m[0322 23:56:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.1
[32m[0322 23:56:13 @monitor.py:363][0m activation-summaries/output-rms: 0.023204
[32m[0322 23:56:13 @monitor.py:363][0m cross_entropy_loss: 2.9047
[32m[0322 23:56:13 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68669
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2723
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26639
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26608
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26903
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0322 23:56:13 @monitor.py:363][0m train-error-top1: 0.70866
[32m[0322 23:56:13 @monitor.py:363][0m val-error-top1: 0.71309
[32m[0322 23:56:13 @monitor.py:363][0m val-utt-error: 0.28775
[32m[0322 23:56:13 @monitor.py:363][0m validation_cost: 2.9467
[32m[0322 23:56:13 @monitor.py:363][0m wd_cost: 6.2411e-08
[32m[0322 23:56:13 @group.py:42][0m Callbacks took 110.928 sec in total. InferenceRunner: 109.193sec
[32m[0322 23:56:13 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15818/173481[03:00<29:54,87.87it/s] 10%|9         |16750/173481[03:10<29:43,87.87it/s] 18%|#8        |31942/173481[06:00<26:35,88.72it/s] 19%|#8        |32487/173481[06:10<26:29,88.72it/s] 24%|##3       |41101/173481[09:00<34:07,64.66it/s] 24%|##4       |41665/173481[09:10<33:58,64.66it/s] 29%|##9       |50516/173481[12:00<35:26,57.82it/s] 29%|##9       |51086/173481[12:10<35:16,57.82it/s] 35%|###4      |60156/173481[15:00<33:58,55.61it/s] 35%|###5      |60817/173481[15:10<33:46,55.61it/s] 41%|####      |70781/173481[18:00<29:53,57.26it/s] 41%|####1     |71337/173481[18:10<29:43,57.26it/s] 46%|####6     |80315/173481[21:00<28:13,55.03it/s] 47%|####6     |80936/173481[21:11<28:01,55.03it/s] 52%|#####1    |89881/173481[24:00<25:46,54.07it/s] 52%|#####2    |90525/173481[24:11<25:34,54.07it/s] 57%|#####7    |99368/173481[27:00<23:08,53.38it/s] 58%|#####7    |99981/173481[27:11<22:57,53.38it/s] 63%|######2   |108618/173481[30:00<20:38,52.36it/s] 63%|######2   |109238/173481[30:11<20:26,52.36it/s] 68%|######7   |117896/173481[33:00<17:49,51.95it/s] 68%|######8   |118435/173481[33:11<17:39,51.95it/s] 73%|#######3  |127392/173481[36:00<14:40,52.35it/s] 74%|#######3  |127990/173481[36:11<14:29,52.35it/s] 79%|#######8  |136781/173481[39:00<11:42,52.25it/s] 79%|#######9  |137388/173481[39:12<11:30,52.25it/s] 84%|########4 |146256/173481[42:00<08:39,52.44it/s] 85%|########4 |146865/173481[42:12<08:27,52.44it/s] 90%|########9 |156061/173481[45:00<05:26,53.43it/s] 90%|######### |156670/173481[45:12<05:14,53.43it/s] 95%|#########5|165343/173481[48:00<02:35,52.48it/s] 96%|#########5|165940/173481[48:12<02:23,52.48it/s]100%|##########|173481/173481[50:45<00:00,56.96it/s]
[32m[0323 00:46:59 @base.py:257][0m Epoch 16 (global_step 6071835) finished, time:3045.65 sec.
[32m[0323 00:46:59 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-6071835.
[32m[0323 00:47:01 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,171.46it/s]
15
[32m[0323 00:48:51 @monitor.py:363][0m QueueInput/queue_size: 0.48921
[32m[0323 00:48:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.072
[32m[0323 00:48:51 @monitor.py:363][0m activation-summaries/output-rms: 0.023441
[32m[0323 00:48:51 @monitor.py:363][0m cross_entropy_loss: 2.8951
[32m[0323 00:48:51 @monitor.py:363][0m lr: 2.4414e-07
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68688
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2449
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27233
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26642
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2661
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26905
[32m[0323 00:48:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 00:48:51 @monitor.py:363][0m train-error-top1: 0.71417
[32m[0323 00:48:51 @monitor.py:363][0m val-error-top1: 0.71171
[32m[0323 00:48:51 @monitor.py:363][0m val-utt-error: 0.28424
[32m[0323 00:48:51 @monitor.py:363][0m validation_cost: 2.9375
[32m[0323 00:48:51 @monitor.py:363][0m wd_cost: 6.2431e-08
[32m[0323 00:48:51 @group.py:42][0m Callbacks took 112.184 sec in total. InferenceRunner: 109.787sec
[32m[0323 00:48:51 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9815/173481[03:00<50:01,54.52it/s]  6%|5         |10354/173481[03:10<49:51,54.52it/s] 11%|#1        |19291/173481[06:00<47:58,53.57it/s] 11%|#1        |19799/173481[06:10<47:48,53.57it/s] 17%|#6        |28730/173481[09:00<45:31,53.00it/s] 17%|#6        |29336/173481[09:10<45:19,53.00it/s] 22%|##1       |37527/173481[12:00<44:33,50.85it/s] 22%|##1       |38024/173481[12:10<44:23,50.85it/s] 27%|##6       |45978/173481[15:00<43:31,48.82it/s] 27%|##6       |46489/173481[15:10<43:21,48.82it/s] 32%|###1      |54695/173481[18:00<40:43,48.62it/s] 32%|###1      |55249/173481[18:10<40:31,48.62it/s] 37%|###6      |63760/173481[21:00<36:58,49.47it/s] 37%|###7      |64259/173481[21:11<36:47,49.47it/s] 42%|####1     |72855/173481[24:00<33:32,49.99it/s] 42%|####2     |73384/173481[24:11<33:22,49.99it/s] 47%|####7     |82235/173481[27:00<29:48,51.03it/s] 48%|####7     |82814/173481[27:11<29:36,51.03it/s] 53%|#####2    |91605/173481[30:00<26:28,51.53it/s] 53%|#####3    |92184/173481[30:11<26:17,51.53it/s] 58%|#####8    |100982/173481[33:00<23:19,51.81it/s] 59%|#####8    |101589/173481[33:11<23:07,51.81it/s] 64%|######3   |110660/173481[36:00<19:50,52.77it/s] 64%|######4   |111279/173481[36:11<19:38,52.77it/s] 69%|######8   |119700/173481[39:00<17:25,51.46it/s] 69%|######9   |120328/173481[39:12<17:12,51.46it/s] 74%|#######4  |129025/173481[42:00<14:21,51.62it/s] 75%|#######4  |129632/173481[42:12<14:09,51.62it/s] 80%|#######9  |138245/173481[45:00<11:25,51.42it/s] 80%|########  |138879/173481[45:12<11:12,51.42it/s] 85%|########5 |147740/173481[48:00<08:14,52.07it/s] 86%|########5 |148382/173481[48:12<08:02,52.07it/s] 91%|######### |157430/173481[51:00<05:03,52.93it/s] 91%|#########1|158069/173481[51:12<04:51,52.93it/s] 96%|#########6|166704/173481[54:00<02:09,52.22it/s] 96%|#########6|167294/173481[54:12<01:58,52.22it/s]100%|##########|173481/173481[56:11<00:00,51.45it/s]
[32m[0323 01:45:02 @base.py:257][0m Epoch 17 (global_step 6245316) finished, time:3371.56 sec.
[32m[0323 01:45:03 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-6245316.
[32m[0323 01:45:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:48<00:00,174.26it/s]
16
[32m[0323 01:46:53 @monitor.py:363][0m QueueInput/queue_size: 0.34687
[32m[0323 01:46:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.407
[32m[0323 01:46:53 @monitor.py:363][0m activation-summaries/output-rms: 0.022729
[32m[0323 01:46:53 @monitor.py:363][0m cross_entropy_loss: 2.887
[32m[0323 01:46:53 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6868
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2449
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27235
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26643
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26611
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26907
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 01:46:53 @monitor.py:363][0m train-error-top1: 0.69856
[32m[0323 01:46:53 @monitor.py:363][0m val-error-top1: 0.71224
[32m[0323 01:46:53 @monitor.py:363][0m val-utt-error: 0.28169
[32m[0323 01:46:53 @monitor.py:363][0m validation_cost: 2.9383
[32m[0323 01:46:53 @monitor.py:363][0m wd_cost: 1.2486e-08
[32m[0323 01:46:53 @group.py:42][0m Callbacks took 110.949 sec in total. InferenceRunner: 108.024sec
[32m[0323 01:46:53 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10744/173481[03:00<45:27,59.68it/s]  7%|6         |11301/173481[03:10<45:17,59.68it/s] 12%|#2        |21574/173481[06:00<42:15,59.92it/s] 13%|#2        |22124/173481[06:10<42:06,59.92it/s] 18%|#7        |30968/173481[09:00<42:34,55.79it/s] 18%|#8        |31515/173481[09:10<42:24,55.79it/s] 23%|##3       |40069/173481[12:00<41:55,53.04it/s] 23%|##3       |40622/173481[12:10<41:44,53.04it/s] 30%|###       |52777/173481[15:00<33:12,60.57it/s] 31%|###       |53618/173481[15:10<32:58,60.57it/s] 39%|###9      |68520/173481[18:00<24:26,71.57it/s] 40%|###9      |69143/173481[18:10<24:17,71.57it/s] 45%|####5     |78634/173481[21:00<25:06,62.95it/s] 46%|####5     |79201/173481[21:11<24:57,62.95it/s] 51%|#####     |87919/173481[24:00<25:09,56.69it/s] 51%|#####1    |88538/173481[24:11<24:58,56.69it/s] 56%|#####6    |97236/173481[27:00<23:29,54.11it/s] 56%|#####6    |97858/173481[27:11<23:17,54.11it/s] 61%|######1   |106664/173481[30:00<20:55,53.23it/s] 62%|######1   |107318/173481[30:11<20:43,53.23it/s] 67%|######7   |116639/173481[33:00<17:26,54.30it/s] 68%|######7   |117265/173481[33:11<17:15,54.30it/s] 73%|#######2  |126499/173481[36:00<14:21,54.53it/s] 73%|#######3  |127151/173481[36:11<14:09,54.53it/s] 79%|#######9  |137259/173481[39:00<10:35,57.03it/s] 80%|#######9  |137968/173481[39:12<10:22,57.03it/s] 85%|########5 |147879/173481[42:00<07:21,57.99it/s] 86%|########5 |148559/173481[42:12<07:09,57.99it/s] 91%|#########1|158594/173481[45:00<04:13,58.74it/s] 92%|#########1|159274/173481[45:12<04:01,58.74it/s] 98%|#########7|169215/173481[48:00<01:12,58.87it/s] 98%|#########7|169935/173481[48:12<01:00,58.87it/s]100%|##########|173481/173481[49:12<00:00,58.75it/s]
[32m[0323 02:36:06 @base.py:257][0m Epoch 18 (global_step 6418797) finished, time:2952.78 sec.
[32m[0323 02:36:07 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.34it/s]
17
[32m[0323 02:37:59 @monitor.py:363][0m QueueInput/queue_size: 0.3833
[32m[0323 02:37:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.836
[32m[0323 02:37:59 @monitor.py:363][0m activation-summaries/output-rms: 0.023405
[32m[0323 02:37:59 @monitor.py:363][0m cross_entropy_loss: 2.9105
[32m[0323 02:37:59 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68657
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2449
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27236
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26644
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26612
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26907
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 02:37:59 @monitor.py:363][0m train-error-top1: 0.70227
[32m[0323 02:37:59 @monitor.py:363][0m val-error-top1: 0.71118
[32m[0323 02:37:59 @monitor.py:363][0m val-utt-error: 0.28159
[32m[0323 02:37:59 @monitor.py:363][0m validation_cost: 2.9324
[32m[0323 02:37:59 @monitor.py:363][0m wd_cost: 1.2483e-08
[32m[0323 02:37:59 @group.py:42][0m Callbacks took 113.118 sec in total. InferenceRunner: 112.489sec
[32m[0323 02:37:59 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17471/173481[03:00<26:47,97.06it/s] 10%|#         |18202/173481[03:10<26:39,97.06it/s] 17%|#7        |29518/173481[06:00<30:17,79.21it/s] 17%|#7        |30216/173481[06:10<30:08,79.21it/s] 24%|##4       |41788/173481[09:00<29:57,73.27it/s] 24%|##4       |42462/173481[09:10<29:48,73.27it/s] 31%|###       |53715/173481[12:00<28:41,69.59it/s] 31%|###1      |54380/173481[12:10<28:31,69.59it/s] 38%|###7      |65116/173481[15:00<27:14,66.31it/s] 38%|###7      |65826/173481[15:10<27:03,66.31it/s] 44%|####4     |76658/173481[18:00<24:45,65.19it/s] 45%|####4     |77267/173481[18:10<24:35,65.19it/s] 51%|#####     |87989/173481[21:00<22:14,64.05it/s] 51%|#####1    |88688/173481[21:11<22:03,64.05it/s] 57%|#####7    |99618/173481[24:00<19:08,64.32it/s] 58%|#####7    |100289/173481[24:11<18:57,64.32it/s] 64%|######3   |110800/173481[27:00<16:31,63.20it/s] 64%|######4   |111546/173481[27:11<16:20,63.20it/s] 71%|#######   |122389/173481[30:00<13:21,63.78it/s] 71%|#######   |123167/173481[30:11<13:08,63.78it/s] 77%|#######7  |134018/173481[33:00<10:14,64.19it/s] 78%|#######7  |134760/173481[33:11<10:03,64.19it/s] 84%|########3 |145302/173481[36:00<07:24,63.43it/s] 84%|########4 |146025/173481[36:11<07:12,63.43it/s] 90%|######### |156837/173481[39:00<04:21,63.75it/s] 91%|######### |157627/173481[39:12<04:08,63.75it/s] 96%|#########6|167182/173481[42:00<01:44,60.45it/s] 97%|#########6|167887/173481[42:12<01:32,60.45it/s]100%|##########|173481/173481[43:50<00:00,65.95it/s]
[32m[0323 03:21:50 @base.py:257][0m Epoch 19 (global_step 6592278) finished, time:2630.32 sec.
[32m[0323 03:21:50 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-6592278.
[32m[0323 03:21:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.43it/s]
18
[32m[0323 03:23:53 @monitor.py:363][0m QueueInput/queue_size: 0.29013
[32m[0323 03:23:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.045
[32m[0323 03:23:53 @monitor.py:363][0m activation-summaries/output-rms: 0.023331
[32m[0323 03:23:53 @monitor.py:363][0m cross_entropy_loss: 2.9214
[32m[0323 03:23:53 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68635
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2449
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26613
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26908
[32m[0323 03:23:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 03:23:53 @monitor.py:363][0m train-error-top1: 0.70406
[32m[0323 03:23:53 @monitor.py:363][0m val-error-top1: 0.71028
[32m[0323 03:23:53 @monitor.py:363][0m val-utt-error: 0.28376
[32m[0323 03:23:53 @monitor.py:363][0m validation_cost: 2.9295
[32m[0323 03:23:53 @monitor.py:363][0m wd_cost: 1.248e-08
[32m[0323 03:23:53 @group.py:42][0m Callbacks took 123.170 sec in total. InferenceRunner: 121.107sec
[32m[0323 03:23:53 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17527/173481[03:00<26:41,97.37it/s] 11%|#         |18474/173481[03:10<26:31,97.37it/s] 16%|#6        |28377/173481[06:00<32:29,74.45it/s] 17%|#6        |28967/173481[06:10<32:21,74.45it/s] 23%|##2       |39213/173481[09:00<33:36,66.57it/s] 23%|##2       |39881/173481[09:10<33:26,66.57it/s] 29%|##9       |50591/173481[12:00<31:35,64.84it/s] 30%|##9       |51209/173481[12:10<31:25,64.84it/s] 35%|###5      |61398/173481[15:00<29:57,62.35it/s] 36%|###5      |62092/173481[15:10<29:46,62.35it/s] 42%|####1     |72582/173481[18:00<27:01,62.24it/s] 42%|####2     |73301/173481[18:10<26:49,62.24it/s] 48%|####8     |84090/173481[21:00<23:37,63.07it/s] 49%|####8     |84792/173481[21:11<23:26,63.07it/s] 55%|#####4    |94852/173481[24:00<21:20,61.38it/s] 55%|#####5    |95471/173481[24:11<21:10,61.38it/s] 62%|######1   |107034/173481[27:00<17:12,64.37it/s] 62%|######2   |107858/173481[27:11<16:59,64.37it/s] 69%|######9   |120529/173481[30:00<12:44,69.27it/s] 70%|#######   |121477/173481[30:11<12:30,69.27it/s] 78%|#######7  |134883/173481[33:00<08:40,74.14it/s] 78%|#######8  |135679/173481[33:11<08:29,74.14it/s] 85%|########5 |147537/173481[36:00<05:59,72.14it/s] 86%|########5 |148481/173481[36:11<05:46,72.14it/s] 92%|#########2|159713/173481[39:00<03:17,69.82it/s] 92%|#########2|160411/173481[39:12<03:07,69.82it/s] 99%|#########9|172338/173481[42:00<00:16,69.98it/s]100%|#########9|173281/173481[42:12<00:02,69.98it/s]100%|##########|173481/173481[42:14<00:00,68.44it/s]
[32m[0323 04:06:07 @base.py:257][0m Epoch 20 (global_step 6765759) finished, time:2534.64 sec.
[32m[0323 04:06:08 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-6765759.
[32m[0323 04:06:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.62it/s]
19
[32m[0323 04:07:56 @monitor.py:363][0m QueueInput/queue_size: 0.45126
[32m[0323 04:07:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.078
[32m[0323 04:07:56 @monitor.py:363][0m activation-summaries/output-rms: 0.023228
[32m[0323 04:07:56 @monitor.py:363][0m cross_entropy_loss: 2.8898
[32m[0323 04:07:56 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68598
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2449
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26614
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26909
[32m[0323 04:07:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 04:07:56 @monitor.py:363][0m train-error-top1: 0.70632
[32m[0323 04:07:56 @monitor.py:363][0m val-error-top1: 0.71066
[32m[0323 04:07:56 @monitor.py:363][0m val-utt-error: 0.2844
[32m[0323 04:07:56 @monitor.py:363][0m validation_cost: 2.9336
[32m[0323 04:07:56 @monitor.py:363][0m wd_cost: 2.495e-09
[32m[0323 04:07:56 @group.py:42][0m Callbacks took 108.436 sec in total. InferenceRunner: 106.579sec
[32m[0323 04:07:56 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15023/173481[03:00<31:38,83.46it/s]  9%|9         |15899/173481[03:10<31:28,83.46it/s] 18%|#8        |31274/173481[06:00<27:19,86.73it/s] 19%|#8        |32225/173481[06:10<27:08,86.73it/s] 28%|##7       |48160/173481[09:00<23:10,90.13it/s] 28%|##8       |49148/173481[09:10<22:59,90.13it/s] 35%|###4      |60131/173481[12:00<24:41,76.54it/s] 35%|###5      |60781/173481[12:10<24:32,76.54it/s] 41%|####      |70926/173481[15:00<25:25,67.24it/s] 41%|####1     |71538/173481[15:10<25:16,67.24it/s] 47%|####6     |81474/173481[18:00<24:29,62.62it/s] 47%|####7     |82120/173481[18:10<24:18,62.62it/s] 53%|#####3    |92118/173481[21:00<22:17,60.83it/s] 53%|#####3    |92782/173481[21:11<22:06,60.83it/s] 59%|#####9    |102831/173481[24:00<19:34,60.16it/s] 60%|#####9    |103476/173481[24:11<19:23,60.16it/s] 65%|######5   |113521/173481[27:00<16:43,59.76it/s] 66%|######5   |114200/173481[27:11<16:32,59.76it/s] 72%|#######1  |124152/173481[30:00<13:50,59.40it/s] 72%|#######1  |124874/173481[30:11<13:38,59.40it/s] 78%|#######7  |135121/173481[33:00<10:37,60.16it/s] 78%|#######8  |135808/173481[33:11<10:26,60.16it/s] 84%|########4 |146258/173481[36:00<07:26,61.00it/s] 85%|########4 |146973/173481[36:11<07:14,61.00it/s] 90%|######### |156425/173481[39:00<04:50,58.65it/s] 91%|######### |157102/173481[39:12<04:39,58.65it/s] 96%|#########6|166746/173481[42:00<01:56,57.99it/s] 97%|#########6|167453/173481[42:12<01:43,57.99it/s]100%|##########|173481/173481[43:54<00:00,65.84it/s]
[32m[0323 04:51:51 @base.py:257][0m Epoch 21 (global_step 6939240) finished, time:2634.79 sec.
[32m[0323 04:51:51 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-6939240.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,156.87it/s]
20
[32m[0323 04:53:51 @monitor.py:363][0m QueueInput/queue_size: 0.11363
[32m[0323 04:53:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.035
[32m[0323 04:53:51 @monitor.py:363][0m activation-summaries/output-rms: 0.02343
[32m[0323 04:53:51 @monitor.py:363][0m cross_entropy_loss: 2.8836
[32m[0323 04:53:51 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68559
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.2449
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26614
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26909
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 04:53:51 @monitor.py:363][0m train-error-top1: 0.70948
[32m[0323 04:53:51 @monitor.py:363][0m val-error-top1: 0.70991
[32m[0323 04:53:51 @monitor.py:363][0m val-utt-error: 0.28244
[32m[0323 04:53:51 @monitor.py:363][0m validation_cost: 2.9278
[32m[0323 04:53:51 @monitor.py:363][0m wd_cost: 2.4939e-09
[32m[0323 04:53:51 @group.py:42][0m Callbacks took 120.611 sec in total. InferenceRunner: 120.002sec
[32m[0323 04:53:51 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17329/173481[03:00<27:02,96.27it/s] 11%|#         |18271/173481[03:10<26:52,96.27it/s] 17%|#6        |28855/173481[06:00<31:20,76.90it/s] 17%|#7        |29508/173481[06:10<31:12,76.90it/s] 23%|##2       |39131/173481[09:00<34:10,65.53it/s] 23%|##2       |39719/173481[09:10<34:01,65.53it/s] 28%|##8       |48705/173481[12:00<35:25,58.71it/s] 28%|##8       |49294/173481[12:10<35:15,58.71it/s] 34%|###4      |59200/173481[15:00<32:33,58.50it/s] 35%|###4      |59864/173481[15:10<32:22,58.50it/s] 40%|####      |69867/173481[18:00<29:19,58.87it/s] 41%|####      |70528/173481[18:10<29:08,58.87it/s] 47%|####6     |80738/173481[21:00<25:55,59.62it/s] 47%|####6     |81397/173481[21:11<25:44,59.62it/s] 53%|#####2    |91535/173481[24:00<22:50,59.80it/s] 53%|#####3    |92184/173481[24:11<22:39,59.80it/s] 59%|#####8    |102187/173481[27:00<19:58,59.49it/s] 59%|#####9    |102897/173481[27:11<19:46,59.49it/s] 65%|######5   |112990/173481[30:00<16:52,59.75it/s] 65%|######5   |113629/173481[30:11<16:41,59.75it/s] 71%|#######   |123121/173481[33:00<14:28,57.96it/s] 71%|#######1  |123730/173481[33:11<14:18,57.96it/s] 77%|#######6  |133122/173481[36:00<11:51,56.73it/s] 77%|#######7  |133746/173481[36:11<11:40,56.73it/s] 83%|########2 |143624/173481[39:00<08:39,57.53it/s] 83%|########3 |144354/173481[39:12<08:26,57.53it/s] 89%|########8 |154200/173481[42:00<05:31,58.13it/s] 89%|########9 |154851/173481[42:12<05:20,58.13it/s] 95%|#########4|164245/173481[45:00<02:42,56.94it/s] 95%|#########5|164890/173481[45:12<02:30,56.94it/s]100%|##########|173481/173481[47:42<00:00,60.61it/s]
[32m[0323 05:41:34 @base.py:257][0m Epoch 22 (global_step 7112721) finished, time:2862.30 sec.
[32m[0323 05:41:34 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-7112721.
[32m[0323 05:41:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.59it/s]
21
[32m[0323 05:43:33 @monitor.py:363][0m QueueInput/queue_size: 0.40688
[32m[0323 05:43:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.372
[32m[0323 05:43:33 @monitor.py:363][0m activation-summaries/output-rms: 0.022786
[32m[0323 05:43:33 @monitor.py:363][0m cross_entropy_loss: 2.8791
[32m[0323 05:43:33 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68524
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26614
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26909
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 05:43:33 @monitor.py:363][0m train-error-top1: 0.70014
[32m[0323 05:43:33 @monitor.py:363][0m val-error-top1: 0.7109
[32m[0323 05:43:33 @monitor.py:363][0m val-utt-error: 0.28137
[32m[0323 05:43:33 @monitor.py:363][0m validation_cost: 2.9308
[32m[0323 05:43:33 @monitor.py:363][0m wd_cost: 2.4929e-09
[32m[0323 05:43:33 @group.py:42][0m Callbacks took 119.821 sec in total. InferenceRunner: 117.950sec
[32m[0323 05:43:33 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17049/173481[03:00<27:31,94.71it/s] 10%|#         |17973/173481[03:10<27:21,94.71it/s] 17%|#6        |29474/173481[06:00<30:03,79.85it/s] 17%|#7        |30070/173481[06:10<29:55,79.85it/s] 23%|##2       |39576/173481[09:00<33:51,65.92it/s] 23%|##3       |40128/173481[09:10<33:43,65.92it/s] 30%|###       |52634/173481[12:00<29:09,69.07it/s] 31%|###       |53459/173481[12:10<28:57,69.07it/s] 39%|###9      |68359/173481[15:00<22:42,77.14it/s] 40%|###9      |69318/173481[15:10<22:30,77.14it/s] 46%|####5     |79429/173481[18:00<22:54,68.43it/s] 46%|####6     |80093/173481[18:10<22:44,68.43it/s] 52%|#####2    |90644/173481[21:00<21:10,65.22it/s] 53%|#####2    |91369/173481[21:11<20:58,65.22it/s] 59%|#####8    |101644/173481[24:00<18:58,63.09it/s] 59%|#####8    |102301/173481[24:11<18:48,63.09it/s] 65%|######4   |112749/173481[27:00<16:13,62.38it/s] 65%|######5   |113478/173481[27:11<16:01,62.38it/s] 71%|#######1  |123662/173481[30:00<13:30,61.49it/s] 72%|#######1  |124378/173481[30:11<13:18,61.49it/s] 78%|#######7  |134734/173481[33:00<10:30,61.50it/s] 78%|#######8  |135413/173481[33:11<10:19,61.50it/s] 84%|########4 |145729/173481[36:00<07:32,61.28it/s] 84%|########4 |146457/173481[36:11<07:21,61.28it/s] 90%|######### |156728/173481[39:00<04:33,61.19it/s] 91%|######### |157478/173481[39:12<04:21,61.19it/s] 97%|#########6|167889/173481[42:00<01:30,61.59it/s] 97%|#########7|168641/173481[42:12<01:18,61.59it/s]100%|##########|173481/173481[43:32<00:00,66.41it/s]
[32m[0323 06:27:06 @base.py:257][0m Epoch 23 (global_step 7286202) finished, time:2612.12 sec.
[32m[0323 06:27:06 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-7286202.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.63it/s]
22
[32m[0323 06:29:03 @monitor.py:363][0m QueueInput/queue_size: 0.6016
[32m[0323 06:29:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.793
[32m[0323 06:29:03 @monitor.py:363][0m activation-summaries/output-rms: 0.023376
[32m[0323 06:29:03 @monitor.py:363][0m cross_entropy_loss: 2.9047
[32m[0323 06:29:03 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68504
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26615
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26909
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 06:29:03 @monitor.py:363][0m train-error-top1: 0.70216
[32m[0323 06:29:03 @monitor.py:363][0m val-error-top1: 0.71018
[32m[0323 06:29:03 @monitor.py:363][0m val-utt-error: 0.281
[32m[0323 06:29:03 @monitor.py:363][0m validation_cost: 2.9267
[32m[0323 06:29:03 @monitor.py:363][0m wd_cost: 4.9848e-10
[32m[0323 06:29:03 @group.py:42][0m Callbacks took 117.862 sec in total. InferenceRunner: 117.202sec
[32m[0323 06:29:03 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |18180/173481[03:00<25:37,101.00it/s] 11%|#         |18887/173481[03:10<25:30,101.00it/s] 17%|#7        |30328/173481[06:00<29:29,80.91it/s]  18%|#7        |31052/173481[06:10<29:20,80.91it/s] 25%|##4       |43268/173481[09:00<28:30,76.13it/s] 25%|##5       |43987/173481[09:10<28:20,76.13it/s] 32%|###2      |56190/173481[12:00<26:27,73.89it/s] 33%|###2      |56842/173481[12:10<26:18,73.89it/s] 40%|###9      |69053/173481[15:00<23:57,72.65it/s] 40%|####      |69798/173481[15:10<23:47,72.65it/s] 47%|####7     |82098/173481[18:00<20:59,72.55it/s] 48%|####7     |82819/173481[18:10<20:49,72.55it/s] 55%|#####4    |95398/173481[21:00<17:46,73.21it/s] 55%|#####5    |96182/173481[21:11<17:35,73.21it/s] 63%|######2   |108798/173481[24:00<14:36,73.82it/s] 63%|######3   |109527/173481[24:11<14:26,73.82it/s] 69%|######9   |120349/173481[27:00<12:53,68.65it/s] 70%|######9   |121191/173481[27:11<12:41,68.65it/s] 76%|#######6  |131938/173481[30:00<10:25,66.45it/s] 76%|#######6  |132642/173481[30:11<10:14,66.45it/s] 82%|########2 |142963/173481[33:00<07:58,63.73it/s] 83%|########2 |143632/173481[33:11<07:48,63.73it/s] 89%|########8 |154178/173481[36:00<05:06,63.01it/s] 89%|########9 |154909/173481[36:11<04:54,63.01it/s] 95%|#########5|165511/173481[39:00<02:06,62.99it/s] 96%|#########5|166172/173481[39:11<01:56,62.99it/s]100%|##########|173481/173481[41:24<00:00,69.82it/s]
[32m[0323 07:10:28 @base.py:257][0m Epoch 24 (global_step 7459683) finished, time:2484.81 sec.
[32m[0323 07:10:29 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-7459683.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.57it/s]
23
[32m[0323 07:12:28 @monitor.py:363][0m QueueInput/queue_size: 0.25473
[32m[0323 07:12:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.988
[32m[0323 07:12:28 @monitor.py:363][0m activation-summaries/output-rms: 0.023308
[32m[0323 07:12:28 @monitor.py:363][0m cross_entropy_loss: 2.917
[32m[0323 07:12:28 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68485
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26615
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26909
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 07:12:28 @monitor.py:363][0m train-error-top1: 0.70419
[32m[0323 07:12:28 @monitor.py:363][0m val-error-top1: 0.7096
[32m[0323 07:12:28 @monitor.py:363][0m val-utt-error: 0.2827
[32m[0323 07:12:28 @monitor.py:363][0m validation_cost: 2.9255
[32m[0323 07:12:28 @monitor.py:363][0m wd_cost: 4.9837e-10
[32m[0323 07:12:28 @group.py:42][0m Callbacks took 120.109 sec in total. InferenceRunner: 119.469sec
[32m[0323 07:12:28 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17062/173481[03:00<27:30,94.79it/s] 10%|#         |18021/173481[03:10<27:20,94.79it/s] 17%|#7        |29512/173481[06:00<30:00,79.97it/s] 17%|#7        |30176/173481[06:10<29:51,79.97it/s] 24%|##3       |41106/173481[09:00<30:55,71.35it/s] 24%|##4       |41921/173481[09:10<30:43,71.35it/s] 30%|###       |52625/173481[12:00<29:51,67.47it/s] 31%|###       |53315/173481[12:10<29:41,67.47it/s] 37%|###6      |64187/173481[15:00<27:40,65.80it/s] 37%|###7      |64846/173481[15:10<27:30,65.80it/s] 43%|####3     |75207/173481[18:00<25:49,63.43it/s] 44%|####3     |75807/173481[18:10<25:39,63.43it/s] 50%|####9     |86122/173481[21:00<23:29,61.99it/s] 50%|#####     |86772/173481[21:11<23:18,61.99it/s] 57%|#####7    |98894/173481[24:00<18:47,66.17it/s] 58%|#####7    |99841/173481[24:11<18:32,66.17it/s] 66%|######6   |115175/173481[27:00<12:42,76.43it/s] 67%|######6   |116026/173481[27:11<12:31,76.43it/s] 74%|#######3  |127704/173481[30:00<10:28,72.86it/s] 74%|#######4  |128606/173481[30:11<10:15,72.86it/s] 80%|########  |139597/173481[33:00<08:08,69.30it/s] 81%|########  |140316/173481[33:11<07:58,69.30it/s] 87%|########6 |150910/173481[36:00<05:42,65.92it/s] 87%|########7 |151635/173481[36:11<05:31,65.92it/s] 93%|#########3|161774/173481[39:00<03:05,63.01it/s] 94%|#########3|162504/173481[39:11<02:54,63.01it/s]100%|#########9|172807/173481[42:00<00:10,62.13it/s]100%|##########|173481/173481[42:11<00:00,68.53it/s]
[32m[0323 07:54:40 @base.py:257][0m Epoch 25 (global_step 7633164) finished, time:2531.64 sec.
[32m[0323 07:54:41 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-7633164.
[32m[0323 07:54:42 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.49it/s]
24
[32m[0323 07:56:47 @monitor.py:363][0m QueueInput/queue_size: 0.93361
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.027
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/output-rms: 0.02324
[32m[0323 07:56:47 @monitor.py:363][0m cross_entropy_loss: 2.8862
[32m[0323 07:56:47 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68473
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26615
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26908
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 07:56:47 @monitor.py:363][0m train-error-top1: 0.70614
[32m[0323 07:56:47 @monitor.py:363][0m val-error-top1: 0.71016
[32m[0323 07:56:47 @monitor.py:363][0m val-utt-error: 0.28408
[32m[0323 07:56:47 @monitor.py:363][0m validation_cost: 2.9305
[32m[0323 07:56:47 @monitor.py:363][0m wd_cost: 4.983e-10
[32m[0323 07:56:47 @group.py:42][0m Callbacks took 127.209 sec in total. InferenceRunner: 125.086sec
[32m[0323 07:56:47 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12876/173481[03:00<37:25,71.53it/s]  8%|7         |13523/173481[03:10<37:16,71.53it/s] 14%|#3        |24212/173481[06:00<37:08,66.98it/s] 14%|#4        |24860/173481[06:10<36:58,66.98it/s] 20%|##        |35411/173481[09:00<35:40,64.51it/s] 21%|##        |36048/173481[09:10<35:30,64.51it/s] 27%|##6       |46420/173481[12:00<33:43,62.79it/s] 27%|##7       |47042/173481[12:10<33:33,62.79it/s] 33%|###2      |57057/173481[15:00<31:52,60.88it/s] 33%|###3      |57702/173481[15:10<31:41,60.88it/s] 39%|###9      |68139/173481[18:00<28:40,61.22it/s] 40%|###9      |68785/173481[18:10<28:30,61.22it/s] 45%|####5     |78786/173481[21:00<26:13,60.17it/s] 46%|####5     |79433/173481[21:11<26:03,60.17it/s] 52%|#####1    |89366/173481[24:00<23:34,59.46it/s] 52%|#####1    |90016/173481[24:11<23:23,59.46it/s] 58%|#####7    |99794/173481[27:00<20:55,58.69it/s] 58%|#####7    |100465/173481[27:11<20:44,58.69it/s] 64%|######3   |110435/173481[30:00<17:50,58.90it/s] 64%|######4   |111084/173481[30:11<17:39,58.90it/s] 70%|######9   |120806/173481[33:00<15:04,58.25it/s] 70%|#######   |121485/173481[33:11<14:52,58.25it/s] 76%|#######5  |131513/173481[36:00<11:53,58.86it/s] 76%|#######6  |132176/173481[36:11<11:41,58.86it/s] 82%|########1 |142208/173481[39:00<08:48,59.14it/s] 82%|########2 |142920/173481[39:11<08:36,59.14it/s] 88%|########8 |152762/173481[42:00<05:51,58.88it/s] 88%|########8 |153480/173481[42:12<05:39,58.88it/s] 94%|#########4|163266/173481[45:00<02:54,58.61it/s] 95%|#########4|163959/173481[45:12<02:42,58.61it/s]100%|##########|173481/173481[47:55<00:00,60.34it/s]
[32m[0323 08:44:42 @base.py:257][0m Epoch 26 (global_step 7806645) finished, time:2875.01 sec.
[32m[0323 08:44:43 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-7806645.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.64it/s]
25
[32m[0323 08:46:47 @monitor.py:363][0m QueueInput/queue_size: 0.30835
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.986
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/output-rms: 0.023432
[32m[0323 08:46:47 @monitor.py:363][0m cross_entropy_loss: 2.8811
[32m[0323 08:46:47 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68469
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26615
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26908
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 08:46:47 @monitor.py:363][0m train-error-top1: 0.70772
[32m[0323 08:46:47 @monitor.py:363][0m val-error-top1: 0.70946
[32m[0323 08:46:47 @monitor.py:363][0m val-utt-error: 0.28127
[32m[0323 08:46:47 @monitor.py:363][0m validation_cost: 2.9255
[32m[0323 08:46:47 @monitor.py:363][0m wd_cost: 9.9655e-11
[32m[0323 08:46:47 @group.py:42][0m Callbacks took 124.792 sec in total. InferenceRunner: 124.131sec
[32m[0323 08:46:47 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16847/173481[03:00<27:53,93.59it/s] 10%|#         |17810/173481[03:10<27:43,93.59it/s] 16%|#6        |27790/173481[06:00<32:57,73.69it/s] 16%|#6        |28354/173481[06:10<32:49,73.69it/s] 21%|##1       |37104/173481[09:00<37:23,60.80it/s] 22%|##1       |37640/173481[09:10<37:14,60.80it/s] 27%|##6       |46753/173481[12:00<37:04,56.97it/s] 27%|##7       |47329/173481[12:10<36:54,56.97it/s] 33%|###2      |57100/173481[15:00<33:53,57.23it/s] 33%|###3      |57769/173481[15:10<33:41,57.23it/s] 39%|###9      |68105/173481[18:00<29:42,59.12it/s] 40%|###9      |68763/173481[18:10<29:31,59.12it/s] 46%|####5     |79201/173481[21:00<26:02,60.35it/s] 46%|####6     |79872/173481[21:11<25:51,60.35it/s] 52%|#####2    |90515/173481[24:00<22:27,61.57it/s] 53%|#####2    |91204/173481[24:11<22:16,61.57it/s] 58%|#####8    |101419/173481[27:00<19:40,61.07it/s] 59%|#####8    |102091/173481[27:11<19:29,61.07it/s] 65%|######4   |112541/173481[30:00<16:32,61.42it/s] 65%|######5   |113249/173481[30:11<16:20,61.42it/s] 71%|#######1  |123425/173481[33:00<13:41,60.94it/s] 72%|#######1  |124129/173481[33:11<13:29,60.94it/s] 77%|#######7  |134305/173481[36:00<10:45,60.69it/s] 78%|#######7  |134978/173481[36:11<10:34,60.69it/s] 84%|########3 |145271/173481[39:00<07:43,60.81it/s] 84%|########4 |145929/173481[39:11<07:33,60.81it/s] 90%|######### |156140/173481[42:00<04:46,60.59it/s] 90%|######### |156921/173481[42:12<04:33,60.59it/s] 96%|#########6|167265/173481[45:00<01:41,61.19it/s] 97%|#########6|168009/173481[45:12<01:29,61.19it/s]100%|##########|173481/173481[46:39<00:00,61.96it/s]
[32m[0323 09:33:27 @base.py:257][0m Epoch 27 (global_step 7980126) finished, time:2799.79 sec.
[32m[0323 09:33:27 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-7980126.
[32m[0323 09:33:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.49it/s]
26
[32m[0323 09:35:26 @monitor.py:363][0m QueueInput/queue_size: 0.74733
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.338
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/output-rms: 0.022797
[32m[0323 09:35:26 @monitor.py:363][0m cross_entropy_loss: 2.8774
[32m[0323 09:35:26 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68466
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26615
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26908
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 09:35:26 @monitor.py:363][0m train-error-top1: 0.70028
[32m[0323 09:35:26 @monitor.py:363][0m val-error-top1: 0.71069
[32m[0323 09:35:26 @monitor.py:363][0m val-utt-error: 0.28015
[32m[0323 09:35:26 @monitor.py:363][0m validation_cost: 2.9292
[32m[0323 09:35:26 @monitor.py:363][0m wd_cost: 9.9651e-11
[32m[0323 09:35:26 @group.py:42][0m Callbacks took 118.839 sec in total. InferenceRunner: 117.291sec
[32m[0323 09:35:26 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17096/173481[03:00<27:26,94.97it/s] 10%|#         |18044/173481[03:10<27:16,94.97it/s] 17%|#7        |30119/173481[06:00<29:05,82.13it/s] 18%|#7        |30753/173481[06:10<28:57,82.13it/s] 24%|##3       |41360/173481[09:00<31:02,70.95it/s] 24%|##4       |42025/173481[09:10<30:52,70.95it/s] 34%|###4      |59584/173481[12:00<22:45,83.43it/s] 35%|###4      |60692/173481[12:10<22:31,83.43it/s] 45%|####5     |78577/173481[15:00<16:58,93.18it/s] 46%|####5     |79598/173481[15:10<16:47,93.18it/s] 55%|#####5    |96066/173481[18:00<13:33,95.13it/s] 56%|#####5    |97125/173481[18:10<13:22,95.13it/s] 65%|######5   |113299/173481[21:00<10:30,95.43it/s] 66%|######5   |114338/173481[21:11<10:19,95.43it/s] 74%|#######4  |129099/173481[24:00<08:05,91.44it/s] 75%|#######4  |129812/173481[24:11<07:57,91.44it/s] 81%|########1 |140637/173481[27:00<07:15,75.36it/s] 81%|########1 |141359/173481[27:11<07:06,75.36it/s] 88%|########7 |152049/173481[30:00<05:11,68.87it/s] 88%|########8 |152783/173481[30:11<05:00,68.87it/s] 94%|#########4|163620/173481[33:00<02:28,66.49it/s] 95%|#########4|164363/173481[33:11<02:17,66.49it/s]100%|##########|173481/173481[35:22<00:00,81.74it/s]
[32m[0323 10:10:48 @base.py:257][0m Epoch 28 (global_step 8153607) finished, time:2122.46 sec.
[32m[0323 10:10:49 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_8_quant_ends_True_preload/model-8153607.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.65it/s]
27
[32m[0323 10:12:42 @monitor.py:363][0m QueueInput/queue_size: 0.69653
[32m[0323 10:12:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.768
[32m[0323 10:12:42 @monitor.py:363][0m activation-summaries/output-rms: 0.023389
[32m[0323 10:12:42 @monitor.py:363][0m cross_entropy_loss: 2.9034
[32m[0323 10:12:42 @monitor.py:363][0m lr: 7.6294e-09
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68465
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.245
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27237
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.06095
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26645
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063622
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26615
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066024
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26908
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06247
[32m[0323 10:12:42 @monitor.py:363][0m train-error-top1: 0.70207
[32m[0323 10:12:42 @monitor.py:363][0m val-error-top1: 0.71
[32m[0323 10:12:42 @monitor.py:363][0m val-utt-error: 0.28068
[32m[0323 10:12:42 @monitor.py:363][0m validation_cost: 2.9254
[32m[0323 10:12:42 @monitor.py:363][0m wd_cost: 9.965e-11
[32m[0323 10:12:42 @group.py:42][0m Callbacks took 113.521 sec in total. InferenceRunner: 112.960sec
[32m[0323 10:12:42 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#         |18769/173481[03:00<24:43,104.27it/s] 11%|#1        |19834/173481[03:10<24:33,104.27it/s] 22%|##1       |37730/173481[06:00<21:35,104.80it/s] 22%|##2       |38815/173481[06:10<21:24,104.80it/s] 33%|###2      |56529/173481[09:00<18:37,104.62it/s] 33%|###3      |57633/173481[09:10<18:27,104.62it/s] 43%|####2     |73966/173481[12:00<16:29,100.60it/s] 43%|####3     |74851/173481[12:10<16:20,100.60it/s] 51%|#####     |88105/173481[15:00<16:07,88.22it/s]  51%|#####1    |88978/173481[15:10<15:57,88.22it/s] 59%|#####8    |102186/173481[18:00<14:19,82.92it/s] 59%|#####9    |103052/173481[18:10<14:09,82.92it/s] 66%|######6   |114878/173481[21:00<12:48,76.21it/s] 67%|######6   |115597/173481[21:11<12:39,76.21it/s] 73%|#######2  |126539/173481[24:00<11:10,70.03it/s] 73%|#######3  |127262/173481[24:11<10:59,70.03it/s] 80%|#######9  |138564/173481[27:00<08:30,68.38it/s] 80%|########  |139339/173481[27:11<08:19,68.38it/s]srun: got SIGCONT
slurmstepd: *** STEP 82369.0 ON sls-titanx-1 CANCELLED AT 2018-03-23T10:41:19 ***
slurmstepd: *** JOB 82369 ON sls-titanx-1 CANCELLED AT 2018-03-23T10:41:19 ***
srun: forcing job termination
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
