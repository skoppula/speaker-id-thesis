sls-sm-11 1
SLURM_JOBID=70364
SLURM_TASKID=4
[32m[0320 11:46:09 @logger.py:67][0m Existing log file 'train_log/fcn2_w_16_a_32_quant_ends_False/log.log' backuped to 'train_log/fcn2_w_16_a_32_quant_ends_False/log.log.0320-114609'
[32m[0320 11:46:09 @logger.py:74][0m Argv: drf_run.py --model_name=fcn2 --bitw=16 --bita=32 --quant_ends=False
[32m[0320 11:46:19 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0320 11:46:19 @drf_run.py:140][0m Using 6 threads
('whole utterance size', 75290)
[32m[0320 11:46:19 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0320 11:46:19 @drf_run.py:166][0m Using host: sls-sm-11
[32m[0320 11:46:19 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0320 11:46:19 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0320 11:46:19 @drf_run.py:188][0m Using GPU: 1
[32m[0320 11:46:19 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0320 11:46:19 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0320 11:46:19 @training.py:108][0m Building graph for training tower 0 ...
[32m[0320 11:46:19 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0320 11:46:19 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0320 11:46:19 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0320 11:46:19 @registry.py:130][0m linear0 output: [None, 504]
[32m[0320 11:46:19 @registry.py:122][0m linear1 input: [None, 504]
[32m[0320 11:46:19 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0320 11:46:19 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear1 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m linear2 input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear2 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m linear3 input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear3 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m last_linear input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0320 11:46:20 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0320 11:46:20 @registry.py:130][0m last_linear output: [None, 255]
[32m[0320 11:46:20 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0320 11:46:20 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0320 11:46:20 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0320 11:46:20 @drf_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0320 11:46:20 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=1400871, size=5.34MB[0m
[32m[0320 11:46:20 @base.py:196][0m Setup callbacks graph ...
[32m[0320 11:46:21 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0320 11:46:21 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0320 11:46:21 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0320 11:46:21 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0320 11:46:21 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0320 11:46:21 @drf_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0320 11:46:21 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0320 11:46:21 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0320 11:46:21 @base.py:212][0m Creating the session ...
2018-03-20 11:46:22.042608: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-20 11:46:22.669791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:03:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-03-20 11:46:22.669840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
[32m[0320 11:46:29 @base.py:220][0m Initializing the session ...
[32m[0320 11:46:29 @base.py:227][0m Graph Finalized.
[32m[0320 11:46:29 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0320 11:46:38 @monitor.py:251][0m Found existing JSON at train_log/fcn2_w_16_a_32_quant_ends_False/stat.json, will append to it.
[32m[0320 11:46:38 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0320 11:46:38 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11462/173481[03:00<42:24,63.68it/s]  7%|6         |12125/173481[03:10<42:14,63.68it/s] 13%|#3        |23161/173481[06:00<38:56,64.33it/s] 14%|#3        |23850/173481[06:10<38:46,64.33it/s] 20%|##        |34794/173481[09:00<35:50,64.48it/s] 20%|##        |35474/173481[09:10<35:40,64.48it/s] 27%|##6       |46323/173481[12:00<32:58,64.26it/s] 27%|##7       |47023/173481[12:10<32:47,64.26it/s] 34%|###3      |58351/173481[15:00<29:17,65.51it/s] 34%|###4      |59082/173481[15:10<29:06,65.51it/s] 41%|####      |70485/173481[18:00<25:50,66.45it/s] 41%|####1     |71298/173481[18:10<25:37,66.45it/s] 48%|####7     |82585/173481[21:00<22:40,66.83it/s] 48%|####8     |83311/173481[21:11<22:29,66.83it/s] 54%|#####4    |94333/173481[24:00<19:58,66.03it/s] 55%|#####4    |95114/173481[24:11<19:46,66.03it/s] 61%|######    |105259/173481[27:00<17:58,63.25it/s] 61%|######1   |105972/173481[27:11<17:47,63.25it/s] 66%|######6   |115315/173481[30:00<16:20,59.33it/s] 67%|######6   |115970/173481[30:11<16:09,59.33it/s] 73%|#######2  |126025/173481[33:00<13:18,59.41it/s] 73%|#######3  |126775/173481[33:11<13:06,59.41it/s] 79%|#######9  |137884/173481[36:00<09:29,62.48it/s] 80%|########  |139114/173481[36:11<09:10,62.48it/s] 90%|######### |156745/173481[39:00<03:33,78.28it/s] 91%|#########1|157981/173481[39:12<03:18,78.28it/s] 98%|#########7|169311/173481[42:00<00:56,73.80it/s] 98%|#########8|170082/173481[42:12<00:46,73.80it/s]100%|##########|173481/173481[43:05<00:00,67.11it/s]
[32m[0320 12:29:43 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2585.09 sec.
[32m[0320 12:29:43 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########7|18424/18822[03:00<00:03,102.35it/s]100%|##########|18822/18822[03:04<00:00,102.17it/s]
0
[32m[0320 12:32:47 @monitor.py:363][0m QueueInput/queue_size: 0.9837
[32m[0320 12:32:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.7317
[32m[0320 12:32:47 @monitor.py:363][0m activation-summaries/output-rms: 0.02877
[32m[0320 12:32:47 @monitor.py:363][0m cross_entropy_loss: 2.6209
[32m[0320 12:32:47 @monitor.py:363][0m lr: 0.001
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.1103
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.63001
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.080874
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.08663
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064564
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.069706
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.068963
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 12:32:47 @monitor.py:363][0m train-error-top1: 0.63851
[32m[0320 12:32:47 @monitor.py:363][0m val-error-top1: 0.73275
[32m[0320 12:32:47 @monitor.py:363][0m val-utt-error: 0.40198
[32m[0320 12:32:47 @monitor.py:363][0m validation_cost: 3.1384
[32m[0320 12:32:47 @monitor.py:363][0m wd_cost: 0.92077
[32m[0320 12:32:47 @group.py:42][0m Callbacks took 184.846 sec in total. InferenceRunner: 184.230sec
[32m[0320 12:32:47 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12125/173481[03:00<39:55,67.36it/s]  7%|7         |12729/173481[03:10<39:46,67.36it/s] 12%|#2        |21520/173481[06:00<43:03,58.81it/s] 13%|#2        |22092/173481[06:10<42:54,58.81it/s] 19%|#8        |32218/173481[09:00<39:49,59.11it/s] 19%|#8        |32895/173481[09:10<39:38,59.11it/s] 25%|##5       |43799/173481[12:00<35:04,61.61it/s] 26%|##5       |44507/173481[12:10<34:53,61.61it/s] 32%|###2      |55738/173481[15:00<30:43,63.88it/s] 33%|###2      |56505/173481[15:10<30:31,63.88it/s] 39%|###8      |67613/173481[18:00<27:11,64.91it/s] 39%|###9      |68343/173481[18:10<26:59,64.91it/s] 46%|####5     |79723/173481[21:00<23:39,66.07it/s] 46%|####6     |80481/173481[21:11<23:27,66.07it/s] 53%|#####2    |91594/173481[24:00<20:40,66.01it/s] 53%|#####3    |92370/173481[24:11<20:28,66.01it/s] 60%|#####9    |103540/173481[27:00<17:36,66.18it/s] 60%|######    |104344/173481[27:11<17:24,66.18it/s] 67%|######6   |115482/173481[30:00<14:35,66.26it/s] 67%|######7   |116321/173481[30:11<14:22,66.26it/s] 74%|#######3  |127600/173481[33:00<11:27,66.78it/s] 74%|#######4  |128382/173481[33:11<11:15,66.78it/s] 80%|########  |139270/173481[36:00<08:40,65.78it/s] 81%|########  |140059/173481[36:11<08:28,65.78it/s] 91%|######### |157104/173481[39:00<03:27,79.07it/s] 91%|#########1|158338/173481[39:11<03:11,79.07it/s] 98%|#########8|170290/173481[42:00<00:41,76.05it/s] 99%|#########8|171078/173481[42:12<00:31,76.05it/s]100%|##########|173481/173481[42:49<00:00,67.50it/s]
[32m[0320 13:15:37 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2569.99 sec.
[32m[0320 13:15:38 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-346962.
[32m[0320 13:15:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|#########9|18747/18822[03:00<00:00,104.15it/s]100%|##########|18822/18822[03:01<00:00,103.83it/s]
1
[32m[0320 13:18:41 @monitor.py:363][0m QueueInput/queue_size: 0.56611
[32m[0320 13:18:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8453
[32m[0320 13:18:41 @monitor.py:363][0m activation-summaries/output-rms: 0.030569
[32m[0320 13:18:41 @monitor.py:363][0m cross_entropy_loss: 2.5771
[32m[0320 13:18:41 @monitor.py:363][0m lr: 0.001
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.11062
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.83987
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.079951
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.086051
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064564
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.064588
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.064322
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 13:18:41 @monitor.py:363][0m train-error-top1: 0.62885
[32m[0320 13:18:41 @monitor.py:363][0m val-error-top1: 0.73101
[32m[0320 13:18:41 @monitor.py:363][0m val-utt-error: 0.404
[32m[0320 13:18:41 @monitor.py:363][0m validation_cost: 3.1157
[32m[0320 13:18:41 @monitor.py:363][0m wd_cost: 0.87852
[32m[0320 13:18:41 @group.py:42][0m Callbacks took 183.472 sec in total. InferenceRunner: 181.297sec
[32m[0320 13:18:41 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11479/173481[03:00<42:20,63.76it/s]  7%|6         |12118/173481[03:10<42:10,63.76it/s] 13%|#2        |22510/173481[06:00<40:15,62.50it/s] 13%|#3        |23136/173481[06:10<40:05,62.50it/s] 20%|#9        |34185/173481[09:00<36:28,63.66it/s] 20%|##        |34914/173481[09:10<36:16,63.66it/s] 26%|##6       |45589/173481[12:00<33:34,63.49it/s] 27%|##6       |46182/173481[12:10<33:25,63.49it/s] 33%|###2      |56984/173481[15:00<30:37,63.40it/s] 33%|###3      |57696/173481[15:10<30:26,63.40it/s] 40%|###9      |68932/173481[18:00<26:52,64.85it/s] 40%|####      |69660/173481[18:10<26:40,64.85it/s] 47%|####6     |80774/173481[21:00<23:39,65.32it/s] 47%|####6     |81528/173481[21:11<23:27,65.32it/s] 54%|#####3    |92943/173481[24:00<20:12,66.44it/s] 54%|#####3    |93657/173481[24:11<20:01,66.44it/s] 60%|#####9    |103639/173481[27:00<18:33,62.73it/s] 60%|######    |104238/173481[27:11<18:23,62.73it/s] 65%|######5   |113521/173481[30:00<17:04,58.55it/s] 66%|######5   |114204/173481[30:11<16:52,58.55it/s] 71%|#######1  |123607/173481[33:00<14:30,57.26it/s] 72%|#######1  |124344/173481[33:11<14:18,57.26it/s] 78%|#######8  |135513/173481[36:00<10:18,61.38it/s] 79%|#######8  |136326/173481[36:11<10:05,61.38it/s] 86%|########6 |149973/173481[39:00<05:37,69.59it/s] 87%|########7 |151213/173481[39:12<05:19,69.59it/s] 96%|#########6|167066/173481[42:00<01:19,80.32it/s] 97%|#########6|167844/173481[42:12<01:10,80.32it/s]100%|##########|173481/173481[43:36<00:00,66.30it/s]
[32m[0320 14:02:18 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2616.79 sec.
[32m[0320 14:02:18 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-520443.
[32m[0320 14:02:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########8|18616/18822[03:00<00:01,103.42it/s]100%|##########|18822/18822[03:01<00:00,103.53it/s]
2
[32m[0320 14:05:21 @monitor.py:363][0m QueueInput/queue_size: 0.55181
[32m[0320 14:05:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.0125
[32m[0320 14:05:21 @monitor.py:363][0m activation-summaries/output-rms: 0.036372
[32m[0320 14:05:21 @monitor.py:363][0m cross_entropy_loss: 2.0606
[32m[0320 14:05:21 @monitor.py:363][0m lr: 0.0005
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.17249
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.9441
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear0/W-rms: 0.11543
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.12102
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.089292
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.091992
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 14:05:21 @monitor.py:363][0m train-error-top1: 0.54156
[32m[0320 14:05:21 @monitor.py:363][0m val-error-top1: 0.58718
[32m[0320 14:05:21 @monitor.py:363][0m val-utt-error: 0.20779
[32m[0320 14:05:21 @monitor.py:363][0m validation_cost: 2.3299
[32m[0320 14:05:21 @monitor.py:363][0m wd_cost: 0.36864
[32m[0320 14:05:21 @group.py:42][0m Callbacks took 183.682 sec in total. InferenceRunner: 181.813sec
[32m[0320 14:05:21 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12196/173481[03:00<39:40,67.75it/s]  7%|7         |12877/173481[03:10<39:30,67.75it/s] 14%|#3        |24220/173481[06:00<36:58,67.27it/s] 14%|#4        |24879/173481[06:10<36:48,67.27it/s] 21%|##        |35950/173481[09:00<34:37,66.20it/s] 21%|##1       |36501/173481[09:10<34:29,66.20it/s] 27%|##7       |47584/173481[12:00<32:04,65.40it/s] 28%|##7       |48328/173481[12:10<31:53,65.40it/s] 34%|###4      |59125/173481[15:00<29:26,64.75it/s] 35%|###4      |59922/173481[15:10<29:13,64.75it/s] 41%|####1     |71374/173481[18:00<25:38,66.35it/s] 42%|####1     |72264/173481[18:10<25:25,66.35it/s] 48%|####8     |83338/173481[21:00<22:37,66.41it/s] 48%|####8     |84069/173481[21:11<22:26,66.41it/s] 55%|#####4    |95308/173481[24:00<19:36,66.45it/s] 55%|#####5    |96060/173481[24:11<19:25,66.45it/s] 62%|######1   |107152/173481[27:00<16:43,66.12it/s] 62%|######2   |107853/173481[27:11<16:32,66.12it/s] 69%|######8   |119080/173481[30:00<13:41,66.19it/s] 69%|######9   |119836/173481[30:11<13:30,66.19it/s] 76%|#######5  |131224/173481[33:00<10:32,66.81it/s] 76%|#######6  |132001/173481[33:11<10:20,66.81it/s] 83%|########2 |143914/173481[36:00<07:10,68.60it/s] 83%|########3 |144729/173481[36:11<06:59,68.60it/s] 90%|######### |156742/173481[39:00<03:59,69.90it/s] 91%|######### |157608/173481[39:12<03:47,69.90it/s]100%|#########9|173397/173481[42:00<00:01,79.64it/s]100%|##########|173481/173481[42:01<00:00,68.81it/s]
[32m[0320 14:47:22 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2521.04 sec.
[32m[0320 14:47:23 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-693924.
[32m[0320 14:47:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 83%|########2 |15591/18822[03:00<00:37,86.61it/s] 86%|########5 |16123/18822[03:10<00:31,86.61it/s]100%|##########|18822/18822[03:46<00:00,83.08it/s]
3
[32m[0320 14:51:11 @monitor.py:363][0m QueueInput/queue_size: 1.1818
[32m[0320 14:51:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.111
[32m[0320 14:51:11 @monitor.py:363][0m activation-summaries/output-rms: 0.037251
[32m[0320 14:51:11 @monitor.py:363][0m cross_entropy_loss: 1.8944
[32m[0320 14:51:11 @monitor.py:363][0m lr: 0.0005
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.19565
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0129
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12324
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13764
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.10758
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.10706
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 14:51:11 @monitor.py:363][0m train-error-top1: 0.48968
[32m[0320 14:51:11 @monitor.py:363][0m val-error-top1: 0.54632
[32m[0320 14:51:11 @monitor.py:363][0m val-utt-error: 0.16444
[32m[0320 14:51:11 @monitor.py:363][0m validation_cost: 2.142
[32m[0320 14:51:11 @monitor.py:363][0m wd_cost: 0.46474
[32m[0320 14:51:11 @group.py:42][0m Callbacks took 228.452 sec in total. InferenceRunner: 226.577sec
[32m[0320 14:51:11 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11787/173481[03:00<41:09,65.48it/s]  7%|7         |12511/173481[03:10<40:58,65.48it/s] 14%|#4        |24620/173481[06:00<36:20,68.26it/s] 15%|#4        |25357/173481[06:10<36:09,68.26it/s] 21%|##        |36190/173481[09:00<34:33,66.21it/s] 21%|##1       |36846/173481[09:10<34:23,66.21it/s] 27%|##7       |47065/173481[12:00<33:21,63.18it/s] 27%|##7       |47706/173481[12:10<33:10,63.18it/s] 33%|###3      |58069/173481[15:00<30:57,62.14it/s] 34%|###3      |58764/173481[15:10<30:46,62.14it/s] 40%|####      |69686/173481[18:00<27:19,63.31it/s] 41%|####      |70376/173481[18:10<27:08,63.31it/s] 47%|####6     |80719/173481[21:00<24:49,62.28it/s] 47%|####6     |81234/173481[21:11<24:41,62.28it/s] 52%|#####1    |90097/173481[24:00<24:30,56.72it/s] 52%|#####2    |90738/173481[24:11<24:18,56.72it/s] 58%|#####7    |100465/173481[27:00<21:17,57.15it/s] 58%|#####8    |101151/173481[27:11<21:05,57.15it/s] 65%|######4   |112329/173481[30:00<16:38,61.22it/s] 65%|######5   |113100/173481[30:11<16:26,61.22it/s] 72%|#######1  |124238/173481[33:00<12:54,63.59it/s] 72%|#######2  |124980/173481[33:11<12:42,63.59it/s] 79%|#######8  |136189/173481[36:00<09:34,64.96it/s] 79%|#######8  |136992/173481[36:11<09:21,64.96it/s] 85%|########4 |147446/173481[39:00<06:48,63.73it/s] 85%|########5 |148086/173481[39:11<06:38,63.73it/s] 91%|#########1|158721/173481[42:00<03:53,63.18it/s] 92%|#########1|159498/173481[42:12<03:41,63.18it/s] 98%|#########8|170705/173481[45:00<00:42,64.83it/s] 99%|#########8|171486/173481[45:12<00:30,64.83it/s]100%|##########|173481/173481[45:42<00:00,63.25it/s]
[32m[0320 15:36:54 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2742.65 sec.
[32m[0320 15:36:54 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-867405.
[32m[0320 15:36:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:34<00:00,121.75it/s]
4
[32m[0320 15:39:30 @monitor.py:363][0m QueueInput/queue_size: 0.72475
[32m[0320 15:39:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.047
[32m[0320 15:39:30 @monitor.py:363][0m activation-summaries/output-rms: 0.038752
[32m[0320 15:39:30 @monitor.py:363][0m cross_entropy_loss: 1.8061
[32m[0320 15:39:30 @monitor.py:363][0m lr: 0.0005
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.1973
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0654
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12479
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14052
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11142
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.10965
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0320 15:39:30 @monitor.py:363][0m train-error-top1: 0.4774
[32m[0320 15:39:30 @monitor.py:363][0m val-error-top1: 0.52601
[32m[0320 15:39:30 @monitor.py:363][0m val-utt-error: 0.15264
[32m[0320 15:39:30 @monitor.py:363][0m validation_cost: 2.0561
[32m[0320 15:39:30 @monitor.py:363][0m wd_cost: 0.48151
[32m[0320 15:39:30 @group.py:42][0m Callbacks took 156.595 sec in total. InferenceRunner: 154.607sec
[32m[0320 15:39:30 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10930/173481[03:00<44:37,60.71it/s]  7%|6         |11523/173481[03:10<44:27,60.71it/s] 12%|#2        |21358/173481[06:00<42:46,59.28it/s] 13%|#2        |21939/173481[06:10<42:36,59.28it/s] 18%|#8        |31432/173481[09:00<41:07,57.57it/s] 18%|#8        |31974/173481[09:10<40:58,57.57it/s] 24%|##3       |41548/173481[12:00<38:39,56.87it/s] 24%|##4       |42162/173481[12:10<38:29,56.87it/s] 30%|##9       |51543/173481[15:00<36:10,56.19it/s] 30%|###       |52137/173481[15:10<35:59,56.19it/s] 35%|###5      |61462/173481[18:00<33:33,55.63it/s] 36%|###5      |62055/173481[18:10<33:22,55.63it/s] 41%|####1     |71530/173481[21:00<30:27,55.78it/s] 42%|####1     |72129/173481[21:11<30:16,55.78it/s] 47%|####6     |81358/173481[24:00<27:49,55.18it/s] 47%|####7     |81981/173481[24:11<27:38,55.18it/s] 53%|#####2    |91326/173481[27:00<24:46,55.28it/s] 53%|#####3    |91953/173481[27:11<24:34,55.28it/s] 58%|#####8    |101326/173481[30:00<21:42,55.41it/s] 59%|#####8    |101967/173481[30:11<21:30,55.41it/s] 64%|######4   |111314/173481[33:00<18:41,55.45it/s] 65%|######4   |111919/173481[33:11<18:30,55.45it/s] 70%|#######   |122098/173481[36:00<14:52,57.59it/s] 71%|#######   |122837/173481[36:11<14:39,57.59it/s] 77%|#######7  |133879/173481[39:00<10:46,61.27it/s] 78%|#######7  |134601/173481[39:11<10:34,61.27it/s] 83%|########3 |144112/173481[42:00<08:18,58.96it/s] 83%|########3 |144775/173481[42:12<08:06,58.96it/s] 89%|########8 |154036/173481[45:00<05:41,56.98it/s] 89%|########9 |154685/173481[45:12<05:29,56.98it/s] 95%|#########4|164080/173481[48:00<02:46,56.37it/s] 95%|#########4|164761/173481[48:12<02:34,56.37it/s][32m[0320 16:30:25 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:3054.59 sec.
100%|##########|173481/173481[50:54<00:00,56.79it/s]
[32m[0320 16:30:26 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-1040886.
[32m[0320 16:30:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,200.04it/s]
5
[32m[0320 16:32:01 @monitor.py:363][0m QueueInput/queue_size: 0.41363
[32m[0320 16:32:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 17.962
[32m[0320 16:32:01 @monitor.py:363][0m activation-summaries/output-rms: 0.044161
[32m[0320 16:32:01 @monitor.py:363][0m cross_entropy_loss: 1.4164
[32m[0320 16:32:01 @monitor.py:363][0m lr: 0.00025
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.25789
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0846
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.16226
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.17266
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.13093
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.12843
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 16:32:01 @monitor.py:363][0m train-error-top1: 0.38009
[32m[0320 16:32:01 @monitor.py:363][0m val-error-top1: 0.42943
[32m[0320 16:32:01 @monitor.py:363][0m val-utt-error: 0.090214
[32m[0320 16:32:01 @monitor.py:363][0m validation_cost: 1.6191
[32m[0320 16:32:01 @monitor.py:363][0m wd_cost: 0.15173
[32m[0320 16:32:01 @group.py:42][0m Callbacks took 96.181 sec in total. InferenceRunner: 94.103sec
[32m[0320 16:32:01 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10771/173481[03:00<45:19,59.82it/s]  7%|6         |11375/173481[03:10<45:09,59.82it/s] 12%|#2        |20995/173481[06:00<43:37,58.27it/s] 12%|#2        |21612/173481[06:10<43:26,58.27it/s] 18%|#8        |31519/173481[09:00<40:32,58.36it/s] 19%|#8        |32118/173481[09:10<40:22,58.36it/s] 24%|##3       |41599/173481[12:00<38:27,57.14it/s] 24%|##4       |42192/173481[12:10<38:17,57.14it/s] 30%|##9       |51666/173481[15:00<35:54,56.53it/s] 30%|###       |52231/173481[15:10<35:44,56.53it/s] 36%|###5      |61609/173481[18:00<33:22,55.87it/s] 36%|###5      |62154/173481[18:10<33:12,55.87it/s] 41%|####1     |71621/173481[21:00<30:27,55.75it/s] 42%|####1     |72216/173481[21:11<30:16,55.75it/s] 47%|####7     |81727/173481[24:00<27:20,55.93it/s] 47%|####7     |82326/173481[24:11<27:09,55.93it/s] 53%|#####2    |91273/173481[27:00<25:10,54.43it/s] 53%|#####2    |91887/173481[27:11<24:59,54.43it/s] 58%|#####8    |100705/173481[30:00<22:43,53.39it/s] 58%|#####8    |101298/173481[30:11<22:31,53.39it/s] 64%|######3   |110333/173481[33:00<19:41,53.44it/s] 64%|######3   |110940/173481[33:11<19:30,53.44it/s] 69%|######9   |120119/173481[36:00<16:30,53.90it/s] 70%|######9   |120696/173481[36:11<16:19,53.90it/s] 75%|#######4  |129799/173481[39:00<13:31,53.84it/s] 75%|#######5  |130380/173481[39:11<13:20,53.84it/s] 80%|########  |139345/173481[42:00<10:38,53.42it/s] 81%|########  |139969/173481[42:12<10:27,53.42it/s] 86%|########5 |149005/173481[45:00<07:37,53.54it/s] 86%|########6 |149658/173481[45:12<07:24,53.54it/s] 92%|#########1|158857/173481[48:00<04:30,54.13it/s] 92%|#########1|159499/173481[48:12<04:18,54.13it/s] 97%|#########7|168679/173481[51:00<01:28,54.34it/s] 98%|#########7|169350/173481[51:12<01:16,54.34it/s]100%|##########|173481/173481[52:28<00:00,55.10it/s]
[32m[0320 17:24:30 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:3148.57 sec.
[32m[0320 17:24:31 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-1214367.
[32m[0320 17:24:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,183.13it/s]
6
[32m[0320 17:26:15 @monitor.py:363][0m QueueInput/queue_size: 0.60161
[32m[0320 17:26:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.983
[32m[0320 17:26:15 @monitor.py:363][0m activation-summaries/output-rms: 0.044086
[32m[0320 17:26:15 @monitor.py:363][0m cross_entropy_loss: 1.3986
[32m[0320 17:26:15 @monitor.py:363][0m lr: 0.00025
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.32512
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0933
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.18453
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2015
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.15222
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.14971
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 17:26:15 @monitor.py:363][0m train-error-top1: 0.38428
[32m[0320 17:26:15 @monitor.py:363][0m val-error-top1: 0.40918
[32m[0320 17:26:15 @monitor.py:363][0m val-utt-error: 0.076294
[32m[0320 17:26:15 @monitor.py:363][0m validation_cost: 1.5292
[32m[0320 17:26:15 @monitor.py:363][0m wd_cost: 0.21055
[32m[0320 17:26:15 @group.py:42][0m Callbacks took 105.232 sec in total. InferenceRunner: 102.789sec
[32m[0320 17:26:15 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10138/173481[03:00<48:20,56.32it/s]  6%|6         |10695/173481[03:10<48:10,56.32it/s] 11%|#1        |19282/173481[06:00<48:06,53.41it/s] 11%|#1        |19833/173481[06:10<47:56,53.41it/s] 16%|#6        |28618/173481[09:00<45:52,52.62it/s] 17%|#6        |29169/173481[09:10<45:42,52.62it/s] 22%|##1       |37942/173481[12:00<43:16,52.20it/s] 22%|##2       |38436/173481[12:10<43:06,52.20it/s] 27%|##6       |46408/173481[15:00<42:48,49.48it/s] 27%|##7       |46965/173481[15:10<42:36,49.48it/s] 32%|###2      |55675/173481[18:00<38:54,50.46it/s] 32%|###2      |56235/173481[18:10<38:43,50.46it/s] 37%|###7      |64269/173481[21:00<37:05,49.07it/s] 37%|###7      |64797/173481[21:11<36:55,49.07it/s] 42%|####2     |73054/173481[24:00<34:12,48.93it/s] 42%|####2     |73581/173481[24:11<34:01,48.93it/s] 47%|####6     |81200/173481[27:00<32:42,47.02it/s] 47%|####7     |81711/173481[27:11<32:31,47.02it/s] 52%|#####1    |89452/173481[30:00<30:10,46.42it/s] 52%|#####1    |89933/173481[30:11<29:59,46.42it/s] 57%|#####6    |98018/173481[33:00<26:45,47.00it/s] 57%|#####6    |98577/173481[33:11<26:33,47.00it/s] 62%|######1   |107326/173481[36:00<22:23,49.23it/s] 62%|######2   |107911/173481[36:11<22:11,49.23it/s] 67%|######7   |116383/173481[39:00<19:07,49.77it/s] 67%|######7   |116991/173481[39:11<18:55,49.77it/s] 72%|#######2  |125741/173481[42:00<15:38,50.85it/s] 73%|#######2  |126231/173481[42:12<15:29,50.85it/s] 78%|#######7  |134758/173481[45:00<12:47,50.47it/s] 78%|#######8  |135384/173481[45:12<12:34,50.47it/s] 83%|########3 |144124/173481[48:00<09:33,51.23it/s] 83%|########3 |144711/173481[48:12<09:21,51.23it/s] 88%|########8 |153202/173481[51:00<06:39,50.82it/s] 89%|########8 |153833/173481[51:12<06:26,50.82it/s] 94%|#########3|162724/173481[54:00<03:27,51.83it/s] 94%|#########4|163383/173481[54:12<03:14,51.83it/s] 99%|#########9|172276/173481[57:00<00:22,52.44it/s]100%|#########9|172917/173481[57:12<00:10,52.44it/s]100%|##########|173481/173481[57:23<00:00,50.38it/s]
[32m[0320 18:23:38 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:3443.48 sec.
[32m[0320 18:23:39 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-1387848.
[32m[0320 18:23:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.51it/s]
7
[32m[0320 18:25:37 @monitor.py:363][0m QueueInput/queue_size: 0.68598
[32m[0320 18:25:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.86
[32m[0320 18:25:37 @monitor.py:363][0m activation-summaries/output-rms: 0.045428
[32m[0320 18:25:37 @monitor.py:363][0m cross_entropy_loss: 1.2915
[32m[0320 18:25:37 @monitor.py:363][0m lr: 0.00025
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.36257
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1033
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.19001
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.21072
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.16005
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.1569
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 18:25:37 @monitor.py:363][0m train-error-top1: 0.34921
[32m[0320 18:25:37 @monitor.py:363][0m val-error-top1: 0.40122
[32m[0320 18:25:37 @monitor.py:363][0m val-utt-error: 0.072893
[32m[0320 18:25:37 @monitor.py:363][0m validation_cost: 1.4967
[32m[0320 18:25:37 @monitor.py:363][0m wd_cost: 0.23651
[32m[0320 18:25:37 @group.py:42][0m Callbacks took 118.955 sec in total. InferenceRunner: 117.277sec
[32m[0320 18:25:37 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10182/173481[03:00<48:06,56.57it/s]  6%|6         |10722/173481[03:10<47:57,56.57it/s] 11%|#1        |19347/173481[06:00<47:56,53.59it/s] 11%|#1        |19884/173481[06:10<47:46,53.59it/s] 16%|#6        |28189/173481[09:00<47:14,51.25it/s] 17%|#6        |28740/173481[09:10<47:04,51.25it/s] 22%|##1       |37567/173481[12:00<43:50,51.66it/s] 22%|##1       |38081/173481[12:10<43:40,51.66it/s] 27%|##7       |47056/173481[15:00<40:22,52.18it/s] 27%|##7       |47706/173481[15:10<40:10,52.18it/s] 33%|###2      |56681/173481[18:00<36:51,52.82it/s] 33%|###3      |57270/173481[18:10<36:40,52.82it/s] 38%|###8      |66265/173481[21:00<33:42,53.02it/s] 39%|###8      |66846/173481[21:11<33:31,53.02it/s] 44%|####3     |75543/173481[24:00<31:13,52.27it/s] 44%|####3     |76146/173481[24:11<31:02,52.27it/s] 49%|####9     |85398/173481[27:00<27:26,53.48it/s] 50%|####9     |86004/173481[27:11<27:15,53.48it/s] 55%|#####4    |94717/173481[30:00<24:57,52.61it/s] 55%|#####4    |95323/173481[30:11<24:45,52.61it/s] 60%|#####9    |103808/173481[33:00<22:31,51.54it/s] 60%|######    |104352/173481[33:11<22:21,51.54it/s] 64%|######4   |111891/173481[36:00<21:23,47.99it/s] 65%|######4   |112422/173481[36:11<21:12,47.99it/s] 70%|######9   |121303/173481[39:00<17:22,50.04it/s] 70%|#######   |121938/173481[39:11<17:09,50.04it/s] 76%|#######5  |131527/173481[42:00<13:08,53.20it/s] 76%|#######6  |132150/173481[42:12<12:56,53.20it/s] 81%|########1 |141187/173481[45:00<10:04,53.43it/s] 82%|########1 |141834/173481[45:12<09:52,53.43it/s] 87%|########7 |150931/173481[48:00<06:59,53.77it/s] 87%|########7 |151594/173481[48:12<06:47,53.77it/s] 93%|#########2|161004/173481[51:00<03:47,54.85it/s] 93%|#########3|161682/173481[51:12<03:35,54.85it/s] 99%|#########8|171319/173481[54:00<00:38,56.04it/s] 99%|#########9|172040/173481[54:12<00:25,56.04it/s]100%|##########|173481/173481[54:38<00:00,52.92it/s]
[32m[0320 19:20:15 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:3278.16 sec.
[32m[0320 19:20:16 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-1561329.
[32m[0320 19:20:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,190.05it/s]
8
[32m[0320 19:21:57 @monitor.py:363][0m QueueInput/queue_size: 0.64853
[32m[0320 19:21:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.878
[32m[0320 19:21:57 @monitor.py:363][0m activation-summaries/output-rms: 0.047679
[32m[0320 19:21:57 @monitor.py:363][0m cross_entropy_loss: 1.2262
[32m[0320 19:21:57 @monitor.py:363][0m lr: 0.000125
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.41469
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1084
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.21083
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.22266
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064564
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.16674
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16341
[32m[0320 19:21:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 19:21:57 @monitor.py:363][0m train-error-top1: 0.33833
[32m[0320 19:21:57 @monitor.py:363][0m val-error-top1: 0.35795
[32m[0320 19:21:57 @monitor.py:363][0m val-utt-error: 0.053342
[32m[0320 19:21:57 @monitor.py:363][0m validation_cost: 1.3146
[32m[0320 19:21:57 @monitor.py:363][0m wd_cost: 0.056754
[32m[0320 19:21:57 @group.py:42][0m Callbacks took 101.722 sec in total. InferenceRunner: 99.052sec
[32m[0320 19:21:57 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10756/173481[03:00<45:23,59.75it/s]  7%|6         |11333/173481[03:10<45:13,59.75it/s] 12%|#1        |20584/173481[06:00<44:39,57.05it/s] 12%|#2        |21088/173481[06:10<44:31,57.05it/s] 17%|#7        |30328/173481[09:00<42:56,55.55it/s] 18%|#7        |30933/173481[09:10<42:45,55.55it/s] 23%|##3       |40228/173481[12:00<40:10,55.27it/s] 24%|##3       |40803/173481[12:10<40:00,55.27it/s] 29%|##8       |50242/173481[15:00<37:02,55.45it/s] 29%|##9       |50865/173481[15:10<36:51,55.45it/s] 35%|###4      |60551/173481[18:00<33:24,56.35it/s] 35%|###5      |61179/173481[18:10<33:13,56.35it/s] 41%|####      |71057/173481[21:00<29:46,57.34it/s] 41%|####1     |71733/173481[21:11<29:34,57.34it/s] 47%|####6     |81214/173481[24:00<27:02,56.87it/s] 47%|####7     |81850/173481[24:11<26:51,56.87it/s] 53%|#####2    |91576/173481[27:00<23:51,57.21it/s] 53%|#####3    |92214/173481[27:11<23:40,57.21it/s] 59%|#####8    |101992/173481[30:00<20:42,57.53it/s] 59%|#####9    |102644/173481[30:11<20:31,57.53it/s] 65%|######4   |112323/173481[33:00<17:44,57.46it/s] 65%|######5   |112977/173481[33:11<17:32,57.46it/s] 70%|#######   |122159/173481[36:00<15:16,56.02it/s] 71%|#######   |122757/173481[36:11<15:05,56.02it/s] 76%|#######5  |131333/173481[39:00<13:09,53.37it/s] 76%|#######6  |131909/173481[39:11<12:58,53.37it/s] 81%|########1 |140854/173481[42:00<10:14,53.13it/s] 82%|########1 |141495/173481[42:12<10:02,53.13it/s] 87%|########6 |150296/173481[45:00<07:19,52.79it/s] 87%|########7 |150981/173481[45:12<07:06,52.79it/s] 93%|#########2|160696/173481[48:00<03:51,55.17it/s] 93%|#########3|161406/173481[48:12<03:38,55.17it/s] 98%|#########8|170734/173481[51:00<00:49,55.46it/s] 99%|#########8|171393/173481[51:12<00:37,55.46it/s]100%|##########|173481/173481[51:49<00:00,55.78it/s]
[32m[0320 20:13:47 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:3109.91 sec.
[32m[0320 20:13:48 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-1734810.
[32m[0320 20:13:49 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,184.08it/s]
9
[32m[0320 20:15:32 @monitor.py:363][0m QueueInput/queue_size: 0.68294
[32m[0320 20:15:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.562
[32m[0320 20:15:32 @monitor.py:363][0m activation-summaries/output-rms: 0.045761
[32m[0320 20:15:32 @monitor.py:363][0m cross_entropy_loss: 1.2073
[32m[0320 20:15:32 @monitor.py:363][0m lr: 0.000125
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.47139
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1103
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.23366
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.23851
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064564
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.17626
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.17278
[32m[0320 20:15:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 20:15:32 @monitor.py:363][0m train-error-top1: 0.32902
[32m[0320 20:15:32 @monitor.py:363][0m val-error-top1: 0.35105
[32m[0320 20:15:32 @monitor.py:363][0m val-utt-error: 0.048932
[32m[0320 20:15:32 @monitor.py:363][0m validation_cost: 1.2911
[32m[0320 20:15:32 @monitor.py:363][0m wd_cost: 0.0688
[32m[0320 20:15:32 @group.py:42][0m Callbacks took 104.801 sec in total. InferenceRunner: 102.258sec
[32m[0320 20:15:32 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11569/173481[03:00<41:59,64.26it/s]  7%|6         |12138/173481[03:10<41:50,64.26it/s] 13%|#2        |21733/173481[06:00<42:04,60.10it/s] 13%|#2        |22338/173481[06:10<41:54,60.10it/s] 19%|#8        |32107/173481[09:00<40:02,58.84it/s] 19%|#8        |32700/173481[09:10<39:52,58.84it/s] 24%|##4       |42242/173481[12:00<38:00,57.55it/s] 25%|##4       |42852/173481[12:10<37:50,57.55it/s] 30%|###       |52723/173481[15:00<34:46,57.88it/s] 31%|###       |53328/173481[15:10<34:35,57.88it/s] 36%|###6      |62923/173481[18:00<32:10,57.26it/s] 37%|###6      |63522/173481[18:10<32:00,57.26it/s] 42%|####2     |73195/173481[21:00<29:14,57.16it/s] 43%|####2     |73806/173481[21:11<29:03,57.16it/s] 48%|####8     |83345/173481[24:00<26:27,56.77it/s] 48%|####8     |83971/173481[24:11<26:16,56.77it/s] 54%|#####3    |93600/173481[27:00<23:24,56.87it/s] 54%|#####4    |94268/173481[27:11<23:12,56.87it/s] 60%|#####9    |103959/173481[30:00<20:15,57.21it/s] 60%|######    |104676/173481[30:11<20:02,57.21it/s] 66%|######5   |114223/173481[33:00<17:17,57.11it/s] 66%|######6   |114768/173481[33:11<17:08,57.11it/s] 72%|#######2  |125185/173481[36:00<13:39,58.94it/s] 73%|#######2  |125955/173481[36:11<13:26,58.94it/s] 79%|#######9  |137383/173481[39:00<09:32,63.03it/s] 80%|#######9  |138274/173481[39:12<09:18,63.03it/s] 85%|########5 |148303/173481[42:00<06:47,61.82it/s] 86%|########5 |149034/173481[42:12<06:35,61.82it/s] 92%|#########2|159633/173481[45:00<03:42,62.38it/s] 92%|#########2|160386/173481[45:12<03:29,62.38it/s] 99%|#########8|171073/173481[48:00<00:38,62.96it/s] 99%|#########9|171798/173481[48:12<00:26,62.96it/s]100%|##########|173481/173481[48:36<00:00,59.49it/s]
[32m[0320 21:04:08 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:2916.31 sec.
[32m[0320 21:04:09 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-1908291.
[32m[0320 21:04:11 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:28<00:00,212.26it/s]
10
[32m[0320 21:05:39 @monitor.py:363][0m QueueInput/queue_size: 0.7538
[32m[0320 21:05:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 52.489
[32m[0320 21:05:39 @monitor.py:363][0m activation-summaries/output-rms: 0.047299
[32m[0320 21:05:39 @monitor.py:363][0m cross_entropy_loss: 1.1623
[32m[0320 21:05:39 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.51905
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.111
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.24686
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.24888
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064564
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.18306
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.1796
[32m[0320 21:05:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061791
[32m[0320 21:05:39 @monitor.py:363][0m train-error-top1: 0.32038
[32m[0320 21:05:39 @monitor.py:363][0m val-error-top1: 0.33397
[32m[0320 21:05:39 @monitor.py:363][0m val-utt-error: 0.044575
[32m[0320 21:05:39 @monitor.py:363][0m validation_cost: 1.2154
[32m[0320 21:05:39 @monitor.py:363][0m wd_cost: 0.078222
[32m[0320 21:05:39 @group.py:42][0m Callbacks took 91.165 sec in total. InferenceRunner: 88.686sec
[32m[0320 21:05:39 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12581/173481[03:00<38:22,69.89it/s]  8%|7         |13215/173481[03:10<38:13,69.89it/s] 18%|#7        |30610/173481[06:00<28:55,82.33it/s] 18%|#8        |31774/173481[06:10<28:41,82.33it/s] 29%|##8       |49563/173481[09:00<22:21,92.41it/s] 29%|##9       |50590/173481[09:10<22:09,92.41it/s] 38%|###7      |65601/173481[12:00<19:49,90.72it/s] 38%|###8      |66464/173481[12:10<19:39,90.72it/s] 45%|####5     |78568/173481[15:00<19:42,80.29it/s] 46%|####5     |79366/173481[15:10<19:32,80.29it/s] 53%|#####2    |91858/173481[18:00<17:41,76.92it/s] 53%|#####3    |92481/173481[18:10<17:32,76.92it/s] 60%|#####9    |103516/173481[21:00<16:34,70.32it/s] 60%|######    |104175/173481[21:11<16:25,70.32it/s] 65%|######5   |113140/173481[24:00<16:33,60.73it/s] 66%|######5   |113685/173481[24:11<16:24,60.73it/s] 71%|#######   |122638/173481[27:00<15:00,56.47it/s] 71%|#######1  |123234/173481[27:11<14:49,56.47it/s] 76%|#######6  |132488/173481[30:00<12:17,55.58it/s] 77%|#######6  |133133/173481[30:11<12:05,55.58it/s] 82%|########2 |142571/173481[33:00<09:13,55.80it/s] 83%|########2 |143223/173481[33:11<09:02,55.80it/s] 88%|########8 |152818/173481[36:00<06:06,56.34it/s] 88%|########8 |153468/173481[36:11<05:55,56.34it/s] 94%|#########3|163066/173481[39:00<03:03,56.63it/s] 94%|#########4|163731/173481[39:12<02:52,56.63it/s]100%|#########9|172912/173481[42:00<00:10,55.64it/s]100%|##########|173481/173481[42:10<00:00,68.56it/s]
[32m[0320 21:47:50 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:2530.48 sec.
[32m[0320 21:47:50 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-2081772.
[32m[0320 21:47:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.16it/s]
11
[32m[0320 21:49:45 @monitor.py:363][0m QueueInput/queue_size: 0.72855
[32m[0320 21:49:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 58.46
[32m[0320 21:49:45 @monitor.py:363][0m activation-summaries/output-rms: 0.048599
[32m[0320 21:49:45 @monitor.py:363][0m cross_entropy_loss: 1.0858
[32m[0320 21:49:45 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.55235
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1128
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.25769
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.25388
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064564
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.18579
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18227
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0320 21:49:45 @monitor.py:363][0m train-error-top1: 0.29998
[32m[0320 21:49:45 @monitor.py:363][0m val-error-top1: 0.32834
[32m[0320 21:49:45 @monitor.py:363][0m val-utt-error: 0.043672
[32m[0320 21:49:45 @monitor.py:363][0m validation_cost: 1.1948
[32m[0320 21:49:45 @monitor.py:363][0m wd_cost: 0.017001
[32m[0320 21:49:45 @group.py:42][0m Callbacks took 114.896 sec in total. InferenceRunner: 112.609sec
[32m[0320 21:49:45 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12721/173481[03:00<37:55,70.64it/s]  8%|7         |13230/173481[03:10<37:48,70.64it/s] 13%|#2        |22231/173481[06:00<41:42,60.45it/s] 13%|#3        |22794/173481[06:10<41:32,60.45it/s] 19%|#8        |32833/173481[09:00<39:17,59.66it/s] 19%|#9        |33450/173481[09:10<39:07,59.66it/s] 25%|##4       |43141/173481[12:00<37:11,58.42it/s] 25%|##5       |43710/173481[12:10<37:01,58.42it/s] 31%|###       |53077/173481[15:00<35:21,56.76it/s] 31%|###       |53695/173481[15:10<35:10,56.76it/s] 37%|###6      |63379/173481[18:00<32:11,56.99it/s] 37%|###6      |63969/173481[18:10<32:01,56.99it/s] 43%|####2     |73789/173481[21:00<28:56,57.41it/s] 43%|####2     |74397/173481[21:11<28:45,57.41it/s] 48%|####8     |83989/173481[24:00<26:09,57.03it/s] 49%|####8     |84540/173481[24:11<25:59,57.03it/s] 54%|#####4    |93740/173481[27:00<23:55,55.56it/s] 54%|#####4    |94368/173481[27:11<23:43,55.56it/s] 60%|#####9    |103723/173481[30:00<20:56,55.51it/s] 60%|######    |104288/173481[30:11<20:46,55.51it/s] 65%|######5   |113287/173481[33:00<18:28,54.28it/s] 66%|######5   |113873/173481[33:11<18:18,54.28it/s] 71%|#######   |122911/173481[36:00<15:38,53.86it/s] 71%|#######1  |123498/173481[36:11<15:27,53.86it/s] 76%|#######6  |132061/173481[39:00<13:12,52.29it/s] 76%|#######6  |132666/173481[39:11<13:00,52.29it/s] 81%|########1 |141083/173481[42:00<10:32,51.18it/s] 82%|########1 |141687/173481[42:12<10:21,51.18it/s] 87%|########6 |150553/173481[45:00<07:21,51.88it/s] 87%|########7 |151260/173481[45:12<07:08,51.88it/s] 91%|#########1|158597/173481[48:00<05:09,48.02it/s] 92%|#########1|159168/173481[48:12<04:58,48.02it/s] 96%|#########6|166795/173481[51:00<02:23,46.74it/s] 96%|#########6|167388/173481[51:12<02:10,46.74it/s]100%|##########|173481/173481[53:22<00:00,54.17it/s]
[32m[0320 22:43:07 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3202.57 sec.
[32m[0320 22:43:08 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-2255253.
[32m[0320 22:43:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,187.35it/s]
12
[32m[0320 22:44:50 @monitor.py:363][0m QueueInput/queue_size: 0.6916
[32m[0320 22:44:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 62.582
[32m[0320 22:44:50 @monitor.py:363][0m activation-summaries/output-rms: 0.048217
[32m[0320 22:44:50 @monitor.py:363][0m cross_entropy_loss: 1.1278
[32m[0320 22:44:50 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5861
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1129
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.26834
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.25947
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064564
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.18891
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18537
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0320 22:44:50 @monitor.py:363][0m train-error-top1: 0.31114
[32m[0320 22:44:50 @monitor.py:363][0m val-error-top1: 0.32464
[32m[0320 22:44:50 @monitor.py:363][0m val-utt-error: 0.041707
[32m[0320 22:44:50 @monitor.py:363][0m validation_cost: 1.1801
[32m[0320 22:44:50 @monitor.py:363][0m wd_cost: 0.018453
[32m[0320 22:44:50 @group.py:42][0m Callbacks took 102.880 sec in total. InferenceRunner: 100.475sec
[32m[0320 22:44:50 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9921/173481[03:00<49:27,55.11it/s]  6%|6         |10467/173481[03:10<49:17,55.11it/s] 11%|#1        |19240/173481[06:00<48:09,53.39it/s] 11%|#1        |19804/173481[06:10<47:58,53.39it/s] 17%|#6        |28774/173481[09:00<45:21,53.18it/s] 17%|#6        |29361/173481[09:10<45:10,53.18it/s] 22%|##1       |38157/173481[12:00<42:50,52.65it/s] 22%|##2       |38717/173481[12:10<42:39,52.65it/s] 28%|##7       |47723/173481[15:00<39:37,52.89it/s] 28%|##7       |48320/173481[15:10<39:26,52.89it/s] 33%|###2      |57119/173481[18:00<36:54,52.54it/s] 33%|###3      |57693/173481[18:10<36:43,52.54it/s] 39%|###8      |66814/173481[21:00<33:25,53.19it/s] 39%|###8      |67359/173481[21:11<33:15,53.19it/s] 44%|####3     |76210/173481[24:00<30:46,52.67it/s] 44%|####4     |76767/173481[24:11<30:36,52.67it/s] 49%|####9     |85431/173481[27:00<28:15,51.94it/s] 50%|####9     |86008/173481[27:11<28:04,51.94it/s] 55%|#####4    |94792/173481[30:00<25:14,51.96it/s] 55%|#####4    |95391/173481[30:11<25:02,51.96it/s] 60%|######    |104482/173481[33:00<21:45,52.87it/s] 61%|######    |105093/173481[33:11<21:33,52.87it/s] 65%|######5   |113584/173481[36:00<19:18,51.68it/s] 66%|######5   |114183/173481[36:11<19:07,51.68it/s] 71%|#######   |123148/173481[39:00<16:00,52.39it/s] 71%|#######1  |123748/173481[39:11<15:49,52.39it/s] 77%|#######6  |132788/173481[42:00<12:48,52.97it/s] 77%|#######6  |133395/173481[42:12<12:36,52.97it/s] 82%|########2 |142312/173481[45:00<09:48,52.94it/s] 82%|########2 |142935/173481[45:12<09:37,52.94it/s] 88%|########7 |151927/173481[48:00<06:45,53.18it/s] 88%|########7 |152565/173481[48:12<06:33,53.18it/s] 93%|#########3|161608/173481[51:00<03:42,53.47it/s] 94%|#########3|162279/173481[51:12<03:29,53.47it/s] 99%|#########8|171340/173481[54:00<00:39,53.76it/s] 99%|#########9|171957/173481[54:12<00:28,53.76it/s]100%|##########|173481/173481[54:42<00:00,52.86it/s]
[32m[0320 23:39:32 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:3282.11 sec.
[32m[0320 23:39:33 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-2428734.
[32m[0320 23:39:34 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:28<00:00,213.32it/s]
13
[32m[0320 23:41:02 @monitor.py:363][0m QueueInput/queue_size: 0.44733
[32m[0320 23:41:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 66.735
[32m[0320 23:41:02 @monitor.py:363][0m activation-summaries/output-rms: 0.048777
[32m[0320 23:41:02 @monitor.py:363][0m cross_entropy_loss: 1.033
[32m[0320 23:41:02 @monitor.py:363][0m lr: 3.125e-05
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61335
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1131
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27578
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26318
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19102
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.1875
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0320 23:41:02 @monitor.py:363][0m train-error-top1: 0.29095
[32m[0320 23:41:02 @monitor.py:363][0m val-error-top1: 0.31636
[32m[0320 23:41:02 @monitor.py:363][0m val-utt-error: 0.040219
[32m[0320 23:41:02 @monitor.py:363][0m validation_cost: 1.1492
[32m[0320 23:41:02 @monitor.py:363][0m wd_cost: 0.0039192
[32m[0320 23:41:02 @group.py:42][0m Callbacks took 89.883 sec in total. InferenceRunner: 88.247sec
[32m[0320 23:41:02 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10063/173481[03:00<48:43,55.90it/s]  6%|6         |10631/173481[03:10<48:33,55.90it/s] 11%|#         |19035/173481[06:00<48:50,52.70it/s] 11%|#1        |19566/173481[06:10<48:40,52.70it/s] 16%|#6        |28051/173481[09:00<47:11,51.36it/s] 17%|#6        |28638/173481[09:10<47:00,51.36it/s] 22%|##1       |37576/173481[12:00<43:27,52.13it/s] 22%|##1       |38106/173481[12:10<43:17,52.13it/s] 27%|##7       |46920/173481[15:00<40:33,52.02it/s] 27%|##7       |47450/173481[15:10<40:22,52.02it/s] 32%|###2      |56311/173481[18:00<37:29,52.09it/s] 33%|###2      |56895/173481[18:10<37:17,52.09it/s] 38%|###8      |66083/173481[21:00<33:39,53.17it/s] 38%|###8      |66687/173481[21:11<33:28,53.17it/s] 43%|####3     |75181/173481[24:00<31:37,51.82it/s] 44%|####3     |75780/173481[24:11<31:25,51.82it/s] 49%|####8     |84979/173481[27:00<27:47,53.09it/s] 49%|####9     |85482/173481[27:11<27:37,53.09it/s] 54%|#####4    |93976/173481[30:00<25:44,51.49it/s] 55%|#####4    |94571/173481[30:11<25:32,51.49it/s] 59%|#####9    |102586/173481[33:00<23:49,49.59it/s] 59%|#####9    |103148/173481[33:11<23:38,49.59it/s] 64%|######4   |111624/173481[36:00<20:39,49.90it/s] 65%|######4   |112236/173481[36:11<20:27,49.90it/s] 70%|######9   |120647/173481[39:00<17:36,50.01it/s] 70%|######9   |121204/173481[39:11<17:25,50.01it/s] 75%|#######4  |129313/173481[42:00<15:00,49.06it/s] 75%|#######4  |129900/173481[42:12<14:48,49.06it/s] 79%|#######9  |137869/173481[45:00<12:17,48.28it/s] 80%|#######9  |138480/173481[45:12<12:04,48.28it/s] 85%|########4 |147201/173481[48:00<08:45,50.00it/s] 85%|########5 |147864/173481[48:12<08:32,50.00it/s] 90%|######### |156901/173481[51:00<05:19,51.86it/s] 91%|######### |157551/173481[51:12<05:07,51.86it/s] 96%|#########5|166357/173481[54:00<02:16,52.18it/s] 96%|#########6|166941/173481[54:12<02:05,52.18it/s]100%|##########|173481/173481[55:59<00:00,51.64it/s]
[32m[0321 00:37:02 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3359.49 sec.
[32m[0321 00:37:02 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-2602215.
[32m[0321 00:37:04 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:23<00:00,224.82it/s]
14
[32m[0321 00:38:28 @monitor.py:363][0m QueueInput/queue_size: 0.69151
[32m[0321 00:38:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 69.451
[32m[0321 00:38:28 @monitor.py:363][0m activation-summaries/output-rms: 0.049241
[32m[0321 00:38:28 @monitor.py:363][0m cross_entropy_loss: 1.0625
[32m[0321 00:38:28 @monitor.py:363][0m lr: 3.125e-05
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63169
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.113
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28039
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26509
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19197
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18845
[32m[0321 00:38:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 00:38:28 @monitor.py:363][0m train-error-top1: 0.30331
[32m[0321 00:38:28 @monitor.py:363][0m val-error-top1: 0.31343
[32m[0321 00:38:28 @monitor.py:363][0m val-utt-error: 0.038572
[32m[0321 00:38:28 @monitor.py:363][0m validation_cost: 1.1366
[32m[0321 00:38:28 @monitor.py:363][0m wd_cost: 0.0040684
[32m[0321 00:38:28 @group.py:42][0m Callbacks took 86.295 sec in total. InferenceRunner: 83.730sec
[32m[0321 00:38:28 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10180/173481[03:00<48:07,56.55it/s]  6%|6         |10697/173481[03:10<47:58,56.55it/s] 11%|#1        |19284/173481[06:00<48:07,53.40it/s] 11%|#1        |19821/173481[06:10<47:57,53.40it/s] 17%|#6        |28660/173481[09:00<45:46,52.73it/s] 17%|#6        |29227/173481[09:10<45:35,52.73it/s] 22%|##2       |38386/173481[12:00<42:11,53.37it/s] 22%|##2       |38925/173481[12:10<42:00,53.37it/s] 27%|##7       |47692/173481[15:00<39:55,52.52it/s] 28%|##7       |48153/173481[15:10<39:46,52.52it/s] 33%|###2      |56416/173481[18:00<38:42,50.40it/s] 33%|###2      |57007/173481[18:10<38:30,50.40it/s] 38%|###7      |65074/173481[21:00<36:42,49.22it/s] 38%|###7      |65635/173481[21:11<36:31,49.22it/s] 43%|####2     |74314/173481[24:00<32:53,50.25it/s] 43%|####3     |74869/173481[24:11<32:42,50.25it/s] 48%|####8     |83662/173481[27:00<29:18,51.08it/s] 49%|####8     |84267/173481[27:11<29:06,51.08it/s] 54%|#####3    |93088/173481[30:00<25:54,51.71it/s] 54%|#####4    |93688/173481[30:11<25:43,51.71it/s] 59%|#####9    |102712/173481[33:00<22:26,52.56it/s] 60%|#####9    |103311/173481[33:11<22:14,52.56it/s] 65%|######4   |112442/173481[36:00<19:05,53.30it/s] 65%|######5   |113079/173481[36:11<18:53,53.30it/s] 70%|#######   |121942/173481[39:00<16:11,53.03it/s] 71%|#######   |122537/173481[39:12<16:00,53.03it/s] 76%|#######5  |131200/173481[42:00<13:29,52.22it/s] 76%|#######6  |131847/173481[42:12<13:17,52.22it/s] 81%|########1 |140956/173481[45:00<10:11,53.19it/s] 82%|########1 |141620/173481[45:12<09:59,53.19it/s] 87%|########6 |150568/173481[48:00<07:09,53.29it/s] 87%|########7 |151191/173481[48:12<06:58,53.29it/s] 92%|#########2|159850/173481[51:00<04:20,52.41it/s] 93%|#########2|160491/173481[51:12<04:07,52.41it/s] 97%|#########7|169114/173481[54:00<01:24,51.93it/s] 98%|#########7|169745/173481[54:12<01:11,51.93it/s]100%|##########|173481/173481[55:21<00:00,52.24it/s]
[32m[0321 01:33:49 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:3321.16 sec.
[32m[0321 01:33:50 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-2775696.
[32m[0321 01:33:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:24<00:00,221.98it/s]
15
[32m[0321 01:35:16 @monitor.py:363][0m QueueInput/queue_size: 0.37674
[32m[0321 01:35:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 72.383
[32m[0321 01:35:16 @monitor.py:363][0m activation-summaries/output-rms: 0.047782
[32m[0321 01:35:16 @monitor.py:363][0m cross_entropy_loss: 1.0785
[32m[0321 01:35:16 @monitor.py:363][0m lr: 3.125e-05
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.64998
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1133
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28478
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26694
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19291
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18937
[32m[0321 01:35:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 01:35:16 @monitor.py:363][0m train-error-top1: 0.28877
[32m[0321 01:35:16 @monitor.py:363][0m val-error-top1: 0.31301
[32m[0321 01:35:16 @monitor.py:363][0m val-utt-error: 0.037669
[32m[0321 01:35:16 @monitor.py:363][0m validation_cost: 1.1357
[32m[0321 01:35:16 @monitor.py:363][0m wd_cost: 0.0042186
[32m[0321 01:35:16 @group.py:42][0m Callbacks took 86.966 sec in total. InferenceRunner: 84.802sec
[32m[0321 01:35:16 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10435/173481[03:00<46:52,57.97it/s]  6%|6         |10962/173481[03:10<46:43,57.97it/s] 11%|#1        |19800/173481[06:00<46:42,54.84it/s] 12%|#1        |20362/173481[06:10<46:32,54.84it/s] 17%|#6        |29197/173481[09:00<44:57,53.48it/s] 17%|#7        |29725/173481[09:10<44:48,53.48it/s] 22%|##2       |38719/173481[12:00<42:13,53.19it/s] 23%|##2       |39288/173481[12:10<42:03,53.19it/s] 28%|##7       |48535/173481[15:00<38:40,53.85it/s] 28%|##8       |49122/173481[15:10<38:29,53.85it/s] 34%|###3      |58142/173481[18:00<35:51,53.61it/s] 34%|###3      |58711/173481[18:10<35:40,53.61it/s] 39%|###9      |67738/173481[21:00<32:58,53.46it/s] 39%|###9      |68324/173481[21:11<32:47,53.46it/s] 45%|####4     |77215/173481[24:00<30:14,53.05it/s] 45%|####4     |77784/173481[24:11<30:03,53.05it/s] 50%|####9     |86267/173481[27:00<28:09,51.63it/s] 50%|#####     |86838/173481[27:11<27:58,51.63it/s] 55%|#####5    |95557/173481[30:00<25:09,51.62it/s] 55%|#####5    |96142/173481[30:11<24:58,51.62it/s] 60%|######    |104894/173481[33:00<22:05,51.74it/s] 61%|######    |105492/173481[33:11<21:53,51.74it/s] 66%|######5   |114404/173481[36:00<18:49,52.28it/s] 66%|######6   |115020/173481[36:11<18:38,52.28it/s] 71%|#######1  |123703/173481[39:00<15:57,51.97it/s] 72%|#######1  |124380/173481[39:12<15:44,51.97it/s] 77%|#######6  |133021/173481[42:00<13:00,51.85it/s] 77%|#######7  |133638/173481[42:12<12:48,51.85it/s] 82%|########1 |142009/173481[45:00<10:18,50.87it/s] 82%|########2 |142675/173481[45:12<10:05,50.87it/s] 87%|########7 |151039/173481[48:00<07:24,50.51it/s] 87%|########7 |151596/173481[48:12<07:13,50.51it/s] 92%|#########2|159614/173481[51:00<04:42,49.03it/s] 92%|#########2|160244/173481[51:12<04:29,49.03it/s] 97%|#########7|169090/173481[54:00<01:26,50.77it/s] 98%|#########7|169765/173481[54:12<01:13,50.77it/s]100%|##########|173481/173481[55:21<00:00,52.23it/s]
[32m[0321 02:30:38 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:3321.59 sec.
[32m[0321 02:30:38 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-2949177.
[32m[0321 02:30:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:24<00:00,223.36it/s]
16
[32m[0321 02:32:04 @monitor.py:363][0m QueueInput/queue_size: 0.46425
[32m[0321 02:32:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 74.862
[32m[0321 02:32:04 @monitor.py:363][0m activation-summaries/output-rms: 0.048463
[32m[0321 02:32:04 @monitor.py:363][0m cross_entropy_loss: 1.0854
[32m[0321 02:32:04 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.66233
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1135
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28735
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26794
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19339
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18986
[32m[0321 02:32:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 02:32:04 @monitor.py:363][0m train-error-top1: 0.30262
[32m[0321 02:32:04 @monitor.py:363][0m val-error-top1: 0.30884
[32m[0321 02:32:04 @monitor.py:363][0m val-utt-error: 0.036128
[32m[0321 02:32:04 @monitor.py:363][0m validation_cost: 1.1165
[32m[0321 02:32:04 @monitor.py:363][0m wd_cost: 0.00086328
[32m[0321 02:32:04 @group.py:42][0m Callbacks took 86.603 sec in total. InferenceRunner: 84.295sec
[32m[0321 02:32:04 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10642/173481[03:00<45:55,59.11it/s]  6%|6         |11181/173481[03:10<45:45,59.11it/s] 12%|#1        |20526/173481[06:00<44:46,56.93it/s] 12%|#2        |21063/173481[06:10<44:37,56.93it/s] 17%|#7        |30160/173481[09:00<43:17,55.17it/s] 18%|#7        |30723/173481[09:10<43:07,55.17it/s] 23%|##3       |39994/173481[12:00<40:31,54.90it/s] 23%|##3       |40576/173481[12:10<40:20,54.90it/s] 29%|##8       |49816/173481[15:00<37:40,54.71it/s] 29%|##9       |50367/173481[15:10<37:30,54.71it/s] 34%|###4      |59435/173481[18:00<35:09,54.07it/s] 35%|###4      |60003/173481[18:10<34:58,54.07it/s] 40%|###9      |69226/173481[21:00<32:02,54.22it/s] 40%|####      |69781/173481[21:11<31:52,54.22it/s] 46%|####5     |78988/173481[24:00<29:02,54.22it/s] 46%|####5     |79593/173481[24:11<28:51,54.22it/s] 51%|#####1    |88719/173481[27:00<26:05,54.14it/s] 51%|#####1    |89322/173481[27:11<25:54,54.14it/s] 57%|#####6    |98278/173481[30:00<23:22,53.62it/s] 57%|#####7    |98892/173481[30:11<23:11,53.62it/s] 62%|######2   |107650/173481[33:00<20:46,52.82it/s] 62%|######2   |108214/173481[33:11<20:35,52.82it/s] 68%|######7   |117145/173481[36:00<17:47,52.78it/s] 68%|######7   |117759/173481[36:11<17:35,52.78it/s] 73%|#######3  |126762/173481[39:00<14:39,53.10it/s] 73%|#######3  |127341/173481[39:11<14:28,53.10it/s] 79%|#######8  |136306/173481[42:00<11:40,53.06it/s] 79%|#######8  |136941/173481[42:12<11:28,53.06it/s] 84%|########4 |145984/173481[45:00<08:34,53.41it/s] 85%|########4 |146623/173481[45:12<08:22,53.41it/s] 90%|########9 |155686/173481[48:00<05:31,53.64it/s] 90%|######### |156345/173481[48:12<05:19,53.64it/s] 95%|#########5|165304/173481[51:00<02:32,53.53it/s] 96%|#########5|165957/173481[51:12<02:20,53.53it/s]100%|##########|173481/173481[53:32<00:00,54.01it/s]
[32m[0321 03:25:36 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:3212.01 sec.
[32m[0321 03:25:37 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-3122658.
[32m[0321 03:25:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:23<00:00,225.80it/s]
17
[32m[0321 03:27:02 @monitor.py:363][0m QueueInput/queue_size: 0.72276
[32m[0321 03:27:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 76.45
[32m[0321 03:27:02 @monitor.py:363][0m activation-summaries/output-rms: 0.04922
[32m[0321 03:27:02 @monitor.py:363][0m cross_entropy_loss: 1.0288
[32m[0321 03:27:02 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67188
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1137
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28914
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26854
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19367
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19014
[32m[0321 03:27:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 03:27:02 @monitor.py:363][0m train-error-top1: 0.28872
[32m[0321 03:27:02 @monitor.py:363][0m val-error-top1: 0.30817
[32m[0321 03:27:02 @monitor.py:363][0m val-utt-error: 0.036712
[32m[0321 03:27:02 @monitor.py:363][0m validation_cost: 1.1136
[32m[0321 03:27:02 @monitor.py:363][0m wd_cost: 0.00087795
[32m[0321 03:27:02 @group.py:42][0m Callbacks took 85.571 sec in total. InferenceRunner: 83.366sec
[32m[0321 03:27:02 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10135/173481[03:00<48:22,56.28it/s]  6%|6         |10628/173481[03:10<48:13,56.28it/s] 11%|#1        |19111/173481[06:00<48:39,52.88it/s] 11%|#1        |19656/173481[06:10<48:28,52.88it/s] 16%|#6        |28609/173481[09:00<45:42,52.82it/s] 17%|#6        |29148/173481[09:10<45:32,52.82it/s] 22%|##2       |38635/173481[12:00<41:26,54.22it/s] 23%|##2       |39303/173481[12:10<41:14,54.22it/s] 29%|##9       |50436/173481[15:00<34:33,59.35it/s] 30%|##9       |51208/173481[15:10<34:20,59.35it/s] 35%|###4      |60619/173481[18:00<32:28,57.92it/s] 35%|###5      |61141/173481[18:10<32:19,57.92it/s] 39%|###9      |68287/173481[21:00<35:43,49.08it/s] 40%|###9      |68880/173481[21:11<35:31,49.08it/s] 45%|####4     |77998/173481[24:00<30:57,51.40it/s] 45%|####5     |78600/173481[24:11<30:45,51.40it/s] 50%|#####     |87025/173481[27:00<28:23,50.76it/s] 50%|#####     |87576/173481[27:11<28:12,50.76it/s] 55%|#####5    |96013/173481[30:00<25:38,50.34it/s] 56%|#####5    |96600/173481[30:11<25:27,50.34it/s] 60%|######    |104834/173481[33:00<23:02,49.66it/s] 61%|######    |105378/173481[33:11<22:51,49.66it/s] 65%|######5   |113479/173481[36:00<20:28,48.83it/s] 66%|######5   |114042/173481[36:11<20:17,48.83it/s] 70%|#######   |122137/173481[39:00<17:39,48.46it/s] 71%|#######   |122724/173481[39:12<17:27,48.46it/s] 75%|#######5  |130842/173481[42:00<14:40,48.41it/s] 76%|#######5  |131392/173481[42:12<14:29,48.41it/s] 81%|########  |139873/173481[45:00<11:22,49.27it/s] 81%|########1 |140521/173481[45:12<11:08,49.27it/s] 86%|########6 |149443/173481[48:00<07:50,51.14it/s] 87%|########6 |150090/173481[48:12<07:37,51.14it/s] 91%|#########1|158155/173481[51:00<05:08,49.73it/s] 92%|#########1|158766/173481[51:12<04:55,49.73it/s] 96%|#########6|167217/173481[54:00<02:05,50.03it/s] 97%|#########6|167832/173481[54:12<01:52,50.03it/s][32m[0321 04:23:02 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:3359.77 sec.
100%|##########|173481/173481[55:59<00:00,51.63it/s]
[32m[0321 04:23:03 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-3296139.
[32m[0321 04:23:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:33<00:00,201.68it/s]
18
[32m[0321 04:24:38 @monitor.py:363][0m QueueInput/queue_size: 0.59366
[32m[0321 04:24:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 77.759
[32m[0321 04:24:38 @monitor.py:363][0m activation-summaries/output-rms: 0.049325
[32m[0321 04:24:38 @monitor.py:363][0m cross_entropy_loss: 1.0656
[32m[0321 04:24:38 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68143
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1138
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29087
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26915
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19394
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19041
[32m[0321 04:24:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 04:24:38 @monitor.py:363][0m train-error-top1: 0.28792
[32m[0321 04:24:38 @monitor.py:363][0m val-error-top1: 0.30655
[32m[0321 04:24:38 @monitor.py:363][0m val-utt-error: 0.036234
[32m[0321 04:24:38 @monitor.py:363][0m validation_cost: 1.1077
[32m[0321 04:24:38 @monitor.py:363][0m wd_cost: 0.00089269
[32m[0321 04:24:38 @group.py:42][0m Callbacks took 96.630 sec in total. InferenceRunner: 93.336sec
[32m[0321 04:24:38 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9298/173481[03:00<52:59,51.64it/s]  6%|5         |9771/173481[03:10<52:50,51.64it/s] 10%|#         |17488/173481[06:00<53:44,48.38it/s] 10%|#         |17961/173481[06:10<53:34,48.38it/s] 15%|#4        |25817/173481[09:00<52:01,47.30it/s] 15%|#5        |26313/173481[09:10<51:51,47.30it/s] 20%|#9        |34272/173481[12:00<49:13,47.13it/s] 20%|##        |34767/173481[12:10<49:02,47.13it/s] 25%|##4       |42778/173481[15:00<46:09,47.19it/s] 25%|##4       |43293/173481[15:10<45:58,47.19it/s] 30%|##9       |51508/173481[18:00<42:29,47.83it/s] 30%|###       |52071/173481[18:10<42:18,47.83it/s] 35%|###4      |60320/173481[21:00<38:58,48.39it/s] 35%|###5      |60867/173481[21:11<38:47,48.39it/s] 40%|###9      |69046/173481[24:00<35:56,48.43it/s] 40%|####      |69603/173481[24:11<35:45,48.43it/s] 45%|####4     |78012/173481[27:00<32:24,49.11it/s] 45%|####5     |78695/173481[27:11<32:10,49.11it/s] 51%|#####     |87808/173481[30:00<27:39,51.63it/s] 51%|#####     |88425/173481[30:11<27:27,51.63it/s] 56%|#####5    |96874/173481[33:00<25:02,50.98it/s] 56%|#####6    |97437/173481[33:11<24:51,50.98it/s] 61%|######1   |105906/173481[36:00<22:16,50.58it/s] 61%|######1   |106491/173481[36:11<22:04,50.58it/s] 66%|######6   |114558/173481[39:00<19:55,49.29it/s] 66%|######6   |115137/173481[39:12<19:43,49.29it/s] 71%|#######1  |123838/173481[42:00<16:25,50.39it/s] 72%|#######1  |124486/173481[42:12<16:12,50.39it/s] 77%|#######6  |133505/173481[45:00<12:48,52.00it/s] 77%|#######7  |134137/173481[45:12<12:36,52.00it/s] 83%|########2 |143416/173481[48:00<09:22,53.48it/s] 83%|########3 |144153/173481[48:12<09:08,53.48it/s] 89%|########8 |154167/173481[51:00<05:42,56.43it/s] 89%|########9 |154893/173481[51:12<05:29,56.43it/s] 95%|#########4|164098/173481[54:00<02:48,55.79it/s] 95%|#########4|164794/173481[54:12<02:35,55.79it/s]100%|##########|173481/173481[56:55<00:00,50.79it/s]
[32m[0321 05:21:34 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:3415.90 sec.
[32m[0321 05:21:35 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-3469620.
[32m[0321 05:21:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,198.26it/s]
19
[32m[0321 05:23:11 @monitor.py:363][0m QueueInput/queue_size: 0.72521
[32m[0321 05:23:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 79.104
[32m[0321 05:23:11 @monitor.py:363][0m activation-summaries/output-rms: 0.049311
[32m[0321 05:23:11 @monitor.py:363][0m cross_entropy_loss: 0.9904
[32m[0321 05:23:11 @monitor.py:363][0m lr: 7.8125e-06
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6866
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1138
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2917
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26938
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19403
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.1905
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 05:23:11 @monitor.py:363][0m train-error-top1: 0.27178
[32m[0321 05:23:11 @monitor.py:363][0m val-error-top1: 0.30566
[32m[0321 05:23:11 @monitor.py:363][0m val-utt-error: 0.036978
[32m[0321 05:23:11 @monitor.py:363][0m validation_cost: 1.1063
[32m[0321 05:23:11 @monitor.py:363][0m wd_cost: 0.00018008
[32m[0321 05:23:11 @group.py:42][0m Callbacks took 97.052 sec in total. InferenceRunner: 94.949sec
[32m[0321 05:23:11 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11290/173481[03:00<43:05,62.72it/s]  7%|6         |12116/173481[03:10<42:52,62.72it/s] 13%|#3        |22969/173481[06:00<39:19,63.78it/s] 14%|#3        |23544/173481[06:10<39:10,63.78it/s] 19%|#8        |32797/173481[09:00<39:51,58.82it/s] 19%|#9        |33336/173481[09:10<39:42,58.82it/s] 24%|##4       |42313/173481[12:00<39:16,55.67it/s] 25%|##4       |42888/173481[12:10<39:05,55.67it/s] 30%|##9       |52038/173481[15:00<36:54,54.84it/s] 30%|###       |52620/173481[15:10<36:44,54.84it/s] 36%|###5      |61867/173481[18:00<33:59,54.72it/s] 36%|###5      |62438/173481[18:10<33:49,54.72it/s] 41%|####1     |71809/173481[21:00<30:49,54.97it/s] 42%|####1     |72403/173481[21:11<30:38,54.97it/s] 47%|####7     |82048/173481[24:00<27:15,55.91it/s] 48%|####7     |82652/173481[24:11<27:04,55.91it/s] 53%|#####3    |92119/173481[27:00<24:14,55.92it/s] 53%|#####3    |92752/173481[27:11<24:03,55.92it/s] 59%|#####8    |101743/173481[30:00<21:52,54.65it/s] 59%|#####8    |102312/173481[30:11<21:42,54.65it/s] 64%|######4   |111152/173481[33:00<19:26,53.44it/s] 64%|######4   |111813/173481[33:11<19:14,53.44it/s] 70%|######9   |120658/173481[36:00<16:34,53.12it/s] 70%|######9   |121242/173481[36:11<16:23,53.12it/s] 75%|#######4  |130069/173481[39:00<13:43,52.70it/s] 75%|#######5  |130674/173481[39:12<13:32,52.70it/s] 80%|########  |139610/173481[42:00<10:40,52.85it/s] 81%|########  |140216/173481[42:12<10:29,52.85it/s] 86%|########6 |149233/173481[45:00<07:36,53.15it/s] 86%|########6 |149889/173481[45:12<07:23,53.15it/s] 92%|#########1|158971/173481[48:00<04:30,53.61it/s] 92%|#########1|159516/173481[48:12<04:20,53.61it/s] 97%|#########7|168739/173481[51:00<01:27,53.93it/s] 98%|#########7|169416/173481[51:12<01:15,53.93it/s]100%|##########|173481/173481[52:27<00:00,55.12it/s]
[32m[0321 06:15:38 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:3147.06 sec.
[32m[0321 06:15:39 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-3643101.
[32m[0321 06:15:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:28<00:00,212.10it/s]
20
[32m[0321 06:17:09 @monitor.py:363][0m QueueInput/queue_size: 0.60821
[32m[0321 06:17:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 79.504
[32m[0321 06:17:09 @monitor.py:363][0m activation-summaries/output-rms: 0.049622
[32m[0321 06:17:09 @monitor.py:363][0m cross_entropy_loss: 1.0261
[32m[0321 06:17:09 @monitor.py:363][0m lr: 7.8125e-06
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6915
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1136
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29246
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26958
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.1941
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19059
[32m[0321 06:17:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 06:17:09 @monitor.py:363][0m train-error-top1: 0.28664
[32m[0321 06:17:09 @monitor.py:363][0m val-error-top1: 0.30409
[32m[0321 06:17:09 @monitor.py:363][0m val-utt-error: 0.034747
[32m[0321 06:17:09 @monitor.py:363][0m validation_cost: 1.1
[32m[0321 06:17:09 @monitor.py:363][0m wd_cost: 0.00018153
[32m[0321 06:17:09 @group.py:42][0m Callbacks took 91.078 sec in total. InferenceRunner: 88.751sec
[32m[0321 06:17:09 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10558/173481[03:00<46:17,58.65it/s]  6%|6         |11079/173481[03:10<46:08,58.65it/s] 11%|#1        |19493/173481[06:00<47:43,53.77it/s] 12%|#1        |20073/173481[06:10<47:33,53.77it/s] 17%|#6        |29470/173481[09:00<43:58,54.58it/s] 17%|#7        |30051/173481[09:10<43:48,54.58it/s] 23%|##2       |39697/173481[12:00<40:03,55.67it/s] 23%|##3       |40264/173481[12:10<39:52,55.67it/s] 29%|##8       |49494/173481[15:00<37:32,55.04it/s] 29%|##8       |50067/173481[15:10<37:22,55.04it/s] 34%|###4      |59578/173481[18:00<34:11,55.53it/s] 35%|###4      |60207/173481[18:10<33:59,55.53it/s] 40%|####      |69676/173481[21:00<31:00,55.80it/s] 41%|####      |70281/173481[21:11<30:49,55.80it/s] 46%|####5     |79678/173481[24:00<28:04,55.68it/s] 46%|####6     |80313/173481[24:11<27:53,55.68it/s] 52%|#####1    |89926/173481[27:00<24:44,56.28it/s] 52%|#####2    |90507/173481[27:11<24:34,56.28it/s] 58%|#####7    |100246/173481[30:00<21:29,56.80it/s] 58%|#####8    |100863/173481[30:11<21:18,56.80it/s] 64%|######3   |110408/173481[33:00<18:33,56.63it/s] 64%|######4   |111057/173481[33:11<18:22,56.63it/s] 69%|######9   |120472/173481[36:00<15:42,56.26it/s] 70%|######9   |121132/173481[36:11<15:30,56.26it/s] 75%|#######5  |130222/173481[39:00<13:03,55.19it/s] 75%|#######5  |130881/173481[39:11<12:51,55.19it/s] 81%|########  |139778/173481[42:00<10:22,54.12it/s] 81%|########  |140433/173481[42:12<10:10,54.12it/s] 86%|########6 |149930/173481[45:00<07:06,55.24it/s] 87%|########6 |150597/173481[45:12<06:54,55.24it/s] 92%|#########2|160226/173481[48:00<03:55,56.20it/s] 93%|#########2|160917/173481[48:12<03:43,56.20it/s] 98%|#########8|170336/173481[51:00<00:55,56.18it/s] 99%|#########8|171006/173481[51:12<00:44,56.18it/s]100%|##########|173481/173481[51:57<00:00,55.65it/s]
[32m[0321 07:09:06 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:3117.13 sec.
[32m[0321 07:09:07 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-3816582.
[32m[0321 07:09:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:26<00:00,218.40it/s]
21
[32m[0321 07:10:35 @monitor.py:363][0m QueueInput/queue_size: 0.72158
[32m[0321 07:10:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 80.349
[32m[0321 07:10:35 @monitor.py:363][0m activation-summaries/output-rms: 0.048187
[32m[0321 07:10:35 @monitor.py:363][0m cross_entropy_loss: 1.0458
[32m[0321 07:10:35 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6959
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1139
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29313
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26977
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19417
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19065
[32m[0321 07:10:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 07:10:35 @monitor.py:363][0m train-error-top1: 0.28159
[32m[0321 07:10:35 @monitor.py:363][0m val-error-top1: 0.30388
[32m[0321 07:10:35 @monitor.py:363][0m val-utt-error: 0.035969
[32m[0321 07:10:35 @monitor.py:363][0m validation_cost: 1.0978
[32m[0321 07:10:35 @monitor.py:363][0m wd_cost: 0.00018284
[32m[0321 07:10:35 @group.py:42][0m Callbacks took 88.487 sec in total. InferenceRunner: 86.200sec
[32m[0321 07:10:35 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11292/173481[03:00<43:05,62.73it/s]  7%|6         |11862/173481[03:10<42:56,62.73it/s] 12%|#2        |21547/173481[06:00<42:24,59.71it/s] 13%|#2        |22147/173481[06:10<42:14,59.71it/s] 18%|#8        |31783/173481[09:00<40:32,58.25it/s] 19%|#8        |32384/173481[09:10<40:22,58.25it/s] 24%|##4       |42043/173481[12:00<38:01,57.61it/s] 25%|##4       |42655/173481[12:10<37:50,57.61it/s] 30%|###       |52357/173481[15:00<35:08,57.45it/s] 31%|###       |52980/173481[15:10<34:57,57.45it/s] 36%|###6      |62733/173481[18:00<32:04,57.55it/s] 36%|###6      |63318/173481[18:10<31:54,57.55it/s] 42%|####1     |72794/173481[21:00<29:35,56.71it/s] 42%|####2     |73404/173481[21:11<29:24,56.71it/s] 48%|####7     |82957/173481[24:00<26:39,56.58it/s] 48%|####8     |83556/173481[24:11<26:29,56.58it/s] 54%|#####3    |93235/173481[27:00<23:32,56.83it/s] 54%|#####4    |93834/173481[27:11<23:21,56.83it/s] 60%|#####9    |103413/173481[30:00<20:36,56.68it/s] 60%|#####9    |104034/173481[30:11<20:25,56.68it/s] 66%|######5   |113653/173481[33:00<17:33,56.78it/s] 66%|######5   |114294/173481[33:11<17:22,56.78it/s] 71%|#######1  |123943/173481[36:00<14:29,56.97it/s] 72%|#######1  |124598/173481[36:11<14:18,56.97it/s] 77%|#######7  |133933/173481[39:00<11:43,56.21it/s] 78%|#######7  |134522/173481[39:11<11:33,56.21it/s] 83%|########2 |143665/173481[42:00<09:00,55.11it/s] 83%|########3 |144276/173481[42:12<08:49,55.11it/s] 88%|########8 |153301/173481[45:00<06:11,54.31it/s] 89%|########8 |153995/173481[45:12<05:58,54.31it/s] 94%|#########4|163448/173481[48:00<03:01,55.32it/s] 95%|#########4|164110/173481[48:12<02:49,55.32it/s]100%|#########9|173269/173481[51:00<00:03,54.94it/s]100%|##########|173481/173481[51:04<00:00,56.62it/s]
[32m[0321 08:01:39 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:3064.03 sec.
[32m[0321 08:01:40 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-3990063.
[32m[0321 08:01:41 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:24<00:00,222.68it/s]
22
[32m[0321 08:03:05 @monitor.py:363][0m QueueInput/queue_size: 0.76945
[32m[0321 08:03:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 81.436
[32m[0321 08:03:05 @monitor.py:363][0m activation-summaries/output-rms: 0.048598
[32m[0321 08:03:05 @monitor.py:363][0m cross_entropy_loss: 1.0659
[32m[0321 08:03:05 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.69841
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1139
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29348
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26985
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.1942
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19068
[32m[0321 08:03:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 08:03:05 @monitor.py:363][0m train-error-top1: 0.29835
[32m[0321 08:03:05 @monitor.py:363][0m val-error-top1: 0.30373
[32m[0321 08:03:05 @monitor.py:363][0m val-utt-error: 0.034375
[32m[0321 08:03:05 @monitor.py:363][0m validation_cost: 1.0973
[32m[0321 08:03:05 @monitor.py:363][0m wd_cost: 3.6713e-05
[32m[0321 08:03:05 @group.py:42][0m Callbacks took 86.386 sec in total. InferenceRunner: 84.537sec
[32m[0321 08:03:05 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11206/173481[03:00<43:26,62.25it/s]  7%|6         |11823/173481[03:10<43:16,62.25it/s] 13%|#2        |21850/173481[06:00<41:40,60.65it/s] 13%|#2        |22479/173481[06:10<41:29,60.65it/s] 19%|#8        |32344/173481[09:00<39:34,59.44it/s] 19%|#8        |32913/173481[09:10<39:24,59.44it/s] 25%|##4       |42550/173481[12:00<37:36,58.04it/s] 25%|##4       |43138/173481[12:10<37:25,58.04it/s] 30%|###       |52702/173481[15:00<35:11,57.20it/s] 31%|###       |53283/173481[15:10<35:01,57.20it/s] 36%|###6      |62778/173481[18:00<32:36,56.58it/s] 37%|###6      |63393/173481[18:10<32:25,56.58it/s] 42%|####1     |72856/173481[21:00<29:47,56.28it/s] 42%|####2     |73474/173481[21:11<29:36,56.28it/s] 48%|####7     |82867/173481[24:00<26:59,55.95it/s] 48%|####8     |83505/173481[24:11<26:48,55.95it/s] 52%|#####2    |90565/173481[27:00<28:30,48.48it/s] 53%|#####2    |91191/173481[27:11<28:17,48.48it/s] 58%|#####8    |100870/173481[30:00<23:03,52.50it/s] 59%|#####8    |101511/173481[30:11<22:50,52.50it/s] 64%|######3   |111004/173481[33:00<19:10,54.32it/s] 64%|######4   |111647/173481[33:11<18:58,54.32it/s] 70%|######9   |121072/173481[36:00<15:51,55.11it/s] 70%|#######   |121719/173481[36:11<15:39,55.11it/s] 76%|#######5  |131293/173481[39:00<12:34,55.93it/s] 76%|#######6  |131955/173481[39:11<12:22,55.93it/s] 82%|########1 |141616/173481[42:00<09:22,56.63it/s] 82%|########2 |142299/173481[42:12<09:10,56.63it/s] 88%|########7 |151966/173481[45:00<06:17,57.05it/s] 88%|########7 |152647/173481[45:12<06:05,57.05it/s] 93%|#########3|162178/173481[48:00<03:18,56.88it/s] 94%|#########3|162856/173481[48:12<03:06,56.88it/s] 99%|#########9|172332/173481[51:00<00:20,56.65it/s]100%|#########9|173007/173481[51:12<00:08,56.65it/s]100%|##########|173481/173481[51:20<00:00,56.31it/s]
[32m[0321 08:54:26 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:3080.70 sec.
[32m[0321 08:54:27 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_32_quant_ends_False/model-4163544.
[32m[0321 08:54:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,169.79it/s]
23
[32m[0321 08:56:19 @monitor.py:363][0m QueueInput/queue_size: 0.80496
[32m[0321 08:56:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 81.747
[32m[0321 08:56:19 @monitor.py:363][0m activation-summaries/output-rms: 0.049452
[32m[0321 08:56:19 @monitor.py:363][0m cross_entropy_loss: 1.0095
[32m[0321 08:56:19 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.70091
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.114
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29382
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063424
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26993
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064565
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19423
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065056
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19071
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061792
[32m[0321 08:56:19 @monitor.py:363][0m train-error-top1: 0.28267
[32m[0321 08:56:19 @monitor.py:363][0m val-error-top1: 0.30376
[32m[0321 08:56:19 @monitor.py:363][0m val-utt-error: 0.035012
[32m[0321 08:56:19 @monitor.py:363][0m validation_cost: 1.0963
[32m[0321 08:56:19 @monitor.py:363][0m wd_cost: 3.6859e-05
[32m[0321 08:56:19 @group.py:42][0m Callbacks took 113.267 sec in total. InferenceRunner: 110.865sec
[32m[0321 08:56:19 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11245/173481[03:00<43:17,62.46it/s]  7%|6         |11845/173481[03:10<43:07,62.46it/s] 12%|#2        |21541/173481[06:00<42:24,59.71it/s] 13%|#2        |22122/173481[06:10<42:14,59.71it/s] 18%|#8        |32080/173481[09:00<39:51,59.12it/s] 19%|#8        |32712/173481[09:10<39:40,59.12it/s] 24%|##4       |42439/173481[12:00<37:26,58.32it/s] 25%|##4       |43046/173481[12:10<37:16,58.32it/s] 31%|###       |53170/173481[15:00<34:00,58.96it/s] 31%|###1      |53844/173481[15:10<33:49,58.96it/s] 38%|###7      |65509/173481[18:00<28:23,63.40it/s] 38%|###8      |66160/173481[18:10<28:12,63.40it/s] 45%|####4     |77671/173481[21:00<24:24,65.41it/s] 45%|####5     |78426/173481[21:11<24:13,65.41it/s] 52%|#####1    |89912/173481[24:00<20:53,66.68it/s] 52%|#####2    |90654/173481[24:11<20:42,66.68it/s] 59%|#####9    |102595/173481[27:00<17:14,68.52it/s] 60%|#####9    |103338/173481[27:11<17:03,68.52it/s] 66%|######6   |115310/173481[30:00<13:56,69.56it/s] 67%|######6   |116190/173481[30:11<13:43,69.56it/s]slurmstepd: *** STEP 70364.0 ON sls-sm-11 CANCELLED AT 2018-03-21T09:28:48 ***
slurmstepd: *** JOB 70364 ON sls-sm-11 CANCELLED AT 2018-03-21T09:28:48 ***
