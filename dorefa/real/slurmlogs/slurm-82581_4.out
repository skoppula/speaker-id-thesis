sls-sm-16 3
SLURM_JOBID=82585
SLURM_TASKID=4
[32m[0323 10:45:59 @logger.py:67][0m Existing log file 'train_log/lcn_w_16_a_32_quant_ends_False/log.log' backuped to 'train_log/lcn_w_16_a_32_quant_ends_False/log.log.0323-104559'
[32m[0323 10:45:59 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=16 --bita=32 --quant_ends=False
[32m[0323 10:46:18 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 10:46:18 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 10:46:18 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 10:46:18 @drf_run.py:166][0m Using host: sls-sm-16
[32m[0323 10:46:18 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 10:46:18 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 10:46:18 @drf_run.py:188][0m Using GPU: 3
[32m[0323 10:46:18 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 10:46:18 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 10:46:18 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 10:46:18 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:19 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:19 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 10:46:19 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:19 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0323 10:46:19 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 10:46:19 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0323 10:46:20 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0323 10:46:20 @base.py:196][0m Setup callbacks graph ...
[32m[0323 10:46:21 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:21 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:21 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:21 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0323 10:46:21 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 10:46:21 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0323 10:46:22 @base.py:212][0m Creating the session ...
2018-03-23 10:46:22.722510: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-23 10:46:26.188710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:82:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-03-23 10:46:26.188755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:82:00.0, compute capability: 6.1)
[32m[0323 10:46:31 @base.py:220][0m Initializing the session ...
[32m[0323 10:46:31 @base.py:227][0m Graph Finalized.
[32m[0323 10:46:31 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 10:46:34 @monitor.py:251][0m Found existing JSON at train_log/lcn_w_16_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 10:46:34 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 10:46:34 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11797/173481[03:00<41:07,65.54it/s]  7%|7         |12480/173481[03:10<40:56,65.54it/s] 14%|#3        |23526/173481[06:00<38:14,65.34it/s] 14%|#3        |24156/173481[06:10<38:05,65.34it/s] 20%|#9        |34461/173481[09:00<36:48,62.96it/s] 20%|##        |35096/173481[09:10<36:37,62.96it/s] 26%|##6       |45382/173481[12:00<34:32,61.79it/s] 26%|##6       |45895/173481[12:10<34:24,61.79it/s] 32%|###2      |55851/173481[15:00<32:43,59.92it/s] 33%|###2      |56482/173481[15:10<32:32,59.92it/s] 38%|###7      |65179/173481[18:00<32:28,55.58it/s] 38%|###7      |65790/173481[18:10<32:17,55.58it/s] 43%|####3     |75216/173481[21:00<29:25,55.66it/s] 44%|####3     |75839/173481[21:11<29:14,55.66it/s] 49%|####9     |85452/173481[24:00<26:04,56.25it/s] 50%|####9     |86075/173481[24:11<25:53,56.25it/s] 55%|#####4    |94606/173481[27:00<24:36,53.42it/s] 55%|#####4    |95230/173481[27:11<24:24,53.42it/s] 61%|######    |105297/173481[30:00<20:12,56.25it/s] 61%|######1   |105995/173481[30:11<19:59,56.25it/s] 67%|######7   |116702/173481[33:00<15:52,59.59it/s] 68%|######7   |117419/173481[33:11<15:40,59.59it/s] 73%|#######3  |127246/173481[36:00<13:02,59.08it/s] 74%|#######3  |128118/173481[36:11<12:47,59.08it/s] 81%|########  |139771/173481[39:00<08:47,63.90it/s] 81%|########  |140488/173481[39:11<08:36,63.90it/s] 87%|########6 |150876/173481[42:00<06:00,62.77it/s] 87%|########7 |151592/173481[42:12<05:48,62.77it/s] 93%|#########2|161284/173481[45:00<03:22,60.20it/s] 93%|#########3|161890/173481[45:12<03:12,60.20it/s] 99%|#########8|171322/173481[48:00<00:37,57.90it/s] 99%|#########9|172245/173481[48:12<00:21,57.90it/s]100%|##########|173481/173481[48:29<00:00,59.63it/s]
[32m[0323 11:35:04 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2909.35 sec.
[32m[0323 11:35:04 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:22<00:00,131.85it/s]
0
[32m[0323 11:37:27 @monitor.py:363][0m QueueInput/queue_size: 1.5242
[32m[0323 11:37:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8679
[32m[0323 11:37:27 @monitor.py:363][0m activation-summaries/output-rms: 0.029997
[32m[0323 11:37:27 @monitor.py:363][0m cross_entropy_loss: 2.5233
[32m[0323 11:37:27 @monitor.py:363][0m lr: 0.001
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.18809
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 2.8337e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.15512
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 2.8985e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.18124
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 2.3507e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.14888
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 2.9097e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.18024
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 2.5727e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14969
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 2.1255e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.17993
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 3.3229e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14935
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 2.95e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.19315
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.6792e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.15231
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 2.8218e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13654
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.65855
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14484
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089453
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12233
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.1167
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0323 11:37:27 @monitor.py:363][0m train-error-top1: 0.61898
[32m[0323 11:37:27 @monitor.py:363][0m val-error-top1: 0.674
[32m[0323 11:37:27 @monitor.py:363][0m val-utt-error: 0.34688
[32m[0323 11:37:27 @monitor.py:363][0m validation_cost: 2.7647
[32m[0323 11:37:27 @monitor.py:363][0m wd_cost: 0.51449
[32m[0323 11:37:27 @group.py:42][0m Callbacks took 143.199 sec in total. InferenceRunner: 142.772sec
[32m[0323 11:37:27 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14180/173481[03:00<33:42,78.78it/s]  9%|8         |14982/173481[03:10<33:31,78.78it/s] 16%|#5        |27390/173481[06:00<32:04,75.92it/s] 16%|#6        |28215/173481[06:20<31:53,75.92it/s] 22%|##1       |38161/173481[09:00<33:41,66.92it/s] 22%|##2       |38779/173481[09:10<33:32,66.92it/s] 28%|##8       |49104/173481[12:00<32:32,63.71it/s] 29%|##8       |49727/173481[12:10<32:22,63.71it/s] 35%|###4      |60480/173481[15:00<29:40,63.45it/s] 35%|###5      |61137/173481[15:10<29:30,63.45it/s] 41%|####1     |71374/173481[18:00<27:28,61.95it/s] 42%|####1     |72042/173481[18:10<27:17,61.95it/s] 48%|####7     |82500/173481[21:00<24:30,61.87it/s] 48%|####7     |83177/173481[21:11<24:19,61.87it/s] 54%|#####4    |93754/173481[24:00<21:21,62.20it/s] 54%|#####4    |94450/173481[24:11<21:10,62.20it/s] 60%|######    |104642/173481[27:00<18:42,61.33it/s] 61%|######    |105504/173481[27:11<18:28,61.33it/s] 67%|######6   |116088/173481[30:00<15:19,62.44it/s] 67%|######7   |116771/173481[30:11<15:08,62.44it/s] 73%|#######3  |126942/173481[33:00<12:38,61.35it/s] 74%|#######3  |127634/173481[33:11<12:27,61.35it/s] 79%|#######8  |136465/173481[36:00<10:51,56.81it/s] 79%|#######9  |137386/173481[36:11<10:35,56.81it/s] 85%|########5 |147805/173481[39:00<07:09,59.74it/s] 86%|########5 |148483/173481[39:12<06:58,59.74it/s] 91%|#########1|158618/173481[42:00<04:08,59.90it/s] 92%|#########1|159351/173481[42:12<03:55,59.90it/s] 98%|#########7|169892/173481[45:00<00:58,61.24it/s] 98%|#########8|170649/173481[45:12<00:46,61.24it/s]100%|##########|173481/173481[46:06<00:00,62.70it/s]
[32m[0323 12:23:34 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2766.96 sec.
[32m[0323 12:23:35 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-346962.
[32m[0323 12:23:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:22<00:00,132.11it/s]
1
[32m[0323 12:25:57 @monitor.py:363][0m QueueInput/queue_size: 2.0585
[32m[0323 12:25:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.0253
[32m[0323 12:25:57 @monitor.py:363][0m activation-summaries/output-rms: 0.030413
[32m[0323 12:25:57 @monitor.py:363][0m cross_entropy_loss: 2.5046
[32m[0323 12:25:57 @monitor.py:363][0m lr: 0.001
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.19136
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 3.9831e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.15571
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.2853e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.18039
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 5.494e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.14921
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 2.9512e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.18143
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.9568e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14963
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.2154e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.18037
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4314e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.15014
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5496e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.19116
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 7.0375e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.15173
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.5454e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13727
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.91936
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14536
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089453
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12164
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11649
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0323 12:25:57 @monitor.py:363][0m train-error-top1: 0.63276
[32m[0323 12:25:57 @monitor.py:363][0m val-error-top1: 0.66695
[32m[0323 12:25:57 @monitor.py:363][0m val-utt-error: 0.33471
[32m[0323 12:25:57 @monitor.py:363][0m validation_cost: 2.7299
[32m[0323 12:25:57 @monitor.py:363][0m wd_cost: 0.51549
[32m[0323 12:25:57 @group.py:42][0m Callbacks took 143.517 sec in total. InferenceRunner: 142.481sec
[32m[0323 12:25:57 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15203/173481[03:00<31:14,84.46it/s]  9%|9         |16045/173481[03:10<31:04,84.46it/s] 17%|#6        |29321/173481[06:00<29:32,81.33it/s] 17%|#7        |29918/173481[06:10<29:25,81.33it/s] 23%|##2       |39521/173481[09:00<33:25,66.80it/s] 23%|##3       |40141/173481[09:10<33:16,66.80it/s] 29%|##8       |49869/173481[12:00<33:20,61.78it/s] 29%|##9       |50496/173481[12:10<33:10,61.78it/s] 35%|###4      |60357/173481[15:00<31:26,59.97it/s] 35%|###5      |60988/173481[15:10<31:15,59.97it/s] 41%|####1     |71533/173481[18:00<27:50,61.01it/s] 42%|####1     |72223/173481[18:10<27:39,61.01it/s] 48%|####7     |83147/173481[21:00<24:00,62.72it/s] 48%|####8     |83840/173481[21:11<23:49,62.72it/s] 55%|#####4    |94679/173481[24:00<20:43,63.38it/s] 55%|#####4    |95388/173481[24:11<20:32,63.38it/s] 61%|######    |105489/173481[27:00<18:22,61.67it/s] 61%|######1   |106394/173481[27:11<18:07,61.67it/s] 68%|######7   |117562/173481[30:00<14:30,64.26it/s] 68%|######8   |118299/173481[30:11<14:18,64.26it/s] 74%|#######4  |128969/173481[33:00<11:37,63.81it/s] 75%|#######4  |129736/173481[33:11<11:25,63.81it/s] 81%|########1 |140857/173481[36:00<08:22,64.91it/s] 81%|########1 |141323/173481[36:11<08:15,64.91it/s] 88%|########8 |152750/173481[39:00<05:16,65.48it/s] 89%|########8 |153563/173481[39:12<05:04,65.48it/s] 95%|#########5|164811/173481[42:00<02:10,66.23it/s] 95%|#########5|165603/173481[42:12<01:58,66.23it/s]100%|##########|173481/173481[44:12<00:00,65.41it/s]
[32m[0323 13:10:10 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2652.11 sec.
[32m[0323 13:10:10 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-520443.
[32m[0323 13:10:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:41<00:00,116.66it/s]
2
[32m[0323 13:12:51 @monitor.py:363][0m QueueInput/queue_size: 0.53846
[32m[0323 13:12:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.929
[32m[0323 13:12:51 @monitor.py:363][0m activation-summaries/output-rms: 0.035222
[32m[0323 13:12:51 @monitor.py:363][0m cross_entropy_loss: 2.0634
[32m[0323 13:12:51 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.25699
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.6425e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.20619
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.5663e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.24252
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.1736e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.1992
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.0424e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.2448
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.0754e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.19916
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.2518e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.2454
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.3201e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.19902
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.469e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.26019
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.0515e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.1992
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.2216e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.18685
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0571
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.19061
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089453
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.16822
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16386
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091888
[32m[0323 13:12:51 @monitor.py:363][0m train-error-top1: 0.5342
[32m[0323 13:12:51 @monitor.py:363][0m val-error-top1: 0.5615
[32m[0323 13:12:51 @monitor.py:363][0m val-utt-error: 0.20173
[32m[0323 13:12:51 @monitor.py:363][0m validation_cost: 2.1904
[32m[0323 13:12:51 @monitor.py:363][0m wd_cost: 0.19003
[32m[0323 13:12:51 @group.py:42][0m Callbacks took 161.875 sec in total. InferenceRunner: 161.354sec
[32m[0323 13:12:51 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14501/173481[03:00<32:53,80.56it/s]  9%|8         |15295/173481[03:10<32:43,80.56it/s] 16%|#5        |27425/173481[06:00<32:03,75.93it/s] 16%|#6        |28087/173481[06:10<31:54,75.93it/s] 23%|##2       |39063/173481[09:00<32:06,69.79it/s] 23%|##2       |39172/173481[09:10<32:04,69.79it/s] 30%|##9       |51376/173481[12:00<29:27,69.09it/s] 30%|##9       |52033/173481[12:10<29:17,69.09it/s] 36%|###6      |63278/173481[15:00<27:11,67.57it/s] 37%|###6      |64002/173481[15:10<27:00,67.57it/s] 44%|####3     |75510/173481[18:00<24:05,67.76it/s] 44%|####3     |76212/173481[18:10<23:55,67.76it/s] 50%|#####     |87370/173481[21:00<21:28,66.81it/s] 51%|#####     |88068/173481[21:11<21:18,66.81it/s] 57%|#####7    |99288/173481[24:00<18:35,66.50it/s] 58%|#####7    |99993/173481[24:11<18:25,66.50it/s] 64%|######4   |111398/173481[27:00<15:28,66.88it/s] 65%|######4   |112147/173481[27:11<15:17,66.88it/s] 71%|#######   |122775/173481[30:00<13:00,64.99it/s] 71%|#######1  |123583/173481[30:11<12:47,64.99it/s] 78%|#######7  |135200/173481[33:00<09:31,66.95it/s] 78%|#######8  |135980/173481[33:11<09:20,66.95it/s] 85%|########4 |147146/173481[36:00<06:35,66.66it/s] 85%|########5 |147895/173481[36:11<06:23,66.66it/s] 91%|######### |157609/173481[39:00<04:15,62.10it/s] 91%|#########1|158499/173481[39:12<04:01,62.10it/s] 98%|#########7|169743/173481[42:00<00:57,64.64it/s] 98%|#########8|170437/173481[42:12<00:47,64.64it/s]100%|##########|173481/173481[43:01<00:00,67.21it/s]
[32m[0323 13:55:53 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2581.32 sec.
[32m[0323 13:55:53 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-693924.
[32m[0323 13:55:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,139.51it/s]
3
[32m[0323 13:58:08 @monitor.py:363][0m QueueInput/queue_size: 0.76249
[32m[0323 13:58:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.4027
[32m[0323 13:58:08 @monitor.py:363][0m activation-summaries/output-rms: 0.035602
[32m[0323 13:58:08 @monitor.py:363][0m cross_entropy_loss: 2.0072
[32m[0323 13:58:08 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.28195
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 8.488e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.22409
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8218e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.26449
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.7805e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.21899
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1331e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.26784
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 3.6291e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.21833
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.0951e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.26777
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.449e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21799
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.5627e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.28267
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.9953e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.21958
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.9277e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21739
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1147
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2091
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089453
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19267
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.1845
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091888
[32m[0323 13:58:08 @monitor.py:363][0m train-error-top1: 0.52428
[32m[0323 13:58:08 @monitor.py:363][0m val-error-top1: 0.54324
[32m[0323 13:58:08 @monitor.py:363][0m val-utt-error: 0.18664
[32m[0323 13:58:08 @monitor.py:363][0m validation_cost: 2.111
[32m[0323 13:58:08 @monitor.py:363][0m wd_cost: 0.24165
[32m[0323 13:58:08 @group.py:42][0m Callbacks took 135.516 sec in total. InferenceRunner: 134.930sec
[32m[0323 13:58:08 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13939/173481[03:00<34:20,77.44it/s]  8%|8         |14581/173481[03:10<34:12,77.44it/s] 15%|#4        |25425/173481[06:00<35:16,69.96it/s] 15%|#5        |26086/173481[06:10<35:06,69.96it/s] 22%|##1       |37368/173481[09:00<33:18,68.11it/s] 22%|##1       |38013/173481[09:10<33:09,68.11it/s] 28%|##8       |49131/173481[12:00<31:04,66.70it/s] 29%|##8       |49819/173481[12:10<30:54,66.70it/s] 35%|###5      |60892/173481[15:00<28:25,66.01it/s] 36%|###5      |61652/173481[15:10<28:14,66.01it/s] 42%|####1     |72087/173481[18:00<26:23,64.04it/s] 42%|####1     |72806/173481[18:10<26:12,64.04it/s] 48%|####8     |83882/173481[21:00<23:03,64.78it/s] 49%|####8     |84556/173481[21:11<22:52,64.78it/s] 55%|#####4    |94874/173481[24:00<20:50,62.87it/s] 55%|#####5    |95726/173481[24:11<20:36,62.87it/s] 62%|######1   |107012/173481[27:00<17:01,65.07it/s] 62%|######2   |107736/173481[27:11<16:50,65.07it/s] 68%|######8   |118622/173481[30:00<14:06,64.77it/s] 69%|######8   |119306/173481[30:11<13:56,64.77it/s] 74%|#######4  |129207/173481[33:00<11:58,61.62it/s] 75%|#######4  |129859/173481[33:11<11:47,61.62it/s] 82%|########1 |141802/173481[36:00<08:03,65.52it/s] 82%|########2 |142551/173481[36:11<07:52,65.52it/s] 89%|########8 |153650/173481[39:00<05:01,65.67it/s] 89%|########8 |154389/173481[39:12<04:50,65.67it/s] 95%|#########5|164987/173481[42:00<02:12,64.30it/s] 96%|#########5|165717/173481[42:12<02:00,64.30it/s]100%|##########|173481/173481[44:21<00:00,65.17it/s]
[32m[0323 14:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2661.93 sec.
[32m[0323 14:42:30 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-867405.
[32m[0323 14:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:17<00:00,137.37it/s]
4
[32m[0323 14:44:48 @monitor.py:363][0m QueueInput/queue_size: 0.72851
[32m[0323 14:44:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.4239
[32m[0323 14:44:48 @monitor.py:363][0m activation-summaries/output-rms: 0.037462
[32m[0323 14:44:48 @monitor.py:363][0m cross_entropy_loss: 1.9392
[32m[0323 14:44:48 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.28321
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 8.0491e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.22654
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.2628e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.26481
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.6349e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.22016
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.0945e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.26737
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 3.6269e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.21941
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5443e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.26879
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.2065e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21947
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9236e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.28372
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.7315e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.22158
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.601e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.22095
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1647
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.21002
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19513
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18678
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091888
[32m[0323 14:44:48 @monitor.py:363][0m train-error-top1: 0.51119
[32m[0323 14:44:48 @monitor.py:363][0m val-error-top1: 0.54152
[32m[0323 14:44:48 @monitor.py:363][0m val-utt-error: 0.18723
[32m[0323 14:44:48 @monitor.py:363][0m validation_cost: 2.1027
[32m[0323 14:44:48 @monitor.py:363][0m wd_cost: 0.24682
[32m[0323 14:44:48 @group.py:42][0m Callbacks took 137.655 sec in total. InferenceRunner: 137.040sec
[32m[0323 14:44:48 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14455/173481[03:00<33:00,80.30it/s]  9%|8         |15252/173481[03:10<32:50,80.30it/s] 15%|#4        |26000/173481[06:00<34:28,71.31it/s] 15%|#5        |26795/173481[06:10<34:16,71.31it/s] 20%|#9        |33946/173481[09:00<42:38,54.53it/s] 20%|##        |34763/173481[09:10<42:23,54.53it/s] 28%|##7       |48065/173481[12:00<32:29,64.33it/s] 28%|##8       |48830/173481[12:10<32:17,64.33it/s] 36%|###5      |62121/173481[15:00<26:18,70.54it/s] 36%|###6      |62983/173481[15:10<26:06,70.54it/s] 43%|####3     |75436/173481[18:00<22:39,72.14it/s] 44%|####3     |76113/173481[18:10<22:29,72.14it/s] 52%|#####1    |90018/173481[21:00<18:13,76.32it/s] 52%|#####2    |90899/173481[21:11<18:02,76.32it/s] 60%|######    |104742/173481[24:00<14:30,78.96it/s] 61%|######    |105630/173481[24:11<14:19,78.96it/s] 67%|######6   |116216/173481[27:00<13:31,70.54it/s] 67%|######7   |116869/173481[27:11<13:22,70.54it/s] 73%|#######3  |127056/173481[30:00<11:54,64.97it/s] 74%|#######3  |127730/173481[30:11<11:44,64.97it/s] 80%|#######9  |138013/173481[33:00<09:24,62.85it/s] 80%|#######9  |138690/173481[33:11<09:13,62.85it/s] 86%|########5 |148997/173481[36:00<06:35,61.92it/s] 86%|########6 |149675/173481[36:11<06:24,61.92it/s] 92%|#########2|159637/173481[39:00<03:48,60.48it/s] 92%|#########2|160346/173481[39:12<03:37,60.48it/s] 98%|#########8|170600/173481[42:00<00:47,60.69it/s] 99%|#########8|171296/173481[42:12<00:36,60.69it/s]100%|##########|173481/173481[42:48<00:00,67.54it/s]
[32m[0323 15:27:36 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:2568.58 sec.
[32m[0323 15:27:37 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-1040886.
[32m[0323 15:27:42 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:11<00:00,143.45it/s]
5
[32m[0323 15:29:54 @monitor.py:363][0m QueueInput/queue_size: 0.70462
[32m[0323 15:29:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.429
[32m[0323 15:29:54 @monitor.py:363][0m activation-summaries/output-rms: 0.038836
[32m[0323 15:29:54 @monitor.py:363][0m cross_entropy_loss: 1.7985
[32m[0323 15:29:54 @monitor.py:363][0m lr: 0.00025
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.32475
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.0759e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.25258
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.4618e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.30436
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.0574e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.24613
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 3.9895e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.30934
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.2684e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.24672
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.567e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.31055
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.7901e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.24613
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8917e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.32735
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.3664e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.24807
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4923e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26193
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1989
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.23433
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21928
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.21122
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091888
[32m[0323 15:29:54 @monitor.py:363][0m train-error-top1: 0.46788
[32m[0323 15:29:54 @monitor.py:363][0m val-error-top1: 0.49284
[32m[0323 15:29:54 @monitor.py:363][0m val-utt-error: 0.14127
[32m[0323 15:29:54 @monitor.py:363][0m validation_cost: 1.8808
[32m[0323 15:29:54 @monitor.py:363][0m wd_cost: 0.064317
[32m[0323 15:29:54 @group.py:42][0m Callbacks took 137.213 sec in total. InferenceRunner: 131.222sec
[32m[0323 15:29:54 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13204/173481[03:00<36:24,73.35it/s]  8%|8         |14026/173481[03:10<36:13,73.35it/s] 14%|#4        |24576/173481[06:00<36:33,67.88it/s] 15%|#4        |25183/173481[06:10<36:24,67.88it/s] 20%|##        |34951/173481[09:00<37:02,62.34it/s] 20%|##        |35520/173481[09:10<36:52,62.34it/s] 26%|##5       |44945/173481[12:00<36:28,58.73it/s] 26%|##6       |45563/173481[12:10<36:18,58.73it/s] 32%|###2      |55807/173481[15:00<32:56,59.52it/s] 33%|###2      |56514/173481[15:10<32:45,59.52it/s] 38%|###8      |66740/173481[18:00<29:35,60.12it/s] 39%|###8      |67403/173481[18:10<29:24,60.12it/s] 44%|####4     |77153/173481[21:00<27:13,58.96it/s] 45%|####4     |78051/173481[21:11<26:58,58.96it/s] 51%|#####1    |89257/173481[24:00<22:20,62.83it/s] 52%|#####1    |89959/173481[24:11<22:09,62.83it/s] 58%|#####7    |100476/173481[27:00<19:26,62.58it/s] 58%|#####8    |101209/173481[27:11<19:14,62.58it/s] 64%|######4   |111530/173481[30:00<16:40,61.92it/s] 64%|######4   |111644/173481[30:11<16:38,61.92it/s] 71%|#######   |122545/173481[33:00<13:47,61.55it/s] 71%|#######1  |123241/173481[33:11<13:36,61.55it/s] 77%|#######6  |133527/173481[36:00<10:51,61.28it/s] 77%|#######7  |134229/173481[36:11<10:40,61.28it/s] 84%|########3 |145505/173481[39:00<07:18,63.80it/s] 84%|########4 |146373/173481[39:12<07:04,63.80it/s] 91%|######### |157595/173481[42:00<04:02,65.44it/s] 91%|#########1|158354/173481[42:12<03:51,65.44it/s] 99%|#########9|171810/173481[45:00<00:23,71.57it/s]100%|#########9|172754/173481[45:12<00:10,71.57it/s]100%|##########|173481/173481[45:21<00:00,63.74it/s]
[32m[0323 16:15:15 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:2721.49 sec.
[32m[0323 16:15:16 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-1214367.
[32m[0323 16:15:16 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.70it/s]
6
[32m[0323 16:17:19 @monitor.py:363][0m QueueInput/queue_size: 0.49153
[32m[0323 16:17:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 16.945
[32m[0323 16:17:19 @monitor.py:363][0m activation-summaries/output-rms: 0.038757
[32m[0323 16:17:19 @monitor.py:363][0m cross_entropy_loss: 1.7751
[32m[0323 16:17:19 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.3738
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5169e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.29077
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.6795e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.34916
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.7509e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.28319
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.0476e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.35449
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.3004e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.28392
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.615e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.35666
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.0874e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.28395
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.7558e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.37691
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.7592e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.28586
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3725e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31736
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2161
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26193
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25232
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.24471
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091888
[32m[0323 16:17:19 @monitor.py:363][0m train-error-top1: 0.47398
[32m[0323 16:17:19 @monitor.py:363][0m val-error-top1: 0.48451
[32m[0323 16:17:19 @monitor.py:363][0m val-utt-error: 0.13511
[32m[0323 16:17:19 @monitor.py:363][0m validation_cost: 1.8435
[32m[0323 16:17:19 @monitor.py:363][0m wd_cost: 0.086888
[32m[0323 16:17:19 @group.py:42][0m Callbacks took 123.720 sec in total. InferenceRunner: 122.477sec
[32m[0323 16:17:19 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12944/173481[03:00<37:12,71.91it/s]  8%|7         |13731/173481[03:10<37:01,71.91it/s] 16%|#5        |27016/173481[06:00<32:35,74.91it/s] 16%|#6        |27836/173481[06:10<32:24,74.91it/s] 24%|##3       |41032/173481[09:00<28:54,76.36it/s] 24%|##4       |41849/173481[09:10<28:43,76.36it/s] 30%|##9       |51274/173481[12:00<31:14,65.21it/s] 30%|###       |52099/173481[12:10<31:01,65.21it/s] 36%|###6      |62666/173481[15:00<28:45,64.23it/s] 36%|###6      |63303/173481[15:10<28:35,64.23it/s] 43%|####2     |74107/173481[18:00<25:55,63.89it/s] 43%|####3     |74788/173481[18:10<25:44,63.89it/s] 49%|####9     |85404/173481[21:00<23:10,63.32it/s] 49%|####9     |85828/173481[21:11<23:04,63.32it/s] 56%|#####5    |96574/173481[24:00<20:26,62.68it/s] 56%|#####6    |97223/173481[24:11<20:16,62.68it/s] 62%|######2   |108174/173481[27:00<17:07,63.54it/s] 63%|######2   |108913/173481[27:11<16:56,63.54it/s] 69%|######9   |119725/173481[30:00<14:01,63.86it/s] 69%|######9   |120455/173481[30:11<13:50,63.86it/s] 75%|#######5  |130928/173481[33:00<11:15,63.04it/s] 76%|#######5  |131678/173481[33:11<11:03,63.04it/s] 82%|########2 |142719/173481[36:00<07:58,64.25it/s] 83%|########2 |143478/173481[36:11<07:47,64.25it/s] 89%|########9 |154524/173481[39:00<04:52,64.91it/s] 89%|########9 |155258/173481[39:11<04:40,64.91it/s] 96%|#########5|165809/173481[42:00<02:00,63.78it/s] 96%|#########6|166607/173481[42:12<01:47,63.78it/s]100%|##########|173481/173481[43:58<00:00,65.74it/s]
[32m[0323 17:01:18 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:2638.95 sec.
[32m[0323 17:01:18 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-1387848.
[32m[0323 17:01:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.90it/s]
7
[32m[0323 17:03:21 @monitor.py:363][0m QueueInput/queue_size: 0.83675
[32m[0323 17:03:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.724
[32m[0323 17:03:21 @monitor.py:363][0m activation-summaries/output-rms: 0.038756
[32m[0323 17:03:21 @monitor.py:363][0m cross_entropy_loss: 1.765
[32m[0323 17:03:21 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.39132
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.4267e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.30622
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.7804e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3656
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9883e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.29825
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2807e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.37183
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.2875e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.29844
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.887e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.374
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.7731e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.29787
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.0086e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.39532
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0i/b-rms: 7.0233e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.30052
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.2749e-06
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.35324
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2305
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2707
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26591
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25791
[32m[0323 17:03:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091888
[32m[0323 17:03:21 @monitor.py:363][0m train-error-top1: 0.46852
[32m[0323 17:03:21 @monitor.py:363][0m val-error-top1: 0.48085
[32m[0323 17:03:21 @monitor.py:363][0m val-utt-error: 0.13091
[32m[0323 17:03:21 @monitor.py:363][0m validation_cost: 1.8234
[32m[0323 17:03:21 @monitor.py:363][0m wd_cost: 0.099033
[32m[0323 17:03:21 @group.py:42][0m Callbacks took 122.863 sec in total. InferenceRunner: 122.316sec
[32m[0323 17:03:21 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13463/173481[03:00<35:39,74.78it/s]  8%|8         |14093/173481[03:10<35:31,74.78it/s] 14%|#4        |24305/173481[06:00<37:15,66.72it/s] 14%|#4        |24918/173481[06:10<37:06,66.72it/s] 21%|##        |35721/173481[09:00<35:18,65.03it/s] 21%|##        |36388/173481[09:10<35:08,65.03it/s] 27%|##7       |47438/173481[12:00<32:17,65.06it/s] 28%|##7       |48121/173481[12:10<32:06,65.06it/s] 34%|###3      |58733/173481[15:00<29:56,63.88it/s] 34%|###4      |59412/173481[15:10<29:45,63.88it/s] 41%|####      |70418/173481[18:00<26:40,64.39it/s] 41%|####      |71122/173481[18:10<26:29,64.39it/s] 47%|####7     |81975/173481[21:00<23:43,64.30it/s] 48%|####7     |82662/173481[21:11<23:32,64.30it/s] 53%|#####3    |92145/173481[24:00<22:32,60.15it/s] 54%|#####3    |92903/173481[24:11<22:19,60.15it/s] 60%|######    |104280/173481[27:00<18:08,63.57it/s] 61%|######    |105043/173481[27:11<17:56,63.57it/s] 67%|######6   |116068/173481[30:00<14:49,64.51it/s] 67%|######7   |116762/173481[30:11<14:39,64.51it/s] 73%|#######3  |127433/173481[33:00<12:01,63.82it/s] 74%|#######3  |127707/173481[33:11<11:57,63.82it/s] 80%|#######9  |138583/173481[36:00<09:15,62.87it/s] 80%|########  |139401/173481[36:11<09:02,62.87it/s] 87%|########6 |150223/173481[39:00<06:04,63.75it/s] 87%|########7 |151036/173481[39:11<05:52,63.75it/s] 93%|#########3|162170/173481[42:00<02:53,65.03it/s] 94%|#########3|162848/173481[42:12<02:43,65.03it/s] 99%|#########9|172214/173481[45:00<00:21,60.06it/s]100%|#########9|172938/173481[45:12<00:09,60.06it/s]100%|##########|173481/173481[45:21<00:00,63.74it/s]
[32m[0323 17:48:43 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:2721.82 sec.
[32m[0323 17:48:43 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-1561329.
[32m[0323 17:48:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.79it/s]
8
[32m[0323 17:50:46 @monitor.py:363][0m QueueInput/queue_size: 0.5162
[32m[0323 17:50:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 24.133
[32m[0323 17:50:46 @monitor.py:363][0m activation-summaries/output-rms: 0.039411
[32m[0323 17:50:46 @monitor.py:363][0m cross_entropy_loss: 1.7096
[32m[0323 17:50:46 @monitor.py:363][0m lr: 0.000125
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.41209
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.4848e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.31629
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8891e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38595
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9372e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.30843
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2063e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3937
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.3836e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.30905
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.7461e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.39375
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6676e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.30788
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9416e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41569
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0i/b-rms: 7.043e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.31225
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3247e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.39022
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2408
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.28124
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27531
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089032
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26714
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091888
[32m[0323 17:50:46 @monitor.py:363][0m train-error-top1: 0.45594
[32m[0323 17:50:46 @monitor.py:363][0m val-error-top1: 0.46096
[32m[0323 17:50:46 @monitor.py:363][0m val-utt-error: 0.1163
[32m[0323 17:50:46 @monitor.py:363][0m validation_cost: 1.7399
[32m[0323 17:50:46 @monitor.py:363][0m wd_cost: 0.022286
[32m[0323 17:50:46 @group.py:42][0m Callbacks took 123.612 sec in total. InferenceRunner: 123.201sec
[32m[0323 17:50:46 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13722/173481[03:00<34:55,76.23it/s]  8%|8         |14310/173481[03:10<34:48,76.23it/s] 14%|#3        |24095/173481[06:00<37:55,65.64it/s] 14%|#4        |24876/173481[06:10<37:44,65.64it/s] 21%|##        |35922/173481[09:00<34:54,65.67it/s] 21%|##1       |36548/173481[09:10<34:45,65.67it/s] 27%|##7       |47198/173481[12:00<32:49,64.12it/s] 28%|##7       |47874/173481[12:10<32:39,64.12it/s] 34%|###3      |58158/173481[15:00<30:46,62.46it/s] 34%|###3      |58266/173481[15:10<30:44,62.46it/s] 37%|###6      |64110/173481[18:00<42:09,43.24it/s] 37%|###7      |64755/173481[18:10<41:54,43.24it/s] 44%|####4     |76360/173481[21:00<30:36,52.88it/s] 44%|####4     |77131/173481[21:11<30:22,52.88it/s] 51%|#####     |88437/173481[24:00<23:57,59.14it/s] 51%|#####1    |89202/173481[24:11<23:44,59.14it/s] 58%|#####7    |100603/173481[27:00<19:15,63.08it/s] 58%|#####8    |101399/173481[27:11<19:02,63.08it/s] 64%|######4   |111891/173481[30:00<16:19,62.90it/s] 65%|######4   |112701/173481[30:11<16:06,62.90it/s] 72%|#######1  |124424/173481[33:00<12:22,66.09it/s] 72%|#######2  |125233/173481[33:11<12:10,66.09it/s] 79%|#######8  |136837/173481[36:00<09:02,67.49it/s] 79%|#######9  |137647/173481[36:11<08:50,67.49it/s] 86%|########5 |148756/173481[39:00<06:09,66.85it/s] 86%|########6 |149755/173481[39:12<05:54,66.85it/s] 94%|#########4|163807/173481[42:00<02:10,74.30it/s] 95%|#########5|164813/173481[42:12<01:56,74.30it/s]100%|##########|173481/173481[43:55<00:00,65.82it/s]
[32m[0323 18:34:42 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:2635.89 sec.
[32m[0323 18:34:42 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-1734810.
[32m[0323 18:34:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,140.97it/s]
9
[32m[0323 18:36:56 @monitor.py:363][0m QueueInput/queue_size: 0.65141
[32m[0323 18:36:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.505
[32m[0323 18:36:56 @monitor.py:363][0m activation-summaries/output-rms: 0.041318
[32m[0323 18:36:56 @monitor.py:363][0m cross_entropy_loss: 1.6615
[32m[0323 18:36:56 @monitor.py:363][0m lr: 0.000125
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.43408
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.4145e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.33079
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8645e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.40815
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9354e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3231
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.172e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.41574
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.4368e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3227
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6254e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.41629
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5326e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.32224
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.993e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.43933
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.9708e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.32712
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3976e-06
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.43005
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2456
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29462
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28824
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089032
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28018
[32m[0323 18:36:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091888
[32m[0323 18:36:56 @monitor.py:363][0m train-error-top1: 0.44902
[32m[0323 18:36:56 @monitor.py:363][0m val-error-top1: 0.45997
[32m[0323 18:36:56 @monitor.py:363][0m val-utt-error: 0.11566
[32m[0323 18:36:56 @monitor.py:363][0m validation_cost: 1.7376
[32m[0323 18:36:56 @monitor.py:363][0m wd_cost: 0.02542
[32m[0323 18:36:56 @group.py:42][0m Callbacks took 134.046 sec in total. InferenceRunner: 133.535sec
[32m[0323 18:36:56 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13396/173481[03:00<35:51,74.42it/s]  8%|8         |14222/173481[03:10<35:40,74.42it/s] 16%|#6        |28051/173481[06:00<31:10,77.76it/s] 17%|#6        |28650/173481[06:10<31:02,77.76it/s] 21%|##1       |37051/173481[09:00<37:22,60.85it/s] 22%|##1       |37550/173481[09:10<37:13,60.85it/s] 26%|##6       |45621/173481[12:00<39:53,53.42it/s] 27%|##6       |46117/173481[12:10<39:44,53.42it/s] 31%|###1      |54084/173481[15:00<39:47,50.01it/s] 31%|###1      |54645/173481[15:10<39:36,50.01it/s] 37%|###6      |63749/173481[18:00<35:18,51.79it/s] 37%|###7      |64448/173481[18:10<35:05,51.79it/s] 42%|####2     |72914/173481[21:00<32:38,51.35it/s] 42%|####2     |73448/173481[21:10<32:28,51.35it/s] 47%|####7     |82252/173481[24:00<29:27,51.61it/s] 48%|####7     |82805/173481[24:11<29:16,51.61it/s] 53%|#####2    |91616/173481[27:00<26:19,51.81it/s] 53%|#####3    |92205/173481[27:11<26:08,51.81it/s] 58%|#####7    |100097/173481[30:00<24:46,49.35it/s] 58%|#####8    |100971/173481[30:11<24:29,49.35it/s] 64%|######3   |110168/173481[33:00<20:07,52.44it/s] 64%|######3   |110965/173481[33:11<19:52,52.44it/s] 70%|#######   |121611/173481[36:00<15:02,57.47it/s] 70%|#######   |122270/173481[36:11<14:51,57.47it/s] 76%|#######6  |132536/173481[39:00<11:33,59.04it/s] 77%|#######6  |132870/173481[39:11<11:27,59.04it/s] 82%|########2 |142366/173481[42:00<09:08,56.74it/s] 82%|########2 |143051/173481[42:12<08:56,56.74it/s] 88%|########7 |152067/173481[45:00<06:27,55.28it/s] 88%|########8 |152731/173481[45:12<06:15,55.28it/s] 93%|#########3|161884/173481[48:00<03:31,54.90it/s] 94%|#########3|162472/173481[48:12<03:20,54.90it/s] 98%|#########8|170789/173481[51:00<00:51,52.05it/s] 99%|#########8|171407/173481[51:12<00:39,52.05it/s]100%|##########|173481/173481[51:53<00:00,55.71it/s]
[32m[0323 19:28:50 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3113.99 sec.
[32m[0323 19:28:50 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-1908291.
[32m[0323 19:28:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.73it/s]
10
[32m[0323 19:30:48 @monitor.py:363][0m QueueInput/queue_size: 0.45808
[32m[0323 19:30:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.48
[32m[0323 19:30:48 @monitor.py:363][0m activation-summaries/output-rms: 0.040525
[32m[0323 19:30:48 @monitor.py:363][0m cross_entropy_loss: 1.6495
[32m[0323 19:30:48 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.45085
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.3799e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34183
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8744e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.42392
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.0127e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.33398
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1193e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4341
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.536e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.33414
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.574e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.43267
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4799e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33284
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9524e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.45617
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.9629e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.33849
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.38e-06
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46557
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2508
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30233
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29788
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28997
[32m[0323 19:30:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0323 19:30:48 @monitor.py:363][0m train-error-top1: 0.43378
[32m[0323 19:30:48 @monitor.py:363][0m val-error-top1: 0.45052
[32m[0323 19:30:48 @monitor.py:363][0m val-utt-error: 0.10822
[32m[0323 19:30:48 @monitor.py:363][0m validation_cost: 1.6952
[32m[0323 19:30:48 @monitor.py:363][0m wd_cost: 0.028124
[32m[0323 19:30:48 @group.py:42][0m Callbacks took 118.198 sec in total. InferenceRunner: 117.117sec
[32m[0323 19:30:48 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12005/173481[03:00<40:21,66.68it/s]  7%|7         |12519/173481[03:10<40:13,66.68it/s] 12%|#2        |21222/173481[06:00<43:48,57.93it/s] 13%|#2        |21786/173481[06:10<43:38,57.93it/s] 18%|#7        |30576/173481[09:00<43:28,54.78it/s] 18%|#7        |31096/173481[09:10<43:19,54.78it/s] 23%|##2       |39330/173481[12:00<43:23,51.52it/s] 23%|##2       |39844/173481[12:10<43:13,51.52it/s] 28%|##7       |47935/173481[15:00<42:12,49.58it/s] 28%|##7       |48439/173481[15:10<42:01,49.58it/s] 33%|###2      |56708/173481[18:00<39:35,49.16it/s] 33%|###3      |57254/173481[18:10<39:24,49.16it/s] 38%|###7      |65795/173481[21:00<36:02,49.80it/s] 38%|###8      |66369/173481[21:11<35:50,49.80it/s] 43%|####3     |74872/173481[24:00<32:47,50.11it/s] 44%|####3     |75710/173481[24:11<32:30,50.11it/s] 49%|####8     |84740/173481[27:00<28:15,52.35it/s] 49%|####9     |85281/173481[27:11<28:04,52.35it/s] 54%|#####4    |94133/173481[30:00<25:18,52.27it/s] 55%|#####4    |94714/173481[30:11<25:07,52.27it/s] 60%|#####9    |103670/173481[33:00<22:08,52.56it/s] 60%|#####9    |103784/173481[33:11<22:06,52.56it/s] 65%|######5   |113319/173481[36:00<18:53,53.08it/s] 66%|######5   |113897/173481[36:11<18:42,53.08it/s] 71%|#######   |122735/173481[39:00<16:03,52.69it/s] 71%|#######1  |123364/173481[39:11<15:51,52.69it/s] 76%|#######6  |132135/173481[42:00<13:08,52.44it/s] 76%|#######6  |132674/173481[42:11<12:58,52.44it/s] 82%|########2 |142845/173481[45:00<09:09,55.74it/s] 83%|########2 |143550/173481[45:12<08:56,55.74it/s] 89%|########8 |154151/173481[48:00<05:27,59.06it/s] 89%|########9 |154846/173481[48:12<05:15,59.06it/s] 95%|#########4|164505/173481[51:00<02:34,58.28it/s] 95%|#########5|165325/173481[51:12<02:19,58.28it/s]100%|##########|173481/173481[53:29<00:00,54.06it/s]
[32m[0323 20:24:17 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3209.18 sec.
[32m[0323 20:24:18 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-2081772.
[32m[0323 20:24:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.52it/s]
11
[32m[0323 20:26:17 @monitor.py:363][0m QueueInput/queue_size: 0.94453
[32m[0323 20:26:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 33.331
[32m[0323 20:26:17 @monitor.py:363][0m activation-summaries/output-rms: 0.040213
[32m[0323 20:26:17 @monitor.py:363][0m cross_entropy_loss: 1.6473
[32m[0323 20:26:17 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.46036
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.3885e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34648
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8507e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.43494
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.0154e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.33866
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1153e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.44335
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.4929e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.33852
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5346e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.44153
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4628e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33759
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.917e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.46536
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8687e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34333
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3809e-06
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4891
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2541
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30787
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30207
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29407
[32m[0323 20:26:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0323 20:26:17 @monitor.py:363][0m train-error-top1: 0.45174
[32m[0323 20:26:17 @monitor.py:363][0m val-error-top1: 0.44761
[32m[0323 20:26:17 @monitor.py:363][0m val-utt-error: 0.10429
[32m[0323 20:26:17 @monitor.py:363][0m validation_cost: 1.6842
[32m[0323 20:26:17 @monitor.py:363][0m wd_cost: 0.0059688
[32m[0323 20:26:17 @group.py:42][0m Callbacks took 120.060 sec in total. InferenceRunner: 119.516sec
[32m[0323 20:26:17 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12994/173481[03:00<37:03,72.19it/s]  8%|7         |13719/173481[03:10<36:53,72.19it/s] 15%|#5        |26334/173481[06:00<33:32,73.13it/s] 16%|#5        |27053/173481[06:10<33:22,73.13it/s] 21%|##        |36020/173481[09:00<36:57,62.00it/s] 21%|##1       |36553/173481[09:10<36:48,62.00it/s] 26%|##6       |45351/173481[12:00<37:49,56.47it/s] 26%|##6       |45916/173481[12:10<37:39,56.47it/s] 32%|###1      |54674/173481[15:00<36:39,54.02it/s] 32%|###1      |55263/173481[15:10<36:28,54.02it/s] 37%|###7      |64409/173481[18:00<33:37,54.05it/s] 38%|###7      |65083/173481[18:10<33:25,54.05it/s] 43%|####3     |75206/173481[21:00<28:48,56.86it/s] 44%|####3     |75883/173481[21:11<28:36,56.86it/s] 49%|####9     |85365/173481[24:00<25:55,56.65it/s] 50%|####9     |86005/173481[24:11<25:44,56.65it/s] 55%|#####4    |95310/173481[27:00<23:17,55.94it/s] 55%|#####5    |95945/173481[27:11<23:06,55.94it/s] 61%|######    |105172/173481[30:00<20:33,55.36it/s] 61%|######    |105778/173481[30:11<20:23,55.36it/s] 66%|######6   |115354/173481[33:00<17:18,55.95it/s] 67%|######6   |116025/173481[33:11<17:06,55.95it/s] 72%|#######1  |124722/173481[36:00<15:04,53.93it/s] 72%|#######2  |125675/173481[36:11<14:46,53.93it/s] 79%|#######8  |136387/173481[39:00<10:30,58.87it/s] 79%|#######8  |137018/173481[39:12<10:19,58.87it/s] 85%|########5 |147534/173481[42:00<07:09,60.36it/s] 85%|########5 |148228/173481[42:12<06:58,60.36it/s] 91%|#########1|158294/173481[45:00<04:12,60.07it/s] 92%|#########1|159009/173481[45:12<04:00,60.07it/s] 97%|#########7|168859/173481[48:00<01:17,59.37it/s] 98%|#########7|169593/173481[48:12<01:05,59.37it/s]100%|##########|173481/173481[49:18<00:00,58.65it/s]
[32m[0323 21:15:35 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:2958.01 sec.
[32m[0323 21:15:36 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-2255253.
[32m[0323 21:15:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.22it/s]
12
[32m[0323 21:17:31 @monitor.py:363][0m QueueInput/queue_size: 0.95539
[32m[0323 21:17:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.639
[32m[0323 21:17:31 @monitor.py:363][0m activation-summaries/output-rms: 0.040556
[32m[0323 21:17:31 @monitor.py:363][0m cross_entropy_loss: 1.6423
[32m[0323 21:17:31 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.46767
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5099e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35132
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8857e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.44413
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.0052e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34319
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1657e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4522
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.4694e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34349
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5336e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.44993
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4533e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34206
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8884e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.47434
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.9311e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34802
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.398e-06
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.51223
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2566
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3131
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089454
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30633
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29834
[32m[0323 21:17:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0323 21:17:31 @monitor.py:363][0m train-error-top1: 0.43637
[32m[0323 21:17:31 @monitor.py:363][0m val-error-top1: 0.44764
[32m[0323 21:17:31 @monitor.py:363][0m val-utt-error: 0.10567
[32m[0323 21:17:31 @monitor.py:363][0m validation_cost: 1.68
[32m[0323 21:17:31 @monitor.py:363][0m wd_cost: 0.0063196
[32m[0323 21:17:31 @group.py:42][0m Callbacks took 115.248 sec in total. InferenceRunner: 114.625sec
[32m[0323 21:17:31 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12858/173481[03:00<37:28,71.43it/s]  8%|7         |13432/173481[03:10<37:20,71.43it/s] 11%|#         |18242/173481[06:00<1:01:21,42.16it/s] 11%|#         |19021/173481[06:10<1:01:03,42.16it/s] 18%|#8        |31783/173481[09:00<43:42,54.04it/s]   19%|#8        |32567/173481[09:10<43:27,54.04it/s] 25%|##5       |44034/173481[12:00<35:48,60.24it/s] 26%|##5       |44626/173481[12:10<35:38,60.24it/s] 32%|###1      |54903/173481[15:00<32:46,60.31it/s] 32%|###2      |55561/173481[15:10<32:35,60.31it/s] 38%|###8      |66341/173481[18:00<28:51,61.88it/s] 39%|###8      |67139/173481[18:10<28:38,61.88it/s] 45%|####5     |78394/173481[21:00<24:38,64.32it/s] 46%|####5     |79114/173481[21:11<24:27,64.32it/s] 52%|#####2    |90511/173481[24:00<21:01,65.78it/s] 53%|#####2    |91274/173481[24:11<20:49,65.78it/s] 59%|#####8    |101865/173481[27:00<18:32,64.40it/s] 59%|#####9    |102672/173481[27:11<18:19,64.40it/s] 66%|######5   |114001/173481[30:00<15:02,65.88it/s] 66%|######6   |114702/173481[30:11<14:52,65.88it/s] 72%|#######2  |125563/173481[33:00<12:16,65.04it/s] 73%|#######2  |126327/173481[33:11<12:04,65.04it/s] 78%|#######8  |136139/173481[36:00<10:04,61.74it/s] 79%|#######8  |136962/173481[36:11<09:51,61.74it/s] 85%|########5 |147927/173481[39:00<06:42,63.56it/s] 86%|########5 |148717/173481[39:12<06:29,63.56it/s] 92%|#########2|159674/173481[42:00<03:34,64.40it/s] 92%|#########2|160430/173481[42:12<03:22,64.40it/s] 98%|#########8|170167/173481[45:00<00:54,61.19it/s] 98%|#########8|170627/173481[45:12<00:46,61.19it/s]100%|##########|173481/173481[46:02<00:00,62.80it/s]
[32m[0323 22:03:33 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:2762.34 sec.
[32m[0323 22:03:33 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-2428734.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.93it/s]
13
[32m[0323 22:05:26 @monitor.py:363][0m QueueInput/queue_size: 0.58513
[32m[0323 22:05:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.433
[32m[0323 22:05:26 @monitor.py:363][0m activation-summaries/output-rms: 0.040273
[32m[0323 22:05:26 @monitor.py:363][0m cross_entropy_loss: 1.648
[32m[0323 22:05:26 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47357
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.4656e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35418
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9264e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45088
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9298e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34611
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1275e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.45801
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5051e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34666
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5954e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45544
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.399e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34507
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9162e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48038
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8619e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35141
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4148e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.53095
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2588
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31636
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30925
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30125
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0323 22:05:26 @monitor.py:363][0m train-error-top1: 0.44616
[32m[0323 22:05:26 @monitor.py:363][0m val-error-top1: 0.44248
[32m[0323 22:05:26 @monitor.py:363][0m val-utt-error: 0.10466
[32m[0323 22:05:26 @monitor.py:363][0m validation_cost: 1.6609
[32m[0323 22:05:26 @monitor.py:363][0m wd_cost: 0.0013194
[32m[0323 22:05:26 @group.py:42][0m Callbacks took 112.967 sec in total. InferenceRunner: 112.768sec
[32m[0323 22:05:26 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14188/173481[03:00<33:41,78.82it/s]  9%|8         |14861/173481[03:10<33:32,78.82it/s] 14%|#4        |24667/173481[06:00<37:02,66.95it/s] 15%|#4        |25181/173481[06:10<36:55,66.95it/s] 20%|#9        |34072/173481[09:00<39:35,58.69it/s] 20%|#9        |34674/173481[09:10<39:25,58.69it/s] 26%|##5       |44665/173481[12:00<36:31,58.77it/s] 26%|##6       |45301/173481[12:10<36:21,58.77it/s] 32%|###1      |54769/173481[15:00<34:27,57.42it/s] 32%|###1      |55221/173481[15:10<34:19,57.42it/s] 37%|###6      |63407/173481[18:00<35:05,52.27it/s] 37%|###6      |64043/173481[18:10<34:53,52.27it/s] 43%|####2     |74268/173481[21:00<29:31,56.02it/s] 43%|####3     |74851/173481[21:11<29:20,56.02it/s] 49%|####8     |84805/173481[24:00<25:48,57.25it/s] 49%|####9     |85451/173481[24:11<25:37,57.25it/s] 54%|#####4    |94092/173481[27:00<24:22,54.27it/s] 55%|#####4    |94561/173481[27:11<24:14,54.27it/s] 59%|#####9    |102847/173481[30:00<22:57,51.29it/s] 60%|#####9    |103421/173481[30:11<22:45,51.29it/s] 66%|######5   |114122/173481[33:00<17:32,56.40it/s] 66%|######6   |114801/173481[33:11<17:20,56.40it/s] 72%|#######2  |125312/173481[36:00<13:34,59.14it/s] 73%|#######2  |125926/173481[36:11<13:24,59.14it/s] 78%|#######7  |135082/173481[39:00<11:18,56.60it/s] 78%|#######8  |135731/173481[39:11<11:06,56.60it/s] 84%|########3 |144892/173481[42:00<08:34,55.52it/s] 84%|########3 |145605/173481[42:12<08:22,55.52it/s] 89%|########9 |154576/173481[45:00<05:45,54.65it/s] 90%|########9 |155409/173481[45:12<05:30,54.65it/s] 95%|#########5|165602/173481[48:00<02:16,57.75it/s] 96%|#########5|166202/173481[48:12<02:06,57.75it/s]100%|##########|173481/173481[49:57<00:00,57.88it/s]
[32m[0323 22:55:23 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:2997.07 sec.
[32m[0323 22:55:23 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-2602215.
[32m[0323 22:55:25 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.63it/s]
14
[32m[0323 22:57:25 @monitor.py:363][0m QueueInput/queue_size: 49.997
[32m[0323 22:57:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.02
[32m[0323 22:57:25 @monitor.py:363][0m activation-summaries/output-rms: 0.04141
[32m[0323 22:57:25 @monitor.py:363][0m cross_entropy_loss: 1.6201
[32m[0323 22:57:25 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47647
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.4634e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35549
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9125e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4545
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9285e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34763
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1238e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46072
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5239e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34782
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5825e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45848
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4229e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34647
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8947e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48357
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.807e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35281
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4323e-06
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.54342
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2603
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31851
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31066
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30254
[32m[0323 22:57:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0323 22:57:25 @monitor.py:363][0m train-error-top1: 0.43278
[32m[0323 22:57:25 @monitor.py:363][0m val-error-top1: 0.44075
[32m[0323 22:57:25 @monitor.py:363][0m val-utt-error: 0.10137
[32m[0323 22:57:25 @monitor.py:363][0m validation_cost: 1.6521
[32m[0323 22:57:25 @monitor.py:363][0m wd_cost: 0.0013552
[32m[0323 22:57:25 @group.py:42][0m Callbacks took 121.626 sec in total. InferenceRunner: 120.186sec
[32m[0323 22:57:25 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13016/173481[03:00<36:59,72.30it/s]  8%|7         |13745/173481[03:10<36:49,72.30it/s] 15%|#4        |25805/173481[06:00<34:20,71.67it/s] 15%|#5        |26652/173481[06:10<34:08,71.67it/s] 21%|##1       |36681/173481[09:00<34:46,65.56it/s] 21%|##1       |37260/173481[09:10<34:37,65.56it/s] 27%|##7       |47441/173481[12:00<33:35,62.53it/s] 28%|##7       |48070/173481[12:10<33:25,62.53it/s] 33%|###3      |57934/173481[15:00<31:55,60.33it/s] 34%|###3      |58618/173481[15:10<31:43,60.33it/s] 39%|###9      |68497/173481[18:00<29:24,59.50it/s] 40%|###9      |69140/173481[18:10<29:13,59.50it/s] 46%|####5     |79599/173481[21:00<25:50,60.57it/s] 46%|####6     |80391/173481[21:11<25:36,60.57it/s] 53%|#####2    |91786/173481[24:00<21:17,63.94it/s] 53%|#####3    |92658/173481[24:11<21:04,63.94it/s] 60%|#####9    |104081/173481[27:00<17:30,66.05it/s] 60%|######    |104840/173481[27:11<17:19,66.05it/s] 67%|######7   |116886/173481[30:00<13:46,68.49it/s] 68%|######7   |117692/173481[30:11<13:34,68.49it/s] 74%|#######4  |128457/173481[33:00<11:18,66.32it/s] 75%|#######4  |129326/173481[33:11<11:05,66.32it/s] 81%|########  |139823/173481[36:00<08:40,64.69it/s] 81%|########1 |140530/173481[36:11<08:29,64.69it/s] 87%|########6 |150528/173481[39:00<06:10,61.97it/s] 87%|########7 |151205/173481[39:11<05:59,61.97it/s] 92%|#########2|160070/173481[42:00<03:54,57.14it/s] 93%|#########2|160985/173481[42:12<03:38,57.14it/s]100%|##########|173481/173481[44:54<00:00,64.37it/s]
[32m[0323 23:42:20 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:2694.95 sec.
[32m[0323 23:42:20 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-2775696.
[32m[0323 23:42:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.08it/s]
15
[32m[0323 23:44:16 @monitor.py:363][0m QueueInput/queue_size: 0.72186
[32m[0323 23:44:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.285
[32m[0323 23:44:16 @monitor.py:363][0m activation-summaries/output-rms: 0.041024
[32m[0323 23:44:16 @monitor.py:363][0m cross_entropy_loss: 1.6161
[32m[0323 23:44:16 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.479
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5046e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35677
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9026e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45731
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9176e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34874
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1163e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46376
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5157e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34919
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5975e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46158
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4377e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34755
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8945e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48616
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.842e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3541
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4441e-06
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.55566
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2619
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32048
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31199
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30379
[32m[0323 23:44:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0323 23:44:16 @monitor.py:363][0m train-error-top1: 0.42662
[32m[0323 23:44:16 @monitor.py:363][0m val-error-top1: 0.44254
[32m[0323 23:44:16 @monitor.py:363][0m val-utt-error: 0.10227
[32m[0323 23:44:16 @monitor.py:363][0m validation_cost: 1.6597
[32m[0323 23:44:16 @monitor.py:363][0m wd_cost: 0.0013906
[32m[0323 23:44:16 @group.py:42][0m Callbacks took 116.144 sec in total. InferenceRunner: 115.428sec
[32m[0323 23:44:16 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14180/173481[03:00<33:42,78.77it/s]  9%|8         |14984/173481[03:10<33:32,78.77it/s] 15%|#4        |25815/173481[06:00<34:39,71.00it/s] 15%|#5        |26628/173481[06:10<34:28,71.00it/s] 22%|##2       |38863/173481[09:00<31:16,71.74it/s] 23%|##2       |39519/173481[09:10<31:07,71.74it/s] 29%|##9       |50500/173481[12:00<30:08,68.01it/s] 29%|##9       |51169/173481[12:10<29:58,68.01it/s] 36%|###5      |62339/173481[15:00<27:42,66.87it/s] 36%|###6      |63159/173481[15:10<27:29,66.87it/s] 44%|####3     |75885/173481[18:00<22:58,70.81it/s] 44%|####4     |76690/173481[18:10<22:46,70.81it/s] 52%|#####1    |89449/173481[21:00<19:10,73.01it/s] 52%|#####2    |90276/173481[21:11<18:59,73.01it/s] 59%|#####9    |102904/173481[24:00<15:55,73.87it/s] 60%|#####9    |103730/173481[24:11<15:44,73.87it/s] 66%|######6   |114767/173481[27:00<14:02,69.66it/s] 67%|######6   |115604/173481[27:11<13:50,69.66it/s] 74%|#######3  |127835/173481[30:00<10:42,71.10it/s] 74%|#######4  |128662/173481[30:11<10:30,71.10it/s] 81%|########1 |140777/173481[33:00<07:37,71.50it/s] 82%|########1 |141613/173481[33:11<07:25,71.50it/s] 89%|########8 |154050/173481[36:00<04:27,72.60it/s] 89%|########9 |155059/173481[36:11<04:13,72.60it/s] 97%|#########7|168745/173481[39:00<01:01,76.85it/s] 98%|#########7|169459/173481[39:11<00:52,76.85it/s]100%|##########|173481/173481[40:21<00:00,71.66it/s]
[32m[0324 00:24:37 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:2421.02 sec.
[32m[0324 00:24:37 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-2949177.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,169.11it/s]
16
[32m[0324 00:26:28 @monitor.py:363][0m QueueInput/queue_size: 0.62124
[32m[0324 00:26:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.373
[32m[0324 00:26:28 @monitor.py:363][0m activation-summaries/output-rms: 0.040581
[32m[0324 00:26:28 @monitor.py:363][0m cross_entropy_loss: 1.6232
[32m[0324 00:26:28 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48076
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5553e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35752
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9035e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45919
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9113e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3494
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1228e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46526
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.4998e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3498
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6068e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46295
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4261e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34837
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9071e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48777
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8738e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3547
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4327e-06
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56412
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2629
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32156
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31269
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30445
[32m[0324 00:26:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 00:26:28 @monitor.py:363][0m train-error-top1: 0.4453
[32m[0324 00:26:28 @monitor.py:363][0m val-error-top1: 0.43934
[32m[0324 00:26:28 @monitor.py:363][0m val-utt-error: 0.10057
[32m[0324 00:26:28 @monitor.py:363][0m validation_cost: 1.6488
[32m[0324 00:26:28 @monitor.py:363][0m wd_cost: 0.00028288
[32m[0324 00:26:28 @group.py:42][0m Callbacks took 111.566 sec in total. InferenceRunner: 111.312sec
[32m[0324 00:26:28 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13158/173481[03:00<36:33,73.10it/s]  8%|8         |13986/173481[03:10<36:21,73.10it/s] 15%|#4        |25167/173481[06:00<35:26,69.76it/s] 15%|#4        |25743/173481[06:10<35:17,69.76it/s] 20%|##        |35034/173481[09:00<37:35,61.39it/s] 21%|##        |35650/173481[09:10<37:25,61.39it/s] 26%|##5       |44868/173481[12:00<37:04,57.81it/s] 26%|##6       |45712/173481[12:10<36:50,57.81it/s] 32%|###1      |54939/173481[15:00<34:44,56.86it/s] 32%|###2      |55523/173481[15:10<34:34,56.86it/s] 37%|###7      |65040/173481[18:00<31:59,56.48it/s] 38%|###7      |65675/173481[18:10<31:48,56.48it/s] 44%|####3     |76176/173481[21:00<27:27,59.05it/s] 44%|####4     |76829/173481[21:11<27:16,59.05it/s] 50%|#####     |87131/173481[24:00<24:00,59.94it/s] 51%|#####     |87835/173481[24:11<23:48,59.94it/s] 57%|#####6    |98031/173481[27:00<20:52,60.25it/s] 57%|#####6    |98709/173481[27:11<20:41,60.25it/s] 63%|######2   |108907/173481[30:00<17:50,60.33it/s] 63%|######3   |109620/173481[30:11<17:38,60.33it/s] 69%|######9   |120412/173481[33:00<14:14,62.07it/s] 70%|######9   |121058/173481[33:11<14:04,62.07it/s] 76%|#######5  |131164/173481[36:00<11:35,60.88it/s] 76%|#######6  |131895/173481[36:11<11:23,60.88it/s] 82%|########1 |142023/173481[39:00<08:39,60.60it/s] 82%|########2 |142763/173481[39:11<08:26,60.60it/s] 88%|########8 |153119/173481[42:00<05:33,61.11it/s] 89%|########8 |153868/173481[42:12<05:20,61.11it/s] 95%|#########4|164514/173481[45:00<02:24,62.19it/s] 95%|#########5|165260/173481[45:12<02:12,62.19it/s]100%|##########|173481/173481[47:50<00:00,60.44it/s]
[32m[0324 01:14:19 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:2870.19 sec.
[32m[0324 01:14:19 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-3122658.
[32m[0324 01:14:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.54it/s]
17
[32m[0324 01:16:20 @monitor.py:363][0m QueueInput/queue_size: 0.73809
[32m[0324 01:16:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 42.29
[32m[0324 01:16:20 @monitor.py:363][0m activation-summaries/output-rms: 0.041034
[32m[0324 01:16:20 @monitor.py:363][0m cross_entropy_loss: 1.6163
[32m[0324 01:16:20 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48178
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5469e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35798
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9048e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46032
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9128e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34982
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1293e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46633
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5168e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35032
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6082e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46412
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4183e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.3486
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8992e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48897
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8557e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3551
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4462e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57065
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2637
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32228
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31311
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30481
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 01:16:20 @monitor.py:363][0m train-error-top1: 0.42982
[32m[0324 01:16:20 @monitor.py:363][0m val-error-top1: 0.43947
[32m[0324 01:16:20 @monitor.py:363][0m val-utt-error: 0.099617
[32m[0324 01:16:20 @monitor.py:363][0m validation_cost: 1.6471
[32m[0324 01:16:20 @monitor.py:363][0m wd_cost: 0.00028647
[32m[0324 01:16:20 @group.py:42][0m Callbacks took 121.848 sec in total. InferenceRunner: 120.250sec
[32m[0324 01:16:20 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13264/173481[03:00<36:14,73.69it/s]  8%|8         |14000/173481[03:10<36:04,73.69it/s] 15%|#4        |25419/173481[06:00<35:01,70.47it/s] 15%|#4        |25956/173481[06:10<34:53,70.47it/s] 21%|##        |35943/173481[09:00<35:52,63.91it/s] 21%|##1       |36587/173481[09:10<35:42,63.91it/s] 27%|##6       |46228/173481[12:00<35:10,60.30it/s] 27%|##6       |46599/173481[12:10<35:04,60.30it/s] 33%|###2      |57018/173481[15:00<32:17,60.12it/s] 33%|###3      |57582/173481[15:10<32:07,60.12it/s] 39%|###9      |68048/173481[18:00<28:57,60.69it/s] 40%|###9      |68679/173481[18:10<28:46,60.69it/s] 45%|####5     |78648/173481[21:00<26:26,59.78it/s] 46%|####5     |79261/173481[21:11<26:16,59.78it/s] 51%|#####1    |88723/173481[24:00<24:26,57.81it/s] 51%|#####1    |89327/173481[24:11<24:15,57.81it/s] 57%|#####6    |98533/173481[27:00<22:15,56.10it/s] 57%|#####7    |99173/173481[27:11<22:04,56.10it/s] 63%|######2   |109003/173481[30:00<18:48,57.12it/s] 63%|######3   |109687/173481[30:11<18:36,57.12it/s] 69%|######9   |119798/173481[33:00<15:17,58.50it/s] 69%|######9   |120464/173481[33:11<15:06,58.50it/s] 75%|#######4  |129963/173481[36:00<12:37,57.46it/s] 75%|#######5  |130627/173481[36:11<12:25,57.46it/s] 81%|########1 |140588/173481[39:00<09:24,58.23it/s] 81%|########1 |141367/173481[39:12<09:11,58.23it/s] 87%|########7 |151740/173481[42:00<06:02,60.03it/s] 88%|########7 |152514/173481[42:12<05:49,60.03it/s] 94%|#########4|163208/173481[45:00<02:46,61.81it/s] 95%|#########4|163977/173481[45:12<02:33,61.81it/s]100%|##########|173481/173481[47:53<00:00,60.38it/s]
[32m[0324 02:04:14 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:2873.18 sec.
[32m[0324 02:04:14 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-3296139.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.72it/s]
18
[32m[0324 02:06:39 @monitor.py:363][0m QueueInput/queue_size: 0.72582
[32m[0324 02:06:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 42.875
[32m[0324 02:06:39 @monitor.py:363][0m activation-summaries/output-rms: 0.040395
[32m[0324 02:06:39 @monitor.py:363][0m cross_entropy_loss: 1.6333
[32m[0324 02:06:39 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4829
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5482e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35825
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8977e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46147
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9065e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35012
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1302e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46738
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5273e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35069
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6019e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46504
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4148e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34899
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8976e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49018
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8735e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35553
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4496e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5772
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2643
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32298
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31353
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30521
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 02:06:39 @monitor.py:363][0m train-error-top1: 0.43957
[32m[0324 02:06:39 @monitor.py:363][0m val-error-top1: 0.43916
[32m[0324 02:06:39 @monitor.py:363][0m val-utt-error: 0.1027
[32m[0324 02:06:39 @monitor.py:363][0m validation_cost: 1.6454
[32m[0324 02:06:39 @monitor.py:363][0m wd_cost: 0.00029011
[32m[0324 02:06:39 @group.py:42][0m Callbacks took 145.370 sec in total. InferenceRunner: 145.110sec
[32m[0324 02:06:39 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13930/173481[03:00<34:21,77.39it/s]  8%|8         |14672/173481[03:10<34:12,77.39it/s] 14%|#4        |24857/173481[06:00<36:24,68.03it/s] 15%|#4        |25447/173481[06:10<36:15,68.03it/s] 21%|##        |36422/173481[09:00<34:34,66.07it/s] 21%|##1       |37030/173481[09:10<34:25,66.07it/s] 27%|##7       |47157/173481[12:00<33:35,62.68it/s] 28%|##7       |47819/173481[12:10<33:24,62.68it/s] 34%|###4      |59380/173481[15:00<29:10,65.19it/s] 35%|###4      |60116/173481[15:10<28:58,65.19it/s] 42%|####1     |72057/173481[18:00<24:58,67.70it/s] 42%|####1     |72251/173481[18:10<24:55,67.70it/s] 49%|####8     |84276/173481[21:00<21:55,67.79it/s] 49%|####9     |85061/173481[21:11<21:44,67.79it/s] 56%|#####6    |97285/173481[24:00<18:09,69.96it/s] 57%|#####6    |98054/173481[24:11<17:58,69.96it/s] 64%|######3   |110168/173481[27:00<14:54,70.75it/s] 64%|######3   |110964/173481[27:11<14:43,70.75it/s] 71%|#######   |122898/173481[30:00<11:55,70.74it/s] 71%|#######1  |123703/173481[30:11<11:43,70.74it/s] 77%|#######7  |134397/173481[33:00<09:42,67.13it/s] 78%|#######7  |135181/173481[33:11<09:30,67.13it/s] 86%|########5 |148400/173481[36:00<05:48,72.07it/s] 86%|########6 |149372/173481[36:11<05:34,72.07it/s] 94%|#########3|162715/173481[39:00<02:22,75.61it/s] 94%|#########4|163642/173481[39:11<02:10,75.61it/s]100%|##########|173481/173481[41:15<00:00,70.08it/s]
[32m[0324 02:47:54 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:2475.46 sec.
[32m[0324 02:47:55 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-3469620.
[32m[0324 02:47:55 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.98it/s]
19
[32m[0324 02:49:53 @monitor.py:363][0m QueueInput/queue_size: 0.68053
[32m[0324 02:49:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.418
[32m[0324 02:49:53 @monitor.py:363][0m activation-summaries/output-rms: 0.042056
[32m[0324 02:49:53 @monitor.py:363][0m cross_entropy_loss: 1.6064
[32m[0324 02:49:53 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48324
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5469e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35836
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8976e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46212
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9147e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35035
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1306e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46782
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5214e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35076
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6059e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46547
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4213e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34913
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8979e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49072
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.871e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35568
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4466e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58079
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2648
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32329
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3137
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30533
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 02:49:53 @monitor.py:363][0m train-error-top1: 0.43383
[32m[0324 02:49:53 @monitor.py:363][0m val-error-top1: 0.43842
[32m[0324 02:49:53 @monitor.py:363][0m val-utt-error: 0.1002
[32m[0324 02:49:53 @monitor.py:363][0m validation_cost: 1.6433
[32m[0324 02:49:53 @monitor.py:363][0m wd_cost: 5.841e-05
[32m[0324 02:49:53 @group.py:42][0m Callbacks took 118.872 sec in total. InferenceRunner: 118.411sec
[32m[0324 02:49:53 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13731/173481[03:00<34:54,76.26it/s]  8%|8         |14385/173481[03:10<34:46,76.26it/s] 15%|#5        |26316/173481[06:00<33:37,72.95it/s] 16%|#5        |27163/173481[06:10<33:25,72.95it/s] 24%|##3       |40968/173481[09:00<28:42,76.94it/s] 24%|##4       |41813/173481[09:10<28:31,76.94it/s] 32%|###1      |55459/173481[12:00<24:59,78.68it/s] 32%|###2      |56308/173481[12:10<24:49,78.68it/s] 40%|####      |70017/173481[15:00<21:37,79.76it/s] 41%|####      |70890/173481[15:10<21:26,79.76it/s] 47%|####7     |82190/173481[18:00<20:47,73.19it/s] 48%|####7     |83076/173481[18:10<20:35,73.19it/s] 54%|#####4    |93804/173481[21:00<19:21,68.58it/s] 54%|#####4    |94520/173481[21:11<19:11,68.58it/s] 60%|######    |104856/173481[24:00<17:39,64.78it/s] 61%|######    |105532/173481[24:11<17:28,64.78it/s] 67%|######6   |115953/173481[27:00<15:10,63.18it/s] 67%|######7   |116636/173481[27:11<14:59,63.18it/s] 73%|#######3  |127168/173481[30:00<12:18,62.74it/s] 74%|#######3  |127869/173481[30:11<12:07,62.74it/s] 80%|#######9  |138136/173481[33:00<09:31,61.82it/s] 80%|########  |138854/173481[33:11<09:20,61.82it/s] 86%|########5 |149186/173481[36:00<06:34,61.60it/s] 86%|########6 |149854/173481[36:11<06:23,61.60it/s] 92%|#########2|159872/173481[39:00<03:45,60.46it/s] 93%|#########2|160656/173481[39:12<03:32,60.46it/s] 99%|#########9|172544/173481[42:00<00:14,65.05it/s]100%|#########9|173366/173481[42:12<00:01,65.05it/s]100%|##########|173481/173481[42:13<00:00,68.46it/s]
[32m[0324 03:32:07 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:2534.00 sec.
[32m[0324 03:32:08 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-3643101.
[32m[0324 03:32:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.41it/s]
20
[32m[0324 03:34:07 @monitor.py:363][0m QueueInput/queue_size: 1.0106
[32m[0324 03:34:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.881
[32m[0324 03:34:07 @monitor.py:363][0m activation-summaries/output-rms: 0.041249
[32m[0324 03:34:07 @monitor.py:363][0m cross_entropy_loss: 1.603
[32m[0324 03:34:07 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4836
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5507e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35847
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8977e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4626
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.916e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35035
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1333e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46823
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5299e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3509
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6055e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46593
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.422e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34918
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8973e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49107
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8697e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35577
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4524e-06
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58423
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2652
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32358
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31384
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30545
[32m[0324 03:34:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 03:34:07 @monitor.py:363][0m train-error-top1: 0.42453
[32m[0324 03:34:07 @monitor.py:363][0m val-error-top1: 0.43849
[32m[0324 03:34:07 @monitor.py:363][0m val-utt-error: 0.099936
[32m[0324 03:34:07 @monitor.py:363][0m validation_cost: 1.6427
[32m[0324 03:34:07 @monitor.py:363][0m wd_cost: 5.8781e-05
[32m[0324 03:34:07 @group.py:42][0m Callbacks took 120.084 sec in total. InferenceRunner: 118.834sec
[32m[0324 03:34:07 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12550/173481[03:00<38:28,69.71it/s]  8%|7         |13299/173481[03:10<38:17,69.71it/s] 15%|#4        |25690/173481[06:00<34:32,71.31it/s] 15%|#5        |26424/173481[06:10<34:22,71.31it/s] 21%|##1       |36530/173481[09:00<34:57,65.29it/s] 21%|##1       |37154/173481[09:10<34:48,65.29it/s] 27%|##6       |46820/173481[12:00<34:37,60.95it/s] 27%|##7       |47449/173481[12:10<34:27,60.95it/s] 34%|###3      |58375/173481[15:00<30:40,62.53it/s] 34%|###4      |59131/173481[15:10<30:28,62.53it/s] 41%|####      |70313/173481[18:00<26:42,64.37it/s] 41%|####      |70966/173481[18:10<26:32,64.37it/s] 47%|####6     |81295/173481[21:00<24:31,62.64it/s] 47%|####7     |81964/173481[21:11<24:20,62.64it/s] 53%|#####3    |92420/173481[24:00<21:42,62.22it/s] 54%|#####3    |93095/173481[24:11<21:32,62.22it/s] 60%|#####9    |103755/173481[27:00<18:34,62.58it/s] 60%|######    |104465/173481[27:11<18:22,62.58it/s] 66%|######6   |114914/173481[30:00<15:40,62.29it/s] 67%|######6   |115824/173481[30:11<15:25,62.29it/s] 73%|#######3  |126918/173481[33:00<12:02,64.41it/s] 74%|#######3  |127635/173481[33:11<11:51,64.41it/s] 80%|#######9  |138095/173481[36:00<09:19,63.23it/s] 80%|########  |138801/173481[36:11<09:08,63.23it/s] 86%|########6 |149418/173481[39:00<06:21,63.06it/s] 87%|########6 |150169/173481[39:12<06:09,63.06it/s] 93%|#########2|160819/173481[42:00<03:20,63.20it/s] 93%|#########3|161539/173481[42:12<03:08,63.20it/s] 99%|#########9|171899/173481[45:00<00:25,62.37it/s]100%|#########9|172841/173481[45:12<00:10,62.37it/s]100%|##########|173481/173481[45:21<00:00,63.73it/s]
[32m[0324 04:19:29 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:2721.97 sec.
[32m[0324 04:19:30 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-3816582.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.17it/s]
21
[32m[0324 04:21:29 @monitor.py:363][0m QueueInput/queue_size: 0.71396
[32m[0324 04:21:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.294
[32m[0324 04:21:29 @monitor.py:363][0m activation-summaries/output-rms: 0.04074
[32m[0324 04:21:29 @monitor.py:363][0m cross_entropy_loss: 1.6164
[32m[0324 04:21:29 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48395
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5504e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35864
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8917e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46294
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9105e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35039
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1344e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46849
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5209e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35097
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6054e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46625
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4215e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34933
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8958e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49139
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8761e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35583
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4486e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58727
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2656
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32381
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31396
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30555
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 04:21:29 @monitor.py:363][0m train-error-top1: 0.43716
[32m[0324 04:21:29 @monitor.py:363][0m val-error-top1: 0.43735
[32m[0324 04:21:29 @monitor.py:363][0m val-utt-error: 0.099511
[32m[0324 04:21:29 @monitor.py:363][0m validation_cost: 1.6401
[32m[0324 04:21:29 @monitor.py:363][0m wd_cost: 5.9108e-05
[32m[0324 04:21:29 @group.py:42][0m Callbacks took 119.989 sec in total. InferenceRunner: 119.769sec
[32m[0324 04:21:29 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14212/173481[03:00<33:37,78.96it/s]  9%|8         |15004/173481[03:10<33:27,78.96it/s] 16%|#6        |27894/173481[06:00<31:19,77.45it/s] 16%|#6        |28478/173481[06:10<31:12,77.45it/s] 22%|##2       |38891/173481[09:00<32:50,68.31it/s] 23%|##2       |39563/173481[09:10<32:40,68.31it/s] 29%|##8       |49584/173481[12:00<32:29,63.54it/s] 29%|##8       |50203/173481[12:10<32:20,63.54it/s] 35%|###4      |60349/173481[15:00<30:36,61.61it/s] 35%|###5      |60979/173481[15:10<30:25,61.61it/s] 42%|####1     |72104/173481[18:00<26:38,63.40it/s] 42%|####2     |72864/173481[18:10<26:27,63.40it/s] 48%|####8     |83824/173481[21:00<23:15,64.24it/s] 49%|####8     |84513/173481[21:11<23:04,64.24it/s] 55%|#####5    |95463/173481[24:00<20:10,64.45it/s] 55%|#####5    |96197/173481[24:11<19:59,64.45it/s] 62%|######1   |106961/173481[27:00<17:16,64.16it/s] 62%|######2   |107768/173481[27:11<17:04,64.16it/s] 69%|######8   |119574/173481[30:00<13:24,66.99it/s] 69%|######9   |120386/173481[30:11<13:12,66.99it/s] 76%|#######6  |132119/173481[33:00<10:05,68.31it/s] 77%|#######6  |132912/173481[33:11<09:53,68.31it/s] 83%|########3 |144639/173481[36:00<06:58,68.93it/s] 84%|########3 |145622/173481[36:11<06:44,68.93it/s] 90%|######### |156904/173481[39:00<04:02,68.47it/s] 91%|######### |157023/173481[39:12<04:00,68.47it/s] 97%|#########7|169059/173481[42:00<01:05,67.99it/s] 98%|#########7|169828/173481[42:12<00:53,67.99it/s]100%|##########|173481/173481[43:08<00:00,67.02it/s]
[32m[0324 05:04:38 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:2588.67 sec.
[32m[0324 05:04:38 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-3990063.
[32m[0324 05:04:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.72it/s]
22
[32m[0324 05:06:36 @monitor.py:363][0m QueueInput/queue_size: 0.69076
[32m[0324 05:06:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.654
[32m[0324 05:06:36 @monitor.py:363][0m activation-summaries/output-rms: 0.041092
[32m[0324 05:06:36 @monitor.py:363][0m cross_entropy_loss: 1.6102
[32m[0324 05:06:36 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48412
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5485e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35866
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8957e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46314
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9088e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35043
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1354e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46869
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5204e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35104
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6058e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46649
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4215e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34933
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8961e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49158
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8828e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35585
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4514e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58902
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2658
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32392
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31401
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30558
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 05:06:36 @monitor.py:363][0m train-error-top1: 0.43254
[32m[0324 05:06:36 @monitor.py:363][0m val-error-top1: 0.4375
[32m[0324 05:06:36 @monitor.py:363][0m val-utt-error: 0.098502
[32m[0324 05:06:36 @monitor.py:363][0m validation_cost: 1.6393
[32m[0324 05:06:36 @monitor.py:363][0m wd_cost: 1.1859e-05
[32m[0324 05:06:36 @group.py:42][0m Callbacks took 118.407 sec in total. InferenceRunner: 117.858sec
[32m[0324 05:06:36 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14742/173481[03:00<32:18,81.90it/s]  9%|8         |15567/173481[03:10<32:08,81.90it/s] 15%|#5        |26152/173481[06:00<34:21,71.46it/s] 15%|#5        |26876/173481[06:10<34:11,71.46it/s] 22%|##1       |38047/173481[09:00<32:52,68.67it/s] 22%|##2       |38900/173481[09:10<32:39,68.67it/s] 29%|##9       |50571/173481[12:00<29:38,69.12it/s] 30%|##9       |51289/173481[12:10<29:27,69.12it/s] 36%|###6      |62803/173481[15:00<26:55,68.53it/s] 37%|###6      |63567/173481[15:10<26:43,68.53it/s] 44%|####3     |76320/173481[18:00<22:35,71.66it/s] 44%|####4     |77192/173481[18:10<22:23,71.66it/s] 51%|#####1    |88916/173481[21:00<19:54,70.81it/s] 52%|#####1    |89778/173481[21:11<19:42,70.81it/s] 59%|#####8    |101778/173481[24:00<16:48,71.13it/s] 59%|#####9    |102636/173481[24:11<16:36,71.13it/s] 67%|######6   |115624/173481[27:00<13:02,73.91it/s] 67%|######7   |116489/173481[27:11<12:51,73.91it/s] 74%|#######3  |128035/173481[30:00<10:37,71.34it/s] 74%|#######4  |128827/173481[30:11<10:25,71.34it/s] 81%|########  |140363/173481[33:00<07:53,69.88it/s] 81%|########1 |141167/173481[33:11<07:42,69.88it/s] 89%|########8 |153801/173481[36:00<04:32,72.19it/s] 89%|########9 |154862/173481[36:11<04:17,72.19it/s] 97%|#########7|168536/173481[39:00<01:04,76.72it/s] 98%|#########7|169591/173481[39:12<00:50,76.72it/s]100%|##########|173481/173481[39:56<00:00,72.39it/s]
[32m[0324 05:46:33 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:2396.63 sec.
[32m[0324 05:46:33 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-4163544.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.51it/s]
23
[32m[0324 05:48:36 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 05:48:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.76
[32m[0324 05:48:36 @monitor.py:363][0m activation-summaries/output-rms: 0.04119
[32m[0324 05:48:36 @monitor.py:363][0m cross_entropy_loss: 1.5847
[32m[0324 05:48:36 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48435
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5425e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35869
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8966e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46334
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9089e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35049
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1356e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46888
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5177e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35108
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6043e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46662
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4161e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34936
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8956e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49183
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8822e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35591
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.453e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59074
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2659
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32403
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31406
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30562
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 05:48:36 @monitor.py:363][0m train-error-top1: 0.43025
[32m[0324 05:48:36 @monitor.py:363][0m val-error-top1: 0.43731
[32m[0324 05:48:36 @monitor.py:363][0m val-utt-error: 0.099139
[32m[0324 05:48:36 @monitor.py:363][0m validation_cost: 1.6381
[32m[0324 05:48:36 @monitor.py:363][0m wd_cost: 1.1896e-05
[32m[0324 05:48:36 @group.py:42][0m Callbacks took 122.746 sec in total. InferenceRunner: 122.627sec
[32m[0324 05:48:36 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16180/173481[03:00<29:09,89.89it/s] 10%|9         |17084/173481[03:10<28:59,89.89it/s] 18%|#8        |31822/173481[06:00<26:43,88.37it/s] 19%|#8        |32613/173481[06:10<26:34,88.37it/s] 27%|##6       |46497/173481[09:00<24:58,84.73it/s] 27%|##6       |46606/173481[09:10<24:57,84.73it/s] 33%|###3      |57665/173481[12:00<26:56,71.63it/s] 34%|###3      |58431/173481[12:10<26:46,71.63it/s] 42%|####2     |73656/173481[15:00<20:58,79.31it/s] 43%|####3     |74597/173481[15:10<20:46,79.31it/s] 52%|#####2    |90261/173481[18:00<16:15,85.29it/s] 53%|#####2    |91277/173481[18:10<16:03,85.29it/s] 61%|######1   |106128/173481[21:00<12:56,86.70it/s] 62%|######1   |107099/173481[21:11<12:45,86.70it/s] 70%|#######   |121994/173481[24:00<09:49,87.41it/s] 71%|#######   |122721/173481[24:11<09:40,87.41it/s] 79%|#######8  |136694/173481[27:00<07:15,84.44it/s] 79%|#######9  |137705/173481[27:11<07:03,84.44it/s] 88%|########8 |153036/173481[30:00<03:53,87.50it/s] 89%|########8 |154097/173481[30:11<03:41,87.50it/s] 97%|#########6|168114/173481[33:00<01:02,85.59it/s] 97%|#########7|169058/173481[33:11<00:51,85.59it/s]100%|##########|173481/173481[34:05<00:00,84.81it/s]
[32m[0324 06:22:41 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:2045.50 sec.
[32m[0324 06:22:42 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-4337025.
[32m[0324 06:22:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.24it/s]
24
[32m[0324 06:24:37 @monitor.py:363][0m QueueInput/queue_size: 0.95422
[32m[0324 06:24:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.914
[32m[0324 06:24:37 @monitor.py:363][0m activation-summaries/output-rms: 0.042107
[32m[0324 06:24:37 @monitor.py:363][0m cross_entropy_loss: 1.6014
[32m[0324 06:24:37 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4844
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5431e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35868
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8973e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46354
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9066e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35057
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1374e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46899
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.519e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35108
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6049e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46675
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4136e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34939
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.895e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49198
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8843e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35594
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4543e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59193
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2661
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3241
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31409
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30565
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 06:24:37 @monitor.py:363][0m train-error-top1: 0.43328
[32m[0324 06:24:37 @monitor.py:363][0m val-error-top1: 0.43738
[32m[0324 06:24:37 @monitor.py:363][0m val-utt-error: 0.099352
[32m[0324 06:24:37 @monitor.py:363][0m validation_cost: 1.639
[32m[0324 06:24:37 @monitor.py:363][0m wd_cost: 2.3842e-06
[32m[0324 06:24:37 @group.py:42][0m Callbacks took 115.854 sec in total. InferenceRunner: 114.609sec
[32m[0324 06:24:37 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14026/173481[03:00<34:06,77.92it/s]  9%|8         |14849/173481[03:10<33:55,77.92it/s] 17%|#6        |28953/173481[06:00<29:58,80.34it/s] 17%|#7        |29788/173481[06:10<29:48,80.34it/s] 26%|##5       |44360/173481[09:00<25:57,82.89it/s] 26%|##6       |45270/173481[09:10<25:46,82.89it/s] 35%|###5      |60730/173481[12:00<21:40,86.73it/s] 36%|###5      |61618/173481[12:10<21:29,86.73it/s] 43%|####3     |75253/173481[15:00<19:35,83.59it/s] 44%|####3     |76110/173481[15:10<19:24,83.59it/s] 51%|#####     |88446/173481[18:00<18:08,78.10it/s] 51%|#####1    |89316/173481[18:10<17:57,78.10it/s] 58%|#####8    |100699/173481[21:00<16:40,72.74it/s] 58%|#####8    |101417/173481[21:11<16:30,72.74it/s] 65%|######4   |112505/173481[24:00<14:43,68.98it/s] 65%|######5   |113260/173481[24:11<14:33,68.98it/s] 72%|#######1  |124482/173481[27:00<12:03,67.74it/s] 72%|#######2  |125247/173481[27:11<11:52,67.74it/s] 78%|#######8  |136108/173481[30:00<09:25,66.12it/s] 79%|#######8  |136640/173481[30:11<09:17,66.12it/s] 85%|########5 |147670/173481[33:00<06:36,65.17it/s] 86%|########5 |148421/173481[33:11<06:24,65.17it/s] 92%|#########1|158964/173481[36:00<03:47,63.93it/s] 92%|#########2|159718/173481[36:11<03:35,63.93it/s] 99%|#########9|171868/173481[39:00<00:23,67.59it/s]100%|#########9|172676/173481[39:12<00:11,67.59it/s]100%|##########|173481/173481[39:24<00:00,73.38it/s]
[32m[0324 07:04:01 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:2364.02 sec.
[32m[0324 07:04:01 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.40it/s]
25
[32m[0324 07:06:03 @monitor.py:363][0m QueueInput/queue_size: 1.0596
[32m[0324 07:06:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.038
[32m[0324 07:06:03 @monitor.py:363][0m activation-summaries/output-rms: 0.041302
[32m[0324 07:06:03 @monitor.py:363][0m cross_entropy_loss: 1.5992
[32m[0324 07:06:03 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48452
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5418e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35868
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8987e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46365
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9079e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35054
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1366e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46907
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5206e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35109
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6058e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46685
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4139e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34938
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8948e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49206
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8859e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35596
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4535e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59282
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2662
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32416
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31411
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30566
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 07:06:03 @monitor.py:363][0m train-error-top1: 0.4252
[32m[0324 07:06:03 @monitor.py:363][0m val-error-top1: 0.43748
[32m[0324 07:06:03 @monitor.py:363][0m val-utt-error: 0.099936
[32m[0324 07:06:03 @monitor.py:363][0m validation_cost: 1.6389
[32m[0324 07:06:03 @monitor.py:363][0m wd_cost: 2.3879e-06
[32m[0324 07:06:03 @group.py:42][0m Callbacks took 121.349 sec in total. InferenceRunner: 121.139sec
[32m[0324 07:06:03 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12475/173481[03:00<38:43,69.30it/s]  8%|7         |13218/173481[03:10<38:32,69.30it/s] 15%|#4        |25574/173481[06:00<34:43,70.99it/s] 15%|#5        |26310/173481[06:10<34:33,70.99it/s] 22%|##1       |37525/173481[09:00<33:01,68.61it/s] 22%|##1       |38125/173481[09:10<32:52,68.61it/s] 28%|##7       |48148/173481[12:00<32:55,63.45it/s] 28%|##8       |48794/173481[12:10<32:45,63.45it/s] 34%|###4      |59374/173481[15:00<30:14,62.90it/s] 35%|###4      |60054/173481[15:10<30:03,62.90it/s] 41%|####      |70361/173481[18:00<27:44,61.96it/s] 41%|####      |71060/173481[18:10<27:33,61.96it/s] 47%|####7     |81850/173481[21:00<24:17,62.87it/s] 48%|####7     |82550/173481[21:11<24:06,62.87it/s] 54%|#####3    |93575/173481[24:00<20:48,63.98it/s] 54%|#####4    |94318/173481[24:11<20:37,63.98it/s] 61%|######    |105058/173481[27:00<17:51,63.89it/s] 61%|######    |105813/173481[27:11<17:39,63.89it/s] 67%|######7   |116806/173481[30:00<14:37,64.57it/s] 68%|######7   |117532/173481[30:11<14:26,64.57it/s] 74%|#######3  |127864/173481[33:00<12:04,62.96it/s] 74%|#######4  |128584/173481[33:11<11:53,62.96it/s] 80%|#######9  |138618/173481[36:00<09:28,61.31it/s] 80%|########  |139339/173481[36:11<09:16,61.31it/s] 86%|########6 |149452/173481[39:00<06:35,60.74it/s] 87%|########6 |150194/173481[39:12<06:23,60.74it/s] 93%|#########2|160820/173481[42:00<03:24,61.92it/s] 93%|#########3|161597/173481[42:12<03:11,61.92it/s] 99%|#########8|171486/173481[45:00<00:32,60.56it/s] 99%|#########9|172374/173481[45:12<00:18,60.56it/s]100%|##########|173481/173481[45:27<00:00,63.61it/s]
[32m[0324 07:51:30 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:2727.37 sec.
[32m[0324 07:51:30 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:23<00:00,130.74it/s]
26
[32m[0324 07:53:54 @monitor.py:363][0m QueueInput/queue_size: 0.80793
[32m[0324 07:53:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.186
[32m[0324 07:53:54 @monitor.py:363][0m activation-summaries/output-rms: 0.040807
[32m[0324 07:53:54 @monitor.py:363][0m cross_entropy_loss: 1.6141
[32m[0324 07:53:54 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48456
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5409e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35872
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8986e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46373
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9065e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35053
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1373e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46911
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5209e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35108
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6064e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.4669
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.415e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.3494
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8948e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4921
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8865e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35596
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4543e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59372
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2663
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32421
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31414
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30568
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 07:53:54 @monitor.py:363][0m train-error-top1: 0.43829
[32m[0324 07:53:54 @monitor.py:363][0m val-error-top1: 0.43691
[32m[0324 07:53:54 @monitor.py:363][0m val-utt-error: 0.09983
[32m[0324 07:53:54 @monitor.py:363][0m validation_cost: 1.6378
[32m[0324 07:53:54 @monitor.py:363][0m wd_cost: 2.3917e-06
[32m[0324 07:53:54 @group.py:42][0m Callbacks took 144.266 sec in total. InferenceRunner: 143.981sec
[32m[0324 07:53:54 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13714/173481[03:00<34:57,76.18it/s]  8%|8         |14457/173481[03:10<34:47,76.18it/s] 15%|#5        |26798/173481[06:00<32:51,74.39it/s] 16%|#5        |27532/173481[06:10<32:41,74.39it/s] 23%|##2       |39658/173481[09:00<30:36,72.89it/s] 23%|##3       |40399/173481[09:10<30:25,72.89it/s] 29%|##9       |51091/173481[12:00<30:03,67.88it/s] 30%|##9       |51754/173481[12:10<29:53,67.88it/s] 36%|###5      |61904/173481[15:00<29:10,63.73it/s] 36%|###6      |62599/173481[15:10<28:59,63.73it/s] 43%|####2     |73757/173481[18:00<25:39,64.77it/s] 43%|####2     |74489/173481[18:10<25:28,64.77it/s] 49%|####9     |85715/173481[21:00<22:18,65.59it/s] 50%|####9     |86462/173481[21:11<22:06,65.59it/s] 56%|#####6    |97354/173481[24:00<19:29,65.12it/s] 57%|#####6    |98044/173481[24:11<19:18,65.12it/s] 63%|######2   |108599/173481[27:00<16:57,63.77it/s] 63%|######3   |109295/173481[27:11<16:46,63.77it/s] 70%|######9   |120744/173481[30:00<13:24,65.57it/s] 70%|######9   |121435/173481[30:11<13:13,65.57it/s] 76%|#######6  |132049/173481[33:00<10:45,64.15it/s] 77%|#######6  |132793/173481[33:11<10:34,64.15it/s] 83%|########2 |143691/173481[36:00<07:42,64.41it/s] 83%|########3 |144484/173481[36:11<07:30,64.41it/s] 89%|########9 |154568/173481[39:00<05:03,62.36it/s] 90%|########9 |155562/173481[39:12<04:47,62.36it/s] 96%|#########6|167296/173481[42:00<01:33,66.27it/s] 97%|#########6|168082/173481[42:12<01:21,66.27it/s]100%|##########|173481/173481[43:34<00:00,66.36it/s]
[32m[0324 08:37:28 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:2614.15 sec.
[32m[0324 08:37:29 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-4857468.
[32m[0324 08:37:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.30it/s]
27
[32m[0324 08:39:37 @monitor.py:363][0m QueueInput/queue_size: 0.67745
[32m[0324 08:39:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.393
[32m[0324 08:39:37 @monitor.py:363][0m activation-summaries/output-rms: 0.041083
[32m[0324 08:39:37 @monitor.py:363][0m cross_entropy_loss: 1.6083
[32m[0324 08:39:37 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4846
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5418e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8982e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46378
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9074e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35054
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1379e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46916
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5218e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3511
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6066e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46698
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4159e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.3494
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.895e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49217
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8845e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35596
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4543e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59426
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32423
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31415
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30568
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 08:39:37 @monitor.py:363][0m train-error-top1: 0.43164
[32m[0324 08:39:37 @monitor.py:363][0m val-error-top1: 0.437
[32m[0324 08:39:37 @monitor.py:363][0m val-utt-error: 0.09813
[32m[0324 08:39:37 @monitor.py:363][0m validation_cost: 1.6375
[32m[0324 08:39:37 @monitor.py:363][0m wd_cost: 4.788e-07
[32m[0324 08:39:37 @group.py:42][0m Callbacks took 128.262 sec in total. InferenceRunner: 127.790sec
[32m[0324 08:39:37 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14520/173481[03:00<32:50,80.66it/s]  9%|8         |15142/173481[03:10<32:42,80.66it/s] 15%|#4        |25384/173481[06:00<35:44,69.05it/s] 15%|#4        |26008/173481[06:10<35:35,69.05it/s] 21%|##1       |36933/173481[09:00<34:13,66.51it/s] 22%|##1       |37644/173481[09:10<34:02,66.51it/s] 28%|##8       |48862/173481[12:00<31:17,66.39it/s] 29%|##8       |49611/173481[12:10<31:05,66.39it/s] 35%|###4      |60457/173481[15:00<28:48,65.39it/s] 35%|###5      |61148/173481[15:10<28:37,65.39it/s] 42%|####1     |72387/173481[18:00<25:35,65.83it/s] 42%|####2     |73122/173481[18:10<25:24,65.83it/s] 48%|####8     |83432/173481[21:00<23:37,63.52it/s] 49%|####8     |84332/173481[21:11<23:23,63.52it/s] 55%|#####5    |96068/173481[24:00<19:20,66.69it/s] 56%|#####5    |96813/173481[24:11<19:09,66.69it/s] 62%|######2   |108107/173481[27:00<16:18,66.78it/s] 63%|######2   |108851/173481[27:11<16:07,66.78it/s] 69%|######9   |120123/173481[30:00<13:19,66.76it/s] 70%|######9   |120912/173481[30:11<13:07,66.76it/s] 76%|#######6  |132145/173481[33:00<10:19,66.77it/s] 77%|#######6  |132891/173481[33:11<10:07,66.77it/s] 83%|########3 |144120/173481[36:00<07:20,66.65it/s] 84%|########3 |145047/173481[36:11<07:06,66.65it/s] 90%|######### |156380/173481[39:00<04:13,67.37it/s] 91%|######### |157140/173481[39:12<04:02,67.37it/s] 97%|#########7|168393/173481[42:00<01:15,67.05it/s] 98%|#########7|169215/173481[42:12<01:03,67.05it/s]100%|##########|173481/173481[43:19<00:00,66.74it/s]
[32m[0324 09:22:56 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:2599.19 sec.
[32m[0324 09:22:56 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-5030949.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:10<00:00,144.56it/s]
28
[32m[0324 09:25:06 @monitor.py:363][0m QueueInput/queue_size: 0.68179
[32m[0324 09:25:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.238
[32m[0324 09:25:06 @monitor.py:363][0m activation-summaries/output-rms: 0.040545
[32m[0324 09:25:06 @monitor.py:363][0m cross_entropy_loss: 1.6244
[32m[0324 09:25:06 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48467
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5426e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35874
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8977e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46381
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9082e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35054
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1379e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46921
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.523e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35111
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46701
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.415e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34941
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8946e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49222
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8847e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35597
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4543e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5947
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32426
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31416
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30569
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 09:25:06 @monitor.py:363][0m train-error-top1: 0.43809
[32m[0324 09:25:06 @monitor.py:363][0m val-error-top1: 0.43677
[32m[0324 09:25:06 @monitor.py:363][0m val-utt-error: 0.10004
[32m[0324 09:25:06 @monitor.py:363][0m validation_cost: 1.6358
[32m[0324 09:25:06 @monitor.py:363][0m wd_cost: 4.7917e-07
[32m[0324 09:25:06 @group.py:42][0m Callbacks took 130.402 sec in total. InferenceRunner: 130.211sec
[32m[0324 09:25:06 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12947/173481[03:00<37:18,71.72it/s]  8%|8         |14381/173481[03:20<36:58,71.72it/s] 15%|#5        |26296/173481[06:00<33:38,72.92it/s] 16%|#5        |27755/173481[06:20<33:18,72.92it/s] 23%|##2       |39396/173481[09:00<30:40,72.85it/s] 24%|##3       |40868/173481[09:20<30:20,72.85it/s] 30%|###       |52578/173481[12:00<27:35,73.04it/s] 31%|###       |53298/173481[12:10<27:25,73.04it/s] 38%|###7      |65516/173481[15:00<24:50,72.45it/s] 38%|###8      |66251/173481[15:10<24:39,72.45it/s] 45%|####4     |77835/173481[18:00<22:38,70.39it/s] 45%|####5     |78731/173481[18:10<22:26,70.39it/s] 54%|#####3    |93127/173481[21:00<17:23,76.99it/s] 54%|#####4    |94017/173481[21:11<17:12,76.99it/s] 62%|######2   |108381/173481[24:00<13:26,80.68it/s] 63%|######2   |109291/173481[24:11<13:15,80.68it/s] 71%|#######1  |123627/173481[27:00<10:03,82.64it/s] 72%|#######1  |124550/173481[27:11<09:52,82.64it/s] 80%|#######9  |138122/173481[30:00<07:13,81.55it/s] 80%|#######9  |138481/173481[30:11<07:09,81.55it/s] 87%|########6 |150563/173481[33:00<05:06,74.82it/s] 87%|########7 |151261/173481[33:11<04:56,74.82it/s] 93%|#########3|161822/173481[36:00<02:51,68.13it/s] 94%|#########3|162526/173481[36:11<02:40,68.13it/s]100%|#########9|172793/173481[39:00<00:10,64.34it/s]100%|#########9|173431/173481[39:11<00:00,64.34it/s]100%|##########|173481/173481[39:12<00:00,73.73it/s]
[32m[0324 10:04:19 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:2352.78 sec.
[32m[0324 10:04:19 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-5204430.
[32m[0324 10:04:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,140.66it/s]
29
[32m[0324 10:06:34 @monitor.py:363][0m QueueInput/queue_size: 0.57869
[32m[0324 10:06:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.368
[32m[0324 10:06:34 @monitor.py:363][0m activation-summaries/output-rms: 0.042112
[32m[0324 10:06:34 @monitor.py:363][0m cross_entropy_loss: 1.6004
[32m[0324 10:06:34 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48467
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5414e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8977e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46388
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9085e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35058
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1379e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46925
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5225e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35111
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6063e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46704
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4147e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34941
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8942e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49228
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8834e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35598
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4546e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59512
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2665
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32428
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31417
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 10:06:34 @monitor.py:363][0m train-error-top1: 0.43303
[32m[0324 10:06:34 @monitor.py:363][0m val-error-top1: 0.4372
[32m[0324 10:06:34 @monitor.py:363][0m val-utt-error: 0.099564
[32m[0324 10:06:34 @monitor.py:363][0m validation_cost: 1.6383
[32m[0324 10:06:34 @monitor.py:363][0m wd_cost: 4.7953e-07
[32m[0324 10:06:34 @group.py:42][0m Callbacks took 134.544 sec in total. InferenceRunner: 133.824sec
[32m[0324 10:06:34 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13502/173481[03:00<35:32,75.01it/s]  8%|8         |14290/173481[03:10<35:22,75.01it/s] 16%|#5        |27367/173481[06:00<32:02,76.00it/s] 16%|#6        |28040/173481[06:10<31:53,76.00it/s] 22%|##2       |38290/173481[09:00<33:23,67.48it/s] 22%|##2       |38910/173481[09:10<33:14,67.48it/s] 28%|##8       |49390/173481[12:00<32:05,64.44it/s] 29%|##8       |50025/173481[12:10<31:55,64.44it/s] 35%|###4      |60501/173481[15:00<29:51,63.05it/s] 35%|###5      |61120/173481[15:10<29:41,63.05it/s] 41%|####1     |71406/173481[18:00<27:32,61.79it/s] 42%|####1     |72032/173481[18:10<27:21,61.79it/s] 48%|####7     |82932/173481[21:00<23:59,62.89it/s] 48%|####8     |83622/173481[21:11<23:48,62.89it/s] 54%|#####4    |94272/173481[24:00<20:58,62.94it/s] 55%|#####4    |95004/173481[24:11<20:46,62.94it/s] 61%|######    |105564/173481[27:00<18:00,62.84it/s] 61%|######1   |106277/173481[27:11<17:49,62.84it/s] 67%|######7   |116287/173481[30:00<15:35,61.16it/s] 67%|######7   |117039/173481[30:11<15:22,61.16it/s] 74%|#######3  |128077/173481[33:00<11:57,63.25it/s] 74%|#######4  |128847/173481[33:11<11:45,63.25it/s] 80%|########  |139368/173481[36:00<09:01,62.99it/s] 81%|########  |140075/173481[36:11<08:50,62.99it/s] 87%|########6 |150278/173481[39:00<06:15,61.78it/s] 87%|########7 |150995/173481[39:12<06:03,61.78it/s] 93%|#########2|161211/173481[42:00<03:20,61.25it/s] 93%|#########3|161965/173481[42:12<03:08,61.25it/s]100%|#########9|172993/173481[45:00<00:07,63.28it/s]100%|##########|173481/173481[45:06<00:00,64.09it/s]
[32m[0324 10:51:41 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:2706.97 sec.
[32m[0324 10:51:41 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-5377911.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.04it/s]
30
[32m[0324 10:54:07 @monitor.py:363][0m QueueInput/queue_size: 0.6281
[32m[0324 10:54:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.395
[32m[0324 10:54:07 @monitor.py:363][0m activation-summaries/output-rms: 0.041319
[32m[0324 10:54:07 @monitor.py:363][0m cross_entropy_loss: 1.597
[32m[0324 10:54:07 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48471
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5405e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35872
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8976e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46391
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.909e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1381e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46927
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5222e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35111
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6062e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46707
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4149e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34941
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49229
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8833e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35598
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4548e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59531
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2665
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32429
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31417
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 10:54:07 @monitor.py:363][0m train-error-top1: 0.42432
[32m[0324 10:54:07 @monitor.py:363][0m val-error-top1: 0.43723
[32m[0324 10:54:07 @monitor.py:363][0m val-utt-error: 0.099299
[32m[0324 10:54:07 @monitor.py:363][0m validation_cost: 1.6383
[32m[0324 10:54:07 @monitor.py:363][0m wd_cost: 9.5938e-08
[32m[0324 10:54:07 @group.py:42][0m Callbacks took 146.053 sec in total. InferenceRunner: 145.877sec
[32m[0324 10:54:07 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11888/173481[03:00<40:46,66.04it/s]  7%|7         |12516/173481[03:10<40:37,66.04it/s] 13%|#3        |22800/173481[06:00<39:43,63.22it/s] 13%|#3        |23386/173481[06:10<39:34,63.22it/s] 20%|##        |35030/173481[09:00<35:14,65.49it/s] 21%|##        |35688/173481[09:10<35:04,65.49it/s] 27%|##7       |47058/173481[12:00<31:51,66.15it/s] 28%|##7       |47774/173481[12:10<31:40,66.15it/s] 34%|###4      |59105/173481[15:00<28:39,66.54it/s] 35%|###4      |59851/173481[15:10<28:27,66.54it/s] 41%|####1     |71215/173481[18:00<25:28,66.90it/s] 41%|####1     |71907/173481[18:10<25:18,66.90it/s] 48%|####7     |82672/173481[21:00<23:12,65.23it/s] 48%|####8     |83383/173481[21:11<23:01,65.23it/s] 54%|#####4    |94141/173481[24:00<20:30,64.47it/s] 55%|#####4    |94844/173481[24:11<20:19,64.47it/s] 61%|######1   |106592/173481[27:00<16:42,66.73it/s] 62%|######2   |107572/173481[27:11<16:27,66.73it/s] 71%|#######   |122485/173481[30:00<11:10,76.02it/s] 71%|#######1  |123455/173481[30:11<10:58,76.02it/s] 78%|#######8  |135350/173481[33:00<08:37,73.67it/s] 78%|#######8  |135951/173481[33:11<08:29,73.67it/s] 84%|########3 |145660/173481[36:00<07:11,64.45it/s] 84%|########4 |146381/173481[36:11<07:00,64.45it/s] 91%|######### |157145/173481[39:00<04:14,64.12it/s] 91%|#########1|158145/173481[39:11<03:59,64.12it/s] 97%|#########7|168783/173481[42:00<01:12,64.39it/s] 98%|#########7|169587/173481[42:12<01:00,64.39it/s]100%|##########|173481/173481[43:15<00:00,66.85it/s]
[32m[0324 11:37:22 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:2595.13 sec.
[32m[0324 11:37:22 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.03it/s]
31
[32m[0324 11:39:48 @monitor.py:363][0m QueueInput/queue_size: 0.69069
[32m[0324 11:39:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.444
[32m[0324 11:39:48 @monitor.py:363][0m activation-summaries/output-rms: 0.040844
[32m[0324 11:39:48 @monitor.py:363][0m cross_entropy_loss: 1.6119
[32m[0324 11:39:48 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48472
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8978e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46392
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9092e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1383e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46927
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5222e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35111
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6063e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46708
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4149e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34941
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49229
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8835e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35598
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4551e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5955
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2665
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3243
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31417
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 11:39:48 @monitor.py:363][0m train-error-top1: 0.43774
[32m[0324 11:39:48 @monitor.py:363][0m val-error-top1: 0.43667
[32m[0324 11:39:48 @monitor.py:363][0m val-utt-error: 0.099246
[32m[0324 11:39:48 @monitor.py:363][0m validation_cost: 1.6367
[32m[0324 11:39:48 @monitor.py:363][0m wd_cost: 9.5969e-08
[32m[0324 11:39:48 @group.py:42][0m Callbacks took 146.065 sec in total. InferenceRunner: 145.892sec
[32m[0324 11:39:48 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13937/173481[03:00<34:20,77.43it/s]  8%|8         |14741/173481[03:10<34:10,77.43it/s] 16%|#5        |27399/173481[06:00<32:00,76.08it/s] 16%|#6        |28157/173481[06:10<31:50,76.08it/s] 22%|##2       |38364/173481[09:00<33:17,67.66it/s] 22%|##2       |39003/173481[09:10<33:07,67.66it/s] 28%|##8       |48971/173481[12:00<32:56,62.99it/s] 29%|##8       |49593/173481[12:10<32:46,62.99it/s] 34%|###4      |59424/173481[15:00<31:27,60.43it/s] 35%|###4      |60073/173481[15:10<31:16,60.43it/s] 41%|####      |70627/173481[18:00<27:57,61.32it/s] 41%|####1     |71258/173481[18:10<27:47,61.32it/s] 47%|####7     |82187/173481[21:00<24:15,62.74it/s] 48%|####7     |82993/173481[21:11<24:02,62.74it/s] 54%|#####4    |94247/173481[24:00<20:22,64.80it/s] 55%|#####4    |95050/173481[24:11<20:10,64.80it/s] 61%|######    |105535/173481[27:00<17:46,63.73it/s] 61%|######1   |106236/173481[27:11<17:35,63.73it/s] 68%|######7   |117266/173481[30:00<14:32,64.44it/s] 68%|######8   |117984/173481[30:11<14:21,64.44it/s] 74%|#######4  |128404/173481[33:00<11:54,63.12it/s] 74%|#######4  |129037/173481[33:11<11:44,63.12it/s] 80%|#######9  |138206/173481[36:00<10:03,58.47it/s] 80%|########  |138958/173481[36:11<09:50,58.47it/s] 85%|########5 |148014/173481[39:00<07:31,56.41it/s] 86%|########5 |148674/173481[39:12<07:19,56.41it/s] 91%|#########1|157868/173481[42:00<04:41,55.56it/s] 91%|#########1|158445/173481[42:12<04:30,55.56it/s] 95%|#########5|165304/173481[45:00<02:52,47.39it/s] 96%|#########5|165753/173481[45:12<02:43,47.39it/s] 99%|#########9|172609/173481[48:00<00:19,43.71it/s]100%|#########9|173058/173481[48:12<00:09,43.71it/s]100%|##########|173481/173481[48:23<00:00,59.75it/s]
[32m[0324 12:28:11 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:2903.56 sec.
[32m[0324 12:28:12 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-5724873.
[32m[0324 12:28:12 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:55<00:00,107.39it/s]
32
[32m[0324 12:31:07 @monitor.py:363][0m QueueInput/queue_size: 0.608
[32m[0324 12:31:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.606
[32m[0324 12:31:07 @monitor.py:363][0m activation-summaries/output-rms: 0.041078
[32m[0324 12:31:07 @monitor.py:363][0m cross_entropy_loss: 1.6074
[32m[0324 12:31:07 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48473
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5399e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8978e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46394
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9098e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1385e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46928
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5223e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35111
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6063e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.4671
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4153e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34941
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8942e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49231
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8837e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35598
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.455e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59562
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2666
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 12:31:07 @monitor.py:363][0m train-error-top1: 0.43085
[32m[0324 12:31:07 @monitor.py:363][0m val-error-top1: 0.43689
[32m[0324 12:31:07 @monitor.py:363][0m val-utt-error: 0.09813
[32m[0324 12:31:07 @monitor.py:363][0m validation_cost: 1.6371
[32m[0324 12:31:07 @monitor.py:363][0m wd_cost: 9.599e-08
[32m[0324 12:31:07 @group.py:42][0m Callbacks took 175.891 sec in total. InferenceRunner: 175.293sec
[32m[0324 12:31:07 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7765/173481[03:00<1:04:01,43.14it/s]  5%|4         |8152/173481[03:10<1:03:52,43.14it/s]  9%|8         |15268/173481[06:00<1:02:11,42.40it/s]  9%|9         |15657/173481[06:10<1:02:02,42.40it/s] 13%|#3        |22638/173481[09:00<1:00:21,41.66it/s] 13%|#3        |23097/173481[09:10<1:00:10,41.66it/s] 17%|#7        |30268/173481[12:00<56:48,42.02it/s]   18%|#7        |30707/173481[12:10<56:38,42.02it/s] 22%|##1       |37532/173481[15:00<55:02,41.17it/s] 22%|##1       |37918/173481[15:10<54:52,41.17it/s] 25%|##5       |43673/173481[18:00<58:00,37.30it/s] 25%|##5       |44052/173481[18:10<57:49,37.30it/s] 29%|##8       |49545/173481[21:00<59:20,34.80it/s] 29%|##8       |49867/173481[21:11<59:11,34.80it/s] 32%|###1      |55218/173481[24:00<59:35,33.07it/s] 32%|###2      |55579/173481[24:11<59:24,33.07it/s] 35%|###5      |61329/173481[27:00<55:47,33.51it/s] 36%|###5      |61697/173481[27:11<55:36,33.51it/s] 39%|###9      |67707/173481[30:00<51:11,34.44it/s] 39%|###9      |68122/173481[30:11<50:59,34.44it/s] 43%|####3     |75093/173481[33:00<43:47,37.44it/s] 44%|####3     |75577/173481[33:11<43:34,37.44it/s] 48%|####7     |82978/173481[36:00<37:21,40.37it/s] 48%|####8     |83505/173481[36:11<37:08,40.37it/s] 52%|#####2    |91073/173481[39:00<32:17,42.54it/s] 53%|#####2    |91607/173481[39:12<32:04,42.54it/s] 57%|#####7    |99463/173481[42:00<27:44,44.48it/s] 58%|#####7    |100037/173481[42:12<27:31,44.48it/s] 63%|######2   |108531/173481[45:00<22:54,47.24it/s] 63%|######2   |109117/173481[45:12<22:42,47.24it/s] 68%|######7   |117898/173481[48:00<18:42,49.52it/s] 68%|######8   |118467/173481[48:12<18:30,49.52it/s] 73%|#######3  |127347/173481[51:00<15:05,50.97it/s] 74%|#######3  |128022/173481[51:12<14:51,50.97it/s] 79%|#######8  |136903/173481[54:00<11:43,52.00it/s] 79%|#######9  |137585/173481[54:13<11:30,52.00it/s] 84%|########4 |146432/173481[57:00<08:35,52.47it/s] 85%|########4 |147097/173481[57:13<08:22,52.47it/s] 90%|########9 |155843/173481[1:00:00<05:36,52.37it/s] 90%|######### |156517/173481[1:00:13<05:23,52.37it/s] 95%|#########5|165098/173481[1:03:00<02:41,51.89it/s] 96%|#########5|165762/173481[1:03:13<02:28,51.89it/s]100%|##########|173481/173481[1:05:45<00:00,43.97it/s]
[32m[0324 13:36:53 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:3945.37 sec.
[32m[0324 13:36:53 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:26<00:00,128.40it/s]
33
[32m[0324 13:39:19 @monitor.py:363][0m QueueInput/queue_size: 0.90217
[32m[0324 13:39:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.405
[32m[0324 13:39:19 @monitor.py:363][0m activation-summaries/output-rms: 0.040531
[32m[0324 13:39:19 @monitor.py:363][0m cross_entropy_loss: 1.6237
[32m[0324 13:39:19 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48474
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.54e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35874
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46394
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9098e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1385e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46929
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5225e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6064e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.4671
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4152e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8942e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49232
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4549e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59562
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2665
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30571
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 13:39:19 @monitor.py:363][0m train-error-top1: 0.43702
[32m[0324 13:39:19 @monitor.py:363][0m val-error-top1: 0.43668
[32m[0324 13:39:19 @monitor.py:363][0m val-utt-error: 0.099883
[32m[0324 13:39:19 @monitor.py:363][0m validation_cost: 1.6355
[32m[0324 13:39:19 @monitor.py:363][0m wd_cost: 1.9198e-08
[32m[0324 13:39:19 @group.py:42][0m Callbacks took 146.766 sec in total. InferenceRunner: 146.610sec
[32m[0324 13:39:19 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9912/173481[03:00<49:30,55.06it/s]  6%|6         |10461/173481[03:10<49:20,55.06it/s] 11%|#1        |19553/173481[06:00<47:14,54.30it/s] 12%|#1        |20111/173481[06:10<47:04,54.30it/s] 17%|#6        |29174/173481[09:00<44:38,53.87it/s] 17%|#7        |29757/173481[09:10<44:27,53.87it/s] 23%|##2       |39062/173481[12:00<41:11,54.39it/s] 23%|##2       |39631/173481[12:10<41:00,54.39it/s] 28%|##8       |48949/173481[15:00<37:58,54.66it/s] 29%|##8       |49527/173481[15:10<37:47,54.66it/s] 34%|###3      |58722/173481[18:00<35:06,54.47it/s] 34%|###4      |59308/173481[18:10<34:56,54.47it/s] 39%|###9      |68277/173481[21:00<32:36,53.76it/s] 40%|###9      |68864/173481[21:11<32:26,53.76it/s] 44%|####4     |76847/173481[24:00<31:53,50.50it/s] 45%|####4     |77407/173481[24:11<31:42,50.50it/s] 49%|####9     |85801/173481[27:00<29:09,50.12it/s] 50%|####9     |86178/173481[27:11<29:01,50.12it/s] 55%|#####4    |94785/173481[30:00<26:13,50.01it/s] 55%|#####4    |95346/173481[30:11<26:02,50.01it/s] 60%|#####9    |103662/173481[33:00<23:25,49.66it/s] 60%|######    |104261/173481[33:11<23:13,49.66it/s] 65%|######4   |112135/173481[36:00<21:09,48.33it/s] 65%|######4   |112733/173481[36:11<20:56,48.33it/s] 70%|#######   |122107/173481[39:00<16:35,51.62it/s] 71%|#######   |122811/173481[39:12<16:21,51.62it/s] 76%|#######6  |132287/173481[42:00<12:43,53.97it/s] 77%|#######6  |132943/173481[42:12<12:31,53.97it/s] 82%|########2 |142488/173481[45:00<09:20,55.28it/s] 83%|########2 |143166/173481[45:12<09:08,55.28it/s] 88%|########8 |152731/173481[48:00<06:09,56.08it/s] 88%|########8 |153441/173481[48:12<05:57,56.08it/s] 94%|#########3|162984/173481[51:00<03:05,56.52it/s] 94%|#########4|163566/173481[51:12<02:55,56.52it/s]100%|#########9|173087/173481[54:00<00:06,56.32it/s]100%|##########|173481/173481[54:07<00:00,53.41it/s]
[32m[0324 14:33:27 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:3247.92 sec.
[32m[0324 14:33:27 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-6071835.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:23<00:00,130.98it/s]
34
[32m[0324 14:35:51 @monitor.py:363][0m QueueInput/queue_size: 0.57297
[32m[0324 14:35:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.489
[32m[0324 14:35:51 @monitor.py:363][0m activation-summaries/output-rms: 0.042122
[32m[0324 14:35:51 @monitor.py:363][0m cross_entropy_loss: 1.6002
[32m[0324 14:35:51 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48474
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5401e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35874
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46396
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35057
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1387e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4693
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5225e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6064e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46711
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4154e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8942e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49233
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8834e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59562
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2665
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30571
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 14:35:51 @monitor.py:363][0m train-error-top1: 0.43434
[32m[0324 14:35:51 @monitor.py:363][0m val-error-top1: 0.43717
[32m[0324 14:35:51 @monitor.py:363][0m val-utt-error: 0.099724
[32m[0324 14:35:51 @monitor.py:363][0m validation_cost: 1.638
[32m[0324 14:35:51 @monitor.py:363][0m wd_cost: 1.9199e-08
[32m[0324 14:35:51 @group.py:42][0m Callbacks took 143.863 sec in total. InferenceRunner: 143.716sec
[32m[0324 14:35:51 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9977/173481[03:00<49:09,55.43it/s]  6%|6         |10526/173481[03:10<49:00,55.43it/s] 11%|#1        |19486/173481[06:00<47:26,54.09it/s] 12%|#1        |20020/173481[06:10<47:17,54.09it/s] 17%|#6        |28918/173481[09:00<45:15,53.23it/s] 17%|#6        |29438/173481[09:10<45:05,53.23it/s] 22%|##1       |37947/173481[12:00<43:44,51.65it/s] 22%|##2       |38467/173481[12:10<43:34,51.65it/s] 27%|##6       |46205/173481[15:00<43:39,48.59it/s] 27%|##6       |46685/173481[15:10<43:29,48.59it/s] 31%|###1      |54272/173481[18:00<42:36,46.63it/s] 32%|###1      |54785/173481[18:10<42:25,46.63it/s] 36%|###6      |62491/173481[21:00<40:06,46.13it/s] 36%|###6      |63010/173481[21:11<39:54,46.13it/s] 41%|####      |70676/173481[24:00<37:24,45.80it/s] 41%|####1     |71151/173481[24:11<37:14,45.80it/s] 45%|####5     |78366/173481[27:00<35:52,44.20it/s] 45%|####5     |78856/173481[27:11<35:41,44.20it/s] 50%|####9     |86396/173481[30:00<32:41,44.40it/s] 50%|#####     |86905/173481[30:11<32:30,44.40it/s] 55%|#####4    |94735/173481[33:00<28:56,45.34it/s] 55%|#####4    |95231/173481[33:11<28:45,45.34it/s] 59%|#####9    |102660/173481[36:00<26:25,44.67it/s] 59%|#####9    |103165/173481[36:11<26:13,44.67it/s] 64%|######3   |110579/173481[39:00<23:38,44.33it/s] 64%|######4   |111115/173481[39:12<23:26,44.33it/s] 69%|######8   |118991/173481[42:00<19:57,45.50it/s] 69%|######8   |119553/173481[42:12<19:45,45.50it/s] 74%|#######3  |127666/173481[45:00<16:18,46.81it/s] 74%|#######3  |128239/173481[45:12<16:06,46.81it/s] 78%|#######8  |135987/173481[48:00<13:26,46.51it/s] 79%|#######8  |136515/173481[48:12<13:14,46.51it/s] 83%|########3 |144326/173481[51:00<10:28,46.38it/s] 83%|########3 |144465/173481[51:12<10:25,46.38it/s] 88%|########8 |152696/173481[54:00<07:27,46.44it/s] 88%|########8 |153345/173481[54:12<07:13,46.44it/s] 93%|#########3|162200/173481[57:00<03:48,49.41it/s] 94%|#########3|162842/173481[57:12<03:35,49.41it/s] 99%|#########8|171418/173481[1:00:00<00:41,50.30it/s] 99%|#########9|172020/173481[1:00:13<00:29,50.30it/s]100%|##########|173481/173481[1:00:42<00:00,47.62it/s]
[32m[0324 15:36:34 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:3642.74 sec.
[32m[0324 15:36:34 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:08<00:00,146.08it/s]
35
[32m[0324 15:38:43 @monitor.py:363][0m QueueInput/queue_size: 0.659
[32m[0324 15:38:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.487
[32m[0324 15:38:43 @monitor.py:363][0m activation-summaries/output-rms: 0.041313
[32m[0324 15:38:43 @monitor.py:363][0m cross_entropy_loss: 1.5961
[32m[0324 15:38:43 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48475
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46397
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9102e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1385e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5224e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46712
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8942e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8837e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59553
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32432
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30571
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 15:38:43 @monitor.py:363][0m train-error-top1: 0.42477
[32m[0324 15:38:43 @monitor.py:363][0m val-error-top1: 0.43721
[32m[0324 15:38:43 @monitor.py:363][0m val-utt-error: 0.09898
[32m[0324 15:38:43 @monitor.py:363][0m validation_cost: 1.6382
[32m[0324 15:38:43 @monitor.py:363][0m wd_cost: 3.8391e-09
[32m[0324 15:38:43 @group.py:42][0m Callbacks took 129.062 sec in total. InferenceRunner: 128.856sec
[32m[0324 15:38:43 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8099/173481[03:00<1:01:15,44.99it/s]  5%|4         |8584/173481[03:10<1:01:04,44.99it/s] 10%|9         |16680/173481[06:00<56:27,46.29it/s]  10%|9         |17180/173481[06:10<56:16,46.29it/s] 15%|#4        |25245/173481[09:00<52:39,46.92it/s] 15%|#4        |25749/173481[09:10<52:28,46.92it/s] 19%|#9        |33650/173481[12:00<49:47,46.80it/s] 20%|#9        |34139/173481[12:10<49:37,46.80it/s] 24%|##4       |41696/173481[15:00<48:02,45.73it/s] 24%|##4       |42188/173481[15:10<47:51,45.73it/s] 28%|##8       |49055/173481[18:00<48:08,43.08it/s] 29%|##8       |49519/173481[18:10<47:57,43.08it/s] 33%|###3      |57346/173481[21:00<43:28,44.52it/s] 33%|###3      |57830/173481[21:11<43:17,44.52it/s] 38%|###7      |65096/173481[24:00<41:15,43.78it/s] 38%|###7      |65564/173481[24:11<41:05,43.78it/s] 42%|####2     |73225/173481[27:00<37:35,44.45it/s] 42%|####2     |73709/173481[27:11<37:24,44.45it/s] 46%|####6     |80510/173481[30:00<36:34,42.37it/s] 47%|####6     |80993/173481[30:11<36:22,42.37it/s] 51%|#####     |88275/173481[33:00<33:13,42.74it/s] 51%|#####1    |88532/173481[33:11<33:07,42.74it/s] 55%|#####5    |95668/173481[36:00<30:57,41.89it/s] 55%|#####5    |96159/173481[36:11<30:45,41.89it/s] 59%|#####9    |103074/173481[39:00<28:16,41.51it/s] 60%|#####9    |103533/173481[39:12<28:04,41.51it/s] 63%|######3   |109950/173481[42:01<26:37,39.78it/s] 64%|######3   |110380/173481[42:12<26:26,39.78it/s] 67%|######7   |116338/173481[45:01<25:23,37.51it/s] 67%|######7   |116799/173481[45:12<25:11,37.51it/s] 71%|#######   |122385/173481[48:01<24:01,35.44it/s] 71%|#######   |122828/173481[48:12<23:49,35.44it/s] 74%|#######4  |128967/173481[51:01<20:36,35.99it/s] 75%|#######4  |129347/173481[51:12<20:26,35.99it/s] 78%|#######8  |135545/173481[54:01<17:26,36.26it/s] 78%|#######8  |135999/173481[54:12<17:13,36.26it/s] 82%|########1 |142114/173481[57:01<14:22,36.38it/s] 82%|########2 |142611/173481[57:13<14:08,36.38it/s] 86%|########6 |149326/173481[1:00:01<10:33,38.13it/s] 86%|########6 |149777/173481[1:00:13<10:21,38.13it/s] 90%|######### |156647/173481[1:03:01<07:07,39.36it/s] 91%|######### |157149/173481[1:03:13<06:54,39.36it/s] 95%|#########4|164090/173481[1:06:01<03:52,40.33it/s] 95%|#########4|164605/173481[1:06:13<03:40,40.33it/s] 98%|#########8|170780/173481[1:09:01<01:09,38.68it/s] 99%|#########8|171304/173481[1:09:13<00:56,38.68it/s]100%|##########|173481/173481[1:10:07<00:00,41.23it/s]
[32m[0324 16:48:51 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:4207.69 sec.
[32m[0324 16:48:51 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s] 73%|#######2  |13724/18822[03:00<01:06,76.24it/s] 77%|#######6  |14492/18822[03:10<00:56,76.24it/s]100%|##########|18822/18822[04:07<00:00,75.96it/s]
36
[32m[0324 16:52:59 @monitor.py:363][0m QueueInput/queue_size: 0.67957
[32m[0324 16:52:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.5
[32m[0324 16:52:59 @monitor.py:363][0m activation-summaries/output-rms: 0.040851
[32m[0324 16:52:59 @monitor.py:363][0m cross_entropy_loss: 1.6115
[32m[0324 16:52:59 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48475
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46397
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5225e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46712
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8837e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59537
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30571
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 16:52:59 @monitor.py:363][0m train-error-top1: 0.43852
[32m[0324 16:52:59 @monitor.py:363][0m val-error-top1: 0.43666
[32m[0324 16:52:59 @monitor.py:363][0m val-utt-error: 0.099671
[32m[0324 16:52:59 @monitor.py:363][0m validation_cost: 1.6364
[32m[0324 16:52:59 @monitor.py:363][0m wd_cost: 3.8381e-09
[32m[0324 16:52:59 @group.py:42][0m Callbacks took 248.343 sec in total. InferenceRunner: 247.869sec
[32m[0324 16:52:59 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |7836/173481[03:00<1:03:25,43.53it/s]  5%|4         |8245/173481[03:10<1:03:15,43.53it/s]  9%|8         |15289/173481[06:00<1:02:07,42.44it/s]  9%|9         |15746/173481[06:10<1:01:56,42.44it/s] 13%|#3        |22860/173481[09:00<59:25,42.25it/s]   13%|#3        |23213/173481[09:10<59:16,42.25it/s] 17%|#7        |29509/173481[12:00<1:00:53,39.41it/s] 17%|#7        |29947/173481[12:10<1:00:41,39.41it/s] 21%|##        |35969/173481[15:00<1:01:02,37.55it/s] 21%|##        |36325/173481[15:10<1:00:52,37.55it/s] 25%|##4       |42884/173481[18:00<57:19,37.98it/s]   25%|##4       |43284/173481[18:10<57:08,37.98it/s] 29%|##8       |49662/173481[21:00<54:34,37.81it/s] 29%|##8       |50083/173481[21:11<54:23,37.81it/s] 33%|###2      |56799/173481[24:00<50:15,38.69it/s] 33%|###2      |57235/173481[24:11<50:04,38.69it/s] 37%|###6      |63945/173481[27:00<46:35,39.19it/s] 37%|###7      |64356/173481[27:11<46:24,39.19it/s] 41%|####      |71077/173481[30:00<43:18,39.40it/s] 41%|####1     |71538/173481[30:11<43:07,39.40it/s] 45%|####5     |78205/173481[33:00<40:12,39.50it/s] 45%|####5     |78671/173481[33:11<40:00,39.50it/s] 49%|####8     |84680/173481[36:00<39:18,37.65it/s] 49%|####9     |85127/173481[36:11<39:06,37.65it/s] 53%|#####2    |91610/173481[39:00<35:50,38.07it/s] 53%|#####3    |92025/173481[39:12<35:39,38.07it/s] 57%|#####6    |98359/173481[42:00<33:08,37.78it/s] 57%|#####6    |98823/173481[42:12<32:56,37.78it/s] 60%|######    |104919/173481[45:00<30:48,37.09it/s] 61%|######    |105394/173481[45:12<30:35,37.09it/s] 65%|######5   |112800/173481[48:00<25:10,40.16it/s] 65%|######5   |113339/173481[48:12<24:57,40.16it/s] 70%|######9   |120914/173481[51:00<20:37,42.48it/s] 70%|######9   |121425/173481[51:12<20:25,42.48it/s] 74%|#######3  |128339/173481[54:00<17:58,41.85it/s] 74%|#######4  |128885/173481[54:12<17:45,41.85it/s] 79%|#######8  |136504/173481[57:00<14:09,43.52it/s] 79%|#######9  |137078/173481[57:13<13:56,43.52it/s] 83%|########3 |144349/173481[1:00:00<11:08,43.55it/s] 84%|########3 |144912/173481[1:00:13<10:56,43.55it/s] 88%|########7 |152248/173481[1:03:00<08:05,43.71it/s] 88%|########8 |152764/173481[1:03:13<07:53,43.71it/s] 92%|#########2|160229/173481[1:06:00<05:01,44.02it/s] 93%|#########2|160803/173481[1:06:13<04:47,44.02it/s] 97%|#########7|169096/173481[1:09:00<01:34,46.50it/s] 98%|#########7|169724/173481[1:09:13<01:20,46.50it/s]100%|##########|173481/173481[1:10:48<00:00,40.83it/s]
[32m[0324 18:03:48 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:4249.08 sec.
[32m[0324 18:03:49 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-6592278.
[32m[0324 18:03:49 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 91%|######### |17064/18822[03:00<00:18,94.80it/s] 97%|#########6|18165/18822[03:10<00:06,94.80it/s]100%|##########|18822/18822[03:17<00:00,95.42it/s]
37
[32m[0324 18:07:06 @monitor.py:363][0m QueueInput/queue_size: 1.1543
[32m[0324 18:07:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.639
[32m[0324 18:07:06 @monitor.py:363][0m activation-summaries/output-rms: 0.041066
[32m[0324 18:07:06 @monitor.py:363][0m cross_entropy_loss: 1.6071
[32m[0324 18:07:06 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35874
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46397
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46712
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59521
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30571
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 18:07:06 @monitor.py:363][0m train-error-top1: 0.43103
[32m[0324 18:07:06 @monitor.py:363][0m val-error-top1: 0.43688
[32m[0324 18:07:06 @monitor.py:363][0m val-utt-error: 0.098449
[32m[0324 18:07:06 @monitor.py:363][0m validation_cost: 1.6369
[32m[0324 18:07:06 @monitor.py:363][0m wd_cost: 3.8371e-09
[32m[0324 18:07:06 @group.py:42][0m Callbacks took 198.192 sec in total. InferenceRunner: 197.296sec
[32m[0324 18:07:06 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9159/173481[03:00<53:49,50.88it/s]  6%|5         |9634/173481[03:10<53:40,50.88it/s] 10%|#         |17554/173481[06:00<53:24,48.67it/s] 10%|#         |18033/173481[06:10<53:14,48.67it/s] 15%|#4        |25783/173481[09:00<52:13,47.14it/s] 15%|#5        |26303/173481[09:10<52:02,47.14it/s] 20%|#9        |34273/173481[12:00<49:12,47.15it/s] 20%|##        |34817/173481[12:10<49:00,47.15it/s] 24%|##4       |41653/173481[15:00<50:05,43.86it/s] 24%|##4       |42161/173481[15:10<49:54,43.86it/s] 29%|##8       |49909/173481[18:00<45:55,44.84it/s] 29%|##9       |50439/173481[18:10<45:44,44.84it/s] 34%|###3      |58144/173481[21:00<42:26,45.29it/s] 34%|###3      |58673/173481[21:11<42:14,45.29it/s] 38%|###8      |66414/173481[24:00<39:07,45.61it/s] 39%|###8      |66883/173481[24:11<38:56,45.61it/s] 42%|####2     |73568/173481[27:00<39:12,42.47it/s] 43%|####2     |74000/173481[27:11<39:02,42.47it/s] 47%|####6     |80847/173481[30:00<37:16,41.43it/s] 47%|####6     |81303/173481[30:11<37:05,41.43it/s] 50%|#####     |87405/173481[33:00<37:00,38.77it/s] 51%|#####     |87860/173481[33:11<36:48,38.77it/s] 55%|#####4    |94887/173481[36:00<32:39,40.12it/s] 55%|#####5    |95449/173481[36:11<32:25,40.12it/s] 60%|#####9    |103613/173481[39:00<26:31,43.90it/s] 60%|######    |104202/173481[39:12<26:18,43.90it/s] 65%|######4   |112313/173481[42:00<22:09,46.01it/s] 65%|######5   |112884/173481[42:12<21:57,46.01it/s] 70%|######9   |120973/173481[45:00<18:37,46.98it/s] 70%|#######   |121551/173481[45:12<18:25,46.98it/s] 74%|#######4  |129218/173481[48:00<15:54,46.38it/s] 75%|#######4  |129765/173481[48:12<15:42,46.38it/s] 79%|#######8  |136698/173481[51:00<13:59,43.83it/s] 79%|#######9  |137306/173481[51:12<13:45,43.83it/s] 84%|########3 |145015/173481[54:00<10:32,44.99it/s] 84%|########3 |145592/173481[54:12<10:19,44.99it/s] 89%|########8 |153825/173481[57:00<06:59,46.88it/s] 89%|########9 |154415/173481[57:13<06:46,46.88it/s] 94%|#########3|162688/173481[1:00:00<03:44,48.03it/s] 94%|#########4|163295/173481[1:00:13<03:32,48.03it/s] 99%|#########8|171086/173481[1:03:00<00:50,47.33it/s] 99%|#########8|171659/173481[1:03:13<00:38,47.33it/s]100%|##########|173481/173481[1:03:56<00:00,45.22it/s]
[32m[0324 19:11:02 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:3836.07 sec.
[32m[0324 19:11:03 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14795/18822[03:00<00:49,82.15it/s] 79%|#######8  |14856/18822[03:10<00:48,82.15it/s]100%|##########|18822/18822[04:05<00:00,76.69it/s]
38
[32m[0324 19:15:09 @monitor.py:363][0m QueueInput/queue_size: 0.51449
[32m[0324 19:15:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.409
[32m[0324 19:15:09 @monitor.py:363][0m activation-summaries/output-rms: 0.0405
[32m[0324 19:15:09 @monitor.py:363][0m cross_entropy_loss: 1.6236
[32m[0324 19:15:09 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59496
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30571
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 19:15:09 @monitor.py:363][0m train-error-top1: 0.43832
[32m[0324 19:15:09 @monitor.py:363][0m val-error-top1: 0.43669
[32m[0324 19:15:09 @monitor.py:363][0m val-utt-error: 0.099724
[32m[0324 19:15:09 @monitor.py:363][0m validation_cost: 1.6354
[32m[0324 19:15:09 @monitor.py:363][0m wd_cost: 7.6709e-10
[32m[0324 19:15:09 @group.py:42][0m Callbacks took 246.302 sec in total. InferenceRunner: 245.443sec
[32m[0324 19:15:09 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8999/173481[03:00<54:50,49.99it/s]  5%|5         |9441/173481[03:10<54:41,49.99it/s] 10%|#         |17503/173481[06:00<53:30,48.58it/s] 10%|#         |18013/173481[06:10<53:20,48.58it/s] 15%|#4        |25986/173481[09:00<51:22,47.84it/s] 15%|#5        |26505/173481[09:10<51:12,47.84it/s] 20%|##        |34716/173481[12:00<48:00,48.17it/s] 20%|##        |35239/173481[12:10<47:50,48.17it/s] 25%|##4       |43333/173481[15:00<45:10,48.02it/s] 25%|##5       |43815/173481[15:10<45:00,48.02it/s] 29%|##9       |50570/173481[18:00<46:48,43.77it/s] 29%|##9       |50997/173481[18:11<46:38,43.77it/s] 34%|###3      |58382/173481[21:00<44:01,43.58it/s] 34%|###3      |58856/173481[21:11<43:50,43.58it/s] 38%|###8      |66097/173481[24:00<41:24,43.22it/s] 38%|###8      |66551/173481[24:11<41:14,43.22it/s] 42%|####2     |73627/173481[27:00<39:09,42.51it/s] 43%|####2     |74111/173481[27:11<38:57,42.51it/s] 47%|####6     |81137/173481[30:00<36:33,42.11it/s] 47%|####7     |81616/173481[30:11<36:21,42.11it/s] 51%|#####     |88212/173481[33:00<34:57,40.66it/s] 51%|#####1    |88710/173481[33:11<34:44,40.66it/s] 55%|#####4    |95012/173481[36:00<33:23,39.16it/s] 55%|#####5    |95511/173481[36:12<33:10,39.16it/s] 59%|#####9    |102572/173481[39:00<29:09,40.53it/s] 59%|#####9    |103111/173481[39:12<28:56,40.53it/s] 64%|######3   |110572/173481[42:00<24:43,42.39it/s] 64%|######4   |111123/173481[42:12<24:30,42.39it/s] 69%|######8   |119584/173481[45:00<19:33,45.91it/s] 69%|######9   |120261/173481[45:12<19:19,45.91it/s] 74%|#######4  |128430/173481[48:00<15:48,47.47it/s] 74%|#######4  |129042/173481[48:12<15:36,47.47it/s] 79%|#######9  |137377/173481[51:00<12:23,48.56it/s] 80%|#######9  |137963/173481[51:12<12:11,48.56it/s] 84%|########3 |145478/173481[54:00<09:59,46.72it/s] 84%|########4 |146114/173481[54:12<09:45,46.72it/s] 89%|########9 |154548/173481[57:00<06:30,48.48it/s] 89%|########9 |155231/173481[57:13<06:16,48.48it/s] 94%|#########4|163360/173481[1:00:00<03:27,48.72it/s] 95%|#########4|163947/173481[1:00:13<03:15,48.72it/s] 99%|#########8|171597/173481[1:03:00<00:39,47.19it/s] 99%|#########9|172252/173481[1:03:13<00:26,47.19it/s]100%|##########|173481/173481[1:03:39<00:00,45.42it/s][32m[0324 20:18:49 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:3819.93 sec.

[32m[0324 20:18:50 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-6939240.
  0%|          |0/18822[00:00<?,?it/s] 83%|########3 |15678/18822[03:00<00:36,87.10it/s] 88%|########7 |16490/18822[03:10<00:26,87.10it/s]100%|##########|18822/18822[03:37<00:00,86.49it/s]
39
[32m[0324 20:22:27 @monitor.py:363][0m QueueInput/queue_size: 1.6269
[32m[0324 20:22:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.461
[32m[0324 20:22:27 @monitor.py:363][0m activation-summaries/output-rms: 0.042088
[32m[0324 20:22:27 @monitor.py:363][0m cross_entropy_loss: 1.5999
[32m[0324 20:22:27 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35057
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59469
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30571
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 20:22:27 @monitor.py:363][0m train-error-top1: 0.4339
[32m[0324 20:22:27 @monitor.py:363][0m val-error-top1: 0.43717
[32m[0324 20:22:27 @monitor.py:363][0m val-utt-error: 0.099405
[32m[0324 20:22:27 @monitor.py:363][0m validation_cost: 1.6378
[32m[0324 20:22:27 @monitor.py:363][0m wd_cost: 7.6675e-10
[32m[0324 20:22:27 @group.py:42][0m Callbacks took 218.764 sec in total. InferenceRunner: 217.684sec
[32m[0324 20:22:27 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8199/173481[03:00<1:00:28,45.55it/s]  5%|4         |8617/173481[03:10<1:00:19,45.55it/s] 10%|9         |16481/173481[06:00<57:09,45.78it/s]  10%|9         |16949/173481[06:10<56:59,45.78it/s] 14%|#3        |23913/173481[09:00<57:24,43.42it/s] 14%|#4        |24383/173481[09:10<57:14,43.42it/s] 18%|#8        |31454/173481[12:00<55:30,42.64it/s] 18%|#8        |31884/173481[12:10<55:20,42.64it/s] 22%|##2       |38680/173481[15:00<54:19,41.35it/s] 23%|##2       |39125/173481[15:10<54:08,41.35it/s] 26%|##6       |45906/173481[18:00<52:11,40.74it/s] 27%|##6       |46363/173481[18:10<52:00,40.74it/s] 30%|###       |52556/173481[21:00<52:00,38.75it/s] 31%|###       |53001/173481[21:11<51:49,38.75it/s] 34%|###4      |59747/173481[24:00<48:11,39.34it/s] 35%|###4      |60210/173481[24:11<47:59,39.34it/s] 39%|###8      |66945/173481[27:00<44:46,39.66it/s] 39%|###8      |67396/173481[27:11<44:34,39.66it/s] 43%|####2     |73856/173481[30:00<42:33,39.01it/s] 43%|####2     |74325/173481[30:11<42:21,39.01it/s] 47%|####6     |80951/173481[33:00<39:19,39.21it/s] 47%|####6     |81457/173481[33:11<39:06,39.21it/s] 51%|#####     |88363/173481[36:00<35:18,40.17it/s] 51%|#####1    |88875/173481[36:11<35:06,40.17it/s] 55%|#####5    |96001/173481[39:00<31:17,41.27it/s] 56%|#####5    |96600/173481[39:12<31:02,41.27it/s] 60%|######    |104276/173481[42:00<26:31,43.49it/s] 60%|######    |104867/173481[42:12<26:17,43.49it/s] 65%|######5   |112949/173481[45:00<22:04,45.72it/s] 65%|######5   |113550/173481[45:12<21:50,45.72it/s] 70%|#######   |121651/173481[48:00<18:22,46.99it/s] 70%|#######   |122235/173481[48:12<18:10,46.99it/s] 75%|#######4  |129728/173481[51:00<15:53,45.91it/s] 75%|#######5  |130350/173481[51:12<15:39,45.91it/s] 80%|#######9  |138021/173481[54:00<12:51,45.99it/s] 80%|#######9  |138618/173481[54:12<12:38,45.99it/s] 84%|########3 |145056/173481[57:00<11:12,42.24it/s] 84%|########3 |145191/173481[57:13<11:09,42.24it/s] 88%|########8 |152746/173481[1:00:00<08:08,42.48it/s] 88%|########8 |153365/173481[1:00:13<07:53,42.48it/s] 93%|#########2|161020/173481[1:03:00<04:42,44.15it/s] 93%|#########3|161602/173481[1:03:13<04:29,44.15it/s] 98%|#########7|169151/173481[1:06:00<01:36,44.65it/s] 98%|#########7|169770/173481[1:06:13<01:23,44.65it/s]100%|##########|173481/173481[1:07:42<00:00,42.70it/s]
[32m[0324 21:30:10 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:4062.73 sec.
[32m[0324 21:30:11 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######8  |14703/18822[03:00<00:50,81.68it/s] 83%|########2 |15618/18822[03:10<00:39,81.68it/s]100%|##########|18822/18822[03:48<00:00,82.28it/s]
40
[32m[0324 21:33:59 @monitor.py:363][0m QueueInput/queue_size: 0.64066
[32m[0324 21:33:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.439
[32m[0324 21:33:59 @monitor.py:363][0m activation-summaries/output-rms: 0.041274
[32m[0324 21:33:59 @monitor.py:363][0m cross_entropy_loss: 1.5959
[32m[0324 21:33:59 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59444
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30571
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 21:33:59 @monitor.py:363][0m train-error-top1: 0.42464
[32m[0324 21:33:59 @monitor.py:363][0m val-error-top1: 0.43717
[32m[0324 21:33:59 @monitor.py:363][0m val-utt-error: 0.098821
[32m[0324 21:33:59 @monitor.py:363][0m validation_cost: 1.638
[32m[0324 21:33:59 @monitor.py:363][0m wd_cost: 7.6643e-10
[32m[0324 21:33:59 @group.py:42][0m Callbacks took 229.282 sec in total. InferenceRunner: 228.789sec
[32m[0324 21:33:59 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7485/173481[03:00<1:06:38,41.52it/s]  5%|4         |8089/173481[03:20<1:06:23,41.52it/s]  9%|8         |14760/173481[06:00<1:04:35,40.96it/s]  9%|8         |15164/173481[06:10<1:04:25,40.96it/s] 13%|#2        |22195/173481[09:00<1:01:18,41.12it/s] 13%|#3        |22644/173481[09:10<1:01:07,41.12it/s] 17%|#7        |29877/173481[12:00<57:08,41.88it/s]   17%|#7        |30309/173481[12:10<56:58,41.88it/s] 22%|##1       |37457/173481[15:00<53:58,42.00it/s] 22%|##1       |37881/173481[15:10<53:48,42.00it/s] 26%|##5       |44779/173481[18:00<51:54,41.33it/s] 26%|##6       |45203/173481[18:11<51:44,41.33it/s] 30%|##9       |51375/173481[21:00<52:23,38.84it/s] 30%|##9       |51812/173481[21:11<52:12,38.84it/s] 34%|###3      |58755/173481[24:00<47:56,39.88it/s] 34%|###4      |59192/173481[24:11<47:45,39.88it/s] 38%|###8      |66690/173481[27:00<42:30,41.87it/s] 39%|###8      |67194/173481[27:11<42:18,41.87it/s] 44%|####3     |75830/173481[30:00<35:27,45.90it/s] 44%|####4     |76419/173481[30:11<35:14,45.90it/s] 49%|####9     |85471/173481[33:00<29:40,49.43it/s] 50%|####9     |86096/173481[33:11<29:27,49.43it/s] 55%|#####4    |95154/173481[36:00<25:20,51.52it/s] 55%|#####5    |95794/173481[36:11<25:07,51.52it/s] 60%|#####9    |104045/173481[39:01<23:01,50.28it/s] 60%|######    |104215/173481[39:12<22:57,50.28it/s] 66%|######6   |114930/173481[42:01<17:46,54.91it/s] 67%|######6   |115518/173481[42:12<17:35,54.91it/s] 72%|#######1  |124625/173481[45:01<14:58,54.38it/s] 72%|#######2  |125221/173481[45:12<14:47,54.38it/s] 77%|#######7  |134253/173481[48:01<12:07,53.93it/s] 78%|#######7  |134848/173481[48:12<11:56,53.93it/s] 83%|########3 |144049/173481[51:01<09:03,54.17it/s] 83%|########3 |144648/173481[51:12<08:52,54.17it/s] 89%|########8 |153792/173481[54:01<06:03,54.15it/s] 89%|########8 |154381/173481[54:12<05:52,54.15it/s] 94%|#########3|162772/173481[57:01<03:26,51.93it/s] 94%|#########4|163245/173481[57:13<03:17,51.93it/s] 99%|#########9|171790/173481[1:00:01<00:33,51.00it/s] 99%|#########9|172389/173481[1:00:13<00:21,51.00it/s]100%|##########|173481/173481[1:00:33<00:00,47.74it/s]
[32m[0324 22:34:33 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3633.83 sec.
[32m[0324 22:34:34 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-7286202.
  0%|          |0/18822[00:00<?,?it/s] 84%|########4 |15829/18822[03:00<00:34,87.93it/s] 89%|########9 |16788/18822[03:10<00:23,87.93it/s]100%|##########|18822/18822[03:33<00:00,88.06it/s]
41
[32m[0324 22:38:07 @monitor.py:363][0m QueueInput/queue_size: 0.79119
[32m[0324 22:38:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.436
[32m[0324 22:38:07 @monitor.py:363][0m activation-summaries/output-rms: 0.040813
[32m[0324 22:38:07 @monitor.py:363][0m cross_entropy_loss: 1.6114
[32m[0324 22:38:07 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46932
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59428
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 22:38:07 @monitor.py:363][0m train-error-top1: 0.43819
[32m[0324 22:38:07 @monitor.py:363][0m val-error-top1: 0.43668
[32m[0324 22:38:07 @monitor.py:363][0m val-utt-error: 0.099458
[32m[0324 22:38:07 @monitor.py:363][0m validation_cost: 1.6361
[32m[0324 22:38:07 @monitor.py:363][0m wd_cost: 1.5324e-10
[32m[0324 22:38:07 @group.py:42][0m Callbacks took 214.097 sec in total. InferenceRunner: 213.750sec
[32m[0324 22:38:07 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9400/173481[03:00<52:22,52.22it/s]  6%|5         |9927/173481[03:10<52:11,52.22it/s] 11%|#         |18714/173481[06:00<49:37,51.98it/s] 11%|#1        |19244/173481[06:10<49:27,51.98it/s] 16%|#6        |27930/173481[09:00<47:01,51.58it/s] 16%|#6        |28465/173481[09:10<46:51,51.58it/s] 21%|##        |36234/173481[12:00<46:58,48.70it/s] 21%|##1       |36763/173481[12:10<46:47,48.70it/s] 26%|##6       |45544/173481[15:00<42:30,50.17it/s] 27%|##6       |46134/173481[15:10<42:18,50.17it/s] 32%|###1      |54931/173481[18:00<38:38,51.14it/s] 32%|###1      |55503/173481[18:10<38:27,51.14it/s] 37%|###7      |64567/173481[21:00<34:42,52.30it/s] 38%|###7      |65132/173481[21:11<34:31,52.30it/s] 43%|####3     |74707/173481[24:00<30:20,54.24it/s] 43%|####3     |75286/173481[24:11<30:10,54.24it/s] 49%|####8     |84439/173481[27:00<27:24,54.15it/s] 49%|####9     |85040/173481[27:11<27:13,54.15it/s] 54%|#####4    |94518/173481[30:00<23:54,55.06it/s] 55%|#####4    |94648/173481[30:11<23:51,55.06it/s] 60%|#####9    |103895/173481[33:00<21:39,53.53it/s] 60%|######    |104564/173481[33:11<21:27,53.53it/s] 65%|######5   |113374/173481[36:00<18:52,53.07it/s] 66%|######5   |114006/173481[36:11<18:40,53.07it/s] 71%|#######   |123102/173481[39:00<15:40,53.55it/s] 71%|#######1  |123779/173481[39:12<15:28,53.55it/s] 77%|#######6  |133109/173481[42:00<12:20,54.55it/s] 77%|#######7  |133822/173481[42:12<12:06,54.55it/s] 82%|########2 |143056/173481[45:00<09:14,54.90it/s] 83%|########2 |143908/173481[45:12<08:58,54.90it/s] 89%|########8 |153993/173481[48:00<05:37,57.68it/s] 89%|########9 |154648/173481[48:12<05:26,57.68it/s] 94%|#########4|163240/173481[51:00<03:08,54.34it/s] 95%|#########4|163986/173481[51:12<02:54,54.34it/s] 98%|#########8|170777/173481[54:00<00:57,47.30it/s] 99%|#########8|171122/173481[54:12<00:49,47.30it/s]100%|##########|173481/173481[55:21<00:00,52.22it/s]
[32m[0324 23:33:29 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3321.93 sec.
[32m[0324 23:33:30 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######4  |13995/18822[03:00<01:02,77.75it/s] 79%|#######8  |14802/18822[03:10<00:51,77.75it/s]100%|##########|18822/18822[03:56<00:00,79.48it/s]
42
[32m[0324 23:37:27 @monitor.py:363][0m QueueInput/queue_size: 0.75454
[32m[0324 23:37:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.559
[32m[0324 23:37:27 @monitor.py:363][0m activation-summaries/output-rms: 0.041023
[32m[0324 23:37:27 @monitor.py:363][0m cross_entropy_loss: 1.6068
[32m[0324 23:37:27 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59412
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0324 23:37:27 @monitor.py:363][0m train-error-top1: 0.4316
[32m[0324 23:37:27 @monitor.py:363][0m val-error-top1: 0.43689
[32m[0324 23:37:27 @monitor.py:363][0m val-utt-error: 0.098555
[32m[0324 23:37:27 @monitor.py:363][0m validation_cost: 1.6366
[32m[0324 23:37:27 @monitor.py:363][0m wd_cost: 1.532e-10
[32m[0324 23:37:27 @group.py:42][0m Callbacks took 237.427 sec in total. InferenceRunner: 236.849sec
[32m[0324 23:37:27 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |6968/173481[03:00<1:11:42,38.70it/s]  4%|4         |7323/173481[03:10<1:11:33,38.70it/s]  8%|7         |13288/173481[06:00<1:12:31,36.81it/s]  8%|7         |13662/173481[06:10<1:12:21,36.81it/s] 11%|#1        |19218/173481[09:00<1:13:57,34.76it/s] 11%|#1        |19592/173481[09:10<1:13:46,34.76it/s] 15%|#4        |25408/173481[12:00<1:11:23,34.57it/s] 15%|#4        |25762/173481[12:10<1:11:13,34.57it/s] 18%|#8        |32052/173481[15:00<1:06:01,35.70it/s] 19%|#8        |32367/173481[15:10<1:05:52,35.70it/s] 23%|##2       |39389/173481[18:00<58:42,38.06it/s]   23%|##3       |39908/173481[18:10<58:29,38.06it/s] 27%|##7       |47673/173481[21:00<50:19,41.66it/s] 28%|##7       |48169/173481[21:11<50:07,41.66it/s] 32%|###2      |55888/173481[24:00<44:59,43.56it/s] 33%|###2      |56412/173481[24:11<44:47,43.56it/s] 37%|###6      |63568/173481[27:00<42:29,43.11it/s] 37%|###6      |64047/173481[27:11<42:18,43.11it/s] 41%|####1     |71599/173481[30:00<38:43,43.85it/s] 42%|####1     |72063/173481[30:11<38:33,43.85it/s] 46%|####5     |79534/173481[33:00<35:36,43.96it/s] 46%|####6     |80151/173481[33:11<35:22,43.96it/s] 51%|#####     |88321/173481[36:00<30:40,46.26it/s] 51%|#####1    |88907/173481[36:11<30:28,46.26it/s] 56%|#####5    |97118/173481[39:00<26:46,47.53it/s] 56%|#####6    |97657/173481[39:12<26:35,47.53it/s] 61%|######1   |106101/173481[42:00<23:03,48.69it/s] 62%|######1   |106691/173481[42:12<22:51,48.69it/s] 66%|######5   |114416/173481[45:00<20:45,47.41it/s] 66%|######6   |115066/173481[45:12<20:32,47.41it/s] 71%|#######1  |123853/173481[48:00<16:36,49.79it/s] 72%|#######1  |124509/173481[48:12<16:23,49.79it/s] 77%|#######6  |133154/173481[51:00<13:15,50.71it/s] 77%|#######7  |133668/173481[51:12<13:05,50.71it/s] 81%|########  |140171/173481[54:00<12:35,44.08it/s] 81%|########1 |140647/173481[54:12<12:24,44.08it/s] 85%|########4 |147051/173481[57:00<10:45,40.94it/s] 85%|########5 |147843/173481[57:13<10:26,40.94it/s] 91%|#########1|157944/173481[1:00:00<05:18,48.84it/s] 92%|#########1|158738/173481[1:00:13<05:01,48.84it/s] 97%|#########7|169098/173481[1:03:00<01:20,54.62it/s] 98%|#########7|169879/173481[1:03:13<01:05,54.62it/s]100%|##########|173481/173481[1:04:21<00:00,44.93it/s]
[32m[0325 00:41:48 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3861.25 sec.
[32m[0325 00:41:48 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-7633164.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:27<00:00,127.66it/s]
43
[32m[0325 00:44:16 @monitor.py:363][0m QueueInput/queue_size: 0.84854
[32m[0325 00:44:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.335
[32m[0325 00:44:16 @monitor.py:363][0m activation-summaries/output-rms: 0.040462
[32m[0325 00:44:16 @monitor.py:363][0m cross_entropy_loss: 1.6234
[32m[0325 00:44:16 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59401
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 00:44:16 @monitor.py:363][0m train-error-top1: 0.43761
[32m[0325 00:44:16 @monitor.py:363][0m val-error-top1: 0.43666
[32m[0325 00:44:16 @monitor.py:363][0m val-utt-error: 0.099405
[32m[0325 00:44:16 @monitor.py:363][0m validation_cost: 1.6352
[32m[0325 00:44:16 @monitor.py:363][0m wd_cost: 1.5318e-10
[32m[0325 00:44:16 @group.py:42][0m Callbacks took 147.926 sec in total. InferenceRunner: 147.458sec
[32m[0325 00:44:16 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10132/173481[03:00<48:22,56.28it/s]  6%|5         |10286/173481[03:10<48:19,56.28it/s] 12%|#1        |19963/173481[06:00<46:09,55.44it/s] 12%|#1        |20550/173481[06:10<45:58,55.44it/s] 18%|#7        |31032/173481[09:00<40:43,58.31it/s] 18%|#8        |31730/173481[09:10<40:31,58.31it/s] 25%|##4       |42632/173481[12:00<35:37,61.22it/s] 25%|##4       |43255/173481[12:10<35:27,61.22it/s] 31%|###1      |54182/173481[15:00<31:44,62.65it/s] 32%|###1      |54909/173481[15:10<31:32,62.65it/s] 37%|###7      |64367/173481[18:00<30:35,59.46it/s] 37%|###7      |65038/173481[18:10<30:23,59.46it/s] 44%|####3     |75492/173481[21:00<26:56,60.60it/s] 44%|####3     |76161/173481[21:11<26:45,60.60it/s] 50%|####9     |86152/173481[24:00<24:17,59.90it/s] 50%|#####     |86823/173481[24:11<24:06,59.90it/s] 55%|#####4    |94556/173481[27:00<25:04,52.47it/s] 55%|#####4    |95109/173481[27:11<24:53,52.47it/s] 59%|#####9    |103159/173481[30:00<23:25,50.02it/s] 60%|#####9    |103712/173481[30:11<23:14,50.02it/s] 64%|######4   |111158/173481[33:00<22:04,47.06it/s] 64%|######4   |111702/173481[33:11<21:52,47.06it/s] 69%|######9   |120060/173481[36:00<18:27,48.23it/s] 70%|######9   |120611/173481[36:11<18:16,48.23it/s] 74%|#######4  |128772/173481[39:00<15:25,48.31it/s] 75%|#######4  |129307/173481[39:12<15:14,48.31it/s] 79%|#######9  |137251/173481[42:00<12:39,47.70it/s] 79%|#######9  |137800/173481[42:12<12:28,47.70it/s] 84%|########3 |145072/173481[45:00<10:24,45.47it/s] 84%|########3 |145636/173481[45:12<10:12,45.47it/s] 89%|########8 |153600/173481[48:00<07:08,46.40it/s] 89%|########8 |154101/173481[48:12<06:57,46.40it/s] 93%|#########3|161398/173481[51:00<04:29,44.81it/s] 93%|#########3|161576/173481[51:12<04:25,44.81it/s] 97%|#########6|167680/173481[54:00<02:27,39.24it/s] 97%|#########6|168178/173481[54:12<02:15,39.24it/s]100%|##########|173481/173481[56:21<00:00,51.30it/s]
[32m[0325 01:40:37 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:3381.39 sec.
[32m[0325 01:40:38 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-7806645.
[32m[0325 01:40:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 75%|#######4  |14072/18822[03:00<01:00,78.18it/s] 78%|#######8  |14761/18822[03:10<00:51,78.18it/s]100%|##########|18822/18822[03:58<00:00,79.00it/s]
44
[32m[0325 01:44:37 @monitor.py:363][0m QueueInput/queue_size: 1.059
[32m[0325 01:44:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.397
[32m[0325 01:44:37 @monitor.py:363][0m activation-summaries/output-rms: 0.042059
[32m[0325 01:44:37 @monitor.py:363][0m cross_entropy_loss: 1.5998
[32m[0325 01:44:37 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59398
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 01:44:37 @monitor.py:363][0m train-error-top1: 0.4338
[32m[0325 01:44:37 @monitor.py:363][0m val-error-top1: 0.43715
[32m[0325 01:44:37 @monitor.py:363][0m val-utt-error: 0.099511
[32m[0325 01:44:37 @monitor.py:363][0m validation_cost: 1.6377
[32m[0325 01:44:37 @monitor.py:363][0m wd_cost: 3.0634e-11
[32m[0325 01:44:37 @group.py:42][0m Callbacks took 239.291 sec in total. InferenceRunner: 238.284sec
[32m[0325 01:44:37 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9492/173481[03:00<51:49,52.73it/s]  6%|5         |10000/173481[03:10<51:40,52.73it/s] 11%|#         |18596/173481[06:00<49:59,51.63it/s] 11%|#1        |19140/173481[06:10<49:49,51.63it/s] 15%|#5        |26723/173481[09:00<50:46,48.17it/s] 16%|#5        |27210/173481[09:10<50:36,48.17it/s] 20%|##        |35121/173481[12:00<48:39,47.39it/s] 21%|##        |35640/173481[12:10<48:28,47.39it/s] 25%|##4       |42561/173481[15:00<49:25,44.15it/s] 25%|##4       |43025/173481[15:10<49:14,44.15it/s] 29%|##9       |50619/173481[18:00<46:03,44.46it/s] 29%|##9       |51121/173481[18:11<45:52,44.46it/s] 34%|###3      |58936/173481[21:00<42:07,45.31it/s] 34%|###4      |59456/173481[21:11<41:56,45.31it/s] 39%|###8      |67197/173481[24:00<38:50,45.60it/s] 39%|###8      |67580/173481[24:11<38:42,45.60it/s] 43%|####3     |75170/173481[27:00<36:27,44.94it/s] 44%|####3     |75666/173481[27:11<36:16,44.94it/s] 48%|####7     |83109/173481[30:00<33:50,44.52it/s] 48%|####8     |83602/173481[30:11<33:39,44.52it/s] 53%|#####2    |91088/173481[33:00<30:54,44.42it/s] 53%|#####2    |91607/173481[33:11<30:43,44.42it/s] 57%|#####6    |98333/173481[36:00<29:39,42.23it/s] 57%|#####6    |98830/173481[36:11<29:27,42.23it/s] 61%|######1   |106131/173481[39:00<26:14,42.76it/s] 61%|######1   |106672/173481[39:12<26:02,42.76it/s] 66%|######5   |113632/173481[42:00<23:37,42.21it/s] 66%|######5   |114043/173481[42:12<23:28,42.21it/s] 69%|######9   |120428/173481[45:00<22:11,39.86it/s] 70%|######9   |120909/173481[45:12<21:58,39.86it/s] 73%|#######3  |127357/173481[48:00<19:37,39.16it/s] 74%|#######3  |127855/173481[48:12<19:25,39.16it/s] 78%|#######7  |134476/173481[51:00<16:31,39.35it/s] 78%|#######7  |134987/173481[51:13<16:18,39.35it/s] 82%|########1 |141461/173481[54:00<13:39,39.07it/s] 82%|########1 |141990/173481[54:13<13:25,39.07it/s] 85%|########5 |147731/173481[57:00<11:40,36.79it/s] 85%|########5 |148230/173481[57:13<11:26,36.79it/s] 89%|########9 |154429/173481[1:00:00<08:34,37.00it/s] 89%|########9 |154925/173481[1:00:13<08:21,37.00it/s] 93%|#########2|161173/173481[1:03:00<05:30,37.23it/s] 93%|#########3|161668/173481[1:03:13<05:17,37.23it/s] 97%|#########6|168231/173481[1:06:00<02:17,38.19it/s] 97%|#########7|168775/173481[1:06:13<02:03,38.19it/s]100%|##########|173481/173481[1:08:06<00:00,42.45it/s]
[32m[0325 02:52:44 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:4086.96 sec.
[32m[0325 02:52:45 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-7980126.
  0%|          |0/18822[00:00<?,?it/s] 72%|#######2  |13556/18822[03:00<01:09,75.30it/s] 76%|#######6  |14340/18822[03:10<00:59,75.30it/s]100%|##########|18822/18822[04:07<00:00,76.08it/s]
45
[32m[0325 02:56:53 @monitor.py:363][0m QueueInput/queue_size: 0.78593
[32m[0325 02:56:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.386
[32m[0325 02:56:53 @monitor.py:363][0m activation-summaries/output-rms: 0.041254
[32m[0325 02:56:53 @monitor.py:363][0m cross_entropy_loss: 1.5959
[32m[0325 02:56:53 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59395
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 02:56:53 @monitor.py:363][0m train-error-top1: 0.42486
[32m[0325 02:56:53 @monitor.py:363][0m val-error-top1: 0.43716
[32m[0325 02:56:53 @monitor.py:363][0m val-utt-error: 0.098555
[32m[0325 02:56:53 @monitor.py:363][0m validation_cost: 1.6379
[32m[0325 02:56:53 @monitor.py:363][0m wd_cost: 3.0632e-11
[32m[0325 02:56:53 @group.py:42][0m Callbacks took 248.932 sec in total. InferenceRunner: 247.447sec
[32m[0325 02:56:53 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |7879/173481[03:00<1:03:03,43.77it/s]  5%|4         |8318/173481[03:10<1:02:53,43.77it/s]  9%|8         |15343/173481[06:00<1:01:53,42.59it/s]  9%|9         |15801/173481[06:10<1:01:42,42.59it/s] 14%|#3        |23538/173481[09:00<56:47,44.01it/s]   14%|#3        |24041/173481[09:10<56:35,44.01it/s] 18%|#8        |31831/173481[12:00<52:26,45.01it/s] 19%|#8        |32316/173481[12:10<52:16,45.01it/s] 23%|##2       |39769/173481[15:00<50:01,44.55it/s] 23%|##3       |40233/173481[15:10<49:50,44.55it/s] 28%|##7       |47725/173481[18:00<47:14,44.37it/s] 28%|##7       |48210/173481[18:10<47:03,44.37it/s] 32%|###2      |55988/173481[21:00<43:23,45.12it/s] 33%|###2      |56523/173481[21:11<43:11,45.12it/s] 37%|###6      |63865/173481[24:00<41:07,44.43it/s] 37%|###7      |64317/173481[24:11<40:56,44.43it/s] 41%|####1     |71905/173481[27:00<38:00,44.54it/s] 42%|####1     |72373/173481[27:11<37:50,44.54it/s] 45%|####4     |77877/173481[30:00<41:54,38.03it/s] 45%|####5     |78408/173481[30:11<41:40,38.03it/s] 50%|####9     |85926/173481[33:00<35:30,41.10it/s] 50%|####9     |86494/173481[33:11<35:16,41.10it/s] 54%|#####4    |94074/173481[36:00<30:43,43.08it/s] 55%|#####4    |94605/173481[36:11<30:30,43.08it/s] 59%|#####8    |101998/173481[39:00<27:21,43.55it/s] 59%|#####9    |102517/173481[39:12<27:09,43.55it/s] 63%|######3   |109320/173481[42:00<25:25,42.06it/s] 63%|######3   |109810/173481[42:12<25:13,42.06it/s] 67%|######7   |116732/173481[45:00<22:43,41.61it/s] 68%|######7   |117222/173481[45:12<22:31,41.61it/s] 72%|#######1  |124069/173481[48:00<19:59,41.18it/s] 72%|#######1  |124519/173481[48:12<19:48,41.18it/s] 76%|#######5  |131265/173481[51:00<17:20,40.57it/s] 76%|#######5  |131817/173481[51:12<17:06,40.57it/s] 80%|#######9  |138430/173481[54:00<14:32,40.17it/s] 80%|########  |138972/173481[54:12<14:19,40.17it/s] 84%|########4 |146362/173481[57:00<10:45,42.03it/s] 85%|########4 |146924/173481[57:13<10:31,42.03it/s] 89%|########8 |154210/173481[1:00:00<07:30,42.80it/s] 89%|########9 |154741/173481[1:00:13<07:17,42.80it/s] 93%|#########3|161795/173481[1:03:00<04:35,42.46it/s] 94%|#########3|162307/173481[1:03:13<04:23,42.46it/s] 98%|#########7|169505/173481[1:06:00<01:33,42.64it/s] 98%|#########8|170049/173481[1:06:13<01:20,42.64it/s]100%|##########|173481/173481[1:07:36<00:00,42.76it/s]
[32m[0325 04:04:29 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:4056.69 sec.
[32m[0325 04:04:30 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-8153607.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######4  |13956/18822[03:00<01:02,77.53it/s] 79%|#######8  |14807/18822[03:10<00:51,77.53it/s]100%|##########|18822/18822[04:00<00:00,78.30it/s]
46
[32m[0325 04:08:31 @monitor.py:363][0m QueueInput/queue_size: 0.77533
[32m[0325 04:08:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.396
[32m[0325 04:08:31 @monitor.py:363][0m activation-summaries/output-rms: 0.040802
[32m[0325 04:08:31 @monitor.py:363][0m cross_entropy_loss: 1.6114
[32m[0325 04:08:31 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 04:08:31 @monitor.py:363][0m train-error-top1: 0.43811
[32m[0325 04:08:31 @monitor.py:363][0m val-error-top1: 0.43665
[32m[0325 04:08:31 @monitor.py:363][0m val-utt-error: 0.099564
[32m[0325 04:08:31 @monitor.py:363][0m validation_cost: 1.6361
[32m[0325 04:08:31 @monitor.py:363][0m wd_cost: 3.0632e-11
[32m[0325 04:08:31 @group.py:42][0m Callbacks took 241.483 sec in total. InferenceRunner: 240.442sec
[32m[0325 04:08:31 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7244/173481[03:00<1:08:51,40.23it/s]  4%|4         |7683/173481[03:10<1:08:41,40.23it/s]  9%|8         |14796/173481[06:00<1:04:23,41.07it/s]  9%|8         |15264/173481[06:10<1:04:12,41.07it/s] 13%|#2        |22294/173481[09:00<1:00:55,41.36it/s] 13%|#3        |22798/173481[09:10<1:00:43,41.36it/s] 17%|#6        |29369/173481[12:00<59:35,40.31it/s]   17%|#7        |29850/173481[12:10<59:23,40.31it/s] 21%|##1       |37204/173481[15:00<54:16,41.85it/s] 22%|##1       |37692/173481[15:10<54:04,41.85it/s] 26%|##5       |44869/173481[18:00<50:46,42.21it/s] 26%|##6       |45358/173481[18:10<50:35,42.21it/s] 30%|###       |52834/173481[21:00<46:32,43.21it/s] 31%|###       |53339/173481[21:11<46:20,43.21it/s] 35%|###4      |60519/173481[24:00<43:51,42.93it/s] 35%|###4      |60623/173481[24:11<43:48,42.93it/s] 39%|###9      |67730/173481[27:00<42:31,41.45it/s] 39%|###9      |68243/173481[27:11<42:19,41.45it/s] 44%|####3     |75564/173481[30:00<38:26,42.46it/s] 44%|####3     |76074/173481[30:11<38:14,42.46it/s] 48%|####8     |83604/173481[33:00<34:24,43.53it/s] 48%|####8     |84106/173481[33:11<34:12,43.53it/s] 53%|#####2    |91609/173481[36:00<31:01,43.99it/s] 53%|#####3    |92043/173481[36:11<30:51,43.99it/s] 57%|#####7    |99515/173481[39:00<28:02,43.96it/s] 58%|#####7    |100048/173481[39:12<27:50,43.96it/s] 62%|######1   |107458/173481[42:00<24:59,44.04it/s] 62%|######2   |108033/173481[42:12<24:46,44.04it/s] 67%|######6   |115434/173481[45:00<21:54,44.17it/s] 67%|######6   |115988/173481[45:12<21:41,44.17it/s] 71%|#######   |122359/173481[48:00<20:43,41.13it/s] 71%|#######   |122903/173481[48:12<20:29,41.13it/s] 75%|#######5  |130709/173481[51:00<16:21,43.60it/s] 76%|#######5  |131258/173481[51:12<16:08,43.60it/s] 80%|########  |139120/173481[54:00<12:41,45.11it/s] 81%|########  |139674/173481[54:12<12:29,45.11it/s] 85%|########4 |147166/173481[57:00<09:46,44.90it/s] 85%|########5 |147709/173481[57:13<09:33,44.90it/s] 90%|########9 |155544/173481[1:00:00<06:32,45.70it/s] 90%|########9 |156085/173481[1:00:13<06:20,45.70it/s] 94%|#########4|163807/173481[1:03:00<03:31,45.80it/s] 95%|#########4|164418/173481[1:03:13<03:17,45.80it/s] 99%|#########8|171659/173481[1:06:00<00:40,44.68it/s] 99%|#########9|172274/173481[1:06:13<00:27,44.68it/s]100%|##########|173481/173481[1:06:41<00:00,43.35it/s]
[32m[0325 05:15:13 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:4001.78 sec.
[32m[0325 05:15:13 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-8327088.
[32m[0325 05:15:13 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 65%|######5   |12282/18822[03:00<01:35,68.23it/s] 70%|######9   |13099/18822[03:10<01:23,68.23it/s]100%|##########|18822/18822[04:22<00:00,71.71it/s]
47
[32m[0325 05:19:36 @monitor.py:363][0m QueueInput/queue_size: 2.7219
[32m[0325 05:19:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.533
[32m[0325 05:19:36 @monitor.py:363][0m activation-summaries/output-rms: 0.041014
[32m[0325 05:19:36 @monitor.py:363][0m cross_entropy_loss: 1.6068
[32m[0325 05:19:36 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 05:19:36 @monitor.py:363][0m train-error-top1: 0.43148
[32m[0325 05:19:36 @monitor.py:363][0m val-error-top1: 0.43688
[32m[0325 05:19:36 @monitor.py:363][0m val-utt-error: 0.098342
[32m[0325 05:19:36 @monitor.py:363][0m validation_cost: 1.6366
[32m[0325 05:19:36 @monitor.py:363][0m wd_cost: 6.1263e-12
[32m[0325 05:19:36 @group.py:42][0m Callbacks took 263.339 sec in total. InferenceRunner: 262.522sec
[32m[0325 05:19:36 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8667/173481[03:00<57:02,48.15it/s]  5%|5         |9155/173481[03:10<56:52,48.15it/s]  9%|9         |16427/173481[06:00<57:32,45.49it/s] 10%|9         |16872/173481[06:10<57:22,45.49it/s] 14%|#3        |24128/173481[09:00<56:27,44.09it/s] 14%|#4        |24615/173481[09:10<56:16,44.09it/s] 18%|#7        |30925/173481[12:00<58:24,40.68it/s] 18%|#8        |31409/173481[12:10<58:12,40.68it/s] 23%|##2       |39051/173481[15:00<52:21,42.80it/s] 23%|##2       |39585/173481[15:10<52:08,42.80it/s] 27%|##7       |47434/173481[18:00<47:06,44.60it/s] 28%|##7       |47991/173481[18:11<46:53,44.60it/s] 32%|###1      |54985/173481[21:00<45:40,43.23it/s] 32%|###1      |55507/173481[21:11<45:28,43.23it/s] 37%|###7      |64444/173481[24:00<38:18,47.44it/s] 38%|###7      |65068/173481[24:11<38:05,47.44it/s] 42%|####2     |73600/173481[27:00<33:54,49.09it/s] 43%|####2     |74018/173481[27:11<33:46,49.09it/s] 48%|####7     |82764/173481[30:00<30:14,49.98it/s] 48%|####8     |83321/173481[30:11<30:03,49.98it/s] 53%|#####2    |91775/173481[33:00<27:13,50.02it/s] 53%|#####3    |92352/173481[33:11<27:01,50.02it/s] 58%|#####7    |100582/173481[36:00<24:33,49.47it/s] 58%|#####8    |101232/173481[36:12<24:20,49.47it/s] 63%|######3   |110075/173481[39:00<20:42,51.05it/s] 64%|######3   |110677/173481[39:12<20:30,51.05it/s] 68%|######8   |118559/173481[42:00<18:40,49.01it/s] 69%|######8   |119146/173481[42:12<18:28,49.01it/s] 73%|#######3  |126938/173481[45:00<16:14,47.75it/s] 74%|#######3  |127588/173481[45:12<16:01,47.75it/s] 78%|#######8  |136078/173481[48:00<12:40,49.21it/s] 79%|#######8  |136707/173481[48:12<12:27,49.21it/s] 84%|########3 |145113/173481[51:00<09:30,49.69it/s] 84%|########4 |145727/173481[51:12<09:18,49.69it/s] 89%|########8 |154053/173481[54:00<06:31,49.68it/s] 89%|########9 |154690/173481[54:12<06:18,49.68it/s] 94%|#########3|163070/173481[57:00<03:28,49.88it/s] 94%|#########4|163727/173481[57:13<03:15,49.88it/s] 99%|#########9|171908/173481[1:00:00<00:31,49.49it/s] 99%|#########9|172482/173481[1:00:13<00:20,49.49it/s]100%|##########|173481/173481[1:00:54<00:00,47.47it/s]
[32m[0325 06:20:31 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:3654.82 sec.
[32m[0325 06:20:32 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-8500569.
  0%|          |0/18822[00:00<?,?it/s] 82%|########1 |15349/18822[03:00<00:40,85.27it/s] 86%|########6 |16222/18822[03:10<00:30,85.27it/s]100%|##########|18822/18822[03:38<00:00,86.06it/s]
48
[32m[0325 06:24:11 @monitor.py:363][0m QueueInput/queue_size: 0.88489
[32m[0325 06:24:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.319
[32m[0325 06:24:11 @monitor.py:363][0m activation-summaries/output-rms: 0.040459
[32m[0325 06:24:11 @monitor.py:363][0m cross_entropy_loss: 1.6234
[32m[0325 06:24:11 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 06:24:11 @monitor.py:363][0m train-error-top1: 0.43765
[32m[0325 06:24:11 @monitor.py:363][0m val-error-top1: 0.43667
[32m[0325 06:24:11 @monitor.py:363][0m val-utt-error: 0.099405
[32m[0325 06:24:11 @monitor.py:363][0m validation_cost: 1.6351
[32m[0325 06:24:11 @monitor.py:363][0m wd_cost: 6.1263e-12
[32m[0325 06:24:11 @group.py:42][0m Callbacks took 220.004 sec in total. InferenceRunner: 218.717sec
[32m[0325 06:24:11 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10034/173481[03:00<48:52,55.74it/s]  6%|6         |10546/173481[03:10<48:42,55.74it/s] 11%|#1        |19187/173481[06:00<48:21,53.18it/s] 11%|#1        |19769/173481[06:10<48:10,53.18it/s] 17%|#6        |29147/173481[09:00<44:21,54.23it/s] 17%|#7        |29714/173481[09:10<44:11,54.23it/s] 22%|##2       |38839/173481[12:00<41:31,54.04it/s] 23%|##2       |39425/173481[12:10<41:20,54.04it/s] 27%|##7       |47476/173481[15:00<41:19,50.83it/s] 28%|##7       |48013/173481[15:10<41:08,50.83it/s] 33%|###2      |56962/173481[18:00<37:31,51.74it/s] 33%|###3      |57584/173481[18:10<37:19,51.74it/s] 39%|###9      |68470/173481[21:00<30:35,57.20it/s] 40%|###9      |69089/173481[21:11<30:25,57.20it/s] 46%|####5     |79768/173481[24:00<26:05,59.85it/s] 46%|####6     |80512/173481[24:11<25:53,59.85it/s] 53%|#####2    |91716/173481[27:00<21:39,62.94it/s] 53%|#####3    |92468/173481[27:11<21:27,62.94it/s] 59%|#####8    |101867/173481[30:00<20:03,59.49it/s] 59%|#####9    |102461/173481[30:11<19:53,59.49it/s] 64%|######3   |110333/173481[33:00<20:02,52.53it/s] 64%|######3   |111000/173481[33:11<19:49,52.53it/s] 69%|######9   |120270/173481[36:00<16:28,53.83it/s] 70%|######9   |120951/173481[36:12<16:15,53.83it/s] 75%|#######4  |129755/173481[39:00<13:41,53.26it/s] 75%|#######5  |130360/173481[39:12<13:29,53.26it/s] 80%|########  |139052/173481[42:00<10:56,52.44it/s] 81%|########  |139737/173481[42:12<10:43,52.44it/s] 86%|########5 |148396/173481[45:00<08:00,52.17it/s] 86%|########5 |149039/173481[45:12<07:48,52.17it/s] 91%|######### |157739/173481[48:00<05:02,52.04it/s] 91%|#########1|158410/173481[48:12<04:49,52.04it/s] 96%|#########5|166064/173481[51:00<02:31,48.97it/s] 96%|#########6|166678/173481[51:12<02:18,48.97it/s][32m[0325 07:17:44 @base.py:257][0m Epoch 51 (global_step 8674050) finished, time:3213.57 sec.
100%|##########|173481/173481[53:33<00:00,53.98it/s]
[32m[0325 07:17:45 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-8674050.
  0%|          |0/18822[00:00<?,?it/s] 85%|########4 |15930/18822[03:00<00:32,88.50it/s] 90%|######### |16948/18822[03:10<00:21,88.50it/s]100%|##########|18822/18822[03:30<00:00,89.55it/s]
49
[32m[0325 07:21:15 @monitor.py:363][0m QueueInput/queue_size: 0.5561
[32m[0325 07:21:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.387
[32m[0325 07:21:15 @monitor.py:363][0m activation-summaries/output-rms: 0.042058
[32m[0325 07:21:15 @monitor.py:363][0m cross_entropy_loss: 1.5997
[32m[0325 07:21:15 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 07:21:15 @monitor.py:363][0m train-error-top1: 0.43406
[32m[0325 07:21:15 @monitor.py:363][0m val-error-top1: 0.43716
[32m[0325 07:21:15 @monitor.py:363][0m val-utt-error: 0.099564
[32m[0325 07:21:15 @monitor.py:363][0m validation_cost: 1.6376
[32m[0325 07:21:15 @monitor.py:363][0m wd_cost: 1.2253e-12
[32m[0325 07:21:15 @group.py:42][0m Callbacks took 210.654 sec in total. InferenceRunner: 210.201sec
[32m[0325 07:21:15 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9780/173481[03:00<50:13,54.33it/s]  6%|5         |10302/173481[03:10<50:03,54.33it/s] 11%|#         |18955/173481[06:00<48:57,52.60it/s] 11%|#1        |19471/173481[06:10<48:48,52.60it/s] 16%|#6        |27881/173481[09:00<47:32,51.03it/s] 16%|#6        |28407/173481[09:10<47:22,51.03it/s] 21%|##        |36132/173481[12:00<47:23,48.30it/s] 21%|##1       |36640/173481[12:10<47:13,48.30it/s] 26%|##6       |45276/173481[15:00<43:09,49.51it/s] 26%|##6       |45906/173481[15:10<42:56,49.51it/s] 32%|###1      |54914/173481[18:00<38:24,51.45it/s] 32%|###2      |55634/173481[18:11<38:10,51.45it/s] 38%|###7      |65112/173481[21:00<33:29,53.93it/s] 38%|###7      |65707/173481[21:11<33:18,53.93it/s] 43%|####3     |74994/173481[24:00<30:10,54.41it/s] 44%|####3     |75628/173481[24:11<29:58,54.41it/s] 49%|####8     |84938/173481[27:00<26:55,54.82it/s] 49%|####9     |85580/173481[27:11<26:43,54.82it/s] 54%|#####4    |93728/173481[30:00<25:44,51.65it/s] 54%|#####4    |94327/173481[30:11<25:32,51.65it/s] 60%|#####9    |103475/173481[33:00<22:04,52.87it/s] 60%|#####9    |104068/173481[33:11<21:52,52.87it/s] 65%|######5   |112772/173481[36:00<19:21,52.25it/s] 65%|######5   |113396/173481[36:11<19:09,52.25it/s] 71%|#######   |122416/173481[39:00<16:05,52.91it/s] 71%|#######   |123040/173481[39:12<15:53,52.91it/s] 76%|#######6  |132027/173481[42:00<12:59,53.15it/s] 76%|#######6  |132657/173481[42:12<12:48,53.15it/s] 82%|########1 |141574/173481[45:00<10:00,53.09it/s] 82%|########1 |142225/173481[45:12<09:48,53.09it/s] 87%|########6 |150425/173481[48:00<07:31,51.06it/s] 87%|########7 |151100/173481[48:12<07:18,51.06it/s] 92%|#########2|160099/173481[51:00<04:15,52.36it/s] 93%|#########2|160777/173481[51:12<04:02,52.36it/s] 98%|#########7|169350/173481[54:00<01:19,51.87it/s] 98%|#########8|170026/173481[54:12<01:06,51.87it/s]100%|##########|173481/173481[55:19<00:00,52.26it/s]
[32m[0325 08:16:34 @base.py:257][0m Epoch 52 (global_step 8847531) finished, time:3319.37 sec.
[32m[0325 08:16:36 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-8847531.
  0%|          |0/18822[00:00<?,?it/s] 87%|########7 |16396/18822[03:00<00:26,91.09it/s] 93%|#########3|17550/18822[03:10<00:13,91.09it/s]100%|##########|18822/18822[03:23<00:00,92.30it/s]
50
[32m[0325 08:20:00 @monitor.py:363][0m QueueInput/queue_size: 0.62255
[32m[0325 08:20:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.38
[32m[0325 08:20:00 @monitor.py:363][0m activation-summaries/output-rms: 0.041254
[32m[0325 08:20:00 @monitor.py:363][0m cross_entropy_loss: 1.5959
[32m[0325 08:20:00 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 08:20:00 @monitor.py:363][0m train-error-top1: 0.42511
[32m[0325 08:20:00 @monitor.py:363][0m val-error-top1: 0.43717
[32m[0325 08:20:00 @monitor.py:363][0m val-utt-error: 0.098608
[32m[0325 08:20:00 @monitor.py:363][0m validation_cost: 1.6378
[32m[0325 08:20:00 @monitor.py:363][0m wd_cost: 1.2253e-12
[32m[0325 08:20:00 @group.py:42][0m Callbacks took 205.159 sec in total. InferenceRunner: 203.951sec
[32m[0325 08:20:00 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9674/173481[03:00<50:48,53.74it/s]  6%|5         |10166/173481[03:10<50:38,53.74it/s] 11%|#         |18804/173481[06:00<49:23,52.19it/s] 11%|#1        |19344/173481[06:10<49:13,52.19it/s] 16%|#5        |27030/173481[09:00<50:05,48.72it/s] 16%|#5        |27523/173481[09:10<49:55,48.72it/s] 21%|##        |36050/173481[12:00<46:22,49.40it/s] 21%|##1       |36575/173481[12:10<46:11,49.40it/s] 26%|##5       |45005/173481[15:00<43:11,49.57it/s] 26%|##6       |45544/173481[15:10<43:00,49.57it/s] 31%|###1      |53960/173481[18:00<40:07,49.65it/s] 31%|###1      |54495/173481[18:11<39:56,49.65it/s] 36%|###6      |63022/173481[21:00<36:49,49.99it/s] 37%|###6      |63569/173481[21:11<36:38,49.99it/s] 41%|####1     |71860/173481[24:00<34:11,49.54it/s] 42%|####1     |72299/173481[24:11<34:02,49.54it/s] 46%|####5     |79687/173481[27:00<33:45,46.31it/s] 46%|####6     |80229/173481[27:11<33:33,46.31it/s] 51%|#####     |88010/173481[30:00<30:47,46.27it/s] 51%|#####1    |88567/173481[30:11<30:35,46.27it/s] 55%|#####5    |96118/173481[33:00<28:14,45.65it/s] 56%|#####5    |96566/173481[33:11<28:04,45.65it/s] 61%|######    |105156/173481[36:00<23:48,47.82it/s] 61%|######    |105733/173481[36:12<23:36,47.82it/s] 66%|######5   |114470/173481[39:00<19:47,49.70it/s] 66%|######6   |115073/173481[39:12<19:35,49.70it/s] 71%|#######1  |123260/173481[42:00<16:59,49.24it/s] 71%|#######1  |123364/173481[42:12<16:57,49.24it/s] 76%|#######5  |131465/173481[45:00<14:47,47.33it/s] 76%|#######6  |132062/173481[45:12<14:35,47.33it/s] 81%|########  |140299/173481[48:00<11:28,48.19it/s] 81%|########1 |140844/173481[48:12<11:17,48.19it/s] 86%|########5 |148880/173481[51:00<08:33,47.92it/s] 86%|########6 |149477/173481[51:12<08:20,47.92it/s] 91%|######### |157851/173481[54:00<05:19,48.86it/s] 91%|#########1|158499/173481[54:12<05:06,48.86it/s] 97%|#########6|167693/173481[57:00<01:52,51.60it/s] 97%|#########7|168482/173481[57:13<01:36,51.60it/s]100%|##########|173481/173481[58:44<00:00,49.22it/s]
[32m[0325 09:18:44 @base.py:257][0m Epoch 53 (global_step 9021012) finished, time:3524.64 sec.
[32m[0325 09:18:44 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-9021012.
  0%|          |0/18822[00:00<?,?it/s] 80%|########  |15130/18822[03:00<00:43,84.05it/s] 85%|########5 |16078/18822[03:10<00:32,84.05it/s]100%|##########|18822/18822[03:37<00:00,86.36it/s]
51
[32m[0325 09:22:22 @monitor.py:363][0m QueueInput/queue_size: 0.91801
[32m[0325 09:22:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.393
[32m[0325 09:22:22 @monitor.py:363][0m activation-summaries/output-rms: 0.040802
[32m[0325 09:22:22 @monitor.py:363][0m cross_entropy_loss: 1.6114
[32m[0325 09:22:22 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 09:22:22 @monitor.py:363][0m train-error-top1: 0.43811
[32m[0325 09:22:22 @monitor.py:363][0m val-error-top1: 0.43666
[32m[0325 09:22:22 @monitor.py:363][0m val-utt-error: 0.099405
[32m[0325 09:22:22 @monitor.py:363][0m validation_cost: 1.636
[32m[0325 09:22:22 @monitor.py:363][0m wd_cost: 1.2253e-12
[32m[0325 09:22:22 @group.py:42][0m Callbacks took 218.107 sec in total. InferenceRunner: 217.959sec
[32m[0325 09:22:22 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10493/173481[03:00<46:36,58.29it/s]  6%|6         |10883/173481[03:10<46:29,58.29it/s] 11%|#         |18798/173481[06:00<50:03,51.51it/s] 11%|#1        |19323/173481[06:10<49:52,51.51it/s] 16%|#5        |27635/173481[09:00<48:21,50.27it/s] 16%|#6        |28142/173481[09:10<48:11,50.27it/s] 21%|##        |36023/173481[12:00<47:22,48.37it/s] 21%|##1       |36600/173481[12:10<47:10,48.37it/s] 26%|##5       |44574/173481[15:00<44:49,47.92it/s] 26%|##5       |45030/173481[15:10<44:40,47.92it/s] 30%|##9       |51945/173481[18:00<45:51,44.16it/s] 30%|###       |52449/173481[18:11<45:40,44.16it/s] 35%|###4      |60229/173481[21:00<41:52,45.07it/s] 35%|###5      |60753/173481[21:11<41:41,45.07it/s] 40%|###9      |68704/173481[24:00<37:55,46.05it/s] 40%|###9      |69238/173481[24:11<37:43,46.05it/s] 44%|####4     |76964/173481[27:00<34:59,45.97it/s] 45%|####4     |77518/173481[27:11<34:47,45.97it/s] 49%|####9     |85628/173481[30:00<31:08,47.02it/s] 50%|####9     |86166/173481[30:11<30:56,47.02it/s] 54%|#####4    |93746/173481[33:00<28:51,46.04it/s] 54%|#####4    |94103/173481[33:11<28:44,46.04it/s] 58%|#####8    |101289/173481[36:00<27:25,43.87it/s] 59%|#####8    |101829/173481[36:11<27:13,43.87it/s] 63%|######3   |109581/173481[39:00<23:41,44.94it/s] 63%|######3   |110136/173481[39:12<23:29,44.94it/s] 68%|######7   |117840/173481[42:00<20:25,45.41it/s] 68%|######8   |118411/173481[42:12<20:12,45.41it/s] 73%|#######2  |126149/173481[45:00<17:14,45.77it/s] 73%|#######3  |126710/173481[45:12<17:01,45.77it/s] 77%|#######7  |133912/173481[48:00<14:51,44.41it/s] 78%|#######7  |134543/173481[48:12<14:36,44.41it/s] 83%|########2 |143267/173481[51:00<10:30,47.89it/s] 83%|########2 |143919/173481[51:12<10:17,47.89it/s] 88%|########7 |152442/173481[54:00<07:06,49.38it/s] 88%|########8 |153099/173481[54:12<06:52,49.38it/s] 93%|#########3|161840/173481[57:00<03:49,50.76it/s] 94%|#########3|162519/173481[57:13<03:35,50.76it/s] 99%|#########8|171173/173481[1:00:00<00:44,51.30it/s] 99%|#########9|171873/173481[1:00:13<00:31,51.30it/s]100%|##########|173481/173481[1:00:44<00:00,47.60it/s]
[32m[0325 10:23:07 @base.py:257][0m Epoch 54 (global_step 9194493) finished, time:3644.49 sec.
[32m[0325 10:23:07 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_False/model-9194493.
  0%|          |0/18822[00:00<?,?it/s] 86%|########6 |16247/18822[03:00<00:28,90.26it/s] 92%|#########2|17375/18822[03:10<00:16,90.26it/s]100%|##########|18822/18822[03:25<00:00,91.72it/s]
52
[32m[0325 10:26:32 @monitor.py:363][0m QueueInput/queue_size: 0.70594
[32m[0325 10:26:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.531
[32m[0325 10:26:32 @monitor.py:363][0m activation-summaries/output-rms: 0.041015
[32m[0325 10:26:32 @monitor.py:363][0m cross_entropy_loss: 1.6068
[32m[0325 10:26:32 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5402e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8979e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9101e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1386e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5226e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4155e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.8941e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8836e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4552e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0325 10:26:32 @monitor.py:363][0m train-error-top1: 0.43148
[32m[0325 10:26:32 @monitor.py:363][0m val-error-top1: 0.43688
[32m[0325 10:26:32 @monitor.py:363][0m val-utt-error: 0.098342
[32m[0325 10:26:32 @monitor.py:363][0m validation_cost: 1.6366
[32m[0325 10:26:32 @monitor.py:363][0m wd_cost: 2.4505e-13
[32m[0325 10:26:32 @group.py:42][0m Callbacks took 205.520 sec in total. InferenceRunner: 205.387sec
[32m[0325 10:26:32 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11485/173481[03:00<42:19,63.80it/s]  7%|7         |12215/173481[03:10<42:07,63.80it/s] 13%|#3        |22956/173481[06:00<39:20,63.76it/s] 14%|#3        |23518/173481[06:10<39:11,63.76it/s] 20%|#9        |34367/173481[09:00<36:28,63.58it/s] 20%|##        |34993/173481[09:10<36:18,63.58it/s] 26%|##6       |45479/173481[12:00<34:03,62.64it/s] 27%|##6       |46202/173481[12:10<33:51,62.64it/s] 33%|###2      |56708/173481[15:00<31:08,62.51it/s] 33%|###3      |57319/173481[15:10<30:58,62.51it/s] 38%|###8      |66143/173481[18:00<31:22,57.02it/s] 38%|###8      |66747/173481[18:11<31:12,57.02it/s]slurmstepd: *** STEP 82585.0 ON sls-sm-16 CANCELLED AT 2018-03-25T10:45:36 DUE TO TIME LIMIT ***
srun: error: sls-sm-16: task 0: Terminated
srun: Force Terminated job step 82585.0
