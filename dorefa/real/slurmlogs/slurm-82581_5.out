sls-titan-10 0
SLURM_JOBID=82581
SLURM_TASKID=5
[32m[0323 10:45:59 @logger.py:67][0m Existing log file 'train_log/lcn_w_32_a_32_quant_ends_False/log.log' backuped to 'train_log/lcn_w_32_a_32_quant_ends_False/log.log.0323-104559'
[32m[0323 10:45:59 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=32 --bita=32 --quant_ends=False
[32m[0323 10:46:17 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 10:46:17 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 10:46:18 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 10:46:18 @drf_run.py:166][0m Using host: sls-titan-10
[32m[0323 10:46:18 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 10:46:18 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 10:46:18 @drf_run.py:188][0m Using GPU: 0
[32m[0323 10:46:18 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 10:46:18 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 10:46:18 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 10:46:18 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0323 10:46:18 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:18 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 10:46:18 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 10:46:18 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:18 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 10:46:18 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 10:46:18 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:18 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 10:46:18 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 10:46:18 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:18 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:18 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 10:46:19 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:19 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0323 10:46:19 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 10:46:19 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0323 10:46:19 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0323 10:46:19 @base.py:196][0m Setup callbacks graph ...
[32m[0323 10:46:20 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:20 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:20 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:20 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:20 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:20 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:20 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:20 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:20 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0323 10:46:20 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 10:46:20 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0323 10:46:20 @base.py:212][0m Creating the session ...
2018-03-23 10:46:21.234973: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-23 10:46:23.802858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:02:00.0
totalMemory: 11.92GiB freeMemory: 11.81GiB
2018-03-23 10:46:23.802901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0, compute capability: 5.2)
[32m[0323 10:46:30 @base.py:220][0m Initializing the session ...
[32m[0323 10:46:30 @base.py:227][0m Graph Finalized.
[32m[0323 10:46:30 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 10:46:34 @monitor.py:251][0m Found existing JSON at train_log/lcn_w_32_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 10:46:34 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 10:46:34 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11795/173481[03:00<41:07,65.52it/s]  7%|7         |12480/173481[03:10<40:57,65.52it/s] 14%|#3        |23526/173481[06:00<38:14,65.34it/s] 14%|#3        |24156/173481[06:10<38:05,65.34it/s] 20%|#9        |34461/173481[09:00<36:48,62.96it/s] 20%|##        |35097/173481[09:10<36:37,62.96it/s] 25%|##4       |42686/173481[12:00<41:10,52.94it/s] 25%|##4       |42730/173481[12:10<41:09,52.94it/s] 25%|##5       |43821/173481[15:04<3:16:18,11.01it/s] 25%|##5       |44036/173481[15:20<3:15:58,11.01it/s] 30%|###       |52137/173481[18:04<1:53:44,17.78it/s] 31%|###       |53576/173481[18:20<1:52:23,17.78it/s] 38%|###8      |66343/173481[21:04<1:01:31,29.02it/s] 39%|###8      |67290/173481[21:21<1:00:58,29.02it/s] 44%|####4     |76876/173481[24:04<41:29,38.80it/s]   45%|####4     |77763/173481[24:21<41:06,38.80it/s] 50%|#####     |86807/173481[27:04<31:42,45.56it/s] 51%|#####     |88082/173481[27:21<31:14,45.56it/s] 58%|#####7    |99976/173481[30:04<21:49,56.15it/s] 58%|#####8    |101206/173481[30:21<21:27,56.15it/s] 65%|######5   |113182/173481[33:04<15:47,63.61it/s] 66%|######5   |114393/173481[33:21<15:28,63.61it/s] 73%|#######2  |126161/173481[36:04<11:40,67.59it/s] 73%|#######3  |127406/173481[36:21<11:21,67.59it/s] 80%|########  |139311/173481[39:04<08:06,70.21it/s] 81%|########1 |140535/173481[39:21<07:49,70.21it/s] 87%|########7 |151165/173481[42:04<05:28,67.96it/s] 88%|########7 |152150/173481[42:22<05:13,67.96it/s] 93%|#########3|161590/173481[45:04<03:10,62.54it/s] 94%|#########3|162555/173481[45:22<02:54,62.54it/s]100%|#########9|172843/173481[48:04<00:10,62.53it/s]100%|##########|173481/173481[48:16<00:00,59.90it/s]
[32m[0323 11:34:51 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2896.15 sec.
[32m[0323 11:34:51 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.42it/s]
0
[32m[0323 11:36:59 @monitor.py:363][0m QueueInput/queue_size: 1.4301
[32m[0323 11:36:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8621
[32m[0323 11:36:59 @monitor.py:363][0m activation-summaries/output-rms: 0.030827
[32m[0323 11:36:59 @monitor.py:363][0m cross_entropy_loss: 2.4585
[32m[0323 11:36:59 @monitor.py:363][0m lr: 0.001
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.18407
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 2.5372e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.15461
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 2.7474e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.17634
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 3.5438e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.14967
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 2.1333e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.1794
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.3241e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14816
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 2.8742e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.17744
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 2.4144e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14794
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 2.0364e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.18826
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 3.8674e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.15334
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 2.4321e-06
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13742
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.66132
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14897
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089446
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12386
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087087
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11764
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089051
[32m[0323 11:36:59 @monitor.py:363][0m train-error-top1: 0.61147
[32m[0323 11:36:59 @monitor.py:363][0m val-error-top1: 0.66712
[32m[0323 11:36:59 @monitor.py:363][0m val-utt-error: 0.33647
[32m[0323 11:36:59 @monitor.py:363][0m validation_cost: 2.7325
[32m[0323 11:36:59 @monitor.py:363][0m wd_cost: 0.52596
[32m[0323 11:36:59 @group.py:42][0m Callbacks took 128.036 sec in total. InferenceRunner: 127.689sec
[32m[0323 11:36:59 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14420/173481[03:00<33:05,80.11it/s]  9%|8         |15144/173481[03:10<32:56,80.11it/s] 15%|#5        |26235/173481[06:00<34:00,72.15it/s] 15%|#5        |26854/173481[06:10<33:52,72.15it/s] 21%|##1       |36560/173481[09:00<35:42,63.90it/s] 21%|##1       |37124/173481[09:10<35:33,63.90it/s] 27%|##7       |47426/173481[12:00<33:50,62.08it/s] 28%|##7       |48044/173481[12:10<33:40,62.08it/s] 34%|###3      |58646/173481[15:00<30:46,62.21it/s] 34%|###4      |59336/173481[15:10<30:34,62.21it/s] 40%|####      |69561/173481[18:00<28:12,61.41it/s] 40%|####      |70251/173481[18:10<28:00,61.41it/s] 47%|####6     |80771/173481[21:00<24:59,61.84it/s] 47%|####6     |81438/173481[21:11<24:48,61.84it/s] 53%|#####2    |91943/173481[24:00<21:56,61.95it/s] 53%|#####3    |92629/173481[24:11<21:45,61.95it/s] 59%|#####9    |103060/173481[27:00<18:58,61.85it/s] 60%|#####9    |103789/173481[27:11<18:46,61.85it/s] 66%|######5   |114445/173481[30:00<15:43,62.54it/s] 66%|######6   |115099/173481[30:11<15:33,62.54it/s] 72%|#######2  |125265/173481[33:00<13:06,61.29it/s] 73%|#######2  |125904/173481[33:11<12:56,61.29it/s] 78%|#######8  |135690/173481[36:00<10:34,59.53it/s] 79%|#######8  |136328/173481[36:11<10:24,59.53it/s] 84%|########4 |146115/173481[39:00<07:46,58.70it/s] 85%|########4 |146852/173481[39:12<07:33,58.70it/s] 90%|######### |156905/173481[42:00<04:39,59.31it/s] 91%|######### |157616/173481[42:12<04:27,59.31it/s] 97%|#########6|168139/173481[45:00<01:27,60.82it/s] 97%|#########7|168874/173481[45:12<01:15,60.82it/s]100%|##########|173481/173481[46:27<00:00,62.25it/s]
[32m[0323 12:23:26 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2787.05 sec.
[32m[0323 12:23:26 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-346962.
[32m[0323 12:23:26 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.23it/s]
1
[32m[0323 12:25:22 @monitor.py:363][0m QueueInput/queue_size: 1.2383
[32m[0323 12:25:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9953
[32m[0323 12:25:22 @monitor.py:363][0m activation-summaries/output-rms: 0.030706
[32m[0323 12:25:22 @monitor.py:363][0m cross_entropy_loss: 2.4715
[32m[0323 12:25:22 @monitor.py:363][0m lr: 0.001
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.18491
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0a/b-rms: 6.9259e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.15302
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.6596e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.17175
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.8894e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.1473
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0d/b-rms: 3.3055e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.17968
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0e/b-rms: 8.526e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14757
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.2712e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.17494
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0g/b-rms: 2.7703e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14667
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9422e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.18997
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.0932e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.15213
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/conv0j/b-rms: 2.5353e-06
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.1383
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.90067
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14992
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12339
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087087
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.1172
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089049
[32m[0323 12:25:22 @monitor.py:363][0m train-error-top1: 0.62079
[32m[0323 12:25:22 @monitor.py:363][0m val-error-top1: 0.66163
[32m[0323 12:25:22 @monitor.py:363][0m val-utt-error: 0.3268
[32m[0323 12:25:22 @monitor.py:363][0m validation_cost: 2.7025
[32m[0323 12:25:22 @monitor.py:363][0m wd_cost: 0.52701
[32m[0323 12:25:22 @group.py:42][0m Callbacks took 116.021 sec in total. InferenceRunner: 115.318sec
[32m[0323 12:25:22 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15369/173481[03:00<30:51,85.38it/s]  9%|9         |16282/173481[03:10<30:41,85.38it/s] 16%|#5        |27284/173481[06:00<32:40,74.56it/s] 16%|#6        |27868/173481[06:10<32:33,74.56it/s] 22%|##1       |37480/173481[09:00<35:12,64.38it/s] 22%|##1       |38058/173481[09:10<35:03,64.38it/s] 28%|##7       |47809/173481[12:00<34:31,60.68it/s] 28%|##7       |48419/173481[12:10<34:21,60.68it/s] 34%|###3      |58229/173481[15:00<32:25,59.25it/s] 34%|###3      |58888/173481[15:10<32:14,59.25it/s] 40%|###9      |69324/173481[18:00<28:44,60.41it/s] 40%|####      |70029/173481[18:10<28:32,60.41it/s] 47%|####6     |80853/173481[21:00<24:49,62.18it/s] 47%|####7     |81568/173481[21:11<24:38,62.18it/s] 53%|#####3    |92404/173481[24:00<21:23,63.15it/s] 54%|#####3    |93146/173481[24:11<21:12,63.15it/s] 60%|#####9    |103884/173481[27:00<18:16,63.45it/s] 60%|######    |104483/173481[27:11<18:07,63.45it/s] 66%|######6   |115289/173481[30:00<15:17,63.40it/s] 67%|######6   |116018/173481[30:11<15:06,63.40it/s] 73%|#######2  |126614/173481[33:00<12:22,63.15it/s] 73%|#######3  |127395/173481[33:11<12:09,63.15it/s] 80%|#######9  |138520/173481[36:00<09:01,64.61it/s] 80%|########  |139279/173481[36:11<08:49,64.61it/s] 87%|########6 |150365/173481[39:00<05:54,65.20it/s] 87%|########7 |151123/173481[39:12<05:42,65.20it/s] 94%|#########3|162421/173481[42:00<02:47,66.08it/s] 94%|#########4|163195/173481[42:12<02:35,66.08it/s]100%|##########|173481/173481[44:47<00:00,64.54it/s]
[32m[0323 13:10:10 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2687.87 sec.
[32m[0323 13:10:10 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-520443.
[32m[0323 13:10:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.61it/s]
2
[32m[0323 13:12:05 @monitor.py:363][0m QueueInput/queue_size: 0.86198
[32m[0323 13:12:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.9862
[32m[0323 13:12:05 @monitor.py:363][0m activation-summaries/output-rms: 0.035625
[32m[0323 13:12:05 @monitor.py:363][0m cross_entropy_loss: 2.017
[32m[0323 13:12:05 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.25031
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.4846e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.20238
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0b/b-rms: 4.7398e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.23407
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0c/b-rms: 5.7217e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.19582
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0d/b-rms: 3.761e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.24274
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.2167e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.19537
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.3743e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.23408
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4373e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.19467
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.2719e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.25777
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.6065e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.19929
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.473e-06
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.18721
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0247
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.19503
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.16975
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16504
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089051
[32m[0323 13:12:05 @monitor.py:363][0m train-error-top1: 0.52192
[32m[0323 13:12:05 @monitor.py:363][0m val-error-top1: 0.55372
[32m[0323 13:12:05 @monitor.py:363][0m val-utt-error: 0.19196
[32m[0323 13:12:05 @monitor.py:363][0m validation_cost: 2.1559
[32m[0323 13:12:05 @monitor.py:363][0m wd_cost: 0.19252
[32m[0323 13:12:05 @group.py:42][0m Callbacks took 115.394 sec in total. InferenceRunner: 115.053sec
[32m[0323 13:12:05 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13188/173481[03:00<36:27,73.26it/s]  8%|7         |13852/173481[03:10<36:18,73.26it/s] 14%|#4        |24413/173481[06:00<36:52,67.37it/s] 14%|#4        |25020/173481[06:10<36:43,67.37it/s] 21%|##        |36196/173481[09:00<34:27,66.40it/s] 21%|##1       |36917/173481[09:10<34:16,66.40it/s] 28%|##7       |48193/173481[12:00<31:23,66.53it/s] 28%|##8       |48927/173481[12:10<31:12,66.53it/s] 35%|###4      |60140/173481[15:00<28:25,66.45it/s] 35%|###5      |60862/173481[15:10<28:14,66.45it/s] 42%|####1     |72308/173481[18:00<25:09,67.02it/s] 42%|####2     |73055/173481[18:10<24:58,67.02it/s] 49%|####8     |84273/173481[21:00<22:16,66.74it/s] 49%|####8     |84997/173481[21:11<22:05,66.74it/s] 55%|#####5    |96143/173481[24:00<19:25,66.34it/s] 56%|#####5    |96902/173481[24:11<19:14,66.34it/s] 62%|######2   |108235/173481[27:00<16:17,66.75it/s] 63%|######2   |108986/173481[27:11<16:06,66.75it/s] 69%|######9   |120048/173481[30:00<13:27,66.18it/s] 70%|######9   |120822/173481[30:11<13:15,66.18it/s] 76%|#######6  |131998/173481[33:00<10:25,66.28it/s] 77%|#######6  |132768/173481[33:11<10:14,66.28it/s] 83%|########3 |144043/173481[36:00<07:22,66.59it/s] 83%|########3 |144796/173481[36:11<07:10,66.59it/s] 90%|########9 |155624/173481[39:00<04:32,65.45it/s] 90%|######### |156392/173481[39:12<04:21,65.45it/s] 96%|#########6|167053/173481[42:00<01:39,64.45it/s] 97%|#########6|167751/173481[42:12<01:28,64.45it/s]100%|##########|173481/173481[43:47<00:00,66.02it/s]
[32m[0323 13:55:53 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2627.82 sec.
[32m[0323 13:55:53 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-693924.
[32m[0323 13:55:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,183.81it/s]
3
[32m[0323 13:57:36 @monitor.py:363][0m QueueInput/queue_size: 0.65421
[32m[0323 13:57:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.5574
[32m[0323 13:57:36 @monitor.py:363][0m activation-summaries/output-rms: 0.0363
[32m[0323 13:57:36 @monitor.py:363][0m cross_entropy_loss: 1.9393
[32m[0323 13:57:36 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.27741
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.6966e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.2213
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 4.8441e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.25719
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5257e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.21534
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3615e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.26628
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.6737e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.21509
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.2006e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.25788
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.3831e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21343
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.9173e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.28611
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 7.5644e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.21864
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.2014e-06
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21796
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0956
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.22337
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089447
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19771
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18753
[32m[0323 13:57:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 13:57:36 @monitor.py:363][0m train-error-top1: 0.51258
[32m[0323 13:57:36 @monitor.py:363][0m val-error-top1: 0.5346
[32m[0323 13:57:36 @monitor.py:363][0m val-utt-error: 0.18218
[32m[0323 13:57:36 @monitor.py:363][0m validation_cost: 2.0743
[32m[0323 13:57:36 @monitor.py:363][0m wd_cost: 0.25308
[32m[0323 13:57:36 @group.py:42][0m Callbacks took 102.907 sec in total. InferenceRunner: 102.413sec
[32m[0323 13:57:36 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12136/173481[03:00<39:53,67.42it/s]  7%|7         |12761/173481[03:10<39:43,67.42it/s] 13%|#3        |23273/173481[06:00<38:47,64.53it/s] 14%|#3        |23932/173481[06:10<38:37,64.53it/s] 20%|##        |35239/173481[09:00<35:10,65.49it/s] 21%|##        |35916/173481[09:10<35:00,65.49it/s] 27%|##7       |46998/173481[12:00<32:13,65.41it/s] 27%|##7       |47681/173481[12:10<32:03,65.41it/s] 34%|###3      |58798/173481[15:00<29:11,65.48it/s] 34%|###4      |59517/173481[15:10<29:00,65.48it/s] 40%|####      |70249/173481[18:00<26:39,64.53it/s] 41%|####      |70851/173481[18:10<26:30,64.53it/s] 47%|####7     |81771/173481[21:00<23:46,64.27it/s] 48%|####7     |82462/173481[21:11<23:36,64.27it/s] 54%|#####3    |93325/173481[24:00<20:48,64.23it/s] 54%|#####4    |94057/173481[24:11<20:36,64.23it/s] 60%|######    |104909/173481[27:00<17:46,64.29it/s] 61%|######    |105630/173481[27:11<17:35,64.29it/s] 67%|######7   |116466/173481[30:00<14:47,64.25it/s] 68%|######7   |117226/173481[30:11<14:35,64.25it/s] 74%|#######3  |128020/173481[33:00<11:47,64.22it/s] 74%|#######4  |128806/173481[33:11<11:35,64.22it/s] 80%|########  |139626/173481[36:00<08:46,64.35it/s] 81%|########  |140409/173481[36:11<08:33,64.35it/s] 87%|########7 |151507/173481[39:00<05:37,65.16it/s] 88%|########7 |152301/173481[39:12<05:25,65.16it/s] 94%|#########3|162997/173481[42:00<02:42,64.49it/s] 94%|#########4|163701/173481[42:12<02:31,64.49it/s]100%|##########|173481/173481[44:54<00:00,64.38it/s]
[32m[0323 14:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2694.53 sec.
[32m[0323 14:42:30 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-867405.
[32m[0323 14:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:08<00:00,146.94it/s]
4
[32m[0323 14:44:39 @monitor.py:363][0m QueueInput/queue_size: 0.4648
[32m[0323 14:44:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.4639
[32m[0323 14:44:39 @monitor.py:363][0m activation-summaries/output-rms: 0.038326
[32m[0323 14:44:39 @monitor.py:363][0m cross_entropy_loss: 1.8988
[32m[0323 14:44:39 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.27877
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 8.694e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.22258
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 4.9951e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.2568
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 5.9347e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.21636
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.4927e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.26613
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.6952e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.21594
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.4626e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.25974
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6132e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21486
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.8084e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.28547
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.7803e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.22021
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.3511e-06
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.22176
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1564
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.22491
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20042
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18967
[32m[0323 14:44:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 14:44:39 @monitor.py:363][0m train-error-top1: 0.4971
[32m[0323 14:44:39 @monitor.py:363][0m val-error-top1: 0.5301
[32m[0323 14:44:39 @monitor.py:363][0m val-utt-error: 0.17363
[32m[0323 14:44:39 @monitor.py:363][0m validation_cost: 2.0513
[32m[0323 14:44:39 @monitor.py:363][0m wd_cost: 0.25882
[32m[0323 14:44:39 @group.py:42][0m Callbacks took 129.085 sec in total. InferenceRunner: 128.107sec
[32m[0323 14:44:39 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14691/173481[03:00<32:25,81.61it/s]  9%|8         |15375/173481[03:10<32:17,81.61it/s] 15%|#5        |26546/173481[06:00<33:35,72.89it/s] 16%|#5        |27210/173481[06:10<33:26,72.89it/s] 22%|##1       |37501/173481[09:00<34:10,66.33it/s] 22%|##1       |38133/173481[09:10<34:00,66.33it/s] 30%|##9       |51511/173481[12:00<28:23,71.62it/s] 30%|###       |52330/173481[12:10<28:11,71.62it/s] 38%|###7      |65556/173481[15:00<24:05,74.68it/s] 38%|###8      |66410/173481[15:10<23:53,74.68it/s] 46%|####5     |79300/173481[18:00<20:47,75.51it/s] 46%|####6     |80057/173481[18:10<20:37,75.51it/s] 54%|#####4    |93857/173481[21:00<16:59,78.10it/s] 55%|#####4    |94646/173481[21:11<16:49,78.10it/s] 60%|######    |104887/173481[24:00<16:38,68.67it/s] 61%|######    |105558/173481[24:11<16:29,68.67it/s] 67%|######6   |115684/173481[27:00<15:02,64.03it/s] 67%|######7   |116365/173481[27:11<14:51,64.03it/s] 73%|#######2  |126494/173481[30:00<12:38,61.98it/s] 73%|#######3  |127211/173481[30:11<12:26,61.98it/s] 79%|#######9  |137468/173481[33:00<09:45,61.47it/s] 80%|#######9  |138175/173481[33:11<09:34,61.47it/s] 86%|########5 |148449/173481[36:00<06:48,61.23it/s] 86%|########5 |149172/173481[36:11<06:36,61.23it/s] 92%|#########1|159081/173481[39:00<03:59,60.13it/s] 92%|#########2|159822/173481[39:12<03:47,60.13it/s] 98%|#########8|170046/173481[42:00<00:56,60.52it/s] 98%|#########8|170790/173481[42:12<00:44,60.52it/s]100%|##########|173481/173481[42:57<00:00,67.32it/s]
[32m[0323 15:27:36 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:2577.15 sec.
[32m[0323 15:27:37 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-1040886.
[32m[0323 15:27:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.66it/s]
5
[32m[0323 15:30:03 @monitor.py:363][0m QueueInput/queue_size: 0.34366
[32m[0323 15:30:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.621
[32m[0323 15:30:03 @monitor.py:363][0m activation-summaries/output-rms: 0.039436
[32m[0323 15:30:03 @monitor.py:363][0m cross_entropy_loss: 1.7674
[32m[0323 15:30:03 @monitor.py:363][0m lr: 0.00025
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.32076
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0a/b-rms: 8.5228e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.24808
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.425e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.29608
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.1563e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.24216
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2898e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3088
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0e/b-rms: 1.0164e-05
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.24285
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5573e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.30157
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.9506e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.24102
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.2382e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.33056
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.5262e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.24592
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7448e-06
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26116
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1997
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.24501
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089449
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.22243
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.21284
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 15:30:03 @monitor.py:363][0m train-error-top1: 0.46474
[32m[0323 15:30:03 @monitor.py:363][0m val-error-top1: 0.4848
[32m[0323 15:30:03 @monitor.py:363][0m val-utt-error: 0.13739
[32m[0323 15:30:03 @monitor.py:363][0m validation_cost: 1.8498
[32m[0323 15:30:03 @monitor.py:363][0m wd_cost: 0.065858
[32m[0323 15:30:03 @group.py:42][0m Callbacks took 146.912 sec in total. InferenceRunner: 145.169sec
[32m[0323 15:30:03 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14044/173481[03:00<34:03,78.02it/s]  8%|8         |14658/173481[03:10<33:55,78.02it/s] 14%|#4        |25146/173481[06:00<35:53,68.89it/s] 15%|#4        |25749/173481[06:10<35:44,68.89it/s] 20%|##        |35480/173481[09:00<36:43,62.62it/s] 21%|##        |36049/173481[09:10<36:34,62.62it/s] 26%|##6       |45510/173481[12:00<36:10,58.96it/s] 27%|##6       |46109/173481[12:10<36:00,58.96it/s] 33%|###2      |56446/173481[15:00<32:35,59.84it/s] 33%|###2      |57129/173481[15:10<32:24,59.84it/s] 39%|###8      |67330/173481[18:00<29:24,60.15it/s] 39%|###9      |67999/173481[18:10<29:13,60.15it/s] 45%|####5     |78544/173481[21:00<25:51,61.20it/s] 46%|####5     |79194/173481[21:11<25:40,61.20it/s] 52%|#####1    |89869/173481[24:00<22:27,62.05it/s] 52%|#####2    |90599/173481[24:11<22:15,62.05it/s] 58%|#####8    |101106/173481[27:00<19:22,62.24it/s] 59%|#####8    |101789/173481[27:11<19:11,62.24it/s] 65%|######4   |112190/173481[30:00<16:30,61.90it/s] 65%|######5   |112826/173481[30:11<16:19,61.90it/s] 71%|#######   |123123/173481[33:00<13:41,61.31it/s] 71%|#######1  |123825/173481[33:11<13:29,61.31it/s] 77%|#######7  |134103/173481[36:00<10:43,61.16it/s] 78%|#######7  |134804/173481[36:11<10:32,61.16it/s] 86%|########6 |149747/173481[39:00<05:30,71.79it/s] 87%|########6 |150917/173481[39:12<05:14,71.79it/s] 97%|#########6|167448/173481[42:00<01:12,82.99it/s] 97%|#########7|168726/173481[42:12<00:57,82.99it/s]100%|##########|173481/173481[43:14<00:00,66.87it/s]
[32m[0323 16:13:18 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:2594.37 sec.
[32m[0323 16:13:18 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-1214367.
[32m[0323 16:13:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,189.89it/s]
6
[32m[0323 16:14:57 @monitor.py:363][0m QueueInput/queue_size: 0.78898
[32m[0323 16:14:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 17.769
[32m[0323 16:14:57 @monitor.py:363][0m activation-summaries/output-rms: 0.039189
[32m[0323 16:14:57 @monitor.py:363][0m cross_entropy_loss: 1.7709
[32m[0323 16:14:57 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.36128
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 8.1011e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27714
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.445e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.33284
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.6214e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.27138
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3855e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.34478
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.5376e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.27236
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5367e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.33809
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6452e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26909
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5404e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.37275
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.8882e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.27427
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.9246e-06
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31008
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2223
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27359
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25115
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.24179
[32m[0323 16:14:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 16:14:57 @monitor.py:363][0m train-error-top1: 0.47733
[32m[0323 16:14:57 @monitor.py:363][0m val-error-top1: 0.47824
[32m[0323 16:14:57 @monitor.py:363][0m val-utt-error: 0.12985
[32m[0323 16:14:57 @monitor.py:363][0m validation_cost: 1.8198
[32m[0323 16:14:57 @monitor.py:363][0m wd_cost: 0.085984
[32m[0323 16:14:57 @group.py:42][0m Callbacks took 99.404 sec in total. InferenceRunner: 99.131sec
[32m[0323 16:14:57 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12254/173481[03:00<39:28,68.06it/s]  7%|7         |12888/173481[03:10<39:19,68.06it/s] 13%|#3        |23211/173481[06:00<38:58,64.27it/s] 14%|#3        |23783/173481[06:10<38:49,64.27it/s] 19%|#9        |33269/173481[09:00<39:05,59.77it/s] 20%|#9        |33869/173481[09:10<38:55,59.77it/s] 25%|##5       |43869/173481[12:00<36:24,59.33it/s] 26%|##5       |44494/173481[12:10<36:14,59.33it/s] 31%|###1      |54306/173481[15:00<33:52,58.65it/s] 32%|###1      |54945/173481[15:10<33:41,58.65it/s] 37%|###7      |65044/173481[18:00<30:33,59.15it/s] 38%|###7      |65735/173481[18:10<30:21,59.15it/s] 44%|####4     |76529/173481[21:00<26:19,61.38it/s] 45%|####4     |77213/173481[21:11<26:08,61.38it/s] 51%|#####     |87702/173481[24:00<23:09,61.72it/s] 51%|#####     |88418/173481[24:11<22:58,61.72it/s] 57%|#####7    |99003/173481[27:00<19:56,62.25it/s] 57%|#####7    |99685/173481[27:11<19:45,62.25it/s] 64%|######3   |110674/173481[30:00<16:28,63.52it/s] 64%|######4   |111384/173481[30:11<16:17,63.52it/s] 70%|#######   |122082/173481[33:00<13:30,63.45it/s] 71%|#######   |122743/173481[33:11<13:19,63.45it/s] 77%|#######6  |133364/173481[36:00<10:36,63.05it/s] 77%|#######7  |134131/173481[36:11<10:24,63.05it/s] 84%|########3 |145264/173481[39:00<07:17,64.54it/s] 84%|########4 |146072/173481[39:12<07:04,64.54it/s] 90%|######### |156994/173481[42:00<04:14,64.85it/s] 91%|######### |157770/173481[42:12<04:02,64.85it/s] 97%|#########7|168315/173481[45:00<01:20,63.86it/s] 97%|#########7|169113/173481[45:12<01:08,63.86it/s]100%|##########|173481/173481[46:20<00:00,62.39it/s]
[32m[0323 17:01:18 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:2780.71 sec.
[32m[0323 17:01:18 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-1387848.
[32m[0323 17:01:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.49it/s]
7
[32m[0323 17:03:17 @monitor.py:363][0m QueueInput/queue_size: 0.89178
[32m[0323 17:03:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.844
[32m[0323 17:03:17 @monitor.py:363][0m activation-summaries/output-rms: 0.039304
[32m[0323 17:03:17 @monitor.py:363][0m cross_entropy_loss: 1.7404
[32m[0323 17:03:17 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.38566
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0a/b-rms: 8.8509e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.29785
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5615e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.35649
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9161e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.29042
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3042e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.36764
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.6075e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.29238
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.4365e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.36259
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6626e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.2886
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.6562e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.39814
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.2364e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.29343
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/conv0j/b-rms: 5.0051e-06
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.34757
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2427
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29526
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27231
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26269
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 17:03:17 @monitor.py:363][0m train-error-top1: 0.46475
[32m[0323 17:03:17 @monitor.py:363][0m val-error-top1: 0.47248
[32m[0323 17:03:17 @monitor.py:363][0m val-utt-error: 0.12868
[32m[0323 17:03:17 @monitor.py:363][0m validation_cost: 1.7914
[32m[0323 17:03:17 @monitor.py:363][0m wd_cost: 0.10268
[32m[0323 17:03:17 @group.py:42][0m Callbacks took 119.147 sec in total. InferenceRunner: 118.769sec
[32m[0323 17:03:17 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13232/173481[03:00<36:20,73.51it/s]  8%|7         |13857/173481[03:10<36:11,73.51it/s] 14%|#3        |24078/173481[06:00<37:36,66.22it/s] 14%|#4        |24694/173481[06:10<37:26,66.22it/s] 20%|##        |35468/173481[09:00<35:32,64.71it/s] 21%|##        |36152/173481[09:10<35:22,64.71it/s] 27%|##7       |47198/173481[12:00<32:24,64.94it/s] 28%|##7       |47901/173481[12:10<32:13,64.94it/s] 34%|###3      |58487/173481[15:00<30:02,63.81it/s] 34%|###4      |59170/173481[15:10<29:51,63.81it/s] 40%|####      |70183/173481[18:00<26:44,64.38it/s] 41%|####      |70867/173481[18:10<26:33,64.38it/s] 47%|####7     |81734/173481[21:00<23:47,64.28it/s] 48%|####7     |82428/173481[21:11<23:36,64.28it/s] 53%|#####3    |92795/173481[24:00<21:24,62.83it/s] 54%|#####3    |93521/173481[24:11<21:12,62.83it/s] 60%|######    |104313/173481[27:00<18:10,63.40it/s] 61%|######    |105042/173481[27:11<17:59,63.40it/s] 67%|######6   |115842/173481[30:00<15:04,63.72it/s] 67%|######7   |116532/173481[30:11<14:53,63.72it/s] 73%|#######3  |127204/173481[33:00<12:09,63.42it/s] 74%|#######3  |127917/173481[33:11<11:58,63.42it/s] 80%|#######9  |138448/173481[36:00<09:16,62.94it/s] 80%|########  |139202/173481[36:11<09:04,62.94it/s] 86%|########6 |150000/173481[39:00<06:09,63.55it/s] 87%|########6 |150832/173481[39:11<05:56,63.55it/s] 93%|#########3|161953/173481[42:00<02:57,64.94it/s] 94%|#########3|162643/173481[42:12<02:46,64.94it/s] 99%|#########9|171987/173481[45:00<00:24,59.99it/s]100%|#########9|172722/173481[45:12<00:12,59.99it/s]100%|##########|173481/173481[45:25<00:00,63.65it/s]
[32m[0323 17:48:43 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:2725.55 sec.
[32m[0323 17:48:43 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-1561329.
[32m[0323 17:48:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,187.21it/s]
8
[32m[0323 17:50:24 @monitor.py:363][0m QueueInput/queue_size: 1.0962
[32m[0323 17:50:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 24.332
[32m[0323 17:50:24 @monitor.py:363][0m activation-summaries/output-rms: 0.039739
[32m[0323 17:50:24 @monitor.py:363][0m cross_entropy_loss: 1.6571
[32m[0323 17:50:24 @monitor.py:363][0m lr: 0.000125
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40882
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.3641e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.30919
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5444e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.37867
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.7467e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.30135
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.206e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.39027
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.7211e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.30406
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5165e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.3852
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.618e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.29965
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.6773e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41964
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0633e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.30516
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.8894e-06
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.3845
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2552
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30515
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28239
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27265
[32m[0323 17:50:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 17:50:24 @monitor.py:363][0m train-error-top1: 0.44135
[32m[0323 17:50:24 @monitor.py:363][0m val-error-top1: 0.45389
[32m[0323 17:50:24 @monitor.py:363][0m val-utt-error: 0.11417
[32m[0323 17:50:24 @monitor.py:363][0m validation_cost: 1.714
[32m[0323 17:50:24 @monitor.py:363][0m wd_cost: 0.023064
[32m[0323 17:50:24 @group.py:42][0m Callbacks took 101.309 sec in total. InferenceRunner: 100.549sec
[32m[0323 17:50:24 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12347/173481[03:00<39:09,68.59it/s]  7%|7         |12976/173481[03:10<39:00,68.59it/s] 13%|#3        |23098/173481[06:00<39:15,63.85it/s] 14%|#3        |23716/173481[06:10<39:05,63.85it/s] 20%|#9        |34572/173481[09:00<36:17,63.80it/s] 20%|##        |35216/173481[09:10<36:07,63.80it/s] 26%|##6       |45867/173481[12:00<33:37,63.27it/s] 27%|##6       |46516/173481[12:10<33:26,63.27it/s] 33%|###2      |57247/173481[15:00<30:37,63.24it/s] 33%|###3      |57951/173481[15:10<30:26,63.24it/s] 39%|###9      |68142/173481[18:00<28:23,61.85it/s] 40%|###9      |68826/173481[18:10<28:12,61.85it/s] 46%|####5     |79297/173481[21:00<25:21,61.90it/s] 46%|####6     |79987/173481[21:11<25:10,61.90it/s] 52%|#####2    |90611/173481[24:00<22:08,62.37it/s] 53%|#####2    |91276/173481[24:11<21:57,62.37it/s] 58%|#####8    |101450/173481[27:00<19:35,61.27it/s] 59%|#####8    |102105/173481[27:11<19:24,61.27it/s] 65%|######4   |112059/173481[30:00<17:02,60.08it/s] 65%|######5   |112767/173481[30:11<16:50,60.08it/s] 72%|#######1  |124153/173481[33:00<12:57,63.44it/s] 72%|#######2  |124973/173481[33:11<12:44,63.44it/s] 79%|#######9  |137117/173481[36:00<08:59,67.46it/s] 80%|#######9  |138014/173481[36:11<08:45,67.46it/s] 87%|########7 |151299/173481[39:00<05:05,72.68it/s] 88%|########7 |152212/173481[39:12<04:52,72.68it/s] 95%|#########5|165387/173481[42:00<01:47,75.37it/s] 96%|#########5|166346/173481[42:12<01:34,75.37it/s]100%|##########|173481/173481[43:53<00:00,65.87it/s]
[32m[0323 18:34:18 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:2633.83 sec.
[32m[0323 18:34:18 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-1734810.
[32m[0323 18:34:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:43<00:00,182.41it/s]
9
[32m[0323 18:36:02 @monitor.py:363][0m QueueInput/queue_size: 0.54722
[32m[0323 18:36:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.792
[32m[0323 18:36:02 @monitor.py:363][0m activation-summaries/output-rms: 0.041647
[32m[0323 18:36:02 @monitor.py:363][0m cross_entropy_loss: 1.6464
[32m[0323 18:36:02 @monitor.py:363][0m lr: 0.000125
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.43083
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1591e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.3228
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5464e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.40042
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.7067e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3158
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2685e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.41298
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8996e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.31783
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.4775e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.40833
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6828e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.31444
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.8337e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.44458
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.1064e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3195
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.8157e-06
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.42319
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2641
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31705
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29454
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28516
[32m[0323 18:36:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 18:36:02 @monitor.py:363][0m train-error-top1: 0.43897
[32m[0323 18:36:02 @monitor.py:363][0m val-error-top1: 0.45284
[32m[0323 18:36:02 @monitor.py:363][0m val-utt-error: 0.1154
[32m[0323 18:36:02 @monitor.py:363][0m validation_cost: 1.709
[32m[0323 18:36:02 @monitor.py:363][0m wd_cost: 0.026084
[32m[0323 18:36:02 @group.py:42][0m Callbacks took 103.852 sec in total. InferenceRunner: 103.193sec
[32m[0323 18:36:02 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12389/173481[03:00<39:00,68.83it/s]  8%|7         |13170/173481[03:10<38:49,68.83it/s] 14%|#4        |24831/173481[06:00<35:55,68.96it/s] 15%|#4        |25440/173481[06:10<35:46,68.96it/s] 20%|#9        |34442/173481[09:00<38:30,60.18it/s] 20%|##        |34964/173481[09:10<38:21,60.18it/s] 25%|##4       |42998/173481[12:00<40:56,53.12it/s] 25%|##5       |43474/173481[12:10<40:47,53.12it/s] 30%|##9       |51576/173481[15:00<40:26,50.23it/s] 30%|###       |52047/173481[15:10<40:17,50.23it/s] 35%|###4      |60616/173481[18:00<37:27,50.23it/s] 35%|###5      |61315/173481[18:10<37:13,50.23it/s] 41%|####      |70351/173481[21:00<33:00,52.07it/s] 41%|####      |70830/173481[21:11<32:51,52.07it/s] 46%|####5     |79436/173481[24:00<30:34,51.26it/s] 46%|####6     |79994/173481[24:11<30:23,51.26it/s] 51%|#####1    |88676/173481[27:00<27:33,51.29it/s] 51%|#####1    |89234/173481[27:11<27:22,51.29it/s] 56%|#####6    |97971/173481[30:00<24:27,51.46it/s] 57%|#####6    |98555/173481[30:11<24:16,51.46it/s] 62%|######1   |106956/173481[33:00<21:52,50.68it/s] 62%|######1   |107545/173481[33:11<21:41,50.68it/s] 68%|######8   |118356/173481[36:00<16:19,56.30it/s] 69%|######8   |119073/173481[36:11<16:06,56.30it/s] 74%|#######4  |129133/173481[39:00<12:44,58.03it/s] 75%|#######4  |129870/173481[39:12<12:31,58.03it/s] 80%|########  |139341/173481[42:00<09:55,57.35it/s] 81%|########  |139982/173481[42:12<09:44,57.35it/s] 86%|########5 |149095/173481[45:00<07:17,55.73it/s] 86%|########6 |149790/173481[45:12<07:05,55.73it/s] 92%|#########1|158945/173481[48:00<04:23,55.22it/s] 92%|#########1|159602/173481[48:12<04:11,55.22it/s] 97%|#########6|168085/173481[51:00<01:41,52.90it/s] 97%|#########7|168679/173481[51:12<01:30,52.90it/s]100%|##########|173481/173481[52:48<00:00,54.75it/s]
[32m[0323 19:28:50 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3168.51 sec.
[32m[0323 19:28:50 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-1908291.
[32m[0323 19:28:50 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,197.63it/s]
10
[32m[0323 19:30:26 @monitor.py:363][0m QueueInput/queue_size: 0.60356
[32m[0323 19:30:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.867
[32m[0323 19:30:26 @monitor.py:363][0m activation-summaries/output-rms: 0.04042
[32m[0323 19:30:26 @monitor.py:363][0m cross_entropy_loss: 1.6334
[32m[0323 19:30:26 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.44724
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.3697e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.33452
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5598e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.41716
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5332e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.32706
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2605e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.43108
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8658e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.32918
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.4863e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.42561
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6979e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.32594
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9524e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.46276
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.1209e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.33111
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7852e-06
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45786
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2721
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32666
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30434
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29518
[32m[0323 19:30:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 19:30:26 @monitor.py:363][0m train-error-top1: 0.42999
[32m[0323 19:30:26 @monitor.py:363][0m val-error-top1: 0.44431
[32m[0323 19:30:26 @monitor.py:363][0m val-utt-error: 0.10743
[32m[0323 19:30:26 @monitor.py:363][0m validation_cost: 1.6731
[32m[0323 19:30:26 @monitor.py:363][0m wd_cost: 0.028832
[32m[0323 19:30:26 @group.py:42][0m Callbacks took 95.568 sec in total. InferenceRunner: 95.249sec
[32m[0323 19:30:26 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10779/173481[03:00<45:17,59.88it/s]  7%|6         |11344/173481[03:10<45:07,59.88it/s] 12%|#1        |20015/173481[06:00<46:17,55.25it/s] 12%|#1        |20539/173481[06:10<46:08,55.25it/s] 17%|#6        |29410/173481[09:00<44:44,53.67it/s] 17%|#7        |29952/173481[09:10<44:34,53.67it/s] 22%|##2       |38230/173481[12:00<44:00,51.22it/s] 22%|##2       |38749/173481[12:10<43:50,51.22it/s] 27%|##7       |46855/173481[15:00<42:37,49.51it/s] 27%|##7       |47359/173481[15:10<42:27,49.51it/s] 32%|###2      |55550/173481[18:00<40:11,48.90it/s] 32%|###2      |56094/173481[18:11<40:00,48.90it/s] 37%|###7      |64650/173481[21:00<36:29,49.71it/s] 38%|###7      |65214/173481[21:11<36:18,49.71it/s] 43%|####2     |73990/173481[24:00<32:39,50.77it/s] 43%|####2     |74574/173481[24:11<32:28,50.77it/s] 48%|####8     |83513/173481[27:00<28:56,51.82it/s] 48%|####8     |84129/173481[27:11<28:44,51.82it/s] 54%|#####3    |92923/173481[30:00<25:47,52.05it/s] 54%|#####3    |93544/173481[30:11<25:35,52.05it/s] 59%|#####9    |102569/173481[33:00<22:22,52.81it/s] 59%|#####9    |103184/173481[33:11<22:11,52.81it/s] 65%|######4   |112099/173481[36:00<19:20,52.87it/s] 65%|######4   |112721/173481[36:12<19:09,52.87it/s] 70%|#######   |121485/173481[39:00<16:30,52.50it/s] 70%|#######   |122135/173481[39:12<16:18,52.50it/s] 75%|#######5  |130950/173481[42:00<13:29,52.54it/s] 76%|#######5  |131599/173481[42:12<13:17,52.54it/s] 82%|########1 |141419/173481[45:00<09:40,55.20it/s] 82%|########1 |142179/173481[45:12<09:27,55.20it/s] 88%|########8 |152694/173481[48:00<05:54,58.69it/s] 88%|########8 |153474/173481[48:12<05:40,58.69it/s] 96%|#########5|166352/173481[51:00<01:47,66.18it/s] 96%|#########6|167069/173481[51:12<01:36,66.18it/s]100%|##########|173481/173481[53:00<00:00,54.55it/s]
[32m[0323 20:23:26 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3180.33 sec.
[32m[0323 20:23:26 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-2081772.
[32m[0323 20:23:26 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,178.20it/s]
11
[32m[0323 20:25:12 @monitor.py:363][0m QueueInput/queue_size: 1.1925
[32m[0323 20:25:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 33.902
[32m[0323 20:25:12 @monitor.py:363][0m activation-summaries/output-rms: 0.040632
[32m[0323 20:25:12 @monitor.py:363][0m cross_entropy_loss: 1.637
[32m[0323 20:25:12 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.45633
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.5107e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.33901
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5318e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.42728
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5687e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.33169
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2807e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4403
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.9403e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.33389
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5126e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.43429
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.7125e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33045
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9577e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.47141
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.1711e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.33543
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7533e-06
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.48038
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.277
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32999
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30772
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29867
[32m[0323 20:25:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 20:25:12 @monitor.py:363][0m train-error-top1: 0.44004
[32m[0323 20:25:12 @monitor.py:363][0m val-error-top1: 0.44192
[32m[0323 20:25:12 @monitor.py:363][0m val-utt-error: 0.1061
[32m[0323 20:25:12 @monitor.py:363][0m validation_cost: 1.6609
[32m[0323 20:25:12 @monitor.py:363][0m wd_cost: 0.006075
[32m[0323 20:25:12 @group.py:42][0m Callbacks took 106.116 sec in total. InferenceRunner: 105.631sec
[32m[0323 20:25:12 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12934/173481[03:00<37:14,71.86it/s]  8%|7         |13603/173481[03:10<37:04,71.86it/s] 14%|#3        |23938/173481[06:00<37:43,66.06it/s] 14%|#4        |24433/173481[06:10<37:36,66.06it/s] 19%|#8        |32774/173481[09:00<41:38,56.32it/s] 19%|#9        |33261/173481[09:10<41:29,56.32it/s] 24%|##4       |41921/173481[12:00<41:02,53.42it/s] 24%|##4       |42471/173481[12:10<40:52,53.42it/s] 29%|##9       |51134/173481[15:00<39:00,52.27it/s] 30%|##9       |51684/173481[15:10<38:50,52.27it/s] 35%|###5      |60739/173481[18:00<35:34,52.81it/s] 35%|###5      |61350/173481[18:10<35:23,52.81it/s] 41%|####1     |71169/173481[21:00<30:51,55.25it/s] 41%|####1     |71858/173481[21:11<30:39,55.25it/s] 47%|####7     |81775/173481[24:00<26:48,57.02it/s] 47%|####7     |82378/173481[24:11<26:37,57.02it/s] 53%|#####2    |91770/173481[27:00<24:12,56.26it/s] 53%|#####3    |92298/173481[27:11<24:02,56.26it/s] 59%|#####8    |101644/173481[30:00<21:33,55.54it/s] 59%|#####8    |102226/173481[30:11<21:22,55.54it/s] 64%|######4   |111602/173481[33:00<18:36,55.43it/s] 65%|######4   |112277/173481[33:11<18:24,55.43it/s] 70%|#######   |121849/173481[36:00<15:19,56.15it/s] 71%|#######   |122528/173481[36:11<15:07,56.15it/s] 76%|#######6  |132209/173481[39:00<12:06,56.84it/s] 77%|#######6  |132973/173481[39:12<11:52,56.84it/s] 83%|########2 |143454/173481[42:00<08:24,59.52it/s] 83%|########3 |144154/173481[42:12<08:12,59.52it/s] 89%|########9 |154529/173481[45:00<05:13,60.51it/s] 89%|########9 |155259/173481[45:12<05:01,60.51it/s] 95%|#########5|164949/173481[48:00<02:24,59.16it/s] 95%|#########5|165638/173481[48:12<02:12,59.16it/s]100%|##########|173481/173481[50:23<00:00,57.38it/s]
[32m[0323 21:15:35 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3023.41 sec.
[32m[0323 21:15:36 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-2255253.
[32m[0323 21:15:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.11it/s]
12
[32m[0323 21:17:23 @monitor.py:363][0m QueueInput/queue_size: 1.0365
[32m[0323 21:17:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.909
[32m[0323 21:17:23 @monitor.py:363][0m activation-summaries/output-rms: 0.040372
[32m[0323 21:17:23 @monitor.py:363][0m cross_entropy_loss: 1.6181
[32m[0323 21:17:23 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.46425
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2986e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34404
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.4881e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.43581
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5006e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.33607
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3104e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.44861
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.9305e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.33878
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5693e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.44383
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.7002e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33494
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9613e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48022
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.087e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.33988
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7275e-06
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.50275
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2814
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33363
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31142
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30242
[32m[0323 21:17:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 21:17:23 @monitor.py:363][0m train-error-top1: 0.44259
[32m[0323 21:17:23 @monitor.py:363][0m val-error-top1: 0.44262
[32m[0323 21:17:23 @monitor.py:363][0m val-utt-error: 0.10636
[32m[0323 21:17:23 @monitor.py:363][0m validation_cost: 1.6614
[32m[0323 21:17:23 @monitor.py:363][0m wd_cost: 0.006399
[32m[0323 21:17:23 @group.py:42][0m Callbacks took 107.357 sec in total. InferenceRunner: 106.887sec
[32m[0323 21:17:23 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12368/173481[03:00<39:05,68.70it/s]  7%|7         |12996/173481[03:10<38:56,68.70it/s] 12%|#2        |21656/173481[06:00<42:56,58.93it/s] 13%|#2        |22267/173481[06:10<42:45,58.93it/s] 19%|#8        |32384/173481[09:00<39:40,59.26it/s] 19%|#9        |32992/173481[09:10<39:30,59.26it/s] 25%|##5       |43523/173481[12:00<35:46,60.55it/s] 25%|##5       |44192/173481[12:10<35:35,60.55it/s] 31%|###1      |54430/173481[15:00<32:45,60.57it/s] 32%|###1      |55072/173481[15:10<32:34,60.57it/s] 38%|###8      |65946/173481[18:00<28:48,62.23it/s] 38%|###8      |66643/173481[18:10<28:36,62.23it/s] 45%|####4     |77863/173481[21:00<24:50,64.15it/s] 45%|####5     |78607/173481[21:11<24:38,64.15it/s] 52%|#####1    |89988/173481[24:00<21:10,65.72it/s] 52%|#####2    |90734/173481[24:11<20:59,65.72it/s] 59%|#####8    |101968/173481[27:00<18:01,66.13it/s] 59%|#####9    |102696/173481[27:11<17:50,66.13it/s] 65%|######5   |113486/173481[30:00<15:22,65.04it/s] 66%|######5   |114221/173481[30:11<15:11,65.04it/s] 72%|#######2  |125073/173481[33:00<12:28,64.70it/s] 73%|#######2  |125805/173481[33:11<12:16,64.70it/s] 79%|#######8  |136673/173481[36:00<09:30,64.57it/s] 79%|#######9  |137432/173481[36:11<09:18,64.57it/s] 85%|########4 |147453/173481[39:00<06:58,62.14it/s] 85%|########5 |148205/173481[39:12<06:46,62.14it/s] 92%|#########1|159153/173481[42:00<03:45,63.53it/s] 92%|#########2|159952/173481[42:12<03:32,63.53it/s] 98%|#########7|169753/173481[45:00<01:01,61.11it/s] 98%|#########8|170457/173481[45:12<00:49,61.11it/s]100%|##########|173481/173481[46:06<00:00,62.72it/s]
[32m[0323 22:03:29 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:2766.03 sec.
[32m[0323 22:03:29 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-2428734.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.70it/s]
13
[32m[0323 22:05:08 @monitor.py:363][0m QueueInput/queue_size: 1.5389
[32m[0323 22:05:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.786
[32m[0323 22:05:08 @monitor.py:363][0m activation-summaries/output-rms: 0.040557
[32m[0323 22:05:08 @monitor.py:363][0m cross_entropy_loss: 1.6068
[32m[0323 22:05:08 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47099
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1007e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34711
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5317e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.44253
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.4984e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.33944
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2832e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.45539
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8592e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34196
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5878e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.44941
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.715e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33836
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9824e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48595
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.1202e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34316
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7583e-06
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.52092
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.285
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3361
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31392
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30499
[32m[0323 22:05:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 22:05:08 @monitor.py:363][0m train-error-top1: 0.42838
[32m[0323 22:05:08 @monitor.py:363][0m val-error-top1: 0.4373
[32m[0323 22:05:08 @monitor.py:363][0m val-utt-error: 0.10371
[32m[0323 22:05:08 @monitor.py:363][0m validation_cost: 1.6425
[32m[0323 22:05:08 @monitor.py:363][0m wd_cost: 0.0013318
[32m[0323 22:05:08 @group.py:42][0m Callbacks took 98.856 sec in total. InferenceRunner: 98.705sec
[32m[0323 22:05:08 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12927/173481[03:00<37:15,71.81it/s]  8%|7         |13626/173481[03:10<37:05,71.81it/s] 14%|#3        |23740/173481[06:00<38:08,65.42it/s] 14%|#3        |24261/173481[06:10<38:00,65.42it/s] 19%|#9        |32990/173481[09:00<40:40,57.56it/s] 19%|#9        |33596/173481[09:10<40:30,57.56it/s] 25%|##5       |43542/173481[12:00<37:17,58.08it/s] 25%|##5       |44176/173481[12:10<37:06,58.08it/s] 31%|###1      |53901/173481[15:00<34:28,57.81it/s] 31%|###1      |54421/173481[15:10<34:19,57.81it/s] 36%|###5      |62293/173481[18:00<35:54,51.62it/s] 36%|###6      |62903/173481[18:10<35:42,51.62it/s] 42%|####2     |73198/173481[21:00<29:59,55.74it/s] 43%|####2     |73829/173481[21:11<29:47,55.74it/s] 48%|####8     |83717/173481[24:00<26:13,57.05it/s] 49%|####8     |84363/173481[24:11<26:02,57.05it/s] 54%|#####3    |93237/173481[27:00<24:22,54.88it/s] 54%|#####4    |93750/173481[27:11<24:12,54.88it/s] 59%|#####8    |101857/173481[30:00<23:20,51.15it/s] 59%|#####9    |102446/173481[30:11<23:08,51.15it/s] 65%|######5   |113002/173481[33:00<17:59,56.01it/s] 66%|######5   |113665/173481[33:11<17:47,56.01it/s] 72%|#######1  |124352/173481[36:00<13:48,59.32it/s] 72%|#######2  |124956/173481[36:11<13:38,59.32it/s] 77%|#######7  |134032/173481[39:00<11:39,56.41it/s] 78%|#######7  |134682/173481[39:11<11:27,56.41it/s] 83%|########2 |143880/173481[42:00<08:52,55.55it/s] 83%|########3 |144532/173481[42:12<08:41,55.55it/s] 89%|########9 |154536/173481[45:00<05:30,57.31it/s] 89%|########9 |155186/173481[45:12<05:19,57.31it/s] 95%|#########4|164602/173481[48:00<02:36,56.61it/s] 95%|#########5|165286/173481[48:12<02:24,56.61it/s]100%|##########|173481/173481[50:26<00:00,57.31it/s]
[32m[0323 22:55:35 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3026.89 sec.
[32m[0323 22:55:35 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-2602215.
[32m[0323 22:55:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,189.44it/s]
14
[32m[0323 22:57:14 @monitor.py:363][0m QueueInput/queue_size: 0.67363
[32m[0323 22:57:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.363
[32m[0323 22:57:14 @monitor.py:363][0m activation-summaries/output-rms: 0.042189
[32m[0323 22:57:14 @monitor.py:363][0m cross_entropy_loss: 1.601
[32m[0323 22:57:14 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47372
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1459e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34833
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5379e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.44621
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.4564e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34081
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2688e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.45852
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34305
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6065e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45285
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6781e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33979
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9781e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48953
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.1025e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34458
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7719e-06
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.53315
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2871
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33701
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31492
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30603
[32m[0323 22:57:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 22:57:14 @monitor.py:363][0m train-error-top1: 0.43243
[32m[0323 22:57:14 @monitor.py:363][0m val-error-top1: 0.43747
[32m[0323 22:57:14 @monitor.py:363][0m val-utt-error: 0.10477
[32m[0323 22:57:14 @monitor.py:363][0m validation_cost: 1.6433
[32m[0323 22:57:14 @monitor.py:363][0m wd_cost: 0.0013642
[32m[0323 22:57:14 @group.py:42][0m Callbacks took 99.879 sec in total. InferenceRunner: 99.362sec
[32m[0323 22:57:14 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13112/173481[03:00<36:41,72.84it/s]  8%|7         |13714/173481[03:10<36:33,72.84it/s] 14%|#4        |24996/173481[06:00<35:43,69.26it/s] 15%|#4        |25734/173481[06:10<35:33,69.26it/s] 21%|##        |36081/173481[09:00<35:07,65.19it/s] 21%|##1       |36690/173481[09:10<34:58,65.19it/s] 27%|##6       |46802/173481[12:00<33:55,62.25it/s] 27%|##7       |47460/173481[12:10<33:44,62.25it/s] 33%|###3      |57326/173481[15:00<32:06,60.29it/s] 33%|###3      |57965/173481[15:10<31:55,60.29it/s] 39%|###9      |67903/173481[18:00<29:33,59.52it/s] 40%|###9      |68533/173481[18:10<29:23,59.52it/s] 45%|####5     |78922/173481[21:00<26:06,60.35it/s] 46%|####5     |79641/173481[21:11<25:54,60.35it/s] 53%|#####2    |91441/173481[24:00<21:09,64.62it/s] 53%|#####3    |92229/173481[24:11<20:57,64.62it/s] 60%|#####9    |103406/173481[27:00<17:49,65.52it/s] 60%|######    |104155/173481[27:11<17:38,65.52it/s] 67%|######6   |116226/173481[30:00<13:58,68.25it/s] 67%|######7   |116965/173481[30:11<13:48,68.25it/s] 74%|#######3  |128156/173481[33:00<11:14,67.25it/s] 74%|#######4  |128873/173481[33:11<11:03,67.25it/s] 80%|########  |139211/173481[36:00<08:53,64.19it/s] 81%|########  |139894/173481[36:11<08:43,64.19it/s] 86%|########6 |149923/173481[39:00<06:21,61.76it/s] 87%|########6 |150625/173481[39:12<06:10,61.76it/s] 92%|#########2|160295/173481[42:00<03:41,59.62it/s] 93%|#########2|161133/173481[42:12<03:27,59.62it/s]100%|##########|173481/173481[44:56<00:00,64.33it/s]
[32m[0323 23:42:11 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:2696.57 sec.
[32m[0323 23:42:11 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-2775696.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,187.05it/s]
15
[32m[0323 23:43:52 @monitor.py:363][0m QueueInput/queue_size: 0.69069
[32m[0323 23:43:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.696
[32m[0323 23:43:52 @monitor.py:363][0m activation-summaries/output-rms: 0.040791
[32m[0323 23:43:52 @monitor.py:363][0m cross_entropy_loss: 1.6127
[32m[0323 23:43:52 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47646
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1429e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.3497
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5253e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.44939
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5024e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34215
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2321e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46186
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8194e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34452
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6123e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45612
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6851e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34111
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9848e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49259
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.113e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34605
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7638e-06
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.54534
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2892
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33798
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31591
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30705
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0323 23:43:52 @monitor.py:363][0m train-error-top1: 0.42767
[32m[0323 23:43:52 @monitor.py:363][0m val-error-top1: 0.43677
[32m[0323 23:43:52 @monitor.py:363][0m val-utt-error: 0.1018
[32m[0323 23:43:52 @monitor.py:363][0m validation_cost: 1.6402
[32m[0323 23:43:52 @monitor.py:363][0m wd_cost: 0.0013972
[32m[0323 23:43:52 @group.py:42][0m Callbacks took 100.840 sec in total. InferenceRunner: 100.633sec
[32m[0323 23:43:52 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12805/173481[03:00<37:38,71.13it/s]  8%|7         |13469/173481[03:10<37:29,71.13it/s] 14%|#4        |25010/173481[06:00<35:38,69.42it/s] 15%|#4        |25666/173481[06:10<35:29,69.42it/s] 22%|##2       |38736/173481[09:00<30:54,72.68it/s] 23%|##2       |39747/173481[09:10<30:40,72.68it/s] 32%|###2      |55820/173481[12:00<23:49,82.32it/s] 33%|###2      |56550/173481[12:10<23:40,82.32it/s] 39%|###9      |68240/173481[15:00<23:21,75.07it/s] 40%|###9      |68879/173481[15:10<23:13,75.07it/s] 46%|####5     |79505/173481[18:00<22:56,68.26it/s] 46%|####6     |80262/173481[18:10<22:45,68.26it/s] 54%|#####4    |93735/173481[21:00<18:08,73.26it/s] 55%|#####4    |94798/173481[21:11<17:54,73.26it/s] 63%|######2   |108785/173481[24:00<13:48,78.09it/s] 63%|######3   |109965/173481[24:11<13:33,78.09it/s] 70%|######9   |121416/173481[27:00<11:44,73.92it/s] 70%|#######   |122164/173481[27:11<11:34,73.92it/s] 77%|#######6  |132915/173481[30:00<09:51,68.53it/s] 77%|#######7  |133733/173481[30:11<09:40,68.53it/s] 83%|########3 |144585/173481[33:00<07:13,66.63it/s] 84%|########3 |145316/173481[33:11<07:02,66.63it/s] 90%|########9 |155915/173481[36:00<04:31,64.73it/s] 90%|######### |156631/173481[36:11<04:20,64.73it/s] 96%|#########6|167328/173481[39:00<01:36,64.06it/s] 97%|#########6|168023/173481[39:12<01:25,64.06it/s]100%|##########|173481/173481[40:45<00:00,70.95it/s]
[32m[0324 00:24:37 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:2445.03 sec.
[32m[0324 00:24:37 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-2949177.
[32m[0324 00:24:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,184.31it/s]
16
[32m[0324 00:26:20 @monitor.py:363][0m QueueInput/queue_size: 0.67016
[32m[0324 00:26:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.936
[32m[0324 00:26:20 @monitor.py:363][0m activation-summaries/output-rms: 0.040989
[32m[0324 00:26:20 @monitor.py:363][0m cross_entropy_loss: 1.6051
[32m[0324 00:26:20 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47803
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1462e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35031
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5294e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45145
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5464e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34289
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2291e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46351
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8169e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34525
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6181e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45745
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.684e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34158
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9568e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49399
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.1007e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34658
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7673e-06
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.55311
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2906
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33838
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31632
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30749
[32m[0324 00:26:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 00:26:20 @monitor.py:363][0m train-error-top1: 0.43488
[32m[0324 00:26:20 @monitor.py:363][0m val-error-top1: 0.43465
[32m[0324 00:26:20 @monitor.py:363][0m val-utt-error: 0.10206
[32m[0324 00:26:20 @monitor.py:363][0m validation_cost: 1.6294
[32m[0324 00:26:20 @monitor.py:363][0m wd_cost: 0.00028348
[32m[0324 00:26:20 @group.py:42][0m Callbacks took 102.737 sec in total. InferenceRunner: 102.129sec
[32m[0324 00:26:20 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13072/173481[03:00<36:48,72.62it/s]  8%|7         |13718/173481[03:10<36:39,72.62it/s] 14%|#4        |24676/173481[06:00<36:18,68.30it/s] 15%|#4        |25253/173481[06:10<36:10,68.30it/s] 20%|#9        |34529/173481[09:00<38:06,60.77it/s] 20%|##        |35135/173481[09:10<37:56,60.77it/s] 26%|##5       |44854/173481[12:00<36:20,59.00it/s] 26%|##6       |45421/173481[12:10<36:10,59.00it/s] 31%|###1      |54439/173481[15:00<35:26,55.97it/s] 32%|###1      |55049/173481[15:10<35:15,55.97it/s] 37%|###7      |64529/173481[18:00<32:25,56.00it/s] 38%|###7      |65157/173481[18:10<32:14,56.00it/s] 44%|####3     |75658/173481[21:00<27:44,58.77it/s] 44%|####3     |76308/173481[21:11<27:33,58.77it/s] 50%|####9     |86615/173481[24:00<24:12,59.80it/s] 50%|#####     |87263/173481[24:11<24:01,59.80it/s] 56%|#####6    |97504/173481[27:00<21:03,60.14it/s] 57%|#####6    |98186/173481[27:11<20:51,60.14it/s] 62%|######2   |108394/173481[30:00<17:59,60.32it/s] 63%|######2   |109062/173481[30:11<17:47,60.32it/s] 69%|######9   |119898/173481[33:00<14:23,62.06it/s] 70%|######9   |120579/173481[33:11<14:12,62.06it/s] 75%|#######5  |130658/173481[36:00<11:43,60.90it/s] 76%|#######5  |131358/173481[36:11<11:31,60.90it/s] 82%|########1 |141449/173481[39:00<08:50,60.41it/s] 82%|########1 |142214/173481[39:12<08:37,60.41it/s] 88%|########7 |152612/173481[42:00<05:40,61.20it/s] 88%|########8 |153337/173481[42:12<05:29,61.20it/s] 95%|#########4|163957/173481[45:00<02:33,62.10it/s] 95%|#########4|164743/173481[45:12<02:20,62.10it/s]100%|##########|173481/173481[47:36<00:00,60.72it/s]
[32m[0324 01:13:57 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:2856.92 sec.
[32m[0324 01:13:57 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-3122658.
[32m[0324 01:13:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.87it/s]
17
[32m[0324 01:15:36 @monitor.py:363][0m QueueInput/queue_size: 1.134
[32m[0324 01:15:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 42.578
[32m[0324 01:15:36 @monitor.py:363][0m activation-summaries/output-rms: 0.040734
[32m[0324 01:15:36 @monitor.py:363][0m cross_entropy_loss: 1.5906
[32m[0324 01:15:36 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47895
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1269e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35078
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5416e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45265
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5599e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3432
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.236e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46455
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.801e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34568
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6198e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45881
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6796e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34196
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.938e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49518
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0671e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34695
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7678e-06
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.55942
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2919
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33862
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31659
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30773
[32m[0324 01:15:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 01:15:36 @monitor.py:363][0m train-error-top1: 0.43542
[32m[0324 01:15:36 @monitor.py:363][0m val-error-top1: 0.43517
[32m[0324 01:15:36 @monitor.py:363][0m val-utt-error: 0.101
[32m[0324 01:15:36 @monitor.py:363][0m validation_cost: 1.6309
[32m[0324 01:15:36 @monitor.py:363][0m wd_cost: 0.00028673
[32m[0324 01:15:36 @group.py:42][0m Callbacks took 99.304 sec in total. InferenceRunner: 98.621sec
[32m[0324 01:15:36 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12947/173481[03:00<37:11,71.93it/s]  8%|7         |13588/173481[03:10<37:03,71.93it/s] 13%|#3        |23228/173481[06:00<39:19,63.67it/s] 14%|#3        |23761/173481[06:10<39:11,63.67it/s] 19%|#9        |33228/173481[09:00<39:23,59.33it/s] 20%|#9        |33837/173481[09:10<39:13,59.33it/s] 25%|##5       |44005/173481[12:00<36:12,59.60it/s] 26%|##5       |44656/173481[12:10<36:01,59.60it/s] 32%|###1      |54774/173481[15:00<33:08,59.71it/s] 32%|###1      |55302/173481[15:10<32:59,59.71it/s] 38%|###7      |65203/173481[18:00<30:41,58.81it/s] 38%|###7      |65917/173481[18:10<30:29,58.81it/s] 44%|####3     |76078/173481[21:00<27:14,59.59it/s] 44%|####4     |76722/173481[21:11<27:03,59.59it/s] 50%|####9     |86262/173481[24:00<25:02,58.04it/s] 50%|#####     |86857/173481[24:11<24:52,58.04it/s] 55%|#####5    |96018/173481[27:00<23:01,56.05it/s] 56%|#####5    |96662/173481[27:11<22:50,56.05it/s] 61%|######1   |106373/173481[30:00<19:41,56.78it/s] 62%|######1   |107032/173481[30:11<19:30,56.78it/s] 68%|######7   |117184/173481[33:00<16:04,58.37it/s] 68%|######7   |117887/173481[33:11<15:52,58.37it/s] 74%|#######3  |127513/173481[36:00<13:14,57.87it/s] 74%|#######3  |128176/173481[36:11<13:02,57.87it/s] 79%|#######9  |137883/173481[39:00<10:16,57.74it/s] 80%|#######9  |138582/173481[39:12<10:04,57.74it/s] 86%|########5 |148962/173481[42:00<06:51,59.58it/s] 86%|########6 |149704/173481[42:12<06:39,59.58it/s] 92%|#########2|160307/173481[45:00<03:35,61.26it/s] 93%|#########2|161118/173481[45:12<03:21,61.26it/s] 99%|#########8|171243/173481[48:00<00:36,60.99it/s] 99%|#########9|171919/173481[48:12<00:25,60.99it/s]100%|##########|173481/173481[48:37<00:00,59.46it/s]
[32m[0324 02:04:14 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:2917.77 sec.
[32m[0324 02:04:14 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-3296139.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,185.17it/s]
18
[32m[0324 02:05:56 @monitor.py:363][0m QueueInput/queue_size: 0.31916
[32m[0324 02:05:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.296
[32m[0324 02:05:56 @monitor.py:363][0m activation-summaries/output-rms: 0.040826
[32m[0324 02:05:56 @monitor.py:363][0m cross_entropy_loss: 1.5971
[32m[0324 02:05:56 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48031
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.115e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35118
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5377e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45413
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.559e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3436
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2515e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46599
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8156e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34603
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6314e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45974
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6715e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34243
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9444e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49601
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0571e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34736
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7547e-06
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56578
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2928
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33888
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31685
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30799
[32m[0324 02:05:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 02:05:56 @monitor.py:363][0m train-error-top1: 0.42683
[32m[0324 02:05:56 @monitor.py:363][0m val-error-top1: 0.43412
[32m[0324 02:05:56 @monitor.py:363][0m val-utt-error: 0.10169
[32m[0324 02:05:56 @monitor.py:363][0m validation_cost: 1.6286
[32m[0324 02:05:56 @monitor.py:363][0m wd_cost: 0.00029004
[32m[0324 02:05:56 @group.py:42][0m Callbacks took 101.919 sec in total. InferenceRunner: 101.656sec
[32m[0324 02:05:56 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11442/173481[03:00<42:29,63.55it/s]  7%|6         |12037/173481[03:10<42:20,63.55it/s] 13%|#2        |22312/173481[06:00<40:41,61.92it/s] 13%|#3        |22876/173481[06:10<40:32,61.92it/s] 19%|#9        |33703/173481[09:00<37:13,62.60it/s] 20%|#9        |34376/173481[09:10<37:02,62.60it/s] 26%|##5       |44531/173481[12:00<35:01,61.35it/s] 26%|##6       |45166/173481[12:10<34:51,61.35it/s] 32%|###2      |56331/173481[15:00<30:48,63.38it/s] 33%|###2      |57066/173481[15:10<30:36,63.38it/s] 40%|####      |69455/173481[18:00<25:34,67.81it/s] 41%|####      |70329/173481[18:10<25:21,67.81it/s] 48%|####7     |82725/173481[21:00<21:24,70.64it/s] 48%|####8     |83580/173481[21:11<21:12,70.64it/s] 57%|#####6    |98818/173481[24:00<15:46,78.92it/s] 58%|#####7    |99881/173481[24:11<15:32,78.92it/s] 66%|######6   |115285/173481[27:00<11:26,84.74it/s] 67%|######7   |116346/173481[27:11<11:14,84.74it/s] 76%|#######5  |131693/173481[30:00<07:55,87.83it/s] 77%|#######6  |132755/173481[30:11<07:43,87.83it/s] 85%|########5 |148242/173481[33:00<04:40,89.83it/s] 86%|########6 |149248/173481[33:11<04:29,89.83it/s] 95%|#########4|164685/173481[36:00<01:37,90.58it/s] 96%|#########5|165740/173481[36:11<01:25,90.58it/s]100%|##########|173481/173481[37:35<00:00,76.90it/s]
[32m[0324 02:43:31 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:2255.81 sec.
[32m[0324 02:43:32 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-3469620.
[32m[0324 02:43:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,198.88it/s]
19
[32m[0324 02:45:06 @monitor.py:363][0m QueueInput/queue_size: 18.348
[32m[0324 02:45:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.846
[32m[0324 02:45:06 @monitor.py:363][0m activation-summaries/output-rms: 0.042354
[32m[0324 02:45:06 @monitor.py:363][0m cross_entropy_loss: 1.5891
[32m[0324 02:45:06 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48067
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1274e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35126
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5414e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45477
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5545e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34376
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2567e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46638
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8089e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34612
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6335e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46027
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6695e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34259
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9457e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49662
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0666e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34752
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7451e-06
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5692
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2934
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33892
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31691
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30807
[32m[0324 02:45:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 02:45:06 @monitor.py:363][0m train-error-top1: 0.42652
[32m[0324 02:45:06 @monitor.py:363][0m val-error-top1: 0.43421
[32m[0324 02:45:06 @monitor.py:363][0m val-utt-error: 0.10121
[32m[0324 02:45:06 @monitor.py:363][0m validation_cost: 1.6284
[32m[0324 02:45:06 @monitor.py:363][0m wd_cost: 5.8351e-05
[32m[0324 02:45:06 @group.py:42][0m Callbacks took 94.939 sec in total. InferenceRunner: 94.649sec
[32m[0324 02:45:06 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12446/173481[03:00<38:49,69.12it/s]  8%|7         |13037/173481[03:10<38:41,69.12it/s] 13%|#3        |22831/173481[06:00<39:55,62.88it/s] 13%|#3        |23415/173481[06:10<39:46,62.88it/s] 19%|#9        |33342/173481[09:00<38:34,60.55it/s] 20%|#9        |33965/173481[09:10<38:23,60.55it/s] 25%|##5       |44220/173481[12:00<35:36,60.49it/s] 26%|##5       |44849/173481[12:10<35:26,60.49it/s] 32%|###1      |54708/173481[15:00<33:20,59.36it/s] 32%|###1      |55360/173481[15:10<33:09,59.36it/s] 38%|###7      |65430/173481[18:00<30:17,59.46it/s] 38%|###8      |66031/173481[18:10<30:07,59.46it/s] 44%|####3     |76061/173481[21:00<27:23,59.26it/s] 44%|####4     |76702/173481[21:11<27:13,59.26it/s] 50%|#####     |87114/173481[24:00<23:51,60.31it/s] 51%|#####     |87806/173481[24:11<23:40,60.31it/s] 57%|#####6    |98389/173481[27:00<20:21,61.45it/s] 57%|#####7    |99080/173481[27:11<20:10,61.45it/s] 63%|######3   |109304/173481[30:00<17:31,61.04it/s] 63%|######3   |110008/173481[30:11<17:19,61.04it/s] 69%|######9   |120517/173481[33:00<14:18,61.66it/s] 70%|######9   |121244/173481[33:11<14:07,61.66it/s] 76%|#######5  |131591/173481[36:00<11:20,61.59it/s] 76%|#######6  |132303/173481[36:11<11:08,61.59it/s] 82%|########2 |142716/173481[39:00<08:18,61.69it/s] 83%|########2 |143478/173481[39:12<08:06,61.69it/s] 88%|########8 |153492/173481[42:00<05:28,60.76it/s] 89%|########8 |154190/173481[42:12<05:17,60.76it/s] 95%|#########5|165288/173481[45:00<02:09,63.06it/s] 96%|#########5|166301/173481[45:12<01:53,63.06it/s]100%|##########|173481/173481[47:01<00:00,61.50it/s]
[32m[0324 03:32:07 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:2821.03 sec.
[32m[0324 03:32:08 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-3643101.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,188.13it/s]
20
[32m[0324 03:33:48 @monitor.py:363][0m QueueInput/queue_size: 0.85417
[32m[0324 03:33:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.259
[32m[0324 03:33:48 @monitor.py:363][0m activation-summaries/output-rms: 0.040952
[32m[0324 03:33:48 @monitor.py:363][0m cross_entropy_loss: 1.5948
[32m[0324 03:33:48 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4811
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1089e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35139
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5468e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45529
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5517e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34383
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2462e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46693
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8155e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34627
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6344e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46079
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6755e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34268
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9481e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49704
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0565e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34764
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7417e-06
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57256
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2939
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33898
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31697
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30813
[32m[0324 03:33:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 03:33:48 @monitor.py:363][0m train-error-top1: 0.42299
[32m[0324 03:33:48 @monitor.py:363][0m val-error-top1: 0.43352
[32m[0324 03:33:48 @monitor.py:363][0m val-utt-error: 0.10111
[32m[0324 03:33:48 @monitor.py:363][0m validation_cost: 1.6262
[32m[0324 03:33:48 @monitor.py:363][0m wd_cost: 5.869e-05
[32m[0324 03:33:48 @group.py:42][0m Callbacks took 100.314 sec in total. InferenceRunner: 100.053sec
[32m[0324 03:33:48 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13084/173481[03:00<36:46,72.68it/s]  8%|7         |13734/173481[03:10<36:37,72.68it/s] 14%|#4        |24835/173481[06:00<36:01,68.78it/s] 15%|#4        |25489/173481[06:10<35:51,68.78it/s] 20%|##        |35392/173481[09:00<36:21,63.31it/s] 21%|##        |35979/173481[09:10<36:11,63.31it/s] 26%|##6       |45680/173481[12:00<35:27,60.07it/s] 27%|##6       |46274/173481[12:10<35:17,60.07it/s] 33%|###2      |57092/173481[15:00<31:26,61.69it/s] 33%|###3      |57718/173481[15:10<31:16,61.69it/s] 40%|###9      |69085/173481[18:00<27:09,64.06it/s] 40%|####      |69757/173481[18:10<26:59,64.06it/s] 46%|####6     |80091/173481[21:00<24:52,62.57it/s] 47%|####6     |80744/173481[21:11<24:42,62.57it/s] 53%|#####2    |91268/173481[24:00<21:59,62.33it/s] 53%|#####2    |91921/173481[24:11<21:48,62.33it/s] 59%|#####9    |102455/173481[27:00<19:01,62.24it/s] 59%|#####9    |103189/173481[27:11<18:49,62.24it/s] 66%|######5   |114450/173481[30:00<15:17,64.35it/s] 66%|######6   |115113/173481[30:11<15:06,64.35it/s] 72%|#######2  |125655/173481[33:00<12:35,63.28it/s] 73%|#######2  |126391/173481[33:11<12:24,63.28it/s] 79%|#######8  |136885/173481[36:00<09:42,62.83it/s] 79%|#######9  |137589/173481[36:11<09:31,62.83it/s] 85%|########5 |148155/173481[39:00<06:43,62.72it/s] 86%|########5 |148894/173481[39:12<06:32,62.72it/s] 92%|#########1|159570/173481[42:00<03:40,63.05it/s] 92%|#########2|160308/173481[42:12<03:28,63.05it/s] 98%|#########8|170774/173481[45:00<00:43,62.64it/s] 99%|#########8|171576/173481[45:12<00:30,62.64it/s]100%|##########|173481/173481[45:41<00:00,63.28it/s]
[32m[0324 04:19:29 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:2741.72 sec.
[32m[0324 04:19:30 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-3816582.
[32m[0324 04:19:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.37it/s]
21
[32m[0324 04:21:09 @monitor.py:363][0m QueueInput/queue_size: 0.85836
[32m[0324 04:21:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.841
[32m[0324 04:21:09 @monitor.py:363][0m activation-summaries/output-rms: 0.041158
[32m[0324 04:21:09 @monitor.py:363][0m cross_entropy_loss: 1.5969
[32m[0324 04:21:09 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48144
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1023e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35149
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5512e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4558
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5466e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34392
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2434e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46731
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8096e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34639
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6341e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46114
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6766e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.3427
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9563e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49739
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0491e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34769
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.743e-06
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57553
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2944
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33901
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31702
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30818
[32m[0324 04:21:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 04:21:09 @monitor.py:363][0m train-error-top1: 0.43102
[32m[0324 04:21:09 @monitor.py:363][0m val-error-top1: 0.43293
[32m[0324 04:21:09 @monitor.py:363][0m val-utt-error: 0.099989
[32m[0324 04:21:09 @monitor.py:363][0m validation_cost: 1.6223
[32m[0324 04:21:09 @monitor.py:363][0m wd_cost: 5.8988e-05
[32m[0324 04:21:09 @group.py:42][0m Callbacks took 99.803 sec in total. InferenceRunner: 98.878sec
[32m[0324 04:21:09 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14355/173481[03:00<33:15,79.75it/s]  9%|8         |15032/173481[03:10<33:06,79.75it/s] 15%|#5        |26663/173481[06:00<33:14,73.62it/s] 16%|#5        |27290/173481[06:10<33:05,73.62it/s] 22%|##1       |37649/173481[09:00<33:55,66.74it/s] 22%|##2       |38277/173481[09:10<33:45,66.74it/s] 28%|##7       |48379/173481[12:00<33:06,62.96it/s] 28%|##8       |49011/173481[12:10<32:56,62.96it/s] 34%|###4      |59126/173481[15:00<31:05,61.29it/s] 34%|###4      |59785/173481[15:10<30:55,61.29it/s] 41%|####      |70722/173481[18:00<27:15,62.82it/s] 41%|####1     |71463/173481[18:10<27:04,62.82it/s] 48%|####7     |82529/173481[21:00<23:37,64.17it/s] 48%|####7     |83223/173481[21:11<23:26,64.17it/s] 54%|#####4    |94244/173481[24:00<20:26,64.62it/s] 55%|#####4    |94899/173481[24:11<20:16,64.62it/s] 61%|######1   |105824/173481[27:00<17:29,64.47it/s] 61%|######1   |106653/173481[27:11<17:16,64.47it/s] 69%|######8   |119437/173481[30:00<12:56,69.61it/s] 69%|######9   |120273/173481[30:11<12:44,69.61it/s] 76%|#######5  |131829/173481[33:00<10:01,69.21it/s] 76%|#######6  |132595/173481[33:11<09:50,69.21it/s] 83%|########2 |143724/173481[36:00<07:20,67.60it/s] 83%|########3 |144513/173481[36:11<07:08,67.60it/s] 90%|########9 |155608/173481[39:00<04:27,66.80it/s] 90%|######### |156370/173481[39:12<04:16,66.80it/s] 97%|#########6|167685/173481[42:00<01:26,66.95it/s] 97%|#########7|168492/173481[42:12<01:14,66.95it/s]100%|##########|173481/173481[43:28<00:00,66.50it/s]
[32m[0324 05:04:38 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:2608.84 sec.
[32m[0324 05:04:38 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-3990063.
[32m[0324 05:04:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,187.50it/s]
22
[32m[0324 05:06:19 @monitor.py:363][0m QueueInput/queue_size: 0.55107
[32m[0324 05:06:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.914
[32m[0324 05:06:19 @monitor.py:363][0m activation-summaries/output-rms: 0.040798
[32m[0324 05:06:19 @monitor.py:363][0m cross_entropy_loss: 1.5851
[32m[0324 05:06:19 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4816
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1107e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35153
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5521e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45602
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5441e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34396
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2404e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4674
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8063e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34643
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6345e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46138
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6744e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34274
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9561e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49764
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0486e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34775
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7409e-06
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57724
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2948
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33903
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31704
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30819
[32m[0324 05:06:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 05:06:19 @monitor.py:363][0m train-error-top1: 0.43235
[32m[0324 05:06:19 @monitor.py:363][0m val-error-top1: 0.43332
[32m[0324 05:06:19 @monitor.py:363][0m val-utt-error: 0.10073
[32m[0324 05:06:19 @monitor.py:363][0m validation_cost: 1.6233
[32m[0324 05:06:19 @monitor.py:363][0m wd_cost: 1.1832e-05
[32m[0324 05:06:19 @group.py:42][0m Callbacks took 101.110 sec in total. InferenceRunner: 100.395sec
[32m[0324 05:06:19 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13897/173481[03:00<34:27,77.20it/s]  8%|8         |14599/173481[03:10<34:17,77.20it/s] 14%|#4        |24993/173481[06:00<36:06,68.55it/s] 15%|#4        |25682/173481[06:10<35:56,68.55it/s] 21%|##1       |37141/173481[09:00<33:24,68.01it/s] 22%|##1       |37879/173481[09:10<33:13,68.01it/s] 28%|##8       |49428/173481[12:00<30:20,68.13it/s] 29%|##8       |50129/173481[12:10<30:10,68.13it/s] 36%|###5      |61603/173481[15:00<27:28,67.88it/s] 36%|###5      |62355/173481[15:10<27:17,67.88it/s] 43%|####3     |74947/173481[18:00<23:10,70.87it/s] 44%|####3     |75812/173481[18:10<22:58,70.87it/s] 51%|#####1    |88918/173481[21:00<19:01,74.08it/s] 52%|#####1    |89830/173481[21:11<18:49,74.08it/s] 59%|#####8    |101955/173481[24:00<16:16,73.25it/s] 59%|#####9    |102754/173481[24:11<16:05,73.25it/s] 66%|######5   |114490/173481[27:00<13:46,71.40it/s] 66%|######6   |115263/173481[27:11<13:35,71.40it/s] 73%|#######3  |126853/173481[30:00<11:06,70.01it/s] 74%|#######3  |127632/173481[30:11<10:54,70.01it/s] 80%|########  |139173/173481[33:00<08:15,69.21it/s] 81%|########  |139980/173481[33:11<08:04,69.21it/s] 88%|########7 |152216/173481[36:00<05:00,70.80it/s] 88%|########8 |153082/173481[36:11<04:48,70.80it/s] 96%|#########5|166528/173481[39:00<01:32,74.89it/s] 97%|#########6|167434/173481[39:12<01:20,74.89it/s]100%|##########|173481/173481[40:31<00:00,71.35it/s]
[32m[0324 05:46:51 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:2431.37 sec.
[32m[0324 05:46:51 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-4163544.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,177.37it/s]
23
[32m[0324 05:48:37 @monitor.py:363][0m QueueInput/queue_size: 1.0461
[32m[0324 05:48:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.102
[32m[0324 05:48:37 @monitor.py:363][0m activation-summaries/output-rms: 0.040901
[32m[0324 05:48:37 @monitor.py:363][0m cross_entropy_loss: 1.591
[32m[0324 05:48:37 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48185
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1102e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35158
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5547e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45632
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5439e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34399
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2412e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4677
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8024e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34646
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6378e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46154
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6713e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.3428
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9558e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49776
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0555e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34781
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7438e-06
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57896
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.295
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33905
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31706
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30821
[32m[0324 05:48:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 05:48:37 @monitor.py:363][0m train-error-top1: 0.42505
[32m[0324 05:48:37 @monitor.py:363][0m val-error-top1: 0.43245
[32m[0324 05:48:37 @monitor.py:363][0m val-utt-error: 0.10079
[32m[0324 05:48:37 @monitor.py:363][0m validation_cost: 1.6216
[32m[0324 05:48:37 @monitor.py:363][0m wd_cost: 1.1866e-05
[32m[0324 05:48:37 @group.py:42][0m Callbacks took 106.317 sec in total. InferenceRunner: 106.125sec
[32m[0324 05:48:37 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15137/173481[03:00<31:23,84.09it/s]  9%|9         |16138/173481[03:10<31:11,84.09it/s] 18%|#8        |31703/173481[06:00<26:53,87.88it/s] 19%|#8        |32568/173481[06:10<26:43,87.88it/s] 26%|##6       |45116/173481[09:00<26:31,80.65it/s] 27%|##6       |46081/173481[09:10<26:19,80.65it/s] 36%|###6      |63086/173481[12:00<20:37,89.22it/s] 37%|###6      |64076/173481[12:10<20:26,89.22it/s] 46%|####5     |79709/173481[15:00<17:13,90.76it/s] 47%|####6     |80678/173481[15:10<17:02,90.76it/s] 56%|#####5    |96528/173481[18:00<13:55,92.08it/s] 56%|#####6    |97540/173481[18:10<13:44,92.08it/s] 65%|######5   |113588/173481[21:00<10:41,93.41it/s] 66%|######6   |114629/173481[21:11<10:30,93.41it/s] 75%|#######5  |130124/173481[24:00<07:48,92.63it/s] 76%|#######5  |131179/173481[24:11<07:36,92.63it/s] 84%|########4 |146464/173481[27:00<04:54,91.69it/s] 85%|########5 |147477/173481[27:11<04:43,91.69it/s] 94%|#########4|163409/173481[30:00<01:48,92.90it/s] 95%|#########4|164412/173481[30:11<01:37,92.90it/s]100%|##########|173481/173481[31:50<00:00,90.79it/s]
[32m[0324 06:20:28 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:1910.81 sec.
[32m[0324 06:20:28 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-4337025.
[32m[0324 06:20:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.97it/s]
24
[32m[0324 06:22:23 @monitor.py:363][0m QueueInput/queue_size: 9.0605
[32m[0324 06:22:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.347
[32m[0324 06:22:23 @monitor.py:363][0m activation-summaries/output-rms: 0.042413
[32m[0324 06:22:23 @monitor.py:363][0m cross_entropy_loss: 1.5851
[32m[0324 06:22:23 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48194
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.114e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35156
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45653
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5466e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34406
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2464e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46786
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.803e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34649
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6351e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46172
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6686e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34283
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49789
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0517e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34783
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7422e-06
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58015
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2952
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31706
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 06:22:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 06:22:23 @monitor.py:363][0m train-error-top1: 0.4276
[32m[0324 06:22:23 @monitor.py:363][0m val-error-top1: 0.43338
[32m[0324 06:22:23 @monitor.py:363][0m val-utt-error: 0.10116
[32m[0324 06:22:23 @monitor.py:363][0m validation_cost: 1.6247
[32m[0324 06:22:23 @monitor.py:363][0m wd_cost: 2.378e-06
[32m[0324 06:22:23 @group.py:42][0m Callbacks took 115.085 sec in total. InferenceRunner: 114.802sec
[32m[0324 06:22:23 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17592/173481[03:00<26:35,97.73it/s] 11%|#         |18628/173481[03:10<26:24,97.73it/s] 19%|#9        |33469/173481[06:00<25:10,92.72it/s] 20%|#9        |34118/173481[06:10<25:03,92.72it/s] 26%|##5       |44958/173481[09:00<28:19,75.61it/s] 26%|##6       |45640/173481[09:10<28:10,75.61it/s] 33%|###2      |56782/173481[12:00<27:40,70.30it/s] 33%|###3      |57495/173481[12:10<27:29,70.30it/s] 40%|###9      |68566/173481[15:00<25:47,67.80it/s] 40%|###9      |69250/173481[15:10<25:37,67.80it/s] 46%|####6     |80161/173481[18:00<23:32,66.06it/s] 47%|####6     |80939/173481[18:10<23:20,66.06it/s] 53%|#####3    |91973/173481[21:00<20:38,65.84it/s] 53%|#####3    |92667/173481[21:11<20:27,65.84it/s] 60%|#####9    |103543/173481[24:00<17:55,65.05it/s] 60%|######    |104255/173481[24:11<17:44,65.05it/s] 67%|######6   |115556/173481[27:00<14:39,65.88it/s] 67%|######7   |116311/173481[27:11<14:27,65.88it/s] 73%|#######3  |127462/173481[30:00<11:37,66.01it/s] 74%|#######3  |128184/173481[30:11<11:26,66.01it/s] 80%|########  |138994/173481[33:00<08:50,65.02it/s] 81%|########  |139746/173481[33:11<08:38,65.02it/s] 87%|########6 |150583/173481[36:00<05:53,64.70it/s] 87%|########7 |151325/173481[36:11<05:42,64.70it/s] 93%|#########3|162110/173481[39:00<02:56,64.37it/s] 94%|#########3|163040/173481[39:12<02:42,64.37it/s]100%|##########|173481/173481[41:38<00:00,69.43it/s]
[32m[0324 07:04:01 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:2498.50 sec.
[32m[0324 07:04:01 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.80it/s]
25
[32m[0324 07:05:40 @monitor.py:363][0m QueueInput/queue_size: 1.0934
[32m[0324 07:05:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.435
[32m[0324 07:05:40 @monitor.py:363][0m activation-summaries/output-rms: 0.040967
[32m[0324 07:05:40 @monitor.py:363][0m cross_entropy_loss: 1.5924
[32m[0324 07:05:40 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48203
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1122e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35157
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5529e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45665
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5466e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34405
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2448e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46797
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8013e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3465
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6358e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46183
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6697e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34284
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9574e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49797
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0547e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34784
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.742e-06
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.581
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2954
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33905
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31706
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 07:05:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 07:05:40 @monitor.py:363][0m train-error-top1: 0.42294
[32m[0324 07:05:40 @monitor.py:363][0m val-error-top1: 0.43263
[32m[0324 07:05:40 @monitor.py:363][0m val-utt-error: 0.1019
[32m[0324 07:05:40 @monitor.py:363][0m validation_cost: 1.623
[32m[0324 07:05:40 @monitor.py:363][0m wd_cost: 2.3814e-06
[32m[0324 07:05:40 @group.py:42][0m Callbacks took 98.865 sec in total. InferenceRunner: 98.662sec
[32m[0324 07:05:40 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13195/173481[03:00<36:26,73.31it/s]  8%|7         |13799/173481[03:10<36:18,73.31it/s] 15%|#4        |25195/173481[06:00<35:23,69.83it/s] 15%|#4        |25869/173481[06:10<35:13,69.83it/s] 21%|##        |36167/173481[09:00<35:09,65.09it/s] 21%|##1       |36780/173481[09:10<35:00,65.09it/s] 27%|##6       |46825/173481[12:00<34:02,62.00it/s] 27%|##7       |47449/173481[12:10<33:52,62.00it/s] 33%|###3      |57982/173481[15:00<31:03,61.99it/s] 34%|###3      |58659/173481[15:10<30:52,61.99it/s] 40%|###9      |68930/173481[18:00<28:22,61.40it/s] 40%|####      |69604/173481[18:10<28:11,61.40it/s] 46%|####6     |80406/173481[21:00<24:47,62.55it/s] 47%|####6     |81102/173481[21:11<24:36,62.55it/s] 53%|#####3    |92089/173481[24:00<21:17,63.71it/s] 53%|#####3    |92809/173481[24:11<21:06,63.71it/s] 60%|#####9    |103674/173481[27:00<18:10,64.03it/s] 60%|######    |104429/173481[27:11<17:58,64.03it/s] 67%|######6   |115425/173481[30:00<14:58,64.65it/s] 67%|######6   |116129/173481[30:11<14:47,64.65it/s] 73%|#######2  |126380/173481[33:00<12:31,62.70it/s] 73%|#######3  |127149/173481[33:11<12:19,62.70it/s] 79%|#######9  |137290/173481[36:00<09:47,61.62it/s] 80%|#######9  |137989/173481[36:11<09:35,61.62it/s] 85%|########5 |148098/173481[39:00<06:57,60.82it/s] 86%|########5 |148817/173481[39:12<06:45,60.82it/s] 92%|#########1|159404/173481[42:00<03:47,61.80it/s] 92%|#########2|160144/173481[42:12<03:35,61.80it/s] 98%|#########8|170836/173481[45:00<00:42,62.64it/s] 99%|#########8|171573/173481[45:12<00:30,62.64it/s]100%|##########|173481/173481[45:40<00:00,63.30it/s]
[32m[0324 07:51:21 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:2740.71 sec.
[32m[0324 07:51:21 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.88it/s]
26
[32m[0324 07:52:58 @monitor.py:363][0m QueueInput/queue_size: 0.68824
[32m[0324 07:52:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.745
[32m[0324 07:52:58 @monitor.py:363][0m activation-summaries/output-rms: 0.041211
[32m[0324 07:52:58 @monitor.py:363][0m cross_entropy_loss: 1.594
[32m[0324 07:52:58 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4821
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1085e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.3516
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5532e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45677
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5472e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34405
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2439e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46808
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8044e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34652
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6355e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46192
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6691e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34282
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9574e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49805
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.053e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34783
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7417e-06
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58188
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2955
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31706
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 07:52:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 07:52:58 @monitor.py:363][0m train-error-top1: 0.43089
[32m[0324 07:52:58 @monitor.py:363][0m val-error-top1: 0.43252
[32m[0324 07:52:58 @monitor.py:363][0m val-utt-error: 0.099617
[32m[0324 07:52:58 @monitor.py:363][0m validation_cost: 1.6204
[32m[0324 07:52:58 @monitor.py:363][0m wd_cost: 2.3849e-06
[32m[0324 07:52:58 @group.py:42][0m Callbacks took 97.283 sec in total. InferenceRunner: 97.086sec
[32m[0324 07:52:58 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13874/173481[03:00<34:31,77.06it/s]  8%|8         |14558/173481[03:10<34:22,77.06it/s] 15%|#5        |26374/173481[06:00<33:33,73.04it/s] 16%|#5        |26992/173481[06:10<33:25,73.04it/s] 21%|##1       |37054/173481[09:00<34:43,65.47it/s] 22%|##1       |37670/173481[09:10<34:34,65.47it/s] 28%|##7       |47814/173481[12:00<33:31,62.48it/s] 28%|##7       |48433/173481[12:10<33:21,62.48it/s] 34%|###3      |58511/173481[15:00<31:27,60.92it/s] 34%|###4      |59183/173481[15:10<31:16,60.92it/s] 40%|####      |70015/173481[18:00<27:38,62.38it/s] 41%|####      |70753/173481[18:10<27:26,62.38it/s] 47%|####7     |82061/173481[21:00<23:35,64.57it/s] 48%|####7     |82760/173481[21:11<23:25,64.57it/s] 54%|#####4    |93802/173481[24:00<20:27,64.90it/s] 54%|#####4    |94508/173481[24:11<20:16,64.90it/s] 61%|######    |105044/173481[27:00<17:55,63.64it/s] 61%|######    |105758/173481[27:11<17:44,63.64it/s] 68%|######7   |117141/173481[30:00<14:21,65.37it/s] 68%|######7   |117876/173481[30:11<14:10,65.37it/s] 74%|#######4  |128524/173481[33:00<11:39,64.28it/s] 75%|#######4  |129248/173481[33:11<11:28,64.28it/s] 81%|########  |140025/173481[36:00<08:42,64.09it/s] 81%|########1 |140762/173481[36:11<08:30,64.09it/s] 87%|########7 |151744/173481[39:00<05:36,64.58it/s] 88%|########7 |152546/173481[39:12<05:24,64.58it/s] 94%|#########4|163604/173481[42:00<02:31,65.23it/s] 95%|#########4|164429/173481[42:12<02:18,65.23it/s]100%|##########|173481/173481[44:30<00:00,64.97it/s]
[32m[0324 08:37:28 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:2670.29 sec.
[32m[0324 08:37:29 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-4857468.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,178.08it/s]
27
[32m[0324 08:39:14 @monitor.py:363][0m QueueInput/queue_size: 1.4975
[32m[0324 08:39:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.656
[32m[0324 08:39:14 @monitor.py:363][0m activation-summaries/output-rms: 0.040784
[32m[0324 08:39:14 @monitor.py:363][0m cross_entropy_loss: 1.5829
[32m[0324 08:39:14 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48215
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1087e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35162
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5533e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45682
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5495e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34406
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2436e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46807
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8047e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34652
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6351e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46198
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6686e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34284
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9573e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49814
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0536e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34784
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7409e-06
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5824
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2956
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 08:39:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 08:39:14 @monitor.py:363][0m train-error-top1: 0.43057
[32m[0324 08:39:14 @monitor.py:363][0m val-error-top1: 0.43286
[32m[0324 08:39:14 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0324 08:39:14 @monitor.py:363][0m validation_cost: 1.6212
[32m[0324 08:39:14 @monitor.py:363][0m wd_cost: 4.7739e-07
[32m[0324 08:39:14 @group.py:42][0m Callbacks took 105.984 sec in total. InferenceRunner: 105.703sec
[32m[0324 08:39:14 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13038/173481[03:00<36:55,72.42it/s]  8%|7         |13697/173481[03:10<36:46,72.42it/s] 14%|#3        |24038/173481[06:00<37:34,66.28it/s] 14%|#4        |24645/173481[06:10<37:25,66.28it/s] 20%|##        |35453/173481[09:00<35:29,64.81it/s] 21%|##        |36152/173481[09:10<35:18,64.81it/s] 27%|##7       |47413/173481[12:00<32:01,65.62it/s] 28%|##7       |48122/173481[12:10<31:50,65.62it/s] 34%|###3      |58968/173481[15:00<29:24,64.89it/s] 34%|###4      |59672/173481[15:10<29:13,64.89it/s] 41%|####      |70913/173481[18:00<26:03,65.61it/s] 41%|####1     |71644/173481[18:10<25:52,65.61it/s] 48%|####7     |82918/173481[21:00<22:49,66.14it/s] 48%|####8     |83596/173481[21:11<22:38,66.14it/s] 55%|#####4    |94645/173481[24:00<20:01,65.64it/s] 55%|#####4    |95347/173481[24:11<19:50,65.64it/s] 61%|######1   |106633/173481[27:00<16:51,66.11it/s] 62%|######1   |107363/173481[27:11<16:40,66.11it/s] 68%|######8   |118660/173481[30:00<13:44,66.46it/s] 69%|######8   |119433/173481[30:11<13:33,66.46it/s] 75%|#######5  |130668/173481[33:00<10:43,66.58it/s] 76%|#######5  |131413/173481[33:11<10:31,66.58it/s] 82%|########2 |142659/173481[36:00<07:42,66.60it/s] 83%|########2 |143452/173481[36:11<07:30,66.60it/s] 89%|########9 |154913/173481[39:00<04:35,67.32it/s] 90%|########9 |155700/173481[39:12<04:24,67.32it/s] 96%|#########6|166979/173481[42:00<01:36,67.18it/s] 97%|#########6|167744/173481[42:12<01:25,67.18it/s]100%|##########|173481/173481[43:41<00:00,66.18it/s]
[32m[0324 09:22:56 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:2621.43 sec.
[32m[0324 09:22:56 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-5030949.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.30it/s]
28
[32m[0324 09:24:33 @monitor.py:363][0m QueueInput/queue_size: 1.002
[32m[0324 09:24:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.666
[32m[0324 09:24:33 @monitor.py:363][0m activation-summaries/output-rms: 0.040926
[32m[0324 09:24:33 @monitor.py:363][0m cross_entropy_loss: 1.5887
[32m[0324 09:24:33 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48221
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1095e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5531e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45689
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5484e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34406
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2434e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46814
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8054e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34653
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6344e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46201
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6682e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34285
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9573e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49815
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0532e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34786
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.741e-06
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58283
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2956
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33905
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 09:24:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 09:24:33 @monitor.py:363][0m train-error-top1: 0.42752
[32m[0324 09:24:33 @monitor.py:363][0m val-error-top1: 0.43211
[32m[0324 09:24:33 @monitor.py:363][0m val-utt-error: 0.10095
[32m[0324 09:24:33 @monitor.py:363][0m validation_cost: 1.6203
[32m[0324 09:24:33 @monitor.py:363][0m wd_cost: 4.7773e-07
[32m[0324 09:24:33 @group.py:42][0m Callbacks took 97.580 sec in total. InferenceRunner: 97.381sec
[32m[0324 09:24:33 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13814/173481[03:00<34:40,76.74it/s]  8%|8         |14739/173481[03:10<34:28,76.74it/s] 17%|#7        |29928/173481[06:00<28:57,82.64it/s] 18%|#7        |30819/173481[06:10<28:46,82.64it/s] 25%|##4       |42572/173481[09:00<28:44,75.93it/s] 25%|##4       |43288/173481[09:10<28:34,75.93it/s] 32%|###2      |55552/173481[12:00<26:34,73.97it/s] 32%|###2      |56358/173481[12:10<26:23,73.97it/s] 40%|####      |70209/173481[15:00<22:12,77.52it/s] 41%|####1     |71143/173481[15:10<22:00,77.52it/s] 50%|####9     |86352/173481[18:00<17:27,83.16it/s] 50%|#####     |87348/173481[18:10<17:15,83.16it/s] 59%|#####9    |102547/173481[21:00<13:40,86.43it/s] 60%|#####9    |103256/173481[21:11<13:32,86.43it/s] 66%|######5   |114037/173481[24:00<13:29,73.43it/s] 66%|######6   |114751/173481[24:11<13:19,73.43it/s] 72%|#######2  |125459/173481[27:00<11:45,68.08it/s] 73%|#######2  |126181/173481[27:11<11:34,68.08it/s] 79%|#######8  |136952/173481[30:00<09:14,65.89it/s] 79%|#######9  |137676/173481[30:11<09:03,65.89it/s] 86%|########5 |148458/173481[33:00<06:25,64.89it/s] 86%|########6 |149206/173481[33:11<06:14,64.89it/s] 92%|#########2|159767/173481[36:00<03:34,63.83it/s] 93%|#########2|160489/173481[36:11<03:23,63.83it/s] 98%|#########8|170866/173481[39:00<00:41,62.73it/s] 99%|#########8|171566/173481[39:12<00:30,62.73it/s][32m[0324 10:04:19 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:2385.63 sec.
100%|##########|173481/173481[39:45<00:00,72.72it/s]
[32m[0324 10:04:19 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-5204430.
[32m[0324 10:04:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,189.30it/s]
29
[32m[0324 10:05:59 @monitor.py:363][0m QueueInput/queue_size: 0.88002
[32m[0324 10:05:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.803
[32m[0324 10:05:59 @monitor.py:363][0m activation-summaries/output-rms: 0.042431
[32m[0324 10:05:59 @monitor.py:363][0m cross_entropy_loss: 1.5839
[32m[0324 10:05:59 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48224
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1071e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35162
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5542e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45695
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5496e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34407
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.244e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46818
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8056e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34654
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6347e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46206
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6674e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9584e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49821
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0536e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34787
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7416e-06
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58325
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33905
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30823
[32m[0324 10:05:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 10:05:59 @monitor.py:363][0m train-error-top1: 0.42432
[32m[0324 10:05:59 @monitor.py:363][0m val-error-top1: 0.43318
[32m[0324 10:05:59 @monitor.py:363][0m val-utt-error: 0.10026
[32m[0324 10:05:59 @monitor.py:363][0m validation_cost: 1.6239
[32m[0324 10:05:59 @monitor.py:363][0m wd_cost: 4.7806e-07
[32m[0324 10:05:59 @group.py:42][0m Callbacks took 99.823 sec in total. InferenceRunner: 99.435sec
[32m[0324 10:05:59 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13727/173481[03:00<34:54,76.26it/s]  8%|8         |14365/173481[03:10<34:46,76.26it/s] 14%|#4        |25154/173481[06:00<35:40,69.29it/s] 15%|#4        |25830/173481[06:10<35:31,69.29it/s] 21%|##        |36161/173481[09:00<35:13,64.96it/s] 21%|##1       |36795/173481[09:10<35:04,64.96it/s] 27%|##7       |47245/173481[12:00<33:16,63.22it/s] 28%|##7       |47900/173481[12:10<33:06,63.22it/s] 34%|###3      |58306/173481[15:00<30:48,62.32it/s] 34%|###4      |59015/173481[15:10<30:36,62.32it/s] 40%|###9      |69372/173481[18:00<28:01,61.90it/s] 40%|####      |70013/173481[18:10<27:51,61.90it/s] 47%|####6     |80696/173481[21:00<24:47,62.39it/s] 47%|####6     |81426/173481[21:11<24:35,62.39it/s] 53%|#####3    |92116/173481[24:00<21:33,62.91it/s] 53%|#####3    |92780/173481[24:11<21:22,62.91it/s] 60%|#####9    |103416/173481[27:00<18:34,62.84it/s] 60%|######    |104105/173481[27:11<18:24,62.84it/s] 66%|######6   |114844/173481[30:00<15:28,63.16it/s] 67%|######6   |115567/173481[30:11<15:16,63.16it/s] 73%|#######2  |126251/173481[33:00<12:26,63.26it/s] 73%|#######3  |126976/173481[33:11<12:15,63.26it/s] 79%|#######9  |137238/173481[36:00<09:43,62.13it/s] 80%|#######9  |137930/173481[36:11<09:32,62.13it/s] 85%|########5 |148181/173481[39:00<06:51,61.45it/s] 86%|########5 |148910/173481[39:12<06:39,61.45it/s] 92%|#########1|158983/173481[42:00<03:58,60.72it/s] 92%|#########2|159725/173481[42:12<03:46,60.72it/s] 99%|#########8|171006/173481[45:00<00:38,63.61it/s] 99%|#########9|171793/173481[45:12<00:26,63.61it/s]100%|##########|173481/173481[45:38<00:00,63.35it/s]
[32m[0324 10:51:37 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:2738.60 sec.
[32m[0324 10:51:38 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-5377911.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,195.57it/s]
30
[32m[0324 10:53:14 @monitor.py:363][0m QueueInput/queue_size: 0.69888
[32m[0324 10:53:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.796
[32m[0324 10:53:14 @monitor.py:363][0m activation-summaries/output-rms: 0.040959
[32m[0324 10:53:14 @monitor.py:363][0m cross_entropy_loss: 1.5912
[32m[0324 10:53:14 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48227
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1067e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35161
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5544e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45698
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5497e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34407
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.244e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46821
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8058e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34654
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6347e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46208
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6677e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9586e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49823
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.053e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7413e-06
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58344
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2958
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30823
[32m[0324 10:53:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 10:53:14 @monitor.py:363][0m train-error-top1: 0.42323
[32m[0324 10:53:14 @monitor.py:363][0m val-error-top1: 0.43235
[32m[0324 10:53:14 @monitor.py:363][0m val-utt-error: 0.10142
[32m[0324 10:53:14 @monitor.py:363][0m validation_cost: 1.6226
[32m[0324 10:53:14 @monitor.py:363][0m wd_cost: 9.5644e-08
[32m[0324 10:53:14 @group.py:42][0m Callbacks took 96.821 sec in total. InferenceRunner: 96.255sec
[32m[0324 10:53:14 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13150/173481[03:00<36:34,73.04it/s]  8%|7         |13791/173481[03:10<36:26,73.04it/s] 14%|#4        |25127/173481[06:00<35:30,69.64it/s] 15%|#4        |25734/173481[06:10<35:21,69.64it/s] 21%|##        |35780/173481[09:00<35:52,63.98it/s] 21%|##        |36412/173481[09:10<35:42,63.98it/s] 27%|##6       |46535/173481[12:00<34:14,61.79it/s] 27%|##7       |47174/173481[12:10<34:04,61.79it/s] 33%|###3      |57649/173481[15:00<31:15,61.77it/s] 34%|###3      |58310/173481[15:10<31:04,61.77it/s] 39%|###9      |68315/173481[18:00<28:58,60.48it/s] 40%|###9      |68994/173481[18:10<28:47,60.48it/s] 46%|####5     |79456/173481[21:00<25:36,61.18it/s] 46%|####6     |80139/173481[21:11<25:25,61.18it/s] 52%|#####2    |90878/173481[24:00<22:06,62.29it/s] 53%|#####2    |91577/173481[24:11<21:54,62.29it/s] 59%|#####8    |102199/173481[27:00<18:58,62.59it/s] 59%|#####9    |103020/173481[27:11<18:45,62.59it/s] 66%|######6   |114509/173481[30:00<15:02,65.36it/s] 66%|######6   |115254/173481[30:11<14:50,65.36it/s] 73%|#######2  |125926/173481[33:00<12:18,64.38it/s] 73%|#######3  |126712/173481[33:11<12:06,64.38it/s] 81%|########1 |140629/173481[36:00<07:36,72.01it/s] 82%|########1 |141621/173481[36:11<07:22,72.01it/s] 89%|########8 |153810/173481[39:00<04:30,72.61it/s] 89%|########9 |154558/173481[39:12<04:20,72.61it/s] 95%|#########5|165578/173481[42:00<01:54,68.80it/s] 96%|#########5|166364/173481[42:12<01:43,68.80it/s]100%|##########|173481/173481[44:06<00:00,65.55it/s]
[32m[0324 11:37:21 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:2646.38 sec.
[32m[0324 11:37:21 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,189.29it/s]
31
[32m[0324 11:39:00 @monitor.py:363][0m QueueInput/queue_size: 1.6888
[32m[0324 11:39:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.007
[32m[0324 11:39:00 @monitor.py:363][0m activation-summaries/output-rms: 0.041227
[32m[0324 11:39:00 @monitor.py:363][0m cross_entropy_loss: 1.5923
[32m[0324 11:39:00 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48228
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1077e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35162
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5544e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45701
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5489e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34407
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2441e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46824
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8054e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34654
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6348e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46211
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6677e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9582e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49824
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0521e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34787
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7414e-06
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58364
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2958
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30823
[32m[0324 11:39:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 11:39:00 @monitor.py:363][0m train-error-top1: 0.43174
[32m[0324 11:39:00 @monitor.py:363][0m val-error-top1: 0.43236
[32m[0324 11:39:00 @monitor.py:363][0m val-utt-error: 0.099458
[32m[0324 11:39:00 @monitor.py:363][0m validation_cost: 1.6196
[32m[0324 11:39:00 @monitor.py:363][0m wd_cost: 9.5674e-08
[32m[0324 11:39:00 @group.py:42][0m Callbacks took 99.605 sec in total. InferenceRunner: 99.442sec
[32m[0324 11:39:00 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13052/173481[03:00<36:52,72.51it/s]  8%|7         |13608/173481[03:10<36:44,72.51it/s] 14%|#4        |25120/173481[06:00<35:29,69.67it/s] 15%|#4        |25748/173481[06:10<35:20,69.67it/s] 21%|##        |35567/173481[09:00<36:17,63.32it/s] 21%|##        |36218/173481[09:10<36:07,63.32it/s] 27%|##6       |46209/173481[12:00<34:41,61.14it/s] 27%|##6       |46834/173481[12:10<34:31,61.14it/s] 33%|###2      |56674/173481[15:00<32:39,59.60it/s] 33%|###3      |57302/173481[15:10<32:29,59.60it/s] 39%|###8      |67626/173481[18:00<29:17,60.22it/s] 39%|###9      |68348/173481[18:10<29:05,60.22it/s] 46%|####5     |79697/173481[21:00<24:37,63.45it/s] 46%|####6     |80413/173481[21:11<24:26,63.45it/s] 53%|#####2    |91414/173481[24:00<21:17,64.26it/s] 53%|#####3    |92085/173481[24:11<21:06,64.26it/s] 59%|#####9    |102606/173481[27:00<18:41,63.20it/s] 60%|#####9    |103335/173481[27:11<18:29,63.20it/s] 66%|######5   |114204/173481[30:00<15:28,63.81it/s] 66%|######6   |114989/173481[30:11<15:16,63.81it/s] 73%|#######3  |127450/173481[33:00<11:13,68.35it/s] 74%|#######3  |128284/173481[33:11<11:01,68.35it/s] 81%|########  |140489/173481[36:00<07:49,70.33it/s] 81%|########1 |141335/173481[36:11<07:37,70.33it/s] 89%|########8 |153561/173481[39:00<04:38,71.46it/s] 89%|########9 |154439/173481[39:12<04:26,71.46it/s] 95%|#########5|165344/173481[42:00<01:59,68.33it/s] 96%|#########5|166122/173481[42:12<01:47,68.33it/s]100%|##########|173481/173481[44:09<00:00,65.47it/s]
[32m[0324 12:23:10 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:2649.90 sec.
[32m[0324 12:23:10 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-5724873.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,199.78it/s]
32
[32m[0324 12:24:45 @monitor.py:363][0m QueueInput/queue_size: 0.98981
[32m[0324 12:24:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.873
[32m[0324 12:24:45 @monitor.py:363][0m activation-summaries/output-rms: 0.040768
[32m[0324 12:24:45 @monitor.py:363][0m cross_entropy_loss: 1.5819
[32m[0324 12:24:45 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48229
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1086e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35162
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5542e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45703
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5487e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2444e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46825
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8052e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34654
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6347e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46213
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6679e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9579e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49827
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.052e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34787
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7417e-06
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58376
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2958
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30823
[32m[0324 12:24:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 12:24:45 @monitor.py:363][0m train-error-top1: 0.42925
[32m[0324 12:24:45 @monitor.py:363][0m val-error-top1: 0.43271
[32m[0324 12:24:45 @monitor.py:363][0m val-utt-error: 0.1001
[32m[0324 12:24:45 @monitor.py:363][0m validation_cost: 1.6207
[32m[0324 12:24:45 @monitor.py:363][0m wd_cost: 9.5694e-08
[32m[0324 12:24:45 @group.py:42][0m Callbacks took 94.405 sec in total. InferenceRunner: 94.219sec
[32m[0324 12:24:45 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12864/173481[03:00<37:27,71.47it/s]  8%|7         |13502/173481[03:10<37:18,71.47it/s] 14%|#3        |23553/173481[06:00<38:31,64.87it/s] 14%|#3        |24127/173481[06:10<38:22,64.87it/s] 20%|#9        |34508/173481[09:00<36:53,62.80it/s] 20%|##        |35157/173481[09:10<36:42,62.80it/s] 27%|##6       |46078/173481[12:00<33:25,63.53it/s] 27%|##7       |46888/173481[12:10<33:12,63.53it/s] 34%|###3      |58802/173481[15:00<28:33,66.92it/s] 34%|###4      |59722/173481[15:10<28:20,66.92it/s] 42%|####2     |73151/173481[18:00<22:58,72.76it/s] 43%|####2     |73998/173481[18:10<22:47,72.76it/s] 49%|####9     |85208/173481[21:00<21:05,69.74it/s] 50%|####9     |85897/173481[21:11<20:55,69.74it/s] 56%|#####5    |97073/173481[24:00<18:47,67.76it/s] 56%|#####6    |97763/173481[24:11<18:37,67.76it/s] 63%|######2   |108778/173481[27:00<16:14,66.36it/s] 63%|######3   |109488/173481[27:11<16:04,66.36it/s] 69%|######9   |120134/173481[30:00<13:44,64.68it/s] 70%|######9   |120854/173481[30:11<13:33,64.68it/s] 76%|#######5  |131432/173481[33:00<11:00,63.71it/s] 76%|#######6  |132163/173481[33:11<10:48,63.71it/s] 83%|########2 |143358/173481[36:00<07:43,64.93it/s] 83%|########3 |144072/173481[36:11<07:32,64.93it/s] 89%|########9 |155061/173481[39:00<04:43,64.97it/s] 90%|########9 |155824/173481[39:12<04:31,64.97it/s] 96%|#########6|166591/173481[42:00<01:46,64.51it/s] 96%|#########6|167293/173481[42:12<01:35,64.51it/s]100%|##########|173481/173481[43:55<00:00,65.82it/s]
[32m[0324 13:08:40 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:2635.73 sec.
[32m[0324 13:08:40 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,196.27it/s]
33
[32m[0324 13:10:16 @monitor.py:363][0m QueueInput/queue_size: 1.342
[32m[0324 13:10:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.834
[32m[0324 13:10:16 @monitor.py:363][0m activation-summaries/output-rms: 0.040935
[32m[0324 13:10:16 @monitor.py:363][0m cross_entropy_loss: 1.5886
[32m[0324 13:10:16 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4823
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1083e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5541e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45704
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5486e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34407
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46826
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8052e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34654
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6345e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46213
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6679e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9579e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49827
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.052e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34787
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7416e-06
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58377
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2958
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30823
[32m[0324 13:10:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 13:10:16 @monitor.py:363][0m train-error-top1: 0.42786
[32m[0324 13:10:16 @monitor.py:363][0m val-error-top1: 0.43208
[32m[0324 13:10:16 @monitor.py:363][0m val-utt-error: 0.10068
[32m[0324 13:10:16 @monitor.py:363][0m validation_cost: 1.6201
[32m[0324 13:10:16 @monitor.py:363][0m wd_cost: 1.9139e-08
[32m[0324 13:10:16 @group.py:42][0m Callbacks took 96.069 sec in total. InferenceRunner: 95.907sec
[32m[0324 13:10:16 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14834/173481[03:00<32:05,82.40it/s]  9%|9         |15715/173481[03:10<31:54,82.40it/s] 17%|#7        |30236/173481[06:00<28:26,83.95it/s] 18%|#7        |31036/173481[06:10<28:16,83.95it/s] 24%|##4       |41920/173481[09:00<29:56,73.21it/s] 25%|##4       |42599/173481[09:10<29:47,73.21it/s] 31%|###1      |54378/173481[12:00<27:53,71.16it/s] 32%|###1      |55156/173481[12:10<27:42,71.16it/s] 40%|###9      |68698/173481[15:00<23:14,75.12it/s] 40%|####      |69616/173481[15:10<23:02,75.12it/s] 49%|####8     |84752/173481[18:00<18:08,81.54it/s] 49%|####9     |85697/173481[18:10<17:56,81.54it/s] 58%|#####8    |100828/173481[21:00<14:12,85.25it/s] 59%|#####8    |101795/173481[21:11<14:00,85.25it/s] 66%|######5   |114197/173481[24:00<12:26,79.38it/s] 66%|######6   |114886/173481[24:11<12:18,79.38it/s] 72%|#######2  |125442/173481[27:00<11:27,69.91it/s] 73%|#######2  |126167/173481[27:11<11:16,69.91it/s] 79%|#######9  |137247/173481[30:00<08:55,67.68it/s] 80%|#######9  |137956/173481[30:11<08:44,67.68it/s] 86%|########5 |148642/173481[33:00<06:19,65.42it/s] 86%|########6 |149388/173481[33:11<06:08,65.42it/s] 92%|#########2|160105/173481[36:00<03:27,64.54it/s] 93%|#########2|160847/173481[36:11<03:15,64.54it/s] 99%|#########8|171392/173481[39:00<00:32,63.61it/s] 99%|#########9|172144/173481[39:12<00:21,63.61it/s]100%|##########|173481/173481[39:34<00:00,73.07it/s]
[32m[0324 13:49:50 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:2374.07 sec.
[32m[0324 13:49:51 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-6071835.
[32m[0324 13:49:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,190.12it/s]
34
[32m[0324 13:51:31 @monitor.py:363][0m QueueInput/queue_size: 0.78247
[32m[0324 13:51:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.92
[32m[0324 13:51:31 @monitor.py:363][0m activation-summaries/output-rms: 0.042432
[32m[0324 13:51:31 @monitor.py:363][0m cross_entropy_loss: 1.5832
[32m[0324 13:51:31 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48231
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1084e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45706
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5489e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2444e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46827
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6344e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46214
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6679e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49828
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.052e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.742e-06
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58378
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30823
[32m[0324 13:51:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 13:51:31 @monitor.py:363][0m train-error-top1: 0.42386
[32m[0324 13:51:31 @monitor.py:363][0m val-error-top1: 0.43309
[32m[0324 13:51:31 @monitor.py:363][0m val-utt-error: 0.10052
[32m[0324 13:51:31 @monitor.py:363][0m validation_cost: 1.6237
[32m[0324 13:51:31 @monitor.py:363][0m wd_cost: 1.9139e-08
[32m[0324 13:51:31 @group.py:42][0m Callbacks took 100.457 sec in total. InferenceRunner: 99.008sec
[32m[0324 13:51:31 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12551/173481[03:00<38:28,69.72it/s]  8%|7         |13235/173481[03:10<38:18,69.72it/s] 14%|#3        |24001/173481[06:00<37:27,66.52it/s] 14%|#4        |24647/173481[06:10<37:17,66.52it/s] 20%|#9        |34341/173481[09:00<37:37,61.65it/s] 20%|##        |34852/173481[09:10<37:28,61.65it/s] 25%|##5       |43486/173481[12:00<38:54,55.70it/s] 25%|##5       |44050/173481[12:10<38:43,55.70it/s] 30%|###       |52666/173481[15:00<37:49,53.24it/s] 31%|###       |53205/173481[15:10<37:39,53.24it/s] 36%|###6      |62751/173481[18:00<33:48,54.60it/s] 37%|###6      |63410/173481[18:10<33:36,54.60it/s] 42%|####2     |73700/173481[21:00<28:54,57.54it/s] 43%|####2     |74350/173481[21:11<28:42,57.54it/s] 49%|####9     |85308/173481[24:00<24:09,60.82it/s] 50%|####9     |85999/173481[24:11<23:58,60.82it/s] 56%|#####5    |96918/173481[27:00<20:22,62.60it/s] 56%|#####6    |97658/173481[27:11<20:11,62.60it/s] 62%|######2   |108140/173481[30:00<17:25,62.47it/s] 63%|######2   |108865/173481[30:11<17:14,62.47it/s] 69%|######9   |119726/173481[33:00<14:07,63.41it/s] 69%|######9   |120464/173481[33:11<13:56,63.41it/s] 76%|#######5  |131005/173481[36:00<11:13,63.03it/s] 76%|#######5  |131735/173481[36:11<11:02,63.03it/s] 82%|########1 |142171/173481[39:00<08:20,62.53it/s] 82%|########2 |142877/173481[39:12<08:09,62.53it/s] 88%|########8 |152964/173481[42:00<05:35,61.22it/s] 89%|########8 |153690/173481[42:12<05:23,61.22it/s] 95%|#########4|164676/173481[45:00<02:19,63.08it/s] 95%|#########5|165559/173481[45:12<02:05,63.08it/s]100%|##########|173481/173481[47:12<00:00,61.26it/s]
[32m[0324 14:38:43 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:2832.05 sec.
[32m[0324 14:38:43 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,192.93it/s]
35
[32m[0324 14:40:21 @monitor.py:363][0m QueueInput/queue_size: 0.83637
[32m[0324 14:40:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.89
[32m[0324 14:40:21 @monitor.py:363][0m activation-summaries/output-rms: 0.040951
[32m[0324 14:40:21 @monitor.py:363][0m cross_entropy_loss: 1.5906
[32m[0324 14:40:21 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48232
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1083e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35162
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45707
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46827
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8052e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46215
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6679e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49828
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58369
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30823
[32m[0324 14:40:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 14:40:21 @monitor.py:363][0m train-error-top1: 0.42295
[32m[0324 14:40:21 @monitor.py:363][0m val-error-top1: 0.43231
[32m[0324 14:40:21 @monitor.py:363][0m val-utt-error: 0.1018
[32m[0324 14:40:21 @monitor.py:363][0m validation_cost: 1.6224
[32m[0324 14:40:21 @monitor.py:363][0m wd_cost: 3.8273e-09
[32m[0324 14:40:21 @group.py:42][0m Callbacks took 97.715 sec in total. InferenceRunner: 97.565sec
[32m[0324 14:40:21 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13255/173481[03:00<36:16,73.62it/s]  8%|8         |13919/173481[03:10<36:07,73.62it/s] 14%|#4        |24965/173481[06:00<35:50,69.06it/s] 15%|#4        |25539/173481[06:10<35:42,69.06it/s] 20%|##        |35348/173481[09:00<36:37,62.86it/s] 21%|##        |35925/173481[09:10<36:28,62.86it/s] 26%|##6       |45746/173481[12:00<35:21,60.21it/s] 27%|##6       |46374/173481[12:10<35:11,60.21it/s] 32%|###2      |56330/173481[15:00<32:49,59.49it/s] 33%|###2      |56969/173481[15:10<32:38,59.49it/s] 39%|###8      |66979/173481[18:00<29:55,59.33it/s] 39%|###8      |67631/173481[18:10<29:44,59.33it/s] 45%|####4     |77800/173481[21:00<26:42,59.72it/s] 45%|####5     |78459/173481[21:11<26:31,59.72it/s] 51%|#####1    |88867/173481[24:00<23:16,60.59it/s] 52%|#####1    |89533/173481[24:11<23:05,60.59it/s] 58%|#####7    |99885/173481[27:00<20:08,60.89it/s] 58%|#####8    |100644/173481[27:11<19:56,60.89it/s] 64%|######4   |111465/173481[30:00<16:31,62.56it/s] 65%|######4   |112153/173481[30:11<16:20,62.56it/s] 70%|#######   |122260/173481[33:00<13:56,61.23it/s] 71%|#######   |122949/173481[33:11<13:45,61.23it/s] 77%|#######6  |133016/173481[36:00<11:09,60.49it/s] 77%|#######7  |133704/173481[36:11<10:57,60.49it/s] 83%|########2 |143480/173481[39:00<08:26,59.28it/s] 83%|########3 |144214/173481[39:12<08:13,59.28it/s] 89%|########9 |154538/173481[42:00<05:13,60.34it/s] 89%|########9 |155244/173481[42:12<05:02,60.34it/s] 95%|#########5|165281/173481[45:00<02:16,60.01it/s] 96%|#########5|166012/173481[45:12<02:04,60.01it/s]100%|##########|173481/173481[47:17<00:00,61.14it/s]
[32m[0324 15:27:38 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:2837.60 sec.
[32m[0324 15:27:38 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:32<00:00,204.24it/s]
36
[32m[0324 15:29:11 @monitor.py:363][0m QueueInput/queue_size: 0.88833
[32m[0324 15:29:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.065
[32m[0324 15:29:11 @monitor.py:363][0m activation-summaries/output-rms: 0.041224
[32m[0324 15:29:11 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0324 15:29:11 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48232
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35162
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45707
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8052e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46216
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6679e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9579e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49829
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34787
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7422e-06
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58354
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2956
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30823
[32m[0324 15:29:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 15:29:11 @monitor.py:363][0m train-error-top1: 0.43216
[32m[0324 15:29:11 @monitor.py:363][0m val-error-top1: 0.43235
[32m[0324 15:29:11 @monitor.py:363][0m val-utt-error: 0.099246
[32m[0324 15:29:11 @monitor.py:363][0m validation_cost: 1.6193
[32m[0324 15:29:11 @monitor.py:363][0m wd_cost: 3.8264e-09
[32m[0324 15:29:11 @group.py:42][0m Callbacks took 92.383 sec in total. InferenceRunner: 92.162sec
[32m[0324 15:29:11 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14239/173481[03:00<33:33,79.10it/s]  9%|8         |14945/173481[03:10<33:24,79.10it/s] 15%|#5        |26279/173481[06:00<33:50,72.48it/s] 15%|#5        |26883/173481[06:10<33:42,72.48it/s] 21%|##1       |36859/173481[09:00<35:04,64.91it/s] 22%|##1       |37473/173481[09:10<34:55,64.91it/s] 27%|##7       |47494/173481[12:00<33:57,61.85it/s] 28%|##7       |48078/173481[12:10<33:47,61.85it/s] 33%|###3      |57829/173481[15:00<32:22,59.54it/s] 34%|###3      |58410/173481[15:10<32:12,59.54it/s] 39%|###9      |68436/173481[18:00<29:33,59.23it/s] 40%|###9      |69124/173481[18:10<29:21,59.23it/s] 46%|####6     |80149/173481[21:00<25:05,62.01it/s] 47%|####6     |80863/173481[21:11<24:53,62.01it/s] 53%|#####2    |91699/173481[24:00<21:36,63.07it/s] 53%|#####3    |92338/173481[24:11<21:26,63.07it/s] 59%|#####9    |102624/173481[27:00<19:05,61.85it/s] 60%|#####9    |103338/173481[27:11<18:54,61.85it/s] 66%|######5   |113938/173481[30:00<15:55,62.35it/s] 66%|######6   |114825/173481[30:11<15:40,62.35it/s] 73%|#######2  |125913/173481[33:00<12:18,64.37it/s] 73%|#######2  |126597/173481[33:11<12:08,64.37it/s] 79%|#######9  |137218/173481[36:00<09:30,63.58it/s] 80%|#######9  |137978/173481[36:11<09:18,63.58it/s] 86%|########5 |148607/173481[39:00<06:32,63.42it/s] 86%|########6 |149347/173481[39:12<06:20,63.42it/s] 92%|#########2|160174/173481[42:00<03:28,63.84it/s] 93%|#########2|160968/173481[42:12<03:16,63.84it/s]100%|##########|173481/173481[44:54<00:00,64.39it/s]
[32m[0324 16:14:05 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:2694.05 sec.
[32m[0324 16:14:05 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-6592278.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,191.09it/s]
37
[32m[0324 16:15:43 @monitor.py:363][0m QueueInput/queue_size: 0.81006
[32m[0324 16:15:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.905
[32m[0324 16:15:43 @monitor.py:363][0m activation-summaries/output-rms: 0.040762
[32m[0324 16:15:43 @monitor.py:363][0m cross_entropy_loss: 1.5817
[32m[0324 16:15:43 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48232
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1083e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8052e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46216
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.9579e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49829
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34787
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58339
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2956
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 16:15:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 16:15:43 @monitor.py:363][0m train-error-top1: 0.42907
[32m[0324 16:15:43 @monitor.py:363][0m val-error-top1: 0.43264
[32m[0324 16:15:43 @monitor.py:363][0m val-utt-error: 0.10004
[32m[0324 16:15:43 @monitor.py:363][0m validation_cost: 1.6205
[32m[0324 16:15:43 @monitor.py:363][0m wd_cost: 3.8255e-09
[32m[0324 16:15:43 @group.py:42][0m Callbacks took 98.706 sec in total. InferenceRunner: 98.510sec
[32m[0324 16:15:43 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12206/173481[03:00<39:38,67.81it/s]  7%|7         |12809/173481[03:10<39:29,67.81it/s] 13%|#2        |22300/173481[06:00<41:02,61.39it/s] 13%|#3        |22923/173481[06:10<40:52,61.39it/s] 19%|#8        |32483/173481[09:00<39:54,58.88it/s] 19%|#9        |33059/173481[09:10<39:44,58.88it/s] 25%|##4       |43143/173481[12:00<36:47,59.05it/s] 25%|##5       |43748/173481[12:10<36:37,59.05it/s] 31%|###1      |53810/173481[15:00<33:43,59.15it/s] 31%|###1      |54508/173481[15:10<33:31,59.15it/s] 37%|###7      |64301/173481[18:00<30:59,58.71it/s] 37%|###7      |64997/173481[18:11<30:47,58.71it/s] 43%|####3     |75159/173481[21:00<27:32,59.50it/s] 44%|####3     |75845/173481[21:11<27:20,59.50it/s] 49%|####9     |85551/173481[24:00<25:00,58.60it/s] 50%|####9     |86242/173481[24:11<24:48,58.60it/s] 55%|#####5    |95800/173481[27:00<22:24,57.76it/s] 56%|#####5    |96466/173481[27:11<22:13,57.76it/s] 61%|######1   |106038/173481[30:00<19:36,57.31it/s] 62%|######1   |106720/173481[30:11<19:24,57.31it/s] 67%|######7   |116241/173481[33:00<16:44,56.99it/s] 67%|######7   |116901/173481[33:12<16:32,56.99it/s] 73%|#######3  |126807/173481[36:00<13:27,57.83it/s] 74%|#######3  |127559/173481[36:12<13:14,57.83it/s] 79%|#######9  |137357/173481[39:00<10:20,58.22it/s] 80%|#######9  |138083/173481[39:12<10:08,58.22it/s] 85%|########5 |147568/173481[42:00<07:30,57.46it/s] 85%|########5 |148290/173481[42:12<07:18,57.46it/s] 91%|######### |157800/173481[45:00<04:34,57.15it/s] 91%|#########1|158572/173481[45:12<04:20,57.15it/s] 97%|#########6|167750/173481[48:00<01:41,56.20it/s] 97%|#########7|168422/173481[48:12<01:30,56.20it/s]100%|##########|173481/173481[49:46<00:00,58.08it/s]
[32m[0324 17:05:30 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:2986.92 sec.
[32m[0324 17:05:30 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:24<00:00,129.92it/s]
38
[32m[0324 17:07:55 @monitor.py:363][0m QueueInput/queue_size: 0.78379
[32m[0324 17:07:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.84
[32m[0324 17:07:55 @monitor.py:363][0m activation-summaries/output-rms: 0.040915
[32m[0324 17:07:55 @monitor.py:363][0m cross_entropy_loss: 1.5883
[32m[0324 17:07:55 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48232
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1083e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46216
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49829
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58315
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2956
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 17:07:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 17:07:55 @monitor.py:363][0m train-error-top1: 0.42803
[32m[0324 17:07:55 @monitor.py:363][0m val-error-top1: 0.43208
[32m[0324 17:07:55 @monitor.py:363][0m val-utt-error: 0.1001
[32m[0324 17:07:55 @monitor.py:363][0m validation_cost: 1.6199
[32m[0324 17:07:55 @monitor.py:363][0m wd_cost: 7.6479e-10
[32m[0324 17:07:55 @group.py:42][0m Callbacks took 145.010 sec in total. InferenceRunner: 144.889sec
[32m[0324 17:07:55 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10324/173481[03:00<47:24,57.35it/s]  6%|6         |10881/173481[03:10<47:14,57.35it/s] 12%|#1        |20378/173481[06:00<45:05,56.59it/s] 12%|#2        |20938/173481[06:10<44:55,56.59it/s] 18%|#7        |30460/173481[09:00<42:20,56.30it/s] 18%|#7        |31055/173481[09:10<42:09,56.30it/s] 23%|##3       |40691/173481[12:00<39:07,56.56it/s] 24%|##3       |41339/173481[12:10<38:56,56.56it/s] 29%|##9       |51061/173481[15:00<35:44,57.08it/s] 30%|##9       |51745/173481[15:10<35:32,57.08it/s] 36%|###5      |62012/173481[18:00<31:32,58.89it/s] 36%|###6      |62665/173481[18:11<31:21,58.89it/s] 42%|####1     |72484/173481[21:00<28:45,58.53it/s] 42%|####2     |73165/173481[21:11<28:33,58.53it/s] 48%|####7     |82957/173481[24:00<25:51,58.35it/s] 48%|####8     |83647/173481[24:11<25:39,58.35it/s] 54%|#####3    |93527/173481[27:00<22:45,58.53it/s] 54%|#####4    |94191/173481[27:11<22:34,58.53it/s] 60%|#####9    |103923/173481[30:00<19:56,58.14it/s] 60%|######    |104571/173481[30:11<19:45,58.14it/s] 66%|######5   |114311/173481[33:00<17:01,57.92it/s] 66%|######6   |115011/173481[33:12<16:49,57.92it/s] 72%|#######1  |124828/173481[36:00<13:56,58.17it/s] 72%|#######2  |125516/173481[36:12<13:44,58.17it/s] 78%|#######7  |135166/173481[39:00<11:02,57.80it/s] 78%|#######8  |135862/173481[39:12<10:50,57.80it/s] 84%|########3 |145600/173481[42:00<08:01,57.88it/s] 84%|########4 |146305/173481[42:12<07:49,57.88it/s] 90%|######### |156294/173481[45:00<04:53,58.64it/s] 91%|######### |157026/173481[45:12<04:40,58.64it/s] 96%|#########6|166973/173481[48:00<01:50,58.98it/s] 97%|#########6|167733/173481[48:12<01:37,58.98it/s]100%|##########|173481/173481[49:53<00:00,57.95it/s]
[32m[0324 17:57:49 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:2993.41 sec.
[32m[0324 17:57:49 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-6939240.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:39<00:00,118.37it/s]
39
[32m[0324 18:00:28 @monitor.py:363][0m QueueInput/queue_size: 2.3681
[32m[0324 18:00:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.893
[32m[0324 18:00:28 @monitor.py:363][0m activation-summaries/output-rms: 0.042404
[32m[0324 18:00:28 @monitor.py:363][0m cross_entropy_loss: 1.5828
[32m[0324 18:00:28 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48232
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1083e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46216
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49829
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7422e-06
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58289
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 18:00:28 @monitor.py:363][0m train-error-top1: 0.42334
[32m[0324 18:00:28 @monitor.py:363][0m val-error-top1: 0.4331
[32m[0324 18:00:28 @monitor.py:363][0m val-utt-error: 0.10052
[32m[0324 18:00:28 @monitor.py:363][0m validation_cost: 1.6234
[32m[0324 18:00:28 @monitor.py:363][0m wd_cost: 7.6447e-10
[32m[0324 18:00:28 @group.py:42][0m Callbacks took 159.199 sec in total. InferenceRunner: 159.024sec
[32m[0324 18:00:28 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11993/173481[03:00<40:23,66.63it/s]  7%|7         |12736/173481[03:10<40:12,66.63it/s] 13%|#3        |22781/173481[06:00<39:48,63.10it/s] 13%|#3        |23410/173481[06:10<39:38,63.10it/s] 19%|#9        |33341/173481[09:00<38:25,60.79it/s] 20%|#9        |33937/173481[09:10<38:15,60.79it/s] 25%|##5       |43530/173481[12:00<36:56,58.62it/s] 25%|##5       |44117/173481[12:10<36:46,58.62it/s] 30%|###       |52742/173481[15:00<36:49,54.65it/s] 31%|###       |53303/173481[15:10<36:39,54.65it/s] 36%|###6      |62932/173481[18:00<33:07,55.61it/s] 37%|###6      |63590/173481[18:11<32:56,55.61it/s] 42%|####1     |72842/173481[21:00<30:18,55.33it/s] 42%|####2     |73470/173481[21:11<30:07,55.33it/s] 48%|####7     |82723/173481[24:00<27:26,55.11it/s] 48%|####8     |83298/173481[24:11<27:16,55.11it/s] 53%|#####2    |91866/173481[27:00<25:43,52.86it/s] 53%|#####3    |92450/173481[27:11<25:32,52.86it/s] 58%|#####8    |100953/173481[30:00<23:24,51.64it/s] 59%|#####8    |101540/173481[30:11<23:13,51.64it/s] 64%|######3   |110653/173481[33:00<19:51,52.74it/s] 64%|######4   |111255/173481[33:11<19:39,52.74it/s] 69%|######9   |119856/173481[36:00<17:12,51.92it/s] 69%|######9   |120487/173481[36:12<17:00,51.92it/s] 74%|#######4  |129128/173481[39:00<14:17,51.71it/s] 75%|#######4  |129717/173481[39:12<14:06,51.71it/s] 80%|#######9  |138406/173481[42:00<11:19,51.63it/s] 80%|########  |139057/173481[42:12<11:06,51.63it/s] 85%|########5 |147579/173481[45:00<08:25,51.29it/s] 85%|########5 |148224/173481[45:12<08:12,51.29it/s] 91%|######### |157247/173481[48:00<05:09,52.47it/s] 91%|#########1|157937/173481[48:12<04:56,52.47it/s] 96%|#########6|167102/173481[51:00<01:59,53.59it/s] 97%|#########6|167768/173481[51:13<01:46,53.59it/s]100%|##########|173481/173481[52:56<00:00,54.62it/s]
[32m[0324 18:53:24 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:3176.02 sec.
[32m[0324 18:53:24 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:44<00:00,114.73it/s]
40
[32m[0324 18:56:08 @monitor.py:363][0m QueueInput/queue_size: 0.65292
[32m[0324 18:56:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.842
[32m[0324 18:56:08 @monitor.py:363][0m activation-summaries/output-rms: 0.040918
[32m[0324 18:56:08 @monitor.py:363][0m cross_entropy_loss: 1.5901
[32m[0324 18:56:08 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1083e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58265
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 18:56:08 @monitor.py:363][0m train-error-top1: 0.42257
[32m[0324 18:56:08 @monitor.py:363][0m val-error-top1: 0.4323
[32m[0324 18:56:08 @monitor.py:363][0m val-utt-error: 0.10142
[32m[0324 18:56:08 @monitor.py:363][0m validation_cost: 1.6221
[32m[0324 18:56:08 @monitor.py:363][0m wd_cost: 7.6417e-10
[32m[0324 18:56:08 @group.py:42][0m Callbacks took 164.266 sec in total. InferenceRunner: 164.088sec
[32m[0324 18:56:08 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10312/173481[03:00<47:28,57.28it/s]  6%|6         |10920/173481[03:10<47:17,57.28it/s] 12%|#1        |20576/173481[06:00<44:35,57.15it/s] 12%|#2        |21104/173481[06:10<44:26,57.15it/s] 18%|#7        |30464/173481[09:00<42:32,56.02it/s] 18%|#7        |31038/173481[09:10<42:22,56.02it/s] 22%|##2       |39033/173481[12:00<43:32,51.47it/s] 23%|##2       |39534/173481[12:10<43:22,51.47it/s] 27%|##7       |47341/173481[15:00<43:11,48.67it/s] 28%|##7       |47853/173481[15:10<43:01,48.67it/s] 32%|###2      |56250/173481[18:00<39:48,49.07it/s] 33%|###2      |56764/173481[18:11<39:38,49.07it/s] 38%|###7      |65538/173481[21:00<35:45,50.30it/s] 38%|###8      |66148/173481[21:11<35:33,50.30it/s] 44%|####3     |75509/173481[24:00<30:58,52.73it/s] 44%|####3     |76048/173481[24:11<30:47,52.73it/s] 49%|####9     |85197/173481[27:00<27:37,53.27it/s] 49%|####9     |85845/173481[27:11<27:25,53.27it/s] 55%|#####4    |94847/173481[30:00<24:31,53.44it/s] 55%|#####5    |95531/173481[30:11<24:18,53.44it/s] 61%|######    |105171/173481[33:00<20:34,55.33it/s] 61%|######    |105804/173481[33:12<20:23,55.33it/s] 66%|######6   |114890/173481[36:00<17:52,54.65it/s] 67%|######6   |115492/173481[36:12<17:41,54.65it/s] 71%|#######1  |123999/173481[39:00<15:41,52.55it/s] 72%|#######1  |124630/173481[39:12<15:29,52.55it/s] 77%|#######6  |132995/173481[42:00<13:10,51.22it/s] 77%|#######7  |133635/173481[42:12<12:57,51.22it/s] 82%|########1 |141913/173481[45:00<10:26,50.37it/s] 82%|########2 |142546/173481[45:12<10:14,50.37it/s] 87%|########6 |150820/173481[48:00<07:33,49.92it/s] 87%|########7 |151494/173481[48:12<07:20,49.92it/s] 92%|#########2|159888/173481[51:00<04:31,50.14it/s] 93%|#########2|160537/173481[51:13<04:18,50.14it/s] 97%|#########7|168711/173481[54:00<01:36,49.57it/s] 98%|#########7|169363/173481[54:13<01:23,49.57it/s]100%|##########|173481/173481[55:33<00:00,52.05it/s]
[32m[0324 19:51:42 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3333.52 sec.
[32m[0324 19:51:42 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-7286202.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:56<00:00,106.76it/s]
41
[32m[0324 19:54:38 @monitor.py:363][0m QueueInput/queue_size: 1.7686
[32m[0324 19:54:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.003
[32m[0324 19:54:38 @monitor.py:363][0m activation-summaries/output-rms: 0.041188
[32m[0324 19:54:38 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0324 19:54:38 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1083e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58252
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 19:54:38 @monitor.py:363][0m train-error-top1: 0.43184
[32m[0324 19:54:38 @monitor.py:363][0m val-error-top1: 0.43233
[32m[0324 19:54:38 @monitor.py:363][0m val-utt-error: 0.099246
[32m[0324 19:54:38 @monitor.py:363][0m validation_cost: 1.619
[32m[0324 19:54:38 @monitor.py:363][0m wd_cost: 1.528e-10
[32m[0324 19:54:38 @group.py:42][0m Callbacks took 176.486 sec in total. InferenceRunner: 176.307sec
[32m[0324 19:54:38 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10149/173481[03:00<48:17,56.37it/s]  6%|6         |10647/173481[03:10<48:08,56.37it/s] 11%|#1        |19559/173481[06:00<47:17,54.24it/s] 12%|#1        |20100/173481[06:10<47:07,54.24it/s] 16%|#6        |27906/173481[09:00<48:31,50.00it/s] 16%|#6        |28335/173481[09:10<48:23,50.00it/s] 21%|##        |35901/173481[12:00<48:44,47.04it/s] 21%|##        |36390/173481[12:10<48:34,47.04it/s] 25%|##5       |44119/173481[15:00<46:31,46.34it/s] 26%|##5       |44613/173481[15:10<46:21,46.34it/s] 30%|###       |52446/173481[18:00<43:34,46.30it/s] 31%|###       |52962/173481[18:11<43:23,46.30it/s] 35%|###5      |60990/173481[21:00<39:59,46.87it/s] 35%|###5      |61506/173481[21:11<39:48,46.87it/s] 40%|####      |70036/173481[24:00<35:32,48.50it/s] 41%|####      |70581/173481[24:11<35:21,48.50it/s] 46%|####5     |79611/173481[27:00<30:50,50.74it/s] 46%|####6     |80181/173481[27:11<30:38,50.74it/s] 51%|#####1    |88598/173481[30:00<28:06,50.33it/s] 51%|#####1    |89208/173481[30:11<27:54,50.33it/s] 56%|#####6    |97617/173481[33:00<25:10,50.21it/s] 57%|#####6    |98248/173481[33:12<24:58,50.21it/s] 61%|######1   |106529/173481[36:00<22:22,49.86it/s] 62%|######1   |107143/173481[36:12<22:10,49.86it/s] 67%|######6   |115573/173481[39:00<19:16,50.05it/s] 67%|######6   |116208/173481[39:12<19:04,50.05it/s] 72%|#######1  |124595/173481[42:00<16:16,50.09it/s] 72%|#######2  |125212/173481[42:12<16:03,50.09it/s] 77%|#######7  |133871/173481[45:00<12:59,50.80it/s] 78%|#######7  |134561/173481[45:12<12:46,50.80it/s] 83%|########2 |143344/173481[48:00<09:42,51.69it/s] 83%|########3 |144200/173481[48:13<09:26,51.69it/s] 88%|########8 |153028/173481[51:00<06:27,52.72it/s] 89%|########8 |153767/173481[51:13<06:13,52.72it/s] 94%|#########3|162484/173481[54:00<03:28,52.63it/s] 94%|#########3|163072/173481[54:13<03:17,52.63it/s] 99%|#########9|171954/173481[57:00<00:29,52.62it/s]100%|#########9|172680/173481[57:13<00:15,52.62it/s]100%|##########|173481/173481[57:29<00:00,50.29it/s]
[32m[0324 20:52:08 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3449.41 sec.
[32m[0324 20:52:08 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:27<00:00,127.41it/s]
42
[32m[0324 20:54:36 @monitor.py:363][0m QueueInput/queue_size: 0.55104
[32m[0324 20:54:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.705
[32m[0324 20:54:36 @monitor.py:363][0m activation-summaries/output-rms: 0.041067
[32m[0324 20:54:36 @monitor.py:363][0m cross_entropy_loss: 1.5855
[32m[0324 20:54:36 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45709
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58238
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 20:54:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 20:54:36 @monitor.py:363][0m train-error-top1: 0.43245
[32m[0324 20:54:36 @monitor.py:363][0m val-error-top1: 0.43216
[32m[0324 20:54:36 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0324 20:54:36 @monitor.py:363][0m validation_cost: 1.6203
[32m[0324 20:54:36 @monitor.py:363][0m wd_cost: 1.5277e-10
[32m[0324 20:54:36 @group.py:42][0m Callbacks took 147.939 sec in total. InferenceRunner: 147.761sec
[32m[0324 20:54:36 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9901/173481[03:00<49:33,55.00it/s]  6%|5         |10386/173481[03:10<49:25,55.00it/s] 11%|#         |18752/173481[06:00<49:39,51.92it/s] 11%|#1        |19231/173481[06:10<49:30,51.92it/s] 16%|#6        |28113/173481[09:00<46:37,51.96it/s] 16%|#6        |28604/173481[09:10<46:28,51.96it/s] 22%|##1       |37852/173481[12:00<42:38,53.01it/s] 22%|##2       |38445/173481[12:10<42:27,53.01it/s] 28%|##7       |48106/173481[15:00<38:03,54.92it/s] 28%|##8       |48703/173481[15:10<37:52,54.92it/s] 33%|###3      |58110/173481[18:00<34:48,55.24it/s] 34%|###3      |58862/173481[18:11<34:34,55.24it/s] 40%|###9      |68780/173481[21:00<30:30,57.19it/s] 40%|####      |69519/173481[21:11<30:17,57.19it/s] 46%|####5     |79252/173481[24:00<27:13,57.68it/s] 46%|####6     |79983/173481[24:11<27:01,57.68it/s] 52%|#####1    |89703/173481[27:00<24:07,57.86it/s] 52%|#####2    |90379/173481[27:11<23:56,57.86it/s] 58%|#####7    |99918/173481[30:00<21:23,57.30it/s] 58%|#####8    |100712/173481[30:11<21:09,57.30it/s] 64%|######3   |110635/173481[33:00<17:56,58.40it/s] 64%|######4   |111251/173481[33:12<17:45,58.40it/s] 70%|######9   |121199/173481[36:00<14:53,58.54it/s] 70%|#######   |121789/173481[36:12<14:43,58.54it/s] 76%|#######5  |131607/173481[39:00<11:59,58.18it/s] 76%|#######6  |132437/173481[39:12<11:45,58.18it/s] 82%|########2 |142492/173481[42:00<08:42,59.30it/s] 82%|########2 |143119/173481[42:12<08:31,59.30it/s] 88%|########8 |152803/173481[45:00<05:54,58.27it/s] 89%|########8 |153706/173481[45:12<05:39,58.27it/s] 94%|#########4|163166/173481[48:00<02:58,57.92it/s] 94%|#########4|163912/173481[48:13<02:45,57.92it/s]100%|#########9|172857/173481[51:00<00:11,55.80it/s]100%|##########|173481/173481[51:10<00:00,56.51it/s]
[32m[0324 21:45:46 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3070.03 sec.
[32m[0324 21:45:46 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-7633164.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:31<00:00,124.50it/s]
43
[32m[0324 21:48:17 @monitor.py:363][0m QueueInput/queue_size: 6.7452
[32m[0324 21:48:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.771
[32m[0324 21:48:17 @monitor.py:363][0m activation-summaries/output-rms: 0.040879
[32m[0324 21:48:17 @monitor.py:363][0m cross_entropy_loss: 1.5886
[32m[0324 21:48:17 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58231
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 21:48:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 21:48:17 @monitor.py:363][0m train-error-top1: 0.42839
[32m[0324 21:48:17 @monitor.py:363][0m val-error-top1: 0.43203
[32m[0324 21:48:17 @monitor.py:363][0m val-utt-error: 0.10063
[32m[0324 21:48:17 @monitor.py:363][0m validation_cost: 1.6195
[32m[0324 21:48:17 @monitor.py:363][0m wd_cost: 1.5275e-10
[32m[0324 21:48:17 @group.py:42][0m Callbacks took 151.695 sec in total. InferenceRunner: 151.200sec
[32m[0324 21:48:17 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10437/173481[03:00<46:52,57.98it/s]  6%|6         |11054/173481[03:10<46:41,57.98it/s] 12%|#2        |21016/173481[06:00<43:32,58.37it/s] 12%|#2        |21559/173481[06:10<43:22,58.37it/s] 18%|#7        |30594/173481[09:00<42:46,55.67it/s] 18%|#7        |31225/173481[09:10<42:35,55.67it/s] 24%|##3       |41206/173481[12:00<38:29,57.27it/s] 24%|##4       |41913/173481[12:10<38:17,57.27it/s] 30%|##9       |52035/173481[15:00<34:29,58.68it/s] 30%|###       |52856/173481[15:11<34:15,58.68it/s] 36%|###6      |62691/173481[18:00<31:19,58.94it/s] 37%|###6      |63458/173481[18:11<31:06,58.94it/s] 42%|####2     |73477/173481[21:00<28:02,59.42it/s] 43%|####2     |74218/173481[21:11<27:50,59.42it/s] 49%|####8     |84206/173481[24:00<25:00,59.51it/s] 49%|####9     |85068/173481[24:11<24:45,59.51it/s] 55%|#####4    |94855/173481[27:00<22:05,59.34it/s] 55%|#####5    |95737/173481[27:11<21:50,59.34it/s] 61%|######1   |105876/173481[30:00<18:41,60.27it/s] 62%|######1   |106707/173481[30:12<18:27,60.27it/s] 67%|######7   |116362/173481[33:00<16:04,59.24it/s] 68%|######7   |117261/173481[33:12<15:48,59.24it/s] 73%|#######3  |126971/173481[36:00<13:07,59.09it/s] 74%|#######3  |127946/173481[36:12<12:50,59.09it/s] 79%|#######9  |137835/173481[39:00<09:56,59.71it/s] 80%|#######9  |138507/173481[39:12<09:45,59.71it/s] 86%|########5 |148442/173481[42:00<07:02,59.31it/s] 86%|########5 |148931/173481[42:12<06:53,59.31it/s] 92%|#########1|159489/173481[45:00<03:51,60.32it/s] 92%|#########2|160085/173481[45:13<03:42,60.32it/s] 98%|#########8|170185/173481[48:00<00:55,59.87it/s] 99%|#########8|170907/173481[48:13<00:42,59.87it/s]100%|##########|173481/173481[48:57<00:00,59.07it/s]
[32m[0324 22:37:14 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:2937.03 sec.
[32m[0324 22:37:14 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-7806645.
[32m[0324 22:37:15 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:31<00:00,124.22it/s]
44
[32m[0324 22:39:46 @monitor.py:363][0m QueueInput/queue_size: 46.313
[32m[0324 22:39:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.837
[32m[0324 22:39:46 @monitor.py:363][0m activation-summaries/output-rms: 0.042382
[32m[0324 22:39:46 @monitor.py:363][0m cross_entropy_loss: 1.5969
[32m[0324 22:39:46 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58229
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 22:39:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 22:39:46 @monitor.py:363][0m train-error-top1: 0.42591
[32m[0324 22:39:46 @monitor.py:363][0m val-error-top1: 0.43065
[32m[0324 22:39:46 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0324 22:39:46 @monitor.py:363][0m validation_cost: 1.6128
[32m[0324 22:39:46 @monitor.py:363][0m wd_cost: 3.0549e-11
[32m[0324 22:39:46 @group.py:42][0m Callbacks took 151.788 sec in total. InferenceRunner: 151.537sec
[32m[0324 22:39:46 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10780/173481[03:00<45:17,59.88it/s]  7%|6         |11448/173481[03:10<45:05,59.88it/s] 12%|#2        |21428/173481[06:00<42:34,59.52it/s] 13%|#2        |22085/173481[06:10<42:23,59.52it/s] 18%|#8        |31714/173481[09:00<40:31,58.31it/s] 19%|#8        |32324/173481[09:10<40:21,58.31it/s] 24%|##3       |41593/173481[12:00<38:52,56.54it/s] 24%|##4       |42212/173481[12:10<38:41,56.54it/s] 30%|##9       |51730/173481[15:00<35:57,56.42it/s] 30%|###       |52358/173481[15:11<35:46,56.42it/s] 36%|###5      |62148/173481[18:00<32:28,57.14it/s] 36%|###6      |62732/173481[18:11<32:18,57.14it/s] 42%|####1     |72377/173481[21:00<29:34,56.98it/s] 42%|####2     |72976/173481[21:11<29:23,56.98it/s] 48%|####7     |82500/173481[24:00<26:47,56.61it/s] 48%|####7     |83047/173481[24:11<26:37,56.61it/s] 53%|#####3    |92556/173481[27:00<23:59,56.23it/s] 54%|#####3    |93177/173481[27:11<23:48,56.23it/s] 59%|#####9    |102535/173481[30:00<21:10,55.83it/s] 59%|#####9    |103200/173481[30:12<20:58,55.83it/s] 65%|######4   |112612/173481[33:00<18:08,55.91it/s] 65%|######5   |113276/173481[33:12<17:56,55.91it/s] 71%|#######   |122595/173481[36:00<15:13,55.68it/s] 71%|#######1  |123410/173481[36:12<14:59,55.68it/s] 77%|#######6  |132861/173481[39:00<12:00,56.35it/s] 77%|#######7  |133606/173481[39:12<11:47,56.35it/s] 82%|########2 |143073/173481[42:00<08:57,56.54it/s] 83%|########2 |143972/173481[42:13<08:41,56.54it/s] 88%|########8 |153360/173481[45:00<05:53,56.84it/s] 89%|########8 |154111/173481[45:13<05:40,56.84it/s] 94%|#########4|163099/173481[48:00<03:07,55.44it/s] 94%|#########4|163931/173481[48:13<02:52,55.44it/s]100%|#########9|173177/173481[51:00<00:05,55.71it/s]100%|##########|173481/173481[51:06<00:00,56.57it/s]
[32m[0324 23:30:53 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:3066.55 sec.
[32m[0324 23:30:53 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-7980126.
[32m[0324 23:30:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:28<00:00,126.34it/s]
45
[32m[0324 23:33:22 @monitor.py:363][0m QueueInput/queue_size: 48.623
[32m[0324 23:33:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.721
[32m[0324 23:33:22 @monitor.py:363][0m activation-summaries/output-rms: 0.04185
[32m[0324 23:33:22 @monitor.py:363][0m cross_entropy_loss: 1.6023
[32m[0324 23:33:22 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58227
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0324 23:33:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0324 23:33:22 @monitor.py:363][0m train-error-top1: 0.42583
[32m[0324 23:33:22 @monitor.py:363][0m val-error-top1: 0.43181
[32m[0324 23:33:22 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0324 23:33:22 @monitor.py:363][0m validation_cost: 1.6199
[32m[0324 23:33:22 @monitor.py:363][0m wd_cost: 3.0548e-11
[32m[0324 23:33:22 @group.py:42][0m Callbacks took 149.677 sec in total. InferenceRunner: 148.998sec
[32m[0324 23:33:22 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10593/173481[03:00<46:07,58.85it/s]  7%|6         |11377/173481[03:10<45:54,58.85it/s] 12%|#1        |19977/173481[06:00<46:16,55.29it/s] 12%|#1        |20623/173481[06:10<46:04,55.29it/s] 18%|#7        |30536/173481[09:00<41:51,56.92it/s] 18%|#7        |31142/173481[09:10<41:40,56.92it/s] 23%|##2       |39573/173481[12:00<41:50,53.35it/s] 23%|##3       |40146/173481[12:10<41:39,53.35it/s] 28%|##8       |48579/173481[15:00<40:18,51.64it/s] 28%|##8       |49442/173481[15:11<40:02,51.64it/s] 34%|###3      |58859/173481[18:00<35:13,54.23it/s] 34%|###4      |59497/173481[18:11<35:01,54.23it/s] 40%|###9      |68678/173481[21:00<32:06,54.39it/s] 40%|###9      |69379/173481[21:11<31:54,54.39it/s] 45%|####5     |78760/173481[24:00<28:36,55.19it/s] 46%|####5     |79369/173481[24:11<28:25,55.19it/s] 51%|#####1    |88781/173481[27:00<25:28,55.42it/s] 52%|#####1    |89525/173481[27:12<25:14,55.42it/s] 57%|#####7    |98952/173481[30:00<22:11,55.96it/s] 57%|#####7    |99692/173481[30:12<21:58,55.96it/s] 63%|######2   |108919/173481[33:00<19:19,55.66it/s] 63%|######3   |109750/173481[33:12<19:04,55.66it/s] 69%|######8   |118924/173481[36:00<16:20,55.62it/s] 69%|######8   |119635/173481[36:12<16:08,55.62it/s] 74%|#######4  |128912/173481[39:00<13:22,55.55it/s] 75%|#######4  |129565/173481[39:12<13:10,55.55it/s] 80%|#######9  |138737/173481[42:00<10:30,55.06it/s] 80%|########  |139581/173481[42:13<10:15,55.06it/s] 86%|########5 |148895/173481[45:00<07:21,55.74it/s] 86%|########6 |149530/173481[45:13<07:09,55.74it/s] 92%|#########1|158952/173481[48:00<04:20,55.80it/s] 92%|#########2|159725/173481[48:13<04:06,55.80it/s] 97%|#########7|169125/173481[51:00<01:17,56.15it/s] 98%|#########7|169904/173481[51:13<01:03,56.15it/s]100%|##########|173481/173481[52:16<00:00,55.32it/s]
[32m[0325 00:25:38 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:3136.14 sec.
[32m[0325 00:25:39 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-8153607.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:31<00:00,205.91it/s]
46
[32m[0325 00:27:10 @monitor.py:363][0m QueueInput/queue_size: 0.084426
[32m[0325 00:27:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.972
[32m[0325 00:27:10 @monitor.py:363][0m activation-summaries/output-rms: 0.041179
[32m[0325 00:27:10 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0325 00:27:10 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58227
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 00:27:10 @monitor.py:363][0m train-error-top1: 0.43184
[32m[0325 00:27:10 @monitor.py:363][0m val-error-top1: 0.43234
[32m[0325 00:27:10 @monitor.py:363][0m val-utt-error: 0.099139
[32m[0325 00:27:10 @monitor.py:363][0m validation_cost: 1.6189
[32m[0325 00:27:10 @monitor.py:363][0m wd_cost: 3.0548e-11
[32m[0325 00:27:10 @group.py:42][0m Callbacks took 91.638 sec in total. InferenceRunner: 91.419sec
[32m[0325 00:27:10 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10865/173481[03:00<44:54,60.36it/s]  7%|6         |11463/173481[03:10<44:44,60.36it/s] 12%|#2        |21622/173481[06:00<42:08,60.06it/s] 13%|#2        |22203/173481[06:10<41:58,60.06it/s] 18%|#7        |30886/173481[09:00<42:52,55.43it/s] 18%|#8        |31474/173481[09:10<42:41,55.43it/s] 23%|##3       |40666/173481[12:00<40:20,54.88it/s] 24%|##3       |41243/173481[12:10<40:09,54.88it/s] 29%|##9       |50344/173481[15:00<37:47,54.31it/s] 29%|##9       |50953/173481[15:10<37:35,54.31it/s] 35%|###4      |60589/173481[18:00<33:51,55.58it/s] 35%|###5      |61233/173481[18:11<33:39,55.58it/s] 41%|####1     |71504/173481[21:00<29:18,57.99it/s] 42%|####1     |72207/173481[21:11<29:06,57.99it/s] 48%|####7     |82510/173481[24:00<25:28,59.53it/s] 48%|####7     |83220/173481[24:11<25:16,59.53it/s] 54%|#####3    |93526/173481[27:00<22:04,60.35it/s] 54%|#####4    |94191/173481[27:11<21:53,60.35it/s] 60%|######    |104513/173481[30:00<18:56,60.69it/s] 61%|######    |105211/173481[30:11<18:44,60.69it/s] 67%|######6   |115747/173481[33:00<15:38,61.54it/s] 67%|######7   |116453/173481[33:11<15:26,61.54it/s] 73%|#######3  |126679/173481[36:00<12:45,61.13it/s] 73%|#######3  |127454/173481[36:12<12:32,61.13it/s] 80%|#######9  |137984/173481[39:00<09:32,61.95it/s] 80%|#######9  |138744/173481[39:12<09:20,61.95it/s] 86%|########6 |149226/173481[42:00<06:29,62.20it/s] 86%|########6 |149914/173481[42:12<06:18,62.20it/s] 92%|#########2|160110/173481[45:00<03:38,61.32it/s] 93%|#########2|160707/173481[45:12<03:28,61.32it/s] 98%|#########8|170614/173481[48:00<00:47,59.80it/s] 99%|#########8|171329/173481[48:12<00:35,59.80it/s][32m[0325 01:15:59 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:2928.91 sec.
100%|##########|173481/173481[48:48<00:00,59.23it/s]
[32m[0325 01:15:59 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-8327088.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.09it/s]
47
[32m[0325 01:18:25 @monitor.py:363][0m QueueInput/queue_size: 30.824
[32m[0325 01:18:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.793
[32m[0325 01:18:25 @monitor.py:363][0m activation-summaries/output-rms: 0.04102
[32m[0325 01:18:25 @monitor.py:363][0m cross_entropy_loss: 1.5655
[32m[0325 01:18:25 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58227
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 01:18:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 01:18:25 @monitor.py:363][0m train-error-top1: 0.42767
[32m[0325 01:18:25 @monitor.py:363][0m val-error-top1: 0.43161
[32m[0325 01:18:25 @monitor.py:363][0m val-utt-error: 0.10041
[32m[0325 01:18:25 @monitor.py:363][0m validation_cost: 1.6186
[32m[0325 01:18:25 @monitor.py:363][0m wd_cost: 6.1095e-12
[32m[0325 01:18:25 @group.py:42][0m Callbacks took 146.172 sec in total. InferenceRunner: 145.847sec
[32m[0325 01:18:25 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10870/173481[03:00<44:52,60.39it/s]  7%|6         |11332/173481[03:10<44:45,60.39it/s] 12%|#1        |20672/173481[06:00<44:28,57.27it/s] 12%|#2        |21216/173481[06:10<44:18,57.27it/s] 18%|#7        |30747/173481[09:00<42:01,56.61it/s] 18%|#8        |31495/173481[09:10<41:48,56.61it/s] 24%|##4       |42031/173481[12:00<36:49,59.49it/s] 25%|##4       |42713/173481[12:10<36:37,59.49it/s] 31%|###       |53007/173481[15:00<33:20,60.23it/s] 31%|###1      |53950/173481[15:11<33:04,60.23it/s] 37%|###6      |63371/173481[18:00<31:10,58.87it/s] 37%|###6      |64032/173481[18:11<30:59,58.87it/s] 42%|####2     |73614/173481[21:00<28:45,57.86it/s] 43%|####2     |74427/173481[21:11<28:31,57.86it/s] 48%|####8     |84049/173481[24:00<25:44,57.91it/s] 49%|####8     |84689/173481[24:11<25:33,57.91it/s] 54%|#####4    |94278/173481[27:00<23:00,57.36it/s] 55%|#####4    |94994/173481[27:11<22:48,57.36it/s] 61%|######    |104973/173481[30:00<19:33,58.37it/s] 61%|######    |105591/173481[30:12<19:23,58.37it/s] 67%|######6   |115460/173481[33:00<16:35,58.31it/s] 67%|######6   |116169/173481[33:12<16:22,58.31it/s] 73%|#######2  |125923/173481[36:00<13:36,58.21it/s] 73%|#######2  |126619/173481[36:12<13:25,58.21it/s] 79%|#######8  |136312/173481[39:00<10:41,57.96it/s] 79%|#######9  |137058/173481[39:12<10:28,57.96it/s] 85%|########4 |146882/173481[42:00<07:35,58.34it/s] 85%|########5 |147574/173481[42:12<07:24,58.34it/s] 91%|######### |157224/173481[45:00<04:40,57.89it/s] 91%|#########1|157981/173481[45:12<04:27,57.89it/s] 97%|#########6|167476/173481[48:00<01:44,57.42it/s] 97%|#########6|168177/173481[48:13<01:32,57.42it/s]100%|##########|173481/173481[49:51<00:00,57.98it/s]
[32m[0325 02:08:17 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:2991.94 sec.
[32m[0325 02:08:17 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-8500569.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:30<00:00,124.68it/s]
48
[32m[0325 02:10:48 @monitor.py:363][0m QueueInput/queue_size: 1.6151
[32m[0325 02:10:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.76
[32m[0325 02:10:48 @monitor.py:363][0m activation-summaries/output-rms: 0.040877
[32m[0325 02:10:48 @monitor.py:363][0m cross_entropy_loss: 1.5884
[32m[0325 02:10:48 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 02:10:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 02:10:48 @monitor.py:363][0m train-error-top1: 0.42817
[32m[0325 02:10:48 @monitor.py:363][0m val-error-top1: 0.43207
[32m[0325 02:10:48 @monitor.py:363][0m val-utt-error: 0.099989
[32m[0325 02:10:48 @monitor.py:363][0m validation_cost: 1.6196
[32m[0325 02:10:48 @monitor.py:363][0m wd_cost: 6.1095e-12
[32m[0325 02:10:48 @group.py:42][0m Callbacks took 151.267 sec in total. InferenceRunner: 150.977sec
[32m[0325 02:10:48 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11208/173481[03:00<43:26,62.27it/s]  7%|6         |11789/173481[03:10<43:16,62.27it/s] 12%|#2        |21485/173481[06:00<42:31,59.57it/s] 13%|#2        |22013/173481[06:10<42:22,59.57it/s] 18%|#7        |31225/173481[09:00<41:48,56.71it/s] 18%|#8        |31831/173481[09:10<41:37,56.71it/s] 24%|##3       |41503/173481[12:00<38:39,56.90it/s] 24%|##4       |42128/173481[12:10<38:28,56.90it/s] 30%|##9       |51956/173481[15:00<35:14,57.48it/s] 30%|###       |52556/173481[15:10<35:03,57.48it/s] 36%|###5      |62060/173481[18:00<32:41,56.80it/s] 36%|###6      |62669/173481[18:11<32:31,56.80it/s] 42%|####1     |72171/173481[21:00<29:53,56.48it/s] 42%|####1     |72821/173481[21:11<29:42,56.48it/s] 47%|####7     |82277/173481[24:00<26:59,56.31it/s] 48%|####7     |82886/173481[24:11<26:48,56.31it/s] 53%|#####3    |92318/173481[27:00<24:08,56.04it/s] 54%|#####3    |92918/173481[27:11<23:57,56.04it/s] 59%|#####8    |102157/173481[30:00<21:28,55.34it/s] 59%|#####9    |102751/173481[30:11<21:18,55.34it/s] 65%|######4   |112123/173481[33:00<18:28,55.35it/s] 65%|######5   |112818/173481[33:11<18:15,55.35it/s] 71%|#######   |122536/173481[36:00<15:00,56.57it/s] 71%|#######1  |123242/173481[36:12<14:48,56.57it/s] 77%|#######6  |132774/173481[39:00<11:57,56.72it/s] 77%|#######6  |133516/173481[39:12<11:44,56.72it/s] 83%|########2 |143590/173481[42:00<08:32,58.35it/s] 83%|########3 |144347/173481[42:12<08:19,58.35it/s] 89%|########9 |155109/173481[45:00<05:00,61.04it/s] 90%|########9 |155921/173481[45:12<04:47,61.04it/s] 96%|#########5|165837/173481[48:00<02:06,60.31it/s] 96%|#########5|166526/173481[48:12<01:55,60.31it/s]100%|##########|173481/173481[50:13<00:00,57.57it/s]
[32m[0325 03:01:02 @base.py:257][0m Epoch 51 (global_step 8674050) finished, time:3013.64 sec.
[32m[0325 03:01:02 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-8674050.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:39<00:00,118.00it/s]
49
[32m[0325 03:03:42 @monitor.py:363][0m QueueInput/queue_size: 13.011
[32m[0325 03:03:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.829
[32m[0325 03:03:42 @monitor.py:363][0m activation-summaries/output-rms: 0.042382
[32m[0325 03:03:42 @monitor.py:363][0m cross_entropy_loss: 1.5828
[32m[0325 03:03:42 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 03:03:42 @monitor.py:363][0m train-error-top1: 0.42347
[32m[0325 03:03:42 @monitor.py:363][0m val-error-top1: 0.4331
[32m[0325 03:03:42 @monitor.py:363][0m val-utt-error: 0.10026
[32m[0325 03:03:42 @monitor.py:363][0m validation_cost: 1.6233
[32m[0325 03:03:42 @monitor.py:363][0m wd_cost: 1.2219e-12
[32m[0325 03:03:42 @group.py:42][0m Callbacks took 159.774 sec in total. InferenceRunner: 159.541sec
[32m[0325 03:03:42 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11552/173481[03:00<42:03,64.18it/s]  7%|7         |12163/173481[03:10<41:53,64.18it/s] 13%|#3        |23157/173481[06:00<38:57,64.32it/s] 14%|#3        |23829/173481[06:10<38:46,64.32it/s] 20%|##        |35041/173481[09:00<35:24,65.16it/s] 21%|##        |35748/173481[09:10<35:13,65.16it/s] 27%|##6       |46823/173481[12:00<32:19,65.30it/s] 27%|##7       |47509/173481[12:10<32:09,65.30it/s] 34%|###3      |58655/173481[15:00<29:12,65.52it/s] 34%|###4      |59365/173481[15:10<29:01,65.52it/s] 40%|####      |69926/173481[18:00<26:57,64.03it/s] 41%|####      |70575/173481[18:11<26:47,64.03it/s] 46%|####6     |80424/173481[21:00<25:24,61.04it/s] 47%|####6     |81050/173481[21:11<25:14,61.04it/s] 52%|#####2    |90886/173481[24:00<23:07,59.55it/s] 53%|#####2    |91574/173481[24:11<22:55,59.55it/s] 59%|#####8    |101590/173481[27:00<20:08,59.51it/s] 59%|#####8    |102235/173481[27:11<19:57,59.51it/s] 65%|######4   |112202/173481[30:00<17:14,59.23it/s] 65%|######5   |112870/173481[30:11<17:03,59.23it/s] 71%|#######   |122611/173481[33:00<14:29,58.52it/s] 71%|#######1  |123267/173481[33:11<14:18,58.52it/s] 77%|#######6  |133217/173481[36:00<11:25,58.72it/s] 77%|#######7  |133951/173481[36:11<11:13,58.72it/s] 83%|########2 |143904/173481[39:00<08:20,59.04it/s] 83%|########3 |144683/173481[39:12<08:07,59.04it/s] 89%|########9 |154485/173481[42:00<05:22,58.91it/s] 89%|########9 |155177/173481[42:12<05:10,58.91it/s] 95%|#########5|164863/173481[45:00<02:27,58.28it/s] 95%|#########5|165554/173481[45:12<02:16,58.28it/s]100%|##########|173481/173481[47:26<00:00,60.95it/s]
[32m[0325 03:51:08 @base.py:257][0m Epoch 52 (global_step 8847531) finished, time:2846.20 sec.
[32m[0325 03:51:08 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-8847531.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,109.10it/s]
50
[32m[0325 03:54:01 @monitor.py:363][0m QueueInput/queue_size: 0.95949
[32m[0325 03:54:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.795
[32m[0325 03:54:01 @monitor.py:363][0m activation-summaries/output-rms: 0.040903
[32m[0325 03:54:01 @monitor.py:363][0m cross_entropy_loss: 1.5902
[32m[0325 03:54:01 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 03:54:01 @monitor.py:363][0m train-error-top1: 0.4224
[32m[0325 03:54:01 @monitor.py:363][0m val-error-top1: 0.43232
[32m[0325 03:54:01 @monitor.py:363][0m val-utt-error: 0.10132
[32m[0325 03:54:01 @monitor.py:363][0m validation_cost: 1.622
[32m[0325 03:54:01 @monitor.py:363][0m wd_cost: 1.2219e-12
[32m[0325 03:54:01 @group.py:42][0m Callbacks took 172.784 sec in total. InferenceRunner: 172.542sec
[32m[0325 03:54:01 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10554/173481[03:00<46:18,58.63it/s]  6%|6         |11111/173481[03:10<46:09,58.63it/s] 12%|#2        |21325/173481[06:00<42:48,59.23it/s] 13%|#2        |21988/173481[06:10<42:37,59.23it/s] 19%|#8        |32818/173481[09:00<38:09,61.45it/s] 19%|#9        |33551/173481[09:10<37:57,61.45it/s] 25%|##5       |44190/173481[12:00<34:35,62.30it/s] 26%|##5       |44825/173481[12:10<34:25,62.30it/s] 32%|###1      |55366/173481[15:00<31:39,62.19it/s] 32%|###2      |56028/173481[15:10<31:28,62.19it/s] 38%|###8      |65974/173481[18:00<29:36,60.52it/s] 38%|###8      |66621/173481[18:11<29:25,60.52it/s] 44%|####4     |76620/173481[21:00<26:59,59.82it/s] 45%|####4     |77271/173481[21:11<26:48,59.82it/s] 50%|#####     |87103/173481[24:00<24:23,59.02it/s] 51%|#####     |87784/173481[24:11<24:12,59.02it/s] 56%|#####6    |97836/173481[27:00<21:15,59.32it/s] 57%|#####6    |98500/173481[27:11<21:03,59.32it/s] 63%|######2   |108526/173481[30:00<18:14,59.35it/s] 63%|######2   |109193/173481[30:11<18:03,59.35it/s] 69%|######8   |119124/173481[33:00<15:19,59.11it/s] 69%|######9   |119821/173481[33:11<15:07,59.11it/s] 75%|#######4  |129513/173481[36:00<12:32,58.40it/s] 75%|#######5  |130199/173481[36:12<12:21,58.40it/s] 81%|########  |139952/173481[39:00<09:36,58.20it/s] 81%|########1 |140708/173481[39:12<09:23,58.20it/s] 87%|########6 |150731/173481[42:00<06:25,59.03it/s] 87%|########7 |151480/173481[42:12<06:12,59.03it/s] 93%|#########3|161590/173481[45:00<03:19,59.66it/s] 94%|#########3|162264/173481[45:12<03:08,59.66it/s] 99%|#########9|172107/173481[48:00<00:23,59.03it/s]100%|#########9|172791/173481[48:12<00:11,59.03it/s]100%|##########|173481/173481[48:24<00:00,59.72it/s]
[32m[0325 04:42:26 @base.py:257][0m Epoch 53 (global_step 9021012) finished, time:2905.02 sec.
[32m[0325 04:42:26 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-9021012.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:54<00:00,107.94it/s]
51
[32m[0325 04:45:20 @monitor.py:363][0m QueueInput/queue_size: 1.3195
[32m[0325 04:45:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.97
[32m[0325 04:45:20 @monitor.py:363][0m activation-summaries/output-rms: 0.041179
[32m[0325 04:45:20 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0325 04:45:20 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 04:45:20 @monitor.py:363][0m train-error-top1: 0.43151
[32m[0325 04:45:20 @monitor.py:363][0m val-error-top1: 0.43234
[32m[0325 04:45:20 @monitor.py:363][0m val-utt-error: 0.099086
[32m[0325 04:45:20 @monitor.py:363][0m validation_cost: 1.6189
[32m[0325 04:45:20 @monitor.py:363][0m wd_cost: 1.2219e-12
[32m[0325 04:45:20 @group.py:42][0m Callbacks took 174.602 sec in total. InferenceRunner: 174.388sec
[32m[0325 04:45:20 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11017/173481[03:00<44:14,61.20it/s]  7%|6         |11658/173481[03:10<44:04,61.20it/s] 13%|#2        |22477/173481[06:00<40:19,62.41it/s] 13%|#3        |23150/173481[06:10<40:08,62.41it/s] 19%|#9        |33640/173481[09:00<37:27,62.21it/s] 20%|#9        |34306/173481[09:10<37:17,62.21it/s] 26%|##5       |44545/173481[12:00<35:00,61.39it/s] 26%|##6       |45219/173481[12:10<34:49,61.39it/s] 32%|###1      |55042/173481[15:00<33:00,59.81it/s] 32%|###2      |55617/173481[15:10<32:50,59.81it/s] 38%|###7      |65863/173481[18:00<29:54,59.96it/s] 38%|###8      |66553/173481[18:11<29:43,59.96it/s] 44%|####3     |76330/173481[21:00<27:25,59.04it/s] 44%|####4     |77037/173481[21:11<27:13,59.04it/s] 50%|#####     |87122/173481[24:00<24:11,59.49it/s] 51%|#####     |87843/173481[24:11<23:59,59.49it/s] 56%|#####6    |97720/173481[27:00<21:20,59.18it/s] 57%|#####6    |98308/173481[27:11<21:10,59.18it/s] 63%|######2   |108480/173481[30:00<18:12,59.47it/s] 63%|######2   |109171/173481[30:11<18:01,59.47it/s] 69%|######8   |119141/173481[33:00<15:15,59.35it/s] 69%|######9   |119891/173481[33:11<15:02,59.35it/s] 75%|#######4  |129616/173481[36:00<12:26,58.76it/s] 75%|#######5  |130327/173481[36:12<12:14,58.76it/s] 81%|########1 |140655/173481[39:00<09:06,60.02it/s] 81%|########1 |141347/173481[39:12<08:55,60.02it/s] 87%|########7 |151200/173481[42:00<06:15,59.29it/s] 88%|########7 |151966/173481[42:12<06:02,59.29it/s] 94%|#########3|162620/173481[45:00<02:57,61.30it/s] 94%|#########4|163305/173481[45:12<02:46,61.30it/s]100%|##########|173481/173481[47:44<00:00,60.56it/s]
[32m[0325 05:33:05 @base.py:257][0m Epoch 54 (global_step 9194493) finished, time:2864.65 sec.
[32m[0325 05:33:05 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-9194493.
  0%|          |0/18822[00:00<?,?it/s] 81%|########  |15201/18822[03:00<00:42,84.44it/s] 83%|########3 |15699/18822[03:10<00:36,84.44it/s]100%|##########|18822/18822[04:13<00:00,74.34it/s]
52
[32m[0325 05:37:19 @monitor.py:363][0m QueueInput/queue_size: 49.889
[32m[0325 05:37:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.888
[32m[0325 05:37:19 @monitor.py:363][0m activation-summaries/output-rms: 0.041084
[32m[0325 05:37:19 @monitor.py:363][0m cross_entropy_loss: 1.5653
[32m[0325 05:37:19 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 05:37:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 05:37:19 @monitor.py:363][0m train-error-top1: 0.42769
[32m[0325 05:37:19 @monitor.py:363][0m val-error-top1: 0.4319
[32m[0325 05:37:19 @monitor.py:363][0m val-utt-error: 0.1002
[32m[0325 05:37:19 @monitor.py:363][0m validation_cost: 1.6199
[32m[0325 05:37:19 @monitor.py:363][0m wd_cost: 2.4438e-13
[32m[0325 05:37:19 @group.py:42][0m Callbacks took 253.516 sec in total. InferenceRunner: 253.224sec
[32m[0325 05:37:19 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11263/173481[03:00<43:12,62.57it/s]  7%|6         |11867/173481[03:10<43:02,62.57it/s] 13%|#2        |22445/173481[06:00<40:22,62.34it/s] 13%|#3        |23025/173481[06:10<40:13,62.34it/s] 18%|#8        |32026/173481[09:00<41:03,57.42it/s] 19%|#8        |32636/173481[09:10<40:52,57.42it/s] 24%|##4       |41838/173481[12:00<39:13,55.93it/s] 24%|##4       |42495/173481[12:10<39:02,55.93it/s] 30%|###       |52582/173481[15:00<34:53,57.75it/s] 31%|###       |53285/173481[15:10<34:41,57.75it/s] 37%|###6      |63606/173481[18:00<30:48,59.44it/s] 37%|###7      |64211/173481[18:11<30:38,59.44it/s] 43%|####3     |74682/173481[21:00<27:13,60.47it/s] 43%|####3     |75349/173481[21:11<27:02,60.47it/s] 49%|####9     |85528/173481[24:00<24:17,60.36it/s] 50%|####9     |86237/173481[24:11<24:05,60.36it/s] 56%|#####5    |96430/173481[27:00<21:14,60.46it/s] 56%|#####6    |97177/173481[27:11<21:02,60.46it/s] 61%|######1   |106466/173481[30:00<19:15,58.01it/s] 62%|######1   |107157/173481[30:11<19:03,58.01it/s] 67%|######7   |116710/173481[33:00<16:28,57.46it/s] 68%|######7   |117408/173481[33:12<16:15,57.46it/s] 73%|#######2  |126503/173481[36:00<14:00,55.89it/s] 73%|#######3  |127101/173481[36:12<13:49,55.89it/s] 78%|#######8  |135955/173481[39:00<11:33,54.15it/s] 79%|#######8  |136551/173481[39:12<11:22,54.15it/s] 83%|########3 |144418/173481[42:00<09:37,50.33it/s] 84%|########3 |144993/173481[42:12<09:26,50.33it/s] 89%|########9 |154804/173481[45:00<05:47,53.76it/s] 90%|########9 |155822/173481[45:12<05:28,53.76it/s] 97%|#########7|168437/173481[48:00<01:20,62.88it/s] 98%|#########7|169406/173481[48:12<01:04,62.88it/s]100%|##########|173481/173481[49:09<00:00,58.81it/s]
[32m[0325 06:26:28 @base.py:257][0m Epoch 55 (global_step 9367974) finished, time:2949.84 sec.
[32m[0325 06:26:29 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-9367974.
  0%|          |0/18822[00:00<?,?it/s] 49%|####8     |9135/18822[03:00<03:10,50.75it/s] 51%|#####1    |9656/18822[03:10<03:00,50.75it/s]100%|##########|18822/18822[05:43<00:00,54.83it/s]
53
[32m[0325 06:32:12 @monitor.py:363][0m QueueInput/queue_size: 49.815
[32m[0325 06:32:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.993
[32m[0325 06:32:12 @monitor.py:363][0m activation-summaries/output-rms: 0.04125
[32m[0325 06:32:12 @monitor.py:363][0m cross_entropy_loss: 1.5709
[32m[0325 06:32:12 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 06:32:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 06:32:12 @monitor.py:363][0m train-error-top1: 0.42283
[32m[0325 06:32:12 @monitor.py:363][0m val-error-top1: 0.43157
[32m[0325 06:32:12 @monitor.py:363][0m val-utt-error: 0.098874
[32m[0325 06:32:12 @monitor.py:363][0m validation_cost: 1.6178
[32m[0325 06:32:12 @monitor.py:363][0m wd_cost: 2.4438e-13
[32m[0325 06:32:12 @group.py:42][0m Callbacks took 343.394 sec in total. InferenceRunner: 343.269sec
[32m[0325 06:32:12 @base.py:247][0m Start Epoch 56 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11283/173481[03:00<43:07,62.68it/s]  7%|6         |11925/173481[03:10<42:57,62.68it/s] 13%|#2        |22438/173481[06:00<40:23,62.32it/s] 13%|#3        |23081/173481[06:10<40:13,62.32it/s] 20%|#9        |33895/173481[09:00<36:56,62.98it/s] 20%|#9        |34664/173481[09:10<36:44,62.98it/s] 25%|##5       |43761/173481[12:00<36:53,58.61it/s] 26%|##5       |44329/173481[12:10<36:43,58.61it/s] 31%|###1      |54367/173481[15:00<33:46,58.77it/s] 32%|###1      |55011/173481[15:10<33:35,58.77it/s] 37%|###7      |64530/173481[18:00<31:31,57.59it/s] 38%|###7      |65092/173481[18:11<31:22,57.59it/s] 43%|####3     |74981/173481[21:00<28:23,57.82it/s] 44%|####3     |75621/173481[21:11<28:12,57.82it/s] 50%|####9     |85888/173481[24:00<24:40,59.17it/s] 50%|####9     |86636/173481[24:11<24:27,59.17it/s] 56%|#####5    |96733/173481[27:00<21:25,59.71it/s] 56%|#####6    |97375/173481[27:11<21:14,59.71it/s] 62%|######2   |107931/173481[30:00<17:55,60.93it/s] 63%|######2   |108640/173481[30:11<17:44,60.93it/s] 69%|######8   |119340/173481[33:00<14:31,62.13it/s] 69%|######9   |120060/173481[33:11<14:19,62.13it/s] 75%|#######5  |130348/173481[36:00<11:39,61.64it/s] 76%|#######5  |131111/173481[36:12<11:27,61.64it/s] 81%|########1 |141119/173481[39:00<08:52,60.72it/s] 82%|########1 |142002/173481[39:12<08:38,60.72it/s] 88%|########7 |152596/173481[42:00<05:35,62.21it/s] 88%|########8 |153479/173481[42:12<05:21,62.21it/s] 95%|#########4|164102/173481[45:00<02:28,63.05it/s] 95%|#########5|164846/173481[45:12<02:16,63.05it/s]100%|##########|173481/173481[47:13<00:00,61.23it/s]
[32m[0325 07:19:25 @base.py:257][0m Epoch 56 (global_step 9541455) finished, time:2833.27 sec.
[32m[0325 07:19:25 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-9541455.
  0%|          |0/18822[00:00<?,?it/s] 91%|######### |17035/18822[03:00<00:18,94.64it/s] 95%|#########4|17850/18822[03:10<00:10,94.64it/s]100%|##########|18822/18822[03:23<00:00,92.31it/s]
54
[32m[0325 07:22:49 @monitor.py:363][0m QueueInput/queue_size: 49.984
[32m[0325 07:22:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.936
[32m[0325 07:22:49 @monitor.py:363][0m activation-summaries/output-rms: 0.041763
[32m[0325 07:22:49 @monitor.py:363][0m cross_entropy_loss: 1.5898
[32m[0325 07:22:49 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 07:22:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 07:22:49 @monitor.py:363][0m train-error-top1: 0.42647
[32m[0325 07:22:49 @monitor.py:363][0m val-error-top1: 0.43236
[32m[0325 07:22:49 @monitor.py:363][0m val-utt-error: 0.10073
[32m[0325 07:22:49 @monitor.py:363][0m validation_cost: 1.62
[32m[0325 07:22:49 @monitor.py:363][0m wd_cost: 2.4438e-13
[32m[0325 07:22:49 @group.py:42][0m Callbacks took 204.041 sec in total. InferenceRunner: 203.913sec
[32m[0325 07:22:49 @base.py:247][0m Start Epoch 57 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11216/173481[03:00<43:24,62.31it/s]  7%|6         |11806/173481[03:10<43:14,62.31it/s] 13%|#2        |22396/173481[06:00<40:28,62.21it/s] 13%|#3        |23135/173481[06:10<40:16,62.21it/s] 20%|#9        |33907/173481[09:00<36:53,63.06it/s] 20%|#9        |34565/173481[09:10<36:42,63.06it/s] 25%|##5       |43440/173481[12:00<37:38,57.57it/s] 25%|##5       |43960/173481[12:10<37:29,57.57it/s] 30%|###       |52800/173481[15:00<36:48,54.64it/s] 31%|###       |53320/173481[15:10<36:39,54.64it/s] 36%|###5      |62356/173481[18:00<34:23,53.85it/s] 36%|###6      |62910/173481[18:11<34:13,53.85it/s] 41%|####1     |71750/173481[21:00<31:59,53.01it/s] 42%|####1     |72298/173481[21:11<31:48,53.01it/s] 47%|####6     |80938/173481[24:00<29:39,52.01it/s] 47%|####7     |81554/173481[24:11<29:27,52.01it/s] 52%|#####2    |90315/173481[27:00<26:37,52.05it/s] 52%|#####2    |90946/173481[27:11<26:25,52.05it/s] 57%|#####7    |99194/173481[30:00<24:26,50.65it/s] 58%|#####7    |99779/173481[30:11<24:15,50.65it/s] 63%|######2   |108452/173481[33:00<21:14,51.04it/s] 63%|######2   |109086/173481[33:11<21:01,51.04it/s] 68%|######7   |117891/173481[36:00<17:54,51.71it/s] 68%|######8   |118543/173481[36:12<17:42,51.71it/s] 73%|#######3  |127457/173481[39:00<14:38,52.42it/s] 74%|#######3  |128106/173481[39:12<14:25,52.42it/s] 79%|#######8  |136980/173481[42:00<11:33,52.66it/s] 79%|#######9  |137665/173481[42:12<11:20,52.66it/s] 84%|########4 |146578/173481[45:00<08:27,52.99it/s] 85%|########4 |147177/173481[45:12<08:16,52.99it/s] 90%|########9 |155711/173481[48:00<05:42,51.84it/s] 90%|######### |156318/173481[48:12<05:31,51.84it/s] 95%|#########5|164954/173481[51:00<02:45,51.59it/s] 95%|#########5|165600/173481[51:12<02:32,51.59it/s]100%|##########|173481/173481[53:45<00:00,53.79it/s]
[32m[0325 08:16:34 @base.py:257][0m Epoch 57 (global_step 9714936) finished, time:3225.31 sec.
[32m[0325 08:16:35 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-9714936.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:45<00:00,113.47it/s]
55
[32m[0325 08:19:21 @monitor.py:363][0m QueueInput/queue_size: 1.2208
[32m[0325 08:19:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.795
[32m[0325 08:19:21 @monitor.py:363][0m activation-summaries/output-rms: 0.040903
[32m[0325 08:19:21 @monitor.py:363][0m cross_entropy_loss: 1.5932
[32m[0325 08:19:21 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 08:19:21 @monitor.py:363][0m train-error-top1: 0.42284
[32m[0325 08:19:21 @monitor.py:363][0m val-error-top1: 0.43222
[32m[0325 08:19:21 @monitor.py:363][0m val-utt-error: 0.10116
[32m[0325 08:19:21 @monitor.py:363][0m validation_cost: 1.6219
[32m[0325 08:19:21 @monitor.py:363][0m wd_cost: 4.8876e-14
[32m[0325 08:19:21 @group.py:42][0m Callbacks took 166.196 sec in total. InferenceRunner: 165.900sec
[32m[0325 08:19:21 @base.py:247][0m Start Epoch 58 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9677/173481[03:00<50:47,53.76it/s]  6%|5         |10165/173481[03:10<50:37,53.76it/s] 11%|#1        |19090/173481[06:00<48:32,53.01it/s] 11%|#1        |19643/173481[06:10<48:22,53.01it/s] 16%|#6        |28451/173481[09:00<46:02,52.50it/s] 17%|#6        |29038/173481[09:10<45:51,52.50it/s] 22%|##1       |37397/173481[12:00<44:25,51.06it/s] 22%|##1       |37914/173481[12:10<44:15,51.06it/s] 27%|##6       |46370/173481[15:00<41:59,50.44it/s] 27%|##7       |46947/173481[15:10<41:48,50.44it/s] 32%|###2      |55661/173481[18:00<38:29,51.02it/s] 32%|###2      |56235/173481[18:11<38:17,51.02it/s] 37%|###7      |65055/173481[21:00<35:01,51.60it/s] 38%|###7      |65656/173481[21:11<34:49,51.60it/s] 43%|####3     |74688/173481[24:00<31:20,52.54it/s] 43%|####3     |75233/173481[24:11<31:10,52.54it/s] 48%|####8     |84082/173481[27:00<28:27,52.36it/s] 49%|####8     |84679/173481[27:11<28:15,52.36it/s] 54%|#####3    |93509/173481[30:00<25:27,52.36it/s] 54%|#####4    |94156/173481[30:11<25:14,52.36it/s] 59%|#####9    |102833/173481[33:00<22:36,52.08it/s] 60%|#####9    |103397/173481[33:11<22:25,52.08it/s] 64%|######4   |111787/173481[36:00<20:12,50.88it/s] 65%|######4   |112409/173481[36:12<20:00,50.88it/s] 70%|######9   |121084/173481[39:00<17:02,51.26it/s] 70%|#######   |121717/173481[39:12<16:49,51.26it/s] 75%|#######5  |130340/173481[42:00<14:00,51.33it/s] 75%|#######5  |130949/173481[42:12<13:48,51.33it/s] 81%|########  |139700/173481[45:00<10:53,51.66it/s] 81%|########  |140370/173481[45:12<10:40,51.66it/s] 86%|########6 |149209/173481[48:00<07:44,52.24it/s] 86%|########6 |149821/173481[48:12<07:32,52.24it/s] 91%|#########1|158547/173481[51:00<04:46,52.06it/s] 92%|#########1|159197/173481[51:12<04:34,52.06it/s] 97%|#########6|167714/173481[54:00<01:52,51.48it/s] 97%|#########7|168422/173481[54:13<01:38,51.48it/s]100%|##########|173481/173481[55:52<00:00,51.74it/s]
[32m[0325 09:15:14 @base.py:257][0m Epoch 58 (global_step 9888417) finished, time:3352.95 sec.
[32m[0325 09:15:14 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:46<00:00,113.37it/s]
56
[32m[0325 09:18:00 @monitor.py:363][0m QueueInput/queue_size: 0.52444
[32m[0325 09:18:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.969
[32m[0325 09:18:00 @monitor.py:363][0m activation-summaries/output-rms: 0.041179
[32m[0325 09:18:00 @monitor.py:363][0m cross_entropy_loss: 1.5918
[32m[0325 09:18:00 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 09:18:00 @monitor.py:363][0m train-error-top1: 0.4315
[32m[0325 09:18:00 @monitor.py:363][0m val-error-top1: 0.43234
[32m[0325 09:18:00 @monitor.py:363][0m val-utt-error: 0.099033
[32m[0325 09:18:00 @monitor.py:363][0m validation_cost: 1.6189
[32m[0325 09:18:00 @monitor.py:363][0m wd_cost: 4.8876e-14
[32m[0325 09:18:00 @group.py:42][0m Callbacks took 166.239 sec in total. InferenceRunner: 166.051sec
[32m[0325 09:18:00 @base.py:247][0m Start Epoch 59 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9941/173481[03:00<49:21,55.22it/s]  6%|6         |10434/173481[03:10<49:12,55.22it/s] 11%|#1        |19408/173481[06:00<47:39,53.87it/s] 12%|#1        |19983/173481[06:10<47:29,53.87it/s] 16%|#6        |28396/173481[09:00<46:39,51.83it/s] 17%|#6        |28928/173481[09:10<46:29,51.83it/s] 21%|##1       |37274/173481[12:00<44:54,50.54it/s] 22%|##1       |37775/173481[12:10<44:44,50.54it/s] 27%|##6       |46163/173481[15:00<42:28,49.96it/s] 27%|##6       |46678/173481[15:10<42:18,49.96it/s] 32%|###1      |54985/173481[18:00<39:54,49.48it/s] 32%|###1      |55483/173481[18:11<39:44,49.48it/s] 37%|###6      |63926/173481[21:00<36:49,49.57it/s] 37%|###7      |64509/173481[21:11<36:38,49.57it/s] 42%|####2     |73338/173481[24:00<32:47,50.89it/s] 43%|####2     |73966/173481[24:11<32:35,50.89it/s] 48%|####7     |83035/173481[27:00<28:48,52.34it/s] 48%|####8     |83661/173481[27:11<28:36,52.34it/s] 53%|#####3    |92562/173481[30:00<25:37,52.63it/s] 54%|#####3    |93196/173481[30:11<25:25,52.63it/s] 59%|#####8    |102009/173481[33:00<22:39,52.56it/s] 59%|#####9    |102668/173481[33:11<22:27,52.56it/s] 64%|######4   |111594/173481[36:00<19:29,52.90it/s] 65%|######4   |112221/173481[36:12<19:18,52.90it/s] 70%|######9   |120910/173481[39:00<16:44,52.32it/s] 70%|#######   |121534/173481[39:12<16:32,52.32it/s] 75%|#######5  |130322/173481[42:00<13:45,52.30it/s] 75%|#######5  |130938/173481[42:12<13:33,52.30it/s] 81%|########  |140075/173481[45:00<10:27,53.23it/s] 81%|########1 |140787/173481[45:12<10:14,53.23it/s] 86%|########6 |149999/173481[48:00<07:13,54.16it/s] 87%|########6 |150695/173481[48:12<07:00,54.16it/s] 92%|#########2|159847/173481[51:00<04:10,54.43it/s] 93%|#########2|160515/173481[51:12<03:58,54.43it/s] 98%|#########7|169811/173481[54:00<01:06,54.89it/s] 98%|#########8|170507/173481[54:13<00:54,54.89it/s]100%|##########|173481/173481[55:06<00:00,52.46it/s]
[32m[0325 10:13:07 @base.py:257][0m Epoch 59 (global_step 10061898) finished, time:3306.72 sec.
[32m[0325 10:13:07 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_False/model-10061898.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,109.31it/s]
57
[32m[0325 10:15:59 @monitor.py:363][0m QueueInput/queue_size: 1.2604
[32m[0325 10:15:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.809
[32m[0325 10:15:59 @monitor.py:363][0m activation-summaries/output-rms: 0.040718
[32m[0325 10:15:59 @monitor.py:363][0m cross_entropy_loss: 1.5814
[32m[0325 10:15:59 @monitor.py:363][0m lr: 4.7684e-10
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0325 10:15:59 @monitor.py:363][0m train-error-top1: 0.42932
[32m[0325 10:15:59 @monitor.py:363][0m val-error-top1: 0.43266
[32m[0325 10:15:59 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0325 10:15:59 @monitor.py:363][0m validation_cost: 1.6203
[32m[0325 10:15:59 @monitor.py:363][0m wd_cost: 4.8876e-14
[32m[0325 10:15:59 @group.py:42][0m Callbacks took 172.358 sec in total. InferenceRunner: 172.204sec
[32m[0325 10:15:59 @base.py:247][0m Start Epoch 60 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10253/173481[03:00<47:45,56.96it/s]  6%|6         |10803/173481[03:10<47:36,56.96it/s] 11%|#1        |19648/173481[06:00<47:04,54.47it/s] 12%|#1        |20175/173481[06:10<46:54,54.47it/s] 17%|#6        |29248/173481[09:00<44:36,53.89it/s] 17%|#7        |29794/173481[09:10<44:26,53.89it/s] 23%|##2       |39095/173481[12:00<41:15,54.30it/s] 23%|##2       |39707/173481[12:10<41:03,54.30it/s] 28%|##8       |49194/173481[15:00<37:32,55.19it/s] 29%|##8       |49873/173481[15:10<37:19,55.19it/s] 34%|###4      |59137/173481[18:00<34:31,55.21it/s] 34%|###4      |59798/173481[18:11<34:19,55.21it/s] 40%|###9      |69152/173481[21:00<31:22,55.42it/s] 40%|####      |69773/173481[21:11<31:11,55.42it/s] 46%|####5     |79224/173481[24:00<28:12,55.69it/s] 46%|####5     |79761/173481[24:11<28:02,55.69it/s] 51%|#####1    |88964/173481[27:00<25:39,54.89it/s] 52%|#####1    |89560/173481[27:11<25:29,54.89it/s]slurmstepd: *** STEP 82581.0 ON sls-titan-10 CANCELLED AT 2018-03-25T10:45:36 DUE TO TIME LIMIT ***
srun: error: sls-titan-10: task 0: Terminated
srun: Force Terminated job step 82581.0
