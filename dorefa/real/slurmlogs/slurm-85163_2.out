sls-sm-8 3
SLURM_JOBID=85165
SLURM_TASKID=2
[32m[0328 12:10:37 @logger.py:67][0m Existing log file 'train_log/lcn_w_4_a_4_quant_ends_True_preload/log.log' backuped to 'train_log/lcn_w_4_a_4_quant_ends_True_preload/log.log.0328-121037'
[32m[0328 12:10:37 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=4 --bita=4 --quant_ends=True --load_ckpt=train_log/lcn_w_4_a_32_quant_ends_False/checkpoint
[32m[0328 12:10:42 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 12:10:42 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 12:10:43 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 12:10:43 @drf_run.py:166][0m Using host: sls-sm-8
[32m[0328 12:10:43 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 12:10:43 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 12:10:43 @drf_run.py:188][0m Using GPU: 3
[32m[0328 12:10:43 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 12:10:43 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 12:10:43 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 12:10:43 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0a/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0a/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0b/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0b/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0c/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0c/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0d/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0d/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0e/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0e/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0f/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0f/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0g/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0g/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0h/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0h/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0i/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0i/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0j/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight conv0j/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0328 12:10:43 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 12:10:43 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 12:10:43 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 12:10:43 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 12:10:43 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 12:10:43 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 12:10:43 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 12:10:43 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 12:10:44 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 12:10:44 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0328 12:10:44 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 12:10:44 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0328 12:10:46 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0328 12:10:46 @base.py:196][0m Setup callbacks graph ...
[32m[0328 12:10:47 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0a/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0a/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0b/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0b/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0c/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0c/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0d/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0d/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0e/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0e/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0f/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0f/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0g/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0g/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0h/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0h/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0i/W
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0i/b
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0328 12:10:47 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0328 12:10:47 @drf_run.py:70][0m Quantizing weight conv0j/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight conv0j/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 12:10:48 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 12:10:48 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 12:10:48 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 12:10:48 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0328 12:10:48 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 12:10:48 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0328 12:10:50 @base.py:212][0m Creating the session ...
2018-03-28 12:10:51.130231: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-28 12:10:53.592158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:82:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-28 12:10:53.592248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:82:00.0, compute capability: 6.1)
[32m[0328 12:10:58 @base.py:220][0m Initializing the session ...
[32m[0328 12:10:58 @sessinit.py:116][0m Restoring checkpoint from train_log/lcn_w_4_a_32_quant_ends_False/model-9194493 ...
[32m[0328 12:10:59 @base.py:227][0m Graph Finalized.
[32m[0328 12:10:59 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 12:10:59 @steps.py:127][0m Start training with global_step=9194493
[32m[0328 12:11:02 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8395/173481[03:00<58:59,46.64it/s]  5%|5         |8889/173481[03:10<58:49,46.64it/s] 10%|9         |17114/173481[06:00<54:50,47.52it/s] 10%|#         |17609/173481[06:10<54:40,47.52it/s] 15%|#4        |25847/173481[09:00<51:14,48.01it/s] 15%|#5        |26368/173481[09:10<51:04,48.01it/s] 20%|#9        |34536/173481[12:00<48:06,48.14it/s] 20%|##        |35046/173481[12:10<47:55,48.14it/s] 25%|##4       |43228/173481[15:00<45:01,48.21it/s] 25%|##5       |43742/173481[15:10<44:50,48.21it/s] 30%|##9       |51971/173481[18:00<41:51,48.39it/s] 30%|###       |52496/173481[18:10<41:40,48.39it/s] 35%|###4      |60706/173481[21:00<38:47,48.46it/s] 35%|###5      |61234/173481[21:11<38:36,48.46it/s] 40%|####      |69431/173481[24:00<35:47,48.46it/s] 40%|####      |69971/173481[24:11<35:35,48.46it/s] 45%|####5     |78123/173481[27:00<32:51,48.37it/s] 45%|####5     |78658/173481[27:11<32:40,48.37it/s] 50%|#####     |86865/173481[30:00<29:47,48.47it/s] 50%|#####     |87421/173481[30:11<29:35,48.47it/s] 55%|#####5    |95610/173481[33:00<26:44,48.52it/s] 55%|#####5    |96153/173481[33:11<26:33,48.52it/s] 60%|######    |104345/173481[36:00<23:44,48.52it/s] 60%|######    |104916/173481[36:11<23:33,48.52it/s] 65%|######5   |113127/173481[39:00<20:40,48.66it/s] 66%|######5   |113686/173481[39:11<20:28,48.66it/s] 70%|#######   |121829/173481[42:00<17:45,48.50it/s] 71%|#######   |122414/173481[42:12<17:32,48.50it/s] 75%|#######5  |130548/173481[45:00<14:45,48.47it/s] 76%|#######5  |131146/173481[45:12<14:33,48.47it/s] 80%|########  |139352/173481[48:00<11:40,48.69it/s] 81%|########  |139952/173481[48:12<11:28,48.69it/s] 85%|########5 |148089/173481[51:00<08:42,48.61it/s] 86%|########5 |148663/173481[51:12<08:30,48.61it/s] 90%|######### |156743/173481[54:00<05:46,48.34it/s] 91%|######### |157350/173481[54:12<05:33,48.34it/s] 95%|#########5|165396/173481[57:00<02:47,48.20it/s] 96%|#########5|166012/173481[57:12<02:34,48.20it/s]100%|##########|173481/173481[59:51<00:00,48.31it/s]
[32m[0328 13:10:53 @base.py:257][0m Epoch 1 (global_step 9367974) finished, time:3591.02 sec.
[32m[0328 13:10:53 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-9367974.
  0%|          |0/18822[00:00<?,?it/s] 80%|#######9  |15043/18822[03:00<00:45,83.57it/s] 85%|########4 |15928/18822[03:10<00:34,83.57it/s]100%|##########|18822/18822[03:43<00:00,84.13it/s]
0
[32m[0328 13:14:37 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 13:14:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.783
[32m[0328 13:14:37 @monitor.py:363][0m activation-summaries/output-rms: 0.016022
[32m[0328 13:14:37 @monitor.py:363][0m cross_entropy_loss: 6.4372
[32m[0328 13:14:37 @monitor.py:363][0m lr: 1.9073e-09
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.6322e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2066e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8756e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.4336e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0274e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0085e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.2906e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7133e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.68e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4366e-06
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 13:14:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 13:14:37 @monitor.py:363][0m train-error-top1: 0.98544
[32m[0328 13:14:37 @monitor.py:363][0m val-error-top1: 0.9876
[32m[0328 13:14:37 @monitor.py:363][0m val-utt-error: 0.97248
[32m[0328 13:14:37 @monitor.py:363][0m validation_cost: 6.463
[32m[0328 13:14:37 @monitor.py:363][0m wd_cost: 3.0815e-13
[32m[0328 13:14:37 @group.py:42][0m Callbacks took 224.310 sec in total. InferenceRunner: 223.748sec
[32m[0328 13:14:37 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8940/173481[03:00<55:13,49.66it/s]  5%|5         |9417/173481[03:10<55:03,49.66it/s] 10%|#         |17580/173481[06:00<53:13,48.82it/s] 10%|#         |18079/173481[06:10<53:03,48.82it/s] 15%|#5        |26283/173481[09:00<50:30,48.58it/s] 15%|#5        |26792/173481[09:10<50:19,48.58it/s] 20%|##        |34954/173481[12:00<47:43,48.37it/s] 20%|##        |35475/173481[12:10<47:32,48.37it/s] 25%|##5       |43662/173481[15:00<44:43,48.37it/s] 25%|##5       |44171/173481[15:10<44:33,48.37it/s] 30%|###       |52325/173481[18:00<41:50,48.25it/s] 30%|###       |52853/173481[18:10<41:40,48.25it/s] 35%|###5      |61006/173481[21:00<38:51,48.24it/s] 35%|###5      |61545/173481[21:11<38:40,48.24it/s] 40%|####      |69636/173481[24:00<35:59,48.09it/s] 40%|####      |70177/173481[24:11<35:48,48.09it/s] 45%|####5     |78229/173481[27:00<33:08,47.91it/s] 45%|####5     |78766/173481[27:11<32:56,47.91it/s] 50%|#####     |86857/173481[30:00<30:07,47.92it/s] 50%|#####     |87387/173481[30:11<29:56,47.92it/s] 55%|#####5    |95447/173481[33:00<27:11,47.82it/s] 55%|#####5    |95993/173481[33:11<27:00,47.82it/s] 60%|######    |104090/173481[36:00<24:08,47.92it/s] 60%|######    |104641/173481[36:11<23:56,47.92it/s] 65%|######4   |112660/173481[39:00<21:13,47.76it/s] 65%|######5   |113227/173481[39:12<21:01,47.76it/s] 70%|######9   |121246/173481[42:00<18:14,47.73it/s] 70%|#######   |121830/173481[42:12<18:02,47.73it/s] 75%|#######4  |129842/173481[45:00<15:14,47.74it/s] 75%|#######5  |130435/173481[45:12<15:01,47.74it/s] 80%|#######9  |138398/173481[48:00<12:16,47.63it/s] 80%|########  |138990/173481[48:12<12:04,47.63it/s] 85%|########4 |146941/173481[51:00<09:18,47.55it/s] 85%|########5 |147546/173481[51:12<09:05,47.55it/s] 90%|########9 |155465/173481[54:00<06:19,47.45it/s] 90%|########9 |156079/173481[54:12<06:06,47.45it/s] 94%|#########4|163937/173481[57:00<03:21,47.26it/s] 95%|#########4|164546/173481[57:13<03:09,47.26it/s] 99%|#########9|172474/173481[1:00:00<00:21,47.34it/s]100%|#########9|173098/173481[1:00:13<00:08,47.34it/s]100%|##########|173481/173481[1:00:21<00:00,47.90it/s]
[32m[0328 14:14:59 @base.py:257][0m Epoch 2 (global_step 9541455) finished, time:3621.39 sec.
[32m[0328 14:14:59 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-9541455.
[32m[0328 14:14:59 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 75%|#######5  |14202/18822[03:00<00:58,78.89it/s] 80%|#######9  |15013/18822[03:10<00:48,78.89it/s]100%|##########|18822/18822[03:56<00:00,79.69it/s]
1
[32m[0328 14:18:55 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 14:18:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.833
[32m[0328 14:18:55 @monitor.py:363][0m activation-summaries/output-rms: 0.015791
[32m[0328 14:18:55 @monitor.py:363][0m cross_entropy_loss: 6.4124
[32m[0328 14:18:55 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.6857e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2284e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8985e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.4599e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.092e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0409e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3172e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7478e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6746e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4189e-06
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 14:18:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 14:18:55 @monitor.py:363][0m train-error-top1: 0.98952
[32m[0328 14:18:55 @monitor.py:363][0m val-error-top1: 0.98764
[32m[0328 14:18:55 @monitor.py:363][0m val-utt-error: 0.97158
[32m[0328 14:18:55 @monitor.py:363][0m validation_cost: 6.4612
[32m[0328 14:18:55 @monitor.py:363][0m wd_cost: 3.0815e-13
[32m[0328 14:18:55 @group.py:42][0m Callbacks took 236.656 sec in total. InferenceRunner: 236.219sec
[32m[0328 14:18:55 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8975/173481[03:00<54:59,49.86it/s]  5%|5         |9492/173481[03:10<54:48,49.86it/s] 10%|#         |17679/173481[06:00<52:53,49.09it/s] 10%|#         |18169/173481[06:10<52:43,49.09it/s] 15%|#5        |26342/173481[09:00<50:27,48.61it/s] 15%|#5        |26835/173481[09:10<50:17,48.61it/s] 20%|##        |34939/173481[12:00<47:55,48.18it/s] 20%|##        |35438/173481[12:10<47:45,48.18it/s] 25%|##5       |43558/173481[15:00<45:05,48.03it/s] 25%|##5       |44071/173481[15:10<44:54,48.03it/s] 30%|###       |52158/173481[18:00<42:12,47.90it/s] 30%|###       |52696/173481[18:10<42:01,47.90it/s] 35%|###5      |60817/173481[21:00<39:07,48.00it/s] 35%|###5      |61339/173481[21:11<38:56,48.00it/s] 40%|###9      |69392/173481[24:00<36:16,47.82it/s] 40%|####      |69917/173481[24:11<36:05,47.82it/s] 45%|####4     |77953/173481[27:00<33:23,47.69it/s] 45%|####5     |78481/173481[27:11<33:12,47.69it/s] 50%|####9     |86621/173481[30:00<30:12,47.92it/s] 50%|#####     |87175/173481[30:11<30:01,47.92it/s] 55%|#####4    |95250/173481[33:00<27:12,47.93it/s] 55%|#####5    |95801/173481[33:11<27:00,47.93it/s] 60%|#####9    |103881/173481[36:00<24:11,47.94it/s] 60%|######    |104443/173481[36:11<24:00,47.94it/s] 65%|######4   |112526/173481[39:00<21:10,47.98it/s] 65%|######5   |113092/173481[39:11<20:58,47.98it/s] 70%|######9   |121124/173481[42:00<18:13,47.87it/s] 70%|#######   |121690/173481[42:11<18:01,47.87it/s] 75%|#######4  |129715/173481[45:00<15:15,47.80it/s] 75%|#######5  |130291/173481[45:12<15:03,47.80it/s] 80%|#######9  |138285/173481[48:00<12:17,47.70it/s] 80%|########  |138864/173481[48:12<12:05,47.70it/s] 85%|########4 |146908/173481[51:00<09:15,47.80it/s] 85%|########5 |147502/173481[51:12<09:03,47.80it/s] 90%|########9 |155519/173481[54:00<06:15,47.82it/s] 90%|########9 |156096/173481[54:12<06:03,47.82it/s] 95%|#########4|164090/173481[57:00<03:16,47.72it/s] 95%|#########4|164690/173481[57:12<03:04,47.72it/s]100%|#########9|172683/173481[1:00:00<00:16,47.73it/s]100%|#########9|173276/173481[1:00:12<00:04,47.73it/s]100%|##########|173481/173481[1:00:17<00:00,47.96it/s]
[32m[0328 15:19:13 @base.py:257][0m Epoch 3 (global_step 9714936) finished, time:3617.19 sec.
[32m[0328 15:19:13 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-9714936.
  0%|          |0/18822[00:00<?,?it/s] 81%|########1 |15250/18822[03:00<00:42,84.72it/s] 86%|########5 |16107/18822[03:10<00:32,84.72it/s]100%|##########|18822/18822[03:43<00:00,84.10it/s]
2
[32m[0328 15:22:57 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 15:22:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.838
[32m[0328 15:22:57 @monitor.py:363][0m activation-summaries/output-rms: 0.015733
[32m[0328 15:22:57 @monitor.py:363][0m cross_entropy_loss: 6.4753
[32m[0328 15:22:57 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7066e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.226e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8867e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.4498e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0497e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0439e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3152e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7459e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6841e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4246e-06
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 15:22:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 15:22:57 @monitor.py:363][0m train-error-top1: 0.99038
[32m[0328 15:22:57 @monitor.py:363][0m val-error-top1: 0.98758
[32m[0328 15:22:57 @monitor.py:363][0m val-utt-error: 0.97094
[32m[0328 15:22:57 @monitor.py:363][0m validation_cost: 6.4533
[32m[0328 15:22:57 @monitor.py:363][0m wd_cost: 6.163e-14
[32m[0328 15:22:57 @group.py:42][0m Callbacks took 224.081 sec in total. InferenceRunner: 223.822sec
[32m[0328 15:22:57 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8808/173481[03:00<56:05,48.93it/s]  5%|5         |9322/173481[03:10<55:55,48.93it/s] 10%|#         |17847/173481[06:00<52:20,49.56it/s] 11%|#         |18358/173481[06:10<52:09,49.56it/s] 15%|#5        |26487/173481[09:00<50:14,48.77it/s] 16%|#5        |26994/173481[09:10<50:03,48.77it/s] 20%|##        |35129/173481[12:00<47:39,48.38it/s] 21%|##        |35631/173481[12:10<47:29,48.38it/s] 25%|##5       |43830/173481[15:00<44:40,48.36it/s] 26%|##5       |44348/173481[15:10<44:30,48.36it/s] 30%|###       |52458/173481[18:00<41:53,48.14it/s] 31%|###       |52985/173481[18:10<41:42,48.14it/s] 35%|###5      |61064/173481[21:00<39:03,47.97it/s] 35%|###5      |61585/173481[21:11<38:52,47.97it/s] 40%|####      |69719/173481[24:00<36:00,48.03it/s] 40%|####      |70258/173481[24:11<35:49,48.03it/s] 45%|####5     |78352/173481[27:00<33:02,47.99it/s] 45%|####5     |78881/173481[27:11<32:51,47.99it/s] 50%|#####     |86952/173481[30:00<30:07,47.88it/s] 50%|#####     |87504/173481[30:11<29:55,47.88it/s] 55%|#####5    |95616/173481[33:00<27:01,48.01it/s] 55%|#####5    |96162/173481[33:11<26:50,48.01it/s] 60%|######    |104219/173481[36:00<24:05,47.90it/s] 60%|######    |104778/173481[36:11<23:54,47.90it/s] 65%|######5   |112899/173481[39:00<21:00,48.06it/s] 65%|######5   |113483/173481[39:12<20:48,48.06it/s] 70%|#######   |121618/173481[42:00<17:54,48.25it/s] 70%|#######   |122196/173481[42:12<17:42,48.25it/s] 75%|#######5  |130300/173481[45:00<14:55,48.24it/s] 75%|#######5  |130883/173481[45:12<14:43,48.24it/s] 80%|########  |139002/173481[48:00<11:54,48.29it/s] 80%|########  |139593/173481[48:12<11:41,48.29it/s] 85%|########5 |147676/173481[51:00<08:54,48.24it/s] 85%|########5 |148302/173481[51:12<08:41,48.24it/s] 90%|######### |156387/173481[54:00<05:53,48.32it/s] 91%|######### |157001/173481[54:13<05:41,48.32it/s] 95%|#########5|165027/173481[57:00<02:55,48.16it/s] 95%|#########5|165648/173481[57:13<02:42,48.16it/s]100%|##########|173481/173481[59:55<00:00,48.25it/s]
[32m[0328 16:22:52 @base.py:257][0m Epoch 4 (global_step 9888417) finished, time:3595.79 sec.
[32m[0328 16:22:53 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-9888417.
[32m[0328 16:22:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 71%|#######1  |13430/18822[03:00<01:12,74.61it/s] 76%|#######5  |14219/18822[03:10<01:01,74.61it/s]100%|##########|18822/18822[04:13<00:00,74.35it/s]
3
[32m[0328 16:27:06 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 16:27:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.748
[32m[0328 16:27:06 @monitor.py:363][0m activation-summaries/output-rms: 0.015852
[32m[0328 16:27:06 @monitor.py:363][0m cross_entropy_loss: 6.4253
[32m[0328 16:27:06 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.6968e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2233e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8791e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.4623e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0425e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.04e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3437e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7443e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.7024e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4556e-06
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 16:27:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 16:27:06 @monitor.py:363][0m train-error-top1: 0.98426
[32m[0328 16:27:06 @monitor.py:363][0m val-error-top1: 0.98748
[32m[0328 16:27:06 @monitor.py:363][0m val-utt-error: 0.96966
[32m[0328 16:27:06 @monitor.py:363][0m validation_cost: 6.4527
[32m[0328 16:27:06 @monitor.py:363][0m wd_cost: 6.163e-14
[32m[0328 16:27:06 @group.py:42][0m Callbacks took 253.774 sec in total. InferenceRunner: 253.156sec
[32m[0328 16:27:06 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8627/173481[03:00<57:20,47.92it/s]  5%|5         |9116/173481[03:10<57:09,47.92it/s] 10%|#         |17554/173481[06:00<53:18,48.74it/s] 10%|#         |18062/173481[06:10<53:08,48.74it/s] 15%|#5        |26566/173481[09:00<49:34,49.39it/s] 16%|#5        |27081/173481[09:10<49:23,49.39it/s] 20%|##        |35217/173481[12:00<47:18,48.72it/s] 21%|##        |35728/173481[12:10<47:07,48.72it/s] 25%|##5       |43910/173481[15:00<44:31,48.50it/s] 26%|##5       |44430/173481[15:10<44:20,48.50it/s] 30%|###       |52627/173481[18:00<41:33,48.46it/s] 31%|###       |53167/173481[18:10<41:22,48.46it/s] 35%|###5      |61322/173481[21:00<38:38,48.38it/s] 36%|###5      |61852/173481[21:11<38:27,48.38it/s] 40%|####      |69957/173481[24:00<35:48,48.18it/s] 41%|####      |70489/173481[24:11<35:37,48.18it/s] 45%|####5     |78641/173481[27:00<32:47,48.21it/s] 46%|####5     |79188/173481[27:11<32:35,48.21it/s] 50%|#####     |87364/173481[30:00<29:41,48.33it/s] 51%|#####     |87929/173481[30:11<29:30,48.33it/s] 55%|#####5    |96062/173481[33:00<26:42,48.33it/s] 56%|#####5    |96646/173481[33:11<26:29,48.33it/s] 60%|######    |104720/173481[36:00<23:46,48.21it/s] 61%|######    |105280/173481[36:11<23:34,48.21it/s] 65%|######5   |113358/173481[39:00<20:49,48.10it/s] 66%|######5   |113922/173481[39:11<20:38,48.10it/s] 70%|#######   |122040/173481[42:00<17:48,48.16it/s] 71%|#######   |122615/173481[42:12<17:36,48.16it/s] 75%|#######5  |130719/173481[45:00<14:47,48.19it/s] 76%|#######5  |131310/173481[45:12<14:35,48.19it/s] 80%|########  |139411/173481[48:00<11:46,48.24it/s] 81%|########  |140008/173481[48:12<11:33,48.24it/s] 85%|########5 |148019/173481[51:00<08:50,48.03it/s] 86%|########5 |148618/173481[51:12<08:37,48.03it/s] 90%|######### |156672/173481[54:00<05:49,48.05it/s] 91%|######### |157289/173481[54:12<05:36,48.05it/s] 95%|#########5|165335/173481[57:00<02:49,48.09it/s] 96%|#########5|165948/173481[57:12<02:36,48.09it/s]100%|##########|173481/173481[59:49<00:00,48.33it/s]
[32m[0328 17:26:55 @base.py:257][0m Epoch 5 (global_step 10061898) finished, time:3589.15 sec.
[32m[0328 17:26:56 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-10061898.
[32m[0328 17:26:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 71%|#######1  |13431/18822[03:00<01:12,74.61it/s] 75%|#######5  |14192/18822[03:10<01:02,74.61it/s]100%|##########|18822/18822[04:11<00:00,74.86it/s]
4
[32m[0328 17:31:07 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 17:31:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.801
[32m[0328 17:31:07 @monitor.py:363][0m activation-summaries/output-rms: 0.015692
[32m[0328 17:31:07 @monitor.py:363][0m cross_entropy_loss: 6.3857
[32m[0328 17:31:07 @monitor.py:363][0m lr: 4.7684e-10
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7344e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2404e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8716e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.4866e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.026e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0311e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3551e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7484e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.7094e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4797e-06
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 17:31:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 17:31:07 @monitor.py:363][0m train-error-top1: 0.98732
[32m[0328 17:31:07 @monitor.py:363][0m val-error-top1: 0.98733
[32m[0328 17:31:07 @monitor.py:363][0m val-utt-error: 0.96961
[32m[0328 17:31:07 @monitor.py:363][0m validation_cost: 6.4486
[32m[0328 17:31:07 @monitor.py:363][0m wd_cost: 6.163e-14
[32m[0328 17:31:07 @group.py:42][0m Callbacks took 251.837 sec in total. InferenceRunner: 251.471sec
[32m[0328 17:31:07 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8706/173481[03:00<56:46,48.36it/s]  5%|5         |9194/173481[03:10<56:36,48.36it/s] 10%|#         |17385/173481[06:00<53:52,48.29it/s] 10%|#         |17867/173481[06:10<53:42,48.29it/s] 15%|#5        |26295/173481[09:00<50:10,48.89it/s] 15%|#5        |26752/173481[09:10<50:01,48.89it/s] 20%|#9        |34673/173481[12:00<48:30,47.69it/s] 20%|##        |35172/173481[12:10<48:20,47.69it/s] 25%|##4       |43096/173481[15:00<46:00,47.23it/s] 25%|##5       |43604/173481[15:10<45:49,47.23it/s] 30%|##9       |51548/173481[18:00<43:09,47.09it/s] 30%|##9       |52034/173481[18:10<42:58,47.09it/s] 35%|###4      |59914/173481[21:00<40:27,46.78it/s] 35%|###4      |60441/173481[21:11<40:16,46.78it/s] 40%|###9      |68574/173481[24:00<36:51,47.43it/s] 40%|###9      |69108/173481[24:11<36:40,47.43it/s] 44%|####4     |77147/173481[27:00<33:46,47.53it/s] 45%|####4     |77638/173481[27:11<33:36,47.53it/s] 49%|####9     |85612/173481[30:00<30:58,47.28it/s] 50%|####9     |86165/173481[30:11<30:46,47.28it/s] 54%|#####4    |94155/173481[33:00<27:54,47.37it/s] 55%|#####4    |94712/173481[33:11<27:42,47.37it/s] 59%|#####9    |102604/173481[36:00<25:03,47.15it/s] 59%|#####9    |103164/173481[36:11<24:51,47.15it/s] 64%|######4   |111062/173481[39:00<22:06,47.07it/s] 64%|######4   |111606/173481[39:11<21:54,47.07it/s] 69%|######8   |119382/173481[42:00<19:19,46.64it/s] 69%|######9   |119974/173481[42:12<19:07,46.64it/s] 74%|#######3  |127895/173481[45:00<16:10,46.96it/s] 74%|#######4  |128472/173481[45:12<15:58,46.96it/s] 79%|#######8  |136453/173481[48:00<13:03,47.25it/s] 79%|#######8  |137034/173481[48:12<12:51,47.25it/s] 84%|########3 |145017/173481[51:00<10:00,47.41it/s] 84%|########3 |145610/173481[51:12<09:47,47.41it/s] 88%|########8 |153211/173481[54:00<07:16,46.45it/s] 89%|########8 |153785/173481[54:12<07:04,46.45it/s] 93%|#########3|161487/173481[57:00<04:19,46.21it/s] 93%|#########3|162065/173481[57:12<04:07,46.21it/s] 98%|#########7|169792/173481[1:00:00<01:19,46.17it/s] 98%|#########8|170374/173481[1:00:13<01:07,46.17it/s]100%|##########|173481/173481[1:01:19<00:00,47.15it/s]
[32m[0328 18:32:26 @base.py:257][0m Epoch 6 (global_step 10235379) finished, time:3679.27 sec.
[32m[0328 18:32:27 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-10235379.
[32m[0328 18:32:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 68%|######8   |12819/18822[03:00<01:24,71.22it/s] 72%|#######2  |13582/18822[03:10<01:13,71.22it/s]100%|##########|18822/18822[04:19<00:00,72.41it/s]
5
[32m[0328 18:36:47 @monitor.py:363][0m QueueInput/queue_size: 2.9927
[32m[0328 18:36:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.795
[32m[0328 18:36:47 @monitor.py:363][0m activation-summaries/output-rms: 0.015796
[32m[0328 18:36:47 @monitor.py:363][0m cross_entropy_loss: 6.4017
[32m[0328 18:36:47 @monitor.py:363][0m lr: 4.7684e-10
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7475e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2432e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8659e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.4884e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0472e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0274e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3518e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7447e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.7029e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.485e-06
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 18:36:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 18:36:47 @monitor.py:363][0m train-error-top1: 0.98795
[32m[0328 18:36:47 @monitor.py:363][0m val-error-top1: 0.98735
[32m[0328 18:36:47 @monitor.py:363][0m val-utt-error: 0.96956
[32m[0328 18:36:47 @monitor.py:363][0m validation_cost: 6.4341
[32m[0328 18:36:47 @monitor.py:363][0m wd_cost: 1.2326e-14
[32m[0328 18:36:47 @group.py:42][0m Callbacks took 260.615 sec in total. InferenceRunner: 259.958sec
[32m[0328 18:36:47 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8691/173481[03:00<56:53,48.28it/s]  5%|5         |9165/173481[03:10<56:43,48.28it/s] 10%|9         |16997/173481[06:00<55:16,47.19it/s] 10%|#         |17464/173481[06:10<55:06,47.19it/s] 15%|#4        |25305/173481[09:00<52:55,46.67it/s] 15%|#4        |25784/173481[09:10<52:45,46.67it/s] 19%|#9        |33505/173481[12:00<50:36,46.10it/s] 20%|#9        |33972/173481[12:10<50:26,46.10it/s] 24%|##3       |41185/173481[15:00<49:45,44.32it/s] 24%|##4       |41677/173481[15:10<49:34,44.32it/s] 28%|##8       |49259/173481[18:00<46:26,44.58it/s] 29%|##8       |49728/173481[18:10<46:15,44.58it/s] 33%|###3      |57440/173481[21:00<42:57,45.01it/s] 33%|###3      |57928/173481[21:11<42:47,45.01it/s] 38%|###7      |65581/173481[24:00<39:51,45.12it/s] 38%|###8      |66102/173481[24:11<39:40,45.12it/s] 43%|####2     |73950/173481[27:00<36:13,45.80it/s] 43%|####2     |74471/173481[27:11<36:02,45.80it/s] 47%|####7     |82352/173481[30:00<32:51,46.23it/s] 48%|####7     |82897/173481[30:11<32:39,46.23it/s] 52%|#####2    |90698/173481[33:00<29:48,46.30it/s] 53%|#####2    |91233/173481[33:11<29:36,46.30it/s] 57%|#####7    |99194/173481[36:00<26:29,46.74it/s] 58%|#####7    |99766/173481[36:11<26:17,46.74it/s] 62%|######2   |107574/173481[39:00<23:32,46.65it/s] 62%|######2   |108151/173481[39:11<23:20,46.65it/s] 67%|######6   |116079/173481[42:00<20:22,46.95it/s] 67%|######7   |116642/173481[42:12<20:10,46.95it/s] 72%|#######1  |124448/173481[45:00<17:29,46.72it/s] 72%|#######2  |125026/173481[45:12<17:17,46.72it/s] 77%|#######6  |132880/173481[48:00<14:27,46.78it/s] 77%|#######6  |133464/173481[48:12<14:15,46.78it/s] 82%|########1 |141549/173481[51:00<11:12,47.46it/s] 82%|########1 |142137/173481[51:12<11:00,47.46it/s] 87%|########6 |150165/173481[54:00<08:09,47.66it/s] 87%|########6 |150763/173481[54:12<07:56,47.66it/s] 92%|#########1|158762/173481[57:00<05:08,47.71it/s] 92%|#########1|159353/173481[57:12<04:56,47.71it/s] 96%|#########6|167331/173481[1:00:00<02:09,47.66it/s] 97%|#########6|167910/173481[1:00:13<01:56,47.66it/s]100%|##########|173481/173481[1:02:07<00:00,46.54it/s]
[32m[0328 19:38:55 @base.py:257][0m Epoch 7 (global_step 10408860) finished, time:3727.55 sec.
[32m[0328 19:38:55 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-10408860.
  0%|          |0/18822[00:00<?,?it/s] 71%|#######   |13320/18822[03:00<01:14,74.00it/s] 74%|#######4  |14000/18822[03:10<01:05,74.00it/s]100%|##########|18822/18822[04:13<00:00,74.22it/s]
6
[32m[0328 19:43:09 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 19:43:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.837
[32m[0328 19:43:09 @monitor.py:363][0m activation-summaries/output-rms: 0.015926
[32m[0328 19:43:09 @monitor.py:363][0m cross_entropy_loss: 6.4251
[32m[0328 19:43:09 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7149e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.25e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8643e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.4988e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0492e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0282e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3646e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7494e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.692e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.505e-06
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 19:43:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 19:43:09 @monitor.py:363][0m train-error-top1: 0.98728
[32m[0328 19:43:09 @monitor.py:363][0m val-error-top1: 0.98755
[32m[0328 19:43:09 @monitor.py:363][0m val-utt-error: 0.97094
[32m[0328 19:43:09 @monitor.py:363][0m validation_cost: 6.4463
[32m[0328 19:43:09 @monitor.py:363][0m wd_cost: 1.2326e-14
[32m[0328 19:43:09 @group.py:42][0m Callbacks took 253.899 sec in total. InferenceRunner: 253.600sec
[32m[0328 19:43:09 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8705/173481[03:00<56:47,48.36it/s]  5%|5         |9205/173481[03:10<56:37,48.36it/s] 10%|#         |17426/173481[06:00<53:44,48.40it/s] 10%|#         |17936/173481[06:10<53:33,48.40it/s] 15%|#5        |26339/173481[09:00<50:06,48.95it/s] 15%|#5        |26850/173481[09:10<49:55,48.95it/s] 20%|##        |35284/173481[12:00<46:42,49.32it/s] 21%|##        |35754/173481[12:10<46:32,49.32it/s] 25%|##5       |43886/173481[15:00<44:29,48.54it/s] 26%|##5       |44385/173481[15:10<44:19,48.54it/s] 30%|###       |52591/173481[18:00<41:35,48.45it/s] 31%|###       |53130/173481[18:10<41:24,48.45it/s] 35%|###5      |61366/173481[21:00<38:26,48.60it/s] 36%|###5      |61901/173481[21:11<38:15,48.60it/s] 40%|####      |70074/173481[24:00<35:32,48.49it/s] 41%|####      |70605/173481[24:11<35:21,48.49it/s] 45%|####5     |78823/173481[27:00<32:29,48.54it/s] 46%|####5     |79370/173481[27:11<32:18,48.54it/s] 50%|#####     |87550/173481[30:00<29:31,48.51it/s] 51%|#####     |88111/173481[30:11<29:19,48.51it/s] 56%|#####5    |96303/173481[33:00<26:29,48.57it/s] 56%|#####5    |96856/173481[33:11<26:17,48.57it/s] 61%|######    |105053/173481[36:00<23:28,48.59it/s] 61%|######    |105619/173481[36:11<23:16,48.59it/s] 66%|######5   |113828/173481[39:00<20:25,48.67it/s] 66%|######5   |114409/173481[39:11<20:13,48.67it/s] 71%|#######   |122568/173481[42:00<17:27,48.61it/s] 71%|#######   |123153/173481[42:12<17:15,48.61it/s] 75%|#######5  |130246/173481[45:00<15:51,45.44it/s] 75%|#######5  |130693/173481[45:12<15:41,45.44it/s] 79%|#######8  |137029/173481[48:00<14:44,41.20it/s] 79%|#######9  |137494/173481[48:12<14:33,41.20it/s] 83%|########2 |143554/173481[51:00<12:56,38.56it/s] 83%|########3 |144008/173481[51:12<12:44,38.56it/s] 87%|########6 |150597/173481[54:00<09:49,38.84it/s] 87%|########7 |151192/173481[54:12<09:33,38.84it/s] 92%|#########1|159315/173481[57:00<05:28,43.11it/s] 92%|#########2|159918/173481[57:12<05:14,43.11it/s] 97%|#########6|168110/173481[1:00:00<01:57,45.80it/s] 97%|#########7|168720/173481[1:00:12<01:43,45.80it/s]100%|##########|173481/173481[1:01:52<00:00,46.73it/s]
[32m[0328 20:45:01 @base.py:257][0m Epoch 8 (global_step 10582341) finished, time:3712.58 sec.
[32m[0328 20:45:01 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 81%|########1 |15267/18822[03:00<00:41,84.82it/s] 86%|########5 |16175/18822[03:10<00:31,84.82it/s]100%|##########|18822/18822[03:41<00:00,85.02it/s]
7
[32m[0328 20:48:43 @monitor.py:363][0m QueueInput/queue_size: 49.952
[32m[0328 20:48:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.765
[32m[0328 20:48:43 @monitor.py:363][0m activation-summaries/output-rms: 0.015637
[32m[0328 20:48:43 @monitor.py:363][0m cross_entropy_loss: 6.4615
[32m[0328 20:48:43 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7114e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2511e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8574e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5009e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0618e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0299e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3524e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7482e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6898e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5051e-06
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 20:48:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 20:48:43 @monitor.py:363][0m train-error-top1: 0.98764
[32m[0328 20:48:43 @monitor.py:363][0m val-error-top1: 0.98744
[32m[0328 20:48:43 @monitor.py:363][0m val-utt-error: 0.97035
[32m[0328 20:48:43 @monitor.py:363][0m validation_cost: 6.4366
[32m[0328 20:48:43 @monitor.py:363][0m wd_cost: 2.4652e-15
[32m[0328 20:48:43 @group.py:42][0m Callbacks took 221.759 sec in total. InferenceRunner: 221.389sec
[32m[0328 20:48:43 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8677/173481[03:00<56:58,48.21it/s]  5%|5         |9167/173481[03:10<56:48,48.21it/s] 10%|#         |17426/173481[06:00<53:44,48.40it/s] 10%|#         |17917/173481[06:10<53:33,48.40it/s] 15%|#5        |26194/173481[09:00<50:33,48.55it/s] 15%|#5        |26720/173481[09:10<50:22,48.55it/s] 20%|##        |35301/173481[12:00<46:28,49.55it/s] 21%|##        |35833/173481[12:10<46:17,49.55it/s] 26%|##5       |44365/173481[15:00<43:04,49.95it/s] 26%|##5       |44885/173481[15:10<42:54,49.95it/s] 31%|###       |53140/173481[18:00<40:39,49.34it/s] 31%|###       |53669/173481[18:10<40:28,49.34it/s] 36%|###5      |61847/173481[21:00<38:05,48.85it/s] 36%|###5      |62393/173481[21:11<37:54,48.85it/s] 41%|####      |70657/173481[24:00<35:02,48.89it/s] 41%|####1     |71195/173481[24:11<34:51,48.89it/s] 45%|####5     |78661/173481[27:00<33:55,46.58it/s] 46%|####5     |79055/173481[27:11<33:47,46.58it/s] 49%|####8     |84863/173481[30:00<37:17,39.61it/s] 49%|####9     |85242/173481[30:11<37:07,39.61it/s] 52%|#####2    |91037/173481[33:00<37:22,36.76it/s] 53%|#####2    |91447/173481[33:11<37:11,36.76it/s] 56%|#####6    |97348/173481[36:00<35:21,35.89it/s] 56%|#####6    |97761/173481[36:11<35:09,35.89it/s] 60%|#####9    |103749/173481[39:00<32:32,35.72it/s] 60%|######    |104152/173481[39:11<32:20,35.72it/s] 65%|######4   |112069/173481[42:00<25:23,40.30it/s] 65%|######4   |112639/173481[42:11<25:09,40.30it/s] 70%|######9   |120809/173481[45:00<19:55,44.04it/s] 70%|######9   |121385/173481[45:12<19:42,44.04it/s] 75%|#######4  |129582/173481[48:00<15:48,46.27it/s] 75%|#######5  |130172/173481[48:12<15:36,46.27it/s] 80%|#######9  |138245/173481[51:00<12:26,47.18it/s] 80%|########  |138833/173481[51:12<12:14,47.18it/s] 85%|########4 |147018/173481[54:00<09:11,47.94it/s] 85%|########5 |147623/173481[54:12<08:59,47.94it/s] 90%|########9 |155738/173481[57:00<06:08,48.19it/s] 90%|######### |156351/173481[57:12<05:55,48.19it/s] 95%|#########4|164476/173481[1:00:00<03:06,48.37it/s] 95%|#########5|165096/173481[1:00:12<02:53,48.37it/s]100%|#########9|173246/173481[1:03:00<00:04,48.54it/s]100%|##########|173481/173481[1:03:05<00:00,45.83it/s]
[32m[0328 21:51:48 @base.py:257][0m Epoch 9 (global_step 10755822) finished, time:3785.01 sec.
[32m[0328 21:51:48 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-10755822.
  0%|          |0/18822[00:00<?,?it/s] 88%|########7 |16489/18822[03:00<00:25,91.60it/s] 93%|#########2|17414/18822[03:10<00:15,91.60it/s]100%|##########|18822/18822[03:25<00:00,91.56it/s]
8
[32m[0328 21:55:14 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 21:55:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.737
[32m[0328 21:55:14 @monitor.py:363][0m activation-summaries/output-rms: 0.016152
[32m[0328 21:55:14 @monitor.py:363][0m cross_entropy_loss: 6.4278
[32m[0328 21:55:14 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.719e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2541e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8644e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5143e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0546e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0283e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3499e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7466e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6863e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5066e-06
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 21:55:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 21:55:14 @monitor.py:363][0m train-error-top1: 0.9859
[32m[0328 21:55:14 @monitor.py:363][0m val-error-top1: 0.98749
[32m[0328 21:55:14 @monitor.py:363][0m val-utt-error: 0.97041
[32m[0328 21:55:14 @monitor.py:363][0m validation_cost: 6.4485
[32m[0328 21:55:14 @monitor.py:363][0m wd_cost: 2.4652e-15
[32m[0328 21:55:14 @group.py:42][0m Callbacks took 205.912 sec in total. InferenceRunner: 205.596sec
[32m[0328 21:55:14 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8769/173481[03:00<56:21,48.71it/s]  5%|5         |9258/173481[03:10<56:11,48.71it/s] 10%|#         |17484/173481[06:00<53:32,48.56it/s] 10%|#         |17970/173481[06:10<53:22,48.56it/s] 15%|#5        |26194/173481[09:00<50:38,48.47it/s] 15%|#5        |26723/173481[09:10<50:27,48.47it/s] 20%|##        |35280/173481[12:00<46:34,49.45it/s] 21%|##        |35825/173481[12:10<46:23,49.45it/s] 25%|##5       |44235/173481[15:00<43:25,49.60it/s] 26%|##5       |44754/173481[15:10<43:15,49.60it/s] 31%|###       |52997/173481[18:00<40:52,49.13it/s] 31%|###       |53518/173481[18:10<40:41,49.13it/s] 36%|###5      |61754/173481[21:00<38:05,48.89it/s] 36%|###5      |62278/173481[21:11<37:54,48.89it/s] 41%|####      |70551/173481[24:00<35:05,48.88it/s] 41%|####      |71081/173481[24:11<34:54,48.88it/s] 46%|####5     |79355/173481[27:00<32:05,48.89it/s] 46%|####6     |79914/173481[27:11<31:53,48.89it/s] 50%|#####     |87077/173481[30:00<31:30,45.70it/s] 50%|#####     |87542/173481[30:11<31:20,45.70it/s] 55%|#####4    |94724/173481[33:00<29:48,44.03it/s] 55%|#####4    |95274/173481[33:11<29:36,44.03it/s] 60%|#####9    |103467/173481[36:00<25:15,46.19it/s] 60%|#####9    |104029/173481[36:11<25:03,46.19it/s] 65%|######4   |112192/173481[39:00<21:35,47.30it/s] 65%|######5   |112765/173481[39:11<21:23,47.30it/s] 70%|######9   |120932/173481[42:00<18:16,47.92it/s] 70%|#######   |121516/173481[42:11<18:04,47.92it/s] 74%|#######4  |128692/173481[45:00<16:26,45.39it/s] 74%|#######4  |129191/173481[45:12<16:15,45.39it/s] 78%|#######8  |135872/173481[48:00<14:45,42.46it/s] 79%|#######8  |136401/173481[48:12<14:33,42.46it/s] 83%|########2 |143196/173481[51:00<12:08,41.55it/s] 83%|########2 |143675/173481[51:12<11:57,41.55it/s] 87%|########6 |150797/173481[54:00<09:01,41.88it/s] 87%|########7 |151376/173481[54:12<08:47,41.88it/s] 92%|#########1|159222/173481[57:00<05:22,44.21it/s] 92%|#########2|159845/173481[57:12<05:08,44.21it/s] 97%|#########6|168008/173481[1:00:00<01:57,46.39it/s] 97%|#########7|168629/173481[1:00:12<01:44,46.39it/s]100%|##########|173481/173481[1:01:53<00:00,46.72it/s]
[32m[0328 22:57:07 @base.py:257][0m Epoch 10 (global_step 10929303) finished, time:3713.45 sec.
[32m[0328 22:57:08 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13840/18822[03:00<01:04,76.88it/s] 77%|#######7  |14552/18822[03:10<00:55,76.88it/s]100%|##########|18822/18822[04:05<00:00,76.64it/s]
9
[32m[0328 23:01:13 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 23:01:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.782
[32m[0328 23:01:13 @monitor.py:363][0m activation-summaries/output-rms: 0.015946
[32m[0328 23:01:13 @monitor.py:363][0m cross_entropy_loss: 6.3862
[32m[0328 23:01:13 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7243e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2614e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8655e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5108e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0531e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0313e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3492e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7411e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6859e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5149e-06
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0328 23:01:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0328 23:01:13 @monitor.py:363][0m train-error-top1: 0.98616
[32m[0328 23:01:13 @monitor.py:363][0m val-error-top1: 0.98738
[32m[0328 23:01:13 @monitor.py:363][0m val-utt-error: 0.9695
[32m[0328 23:01:13 @monitor.py:363][0m validation_cost: 6.4413
[32m[0328 23:01:13 @monitor.py:363][0m wd_cost: 2.4652e-15
[32m[0328 23:01:13 @group.py:42][0m Callbacks took 245.930 sec in total. InferenceRunner: 245.606sec
[32m[0328 23:01:13 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8699/173481[03:00<56:50,48.32it/s]  5%|5         |9191/173481[03:10<56:39,48.32it/s] 10%|#         |17423/173481[06:00<53:44,48.39it/s] 10%|#         |17928/173481[06:10<53:34,48.39it/s] 15%|#5        |26184/173481[09:00<50:35,48.53it/s] 15%|#5        |26702/173481[09:10<50:24,48.53it/s] 20%|##        |35261/173481[12:00<46:34,49.46it/s] 21%|##        |35788/173481[12:10<46:23,49.46it/s] 25%|##5       |44222/173481[15:00<43:25,49.62it/s] 26%|##5       |44742/173481[15:10<43:14,49.62it/s] 30%|###       |52911/173481[18:00<41:03,48.93it/s] 31%|###       |53442/173481[18:10<40:53,48.93it/s] 36%|###5      |61716/173481[21:00<38:04,48.92it/s] 36%|###5      |62253/173481[21:11<37:53,48.92it/s] 41%|####      |70464/173481[24:00<35:12,48.76it/s] 41%|####      |70995/173481[24:11<35:01,48.76it/s] 45%|####5     |78576/173481[27:00<33:46,46.83it/s] 46%|####5     |78950/173481[27:11<33:38,46.83it/s] 49%|####8     |84512/173481[30:00<38:18,38.70it/s] 49%|####8     |84869/173481[30:11<38:09,38.70it/s] 52%|#####2    |90297/173481[33:00<39:28,35.12it/s] 52%|#####2    |90671/173481[33:11<39:18,35.12it/s] 56%|#####5    |96451/173481[36:00<37:03,34.64it/s] 56%|#####5    |96850/173481[36:11<36:51,34.64it/s] 59%|#####9    |102376/173481[39:00<35:06,33.75it/s] 59%|#####9    |102760/173481[39:11<34:55,33.75it/s] 63%|######2   |108741/173481[42:00<31:14,34.53it/s] 63%|######2   |109218/173481[42:12<31:01,34.53it/s] 67%|######6   |116069/173481[45:00<25:36,37.36it/s] 67%|######7   |116522/173481[45:12<25:24,37.36it/s] 71%|#######   |123120/173481[48:00<21:56,38.25it/s] 71%|#######1  |123588/173481[48:12<21:44,38.25it/s] 75%|#######5  |130309/173481[51:00<18:24,39.07it/s] 75%|#######5  |130793/173481[51:12<18:12,39.07it/s] 80%|########  |138887/173481[54:00<13:25,42.94it/s] 80%|########  |139488/173481[54:12<13:11,42.94it/s] 85%|########5 |147733/173481[57:00<09:21,45.83it/s] 86%|########5 |148343/173481[57:12<09:08,45.83it/s] 90%|######### |156471/173481[1:00:00<06:00,47.15it/s] 91%|######### |157078/173481[1:00:12<05:47,47.15it/s] 95%|#########5|165239/173481[1:03:00<02:52,47.92it/s] 96%|#########5|165852/173481[1:03:13<02:39,47.92it/s]100%|##########|173481/173481[1:05:50<00:00,43.92it/s]
[32m[0329 00:07:03 @base.py:257][0m Epoch 11 (global_step 11102784) finished, time:3950.12 sec.
[32m[0329 00:07:04 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s] 84%|########3 |15717/18822[03:00<00:35,87.31it/s] 88%|########8 |16642/18822[03:10<00:24,87.31it/s]100%|##########|18822/18822[03:35<00:00,87.48it/s]
10
[32m[0329 00:10:39 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 00:10:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.679
[32m[0329 00:10:39 @monitor.py:363][0m activation-summaries/output-rms: 0.015746
[32m[0329 00:10:39 @monitor.py:363][0m cross_entropy_loss: 6.4153
[32m[0329 00:10:39 @monitor.py:363][0m lr: 1.1921e-10
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7233e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.259e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8637e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5088e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.055e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.03e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3514e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7434e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6893e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5157e-06
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 00:10:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 00:10:39 @monitor.py:363][0m train-error-top1: 0.9862
[32m[0329 00:10:39 @monitor.py:363][0m val-error-top1: 0.98734
[32m[0329 00:10:39 @monitor.py:363][0m val-utt-error: 0.97019
[32m[0329 00:10:39 @monitor.py:363][0m validation_cost: 6.4349
[32m[0329 00:10:39 @monitor.py:363][0m wd_cost: 4.9304e-16
[32m[0329 00:10:39 @group.py:42][0m Callbacks took 215.461 sec in total. InferenceRunner: 215.178sec
[32m[0329 00:10:39 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8702/173481[03:00<56:48,48.34it/s]  5%|5         |9186/173481[03:10<56:38,48.34it/s] 10%|#         |17419/173481[06:00<53:45,48.38it/s] 10%|#         |17918/173481[06:10<53:35,48.38it/s] 15%|#5        |26205/173481[09:00<50:30,48.59it/s] 15%|#5        |26725/173481[09:10<50:19,48.59it/s] 20%|##        |35327/173481[12:00<46:24,49.61it/s] 21%|##        |35879/173481[12:10<46:13,49.61it/s] 25%|##5       |44200/173481[15:00<43:34,49.45it/s] 26%|##5       |44713/173481[15:10<43:23,49.45it/s] 31%|###       |52973/173481[18:00<40:54,49.09it/s] 31%|###       |53499/173481[18:10<40:44,49.09it/s] 36%|###5      |61692/173481[21:00<38:12,48.76it/s] 36%|###5      |62216/173481[21:11<38:01,48.76it/s] 41%|####      |70402/173481[24:00<35:22,48.57it/s] 41%|####      |70935/173481[24:11<35:11,48.57it/s] 46%|####5     |79135/173481[27:00<32:23,48.54it/s] 46%|####5     |79665/173481[27:11<32:12,48.54it/s] 51%|#####     |87830/173481[30:00<29:28,48.42it/s] 51%|#####     |88379/173481[30:11<29:17,48.42it/s] 56%|#####5    |96575/173481[33:00<26:25,48.50it/s] 56%|#####5    |97140/173481[33:11<26:13,48.50it/s] 61%|######    |105302/173481[36:00<23:26,48.49it/s] 61%|######1   |105862/173481[36:11<23:14,48.49it/s] 66%|######5   |114027/173481[39:00<20:26,48.48it/s] 66%|######6   |114581/173481[39:11<20:14,48.48it/s] 71%|#######   |122683/173481[42:00<17:32,48.28it/s] 71%|#######1  |123268/173481[42:12<17:19,48.28it/s] 76%|#######5  |131435/173481[45:00<14:27,48.45it/s] 76%|#######6  |132020/173481[45:12<14:15,48.45it/s] 81%|########  |140254/173481[48:00<11:22,48.72it/s] 81%|########1 |140842/173481[48:12<11:09,48.72it/s] 86%|########5 |149012/173481[51:00<08:22,48.69it/s] 86%|########6 |149616/173481[51:12<08:10,48.69it/s] 91%|######### |157800/173481[54:00<05:21,48.75it/s] 91%|#########1|158386/173481[54:12<05:09,48.75it/s] 96%|#########6|166553/173481[57:00<02:22,48.69it/s] 96%|#########6|167174/173481[57:12<02:09,48.69it/s]100%|##########|173481/173481[59:24<00:00,48.68it/s]
[32m[0329 01:10:03 @base.py:257][0m Epoch 12 (global_step 11276265) finished, time:3564.04 sec.
[32m[0329 01:10:04 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-11276265.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######7  |14513/18822[03:00<00:53,80.63it/s] 82%|########1 |15359/18822[03:10<00:42,80.63it/s]100%|##########|18822/18822[03:52<00:00,80.88it/s]
11
[32m[0329 01:13:57 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 01:13:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.83
[32m[0329 01:13:57 @monitor.py:363][0m activation-summaries/output-rms: 0.015991
[32m[0329 01:13:57 @monitor.py:363][0m cross_entropy_loss: 6.4226
[32m[0329 01:13:57 @monitor.py:363][0m lr: 1.1921e-10
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7249e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2604e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8628e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5127e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0547e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0292e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3512e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7471e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6883e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5148e-06
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 01:13:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 01:13:57 @monitor.py:363][0m train-error-top1: 0.98763
[32m[0329 01:13:57 @monitor.py:363][0m val-error-top1: 0.98749
[32m[0329 01:13:57 @monitor.py:363][0m val-utt-error: 0.96972
[32m[0329 01:13:57 @monitor.py:363][0m validation_cost: 6.4385
[32m[0329 01:13:57 @monitor.py:363][0m wd_cost: 4.9304e-16
[32m[0329 01:13:57 @group.py:42][0m Callbacks took 233.573 sec in total. InferenceRunner: 232.723sec
[32m[0329 01:13:57 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8730/173481[03:00<56:37,48.50it/s]  5%|5         |9223/173481[03:10<56:26,48.50it/s] 10%|#         |17436/173481[06:00<53:42,48.43it/s] 10%|#         |17945/173481[06:10<53:31,48.43it/s] 15%|#5        |26171/173481[09:00<50:38,48.48it/s] 15%|#5        |26675/173481[09:10<50:28,48.48it/s] 20%|##        |35155/173481[12:00<46:52,49.18it/s] 21%|##        |35695/173481[12:10<46:41,49.18it/s] 26%|##5       |44265/173481[15:00<43:10,49.89it/s] 26%|##5       |44775/173481[15:10<43:00,49.89it/s] 31%|###       |53000/173481[18:00<40:48,49.20it/s] 31%|###       |53528/173481[18:10<40:38,49.20it/s] 36%|###5      |61773/173481[21:00<38:01,48.97it/s] 36%|###5      |62302/173481[21:11<37:50,48.97it/s] 41%|####      |70514/173481[24:00<35:11,48.76it/s] 41%|####      |71052/173481[24:11<35:00,48.76it/s] 46%|####5     |79298/173481[27:00<32:10,48.78it/s] 46%|####6     |79840/173481[27:11<31:59,48.78it/s] 50%|#####     |87385/173481[30:00<30:40,46.77it/s] 51%|#####     |87887/173481[30:11<30:30,46.77it/s] 55%|#####4    |95317/173481[33:00<28:42,45.38it/s] 55%|#####5    |95846/173481[33:11<28:30,45.38it/s] 60%|#####9    |103534/173481[36:00<25:36,45.51it/s] 60%|######    |104102/173481[36:11<25:24,45.51it/s] 65%|######4   |112264/173481[39:00<21:43,46.96it/s] 65%|######5   |112829/173481[39:11<21:31,46.96it/s] 70%|######9   |121027/173481[42:00<18:17,47.80it/s] 70%|#######   |121614/173481[42:12<18:05,47.80it/s] 75%|#######4  |129575/173481[45:00<15:21,47.64it/s] 75%|#######5  |130113/173481[45:12<15:10,47.64it/s] 79%|#######9  |137827/173481[48:00<12:43,46.73it/s] 80%|#######9  |138391/173481[48:12<12:30,46.73it/s] 84%|########4 |146475/173481[51:00<09:30,47.37it/s] 85%|########4 |147075/173481[51:12<09:17,47.37it/s] 89%|########9 |155219/173481[54:00<06:20,47.97it/s] 90%|########9 |155818/173481[54:12<06:08,47.97it/s] 95%|#########4|163955/173481[57:00<03:17,48.25it/s] 95%|#########4|164566/173481[57:12<03:04,48.25it/s]100%|#########9|172726/173481[1:00:00<00:15,48.49it/s]100%|#########9|173341/173481[1:00:12<00:02,48.49it/s]100%|##########|173481/173481[1:00:15<00:00,47.98it/s]
[32m[0329 02:14:13 @base.py:257][0m Epoch 13 (global_step 11449746) finished, time:3615.90 sec.
[32m[0329 02:14:13 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######6  |14414/18822[03:00<00:55,80.08it/s] 81%|########1 |15273/18822[03:10<00:44,80.08it/s]100%|##########|18822/18822[03:54<00:00,80.12it/s]
12
[32m[0329 02:18:08 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 02:18:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.744
[32m[0329 02:18:08 @monitor.py:363][0m activation-summaries/output-rms: 0.015567
[32m[0329 02:18:08 @monitor.py:363][0m cross_entropy_loss: 6.4632
[32m[0329 02:18:08 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7229e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2596e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8617e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5098e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0527e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0289e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3511e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.749e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6879e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5171e-06
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 02:18:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 02:18:08 @monitor.py:363][0m train-error-top1: 0.9886
[32m[0329 02:18:08 @monitor.py:363][0m val-error-top1: 0.98736
[32m[0329 02:18:08 @monitor.py:363][0m val-utt-error: 0.96972
[32m[0329 02:18:08 @monitor.py:363][0m validation_cost: 6.4345
[32m[0329 02:18:08 @monitor.py:363][0m wd_cost: 4.9304e-16
[32m[0329 02:18:08 @group.py:42][0m Callbacks took 235.310 sec in total. InferenceRunner: 234.936sec
[32m[0329 02:18:08 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8751/173481[03:00<56:28,48.61it/s]  5%|5         |9244/173481[03:10<56:18,48.61it/s] 10%|#         |17463/173481[06:00<53:36,48.50it/s] 10%|#         |17957/173481[06:10<53:26,48.50it/s] 15%|#5        |26252/173481[09:00<50:25,48.66it/s] 15%|#5        |26775/173481[09:10<50:14,48.66it/s] 20%|##        |35108/173481[12:00<47:08,48.93it/s] 21%|##        |35631/173481[12:10<46:57,48.93it/s] 25%|##5       |44197/173481[15:00<43:21,49.70it/s] 26%|##5       |44746/173481[15:10<43:10,49.70it/s] 31%|###       |53041/173481[18:00<40:37,49.41it/s] 31%|###       |53568/173481[18:10<40:26,49.41it/s] 36%|###5      |61779/173481[21:00<38:00,48.97it/s] 36%|###5      |62310/173481[21:11<37:50,48.97it/s] 41%|####      |70548/173481[24:00<35:07,48.84it/s] 41%|####      |71087/173481[24:11<34:56,48.84it/s] 46%|####5     |79331/173481[27:00<32:08,48.82it/s] 46%|####6     |79889/173481[27:11<31:57,48.82it/s] 51%|#####     |88113/173481[30:00<29:09,48.80it/s] 51%|#####1    |88681/173481[30:11<28:57,48.80it/s] 56%|#####5    |96880/173481[33:00<26:11,48.75it/s] 56%|#####6    |97431/173481[33:11<25:59,48.75it/s] 61%|######    |105615/173481[36:00<23:15,48.64it/s] 61%|######1   |106186/173481[36:11<23:03,48.64it/s] 66%|######5   |114396/173481[39:00<20:12,48.71it/s] 66%|######6   |114998/173481[39:11<20:00,48.71it/s] 71%|#######   |123131/173481[42:00<17:15,48.62it/s] 71%|#######1  |123719/173481[42:12<17:03,48.62it/s] 76%|#######6  |131945/173481[45:00<14:11,48.79it/s] 76%|#######6  |132550/173481[45:12<13:58,48.79it/s] 81%|########1 |140712/173481[48:00<11:12,48.75it/s] 81%|########1 |141274/173481[48:12<11:00,48.75it/s] 86%|########5 |149173/173481[51:00<08:27,47.86it/s] 86%|########6 |149759/173481[51:12<08:15,47.86it/s] 91%|######### |157820/173481[54:00<05:26,47.95it/s] 91%|#########1|158412/173481[54:12<05:14,47.95it/s] 96%|#########5|166194/173481[57:00<02:34,47.22it/s] 96%|#########6|166733/173481[57:12<02:22,47.22it/s]100%|##########|173481/173481[59:48<00:00,48.34it/s]
[32m[0329 03:17:57 @base.py:257][0m Epoch 14 (global_step 11623227) finished, time:3588.86 sec.
[32m[0329 03:17:57 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-11623227.
  0%|          |0/18822[00:00<?,?it/s] 66%|######6   |12438/18822[03:00<01:32,69.10it/s] 70%|#######   |13181/18822[03:10<01:21,69.10it/s]100%|##########|18822/18822[04:20<00:00,72.28it/s]
13
[32m[0329 03:22:17 @monitor.py:363][0m QueueInput/queue_size: 1.5375
[32m[0329 03:22:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.775
[32m[0329 03:22:17 @monitor.py:363][0m activation-summaries/output-rms: 0.015135
[32m[0329 03:22:17 @monitor.py:363][0m cross_entropy_loss: 6.4132
[32m[0329 03:22:17 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7232e-06
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2599e-06
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8619e-06
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5094e-06
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.052e-06
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0292e-06
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3523e-06
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7472e-06
[32m[0329 03:22:17 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6867e-06
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5154e-06
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 03:22:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 03:22:18 @monitor.py:363][0m train-error-top1: 0.98673
[32m[0329 03:22:18 @monitor.py:363][0m val-error-top1: 0.98748
[32m[0329 03:22:18 @monitor.py:363][0m val-utt-error: 0.97035
[32m[0329 03:22:18 @monitor.py:363][0m validation_cost: 6.4509
[32m[0329 03:22:18 @monitor.py:363][0m wd_cost: 9.8607e-17
[32m[0329 03:22:18 @group.py:42][0m Callbacks took 260.759 sec in total. InferenceRunner: 260.408sec
[32m[0329 03:22:18 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8723/173481[03:00<56:39,48.46it/s]  5%|5         |9207/173481[03:10<56:29,48.46it/s] 10%|#         |17479/173481[06:00<53:33,48.55it/s] 10%|#         |17972/173481[06:10<53:23,48.55it/s] 15%|#5        |26187/173481[09:00<50:39,48.46it/s] 15%|#5        |26693/173481[09:10<50:28,48.46it/s] 20%|##        |34953/173481[12:00<47:31,48.58it/s] 20%|##        |35468/173481[12:10<47:21,48.58it/s] 25%|##5       |43947/173481[15:00<43:49,49.26it/s] 26%|##5       |44483/173481[15:10<43:38,49.26it/s] 30%|###       |52827/173481[18:00<40:47,49.30it/s] 31%|###       |53359/173481[18:10<40:36,49.30it/s] 35%|###5      |61389/173481[21:00<38:35,48.41it/s] 36%|###5      |61904/173481[21:11<38:24,48.41it/s] 40%|####      |70143/173481[24:00<35:29,48.52it/s] 41%|####      |70688/173481[24:11<35:18,48.52it/s] 45%|####5     |78908/173481[27:00<32:25,48.61it/s] 46%|####5     |79464/173481[27:11<32:14,48.61it/s] 51%|#####     |87662/173481[30:00<29:25,48.62it/s] 51%|#####     |88237/173481[30:11<29:13,48.62it/s] 56%|#####5    |96429/173481[33:00<26:23,48.66it/s] 56%|#####5    |96958/173481[33:11<26:12,48.66it/s] 60%|######    |104691/173481[36:00<24:16,47.24it/s] 61%|######    |105231/173481[36:11<24:04,47.24it/s] 65%|######5   |112840/173481[39:00<21:51,46.23it/s] 65%|######5   |113388/173481[39:11<21:39,46.23it/s] 70%|######9   |121063/173481[42:00<19:00,45.96it/s] 70%|#######   |121610/173481[42:12<18:48,45.96it/s] 74%|#######4  |129238/173481[45:00<16:08,45.68it/s] 75%|#######4  |129795/173481[45:12<15:56,45.68it/s] 79%|#######9  |137693/173481[48:00<12:52,46.32it/s] 80%|#######9  |138247/173481[48:12<12:40,46.32it/s] 84%|########4 |146105/173481[51:00<09:48,46.52it/s] 85%|########4 |146708/173481[51:12<09:35,46.52it/s] 89%|########9 |154617/173481[54:00<06:42,46.90it/s] 89%|########9 |155202/173481[54:12<06:29,46.90it/s] 94%|#########3|162853/173481[57:00<03:49,46.32it/s] 94%|#########4|163473/173481[57:13<03:36,46.32it/s] 99%|#########8|171225/173481[1:00:00<00:48,46.41it/s] 99%|#########9|171860/173481[1:00:13<00:34,46.41it/s]100%|##########|173481/173481[1:00:47<00:00,47.56it/s]
[32m[0329 04:23:05 @base.py:257][0m Epoch 15 (global_step 11796708) finished, time:3647.35 sec.
[32m[0329 04:23:05 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s] 67%|######6   |12594/18822[03:00<01:29,69.96it/s] 71%|#######1  |13400/18822[03:10<01:17,69.96it/s]100%|##########|18822/18822[04:16<00:00,73.42it/s]
14
[32m[0329 04:27:22 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 04:27:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.766
[32m[0329 04:27:22 @monitor.py:363][0m activation-summaries/output-rms: 0.015748
[32m[0329 04:27:22 @monitor.py:363][0m cross_entropy_loss: 6.372
[32m[0329 04:27:22 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7244e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2628e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8624e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5127e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0519e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0289e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3547e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7467e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.684e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5152e-06
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 04:27:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 04:27:22 @monitor.py:363][0m train-error-top1: 0.98574
[32m[0329 04:27:22 @monitor.py:363][0m val-error-top1: 0.98744
[32m[0329 04:27:22 @monitor.py:363][0m val-utt-error: 0.97041
[32m[0329 04:27:22 @monitor.py:363][0m validation_cost: 6.4497
[32m[0329 04:27:22 @monitor.py:363][0m wd_cost: 9.8607e-17
[32m[0329 04:27:22 @group.py:42][0m Callbacks took 256.811 sec in total. InferenceRunner: 256.368sec
[32m[0329 04:27:22 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8647/173481[03:00<57:11,48.04it/s]  5%|5         |9155/173481[03:10<57:00,48.04it/s] 10%|#         |17385/173481[06:00<53:52,48.29it/s] 10%|#         |17875/173481[06:10<53:42,48.29it/s] 15%|#4        |25753/173481[09:00<51:58,47.37it/s] 15%|#5        |26239/173481[09:10<51:48,47.37it/s] 20%|#9        |33848/173481[12:00<50:26,46.14it/s] 20%|#9        |34344/173481[12:10<50:15,46.14it/s] 25%|##4       |42567/173481[15:00<46:10,47.26it/s] 25%|##4       |43091/173481[15:10<45:58,47.26it/s] 30%|##9       |51413/173481[18:00<42:13,48.18it/s] 30%|##9       |51930/173481[18:11<42:02,48.18it/s] 34%|###4      |59723/173481[21:00<40:12,47.15it/s] 35%|###4      |60204/173481[21:11<40:02,47.15it/s] 39%|###9      |67759/173481[24:00<38:25,45.86it/s] 39%|###9      |68236/173481[24:11<38:14,45.86it/s] 44%|####3     |75933/173481[27:00<35:37,45.63it/s] 44%|####4     |76495/173481[27:11<35:25,45.63it/s] 49%|####8     |84767/173481[30:00<31:15,47.29it/s] 49%|####9     |85339/173481[30:11<31:03,47.29it/s] 54%|#####3    |92979/173481[33:00<28:53,46.44it/s] 54%|#####3    |93521/173481[33:11<28:41,46.44it/s] 58%|#####8    |100777/173481[36:00<27:01,44.82it/s] 58%|#####8    |101300/173481[36:11<26:50,44.82it/s] 63%|######2   |108557/173481[39:00<24:35,44.01it/s] 63%|######2   |109083/173481[39:11<24:23,44.01it/s] 67%|######7   |116303/173481[42:00<21:54,43.51it/s] 67%|######7   |116809/173481[42:12<21:42,43.51it/s] 72%|#######1  |124295/173481[45:00<18:39,43.95it/s] 72%|#######1  |124834/173481[45:12<18:26,43.95it/s] 76%|#######6  |132208/173481[48:00<15:39,43.95it/s] 77%|#######6  |132737/173481[48:12<15:26,43.95it/s] 81%|########  |140128/173481[51:00<12:38,43.97it/s] 81%|########1 |140672/173481[51:12<12:26,43.97it/s] 85%|########5 |147927/173481[54:00<09:45,43.65it/s] 86%|########5 |148466/173481[54:12<09:33,43.65it/s] 90%|########9 |155671/173481[57:00<06:51,43.33it/s] 90%|######### |156201/173481[57:12<06:38,43.33it/s] 94%|#########4|163361/173481[1:00:00<03:55,43.02it/s] 94%|#########4|163905/173481[1:00:12<03:42,43.02it/s] 99%|#########8|171221/173481[1:03:00<00:52,43.34it/s] 99%|#########9|171785/173481[1:03:13<00:39,43.34it/s]100%|##########|173481/173481[1:03:53<00:00,45.26it/s]
[32m[0329 05:31:15 @base.py:257][0m Epoch 16 (global_step 11970189) finished, time:3833.24 sec.
[32m[0329 05:31:15 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13864/18822[03:00<01:04,77.02it/s] 78%|#######7  |14679/18822[03:10<00:53,77.02it/s]100%|##########|18822/18822[03:59<00:00,78.46it/s]
15
[32m[0329 05:35:15 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 05:35:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.798
[32m[0329 05:35:15 @monitor.py:363][0m activation-summaries/output-rms: 0.015745
[32m[0329 05:35:15 @monitor.py:363][0m cross_entropy_loss: 6.4233
[32m[0329 05:35:15 @monitor.py:363][0m lr: 2.9802e-11
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7242e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2623e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8615e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5133e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0516e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0285e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3563e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7477e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6838e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5171e-06
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 05:35:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 05:35:15 @monitor.py:363][0m train-error-top1: 0.98252
[32m[0329 05:35:15 @monitor.py:363][0m val-error-top1: 0.98732
[32m[0329 05:35:15 @monitor.py:363][0m val-utt-error: 0.97004
[32m[0329 05:35:15 @monitor.py:363][0m validation_cost: 6.4308
[32m[0329 05:35:15 @monitor.py:363][0m wd_cost: 9.8607e-17
[32m[0329 05:35:15 @group.py:42][0m Callbacks took 240.301 sec in total. InferenceRunner: 239.925sec
[32m[0329 05:35:15 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8658/173481[03:00<57:06,48.10it/s]  5%|5         |9155/173481[03:10<56:56,48.10it/s] 10%|#         |17402/173481[06:00<53:49,48.33it/s] 10%|#         |17911/173481[06:10<53:38,48.33it/s] 15%|#5        |26179/173481[09:00<50:34,48.55it/s] 15%|#5        |26685/173481[09:10<50:23,48.55it/s] 20%|##        |35130/173481[12:00<46:56,49.13it/s] 21%|##        |35647/173481[12:10<46:45,49.13it/s] 25%|##5       |44055/173481[15:00<43:42,49.35it/s] 26%|##5       |44592/173481[15:10<43:31,49.35it/s] 30%|###       |52785/173481[18:00<41:07,48.92it/s] 31%|###       |53323/173481[18:10<40:56,48.92it/s] 35%|###5      |61581/173481[21:00<38:08,48.89it/s] 36%|###5      |62112/173481[21:11<37:57,48.89it/s] 41%|####      |70350/173481[24:00<35:13,48.80it/s] 41%|####      |70890/173481[24:11<35:02,48.80it/s] 46%|####5     |79143/173481[27:00<32:12,48.83it/s] 46%|####5     |79710/173481[27:11<32:00,48.83it/s] 51%|#####     |87908/173481[30:00<29:15,48.76it/s] 51%|#####     |88459/173481[30:11<29:03,48.76it/s] 56%|#####5    |96374/173481[33:00<26:50,47.88it/s] 56%|#####5    |96912/173481[33:11<26:39,47.88it/s] 60%|######    |104700/173481[36:00<24:21,47.05it/s] 61%|######    |105261/173481[36:11<24:09,47.05it/s] 65%|######5   |113284/173481[39:00<21:10,47.37it/s] 66%|######5   |113832/173481[39:11<20:59,47.37it/s] 70%|#######   |121828/173481[42:00<18:09,47.41it/s] 71%|#######   |122394/173481[42:12<17:57,47.41it/s] 75%|#######4  |130022/173481[45:00<15:35,46.45it/s] 75%|#######5  |130610/173481[45:12<15:22,46.45it/s] 80%|#######9  |138580/173481[48:00<12:22,46.99it/s] 80%|########  |139148/173481[48:12<12:10,46.99it/s] 85%|########4 |146791/173481[51:00<09:36,46.29it/s] 85%|########4 |147355/173481[51:12<09:24,46.29it/s] 90%|########9 |155285/173481[54:00<06:29,46.73it/s] 90%|########9 |155831/173481[54:12<06:17,46.73it/s] 94%|#########4|163243/173481[57:00<03:45,45.43it/s] 94%|#########4|163789/173481[57:12<03:33,45.43it/s] 99%|#########9|171748/173481[1:00:00<00:37,46.32it/s] 99%|#########9|172359/173481[1:00:12<00:24,46.32it/s]100%|##########|173481/173481[1:00:36<00:00,47.71it/s]
[32m[0329 06:35:51 @base.py:257][0m Epoch 17 (global_step 12143670) finished, time:3636.19 sec.
[32m[0329 06:35:52 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-12143670.
[32m[0329 06:35:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 75%|#######4  |14103/18822[03:00<01:00,78.34it/s] 79%|#######9  |14939/18822[03:10<00:49,78.34it/s]100%|##########|18822/18822[03:57<00:00,79.34it/s]
16
[32m[0329 06:39:49 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 06:39:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.771
[32m[0329 06:39:49 @monitor.py:363][0m activation-summaries/output-rms: 0.015578
[32m[0329 06:39:49 @monitor.py:363][0m cross_entropy_loss: 6.436
[32m[0329 06:39:49 @monitor.py:363][0m lr: 2.9802e-11
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7242e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.263e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8614e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5149e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0533e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0281e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.356e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.748e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6834e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5158e-06
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 06:39:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 06:39:49 @monitor.py:363][0m train-error-top1: 0.98861
[32m[0329 06:39:49 @monitor.py:363][0m val-error-top1: 0.98755
[32m[0329 06:39:49 @monitor.py:363][0m val-utt-error: 0.97025
[32m[0329 06:39:49 @monitor.py:363][0m validation_cost: 6.4367
[32m[0329 06:39:49 @monitor.py:363][0m wd_cost: 1.9721e-17
[32m[0329 06:39:49 @group.py:42][0m Callbacks took 237.685 sec in total. InferenceRunner: 237.253sec
[32m[0329 06:39:49 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8770/173481[03:00<56:20,48.72it/s]  5%|5         |9252/173481[03:10<56:11,48.72it/s] 10%|#         |17485/173481[06:00<53:32,48.57it/s] 10%|#         |17974/173481[06:10<53:21,48.57it/s] 15%|#5        |26255/173481[09:00<50:26,48.64it/s] 15%|#5        |26771/173481[09:10<50:16,48.64it/s] 20%|##        |35096/173481[12:00<47:11,48.88it/s] 21%|##        |35630/173481[12:10<47:00,48.88it/s] 25%|##5       |44043/173481[15:00<43:46,49.29it/s] 26%|##5       |44561/173481[15:10<43:35,49.29it/s] 30%|###       |52734/173481[18:00<41:15,48.78it/s] 31%|###       |53246/173481[18:10<41:04,48.78it/s] 35%|###5      |61387/173481[21:00<38:34,48.42it/s] 36%|###5      |61923/173481[21:11<38:23,48.42it/s] 40%|####      |70092/173481[24:00<35:36,48.39it/s] 41%|####      |70639/173481[24:11<35:25,48.39it/s] 45%|####5     |78866/173481[27:00<32:28,48.56it/s] 46%|####5     |79409/173481[27:11<32:17,48.56it/s] 50%|#####     |87487/173481[30:00<29:43,48.22it/s] 51%|#####     |88026/173481[30:11<29:32,48.22it/s] 55%|#####5    |95945/173481[33:00<27:09,47.60it/s] 56%|#####5    |96478/173481[33:11<26:57,47.60it/s] 60%|#####9    |104077/173481[36:00<24:57,46.36it/s] 60%|######    |104620/173481[36:11<24:45,46.36it/s] 65%|######4   |112509/173481[39:00<21:48,46.60it/s] 65%|######5   |113061/173481[39:11<21:36,46.60it/s] 70%|######9   |120964/173481[42:00<18:42,46.78it/s] 70%|#######   |121540/173481[42:12<18:30,46.78it/s] 74%|#######4  |129173/173481[45:00<15:59,46.18it/s] 75%|#######4  |129719/173481[45:12<15:47,46.18it/s] 79%|#######9  |137469/173481[48:00<13:00,46.13it/s] 80%|#######9  |138051/173481[48:12<12:47,46.13it/s] 84%|########3 |145674/173481[51:00<10:06,45.85it/s] 84%|########4 |146231/173481[51:12<09:54,45.85it/s] 89%|########8 |153857/173481[54:00<07:09,45.65it/s] 89%|########9 |154413/173481[54:12<06:57,45.65it/s] 93%|#########3|161994/173481[57:00<04:12,45.43it/s] 94%|#########3|162543/173481[57:12<04:00,45.43it/s] 98%|#########7|169889/173481[1:00:00<01:20,44.62it/s] 98%|#########8|170466/173481[1:00:13<01:07,44.62it/s]100%|##########|173481/173481[1:01:20<00:00,47.13it/s]
[32m[0329 07:41:10 @base.py:257][0m Epoch 18 (global_step 12317151) finished, time:3680.58 sec.
[32m[0329 07:41:10 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s] 72%|#######1  |13515/18822[03:00<01:10,75.08it/s] 76%|#######6  |14385/18822[03:10<00:59,75.08it/s]100%|##########|18822/18822[04:05<00:00,76.82it/s]
17
[32m[0329 07:45:15 @monitor.py:363][0m QueueInput/queue_size: 1.5869
[32m[0329 07:45:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.814
[32m[0329 07:45:15 @monitor.py:363][0m activation-summaries/output-rms: 0.015736
[32m[0329 07:45:15 @monitor.py:363][0m cross_entropy_loss: 6.4647
[32m[0329 07:45:15 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7248e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2636e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8621e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5135e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0529e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0282e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3552e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7486e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.684e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5164e-06
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 07:45:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 07:45:15 @monitor.py:363][0m train-error-top1: 0.99042
[32m[0329 07:45:15 @monitor.py:363][0m val-error-top1: 0.98747
[32m[0329 07:45:15 @monitor.py:363][0m val-utt-error: 0.97019
[32m[0329 07:45:15 @monitor.py:363][0m validation_cost: 6.4469
[32m[0329 07:45:15 @monitor.py:363][0m wd_cost: 1.9721e-17
[32m[0329 07:45:15 @group.py:42][0m Callbacks took 245.361 sec in total. InferenceRunner: 245.046sec
[32m[0329 07:45:15 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8644/173481[03:00<57:12,48.02it/s]  5%|5         |9127/173481[03:10<57:02,48.02it/s] 10%|#         |17384/173481[06:00<53:52,48.28it/s] 10%|#         |17888/173481[06:10<53:42,48.28it/s] 15%|#5        |26070/173481[09:00<50:53,48.27it/s] 15%|#5        |26575/173481[09:10<50:43,48.27it/s] 20%|##        |34839/173481[12:00<47:39,48.49it/s] 20%|##        |35360/173481[12:10<47:28,48.49it/s] 25%|##5       |43857/173481[15:00<43:50,49.28it/s] 26%|##5       |44373/173481[15:10<43:39,49.28it/s] 30%|###       |52652/173481[18:00<41:02,49.07it/s] 31%|###       |53167/173481[18:10<40:51,49.07it/s] 35%|###5      |61193/173481[21:00<38:47,48.24it/s] 36%|###5      |61709/173481[21:10<38:36,48.24it/s] 40%|####      |69581/173481[24:00<36:31,47.41it/s] 40%|####      |70119/173481[24:11<36:20,47.41it/s] 45%|####5     |78325/173481[27:00<33:03,47.98it/s] 45%|####5     |78881/173481[27:11<32:51,47.98it/s] 50%|####9     |86489/173481[30:00<31:05,46.63it/s] 50%|#####     |86982/173481[30:11<30:54,46.63it/s] 54%|#####4    |94502/173481[33:00<28:53,45.55it/s] 55%|#####4    |95012/173481[33:11<28:42,45.55it/s] 59%|#####8    |102280/173481[36:00<26:45,44.35it/s] 59%|#####9    |102801/173481[36:11<26:33,44.35it/s] 64%|######3   |110295/173481[39:00<23:41,44.44it/s] 64%|######3   |110831/173481[39:11<23:29,44.44it/s] 68%|######8   |118460/173481[42:00<20:25,44.89it/s] 69%|######8   |119030/173481[42:12<20:12,44.89it/s] 73%|#######2  |126591/173481[45:00<17:21,45.03it/s] 73%|#######3  |127167/173481[45:12<17:08,45.03it/s] 78%|#######7  |134837/173481[48:00<14:10,45.42it/s] 78%|#######8  |135427/173481[48:12<13:57,45.42it/s] 83%|########2 |143540/173481[51:00<10:39,46.84it/s] 83%|########3 |144139/173481[51:12<10:26,46.84it/s] 88%|########7 |152257/173481[54:00<07:25,47.62it/s] 88%|########8 |152844/173481[54:12<07:13,47.62it/s] 93%|#########2|160987/173481[57:00<04:20,48.05it/s] 93%|#########3|161607/173481[57:12<04:07,48.05it/s] 98%|#########7|169284/173481[1:00:00<01:29,47.05it/s] 98%|#########7|169888/173481[1:00:12<01:16,47.05it/s]100%|##########|173481/173481[1:01:29<00:00,47.02it/s]
[32m[0329 08:46:45 @base.py:257][0m Epoch 19 (global_step 12490632) finished, time:3689.84 sec.
[32m[0329 08:46:45 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-12490632.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13899/18822[03:00<01:03,77.21it/s] 78%|#######8  |14728/18822[03:10<00:53,77.21it/s]100%|##########|18822/18822[04:00<00:00,78.34it/s]
18
[32m[0329 08:50:46 @monitor.py:363][0m QueueInput/queue_size: 49.155
[32m[0329 08:50:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.793
[32m[0329 08:50:46 @monitor.py:363][0m activation-summaries/output-rms: 0.015157
[32m[0329 08:50:46 @monitor.py:363][0m cross_entropy_loss: 6.4194
[32m[0329 08:50:46 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7245e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2631e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8621e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5134e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0534e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0283e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3546e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7491e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6834e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5161e-06
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 08:50:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 08:50:46 @monitor.py:363][0m train-error-top1: 0.98866
[32m[0329 08:50:46 @monitor.py:363][0m val-error-top1: 0.98752
[32m[0329 08:50:46 @monitor.py:363][0m val-utt-error: 0.97046
[32m[0329 08:50:46 @monitor.py:363][0m validation_cost: 6.4494
[32m[0329 08:50:46 @monitor.py:363][0m wd_cost: 3.9443e-18
[32m[0329 08:50:46 @group.py:42][0m Callbacks took 240.658 sec in total. InferenceRunner: 240.276sec
[32m[0329 08:50:46 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8689/173481[03:00<56:54,48.27it/s]  5%|5         |9186/173481[03:10<56:43,48.27it/s] 10%|#         |17406/173481[06:00<53:48,48.35it/s] 10%|#         |17910/173481[06:10<53:37,48.35it/s] 15%|#5        |26125/173481[09:00<50:45,48.39it/s] 15%|#5        |26633/173481[09:10<50:34,48.39it/s] 20%|##        |34991/173481[12:00<47:16,48.82it/s] 20%|##        |35516/173481[12:10<47:06,48.82it/s] 25%|##5       |43993/173481[15:00<43:40,49.41it/s] 26%|##5       |44523/173481[15:10<43:30,49.41it/s] 30%|###       |52761/173481[18:00<41:00,49.05it/s] 31%|###       |53279/173481[18:10<40:50,49.05it/s] 35%|###5      |61446/173481[21:00<38:22,48.65it/s] 36%|###5      |61971/173481[21:11<38:12,48.65it/s] 40%|####      |70234/173481[24:00<35:18,48.73it/s] 41%|####      |70776/173481[24:11<35:07,48.73it/s] 46%|####5     |78946/173481[27:00<32:26,48.57it/s] 46%|####5     |79496/173481[27:11<32:15,48.57it/s] 51%|#####     |87644/173481[30:00<29:31,48.44it/s] 51%|#####     |88207/173481[30:11<29:20,48.44it/s] 56%|#####5    |96324/173481[33:00<26:36,48.33it/s] 56%|#####5    |96838/173481[33:11<26:25,48.33it/s] 60%|######    |104665/173481[36:00<24:14,47.31it/s] 61%|######    |105226/173481[36:11<24:02,47.31it/s] 65%|######5   |112965/173481[39:00<21:35,46.70it/s] 65%|######5   |113504/173481[39:11<21:24,46.70it/s] 70%|######9   |120944/173481[42:00<19:15,45.48it/s] 70%|#######   |121507/173481[42:12<19:02,45.48it/s] 75%|#######4  |129325/173481[45:00<15:59,46.01it/s] 75%|#######4  |129908/173481[45:12<15:46,46.01it/s] 79%|#######9  |137655/173481[48:00<12:56,46.14it/s] 80%|#######9  |138196/173481[48:12<12:44,46.14it/s] 84%|########4 |145965/173481[51:00<09:56,46.15it/s] 84%|########4 |146579/173481[51:12<09:42,46.15it/s] 89%|########9 |154793/173481[54:00<06:32,47.56it/s] 90%|########9 |155388/173481[54:12<06:20,47.56it/s] 94%|#########3|162917/173481[57:00<03:48,46.31it/s] 94%|#########4|163504/173481[57:12<03:35,46.31it/s] 99%|#########8|171520/173481[1:00:00<00:41,47.04it/s] 99%|#########9|172091/173481[1:00:12<00:29,47.04it/s]100%|##########|173481/173481[1:00:42<00:00,47.62it/s]
[32m[0329 09:51:29 @base.py:257][0m Epoch 20 (global_step 12664113) finished, time:3642.98 sec.
[32m[0329 09:51:29 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s] 72%|#######1  |13547/18822[03:00<01:10,75.26it/s] 76%|#######6  |14390/18822[03:10<00:58,75.26it/s]100%|##########|18822/18822[04:10<00:00,75.14it/s]
19
[32m[0329 09:55:40 @monitor.py:363][0m QueueInput/queue_size: 41.186
[32m[0329 09:55:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.799
[32m[0329 09:55:40 @monitor.py:363][0m activation-summaries/output-rms: 0.015497
[32m[0329 09:55:40 @monitor.py:363][0m cross_entropy_loss: 6.4152
[32m[0329 09:55:40 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7242e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2631e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8625e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5138e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0533e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0282e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3547e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7495e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6837e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5164e-06
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 09:55:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 09:55:40 @monitor.py:363][0m train-error-top1: 0.98757
[32m[0329 09:55:40 @monitor.py:363][0m val-error-top1: 0.98734
[32m[0329 09:55:40 @monitor.py:363][0m val-utt-error: 0.96929
[32m[0329 09:55:40 @monitor.py:363][0m validation_cost: 6.4296
[32m[0329 09:55:40 @monitor.py:363][0m wd_cost: 3.9443e-18
[32m[0329 09:55:40 @group.py:42][0m Callbacks took 251.158 sec in total. InferenceRunner: 250.510sec
[32m[0329 09:55:40 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8658/173481[03:00<57:06,48.10it/s]  5%|5         |9164/173481[03:10<56:56,48.10it/s] 10%|#         |17350/173481[06:00<53:59,48.19it/s] 10%|#         |17842/173481[06:10<53:49,48.19it/s] 15%|#4        |25761/173481[09:00<51:53,47.45it/s] 15%|#5        |26119/173481[09:10<51:45,47.45it/s] 18%|#8        |31894/173481[12:00<59:29,39.66it/s] 19%|#8        |32412/173481[12:10<59:16,39.66it/s] 23%|##3       |40717/173481[15:00<50:28,43.84it/s] 24%|##3       |41222/173481[15:10<50:16,43.84it/s] 28%|##8       |49336/173481[18:00<45:12,45.77it/s] 29%|##8       |49715/173481[18:10<45:04,45.77it/s] 32%|###1      |55427/173481[21:00<50:34,38.91it/s] 32%|###2      |55810/173481[21:10<50:24,38.91it/s] 36%|###5      |61610/173481[24:00<51:06,36.49it/s] 36%|###5      |61975/173481[24:11<50:56,36.49it/s] 39%|###9      |67729/173481[27:00<50:04,35.19it/s] 39%|###9      |68097/173481[27:11<49:54,35.19it/s] 42%|####2     |73652/173481[30:00<48:55,34.01it/s] 43%|####2     |74035/173481[30:11<48:43,34.01it/s] 47%|####6     |81146/173481[33:00<41:06,37.43it/s] 47%|####7     |81637/173481[33:11<40:53,37.43it/s] 51%|#####1    |88566/173481[36:00<36:04,39.23it/s] 51%|#####1    |88949/173481[36:11<35:54,39.23it/s] 55%|#####4    |94798/173481[39:00<35:39,36.78it/s] 55%|#####4    |95205/173481[39:11<35:28,36.78it/s] 58%|#####8    |100940/173481[42:00<34:09,35.40it/s] 58%|#####8    |101337/173481[42:11<33:57,35.40it/s] 62%|######1   |106964/173481[45:00<32:13,34.40it/s] 62%|######1   |107360/173481[45:12<32:01,34.40it/s] 65%|######5   |113083/173481[48:00<29:26,34.20it/s] 65%|######5   |113495/173481[48:12<29:14,34.20it/s] 69%|######8   |119231/173481[51:00<26:27,34.17it/s] 69%|######8   |119655/173481[51:12<26:15,34.17it/s] 72%|#######2  |125536/173481[54:00<23:05,34.59it/s] 73%|#######2  |125957/173481[54:12<22:53,34.59it/s] 76%|#######6  |131866/173481[57:00<19:53,34.88it/s] 76%|#######6  |132294/173481[57:12<19:40,34.88it/s] 80%|#######9  |138231/173481[1:00:00<16:43,35.11it/s] 80%|#######9  |138655/173481[1:00:12<16:31,35.11it/s] 83%|########3 |144587/173481[1:03:00<13:40,35.21it/s] 84%|########3 |145022/173481[1:03:12<13:28,35.21it/s] 87%|########7 |150996/173481[1:06:00<10:35,35.41it/s] 87%|########7 |151466/173481[1:06:13<10:21,35.41it/s] 90%|######### |156934/173481[1:09:00<08:04,34.15it/s] 91%|######### |157296/173481[1:09:13<07:53,34.15it/s] 93%|#########3|162086/173481[1:12:00<06:05,31.14it/s] 94%|#########3|162450/173481[1:12:13<05:54,31.14it/s] 97%|#########6|167573/173481[1:15:00<03:11,30.81it/s] 97%|#########6|168032/173481[1:15:13<02:56,30.81it/s]100%|##########|173481/173481[1:17:48<00:00,37.16it/s]
[32m[0329 11:13:29 @base.py:257][0m Epoch 21 (global_step 12837594) finished, time:4668.82 sec.
[32m[0329 11:13:29 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s] 65%|######5   |12319/18822[03:00<01:35,68.44it/s] 70%|#######   |13268/18822[03:10<01:21,68.44it/s]100%|##########|18822/18822[04:09<00:00,75.37it/s]
20
[32m[0329 11:17:39 @monitor.py:363][0m QueueInput/queue_size: 1.0366
[32m[0329 11:17:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.803
[32m[0329 11:17:39 @monitor.py:363][0m activation-summaries/output-rms: 0.015801
[32m[0329 11:17:39 @monitor.py:363][0m cross_entropy_loss: 6.3943
[32m[0329 11:17:39 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.7243e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2627e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8621e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5134e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0531e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0281e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3547e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7495e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6838e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.516e-06
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 11:17:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 11:17:39 @monitor.py:363][0m train-error-top1: 0.98579
[32m[0329 11:17:39 @monitor.py:363][0m val-error-top1: 0.98727
[32m[0329 11:17:39 @monitor.py:363][0m val-utt-error: 0.97041
[32m[0329 11:17:39 @monitor.py:363][0m validation_cost: 6.4313
[32m[0329 11:17:39 @monitor.py:363][0m wd_cost: 3.9443e-18
[32m[0329 11:17:39 @group.py:42][0m Callbacks took 250.006 sec in total. InferenceRunner: 249.744sec
[32m[0329 11:17:39 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8737/173481[03:00<56:34,48.54it/s]  5%|5         |9226/173481[03:10<56:24,48.54it/s] 10%|#         |17453/173481[06:00<53:38,48.48it/s] 10%|#         |17948/173481[06:10<53:28,48.48it/s] 15%|#5        |26316/173481[09:00<50:12,48.86it/s] 15%|#5        |26850/173481[09:10<50:01,48.86it/s] 20%|##        |35246/173481[12:00<46:47,49.23it/s] 21%|##        |35754/173481[12:10<46:37,49.23it/s] 25%|##5       |43879/173481[15:00<44:27,48.59it/s] 26%|##5       |44392/173481[15:10<44:16,48.59it/s] 30%|###       |52495/173481[18:00<41:48,48.22it/s] 31%|###       |53007/173481[18:10<41:38,48.22it/s] 35%|###5      |61047/173481[21:00<39:09,47.86it/s] 35%|###5      |61578/173481[21:11<38:58,47.86it/s] 40%|####      |69689/173481[24:00<36:05,47.93it/s] 40%|####      |70235/173481[24:11<35:53,47.93it/s] 45%|####5     |78455/173481[27:00<32:46,48.31it/s] 46%|####5     |79021/173481[27:11<32:35,48.31it/s] 50%|#####     |87193/173481[30:00<29:41,48.43it/s] 51%|#####     |87741/173481[30:11<29:30,48.43it/s] 55%|#####5    |95959/173481[33:00<26:36,48.56it/s] 56%|#####5    |96513/173481[33:11<26:25,48.56it/s] 60%|######    |104651/173481[36:00<23:41,48.42it/s] 61%|######    |105213/173481[36:11<23:29,48.42it/s] 65%|######5   |113343/173481[39:00<20:43,48.35it/s] 66%|######5   |113912/173481[39:11<20:31,48.35it/s] 70%|#######   |122110/173481[42:00<17:38,48.53it/s] 71%|#######   |122677/173481[42:12<17:26,48.53it/s] 75%|#######5  |130886/173481[45:00<14:35,48.64it/s] 76%|#######5  |131471/173481[45:12<14:23,48.64it/s] 80%|########  |139617/173481[48:00<11:37,48.57it/s] 81%|########  |140215/173481[48:12<11:24,48.57it/s] 86%|########5 |148337/173481[51:00<08:38,48.51it/s] 86%|########5 |148918/173481[51:12<08:26,48.51it/s] 91%|######### |157015/173481[54:00<05:40,48.36it/s] 91%|######### |157633/173481[54:12<05:27,48.36it/s] 96%|#########5|165681/173481[57:00<02:41,48.25it/s] 96%|#########5|166274/173481[57:12<02:29,48.25it/s]100%|##########|173481/173481[59:43<00:00,48.42it/s]
[32m[0329 12:17:22 @base.py:257][0m Epoch 22 (global_step 13011075) finished, time:3583.13 sec.
[32m[0329 12:17:22 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_4_quant_ends_True_preload/model-13011075.
[32m[0329 12:17:22 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######8  |14753/18822[03:00<00:49,81.96it/s] 83%|########2 |15619/18822[03:10<00:39,81.96it/s]100%|##########|18822/18822[03:45<00:00,83.44it/s]
21
[32m[0329 12:21:08 @monitor.py:363][0m QueueInput/queue_size: 49.997
[32m[0329 12:21:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 25.771
[32m[0329 12:21:08 @monitor.py:363][0m activation-summaries/output-rms: 0.015539
[32m[0329 12:21:08 @monitor.py:363][0m cross_entropy_loss: 6.4334
[32m[0329 12:21:08 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.724e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2627e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8622e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5132e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0531e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0281e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3551e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7494e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6839e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5162e-06
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0329 12:21:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0329 12:21:08 @monitor.py:363][0m train-error-top1: 0.98843
[32m[0329 12:21:08 @monitor.py:363][0m val-error-top1: 0.98754
[32m[0329 12:21:08 @monitor.py:363][0m val-utt-error: 0.96998
[32m[0329 12:21:08 @monitor.py:363][0m validation_cost: 6.4374
[32m[0329 12:21:08 @monitor.py:363][0m wd_cost: 7.8886e-19
[32m[0329 12:21:08 @group.py:42][0m Callbacks took 226.120 sec in total. InferenceRunner: 225.584sec
[32m[0329 12:21:08 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8481/173481[03:00<58:22,47.11it/s]  5%|5         |8949/173481[03:10<58:12,47.11it/s] 10%|9         |16987/173481[06:00<55:16,47.18it/s] 10%|#         |17470/173481[06:10<55:06,47.18it/s] 15%|#4        |25567/173481[09:00<51:59,47.42it/s] 15%|#5        |26072/173481[09:10<51:48,47.42it/s] 20%|#9        |34529/173481[12:00<47:40,48.57it/s] 20%|##        |35067/173481[12:10<47:29,48.57it/s] 25%|##5       |43513/173481[15:00<43:59,49.23it/s] 25%|##5       |44023/173481[15:10<43:49,49.23it/s] 30%|###       |52174/173481[18:00<41:32,48.67it/s]slurmstepd: *** JOB 85165 ON sls-sm-8 CANCELLED AT 2018-03-29T12:39:10 ***
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 85165.0 ON sls-sm-8 CANCELLED AT 2018-03-29T12:39:10 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
