sls-tesla-1 0
SLURM_JOBID=85143
SLURM_TASKID=4
[32m[0328 11:37:17 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=16 --bita=32 --quant_ends=True --load_ckpt=train_log/fcn1_w_16_a_32_quant_ends_False/checkpoint
[32m[0328 11:37:26 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 11:37:26 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 11:37:26 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 11:37:26 @drf_run.py:166][0m Using host: sls-tesla-1
[32m[0328 11:37:26 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 11:37:26 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 11:37:26 @drf_run.py:188][0m Using GPU: 0
[32m[0328 11:37:26 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 11:37:26 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 11:37:26 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 11:37:26 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear0 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear1 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:37:26 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 11:37:26 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:37:26 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0328 11:37:26 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 11:37:26 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0328 11:37:27 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0328 11:37:27 @base.py:196][0m Setup callbacks graph ...
[32m[0328 11:37:28 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:37:28 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:37:28 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0328 11:37:28 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 11:37:28 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0328 11:37:29 @base.py:212][0m Creating the session ...
2018-03-28 11:37:30.038317: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-03-28 11:37:31.580087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:05:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-28 11:37:31.580132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:05:00.0, compute capability: 6.1)
[32m[0328 11:37:36 @base.py:220][0m Initializing the session ...
[32m[0328 11:37:36 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn1_w_16_a_32_quant_ends_False/model-10408860 ...
[32m[0328 11:37:36 @base.py:227][0m Graph Finalized.
[32m[0328 11:37:36 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 11:37:36 @steps.py:127][0m Start training with global_step=10408860
[32m[0328 11:37:39 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15373/173481[03:00<30:51,85.40it/s]  9%|9         |16251/173481[03:10<30:41,85.40it/s] 18%|#8        |31261/173481[06:00<27:18,86.81it/s] 19%|#8        |32174/173481[06:10<27:07,86.81it/s] 27%|##7       |47411/173481[09:00<23:48,88.24it/s] 28%|##7       |48330/173481[09:10<23:38,88.24it/s] 34%|###3      |58487/173481[12:00<26:26,72.50it/s] 34%|###4      |59150/173481[12:10<26:16,72.50it/s] 40%|###9      |69194/173481[15:00<26:35,65.35it/s] 40%|####      |69820/173481[15:10<26:26,65.35it/s] 46%|####5     |79497/173481[18:00<25:40,61.03it/s] 46%|####6     |80140/173481[18:10<25:29,61.03it/s] 52%|#####1    |90053/173481[21:00<23:14,59.81it/s] 52%|#####2    |90675/173481[21:11<23:04,59.81it/s] 58%|#####7    |100556/173481[24:00<20:34,59.07it/s] 58%|#####8    |101230/173481[24:11<20:23,59.07it/s] 64%|######4   |111186/173481[27:00<17:34,59.06it/s] 64%|######4   |111865/173481[27:11<17:23,59.06it/s] 70%|#######   |121563/173481[30:00<14:49,58.35it/s] 70%|#######   |122221/173481[30:11<14:38,58.35it/s] 76%|#######6  |132116/173481[33:00<11:47,58.48it/s] 77%|#######6  |132810/173481[33:11<11:35,58.48it/s] 82%|########2 |142824/173481[36:00<08:39,58.98it/s] 83%|########2 |143524/173481[36:11<08:27,58.98it/s] 88%|########8 |152751/173481[39:00<06:03,57.00it/s] 88%|########8 |153364/173481[39:11<05:52,57.00it/s] 94%|#########3|162231/173481[42:00<03:25,54.74it/s] 94%|#########3|162895/173481[42:12<03:13,54.74it/s] 99%|#########9|172426/173481[45:00<00:18,55.67it/s]100%|#########9|173095/173481[45:12<00:06,55.67it/s]100%|##########|173481/173481[45:20<00:00,63.76it/s]
[32m[0328 12:23:00 @base.py:257][0m Epoch 1 (global_step 10582341) finished, time:2720.74 sec.
[32m[0328 12:23:00 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 49%|####9     |9280/18822[03:00<03:05,51.55it/s] 52%|#####2    |9862/18822[03:10<02:53,51.55it/s]100%|##########|18822/18822[05:22<00:00,58.30it/s]
0
[32m[0328 12:28:23 @monitor.py:363][0m QueueInput/queue_size: 1.6955
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.653
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/output-rms: 0.035297
[32m[0328 12:28:23 @monitor.py:363][0m cross_entropy_loss: 2.5518
[32m[0328 12:28:23 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 12:28:23 @monitor.py:363][0m train-error-top1: 0.62154
[32m[0328 12:28:23 @monitor.py:363][0m val-error-top1: 0.62661
[32m[0328 12:28:23 @monitor.py:363][0m val-utt-error: 0.25709
[32m[0328 12:28:23 @monitor.py:363][0m validation_cost: 2.5793
[32m[0328 12:28:23 @monitor.py:363][0m wd_cost: 2.8783e-15
[32m[0328 12:28:23 @group.py:42][0m Callbacks took 323.293 sec in total. InferenceRunner: 322.850sec
[32m[0328 12:28:23 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10590/173481[03:00<46:09,58.82it/s]  6%|6         |11124/173481[03:10<46:00,58.82it/s] 12%|#1        |20815/173481[06:00<44:01,57.79it/s] 12%|#2        |21412/173481[06:10<43:51,57.79it/s] 18%|#7        |30835/173481[09:00<41:55,56.71it/s] 18%|#8        |31390/173481[09:10<41:45,56.71it/s] 23%|##2       |39877/173481[12:00<41:47,53.27it/s] 23%|##3       |40414/173481[12:10<41:37,53.27it/s] 28%|##8       |49148/173481[15:00<39:33,52.37it/s] 29%|##8       |49714/173481[15:10<39:23,52.37it/s] 34%|###4      |59165/173481[18:00<35:18,53.95it/s] 34%|###4      |59779/173481[18:10<35:07,53.95it/s] 40%|###9      |69124/173481[21:00<31:50,54.63it/s] 40%|####      |69727/173481[21:11<31:39,54.63it/s] 46%|####5     |79370/173481[24:00<28:08,55.75it/s] 46%|####6     |80010/173481[24:11<27:56,55.75it/s] 52%|#####1    |89620/173481[27:00<24:48,56.33it/s] 52%|#####2    |90237/173481[27:11<24:37,56.33it/s] 58%|#####7    |99768/173481[30:00<21:48,56.36it/s] 58%|#####7    |100387/173481[30:11<21:37,56.36it/s] 63%|######3   |109865/173481[33:00<18:51,56.22it/s] 64%|######3   |110491/173481[33:11<18:40,56.22it/s] 69%|######9   |119777/173481[36:00<16:05,55.64it/s] 69%|######9   |120444/173481[36:11<15:53,55.64it/s] 75%|#######4  |129615/173481[39:00<13:15,55.13it/s] 75%|#######5  |130219/173481[39:11<13:04,55.13it/s] 80%|########  |139421/173481[42:00<10:21,54.80it/s] 81%|########  |140104/173481[42:12<10:09,54.80it/s] 86%|########6 |149455/173481[45:00<07:14,55.26it/s] 87%|########6 |150130/173481[45:12<07:02,55.26it/s] 92%|#########2|159627/173481[48:00<04:07,55.88it/s] 92%|#########2|160289/173481[48:12<03:56,55.88it/s] 98%|#########7|169779/173481[51:00<01:05,56.14it/s] 98%|#########8|170469/173481[51:12<00:53,56.14it/s]100%|##########|173481/173481[52:04<00:00,55.52it/s]
[32m[0328 13:20:28 @base.py:257][0m Epoch 2 (global_step 10755822) finished, time:3124.86 sec.
[32m[0328 13:20:29 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-10755822.
[32m[0328 13:20:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.12it/s]
1
[32m[0328 13:22:23 @monitor.py:363][0m QueueInput/queue_size: 0.80222
[32m[0328 13:22:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.831
[32m[0328 13:22:23 @monitor.py:363][0m activation-summaries/output-rms: 0.03574
[32m[0328 13:22:23 @monitor.py:363][0m cross_entropy_loss: 2.5793
[32m[0328 13:22:23 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 13:22:23 @monitor.py:363][0m train-error-top1: 0.62741
[32m[0328 13:22:23 @monitor.py:363][0m val-error-top1: 0.62807
[32m[0328 13:22:23 @monitor.py:363][0m val-utt-error: 0.2606
[32m[0328 13:22:23 @monitor.py:363][0m validation_cost: 2.5943
[32m[0328 13:22:23 @monitor.py:363][0m wd_cost: 2.8783e-15
[32m[0328 13:22:23 @group.py:42][0m Callbacks took 114.725 sec in total. InferenceRunner: 114.007sec
[32m[0328 13:22:23 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11964/173481[03:00<40:30,66.45it/s]  7%|7         |12603/173481[03:10<40:20,66.45it/s] 13%|#3        |22739/173481[06:00<39:53,62.98it/s] 13%|#3        |23335/173481[06:10<39:43,62.98it/s] 19%|#8        |32156/173481[09:00<41:12,57.16it/s] 19%|#8        |32739/173481[09:10<41:02,57.16it/s] 24%|##4       |41684/173481[12:00<39:58,54.96it/s] 24%|##4       |42243/173481[12:10<39:47,54.96it/s] 29%|##9       |51105/173481[15:00<38:02,53.62it/s] 30%|##9       |51648/173481[15:10<37:52,53.62it/s] 35%|###4      |60404/173481[18:00<35:49,52.61it/s] 35%|###5      |60968/173481[18:10<35:38,52.61it/s] 41%|####      |70593/173481[21:00<31:26,54.54it/s] 41%|####1     |71241/173481[21:10<31:14,54.54it/s] 47%|####6     |80799/173481[24:00<27:47,55.59it/s] 47%|####6     |81442/173481[24:11<27:35,55.59it/s] 53%|#####2    |91287/173481[27:00<24:04,56.90it/s] 53%|#####2    |91918/173481[27:11<23:53,56.90it/s] 59%|#####8    |101539/173481[30:00<21:04,56.92it/s] 59%|#####8    |102173/173481[30:11<20:52,56.92it/s] 65%|######4   |111968/173481[33:00<17:51,57.42it/s] 65%|######4   |112668/173481[33:11<17:39,57.42it/s] 71%|#######   |122436/173481[36:00<14:43,57.79it/s] 71%|#######   |123079/173481[36:11<14:32,57.79it/s] 77%|#######6  |132879/173481[39:00<11:41,57.90it/s] 77%|#######6  |133448/173481[39:11<11:31,57.90it/s] 83%|########2 |143256/173481[42:00<08:43,57.77it/s] 83%|########2 |143967/173481[42:12<08:30,57.77it/s] 89%|########8 |153863/173481[45:00<05:36,58.34it/s] 89%|########9 |154579/173481[45:12<05:23,58.34it/s] 95%|#########4|164639/173481[48:00<02:29,59.09it/s] 95%|#########5|165359/173481[48:12<02:17,59.09it/s]100%|##########|173481/173481[50:25<00:00,57.34it/s]
[32m[0328 14:12:49 @base.py:257][0m Epoch 3 (global_step 10929303) finished, time:3025.51 sec.
[32m[0328 14:12:49 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.48it/s]
2
[32m[0328 14:14:53 @monitor.py:363][0m QueueInput/queue_size: 0.81917
[32m[0328 14:14:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.669
[32m[0328 14:14:53 @monitor.py:363][0m activation-summaries/output-rms: 0.034968
[32m[0328 14:14:53 @monitor.py:363][0m cross_entropy_loss: 2.5824
[32m[0328 14:14:53 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 14:14:53 @monitor.py:363][0m train-error-top1: 0.62927
[32m[0328 14:14:53 @monitor.py:363][0m val-error-top1: 0.62862
[32m[0328 14:14:53 @monitor.py:363][0m val-utt-error: 0.25831
[32m[0328 14:14:53 @monitor.py:363][0m validation_cost: 2.5946
[32m[0328 14:14:53 @monitor.py:363][0m wd_cost: 2.8783e-15
[32m[0328 14:14:53 @group.py:42][0m Callbacks took 124.572 sec in total. InferenceRunner: 124.268sec
[32m[0328 14:14:53 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12494/173481[03:00<38:39,69.41it/s]  8%|7         |13037/173481[03:10<38:31,69.41it/s] 13%|#2        |21949/173481[06:00<42:14,59.80it/s] 13%|#2        |22491/173481[06:10<42:04,59.80it/s] 18%|#8        |31373/173481[09:00<42:25,55.82it/s] 18%|#8        |31932/173481[09:10<42:15,55.82it/s] 24%|##3       |41487/173481[12:00<39:16,56.00it/s] 24%|##4       |42068/173481[12:10<39:06,56.00it/s] 30%|##9       |51761/173481[15:00<35:53,56.53it/s] 30%|###       |52400/173481[15:10<35:41,56.53it/s] 35%|###5      |61320/173481[18:00<34:08,54.77it/s] 36%|###5      |61891/173481[18:10<33:57,54.77it/s] 41%|####1     |71464/173481[21:00<30:36,55.55it/s] 42%|####1     |72047/173481[21:10<30:26,55.55it/s] 47%|####7     |81627/173481[24:00<27:20,56.00it/s] 47%|####7     |82222/173481[24:11<27:09,56.00it/s] 53%|#####2    |91334/173481[27:00<24:55,54.94it/s] 53%|#####2    |91887/173481[27:11<24:45,54.94it/s] 58%|#####8    |101283/173481[30:00<21:50,55.10it/s] 59%|#####8    |101932/173481[30:11<21:38,55.10it/s] 65%|######4   |112178/173481[33:00<17:42,57.68it/s] 65%|######5   |112832/173481[33:11<17:31,57.68it/s] 71%|#######   |123003/173481[36:00<14:17,58.88it/s] 71%|#######1  |123675/173481[36:11<14:05,58.88it/s] 77%|#######7  |133589/173481[39:00<11:17,58.84it/s] 77%|#######7  |134322/173481[39:11<11:05,58.84it/s] 83%|########2 |143888/173481[42:00<08:30,58.01it/s] 83%|########3 |144552/173481[42:12<08:18,58.01it/s] 89%|########8 |154084/173481[45:00<05:38,57.32it/s] 89%|########9 |154812/173481[45:12<05:25,57.32it/s] 95%|#########4|164521/173481[48:00<02:35,57.65it/s] 95%|#########5|165202/173481[48:12<02:23,57.65it/s]100%|##########|173481/173481[50:55<00:00,56.77it/s]
[32m[0328 15:05:49 @base.py:257][0m Epoch 4 (global_step 11102784) finished, time:3056.00 sec.
[32m[0328 15:05:49 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.66it/s]
3
[32m[0328 15:07:50 @monitor.py:363][0m QueueInput/queue_size: 0.99889
[32m[0328 15:07:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.57
[32m[0328 15:07:50 @monitor.py:363][0m activation-summaries/output-rms: 0.034284
[32m[0328 15:07:50 @monitor.py:363][0m cross_entropy_loss: 2.6096
[32m[0328 15:07:50 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 15:07:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 15:07:50 @monitor.py:363][0m train-error-top1: 0.63933
[32m[0328 15:07:50 @monitor.py:363][0m val-error-top1: 0.62718
[32m[0328 15:07:50 @monitor.py:363][0m val-utt-error: 0.25916
[32m[0328 15:07:50 @monitor.py:363][0m validation_cost: 2.5793
[32m[0328 15:07:50 @monitor.py:363][0m wd_cost: 5.7566e-16
[32m[0328 15:07:50 @group.py:42][0m Callbacks took 120.480 sec in total. InferenceRunner: 120.160sec
[32m[0328 15:07:50 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10626/173481[03:00<45:58,59.03it/s]  6%|6         |11086/173481[03:10<45:51,59.03it/s] 12%|#1        |20609/173481[06:00<44:33,57.19it/s] 12%|#2        |21181/173481[06:10<44:23,57.19it/s] 18%|#7        |30847/173481[09:00<41:40,57.03it/s] 18%|#8        |31461/173481[09:10<41:30,57.03it/s] 24%|##3       |41037/173481[12:00<38:50,56.82it/s] 24%|##4       |41641/173481[12:10<38:40,56.82it/s] 29%|##9       |50800/173481[15:00<36:50,55.50it/s] 30%|##9       |51432/173481[15:10<36:39,55.50it/s] 35%|###5      |61349/173481[18:00<32:46,57.01it/s] 36%|###5      |61991/173481[18:10<32:35,57.01it/s] 41%|####1     |71487/173481[21:00<30:00,56.66it/s] 42%|####1     |72097/173481[21:11<29:49,56.66it/s] 47%|####6     |80988/173481[24:00<28:12,54.65it/s] 47%|####7     |81561/173481[24:11<28:01,54.65it/s] 52%|#####2    |90352/173481[27:00<25:59,53.30it/s] 52%|#####2    |90986/173481[27:11<25:47,53.30it/s] 58%|#####7    |99923/173481[30:00<23:01,53.24it/s] 58%|#####7    |100517/173481[30:11<22:50,53.24it/s] 63%|######3   |109514/173481[33:00<20:01,53.26it/s] 63%|######3   |110136/173481[33:11<19:49,53.26it/s] 69%|######8   |119392/173481[36:00<16:40,54.05it/s] 69%|######9   |120031/173481[36:11<16:28,54.05it/s] 74%|#######4  |129117/173481[39:00<13:41,54.04it/s] 75%|#######4  |129786/173481[39:11<13:28,54.04it/s] 80%|#######9  |138588/173481[42:00<10:54,53.32it/s] 80%|########  |139202/173481[42:12<10:42,53.32it/s] 86%|########5 |148673/173481[45:00<07:34,54.64it/s] 86%|########6 |149353/173481[45:12<07:21,54.64it/s] 92%|#########1|158807/173481[48:00<04:24,55.45it/s] 92%|#########1|159441/173481[48:12<04:13,55.45it/s] 97%|#########6|168220/173481[51:00<01:37,53.83it/s] 97%|#########7|168871/173481[51:12<01:25,53.83it/s]100%|##########|173481/173481[52:40<00:00,54.89it/s]
[32m[0328 16:00:30 @base.py:257][0m Epoch 5 (global_step 11276265) finished, time:3160.81 sec.
[32m[0328 16:00:31 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-11276265.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.53it/s]
4
[32m[0328 16:02:33 @monitor.py:363][0m QueueInput/queue_size: 0.74432
[32m[0328 16:02:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.798
[32m[0328 16:02:33 @monitor.py:363][0m activation-summaries/output-rms: 0.03621
[32m[0328 16:02:33 @monitor.py:363][0m cross_entropy_loss: 2.5395
[32m[0328 16:02:33 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 16:02:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 16:02:33 @monitor.py:363][0m train-error-top1: 0.6256
[32m[0328 16:02:33 @monitor.py:363][0m val-error-top1: 0.62752
[32m[0328 16:02:33 @monitor.py:363][0m val-utt-error: 0.26033
[32m[0328 16:02:33 @monitor.py:363][0m validation_cost: 2.5852
[32m[0328 16:02:33 @monitor.py:363][0m wd_cost: 5.7566e-16
[32m[0328 16:02:33 @group.py:42][0m Callbacks took 122.150 sec in total. InferenceRunner: 121.814sec
[32m[0328 16:02:33 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11997/173481[03:00<40:22,66.65it/s]  7%|7         |12605/173481[03:10<40:13,66.65it/s] 13%|#3        |22576/173481[06:00<40:15,62.46it/s] 13%|#3        |23200/173481[06:10<40:05,62.46it/s] 19%|#8        |32701/173481[09:00<39:38,59.19it/s] 19%|#9        |33245/173481[09:10<39:29,59.19it/s] 24%|##4       |41676/173481[12:00<40:35,54.12it/s] 24%|##4       |42213/173481[12:10<40:25,54.12it/s] 29%|##9       |50681/173481[15:00<39:21,51.99it/s] 30%|##9       |51185/173481[15:10<39:12,51.99it/s] 35%|###4      |60054/173481[18:00<36:19,52.03it/s] 35%|###4      |60603/173481[18:10<36:09,52.03it/s] 40%|####      |69946/173481[21:00<32:17,53.45it/s] 41%|####      |70475/173481[21:11<32:07,53.45it/s] 46%|####5     |79246/173481[24:00<29:53,52.54it/s] 46%|####5     |79785/173481[24:11<29:43,52.54it/s] 51%|#####     |88166/173481[27:00<27:52,51.00it/s] 51%|#####1    |88700/173481[27:11<27:42,51.00it/s] 56%|#####6    |97150/173481[30:00<25:12,50.45it/s] 56%|#####6    |97687/173481[30:11<25:02,50.45it/s] 61%|######1   |105865/173481[33:00<22:48,49.41it/s] 61%|######1   |106425/173481[33:11<22:37,49.41it/s] 66%|######6   |114736/173481[36:00<19:50,49.34it/s] 66%|######6   |115326/173481[36:11<19:38,49.34it/s] 72%|#######1  |124081/173481[39:00<16:16,50.59it/s] 72%|#######1  |124686/173481[39:11<16:04,50.59it/s] 77%|#######6  |133108/173481[42:00<13:21,50.37it/s] 77%|#######7  |133695/173481[42:11<13:09,50.37it/s] 82%|########2 |142288/173481[45:00<10:15,50.68it/s] 82%|########2 |142910/173481[45:12<10:03,50.68it/s] 87%|########7 |151436/173481[48:00<07:14,50.74it/s] 88%|########7 |152081/173481[48:12<07:01,50.74it/s] 93%|#########2|160946/173481[51:00<04:02,51.76it/s] 93%|#########3|161550/173481[51:12<03:50,51.76it/s] 98%|#########7|169583/173481[54:00<01:18,49.80it/s] 98%|#########8|170140/173481[54:12<01:07,49.80it/s]100%|##########|173481/173481[55:22<00:00,52.22it/s]
[32m[0328 16:57:55 @base.py:257][0m Epoch 6 (global_step 11449746) finished, time:3322.27 sec.
[32m[0328 16:57:55 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.46it/s]
5
[32m[0328 16:59:56 @monitor.py:363][0m QueueInput/queue_size: 0.77884
[32m[0328 16:59:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.653
[32m[0328 16:59:56 @monitor.py:363][0m activation-summaries/output-rms: 0.035298
[32m[0328 16:59:56 @monitor.py:363][0m cross_entropy_loss: 2.5516
[32m[0328 16:59:56 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 16:59:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 16:59:56 @monitor.py:363][0m train-error-top1: 0.62153
[32m[0328 16:59:56 @monitor.py:363][0m val-error-top1: 0.62657
[32m[0328 16:59:56 @monitor.py:363][0m val-utt-error: 0.25709
[32m[0328 16:59:56 @monitor.py:363][0m validation_cost: 2.579
[32m[0328 16:59:56 @monitor.py:363][0m wd_cost: 5.7566e-16
[32m[0328 16:59:56 @group.py:42][0m Callbacks took 120.739 sec in total. InferenceRunner: 120.310sec
[32m[0328 16:59:56 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10935/173481[03:00<44:36,60.74it/s]  7%|6         |11488/173481[03:10<44:27,60.74it/s] 12%|#1        |20125/173481[06:00<46:04,55.47it/s] 12%|#1        |20631/173481[06:10<45:55,55.47it/s] 17%|#6        |29289/173481[09:00<45:15,53.09it/s] 17%|#7        |29829/173481[09:10<45:05,53.09it/s] 22%|##1       |37890/173481[12:00<44:55,50.30it/s] 22%|##2       |38364/173481[12:10<44:46,50.30it/s] 27%|##6       |46222/173481[15:00<43:59,48.21it/s] 27%|##6       |46729/173481[15:10<43:49,48.21it/s] 32%|###1      |54889/173481[18:00<41:01,48.18it/s] 32%|###1      |55435/173481[18:10<40:50,48.18it/s] 37%|###6      |63910/173481[21:00<37:10,49.13it/s] 37%|###7      |64395/173481[21:11<37:00,49.13it/s] 42%|####2     |73070/173481[24:00<33:28,49.98it/s] 42%|####2     |73631/173481[24:11<33:17,49.98it/s] 47%|####7     |82358/173481[27:00<29:54,50.78it/s] 48%|####7     |82934/173481[27:11<29:43,50.78it/s] 53%|#####2    |91829/173481[30:00<26:19,51.68it/s] 53%|#####3    |92409/173481[30:11<26:08,51.68it/s] 58%|#####8    |101260/173481[33:00<23:08,52.03it/s] 59%|#####8    |101850/173481[33:11<22:56,52.03it/s] 64%|######3   |110605/173481[36:00<20:09,51.96it/s] 64%|######4   |111200/173481[36:11<19:58,51.96it/s] 69%|######8   |119570/173481[39:00<17:40,50.86it/s] 69%|######9   |120126/173481[39:11<17:29,50.86it/s] 74%|#######4  |128570/173481[42:00<14:50,50.42it/s] 74%|#######4  |129135/173481[42:12<14:39,50.42it/s] 79%|#######9  |137325/173481[45:00<12:10,49.51it/s] 79%|#######9  |137904/173481[45:12<11:58,49.51it/s] 84%|########4 |146195/173481[48:00<09:12,49.39it/s] 85%|########4 |146811/173481[48:12<08:59,49.39it/s] 90%|########9 |155332/173481[51:00<06:02,50.07it/s] 90%|########9 |155953/173481[51:12<05:50,50.07it/s] 95%|#########4|164777/173481[54:00<02:49,51.24it/s] 95%|#########5|165419/173481[54:12<02:37,51.24it/s]100%|##########|173481/173481[56:36<00:00,51.07it/s]
[32m[0328 17:56:32 @base.py:257][0m Epoch 7 (global_step 11623227) finished, time:3396.60 sec.
[32m[0328 17:56:32 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-11623227.
[32m[0328 17:56:33 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.58it/s]
6
[32m[0328 17:58:32 @monitor.py:363][0m QueueInput/queue_size: 0.80854
[32m[0328 17:58:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.831
[32m[0328 17:58:32 @monitor.py:363][0m activation-summaries/output-rms: 0.03574
[32m[0328 17:58:32 @monitor.py:363][0m cross_entropy_loss: 2.5791
[32m[0328 17:58:32 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 17:58:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 17:58:32 @monitor.py:363][0m train-error-top1: 0.6273
[32m[0328 17:58:32 @monitor.py:363][0m val-error-top1: 0.62804
[32m[0328 17:58:32 @monitor.py:363][0m val-utt-error: 0.26044
[32m[0328 17:58:32 @monitor.py:363][0m validation_cost: 2.5942
[32m[0328 17:58:32 @monitor.py:363][0m wd_cost: 1.1513e-16
[32m[0328 17:58:32 @group.py:42][0m Callbacks took 119.412 sec in total. InferenceRunner: 118.703sec
[32m[0328 17:58:32 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12848/173481[03:00<37:30,71.38it/s]  8%|7         |13438/173481[03:10<37:22,71.38it/s] 13%|#3        |22954/173481[06:00<39:55,62.84it/s] 14%|#3        |23492/173481[06:10<39:46,62.84it/s] 18%|#8        |31814/173481[09:00<42:46,55.20it/s] 19%|#8        |32360/173481[09:10<42:36,55.20it/s] 24%|##3       |41252/173481[12:00<40:58,53.78it/s] 24%|##4       |41818/173481[12:10<40:48,53.78it/s] 29%|##9       |50889/173481[15:00<38:04,53.66it/s] 30%|##9       |51438/173481[15:10<37:54,53.66it/s] 35%|###4      |60140/173481[18:00<35:58,52.50it/s] 35%|###4      |60688/173481[18:10<35:48,52.50it/s] 40%|####      |70093/173481[21:00<31:59,53.86it/s] 41%|####      |70768/173481[21:11<31:46,53.86it/s] 47%|####6     |80904/173481[24:00<27:10,56.79it/s] 47%|####6     |81513/173481[24:11<26:59,56.79it/s] 52%|#####2    |90453/173481[27:00<25:13,54.86it/s] 52%|#####2    |91068/173481[27:11<25:02,54.86it/s] 58%|#####7    |99967/173481[30:00<22:45,53.84it/s] 58%|#####7    |100570/173481[30:11<22:34,53.84it/s] 63%|######3   |109505/173481[33:00<19:57,53.41it/s] 63%|######3   |110114/173481[33:11<19:46,53.41it/s] 69%|######8   |119424/173481[36:00<16:36,54.24it/s] 69%|######9   |120115/173481[36:11<16:23,54.24it/s] 75%|#######4  |129534/173481[39:00<13:16,55.18it/s] 75%|#######5  |130182/173481[39:12<13:04,55.18it/s] 81%|########  |139857/173481[42:00<09:57,56.24it/s] 81%|########1 |140538/173481[42:12<09:45,56.24it/s] 86%|########6 |149889/173481[45:00<07:01,55.99it/s] 87%|########6 |150535/173481[45:12<06:49,55.99it/s] 92%|#########2|159807/173481[48:00<04:06,55.54it/s] 93%|#########2|160488/173481[48:12<03:53,55.54it/s] 98%|#########7|169813/173481[51:00<01:06,55.56it/s] 98%|#########8|170478/173481[51:12<00:54,55.56it/s]100%|##########|173481/173481[52:06<00:00,55.48it/s]
[32m[0328 18:50:38 @base.py:257][0m Epoch 8 (global_step 11796708) finished, time:3126.74 sec.
[32m[0328 18:50:39 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.97it/s]
7
[32m[0328 18:52:43 @monitor.py:363][0m QueueInput/queue_size: 0.69548
[32m[0328 18:52:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.669
[32m[0328 18:52:43 @monitor.py:363][0m activation-summaries/output-rms: 0.034969
[32m[0328 18:52:43 @monitor.py:363][0m cross_entropy_loss: 2.5823
[32m[0328 18:52:43 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 18:52:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 18:52:43 @monitor.py:363][0m train-error-top1: 0.62964
[32m[0328 18:52:43 @monitor.py:363][0m val-error-top1: 0.62861
[32m[0328 18:52:43 @monitor.py:363][0m val-utt-error: 0.25826
[32m[0328 18:52:43 @monitor.py:363][0m validation_cost: 2.5945
[32m[0328 18:52:43 @monitor.py:363][0m wd_cost: 1.1513e-16
[32m[0328 18:52:43 @group.py:42][0m Callbacks took 125.024 sec in total. InferenceRunner: 124.687sec
[32m[0328 18:52:43 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12377/173481[03:00<39:03,68.76it/s]  7%|7         |12947/173481[03:10<38:54,68.76it/s] 12%|#2        |21491/173481[06:00<43:26,58.32it/s] 13%|#2        |22061/173481[06:10<43:16,58.32it/s] 18%|#8        |31617/173481[09:00<41:17,57.27it/s] 19%|#8        |32231/173481[09:10<41:06,57.27it/s] 24%|##4       |42337/173481[12:00<37:26,58.39it/s] 25%|##4       |43012/173481[12:10<37:14,58.39it/s] 31%|###1      |54002/173481[15:00<32:24,61.43it/s] 31%|###1      |54603/173481[15:10<32:15,61.43it/s] 38%|###7      |65190/173481[18:00<29:12,61.79it/s] 38%|###7      |65882/173481[18:10<29:01,61.79it/s] 44%|####4     |76460/173481[21:00<25:59,62.20it/s] 44%|####4     |77158/173481[21:11<25:48,62.20it/s] 50%|#####     |87196/173481[24:00<23:36,60.89it/s] 51%|#####     |87892/173481[24:11<23:25,60.89it/s] 57%|#####6    |98303/173481[27:00<20:26,61.29it/s] 57%|#####7    |99002/173481[27:11<20:15,61.29it/s] 63%|######3   |109358/173481[30:00<17:25,61.35it/s] 63%|######3   |110064/173481[30:11<17:13,61.35it/s] 69%|######9   |120423/173481[33:00<14:24,61.41it/s] 70%|######9   |121119/173481[33:11<14:12,61.41it/s] 76%|#######5  |131449/173481[36:00<11:25,61.33it/s] 76%|#######6  |132177/173481[36:11<11:13,61.33it/s] 82%|########2 |142764/173481[39:00<08:14,62.09it/s] 83%|########2 |143512/173481[39:11<08:02,62.09it/s] 89%|########8 |154072/173481[42:00<05:10,62.45it/s] 89%|########9 |154832/173481[42:12<04:58,62.45it/s] 95%|#########5|165258/173481[45:00<02:12,62.29it/s] 96%|#########5|165962/173481[45:12<02:00,62.29it/s]100%|##########|173481/173481[47:21<00:00,61.05it/s]
[32m[0328 19:40:05 @base.py:257][0m Epoch 9 (global_step 11970189) finished, time:2841.75 sec.
[32m[0328 19:40:05 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,149.98it/s]
8
[32m[0328 19:42:11 @monitor.py:363][0m QueueInput/queue_size: 0.74631
[32m[0328 19:42:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.57
[32m[0328 19:42:11 @monitor.py:363][0m activation-summaries/output-rms: 0.034284
[32m[0328 19:42:11 @monitor.py:363][0m cross_entropy_loss: 2.6095
[32m[0328 19:42:11 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 19:42:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 19:42:11 @monitor.py:363][0m train-error-top1: 0.63933
[32m[0328 19:42:11 @monitor.py:363][0m val-error-top1: 0.62717
[32m[0328 19:42:11 @monitor.py:363][0m val-utt-error: 0.25916
[32m[0328 19:42:11 @monitor.py:363][0m validation_cost: 2.5792
[32m[0328 19:42:11 @monitor.py:363][0m wd_cost: 1.1513e-16
[32m[0328 19:42:11 @group.py:42][0m Callbacks took 125.834 sec in total. InferenceRunner: 125.505sec
[32m[0328 19:42:11 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13172/173481[03:00<36:30,73.18it/s]  8%|7         |13804/173481[03:10<36:22,73.18it/s] 14%|#3        |23887/173481[06:00<37:59,65.64it/s] 14%|#4        |24531/173481[06:10<37:49,65.64it/s] 20%|##        |35152/173481[09:00<35:58,64.07it/s] 21%|##        |35809/173481[09:10<35:48,64.07it/s] 27%|##6       |46327/173481[12:00<33:36,63.06it/s] 27%|##7       |46951/173481[12:10<33:26,63.06it/s] 33%|###2      |57130/173481[15:00<31:31,61.50it/s] 33%|###3      |57751/173481[15:10<31:21,61.50it/s] 39%|###9      |67882/173481[18:00<29:02,60.60it/s] 40%|###9      |68536/173481[18:10<28:51,60.60it/s] 45%|####5     |78862/173481[21:00<25:56,60.80it/s] 46%|####5     |79551/173481[21:10<25:44,60.80it/s] 52%|#####1    |90103/173481[24:00<22:33,61.61it/s] 52%|#####2    |90737/173481[24:11<22:23,61.61it/s] 58%|#####7    |100368/173481[27:00<20:34,59.23it/s] 58%|#####8    |101011/173481[27:11<20:23,59.23it/s] 64%|######3   |110623/173481[30:00<18:02,58.08it/s] 64%|######4   |111248/173481[30:11<17:51,58.08it/s] 69%|######9   |120495/173481[33:00<15:39,56.41it/s] 70%|######9   |121154/173481[33:11<15:27,56.41it/s] 75%|#######5  |130564/173481[36:00<12:43,56.17it/s] 76%|#######5  |131236/173481[36:11<12:32,56.17it/s] 81%|########1 |141242/173481[39:00<09:18,57.70it/s] 82%|########1 |141931/173481[39:11<09:06,57.70it/s] 88%|########7 |152283/173481[42:00<05:56,59.46it/s] 88%|########8 |152996/173481[42:12<05:44,59.46it/s] 94%|#########3|162942/173481[45:00<02:57,59.34it/s] 94%|#########4|163591/173481[45:12<02:46,59.34it/s]100%|#########9|173060/173481[48:00<00:07,57.73it/s]100%|##########|173481/173481[48:08<00:00,60.06it/s]
[32m[0328 20:30:19 @base.py:257][0m Epoch 10 (global_step 12143670) finished, time:2888.29 sec.
[32m[0328 20:30:20 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-12143670.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.42it/s]
9
[32m[0328 20:32:22 @monitor.py:363][0m QueueInput/queue_size: 0.72858
[32m[0328 20:32:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.798
[32m[0328 20:32:22 @monitor.py:363][0m activation-summaries/output-rms: 0.03621
[32m[0328 20:32:22 @monitor.py:363][0m cross_entropy_loss: 2.5395
[32m[0328 20:32:22 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 20:32:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 20:32:22 @monitor.py:363][0m train-error-top1: 0.6256
[32m[0328 20:32:22 @monitor.py:363][0m val-error-top1: 0.62751
[32m[0328 20:32:22 @monitor.py:363][0m val-utt-error: 0.26033
[32m[0328 20:32:22 @monitor.py:363][0m validation_cost: 2.5852
[32m[0328 20:32:22 @monitor.py:363][0m wd_cost: 2.3026e-17
[32m[0328 20:32:22 @group.py:42][0m Callbacks took 123.094 sec in total. InferenceRunner: 122.700sec
[32m[0328 20:32:22 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13176/173481[03:00<36:30,73.19it/s]  8%|7         |13809/173481[03:10<36:21,73.19it/s] 14%|#4        |24303/173481[06:00<37:05,67.02it/s] 14%|#4        |24942/173481[06:10<36:56,67.02it/s] 20%|##        |35243/173481[09:00<36:08,63.75it/s] 21%|##        |35863/173481[09:10<35:58,63.75it/s] 26%|##6       |45901/173481[12:00<34:38,61.39it/s] 27%|##6       |46542/173481[12:10<34:27,61.39it/s] 33%|###2      |56560/173481[15:00<32:19,60.28it/s] 33%|###2      |57231/173481[15:10<32:08,60.28it/s] 39%|###8      |67551/173481[18:00<29:06,60.66it/s] 39%|###9      |68170/173481[18:10<28:56,60.66it/s] 45%|####4     |77871/173481[21:00<27:01,58.95it/s] 45%|####5     |78527/173481[21:11<26:50,58.95it/s] 51%|#####     |88341/173481[24:00<24:14,58.55it/s] 51%|#####1    |88965/173481[24:11<24:03,58.55it/s] 57%|#####6    |98726/173481[27:00<21:26,58.11it/s] 57%|#####7    |99333/173481[27:11<21:16,58.11it/s] 63%|######2   |109001/173481[30:00<18:39,57.59it/s] 63%|######3   |109680/173481[30:11<18:27,57.59it/s] 69%|######8   |119695/173481[33:00<15:19,58.48it/s] 69%|######9   |120355/173481[33:11<15:08,58.48it/s] 75%|#######5  |130371/173481[36:00<12:11,58.89it/s] 76%|#######5  |131035/173481[36:11<12:00,58.89it/s] 81%|########1 |141101/173481[39:00<09:06,59.24it/s] 82%|########1 |141811/173481[39:11<08:54,59.24it/s] 87%|########7 |151523/173481[42:00<06:14,58.56it/s] 88%|########7 |152226/173481[42:12<06:02,58.56it/s] 93%|#########3|161906/173481[45:00<03:19,58.12it/s] 94%|#########3|162576/173481[45:12<03:07,58.12it/s] 99%|#########9|171993/173481[48:00<00:26,57.06it/s]100%|#########9|172653/173481[48:12<00:14,57.06it/s]100%|##########|173481/173481[48:27<00:00,59.67it/s]
[32m[0328 21:20:50 @base.py:257][0m Epoch 11 (global_step 12317151) finished, time:2907.50 sec.
[32m[0328 21:20:50 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.93it/s]
10
[32m[0328 21:22:53 @monitor.py:363][0m QueueInput/queue_size: 0.62225
[32m[0328 21:22:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.653
[32m[0328 21:22:53 @monitor.py:363][0m activation-summaries/output-rms: 0.035298
[32m[0328 21:22:53 @monitor.py:363][0m cross_entropy_loss: 2.5515
[32m[0328 21:22:53 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 21:22:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 21:22:53 @monitor.py:363][0m train-error-top1: 0.62151
[32m[0328 21:22:53 @monitor.py:363][0m val-error-top1: 0.62657
[32m[0328 21:22:53 @monitor.py:363][0m val-utt-error: 0.25709
[32m[0328 21:22:53 @monitor.py:363][0m validation_cost: 2.579
[32m[0328 21:22:53 @monitor.py:363][0m wd_cost: 2.3026e-17
[32m[0328 21:22:53 @group.py:42][0m Callbacks took 123.471 sec in total. InferenceRunner: 123.090sec
[32m[0328 21:22:53 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12875/173481[03:00<37:26,71.49it/s]  8%|7         |13481/173481[03:10<37:17,71.49it/s] 14%|#3        |23510/173481[06:00<38:38,64.69it/s] 14%|#3        |24107/173481[06:10<38:29,64.69it/s] 20%|#9        |34045/173481[09:00<37:49,61.45it/s] 20%|#9        |34594/173481[09:10<37:40,61.45it/s] 25%|##5       |43668/173481[12:00<37:50,57.18it/s] 26%|##5       |44244/173481[12:10<37:40,57.18it/s] 31%|###1      |53857/173481[15:00<35:02,56.89it/s] 31%|###1      |54490/173481[15:10<34:51,56.89it/s] 37%|###7      |64484/173481[18:00<31:21,57.94it/s] 38%|###7      |65084/173481[18:10<31:10,57.94it/s] 43%|####3     |75455/173481[21:00<27:30,59.41it/s] 44%|####3     |76124/173481[21:10<27:18,59.41it/s] 50%|####9     |86011/173481[24:00<24:41,59.02it/s] 50%|####9     |86644/173481[24:11<24:31,59.02it/s] 56%|#####5    |96556/173481[27:00<21:48,58.80it/s] 56%|#####6    |97161/173481[27:11<21:37,58.80it/s] 62%|######1   |106834/173481[30:00<19:10,57.94it/s] 62%|######1   |107482/173481[30:11<18:59,57.94it/s] 67%|######7   |117080/173481[33:00<16:22,57.42it/s] 68%|######7   |117744/173481[33:11<16:10,57.42it/s] 73%|#######3  |127193/173481[36:00<13:34,56.80it/s] 74%|#######3  |127851/173481[36:11<13:23,56.80it/s] 79%|#######9  |137742/173481[39:00<10:19,57.69it/s] 80%|#######9  |138429/173481[39:11<10:07,57.69it/s] 86%|########5 |148504/173481[42:00<07:05,58.72it/s] 86%|########6 |149224/173481[42:12<06:53,58.72it/s] 92%|#########1|159247/173481[45:00<04:00,59.20it/s] 92%|#########2|159919/173481[45:12<03:49,59.20it/s] 98%|#########7|169815/173481[48:00<01:02,58.94it/s] 98%|#########8|170509/173481[48:12<00:50,58.94it/s]100%|##########|173481/173481[49:03<00:00,58.94it/s]
[32m[0328 22:11:56 @base.py:257][0m Epoch 12 (global_step 12490632) finished, time:2943.18 sec.
[32m[0328 22:11:57 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-12490632.
[32m[0328 22:11:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.47it/s]
11
[32m[0328 22:13:56 @monitor.py:363][0m QueueInput/queue_size: 0.94107
[32m[0328 22:13:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.831
[32m[0328 22:13:56 @monitor.py:363][0m activation-summaries/output-rms: 0.03574
[32m[0328 22:13:56 @monitor.py:363][0m cross_entropy_loss: 2.5791
[32m[0328 22:13:56 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 22:13:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 22:13:56 @monitor.py:363][0m train-error-top1: 0.6273
[32m[0328 22:13:56 @monitor.py:363][0m val-error-top1: 0.62804
[32m[0328 22:13:56 @monitor.py:363][0m val-utt-error: 0.26049
[32m[0328 22:13:56 @monitor.py:363][0m validation_cost: 2.5941
[32m[0328 22:13:56 @monitor.py:363][0m wd_cost: 4.6053e-18
[32m[0328 22:13:56 @group.py:42][0m Callbacks took 120.046 sec in total. InferenceRunner: 119.538sec
[32m[0328 22:13:56 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13869/173481[03:00<34:32,77.03it/s]  8%|8         |14512/173481[03:10<34:23,77.03it/s] 14%|#4        |24549/173481[06:00<37:02,67.03it/s] 14%|#4        |25072/173481[06:10<36:54,67.03it/s] 20%|#9        |34239/173481[09:00<38:52,59.70it/s] 20%|##        |34848/173481[09:10<38:42,59.70it/s] 26%|##5       |44489/173481[12:00<36:52,58.29it/s] 26%|##6       |45106/173481[12:10<36:42,58.29it/s] 32%|###1      |55079/173481[15:00<33:42,58.56it/s] 32%|###2      |55679/173481[15:10<33:31,58.56it/s] 38%|###7      |65672/173481[18:00<30:36,58.70it/s] 38%|###8      |66373/173481[18:10<30:24,58.70it/s] 45%|####4     |77502/173481[21:00<25:47,62.01it/s] 45%|####5     |78243/173481[21:11<25:35,62.01it/s] 51%|#####1    |88561/173481[24:00<22:55,61.72it/s] 51%|#####1    |89228/173481[24:11<22:44,61.72it/s] 57%|#####7    |99099/173481[27:00<20:37,60.09it/s] 57%|#####7    |99748/173481[27:11<20:27,60.09it/s] 63%|######3   |109739/173481[30:00<17:49,59.59it/s] 64%|######3   |110404/173481[30:11<17:38,59.59it/s] 70%|######9   |120599/173481[33:00<14:42,59.95it/s] 70%|######9   |121278/173481[33:11<14:30,59.95it/s] 76%|#######5  |131358/173481[36:00<11:43,59.86it/s] 76%|#######6  |132066/173481[36:11<11:31,59.86it/s] 82%|########2 |142366/173481[39:00<08:34,60.50it/s] 82%|########2 |143088/173481[39:11<08:22,60.50it/s] 88%|########8 |153458/173481[42:00<05:27,61.06it/s] 89%|########8 |154215/173481[42:12<05:15,61.06it/s] 95%|#########4|164796/173481[45:00<02:20,62.01it/s] 95%|#########5|165554/173481[45:12<02:07,62.01it/s]100%|##########|173481/173481[47:13<00:00,61.22it/s]
[32m[0328 23:01:10 @base.py:257][0m Epoch 13 (global_step 12664113) finished, time:2833.81 sec.
[32m[0328 23:01:11 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.89it/s]
12
[32m[0328 23:03:15 @monitor.py:363][0m QueueInput/queue_size: 0.67393
[32m[0328 23:03:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.669
[32m[0328 23:03:15 @monitor.py:363][0m activation-summaries/output-rms: 0.034969
[32m[0328 23:03:15 @monitor.py:363][0m cross_entropy_loss: 2.5823
[32m[0328 23:03:15 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 23:03:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 23:03:15 @monitor.py:363][0m train-error-top1: 0.62964
[32m[0328 23:03:15 @monitor.py:363][0m val-error-top1: 0.62861
[32m[0328 23:03:15 @monitor.py:363][0m val-utt-error: 0.25826
[32m[0328 23:03:15 @monitor.py:363][0m validation_cost: 2.5945
[32m[0328 23:03:15 @monitor.py:363][0m wd_cost: 4.6053e-18
[32m[0328 23:03:15 @group.py:42][0m Callbacks took 125.095 sec in total. InferenceRunner: 124.751sec
[32m[0328 23:03:15 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13630/173481[03:00<35:11,75.72it/s]  8%|8         |14277/173481[03:10<35:02,75.72it/s] 14%|#4        |24336/173481[06:00<37:18,66.62it/s] 14%|#4        |24943/173481[06:10<37:09,66.62it/s] 20%|##        |35338/173481[09:00<36:06,63.75it/s] 21%|##        |35986/173481[09:10<35:56,63.75it/s] 27%|##6       |46623/173481[12:00<33:26,63.22it/s] 27%|##7       |47317/173481[12:10<33:15,63.22it/s] 33%|###3      |57850/173481[15:00<30:41,62.79it/s] 34%|###3      |58512/173481[15:10<30:31,62.79it/s] 40%|###9      |69208/173481[18:00<27:36,62.94it/s] 40%|####      |69907/173481[18:10<27:25,62.94it/s] 46%|####6     |80590/173481[21:00<24:32,63.09it/s] 47%|####6     |81288/173481[21:11<24:21,63.09it/s] 53%|#####2    |91848/173481[24:00<21:39,62.81it/s] 53%|#####3    |92520/173481[24:11<21:28,62.81it/s] 59%|#####9    |103082/173481[27:00<18:44,62.61it/s] 60%|#####9    |103740/173481[27:11<18:33,62.61it/s] 66%|######5   |114218/173481[30:00<15:52,62.23it/s] 66%|######6   |114918/173481[30:11<15:41,62.23it/s] 72%|#######2  |125108/173481[33:00<13:08,61.35it/s] 73%|#######2  |125812/173481[33:11<12:57,61.35it/s] 79%|#######8  |136238/173481[36:00<10:04,61.59it/s] 79%|#######8  |136951/173481[36:11<09:53,61.59it/s] 85%|########5 |147548/173481[39:00<06:56,62.20it/s] 85%|########5 |148278/173481[39:11<06:45,62.20it/s] 92%|#########1|158896/173481[42:00<03:52,62.62it/s] 92%|#########2|159658/173481[42:12<03:40,62.62it/s] 98%|#########7|169738/173481[45:00<01:00,61.40it/s] 98%|#########8|170432/173481[45:12<00:49,61.40it/s]100%|##########|173481/173481[46:04<00:00,62.75it/s]
[32m[0328 23:49:20 @base.py:257][0m Epoch 14 (global_step 12837594) finished, time:2764.74 sec.
[32m[0328 23:49:20 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,151.88it/s]
13
[32m[0328 23:51:24 @monitor.py:363][0m QueueInput/queue_size: 0.86781
[32m[0328 23:51:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.57
[32m[0328 23:51:24 @monitor.py:363][0m activation-summaries/output-rms: 0.034284
[32m[0328 23:51:24 @monitor.py:363][0m cross_entropy_loss: 2.6095
[32m[0328 23:51:24 @monitor.py:363][0m lr: 7.4506e-12
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 23:51:24 @monitor.py:363][0m train-error-top1: 0.63934
[32m[0328 23:51:24 @monitor.py:363][0m val-error-top1: 0.62717
[32m[0328 23:51:24 @monitor.py:363][0m val-utt-error: 0.25916
[32m[0328 23:51:24 @monitor.py:363][0m validation_cost: 2.5792
[32m[0328 23:51:24 @monitor.py:363][0m wd_cost: 4.6053e-18
[32m[0328 23:51:24 @group.py:42][0m Callbacks took 124.269 sec in total. InferenceRunner: 123.945sec
[32m[0328 23:51:24 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13299/173481[03:00<36:08,73.88it/s]  8%|8         |13906/173481[03:10<35:59,73.88it/s] 14%|#3        |24178/173481[06:00<37:25,66.49it/s] 14%|#4        |24822/173481[06:10<37:15,66.49it/s] 21%|##        |35797/173481[09:00<35:02,65.50it/s] 21%|##1       |36470/173481[09:10<34:51,65.50it/s] 27%|##7       |46903/173481[12:00<33:12,63.54it/s] 27%|##7       |47528/173481[12:10<33:02,63.54it/s] 33%|###3      |58050/173481[15:00<30:40,62.72it/s] 34%|###3      |58705/173481[15:10<30:29,62.72it/s] 40%|###9      |69302/173481[18:00<27:43,62.61it/s] 40%|####      |69966/173481[18:10<27:33,62.61it/s] 46%|####6     |80232/173481[21:00<25:12,61.65it/s] 47%|####6     |80892/173481[21:11<25:01,61.65it/s] 53%|#####2    |91167/173481[24:00<22:25,61.19it/s] 53%|#####2    |91821/173481[24:11<22:14,61.19it/s] 59%|#####8    |101987/173481[27:00<19:38,60.64it/s] 59%|#####9    |102676/173481[27:11<19:27,60.64it/s] 65%|######4   |112638/173481[30:00<16:55,59.90it/s] 65%|######5   |113314/173481[30:11<16:44,59.90it/s] 71%|#######1  |123306/173481[33:00<14:02,59.58it/s] 71%|#######1  |124021/173481[33:11<13:50,59.58it/s] 77%|#######7  |134178/173481[36:00<10:55,59.99it/s] 78%|#######7  |134910/173481[36:11<10:42,59.99it/s] 84%|########3 |145083/173481[39:00<07:51,60.28it/s] 84%|########4 |145802/173481[39:12<07:39,60.28it/s] 90%|########9 |156065/173481[42:00<04:47,60.64it/s] 90%|######### |156816/173481[42:12<04:34,60.64it/s] 96%|#########6|166970/173481[45:00<01:47,60.61it/s] 97%|#########6|167714/173481[45:12<01:35,60.61it/s]100%|##########|173481/173481[46:50<00:00,61.73it/s]
[32m[0329 00:38:15 @base.py:257][0m Epoch 15 (global_step 13011075) finished, time:2810.44 sec.
[32m[0329 00:38:15 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-13011075.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.19it/s]
14
[32m[0329 00:40:18 @monitor.py:363][0m QueueInput/queue_size: 0.91941
[32m[0329 00:40:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.798
[32m[0329 00:40:18 @monitor.py:363][0m activation-summaries/output-rms: 0.03621
[32m[0329 00:40:18 @monitor.py:363][0m cross_entropy_loss: 2.5395
[32m[0329 00:40:18 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 00:40:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 00:40:18 @monitor.py:363][0m train-error-top1: 0.6256
[32m[0329 00:40:18 @monitor.py:363][0m val-error-top1: 0.62751
[32m[0329 00:40:18 @monitor.py:363][0m val-utt-error: 0.26033
[32m[0329 00:40:18 @monitor.py:363][0m validation_cost: 2.5852
[32m[0329 00:40:18 @monitor.py:363][0m wd_cost: 9.2106e-19
[32m[0329 00:40:18 @group.py:42][0m Callbacks took 123.282 sec in total. InferenceRunner: 122.877sec
[32m[0329 00:40:18 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13381/173481[03:00<35:54,74.32it/s]  8%|8         |13985/173481[03:10<35:46,74.32it/s] 14%|#3        |24186/173481[06:00<37:27,66.41it/s] 14%|#4        |24812/173481[06:10<37:18,66.41it/s] 20%|##        |34788/173481[09:00<37:01,62.43it/s] 20%|##        |35410/173481[09:10<36:51,62.43it/s] 26%|##6       |45196/173481[12:00<35:36,60.03it/s] 26%|##6       |45805/173481[12:10<35:26,60.03it/s] 32%|###1      |55451/173481[15:00<33:39,58.46it/s] 32%|###2      |56095/173481[15:10<33:28,58.46it/s] 38%|###8      |66147/173481[18:00<30:21,58.94it/s] 39%|###8      |66820/173481[18:10<30:09,58.94it/s] 44%|####4     |76406/173481[21:00<27:55,57.95it/s] 44%|####4     |77044/173481[21:11<27:44,57.95it/s] 50%|#####     |86985/173481[24:00<24:42,58.36it/s] 51%|#####     |87657/173481[24:11<24:30,58.36it/s] 56%|#####6    |97541/173481[27:00<21:38,58.49it/s] 57%|#####6    |98189/173481[27:11<21:27,58.49it/s] 62%|######2   |108016/173481[30:00<18:42,58.34it/s] 63%|######2   |108665/173481[30:11<18:30,58.34it/s] 68%|######8   |118767/173481[33:00<15:26,59.03it/s] 69%|######8   |119467/173481[33:11<15:15,59.03it/s] 75%|#######4  |129572/173481[36:00<12:17,59.52it/s] 75%|#######5  |130261/173481[36:11<12:06,59.52it/s] 81%|########  |140466/173481[39:00<09:10,60.02it/s] 81%|########1 |141215/173481[39:11<08:57,60.02it/s] 87%|########7 |151221/173481[42:00<06:11,59.88it/s] 88%|########7 |151919/173481[42:12<06:00,59.88it/s] 93%|#########3|161486/173481[45:00<03:25,58.42it/s] 93%|#########3|162170/173481[45:12<03:13,58.42it/s] 99%|#########9|171831/173481[48:00<00:28,57.93it/s] 99%|#########9|172520/173481[48:12<00:16,57.93it/s]100%|##########|173481/173481[48:28<00:00,59.64it/s]
[32m[0329 01:28:47 @base.py:257][0m Epoch 16 (global_step 13184556) finished, time:2908.67 sec.
[32m[0329 01:28:47 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.40it/s]
15
[32m[0329 01:30:50 @monitor.py:363][0m QueueInput/queue_size: 0.676
[32m[0329 01:30:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.653
[32m[0329 01:30:50 @monitor.py:363][0m activation-summaries/output-rms: 0.035298
[32m[0329 01:30:50 @monitor.py:363][0m cross_entropy_loss: 2.5515
[32m[0329 01:30:50 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 01:30:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 01:30:50 @monitor.py:363][0m train-error-top1: 0.62151
[32m[0329 01:30:50 @monitor.py:363][0m val-error-top1: 0.62657
[32m[0329 01:30:50 @monitor.py:363][0m val-utt-error: 0.25709
[32m[0329 01:30:50 @monitor.py:363][0m validation_cost: 2.579
[32m[0329 01:30:50 @monitor.py:363][0m wd_cost: 9.2106e-19
[32m[0329 01:30:50 @group.py:42][0m Callbacks took 123.187 sec in total. InferenceRunner: 122.713sec
[32m[0329 01:30:50 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12857/173481[03:00<37:28,71.43it/s]  8%|7         |13470/173481[03:10<37:20,71.43it/s] 13%|#3        |23395/173481[06:00<38:52,64.34it/s] 14%|#3        |24001/173481[06:10<38:43,64.34it/s] 19%|#9        |33540/173481[09:00<38:49,60.08it/s] 20%|#9        |34107/173481[09:10<38:39,60.08it/s] 25%|##4       |43100/173481[12:00<38:32,56.38it/s] 25%|##5       |43679/173481[12:10<38:22,56.38it/s] 31%|###       |53052/173481[15:00<35:57,55.83it/s] 31%|###       |53683/173481[15:10<35:45,55.83it/s] 37%|###6      |63405/173481[18:00<32:22,56.66it/s] 37%|###6      |63959/173481[18:10<32:13,56.66it/s] 43%|####2     |73877/173481[21:00<28:55,57.41it/s] 43%|####2     |74533/173481[21:11<28:43,57.41it/s] 49%|####8     |84445/173481[24:00<25:33,58.04it/s] 49%|####9     |85073/173481[24:11<25:23,58.04it/s] 55%|#####4    |95021/173481[27:00<22:23,58.40it/s] 55%|#####5    |95672/173481[27:11<22:12,58.40it/s] 61%|######    |105447/173481[30:00<19:29,58.16it/s] 61%|######1   |106114/173481[30:11<19:18,58.16it/s] 67%|######6   |115947/173481[33:00<16:27,58.24it/s] 67%|######7   |116600/173481[33:11<16:16,58.24it/s] 73%|#######2  |126479/173481[36:00<13:25,58.38it/s] 73%|#######3  |127163/173481[36:11<13:13,58.38it/s] 79%|#######9  |137090/173481[39:00<10:20,58.66it/s] 79%|#######9  |137774/173481[39:11<10:08,58.66it/s] 85%|########5 |147684/173481[42:00<07:19,58.76it/s] 86%|########5 |148400/173481[42:12<07:06,58.76it/s] 91%|#########1|158636/173481[45:00<04:08,59.78it/s] 92%|#########1|159394/173481[45:12<03:55,59.78it/s] 98%|#########7|169745/173481[48:00<01:01,60.73it/s] 98%|#########8|170481/173481[48:12<00:49,60.73it/s]100%|##########|173481/173481[49:00<00:00,59.00it/s]
[32m[0329 02:19:50 @base.py:257][0m Epoch 17 (global_step 13358037) finished, time:2940.14 sec.
[32m[0329 02:19:50 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.17it/s]
16
[32m[0329 02:21:51 @monitor.py:363][0m QueueInput/queue_size: 0.91852
[32m[0329 02:21:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.831
[32m[0329 02:21:51 @monitor.py:363][0m activation-summaries/output-rms: 0.03574
[32m[0329 02:21:51 @monitor.py:363][0m cross_entropy_loss: 2.579
[32m[0329 02:21:51 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 02:21:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 02:21:51 @monitor.py:363][0m train-error-top1: 0.62727
[32m[0329 02:21:51 @monitor.py:363][0m val-error-top1: 0.62804
[32m[0329 02:21:51 @monitor.py:363][0m val-utt-error: 0.26039
[32m[0329 02:21:51 @monitor.py:363][0m validation_cost: 2.5941
[32m[0329 02:21:51 @monitor.py:363][0m wd_cost: 9.2106e-19
[32m[0329 02:21:51 @group.py:42][0m Callbacks took 120.958 sec in total. InferenceRunner: 120.539sec
[32m[0329 02:21:51 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15159/173481[03:00<31:20,84.19it/s]  9%|9         |15788/173481[03:10<31:13,84.19it/s] 15%|#5        |26134/173481[06:00<34:43,70.72it/s] 15%|#5        |26748/173481[06:10<34:34,70.72it/s] 21%|##1       |36501/173481[09:00<35:57,63.49it/s] 21%|##1       |37111/173481[09:10<35:48,63.49it/s] 27%|##7       |47591/173481[12:00<33:33,62.53it/s] 28%|##7       |48285/173481[12:10<33:22,62.53it/s] 34%|###3      |58238/173481[15:00<31:35,60.79it/s] 34%|###3      |58898/173481[15:10<31:24,60.79it/s] 40%|####      |69409/173481[18:00<28:14,61.42it/s] 40%|####      |70118/173481[18:10<28:02,61.42it/s] 47%|####6     |81334/173481[21:00<24:05,63.73it/s] 47%|####7     |81990/173481[21:11<23:55,63.73it/s] 53%|#####3    |92147/173481[24:00<21:55,61.85it/s] 53%|#####3    |92812/173481[24:11<21:44,61.85it/s] 59%|#####9    |102702/173481[27:00<19:35,60.20it/s] 60%|#####9    |103388/173481[27:11<19:24,60.20it/s] 65%|######5   |113610/173481[30:00<16:31,60.40it/s] 66%|######5   |114265/173481[30:11<16:20,60.40it/s] 72%|#######1  |124514/173481[33:00<13:29,60.49it/s] 72%|#######2  |125195/173481[33:11<13:18,60.49it/s] 78%|#######8  |135494/173481[36:00<10:25,60.74it/s] 79%|#######8  |136228/173481[36:11<10:13,60.74it/s] 85%|########4 |146625/173481[39:00<07:18,61.28it/s] 85%|########4 |147333/173481[39:11<07:06,61.28it/s] 91%|######### |157732/173481[42:00<04:16,61.49it/s] 91%|#########1|158464/173481[42:12<04:04,61.49it/s] 97%|#########7|169024/173481[45:00<01:11,62.10it/s] 98%|#########7|169739/173481[45:12<01:00,62.10it/s]100%|##########|173481/173481[46:13<00:00,62.54it/s]
[32m[0329 03:08:05 @base.py:257][0m Epoch 18 (global_step 13531518) finished, time:2773.72 sec.
[32m[0329 03:08:05 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-13531518.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.83it/s]
17
[32m[0329 03:10:08 @monitor.py:363][0m QueueInput/queue_size: 0.7143
[32m[0329 03:10:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.669
[32m[0329 03:10:08 @monitor.py:363][0m activation-summaries/output-rms: 0.034969
[32m[0329 03:10:08 @monitor.py:363][0m cross_entropy_loss: 2.5823
[32m[0329 03:10:08 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 03:10:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 03:10:08 @monitor.py:363][0m train-error-top1: 0.62964
[32m[0329 03:10:08 @monitor.py:363][0m val-error-top1: 0.62861
[32m[0329 03:10:08 @monitor.py:363][0m val-utt-error: 0.25826
[32m[0329 03:10:08 @monitor.py:363][0m validation_cost: 2.5945
[32m[0329 03:10:08 @monitor.py:363][0m wd_cost: 1.8421e-19
[32m[0329 03:10:08 @group.py:42][0m Callbacks took 123.405 sec in total. InferenceRunner: 123.170sec
[32m[0329 03:10:08 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13778/173481[03:00<34:46,76.54it/s]  8%|8         |14417/173481[03:10<34:38,76.54it/s] 14%|#3        |24228/173481[06:00<37:40,66.02it/s] 14%|#4        |24797/173481[06:10<37:32,66.02it/s] 20%|##        |35072/173481[09:00<36:36,63.00it/s] 21%|##        |35702/173481[09:10<36:26,63.00it/s] 27%|##6       |46315/173481[12:00<33:47,62.73it/s] 27%|##7       |46977/173481[12:10<33:36,62.73it/s] 33%|###3      |57329/173481[15:00<31:14,61.95it/s] 33%|###3      |57976/173481[15:10<31:04,61.95it/s] 39%|###9      |68366/173481[18:00<28:25,61.63it/s] 40%|###9      |69067/173481[18:10<28:14,61.63it/s] 46%|####5     |79348/173481[21:00<25:35,61.31it/s] 46%|####6     |79977/173481[21:11<25:25,61.31it/s] 52%|#####1    |90113/173481[24:00<22:56,60.55it/s] 52%|#####2    |90757/173481[24:11<22:46,60.55it/s] 58%|#####8    |101235/173481[27:00<19:41,61.16it/s] 59%|#####8    |101897/173481[27:11<19:30,61.16it/s] 65%|######4   |112066/173481[30:00<16:52,60.66it/s] 65%|######4   |112737/173481[30:11<16:41,60.66it/s] 71%|#######   |122795/173481[33:00<14:02,60.13it/s] 71%|#######1  |123460/173481[33:11<13:51,60.13it/s] 77%|#######6  |133395/173481[36:00<11:13,59.50it/s] 77%|#######7  |134113/173481[36:11<11:01,59.50it/s] 83%|########3 |144315/173481[39:00<08:05,60.08it/s] 84%|########3 |145063/173481[39:11<07:53,60.08it/s] 90%|########9 |155379/173481[42:00<04:57,60.76it/s] 90%|########9 |156070/173481[42:12<04:46,60.76it/s] 96%|#########5|166248/173481[45:00<01:59,60.57it/s] 96%|#########6|166924/173481[45:12<01:48,60.57it/s]100%|##########|173481/173481[47:06<00:00,61.38it/s]
[32m[0329 03:57:15 @base.py:257][0m Epoch 19 (global_step 13704999) finished, time:2826.33 sec.
[32m[0329 03:57:15 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-13704999.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,154.09it/s]
18
[32m[0329 03:59:17 @monitor.py:363][0m QueueInput/queue_size: 0.77451
[32m[0329 03:59:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.57
[32m[0329 03:59:17 @monitor.py:363][0m activation-summaries/output-rms: 0.034284
[32m[0329 03:59:17 @monitor.py:363][0m cross_entropy_loss: 2.6095
[32m[0329 03:59:17 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 03:59:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 03:59:17 @monitor.py:363][0m train-error-top1: 0.63934
[32m[0329 03:59:17 @monitor.py:363][0m val-error-top1: 0.62717
[32m[0329 03:59:17 @monitor.py:363][0m val-utt-error: 0.25916
[32m[0329 03:59:17 @monitor.py:363][0m validation_cost: 2.5792
[32m[0329 03:59:17 @monitor.py:363][0m wd_cost: 1.8421e-19
[32m[0329 03:59:17 @group.py:42][0m Callbacks took 122.464 sec in total. InferenceRunner: 122.164sec
[32m[0329 03:59:17 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12986/173481[03:00<37:04,72.14it/s]  8%|7         |13594/173481[03:10<36:56,72.14it/s] 14%|#3        |23567/173481[06:00<38:34,64.77it/s] 14%|#3        |24196/173481[06:10<38:24,64.77it/s] 20%|##        |34967/173481[09:00<36:02,64.04it/s] 21%|##        |35624/173481[09:10<35:52,64.04it/s] 27%|##6       |46227/173481[12:00<33:30,63.29it/s] 27%|##7       |46851/173481[12:10<33:20,63.29it/s] 33%|###3      |57345/173481[15:00<30:57,62.52it/s] 33%|###3      |57979/173481[15:10<30:47,62.52it/s] 39%|###9      |68396/173481[18:00<28:16,61.95it/s] 40%|###9      |69053/173481[18:10<28:05,61.95it/s] 46%|####5     |79394/173481[21:00<25:29,61.52it/s] 46%|####6     |80071/173481[21:11<25:18,61.52it/s] 52%|#####2    |90431/173481[24:00<22:32,61.42it/s] 53%|#####2    |91082/173481[24:11<22:21,61.42it/s] 58%|#####8    |101382/173481[27:00<19:39,61.12it/s] 59%|#####8    |102070/173481[27:11<19:28,61.12it/s] 65%|######4   |112342/173481[30:00<16:42,61.00it/s] 65%|######5   |113021/173481[30:11<16:31,61.00it/s] 71%|#######   |123163/173481[33:00<13:50,60.55it/s] 71%|#######1  |123854/173481[33:11<13:39,60.55it/s] 77%|#######7  |133995/173481[36:00<10:54,60.36it/s] 78%|#######7  |134682/173481[36:11<10:42,60.36it/s] 83%|########3 |144667/173481[39:00<08:01,59.82it/s] 84%|########3 |145387/173481[39:11<07:49,59.82it/s] 90%|########9 |155852/173481[42:00<04:49,60.95it/s] 90%|######### |156595/173481[42:12<04:37,60.95it/s] 97%|#########6|167797/173481[45:00<01:29,63.51it/s] 97%|#########7|168652/173481[45:12<01:16,63.51it/s]100%|##########|173481/173481[46:18<00:00,62.45it/s]
[32m[0329 04:45:35 @base.py:257][0m Epoch 20 (global_step 13878480) finished, time:2778.12 sec.
[32m[0329 04:45:35 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-13878480.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,140.97it/s]
19
[32m[0329 04:47:49 @monitor.py:363][0m QueueInput/queue_size: 0.6103
[32m[0329 04:47:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.798
[32m[0329 04:47:49 @monitor.py:363][0m activation-summaries/output-rms: 0.03621
[32m[0329 04:47:49 @monitor.py:363][0m cross_entropy_loss: 2.5395
[32m[0329 04:47:49 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 04:47:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 04:47:49 @monitor.py:363][0m train-error-top1: 0.6256
[32m[0329 04:47:49 @monitor.py:363][0m val-error-top1: 0.62751
[32m[0329 04:47:49 @monitor.py:363][0m val-utt-error: 0.26033
[32m[0329 04:47:49 @monitor.py:363][0m validation_cost: 2.5852
[32m[0329 04:47:49 @monitor.py:363][0m wd_cost: 1.8421e-19
[32m[0329 04:47:49 @group.py:42][0m Callbacks took 133.866 sec in total. InferenceRunner: 133.530sec
[32m[0329 04:47:49 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16560/173481[03:00<28:25,92.00it/s] 10%|#         |17491/173481[03:10<28:15,92.00it/s] 17%|#6        |29483/173481[06:00<29:45,80.65it/s] 17%|#7        |30090/173481[06:10<29:37,80.65it/s] 23%|##2       |39891/173481[09:00<33:03,67.35it/s] 23%|##3       |40490/173481[09:10<32:54,67.35it/s] 29%|##9       |50501/173481[12:00<32:36,62.86it/s] 29%|##9       |51103/173481[12:10<32:26,62.86it/s] 35%|###5      |61282/173481[15:00<30:29,61.34it/s] 36%|###5      |61933/173481[15:10<30:18,61.34it/s] 41%|####1     |71753/173481[18:00<28:23,59.71it/s] 42%|####1     |72350/173481[18:10<28:13,59.71it/s] 47%|####7     |82194/173481[21:00<25:51,58.85it/s] 48%|####7     |82840/173481[21:11<25:40,58.85it/s] 53%|#####3    |92734/173481[24:00<22:55,58.70it/s] 54%|#####3    |93395/173481[24:11<22:44,58.70it/s] 59%|#####9    |103176/173481[27:00<20:04,58.35it/s] 60%|#####9    |103820/173481[27:11<19:53,58.35it/s] 66%|######5   |113736/173481[30:00<17:01,58.50it/s] 66%|######5   |114406/173481[30:11<16:49,58.50it/s] 72%|#######1  |124466/173481[33:00<13:50,59.05it/s] 72%|#######2  |125182/173481[33:11<13:37,59.05it/s] 78%|#######8  |135421/173481[36:00<10:34,59.94it/s] 78%|#######8  |136179/173481[36:11<10:22,59.94it/s] 86%|########5 |149138/173481[39:00<06:02,67.10it/s] 87%|########6 |150220/173481[39:11<05:46,67.10it/s] 96%|#########5|165680/173481[42:00<01:40,77.56it/s] 96%|#########6|166754/173481[42:12<01:26,77.56it/s]100%|##########|173481/173481[43:25<00:00,66.59it/s]
[32m[0329 05:31:14 @base.py:257][0m Epoch 21 (global_step 14051961) finished, time:2605.23 sec.
[32m[0329 05:31:14 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-14051961.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.28it/s]
20
[32m[0329 05:33:19 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 05:33:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.568
[32m[0329 05:33:19 @monitor.py:363][0m activation-summaries/output-rms: 0.035004
[32m[0329 05:33:19 @monitor.py:363][0m cross_entropy_loss: 2.5338
[32m[0329 05:33:19 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 05:33:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 05:33:19 @monitor.py:363][0m train-error-top1: 0.62076
[32m[0329 05:33:19 @monitor.py:363][0m val-error-top1: 0.62651
[32m[0329 05:33:19 @monitor.py:363][0m val-utt-error: 0.2589
[32m[0329 05:33:19 @monitor.py:363][0m validation_cost: 2.5775
[32m[0329 05:33:19 @monitor.py:363][0m wd_cost: 3.6842e-20
[32m[0329 05:33:19 @group.py:42][0m Callbacks took 124.689 sec in total. InferenceRunner: 124.434sec
[32m[0329 05:33:19 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13614/173481[03:00<35:13,75.63it/s]  8%|8         |14220/173481[03:10<35:05,75.63it/s] 14%|#4        |24455/173481[06:00<37:02,67.06it/s] 14%|#4        |25051/173481[06:10<36:53,67.06it/s] 20%|#9        |34625/173481[09:00<37:44,61.33it/s] 20%|##        |35155/173481[09:10<37:35,61.33it/s] 26%|##5       |44329/173481[12:00<37:30,57.38it/s] 26%|##5       |44924/173481[12:10<37:20,57.38it/s] 31%|###1      |54420/173481[15:00<34:59,56.70it/s] 32%|###1      |55033/173481[15:10<34:48,56.70it/s] 37%|###7      |64830/173481[18:00<31:37,57.26it/s] 38%|###7      |65451/173481[18:10<31:26,57.26it/s] 44%|####3     |75514/173481[21:00<28:00,58.29it/s] 44%|####3     |76171/173481[21:11<27:49,58.29it/s] 50%|####9     |86095/173481[24:00<24:52,58.53it/s] 50%|#####     |86761/173481[24:11<24:41,58.53it/s] 56%|#####5    |96819/173481[27:00<21:38,59.05it/s] 56%|#####6    |97446/173481[27:11<21:27,59.05it/s] 62%|######1   |107375/173481[30:00<18:43,58.84it/s] 62%|######2   |108050/173481[30:11<18:31,58.84it/s] 68%|######7   |117804/173481[33:00<15:53,58.39it/s] 68%|######8   |118455/173481[33:11<15:42,58.39it/s] 74%|#######3  |128140/173481[36:00<13:03,57.90it/s] 74%|#######4  |128804/173481[36:11<12:51,57.90it/s] 80%|#######9  |138641/173481[39:00<09:59,58.12it/s] 80%|########  |139322/173481[39:11<09:47,58.12it/s] 86%|########6 |149311/173481[42:00<06:51,58.69it/s] 86%|########6 |150030/173481[42:12<06:39,58.69it/s] 92%|#########2|159994/173481[45:00<03:48,59.02it/s] 93%|#########2|160704/173481[45:12<03:36,59.02it/s] 98%|#########8|170608/173481[48:00<00:48,58.99it/s] 99%|#########8|171344/173481[48:12<00:36,58.99it/s]100%|##########|173481/173481[48:47<00:00,59.27it/s]
[32m[0329 06:22:06 @base.py:257][0m Epoch 22 (global_step 14225442) finished, time:2927.14 sec.
[32m[0329 06:22:06 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-14225442.
[32m[0329 06:22:07 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.79it/s]
21
[32m[0329 06:24:07 @monitor.py:363][0m QueueInput/queue_size: 0.97326
[32m[0329 06:24:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.831
[32m[0329 06:24:07 @monitor.py:363][0m activation-summaries/output-rms: 0.03574
[32m[0329 06:24:07 @monitor.py:363][0m cross_entropy_loss: 2.579
[32m[0329 06:24:07 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 06:24:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 06:24:07 @monitor.py:363][0m train-error-top1: 0.62725
[32m[0329 06:24:07 @monitor.py:363][0m val-error-top1: 0.62804
[32m[0329 06:24:07 @monitor.py:363][0m val-utt-error: 0.26033
[32m[0329 06:24:07 @monitor.py:363][0m validation_cost: 2.5941
[32m[0329 06:24:07 @monitor.py:363][0m wd_cost: 3.6842e-20
[32m[0329 06:24:07 @group.py:42][0m Callbacks took 120.708 sec in total. InferenceRunner: 120.066sec
[32m[0329 06:24:07 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15022/173481[03:00<31:38,83.45it/s]  9%|9         |15698/173481[03:10<31:30,83.45it/s] 15%|#4        |25964/173481[06:00<34:57,70.34it/s] 15%|#5        |26568/173481[06:10<34:48,70.34it/s] 21%|##1       |36439/173481[09:00<35:51,63.69it/s] 21%|##1       |37014/173481[09:10<35:42,63.69it/s] 27%|##7       |47649/173481[12:00<33:18,62.97it/s] 28%|##7       |48374/173481[12:10<33:06,62.97it/s] 34%|###3      |58626/173481[15:00<30:53,61.96it/s] 34%|###4      |59274/173481[15:10<30:43,61.96it/s] 40%|####      |69774/173481[18:00<27:54,61.95it/s] 41%|####      |70489/173481[18:10<27:42,61.95it/s] 47%|####7     |81649/173481[21:00<23:57,63.89it/s] 47%|####7     |82264/173481[21:11<23:47,63.89it/s] 53%|#####3    |92432/173481[24:00<21:50,61.83it/s] 54%|#####3    |93086/173481[24:11<21:40,61.83it/s] 59%|#####9    |103054/173481[27:00<19:26,60.38it/s] 60%|#####9    |103716/173481[27:11<19:15,60.38it/s] 66%|######5   |114087/173481[30:00<16:16,60.84it/s] 66%|######6   |114792/173481[30:11<16:04,60.84it/s] 72%|#######2  |125104/173481[33:00<13:12,61.02it/s] 73%|#######2  |125792/173481[33:11<13:01,61.02it/s] 79%|#######8  |136249/173481[36:00<10:05,61.46it/s] 79%|#######8  |136948/173481[36:11<09:54,61.46it/s] 85%|########5 |147484/173481[39:00<06:59,61.92it/s] 85%|########5 |148156/173481[39:11<06:48,61.92it/s] 91%|#########1|158606/173481[42:00<04:00,61.85it/s] 92%|#########1|159338/173481[42:12<03:48,61.85it/s] 98%|#########7|169764/173481[45:00<01:00,61.92it/s] 98%|#########8|170478/173481[45:12<00:48,61.92it/s]100%|##########|173481/173481[46:01<00:00,62.82it/s]
[32m[0329 07:10:08 @base.py:257][0m Epoch 23 (global_step 14398923) finished, time:2761.54 sec.
[32m[0329 07:10:09 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-14398923.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.49it/s]
22
[32m[0329 07:12:11 @monitor.py:363][0m QueueInput/queue_size: 0.71103
[32m[0329 07:12:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.669
[32m[0329 07:12:11 @monitor.py:363][0m activation-summaries/output-rms: 0.034969
[32m[0329 07:12:11 @monitor.py:363][0m cross_entropy_loss: 2.5823
[32m[0329 07:12:11 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 07:12:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 07:12:11 @monitor.py:363][0m train-error-top1: 0.62964
[32m[0329 07:12:11 @monitor.py:363][0m val-error-top1: 0.62861
[32m[0329 07:12:11 @monitor.py:363][0m val-utt-error: 0.25826
[32m[0329 07:12:11 @monitor.py:363][0m validation_cost: 2.5945
[32m[0329 07:12:11 @monitor.py:363][0m wd_cost: 3.6842e-20
[32m[0329 07:12:11 @group.py:42][0m Callbacks took 122.224 sec in total. InferenceRunner: 121.846sec
[32m[0329 07:12:11 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13443/173481[03:00<35:43,74.66it/s]  8%|8         |14062/173481[03:10<35:35,74.66it/s] 14%|#3        |23838/173481[06:00<38:17,65.13it/s] 14%|#4        |24434/173481[06:10<38:08,65.13it/s] 20%|#9        |34598/173481[09:00<37:08,62.33it/s] 20%|##        |35218/173481[09:10<36:58,62.33it/s] 26%|##6       |45737/173481[12:00<34:16,62.11it/s] 27%|##6       |46377/173481[12:10<34:06,62.11it/s] 33%|###2      |56698/173481[15:00<31:39,61.49it/s] 33%|###3      |57345/173481[15:10<31:28,61.49it/s] 39%|###8      |67515/173481[18:00<29:03,60.78it/s] 39%|###9      |68171/173481[18:10<28:52,60.78it/s] 45%|####5     |78388/173481[21:00<26:09,60.59it/s] 46%|####5     |79067/173481[21:11<25:58,60.59it/s] 51%|#####1    |89273/173481[24:00<23:11,60.53it/s] 52%|#####1    |89956/173481[24:11<22:59,60.53it/s] 58%|#####7    |100239/173481[27:00<20:06,60.72it/s] 58%|#####8    |100908/173481[27:11<19:55,60.72it/s] 64%|######4   |111192/173481[30:00<17:04,60.79it/s] 65%|######4   |111916/173481[30:11<16:52,60.79it/s] 70%|#######   |122216/173481[33:00<14:00,61.01it/s] 71%|#######   |122907/173481[33:11<13:48,61.01it/s] 77%|#######6  |133017/173481[36:00<11:08,60.50it/s] 77%|#######7  |133718/173481[36:11<10:57,60.50it/s] 83%|########2 |143934/173481[39:00<08:07,60.58it/s] 83%|########3 |144653/173481[39:11<07:55,60.58it/s] 89%|########9 |155076/173481[42:00<05:00,61.23it/s] 90%|########9 |155808/173481[42:12<04:48,61.23it/s] 96%|#########5|166293/173481[45:00<01:56,61.76it/s] 96%|#########6|167004/173481[45:12<01:44,61.76it/s]100%|##########|173481/173481[47:01<00:00,61.48it/s]
[32m[0329 07:59:12 @base.py:257][0m Epoch 24 (global_step 14572404) finished, time:2821.72 sec.
[32m[0329 07:59:13 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-14572404.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.34it/s]
23
[32m[0329 08:01:15 @monitor.py:363][0m QueueInput/queue_size: 0.69351
[32m[0329 08:01:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.57
[32m[0329 08:01:15 @monitor.py:363][0m activation-summaries/output-rms: 0.034284
[32m[0329 08:01:15 @monitor.py:363][0m cross_entropy_loss: 2.6095
[32m[0329 08:01:15 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 08:01:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 08:01:15 @monitor.py:363][0m train-error-top1: 0.63934
[32m[0329 08:01:15 @monitor.py:363][0m val-error-top1: 0.62717
[32m[0329 08:01:15 @monitor.py:363][0m val-utt-error: 0.25916
[32m[0329 08:01:15 @monitor.py:363][0m validation_cost: 2.5792
[32m[0329 08:01:15 @monitor.py:363][0m wd_cost: 7.3684e-21
[32m[0329 08:01:15 @group.py:42][0m Callbacks took 122.293 sec in total. InferenceRunner: 121.966sec
[32m[0329 08:01:15 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13062/173481[03:00<36:50,72.56it/s]  8%|7         |13679/173481[03:10<36:42,72.56it/s] 14%|#3        |23577/173481[06:00<38:36,64.72it/s] 14%|#3        |24191/173481[06:10<38:26,64.72it/s] 20%|##        |34778/173481[09:00<36:26,63.45it/s] 20%|##        |35420/173481[09:10<36:15,63.45it/s] 26%|##6       |45779/173481[12:00<34:11,62.26it/s] 27%|##6       |46426/173481[12:10<34:00,62.26it/s] 33%|###2      |56986/173481[15:00<31:11,62.26it/s] 33%|###3      |57626/173481[15:10<31:00,62.26it/s] 39%|###9      |67985/173481[18:00<28:30,61.68it/s] 40%|###9      |68627/173481[18:10<28:20,61.68it/s] 45%|####5     |78707/173481[21:00<26:03,60.60it/s] 46%|####5     |79381/173481[21:11<25:52,60.60it/s] 53%|#####2    |91465/173481[24:00<20:55,65.33it/s] 53%|#####3    |92484/173481[24:11<20:39,65.33it/s] 60%|#####9    |104070/173481[27:00<17:06,67.60it/s] 60%|######    |104712/173481[27:11<16:57,67.60it/s] 66%|######6   |114786/173481[30:00<15:27,63.31it/s] 67%|######6   |115435/173481[30:11<15:16,63.31it/s] 72%|#######2  |125412/173481[33:00<13:06,61.09it/s] 73%|#######2  |126093/173481[33:11<12:55,61.09it/s] 79%|#######9  |137325/173481[36:00<09:29,63.53it/s] 80%|#######9  |138232/173481[36:11<09:14,63.53it/s] 88%|########8 |152948/173481[39:00<04:39,73.36it/s] 89%|########8 |154026/173481[39:12<04:25,73.36it/s] 97%|#########7|168957/173481[42:00<00:56,80.40it/s] 98%|#########7|169731/173481[42:12<00:46,80.40it/s]100%|##########|173481/173481[43:12<00:00,66.93it/s]
[32m[0329 08:44:27 @base.py:257][0m Epoch 25 (global_step 14745885) finished, time:2592.05 sec.
[32m[0329 08:44:27 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-14745885.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.39it/s]
24
[32m[0329 08:46:31 @monitor.py:363][0m QueueInput/queue_size: 0.5507
[32m[0329 08:46:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.798
[32m[0329 08:46:31 @monitor.py:363][0m activation-summaries/output-rms: 0.03621
[32m[0329 08:46:31 @monitor.py:363][0m cross_entropy_loss: 2.5395
[32m[0329 08:46:31 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 08:46:31 @monitor.py:363][0m train-error-top1: 0.6256
[32m[0329 08:46:31 @monitor.py:363][0m val-error-top1: 0.62751
[32m[0329 08:46:31 @monitor.py:363][0m val-utt-error: 0.26033
[32m[0329 08:46:31 @monitor.py:363][0m validation_cost: 2.5852
[32m[0329 08:46:31 @monitor.py:363][0m wd_cost: 7.3684e-21
[32m[0329 08:46:31 @group.py:42][0m Callbacks took 124.547 sec in total. InferenceRunner: 124.342sec
[32m[0329 08:46:31 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13916/173481[03:00<34:24,77.30it/s]  8%|8         |14510/173481[03:10<34:16,77.30it/s] 14%|#4        |24881/173481[06:00<36:20,68.14it/s] 15%|#4        |25519/173481[06:10<36:11,68.14it/s] 21%|##        |35572/173481[09:00<36:13,63.46it/s] 21%|##        |36195/173481[09:10<36:03,63.46it/s] 27%|##6       |46195/173481[12:00<34:41,61.16it/s] 27%|##6       |46814/173481[12:10<34:31,61.16it/s] 33%|###2      |56687/173481[15:00<32:36,59.69it/s] 33%|###3      |57334/173481[15:10<32:25,59.69it/s] 39%|###9      |67662/173481[18:00<29:14,60.32it/s] 39%|###9      |68297/173481[18:10<29:03,60.32it/s] 45%|####4     |77976/173481[21:00<27:05,58.77it/s] 45%|####5     |78624/173481[21:11<26:54,58.77it/s] 51%|#####1    |88505/173481[24:00<24:09,58.63it/s] 51%|#####1    |89135/173481[24:11<23:58,58.63it/s] 57%|#####7    |98894/173481[27:00<21:22,58.17it/s] 57%|#####7    |99558/173481[27:11<21:10,58.17it/s] 63%|######2   |109261/173481[30:00<18:29,57.87it/s] 63%|######3   |109920/173481[30:11<18:18,57.87it/s] 69%|######9   |119831/173481[33:00<15:20,58.29it/s] 69%|######9   |120489/173481[33:11<15:09,58.29it/s] 75%|#######5  |130467/173481[36:00<12:12,58.69it/s] 76%|#######5  |131135/173481[36:11<12:01,58.69it/s] 81%|########1 |141157/173481[39:00<09:07,59.04it/s] 82%|########1 |141863/173481[39:11<08:55,59.04it/s] 87%|########7 |151526/173481[42:00<06:16,58.31it/s] 88%|########7 |152180/173481[42:12<06:05,58.31it/s] 93%|#########3|161867/173481[45:00<03:20,57.87it/s] 94%|#########3|162525/173481[45:12<03:09,57.87it/s] 99%|#########9|172146/173481[48:00<00:23,57.49it/s]100%|#########9|172850/173481[48:12<00:10,57.49it/s]100%|##########|173481/173481[48:23<00:00,59.74it/s]
[32m[0329 09:34:55 @base.py:257][0m Epoch 26 (global_step 14919366) finished, time:2903.89 sec.
[32m[0329 09:34:55 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-14919366.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.00it/s]
25
[32m[0329 09:36:56 @monitor.py:363][0m QueueInput/queue_size: 0.54499
[32m[0329 09:36:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.653
[32m[0329 09:36:56 @monitor.py:363][0m activation-summaries/output-rms: 0.035298
[32m[0329 09:36:56 @monitor.py:363][0m cross_entropy_loss: 2.5515
[32m[0329 09:36:56 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 09:36:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 09:36:56 @monitor.py:363][0m train-error-top1: 0.62151
[32m[0329 09:36:56 @monitor.py:363][0m val-error-top1: 0.62657
[32m[0329 09:36:56 @monitor.py:363][0m val-utt-error: 0.25709
[32m[0329 09:36:56 @monitor.py:363][0m validation_cost: 2.579
[32m[0329 09:36:56 @monitor.py:363][0m wd_cost: 1.4737e-21
[32m[0329 09:36:56 @group.py:42][0m Callbacks took 121.010 sec in total. InferenceRunner: 120.666sec
[32m[0329 09:36:56 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12935/173481[03:00<37:14,71.85it/s]  8%|7         |13564/173481[03:10<37:05,71.85it/s] 14%|#4        |24435/173481[06:00<36:43,67.63it/s] 14%|#4        |25039/173481[06:10<36:34,67.63it/s] 20%|#9        |34670/173481[09:00<37:27,61.77it/s] 20%|##        |35185/173481[09:10<37:18,61.77it/s] 28%|##8       |48577/173481[12:00<30:19,68.65it/s] 29%|##8       |49526/173481[12:10<30:05,68.65it/s] 36%|###5      |61678/173481[15:00<26:22,70.66it/s] 36%|###5      |62323/173481[15:10<26:13,70.66it/s] 42%|####1     |72371/173481[18:00<26:06,64.54it/s] 42%|####2     |73030/173481[18:10<25:56,64.54it/s] 48%|####7     |83255/173481[21:00<24:05,62.44it/s] 48%|####8     |83929/173481[21:11<23:54,62.44it/s] 54%|#####4    |93924/173481[24:00<21:48,60.81it/s] 55%|#####4    |94550/173481[24:11<21:37,60.81it/s] 60%|######    |104444/173481[27:00<19:18,59.60it/s] 61%|######    |105094/173481[27:11<19:07,59.60it/s] 66%|######6   |115064/173481[30:00<16:25,59.30it/s] 67%|######6   |115721/173481[30:11<16:14,59.30it/s] 73%|#######2  |125895/173481[33:00<13:16,59.73it/s] 73%|#######3  |126679/173481[33:11<13:03,59.73it/s] 81%|########1 |141177/173481[36:00<07:40,70.13it/s] 82%|########1 |142250/173481[36:11<07:25,70.13it/s] 91%|######### |157721/173481[39:00<03:18,79.55it/s] 92%|#########1|158812/173481[39:11<03:04,79.55it/s]100%|##########|173481/173481[41:51<00:00,69.08it/s]
[32m[0329 10:18:47 @base.py:257][0m Epoch 27 (global_step 15092847) finished, time:2511.43 sec.
[32m[0329 10:18:48 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-15092847.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.02it/s]
26
[32m[0329 10:20:48 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 10:20:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.827
[32m[0329 10:20:48 @monitor.py:363][0m activation-summaries/output-rms: 0.036741
[32m[0329 10:20:48 @monitor.py:363][0m cross_entropy_loss: 2.5715
[32m[0329 10:20:48 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 10:20:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 10:20:48 @monitor.py:363][0m train-error-top1: 0.62477
[32m[0329 10:20:48 @monitor.py:363][0m val-error-top1: 0.62697
[32m[0329 10:20:48 @monitor.py:363][0m val-utt-error: 0.25731
[32m[0329 10:20:48 @monitor.py:363][0m validation_cost: 2.5872
[32m[0329 10:20:48 @monitor.py:363][0m wd_cost: 1.4737e-21
[32m[0329 10:20:48 @group.py:42][0m Callbacks took 120.902 sec in total. InferenceRunner: 120.653sec
[32m[0329 10:20:48 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15581/173481[03:00<30:24,86.56it/s]  9%|9         |16185/173481[03:10<30:17,86.56it/s] 15%|#5        |26509/173481[06:00<34:19,71.36it/s] 16%|#5        |27092/173481[06:10<34:11,71.36it/s] 21%|##1       |37119/173481[09:00<35:12,64.56it/s] 22%|##1       |37747/173481[09:10<35:02,64.56it/s] 28%|##7       |48552/173481[12:00<32:31,64.03it/s] 28%|##8       |49239/173481[12:10<32:20,64.03it/s] 34%|###4      |59364/173481[15:00<30:41,61.98it/s] 35%|###4      |59993/173481[15:10<30:31,61.98it/s] 41%|####      |70715/173481[18:00<27:23,62.52it/s] 41%|####1     |71548/173481[18:10<27:10,62.52it/s] 48%|####7     |82589/173481[21:00<23:35,64.19it/s] 48%|####7     |83233/173481[21:11<23:25,64.19it/s] 54%|#####3    |93599/173481[24:00<21:15,62.64it/s] 54%|#####4    |94263/173481[24:11<21:04,62.64it/s] 60%|######    |104253/173481[27:00<18:57,60.86it/s] 60%|######    |104933/173481[27:11<18:46,60.86it/s] 67%|######6   |115422/173481[30:00<15:44,61.45it/s] 67%|######6   |116104/173481[30:11<15:33,61.45it/s] 73%|#######2  |126384/173481[33:00<12:49,61.17it/s] 73%|#######3  |127104/173481[33:11<12:38,61.17it/s] 79%|#######9  |137599/173481[36:00<09:41,61.73it/s] 80%|#######9  |138292/173481[36:11<09:30,61.73it/s] 86%|########5 |148452/173481[39:00<06:50,61.00it/s] 86%|########5 |149126/173481[39:11<06:39,61.00it/s] 92%|#########1|159325/173481[42:00<03:53,60.70it/s] 92%|#########2|160068/173481[42:12<03:40,60.70it/s] 98%|#########8|170409/173481[45:00<00:50,61.13it/s] 99%|#########8|171133/173481[45:12<00:38,61.13it/s]100%|##########|173481/173481[45:50<00:00,63.07it/s]
[32m[0329 11:06:39 @base.py:257][0m Epoch 28 (global_step 15266328) finished, time:2750.47 sec.
[32m[0329 11:06:39 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-15266328.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.94it/s]
27
[32m[0329 11:08:44 @monitor.py:363][0m QueueInput/queue_size: 0.74694
[32m[0329 11:08:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.669
[32m[0329 11:08:44 @monitor.py:363][0m activation-summaries/output-rms: 0.034969
[32m[0329 11:08:44 @monitor.py:363][0m cross_entropy_loss: 2.5823
[32m[0329 11:08:44 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 11:08:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 11:08:44 @monitor.py:363][0m train-error-top1: 0.62964
[32m[0329 11:08:44 @monitor.py:363][0m val-error-top1: 0.62861
[32m[0329 11:08:44 @monitor.py:363][0m val-utt-error: 0.25826
[32m[0329 11:08:44 @monitor.py:363][0m validation_cost: 2.5945
[32m[0329 11:08:44 @monitor.py:363][0m wd_cost: 1.4737e-21
[32m[0329 11:08:44 @group.py:42][0m Callbacks took 125.117 sec in total. InferenceRunner: 124.708sec
[32m[0329 11:08:44 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14109/173481[03:00<33:53,78.38it/s]  8%|8         |14735/173481[03:10<33:45,78.38it/s] 14%|#4        |24438/173481[06:00<37:29,66.25it/s] 14%|#4        |25022/173481[06:10<37:20,66.25it/s] 20%|##        |35258/173481[09:00<36:33,63.03it/s] 21%|##        |35901/173481[09:10<36:22,63.03it/s] 27%|##6       |46155/173481[12:00<34:21,61.76it/s] 27%|##6       |46798/173481[12:10<34:11,61.76it/s] 33%|###2      |56813/173481[15:00<32:09,60.45it/s] 33%|###3      |57431/173481[15:10<31:59,60.45it/s] 39%|###9      |67674/173481[18:00<29:11,60.39it/s] 39%|###9      |68287/173481[18:10<29:01,60.39it/s] 45%|####5     |78400/173481[21:00<26:25,59.99it/s] 46%|####5     |79067/173481[21:11<26:13,59.99it/s] 51%|#####1    |89050/173481[24:00<23:37,59.57it/s] 52%|#####1    |89731/173481[24:11<23:25,59.57it/s] 58%|#####7    |99960/173481[27:00<20:23,60.09it/s] 58%|#####8    |100632/173481[27:11<20:12,60.09it/s] 64%|######3   |110823/173481[30:00<17:20,60.21it/s] 64%|######4   |111520/173481[30:11<17:09,60.21it/s] 70%|#######   |121623/173481[33:00<14:22,60.10it/s] 71%|#######   |122319/173481[33:11<14:11,60.10it/s] 76%|#######6  |132500/173481[36:00<11:20,60.26it/s] 77%|#######6  |133188/173481[36:11<11:08,60.26it/s] 83%|########2 |143459/173481[39:00<08:15,60.57it/s] 83%|########3 |144157/173481[39:11<08:04,60.57it/s] 89%|########9 |154550/173481[42:00<05:09,61.09it/s] 89%|########9 |155265/173481[42:12<04:58,61.09it/s] 95%|#########5|165628/173481[45:00<02:08,61.31it/s] 96%|#########5|166323/173481[45:12<01:56,61.31it/s]100%|##########|173481/173481[47:15<00:00,61.18it/s]
[32m[0329 11:56:00 @base.py:257][0m Epoch 29 (global_step 15439809) finished, time:2835.54 sec.
[32m[0329 11:56:00 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_True_preload/model-15439809.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.53it/s]
28
[32m[0329 11:58:02 @monitor.py:363][0m QueueInput/queue_size: 0.74595
[32m[0329 11:58:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.57
[32m[0329 11:58:02 @monitor.py:363][0m activation-summaries/output-rms: 0.034284
[32m[0329 11:58:02 @monitor.py:363][0m cross_entropy_loss: 2.6095
[32m[0329 11:58:02 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 11:58:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 11:58:02 @monitor.py:363][0m train-error-top1: 0.63934
[32m[0329 11:58:02 @monitor.py:363][0m val-error-top1: 0.62717
[32m[0329 11:58:02 @monitor.py:363][0m val-utt-error: 0.25916
[32m[0329 11:58:02 @monitor.py:363][0m validation_cost: 2.5792
[32m[0329 11:58:02 @monitor.py:363][0m wd_cost: 2.9474e-22
[32m[0329 11:58:02 @group.py:42][0m Callbacks took 122.930 sec in total. InferenceRunner: 122.603sec
[32m[0329 11:58:02 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13179/173481[03:00<36:29,73.21it/s]  8%|7         |13780/173481[03:10<36:21,73.21it/s] 14%|#3        |23678/173481[06:00<38:27,64.93it/s] 14%|#4        |24289/173481[06:10<38:17,64.93it/s] 20%|##        |34722/173481[09:00<36:39,63.09it/s] 20%|##        |35349/173481[09:10<36:29,63.09it/s] 26%|##6       |45633/173481[12:00<34:27,61.83it/s] 27%|##6       |46282/173481[12:10<34:17,61.83it/s] 33%|###2      |56623/173481[15:00<31:42,61.44it/s] 33%|###3      |57281/173481[15:10<31:31,61.44it/s] 39%|###8      |67586/173481[18:00<28:51,61.17it/s] 39%|###9      |68218/173481[18:10<28:40,61.17it/s] 45%|####5     |78422/173481[21:00<26:06,60.67it/s] 46%|####5     |79098/173481[21:11<25:55,60.67it/s] 52%|#####1    |89520/173481[24:00<22:52,61.16it/s] 52%|#####2    |90226/173481[24:11<22:41,61.16it/s] 58%|#####7    |100340/173481[27:00<20:06,60.63it/s] 58%|#####8    |101006/173481[27:11<19:55,60.63it/s] 64%|######3   |110921/173481[30:00<17:28,59.69it/s] 64%|######4   |111586/173481[30:11<17:16,59.69it/s] 70%|#######   |121527/173481[33:00<14:36,59.30it/s] 70%|#######   |122206/173481[33:11<14:24,59.30it/s] 76%|#######6  |132183/173481[36:00<11:37,59.25it/s] 77%|#######6  |132861/173481[36:11<11:25,59.25it/s] 82%|########2 |142813/173481[39:00<08:38,59.15it/s] 83%|########2 |143530/173481[39:11<08:26,59.15it/s]slurmstepd: *** STEP 85143.0 ON sls-tesla-1 CANCELLED AT 2018-03-29T12:39:05 ***
slurmstepd: *** JOB 85143 ON sls-tesla-1 CANCELLED AT 2018-03-29T12:39:05 ***
