sls-tesla-1 1
SLURM_JOBID=85139
SLURM_TASKID=5
[32m[0328 11:37:17 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=32 --bita=32 --quant_ends=True --load_ckpt=train_log/fcn1_w_32_a_32_quant_ends_False/checkpoint
[32m[0328 11:37:25 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 11:37:25 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 11:37:26 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 11:37:26 @drf_run.py:166][0m Using host: sls-tesla-1
[32m[0328 11:37:26 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 11:37:26 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 11:37:26 @drf_run.py:188][0m Using GPU: 1
[32m[0328 11:37:26 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 11:37:26 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 11:37:26 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 11:37:26 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear0 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear1 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:37:26 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 11:37:26 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:37:26 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0328 11:37:26 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 11:37:26 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0328 11:37:27 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0328 11:37:27 @base.py:196][0m Setup callbacks graph ...
[32m[0328 11:37:27 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:37:27 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:37:27 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0328 11:37:27 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 11:37:27 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0328 11:37:28 @base.py:212][0m Creating the session ...
2018-03-28 11:37:28.468900: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-03-28 11:37:31.579354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:42:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-28 11:37:31.579413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:42:00.0, compute capability: 6.1)
[32m[0328 11:37:36 @base.py:220][0m Initializing the session ...
[32m[0328 11:37:36 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn1_w_32_a_32_quant_ends_False/model-10408860 ...
[32m[0328 11:37:36 @base.py:227][0m Graph Finalized.
[32m[0328 11:37:36 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 11:37:36 @steps.py:127][0m Start training with global_step=10408860
[32m[0328 11:37:39 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17070/173481[03:00<27:29,94.83it/s] 10%|#         |18028/173481[03:10<27:19,94.83it/s] 20%|#9        |33977/173481[06:00<24:38,94.38it/s] 20%|##        |34947/173481[06:10<24:27,94.38it/s] 27%|##7       |47682/173481[09:00<24:52,84.28it/s] 28%|##7       |48330/173481[09:10<24:44,84.28it/s] 34%|###3      |58487/173481[12:00<27:20,70.12it/s] 34%|###4      |59152/173481[12:10<27:10,70.12it/s] 40%|###9      |69195/173481[15:00<27:00,64.37it/s] 40%|####      |69821/173481[15:10<26:50,64.37it/s] 46%|####5     |79497/173481[18:00<25:51,60.59it/s] 46%|####6     |80140/173481[18:10<25:40,60.59it/s] 52%|#####1    |90052/173481[21:00<23:19,59.60it/s] 52%|#####2    |90676/173481[21:11<23:09,59.60it/s] 58%|#####7    |100556/173481[24:00<20:36,58.97it/s] 58%|#####8    |101234/173481[24:11<20:25,58.97it/s] 64%|######4   |111186/173481[27:00<17:35,59.01it/s] 64%|######4   |111867/173481[27:11<17:24,59.01it/s] 70%|#######   |121563/173481[30:00<14:50,58.32it/s] 70%|#######   |122220/173481[30:11<14:38,58.32it/s] 76%|#######6  |132116/173481[33:00<11:47,58.47it/s] 77%|#######6  |132810/173481[33:11<11:35,58.47it/s] 82%|########2 |142823/173481[36:00<08:39,58.97it/s] 83%|########2 |143525/173481[36:11<08:27,58.97it/s] 88%|########8 |152751/173481[39:00<06:03,57.00it/s] 88%|########8 |153365/173481[39:11<05:52,57.00it/s] 94%|#########3|162231/173481[42:00<03:25,54.74it/s] 94%|#########3|162895/173481[42:12<03:13,54.74it/s] 99%|#########9|172426/173481[45:00<00:18,55.67it/s]100%|#########9|173095/173481[45:12<00:06,55.67it/s]100%|##########|173481/173481[45:20<00:00,63.76it/s]
[32m[0328 12:23:00 @base.py:257][0m Epoch 1 (global_step 10582341) finished, time:2720.76 sec.
[32m[0328 12:23:00 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 49%|####9     |9280/18822[03:00<03:05,51.55it/s] 52%|#####2    |9862/18822[03:10<02:53,51.55it/s]100%|##########|18822/18822[05:22<00:00,58.30it/s]
0
[32m[0328 12:28:23 @monitor.py:363][0m QueueInput/queue_size: 1.4599
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.653
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/output-rms: 0.042082
[32m[0328 12:28:23 @monitor.py:363][0m cross_entropy_loss: 1.5008
[32m[0328 12:28:23 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 12:28:23 @monitor.py:363][0m train-error-top1: 0.39935
[32m[0328 12:28:23 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0328 12:28:23 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0328 12:28:23 @monitor.py:363][0m validation_cost: 1.5514
[32m[0328 12:28:23 @monitor.py:363][0m wd_cost: 2.9335e-15
[32m[0328 12:28:23 @group.py:42][0m Callbacks took 323.281 sec in total. InferenceRunner: 322.845sec
[32m[0328 12:28:23 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10590/173481[03:00<46:09,58.82it/s]  6%|6         |11124/173481[03:10<46:00,58.82it/s] 12%|#1        |20815/173481[06:00<44:01,57.79it/s] 12%|#2        |21411/173481[06:10<43:51,57.79it/s] 18%|#7        |30835/173481[09:00<41:55,56.71it/s] 18%|#8        |31389/173481[09:10<41:45,56.71it/s] 23%|##2       |39877/173481[12:00<41:47,53.27it/s] 23%|##3       |40409/173481[12:10<41:37,53.27it/s] 28%|##8       |49148/173481[15:00<39:33,52.37it/s] 29%|##8       |49709/173481[15:10<39:23,52.37it/s] 34%|###4      |59165/173481[18:00<35:18,53.95it/s] 34%|###4      |59774/173481[18:10<35:07,53.95it/s] 40%|###9      |69125/173481[21:00<31:50,54.62it/s] 40%|####      |69724/173481[21:10<31:39,54.62it/s] 46%|####5     |79375/173481[24:00<28:07,55.75it/s] 46%|####6     |80007/173481[24:11<27:56,55.75it/s] 52%|#####1    |89625/173481[27:00<24:48,56.33it/s] 52%|#####2    |90234/173481[27:11<24:37,56.33it/s] 58%|#####7    |99771/173481[30:00<21:48,56.35it/s] 58%|#####7    |100383/173481[30:11<21:37,56.35it/s] 63%|######3   |109870/173481[33:00<18:51,56.20it/s] 64%|######3   |110487/173481[33:11<18:40,56.20it/s] 69%|######9   |119795/173481[36:00<16:04,55.66it/s] 69%|######9   |120434/173481[36:11<15:53,55.66it/s] 75%|#######4  |129630/173481[39:00<13:15,55.13it/s] 75%|#######5  |130214/173481[39:11<13:04,55.13it/s] 80%|########  |139442/173481[42:00<10:20,54.82it/s] 81%|########  |140099/173481[42:11<10:08,54.82it/s] 86%|########6 |149470/173481[45:00<07:14,55.26it/s] 87%|########6 |150129/173481[45:12<07:02,55.26it/s] 92%|#########2|159643/173481[48:00<04:07,55.88it/s] 92%|#########2|160285/173481[48:12<03:56,55.88it/s] 98%|#########7|169795/173481[51:00<01:05,56.13it/s] 98%|#########8|170468/173481[51:12<00:53,56.13it/s]100%|##########|173481/173481[52:04<00:00,55.52it/s]
[32m[0328 13:20:28 @base.py:257][0m Epoch 2 (global_step 10755822) finished, time:3124.86 sec.
[32m[0328 13:20:29 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-10755822.
[32m[0328 13:20:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.17it/s]
1
[32m[0328 13:22:23 @monitor.py:363][0m QueueInput/queue_size: 0.54344
[32m[0328 13:22:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.815
[32m[0328 13:22:23 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0328 13:22:23 @monitor.py:363][0m cross_entropy_loss: 1.5277
[32m[0328 13:22:23 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 13:22:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 13:22:23 @monitor.py:363][0m train-error-top1: 0.41303
[32m[0328 13:22:23 @monitor.py:363][0m val-error-top1: 0.41584
[32m[0328 13:22:23 @monitor.py:363][0m val-utt-error: 0.090373
[32m[0328 13:22:23 @monitor.py:363][0m validation_cost: 1.5502
[32m[0328 13:22:23 @monitor.py:363][0m wd_cost: 2.9335e-15
[32m[0328 13:22:23 @group.py:42][0m Callbacks took 114.696 sec in total. InferenceRunner: 113.970sec
[32m[0328 13:22:23 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11960/173481[03:00<40:30,66.44it/s]  7%|7         |12603/173481[03:10<40:21,66.44it/s] 13%|#3        |22734/173481[06:00<39:53,62.98it/s] 13%|#3        |23333/173481[06:10<39:44,62.98it/s] 19%|#8        |32154/173481[09:00<41:12,57.16it/s] 19%|#8        |32738/173481[09:10<41:02,57.16it/s] 24%|##4       |41684/173481[12:00<39:58,54.96it/s] 24%|##4       |42242/173481[12:10<39:47,54.96it/s] 29%|##9       |51105/173481[15:00<38:02,53.62it/s] 30%|##9       |51648/173481[15:10<37:52,53.62it/s] 35%|###4      |60404/173481[18:00<35:49,52.61it/s] 35%|###5      |60968/173481[18:10<35:38,52.61it/s] 41%|####      |70594/173481[21:00<31:26,54.54it/s] 41%|####1     |71243/173481[21:11<31:14,54.54it/s] 47%|####6     |80799/173481[24:00<27:47,55.59it/s] 47%|####6     |81446/173481[24:11<27:35,55.59it/s] 53%|#####2    |91289/173481[27:00<24:04,56.90it/s] 53%|#####2    |91918/173481[27:11<23:53,56.90it/s] 59%|#####8    |101539/173481[30:00<21:04,56.92it/s] 59%|#####8    |102173/173481[30:11<20:52,56.92it/s] 65%|######4   |111969/173481[33:00<17:51,57.42it/s] 65%|######4   |112668/173481[33:11<17:39,57.42it/s] 71%|#######   |122439/173481[36:00<14:43,57.79it/s] 71%|#######   |123076/173481[36:11<14:32,57.79it/s] 77%|#######6  |132882/173481[39:00<11:41,57.90it/s] 77%|#######6  |133448/173481[39:11<11:31,57.90it/s] 83%|########2 |143259/173481[42:00<08:43,57.77it/s] 83%|########2 |143963/173481[42:12<08:30,57.77it/s] 89%|########8 |153868/173481[45:00<05:36,58.35it/s] 89%|########9 |154576/173481[45:12<05:24,58.35it/s] 95%|#########4|164644/173481[48:00<02:29,59.09it/s] 95%|#########5|165353/173481[48:12<02:17,59.09it/s]100%|##########|173481/173481[50:25<00:00,57.34it/s]
[32m[0328 14:12:49 @base.py:257][0m Epoch 3 (global_step 10929303) finished, time:3025.55 sec.
[32m[0328 14:12:49 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.62it/s]
2
[32m[0328 14:14:53 @monitor.py:363][0m QueueInput/queue_size: 0.25516
[32m[0328 14:14:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.686
[32m[0328 14:14:53 @monitor.py:363][0m activation-summaries/output-rms: 0.04173
[32m[0328 14:14:53 @monitor.py:363][0m cross_entropy_loss: 1.5085
[32m[0328 14:14:53 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 14:14:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 14:14:53 @monitor.py:363][0m train-error-top1: 0.40654
[32m[0328 14:14:53 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0328 14:14:53 @monitor.py:363][0m val-utt-error: 0.090585
[32m[0328 14:14:53 @monitor.py:363][0m validation_cost: 1.5507
[32m[0328 14:14:53 @monitor.py:363][0m wd_cost: 2.9335e-15
[32m[0328 14:14:53 @group.py:42][0m Callbacks took 124.464 sec in total. InferenceRunner: 124.154sec
[32m[0328 14:14:53 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12493/173481[03:00<38:40,69.37it/s]  8%|7         |13029/173481[03:10<38:32,69.37it/s] 13%|#2        |21948/173481[06:00<42:14,59.79it/s] 13%|#2        |22487/173481[06:10<42:05,59.79it/s] 18%|#8        |31373/173481[09:00<42:25,55.82it/s] 18%|#8        |31927/173481[09:10<42:15,55.82it/s] 24%|##3       |41488/173481[12:00<39:16,56.00it/s] 24%|##4       |42063/173481[12:10<39:06,56.00it/s] 30%|##9       |51763/173481[15:00<35:53,56.52it/s] 30%|###       |52397/173481[15:10<35:42,56.52it/s] 35%|###5      |61326/173481[18:00<34:07,54.77it/s] 36%|###5      |61887/173481[18:10<33:57,54.77it/s] 41%|####1     |71468/173481[21:00<30:36,55.55it/s] 42%|####1     |72046/173481[21:11<30:26,55.55it/s] 47%|####7     |81633/173481[24:00<27:20,56.00it/s] 47%|####7     |82217/173481[24:11<27:09,56.00it/s] 53%|#####2    |91343/173481[27:00<24:54,54.95it/s] 53%|#####2    |91887/173481[27:11<24:44,54.95it/s] 58%|#####8    |101290/173481[30:00<21:50,55.11it/s] 59%|#####8    |101924/173481[30:11<21:38,55.11it/s] 65%|######4   |112186/173481[33:00<17:42,57.69it/s] 65%|######5   |112822/173481[33:11<17:31,57.69it/s] 71%|#######   |123008/173481[36:00<14:17,58.87it/s] 71%|#######1  |123662/173481[36:11<14:06,58.87it/s] 77%|#######7  |133596/173481[39:00<11:17,58.85it/s] 77%|#######7  |134307/173481[39:11<11:05,58.85it/s] 83%|########2 |143893/173481[42:00<08:30,58.01it/s] 83%|########3 |144538/173481[42:11<08:18,58.01it/s] 89%|########8 |154093/173481[45:00<05:38,57.33it/s] 89%|########9 |154807/173481[45:12<05:25,57.33it/s] 95%|#########4|164525/173481[48:00<02:35,57.64it/s] 95%|#########5|165192/173481[48:12<02:23,57.64it/s]100%|##########|173481/173481[50:56<00:00,56.77it/s]
[32m[0328 15:05:49 @base.py:257][0m Epoch 4 (global_step 11102784) finished, time:3056.05 sec.
[32m[0328 15:05:49 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,188.90it/s]
3
[32m[0328 15:07:29 @monitor.py:363][0m QueueInput/queue_size: 0.56373
[32m[0328 15:07:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0328 15:07:29 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0328 15:07:29 @monitor.py:363][0m cross_entropy_loss: 1.5057
[32m[0328 15:07:29 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 15:07:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 15:07:29 @monitor.py:363][0m train-error-top1: 0.40851
[32m[0328 15:07:29 @monitor.py:363][0m val-error-top1: 0.41551
[32m[0328 15:07:29 @monitor.py:363][0m val-utt-error: 0.090054
[32m[0328 15:07:29 @monitor.py:363][0m validation_cost: 1.551
[32m[0328 15:07:29 @monitor.py:363][0m wd_cost: 5.8669e-16
[32m[0328 15:07:29 @group.py:42][0m Callbacks took 99.997 sec in total. InferenceRunner: 99.652sec
[32m[0328 15:07:29 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9587/173481[03:00<51:19,53.22it/s]  6%|5         |10077/173481[03:10<51:10,53.22it/s] 11%|#1        |19477/173481[06:00<47:28,54.07it/s] 12%|#1        |20081/173481[06:10<47:17,54.07it/s] 17%|#7        |29599/173481[09:00<43:29,55.13it/s] 17%|#7        |30231/173481[09:10<43:18,55.13it/s] 23%|##3       |39907/173481[12:00<39:37,56.18it/s] 23%|##3       |40476/173481[12:10<39:27,56.18it/s] 29%|##8       |49632/173481[15:00<37:29,55.06it/s] 29%|##8       |50226/173481[15:10<37:18,55.06it/s] 35%|###4      |60192/173481[18:00<33:14,56.80it/s] 35%|###5      |60796/173481[18:10<33:03,56.80it/s] 41%|####      |70407/173481[21:00<30:15,56.77it/s] 41%|####      |70986/173481[21:11<30:05,56.77it/s] 46%|####6     |79942/173481[24:00<28:26,54.80it/s] 46%|####6     |80511/173481[24:11<28:16,54.80it/s] 51%|#####1    |89187/173481[27:00<26:29,53.02it/s] 52%|#####1    |89826/173481[27:11<26:17,53.02it/s] 57%|#####7    |98907/173481[30:00<23:13,53.50it/s] 57%|#####7    |99466/173481[30:11<23:03,53.50it/s] 62%|######2   |108402/173481[33:00<20:25,53.12it/s] 63%|######2   |109006/173481[33:11<20:13,53.12it/s] 68%|######8   |118278/173481[36:00<17:02,53.98it/s] 69%|######8   |118891/173481[36:11<16:51,53.98it/s] 74%|#######3  |128018/173481[39:00<14:01,54.04it/s] 74%|#######4  |128611/173481[39:11<13:50,54.04it/s] 79%|#######9  |137532/173481[42:00<11:12,53.43it/s] 80%|#######9  |138121/173481[42:11<11:01,53.43it/s] 85%|########5 |147542/173481[45:00<07:56,54.49it/s] 85%|########5 |148196/173481[45:12<07:44,54.49it/s] 91%|######### |157707/173481[48:00<04:44,55.46it/s] 91%|#########1|158366/173481[48:12<04:32,55.46it/s] 96%|#########6|167202/173481[51:00<01:56,54.07it/s] 97%|#########6|167816/173481[51:12<01:44,54.07it/s]100%|##########|173481/173481[53:01<00:00,54.54it/s]
[32m[0328 16:00:30 @base.py:257][0m Epoch 5 (global_step 11276265) finished, time:3181.34 sec.
[32m[0328 16:00:31 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-11276265.
[32m[0328 16:00:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,199.27it/s]
4
[32m[0328 16:02:05 @monitor.py:363][0m QueueInput/queue_size: 0.64471
[32m[0328 16:02:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.753
[32m[0328 16:02:05 @monitor.py:363][0m activation-summaries/output-rms: 0.04355
[32m[0328 16:02:05 @monitor.py:363][0m cross_entropy_loss: 1.4886
[32m[0328 16:02:05 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 16:02:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 16:02:05 @monitor.py:363][0m train-error-top1: 0.40585
[32m[0328 16:02:05 @monitor.py:363][0m val-error-top1: 0.41643
[32m[0328 16:02:05 @monitor.py:363][0m val-utt-error: 0.092604
[32m[0328 16:02:05 @monitor.py:363][0m validation_cost: 1.5522
[32m[0328 16:02:05 @monitor.py:363][0m wd_cost: 5.8669e-16
[32m[0328 16:02:05 @group.py:42][0m Callbacks took 95.053 sec in total. InferenceRunner: 94.464sec
[32m[0328 16:02:05 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10430/173481[03:00<46:53,57.94it/s]  6%|6         |11032/173481[03:10<46:43,57.94it/s] 12%|#2        |21011/173481[06:00<43:32,58.35it/s] 12%|#2        |21609/173481[06:10<43:22,58.35it/s] 18%|#8        |31338/173481[09:00<40:56,57.86it/s] 18%|#8        |31860/173481[09:10<40:47,57.86it/s] 23%|##3       |40326/173481[12:00<41:24,53.59it/s] 24%|##3       |40835/173481[12:10<41:14,53.59it/s] 28%|##8       |49341/173481[15:00<39:57,51.77it/s] 29%|##8       |49877/173481[15:10<39:47,51.77it/s] 34%|###3      |58591/173481[18:00<37:07,51.58it/s] 34%|###4      |59195/173481[18:10<36:55,51.58it/s] 40%|###9      |68621/173481[21:00<32:37,53.57it/s] 40%|###9      |69160/173481[21:11<32:27,53.57it/s] 45%|####4     |77761/173481[24:00<30:36,52.13it/s] 45%|####5     |78395/173481[24:11<30:24,52.13it/s] 50%|#####     |86846/173481[27:00<28:09,51.28it/s] 50%|#####     |87402/173481[27:11<27:58,51.28it/s] 55%|#####5    |95871/173481[30:00<25:30,50.70it/s] 56%|#####5    |96397/173481[30:11<25:20,50.70it/s] 60%|######    |104561/173481[33:00<23:13,49.44it/s] 61%|######    |105105/173481[33:11<23:02,49.44it/s] 65%|######5   |113376/173481[36:00<20:21,49.20it/s] 66%|######5   |113965/173481[36:11<20:09,49.20it/s] 71%|#######   |122663/173481[39:00<16:48,50.37it/s] 71%|#######1  |123265/173481[39:11<16:36,50.37it/s] 76%|#######5  |131781/173481[42:00<13:45,50.51it/s] 76%|#######6  |132365/173481[42:12<13:34,50.51it/s] 81%|########1 |140905/173481[45:00<10:43,50.60it/s] 82%|########1 |141518/173481[45:12<10:31,50.60it/s] 86%|########6 |149971/173481[48:00<07:45,50.48it/s] 87%|########6 |150635/173481[48:12<07:32,50.48it/s] 92%|#########1|159561/173481[51:00<04:28,51.83it/s] 92%|#########2|160194/173481[51:12<04:16,51.83it/s] 97%|#########7|168311/173481[54:00<01:43,50.17it/s] 97%|#########7|168875/173481[54:12<01:31,50.17it/s]100%|##########|173481/173481[55:49<00:00,51.80it/s]
[32m[0328 16:57:55 @base.py:257][0m Epoch 6 (global_step 11449746) finished, time:3349.37 sec.
[32m[0328 16:57:55 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:32<00:00,203.69it/s]
5
[32m[0328 16:59:28 @monitor.py:363][0m QueueInput/queue_size: 0.29454
[32m[0328 16:59:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.653
[32m[0328 16:59:28 @monitor.py:363][0m activation-summaries/output-rms: 0.042082
[32m[0328 16:59:28 @monitor.py:363][0m cross_entropy_loss: 1.5008
[32m[0328 16:59:28 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 16:59:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 16:59:28 @monitor.py:363][0m train-error-top1: 0.39935
[32m[0328 16:59:28 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0328 16:59:28 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0328 16:59:28 @monitor.py:363][0m validation_cost: 1.5514
[32m[0328 16:59:28 @monitor.py:363][0m wd_cost: 5.8669e-16
[32m[0328 16:59:28 @group.py:42][0m Callbacks took 92.839 sec in total. InferenceRunner: 92.417sec
[32m[0328 16:59:28 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9510/173481[03:00<51:44,52.82it/s]  6%|5         |9999/173481[03:10<51:35,52.82it/s] 11%|#         |18690/173481[06:00<49:43,51.88it/s] 11%|#1        |19209/173481[06:10<49:33,51.88it/s] 16%|#6        |27792/173481[09:00<47:24,51.22it/s] 16%|#6        |28344/173481[09:10<47:13,51.22it/s] 21%|##1       |36610/173481[12:00<45:33,50.07it/s] 21%|##1       |37094/173481[12:10<45:23,50.07it/s] 26%|##5       |44935/173481[15:00<44:33,48.08it/s] 26%|##6       |45417/173481[15:10<44:23,48.08it/s] 31%|###       |53475/173481[18:00<41:52,47.76it/s] 31%|###1      |54004/173481[18:10<41:41,47.76it/s] 36%|###6      |62640/173481[21:00<37:29,49.28it/s] 36%|###6      |63159/173481[21:11<37:18,49.28it/s] 41%|####1     |71650/173481[24:00<34:10,49.66it/s] 42%|####1     |72219/173481[24:11<33:59,49.66it/s] 47%|####6     |80950/173481[27:00<30:27,50.64it/s] 47%|####6     |81519/173481[27:11<30:15,50.64it/s] 52%|#####2    |90350/173481[30:00<26:56,51.42it/s] 52%|#####2    |90955/173481[30:11<26:45,51.42it/s] 58%|#####7    |99845/173481[33:00<23:34,52.07it/s] 58%|#####7    |100419/173481[33:11<23:23,52.07it/s] 63%|######2   |109201/173481[36:00<20:35,52.02it/s] 63%|######3   |109764/173481[36:11<20:24,52.02it/s] 68%|######8   |118205/173481[39:00<18:03,50.99it/s] 68%|######8   |118784/173481[39:11<17:52,50.99it/s] 73%|#######3  |127210/173481[42:00<15:16,50.50it/s] 74%|#######3  |127795/173481[42:12<15:04,50.50it/s] 78%|#######8  |135975/173481[45:00<12:36,49.58it/s] 79%|#######8  |136539/173481[45:12<12:25,49.58it/s] 83%|########3 |144854/173481[48:00<09:38,49.45it/s] 84%|########3 |145415/173481[48:12<09:27,49.45it/s] 89%|########8 |153961/173481[51:00<06:30,50.02it/s] 89%|########9 |154554/173481[51:12<06:18,50.02it/s] 94%|#########4|163390/173481[54:00<03:17,51.17it/s] 95%|#########4|164009/173481[54:12<03:05,51.17it/s]100%|#########9|173230/173481[57:00<00:04,52.86it/s]100%|##########|173481/173481[57:04<00:00,50.66it/s]
[32m[0328 17:56:32 @base.py:257][0m Epoch 7 (global_step 11623227) finished, time:3424.53 sec.
[32m[0328 17:56:32 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-11623227.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:31<00:00,204.95it/s]
6
[32m[0328 17:58:04 @monitor.py:363][0m QueueInput/queue_size: 0.31626
[32m[0328 17:58:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.815
[32m[0328 17:58:04 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0328 17:58:04 @monitor.py:363][0m cross_entropy_loss: 1.5276
[32m[0328 17:58:04 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 17:58:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 17:58:04 @monitor.py:363][0m train-error-top1: 0.413
[32m[0328 17:58:04 @monitor.py:363][0m val-error-top1: 0.41584
[32m[0328 17:58:04 @monitor.py:363][0m val-utt-error: 0.090373
[32m[0328 17:58:04 @monitor.py:363][0m validation_cost: 1.5502
[32m[0328 17:58:04 @monitor.py:363][0m wd_cost: 1.1734e-16
[32m[0328 17:58:04 @group.py:42][0m Callbacks took 92.136 sec in total. InferenceRunner: 91.852sec
[32m[0328 17:58:04 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11144/173481[03:00<43:42,61.91it/s]  7%|6         |11768/173481[03:10<43:32,61.91it/s] 12%|#2        |21480/173481[06:00<42:31,59.58it/s] 13%|#2        |22008/173481[06:10<42:22,59.58it/s] 18%|#7        |30474/173481[09:00<43:51,54.35it/s] 18%|#7        |30973/173481[09:10<43:42,54.35it/s] 23%|##2       |39569/173481[12:00<42:37,52.36it/s] 23%|##3       |40228/173481[12:10<42:24,52.36it/s] 29%|##8       |49509/173481[15:00<38:26,53.75it/s] 29%|##8       |50034/173481[15:10<38:16,53.75it/s] 34%|###3      |58784/173481[18:00<36:20,52.61it/s] 34%|###4      |59324/173481[18:10<36:09,52.61it/s] 39%|###9      |68439/173481[21:00<32:57,53.12it/s] 40%|###9      |69113/173481[21:11<32:44,53.12it/s] 46%|####5     |79484/173481[24:00<27:30,56.94it/s] 46%|####6     |80053/173481[24:11<27:20,56.94it/s] 51%|#####1    |89051/173481[27:00<25:35,54.98it/s] 52%|#####1    |89618/173481[27:11<25:25,54.98it/s] 57%|#####6    |98574/173481[30:00<23:09,53.92it/s] 57%|#####7    |99158/173481[30:11<22:58,53.92it/s] 62%|######2   |108116/173481[33:00<20:22,53.46it/s] 63%|######2   |108716/173481[33:11<20:11,53.46it/s] 68%|######7   |117904/173481[36:00<17:10,53.91it/s] 68%|######8   |118553/173481[36:11<16:58,53.91it/s] 74%|#######3  |128004/173481[39:00<13:47,54.99it/s] 74%|#######4  |128683/173481[39:11<13:34,54.99it/s] 80%|#######9  |138384/173481[42:00<10:23,56.29it/s] 80%|########  |139013/173481[42:12<10:12,56.29it/s] 86%|########5 |148394/173481[45:00<07:28,55.94it/s] 86%|########5 |149068/173481[45:12<07:16,55.94it/s] 91%|#########1|158284/173481[48:00<04:34,55.44it/s] 92%|#########1|158933/173481[48:12<04:22,55.44it/s] 97%|#########7|168309/173481[51:00<01:33,55.56it/s] 97%|#########7|168987/173481[51:12<01:20,55.56it/s]100%|##########|173481/173481[52:33<00:00,55.00it/s]
[32m[0328 18:50:38 @base.py:257][0m Epoch 8 (global_step 11796708) finished, time:3153.97 sec.
[32m[0328 18:50:39 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:32<00:00,204.22it/s]
7
[32m[0328 18:52:11 @monitor.py:363][0m QueueInput/queue_size: 0.29244
[32m[0328 18:52:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.686
[32m[0328 18:52:11 @monitor.py:363][0m activation-summaries/output-rms: 0.04173
[32m[0328 18:52:11 @monitor.py:363][0m cross_entropy_loss: 1.5085
[32m[0328 18:52:11 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 18:52:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 18:52:11 @monitor.py:363][0m train-error-top1: 0.40654
[32m[0328 18:52:11 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0328 18:52:11 @monitor.py:363][0m val-utt-error: 0.090585
[32m[0328 18:52:11 @monitor.py:363][0m validation_cost: 1.5507
[32m[0328 18:52:11 @monitor.py:363][0m wd_cost: 1.1734e-16
[32m[0328 18:52:11 @group.py:42][0m Callbacks took 92.527 sec in total. InferenceRunner: 92.184sec
[32m[0328 18:52:11 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10728/173481[03:00<45:31,59.59it/s]  6%|6         |11237/173481[03:10<45:22,59.59it/s] 11%|#1        |19778/173481[06:00<46:58,54.53it/s] 12%|#1        |20307/173481[06:10<46:49,54.53it/s] 17%|#7        |29822/173481[09:00<43:24,55.16it/s] 18%|#7        |30382/173481[09:10<43:14,55.16it/s] 23%|##3       |40243/173481[12:00<39:18,56.49it/s] 24%|##3       |40912/173481[12:10<39:06,56.49it/s] 30%|##9       |51968/173481[15:00<33:28,60.50it/s] 30%|###       |52657/173481[15:10<33:16,60.50it/s] 36%|###6      |63103/173481[18:00<30:04,61.17it/s] 37%|###6      |63802/173481[18:10<29:53,61.17it/s] 43%|####2     |74453/173481[21:00<26:34,62.10it/s] 43%|####3     |75133/173481[21:11<26:23,62.10it/s] 49%|####9     |85308/173481[24:00<24:01,61.19it/s] 50%|####9     |85964/173481[24:11<23:50,61.19it/s] 56%|#####5    |96293/173481[27:00<21:03,61.11it/s] 56%|#####5    |96996/173481[27:11<20:51,61.11it/s] 62%|######1   |107405/173481[30:00<17:55,61.42it/s] 62%|######2   |108089/173481[30:11<17:44,61.42it/s] 68%|######8   |118453/173481[33:00<14:56,61.40it/s] 69%|######8   |119142/173481[33:11<14:45,61.40it/s] 75%|#######4  |129458/173481[36:00<11:58,61.27it/s] 75%|#######5  |130197/173481[36:11<11:46,61.27it/s] 81%|########1 |140718/173481[39:00<08:49,61.90it/s] 82%|########1 |141479/173481[39:11<08:36,61.90it/s] 88%|########7 |151998/173481[42:00<05:44,62.28it/s] 88%|########8 |152752/173481[42:12<05:32,62.28it/s] 94%|#########4|163298/173481[45:00<02:42,62.52it/s] 95%|#########4|164034/173481[45:12<02:31,62.52it/s]100%|##########|173481/173481[47:54<00:00,60.36it/s]
[32m[0328 19:40:05 @base.py:257][0m Epoch 9 (global_step 11970189) finished, time:2874.27 sec.
[32m[0328 19:40:05 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:32<00:00,203.98it/s]
8
[32m[0328 19:41:38 @monitor.py:363][0m QueueInput/queue_size: 0.1951
[32m[0328 19:41:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0328 19:41:38 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0328 19:41:38 @monitor.py:363][0m cross_entropy_loss: 1.5057
[32m[0328 19:41:38 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 19:41:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 19:41:38 @monitor.py:363][0m train-error-top1: 0.40851
[32m[0328 19:41:38 @monitor.py:363][0m val-error-top1: 0.41551
[32m[0328 19:41:38 @monitor.py:363][0m val-utt-error: 0.090054
[32m[0328 19:41:38 @monitor.py:363][0m validation_cost: 1.551
[32m[0328 19:41:38 @monitor.py:363][0m wd_cost: 1.1734e-16
[32m[0328 19:41:38 @group.py:42][0m Callbacks took 92.633 sec in total. InferenceRunner: 92.284sec
[32m[0328 19:41:38 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11129/173481[03:00<43:45,61.83it/s]  7%|6         |11726/173481[03:10<43:36,61.83it/s] 13%|#2        |22132/173481[06:00<41:02,61.47it/s] 13%|#3        |22613/173481[06:10<40:54,61.47it/s] 19%|#9        |33077/173481[09:00<38:16,61.13it/s] 19%|#9        |33721/173481[09:10<38:06,61.13it/s] 26%|##5       |44242/173481[12:00<34:59,61.57it/s] 26%|##5       |44908/173481[12:10<34:48,61.57it/s] 32%|###1      |55172/173481[15:00<32:15,61.14it/s] 32%|###2      |55815/173481[15:10<32:04,61.14it/s] 38%|###7      |65892/173481[18:00<29:43,60.33it/s] 38%|###8      |66514/173481[18:10<29:32,60.33it/s] 44%|####4     |76827/173481[21:00<26:36,60.54it/s] 45%|####4     |77493/173481[21:11<26:25,60.54it/s] 51%|#####     |88062/173481[24:00<23:09,61.46it/s] 51%|#####1    |88750/173481[24:11<22:58,61.46it/s] 57%|#####6    |98387/173481[27:00<21:05,59.34it/s] 57%|#####7    |99066/173481[27:11<20:54,59.34it/s] 63%|######2   |108792/173481[30:00<18:24,58.56it/s] 63%|######3   |109421/173481[30:11<18:14,58.56it/s] 68%|######8   |118638/173481[33:00<16:09,56.56it/s] 69%|######8   |119261/173481[33:11<15:58,56.56it/s] 74%|#######4  |128776/173481[36:00<13:12,56.44it/s] 75%|#######4  |129393/173481[36:11<13:01,56.44it/s] 80%|########  |139212/173481[39:00<09:59,57.19it/s] 81%|########  |139946/173481[39:12<09:46,57.19it/s] 87%|########6 |150248/173481[42:00<06:32,59.18it/s] 87%|########7 |150986/173481[42:12<06:20,59.18it/s] 93%|#########2|161091/173481[45:00<03:27,59.70it/s] 93%|#########3|161741/173481[45:12<03:16,59.70it/s] 99%|#########8|171212/173481[48:00<00:39,57.91it/s] 99%|#########9|171913/173481[48:12<00:27,57.91it/s]100%|##########|173481/173481[48:41<00:00,59.38it/s]
[32m[0328 20:30:19 @base.py:257][0m Epoch 10 (global_step 12143670) finished, time:2921.47 sec.
[32m[0328 20:30:19 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-12143670.
[32m[0328 20:30:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,207.43it/s]
9
[32m[0328 20:31:51 @monitor.py:363][0m QueueInput/queue_size: 0.45532
[32m[0328 20:31:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.753
[32m[0328 20:31:51 @monitor.py:363][0m activation-summaries/output-rms: 0.04355
[32m[0328 20:31:51 @monitor.py:363][0m cross_entropy_loss: 1.4886
[32m[0328 20:31:51 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 20:31:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 20:31:51 @monitor.py:363][0m train-error-top1: 0.40585
[32m[0328 20:31:51 @monitor.py:363][0m val-error-top1: 0.41643
[32m[0328 20:31:51 @monitor.py:363][0m val-utt-error: 0.092604
[32m[0328 20:31:51 @monitor.py:363][0m validation_cost: 1.5522
[32m[0328 20:31:51 @monitor.py:363][0m wd_cost: 2.3468e-17
[32m[0328 20:31:51 @group.py:42][0m Callbacks took 91.330 sec in total. InferenceRunner: 90.752sec
[32m[0328 20:31:51 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11251/173481[03:00<43:16,62.49it/s]  7%|6         |11824/173481[03:10<43:07,62.49it/s] 13%|#2        |22351/173481[06:00<40:34,62.07it/s] 13%|#3        |22985/173481[06:10<40:24,62.07it/s] 19%|#9        |33411/173481[09:00<37:48,61.75it/s] 20%|#9        |34010/173481[09:10<37:38,61.75it/s] 25%|##5       |44023/173481[12:00<35:46,60.32it/s] 26%|##5       |44660/173481[12:10<35:35,60.32it/s] 31%|###1      |54566/173481[15:00<33:20,59.43it/s] 32%|###1      |55219/173481[15:10<33:09,59.43it/s] 38%|###7      |65601/173481[18:00<29:47,60.35it/s] 38%|###8      |66245/173481[18:10<29:36,60.35it/s] 44%|####3     |76025/173481[21:00<27:28,59.10it/s] 44%|####4     |76650/173481[21:11<27:18,59.10it/s] 50%|####9     |86496/173481[24:00<24:43,58.62it/s] 50%|#####     |87140/173481[24:11<24:32,58.62it/s] 56%|#####5    |96936/173481[27:00<21:52,58.30it/s] 56%|#####6    |97588/173481[27:11<21:41,58.30it/s] 62%|######1   |107171/173481[30:00<19:11,57.57it/s] 62%|######2   |107847/173481[30:11<19:00,57.57it/s] 68%|######7   |117836/173481[33:00<15:52,58.39it/s] 68%|######8   |118503/173481[33:11<15:41,58.39it/s] 74%|#######4  |128541/173481[36:00<12:42,58.92it/s] 74%|#######4  |129205/173481[36:11<12:31,58.92it/s] 80%|########  |139226/173481[39:00<09:39,59.14it/s] 81%|########  |139898/173481[39:11<09:27,59.14it/s] 86%|########6 |149711/173481[42:00<06:45,58.69it/s] 87%|########6 |150390/173481[42:12<06:33,58.69it/s] 92%|#########2|160096/173481[45:00<03:50,58.18it/s] 93%|#########2|160765/173481[45:12<03:38,58.18it/s] 98%|#########8|170211/173481[48:00<00:57,57.17it/s] 99%|#########8|170893/173481[48:12<00:45,57.17it/s]100%|##########|173481/173481[48:59<00:00,59.02it/s]
[32m[0328 21:20:50 @base.py:257][0m Epoch 11 (global_step 12317151) finished, time:2939.27 sec.
[32m[0328 21:20:50 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:31<00:00,205.13it/s]
10
[32m[0328 21:22:22 @monitor.py:363][0m QueueInput/queue_size: 0.50565
[32m[0328 21:22:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.653
[32m[0328 21:22:22 @monitor.py:363][0m activation-summaries/output-rms: 0.042082
[32m[0328 21:22:22 @monitor.py:363][0m cross_entropy_loss: 1.5008
[32m[0328 21:22:22 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 21:22:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 21:22:22 @monitor.py:363][0m train-error-top1: 0.39935
[32m[0328 21:22:22 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0328 21:22:22 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0328 21:22:22 @monitor.py:363][0m validation_cost: 1.5514
[32m[0328 21:22:22 @monitor.py:363][0m wd_cost: 2.3468e-17
[32m[0328 21:22:22 @group.py:42][0m Callbacks took 92.139 sec in total. InferenceRunner: 91.768sec
[32m[0328 21:22:22 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11045/173481[03:00<44:07,61.35it/s]  7%|6         |11634/173481[03:10<43:58,61.35it/s] 12%|#2        |21622/173481[06:00<42:09,60.03it/s] 13%|#2        |22259/173481[06:10<41:59,60.03it/s] 19%|#8        |32275/173481[09:00<39:29,59.60it/s] 19%|#8        |32859/173481[09:10<39:19,59.60it/s] 24%|##4       |41995/173481[12:00<38:40,56.65it/s] 24%|##4       |42481/173481[12:10<38:32,56.65it/s] 30%|##9       |51995/173481[15:00<36:05,56.10it/s] 30%|###       |52586/173481[15:10<35:55,56.10it/s] 36%|###6      |62811/173481[18:00<31:47,58.02it/s] 37%|###6      |63395/173481[18:10<31:37,58.02it/s] 42%|####2     |73495/173481[21:00<28:23,58.68it/s] 43%|####2     |74199/173481[21:11<28:11,58.68it/s] 49%|####8     |84264/173481[24:00<25:05,59.25it/s] 49%|####8     |84894/173481[24:11<24:55,59.25it/s] 55%|#####4    |94755/173481[27:00<22:20,58.75it/s] 55%|#####4    |95404/173481[27:11<22:08,58.75it/s] 61%|######    |105014/173481[30:00<19:43,57.86it/s] 61%|######    |105665/173481[30:11<19:32,57.86it/s] 67%|######6   |115398/173481[33:00<16:45,57.77it/s] 67%|######6   |116017/173481[33:11<16:34,57.77it/s] 72%|#######2  |125470/173481[36:00<14:04,56.84it/s] 73%|#######2  |126084/173481[36:11<13:53,56.84it/s] 78%|#######8  |135868/173481[39:00<10:56,57.30it/s] 79%|#######8  |136556/173481[39:11<10:44,57.30it/s] 85%|########4 |146695/173481[42:00<07:36,58.69it/s] 85%|########4 |147395/173481[42:12<07:24,58.69it/s] 91%|######### |157455/173481[45:00<04:30,59.22it/s] 91%|#########1|158116/173481[45:12<04:19,59.22it/s] 97%|#########6|167900/173481[48:00<01:35,58.61it/s] 97%|#########7|168639/173481[48:12<01:22,58.61it/s]100%|##########|173481/173481[49:34<00:00,58.32it/s]
[32m[0328 22:11:56 @base.py:257][0m Epoch 12 (global_step 12490632) finished, time:2974.52 sec.
[32m[0328 22:11:57 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-12490632.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,208.76it/s]
11
[32m[0328 22:13:27 @monitor.py:363][0m QueueInput/queue_size: 0.28949
[32m[0328 22:13:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.815
[32m[0328 22:13:27 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0328 22:13:27 @monitor.py:363][0m cross_entropy_loss: 1.5276
[32m[0328 22:13:27 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 22:13:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 22:13:27 @monitor.py:363][0m train-error-top1: 0.41298
[32m[0328 22:13:27 @monitor.py:363][0m val-error-top1: 0.41585
[32m[0328 22:13:27 @monitor.py:363][0m val-utt-error: 0.09032
[32m[0328 22:13:27 @monitor.py:363][0m validation_cost: 1.5502
[32m[0328 22:13:27 @monitor.py:363][0m wd_cost: 4.6935e-18
[32m[0328 22:13:27 @group.py:42][0m Callbacks took 90.489 sec in total. InferenceRunner: 90.175sec
[32m[0328 22:13:27 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11944/173481[03:00<40:34,66.36it/s]  7%|7         |12613/173481[03:10<40:24,66.36it/s] 13%|#3        |22889/173481[06:00<39:33,63.45it/s] 14%|#3        |23493/173481[06:10<39:23,63.45it/s] 19%|#8        |32601/173481[09:00<40:15,58.32it/s] 19%|#9        |33168/173481[09:10<40:06,58.32it/s] 25%|##4       |42884/173481[12:00<37:43,57.71it/s] 25%|##5       |43443/173481[12:10<37:33,57.71it/s] 31%|###       |53413/173481[15:00<34:26,58.10it/s] 31%|###1      |54043/173481[15:10<34:15,58.10it/s] 37%|###6      |63869/173481[18:00<31:26,58.09it/s] 37%|###7      |64548/173481[18:10<31:15,58.09it/s] 43%|####3     |75374/173481[21:00<26:52,60.86it/s] 44%|####3     |76123/173481[21:11<26:39,60.86it/s] 50%|#####     |86770/173481[24:00<23:17,62.06it/s] 50%|#####     |87403/173481[24:11<23:07,62.06it/s] 56%|#####6    |97339/173481[27:00<21:01,60.34it/s] 56%|#####6    |98013/173481[27:11<20:50,60.34it/s] 62%|######2   |108054/173481[30:00<18:11,59.93it/s] 63%|######2   |108723/173481[30:11<18:00,59.93it/s] 69%|######8   |118864/173481[33:00<15:10,59.99it/s] 69%|######8   |119538/173481[33:11<14:59,59.99it/s] 75%|#######4  |129614/173481[36:00<12:12,59.85it/s] 75%|#######5  |130318/173481[36:11<12:01,59.85it/s] 81%|########1 |140524/173481[39:00<09:07,60.22it/s] 81%|########1 |141257/173481[39:12<08:55,60.22it/s] 87%|########7 |151579/173481[42:00<06:00,60.81it/s] 88%|########7 |152319/173481[42:12<05:48,60.81it/s] 94%|#########3|162820/173481[45:00<02:53,61.62it/s] 94%|#########4|163630/173481[45:12<02:39,61.62it/s]100%|##########|173481/173481[47:43<00:00,60.59it/s]
[32m[0328 23:01:10 @base.py:257][0m Epoch 13 (global_step 12664113) finished, time:2863.35 sec.
[32m[0328 23:01:11 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,208.15it/s]
12
[32m[0328 23:02:41 @monitor.py:363][0m QueueInput/queue_size: 0.27698
[32m[0328 23:02:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.686
[32m[0328 23:02:41 @monitor.py:363][0m activation-summaries/output-rms: 0.04173
[32m[0328 23:02:41 @monitor.py:363][0m cross_entropy_loss: 1.5085
[32m[0328 23:02:41 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 23:02:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 23:02:41 @monitor.py:363][0m train-error-top1: 0.40654
[32m[0328 23:02:41 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0328 23:02:41 @monitor.py:363][0m val-utt-error: 0.090585
[32m[0328 23:02:41 @monitor.py:363][0m validation_cost: 1.5507
[32m[0328 23:02:41 @monitor.py:363][0m wd_cost: 4.6935e-18
[32m[0328 23:02:41 @group.py:42][0m Callbacks took 90.656 sec in total. InferenceRunner: 90.435sec
[32m[0328 23:02:41 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11514/173481[03:00<42:12,63.97it/s]  7%|6         |12129/173481[03:10<42:02,63.97it/s] 13%|#2        |22293/173481[06:00<40:44,61.85it/s] 13%|#3        |22937/173481[06:10<40:33,61.85it/s] 19%|#9        |33238/173481[09:00<38:06,61.32it/s] 20%|#9        |33866/173481[09:10<37:56,61.32it/s] 26%|##5       |44454/173481[12:00<34:47,61.81it/s] 26%|##6       |45137/173481[12:10<34:36,61.81it/s] 32%|###2      |55753/173481[15:00<31:30,62.29it/s] 32%|###2      |56372/173481[15:10<31:20,62.29it/s] 39%|###8      |67058/173481[18:00<28:21,62.53it/s] 39%|###9      |67732/173481[18:10<28:11,62.53it/s] 45%|####5     |78424/173481[21:00<25:12,62.84it/s] 46%|####5     |79109/173481[21:11<25:01,62.84it/s] 52%|#####1    |89713/173481[24:00<22:14,62.78it/s] 52%|#####2    |90417/173481[24:11<22:03,62.78it/s] 58%|#####8    |101098/173481[27:00<19:08,63.01it/s] 59%|#####8    |101737/173481[27:11<18:58,63.01it/s] 65%|######4   |112138/173481[30:00<16:26,62.16it/s] 65%|######5   |112797/173481[30:11<16:16,62.16it/s] 71%|#######   |123043/173481[33:00<13:42,61.35it/s] 71%|#######1  |123712/173481[33:11<13:31,61.35it/s] 77%|#######7  |134113/173481[36:00<10:40,61.43it/s] 78%|#######7  |134817/173481[36:11<10:29,61.43it/s] 84%|########3 |145373/173481[39:00<07:33,61.97it/s] 84%|########4 |146102/173481[39:11<07:21,61.97it/s] 90%|######### |156733/173481[42:00<04:27,62.53it/s] 91%|######### |157492/173481[42:12<04:15,62.53it/s] 97%|#########6|167813/173481[45:00<01:31,62.03it/s] 97%|#########7|168477/173481[45:12<01:20,62.03it/s]100%|##########|173481/173481[46:39<00:00,61.98it/s]
[32m[0328 23:49:20 @base.py:257][0m Epoch 14 (global_step 12837594) finished, time:2799.18 sec.
[32m[0328 23:49:20 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:31<00:00,206.66it/s]
13
[32m[0328 23:50:52 @monitor.py:363][0m QueueInput/queue_size: 0.22061
[32m[0328 23:50:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0328 23:50:52 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0328 23:50:52 @monitor.py:363][0m cross_entropy_loss: 1.5057
[32m[0328 23:50:52 @monitor.py:363][0m lr: 7.4506e-12
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0328 23:50:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0328 23:50:52 @monitor.py:363][0m train-error-top1: 0.40851
[32m[0328 23:50:52 @monitor.py:363][0m val-error-top1: 0.41551
[32m[0328 23:50:52 @monitor.py:363][0m val-utt-error: 0.090054
[32m[0328 23:50:52 @monitor.py:363][0m validation_cost: 1.551
[32m[0328 23:50:52 @monitor.py:363][0m wd_cost: 4.6935e-18
[32m[0328 23:50:52 @group.py:42][0m Callbacks took 91.459 sec in total. InferenceRunner: 91.091sec
[32m[0328 23:50:52 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11262/173481[03:00<43:13,62.56it/s]  7%|6         |11876/173481[03:10<43:03,62.56it/s] 13%|#2        |22312/173481[06:00<40:39,61.96it/s] 13%|#3        |22863/173481[06:10<40:30,61.96it/s] 19%|#9        |33661/173481[09:00<37:17,62.50it/s] 20%|#9        |34350/173481[09:10<37:06,62.50it/s] 26%|##5       |44917/173481[12:00<34:16,62.51it/s] 26%|##6       |45546/173481[12:10<34:06,62.51it/s] 32%|###2      |56032/173481[15:00<31:30,62.12it/s] 33%|###2      |56671/173481[15:10<31:20,62.12it/s] 39%|###8      |67312/173481[18:00<28:21,62.39it/s] 39%|###9      |67971/173481[18:10<28:11,62.39it/s] 45%|####5     |78197/173481[21:00<25:51,61.41it/s] 45%|####5     |78848/173481[21:11<25:41,61.41it/s] 51%|#####1    |89192/173481[24:00<22:56,61.24it/s] 52%|#####1    |89871/173481[24:11<22:45,61.24it/s] 58%|#####7    |99997/173481[27:00<20:12,60.63it/s] 58%|#####8    |100690/173481[27:11<20:00,60.63it/s] 64%|######3   |110714/173481[30:00<17:24,60.08it/s] 64%|######4   |111389/173481[30:11<17:13,60.08it/s] 70%|######9   |121327/173481[33:00<14:36,59.50it/s] 70%|#######   |122011/173481[33:11<14:24,59.50it/s] 76%|#######6  |132212/173481[36:00<11:28,59.98it/s] 77%|#######6  |132888/173481[36:11<11:16,59.98it/s] 82%|########2 |143114/173481[39:00<08:23,60.27it/s] 83%|########2 |143835/173481[39:11<08:11,60.27it/s] 89%|########8 |154087/173481[42:00<05:19,60.61it/s] 89%|########9 |154812/173481[42:12<05:08,60.61it/s] 95%|#########5|165039/173481[45:00<02:19,60.73it/s] 96%|#########5|165738/173481[45:12<02:07,60.73it/s]100%|##########|173481/173481[47:23<00:00,61.02it/s]
[32m[0329 00:38:15 @base.py:257][0m Epoch 15 (global_step 13011075) finished, time:2843.25 sec.
[32m[0329 00:38:15 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-13011075.
[32m[0329 00:38:15 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,207.58it/s]
14
[32m[0329 00:39:46 @monitor.py:363][0m QueueInput/queue_size: 0.29133
[32m[0329 00:39:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.753
[32m[0329 00:39:46 @monitor.py:363][0m activation-summaries/output-rms: 0.04355
[32m[0329 00:39:46 @monitor.py:363][0m cross_entropy_loss: 1.4886
[32m[0329 00:39:46 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 00:39:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 00:39:46 @monitor.py:363][0m train-error-top1: 0.40585
[32m[0329 00:39:46 @monitor.py:363][0m val-error-top1: 0.41643
[32m[0329 00:39:46 @monitor.py:363][0m val-utt-error: 0.092604
[32m[0329 00:39:46 @monitor.py:363][0m validation_cost: 1.5522
[32m[0329 00:39:46 @monitor.py:363][0m wd_cost: 9.3871e-19
[32m[0329 00:39:46 @group.py:42][0m Callbacks took 91.519 sec in total. InferenceRunner: 90.686sec
[32m[0329 00:39:46 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11457/173481[03:00<42:25,63.65it/s]  7%|6         |12061/173481[03:10<42:16,63.65it/s] 13%|#2        |22246/173481[06:00<40:50,61.73it/s] 13%|#3        |22860/173481[06:10<40:40,61.73it/s] 19%|#9        |32971/173481[09:00<38:37,60.63it/s] 19%|#9        |33570/173481[09:10<38:27,60.63it/s] 25%|##4       |43351/173481[12:00<36:41,59.11it/s] 25%|##5       |43962/173481[12:10<36:31,59.11it/s] 31%|###       |53587/173481[15:00<34:28,57.96it/s] 31%|###1      |54195/173481[15:10<34:17,57.96it/s] 37%|###7      |64281/173481[18:00<31:01,58.67it/s] 37%|###7      |64897/173481[18:10<30:50,58.67it/s] 43%|####2     |74571/173481[21:00<28:28,57.90it/s] 43%|####3     |75199/173481[21:11<28:17,57.90it/s] 49%|####9     |85191/173481[24:00<25:10,58.44it/s] 49%|####9     |85821/173481[24:11<24:59,58.44it/s] 55%|#####5    |95706/173481[27:00<22:11,58.43it/s] 56%|#####5    |96340/173481[27:11<22:00,58.43it/s] 61%|######1   |106136/173481[30:00<19:17,58.17it/s] 62%|######1   |106795/173481[30:11<19:06,58.17it/s] 67%|######7   |116856/173481[33:00<16:02,58.85it/s] 68%|######7   |117555/173481[33:11<15:50,58.85it/s] 74%|#######3  |127716/173481[36:00<12:48,59.58it/s] 74%|#######4  |128385/173481[36:11<12:36,59.58it/s] 80%|#######9  |138581/173481[39:00<09:42,59.96it/s] 80%|########  |139283/173481[39:11<09:30,59.96it/s] 86%|########6 |149380/173481[42:00<06:41,59.98it/s] 86%|########6 |150045/173481[42:12<06:30,59.98it/s] 92%|#########2|159721/173481[45:00<03:54,58.68it/s] 92%|#########2|160402/173481[45:12<03:42,58.68it/s] 98%|#########7|170006/173481[48:00<01:00,57.89it/s] 98%|#########8|170700/173481[48:12<00:48,57.89it/s]100%|##########|173481/173481[49:00<00:00,59.00it/s]
[32m[0329 01:28:47 @base.py:257][0m Epoch 16 (global_step 13184556) finished, time:2940.43 sec.
[32m[0329 01:28:47 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,208.77it/s]
15
[32m[0329 01:30:17 @monitor.py:363][0m QueueInput/queue_size: 0.43066
[32m[0329 01:30:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.653
[32m[0329 01:30:17 @monitor.py:363][0m activation-summaries/output-rms: 0.042082
[32m[0329 01:30:17 @monitor.py:363][0m cross_entropy_loss: 1.5008
[32m[0329 01:30:17 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 01:30:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 01:30:17 @monitor.py:363][0m train-error-top1: 0.39935
[32m[0329 01:30:17 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0329 01:30:17 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0329 01:30:17 @monitor.py:363][0m validation_cost: 1.5514
[32m[0329 01:30:17 @monitor.py:363][0m wd_cost: 9.3871e-19
[32m[0329 01:30:17 @group.py:42][0m Callbacks took 90.564 sec in total. InferenceRunner: 90.171sec
[32m[0329 01:30:17 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11027/173481[03:00<44:11,61.26it/s]  7%|6         |11609/173481[03:10<44:02,61.26it/s] 12%|#2        |21480/173481[06:00<42:29,59.62it/s] 13%|#2        |22075/173481[06:10<42:19,59.62it/s] 18%|#8        |31754/173481[09:00<40:30,58.32it/s] 19%|#8        |32334/173481[09:10<40:20,58.32it/s] 24%|##3       |41345/173481[12:00<39:32,55.68it/s] 24%|##4       |41909/173481[12:10<39:22,55.68it/s] 30%|##9       |51210/173481[15:00<36:53,55.24it/s] 30%|##9       |51805/173481[15:10<36:42,55.24it/s] 36%|###5      |61600/173481[18:00<33:01,56.45it/s] 36%|###5      |62209/173481[18:10<32:51,56.45it/s] 41%|####1     |71930/173481[21:00<29:44,56.91it/s] 42%|####1     |72589/173481[21:11<29:32,56.91it/s] 48%|####7     |82529/173481[24:00<26:11,57.88it/s] 48%|####7     |83160/173481[24:11<26:00,57.88it/s] 54%|#####3    |93095/173481[27:00<22:59,58.28it/s] 54%|#####4    |93779/173481[27:11<22:47,58.28it/s] 60%|#####9    |103565/173481[30:00<20:00,58.22it/s] 60%|######    |104199/173481[30:11<19:49,58.22it/s] 66%|######5   |114051/173481[33:00<17:00,58.24it/s] 66%|######6   |114729/173481[33:11<16:48,58.24it/s] 72%|#######1  |124610/173481[36:00<13:56,58.45it/s] 72%|#######2  |125274/173481[36:11<13:44,58.45it/s] 78%|#######7  |135160/173481[39:00<10:54,58.53it/s] 78%|#######8  |135855/173481[39:11<10:42,58.53it/s] 84%|########4 |145745/173481[42:00<07:53,58.61it/s] 84%|########4 |146455/173481[42:12<07:41,58.61it/s] 90%|######### |156710/173481[45:00<04:40,59.74it/s] 91%|######### |157392/173481[45:12<04:29,59.74it/s] 97%|#########6|167760/173481[48:00<01:34,60.55it/s] 97%|#########7|168474/173481[48:12<01:22,60.55it/s]100%|##########|173481/173481[49:32<00:00,58.36it/s]
[32m[0329 02:19:50 @base.py:257][0m Epoch 17 (global_step 13358037) finished, time:2972.77 sec.
[32m[0329 02:19:50 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,211.39it/s]
16
[32m[0329 02:21:20 @monitor.py:363][0m QueueInput/queue_size: 0.43356
[32m[0329 02:21:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.815
[32m[0329 02:21:20 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0329 02:21:20 @monitor.py:363][0m cross_entropy_loss: 1.5277
[32m[0329 02:21:20 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 02:21:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 02:21:20 @monitor.py:363][0m train-error-top1: 0.41303
[32m[0329 02:21:20 @monitor.py:363][0m val-error-top1: 0.41584
[32m[0329 02:21:20 @monitor.py:363][0m val-utt-error: 0.090373
[32m[0329 02:21:20 @monitor.py:363][0m validation_cost: 1.5502
[32m[0329 02:21:20 @monitor.py:363][0m wd_cost: 9.3871e-19
[32m[0329 02:21:20 @group.py:42][0m Callbacks took 89.417 sec in total. InferenceRunner: 89.053sec
[32m[0329 02:21:20 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13124/173481[03:00<36:39,72.90it/s]  8%|7         |13783/173481[03:10<36:30,72.90it/s] 14%|#4        |24374/173481[06:00<36:55,67.30it/s] 14%|#4        |24943/173481[06:10<36:47,67.30it/s] 20%|#9        |34614/173481[09:00<37:32,61.66it/s] 20%|##        |35265/173481[09:10<37:21,61.66it/s] 26%|##6       |45524/173481[12:00<34:53,61.12it/s] 27%|##6       |46273/173481[12:10<34:41,61.12it/s] 33%|###2      |56392/173481[15:00<32:07,60.75it/s] 33%|###2      |57003/173481[15:10<31:57,60.75it/s] 39%|###8      |67414/173481[18:00<28:59,60.97it/s] 39%|###9      |68048/173481[18:10<28:49,60.97it/s] 46%|####5     |79414/173481[21:00<24:37,63.69it/s] 46%|####6     |80053/173481[21:10<24:27,63.69it/s] 52%|#####2    |90309/173481[24:00<22:20,62.07it/s] 52%|#####2    |90960/173481[24:11<22:09,62.07it/s] 58%|#####8    |100849/173481[27:00<20:05,60.26it/s] 59%|#####8    |101488/173481[27:11<19:54,60.26it/s] 64%|######4   |111620/173481[30:00<17:10,60.05it/s] 65%|######4   |112338/173481[30:11<16:58,60.05it/s] 71%|#######   |122629/173481[33:00<13:59,60.60it/s] 71%|#######1  |123299/173481[33:11<13:48,60.60it/s] 77%|#######6  |133539/173481[36:00<10:59,60.59it/s] 77%|#######7  |134238/173481[36:11<10:47,60.59it/s] 83%|########3 |144699/173481[39:00<07:49,61.28it/s] 84%|########3 |145399/173481[39:11<07:38,61.28it/s] 90%|########9 |155735/173481[42:00<04:49,61.29it/s] 90%|######### |156478/173481[42:11<04:37,61.29it/s] 96%|#########6|167069/173481[45:00<01:43,62.11it/s] 97%|#########6|167763/173481[45:12<01:32,62.11it/s]100%|##########|173481/173481[46:45<00:00,61.84it/s]
[32m[0329 03:08:05 @base.py:257][0m Epoch 18 (global_step 13531518) finished, time:2805.27 sec.
[32m[0329 03:08:05 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-13531518.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,209.73it/s]
17
[32m[0329 03:09:35 @monitor.py:363][0m QueueInput/queue_size: 0.47905
[32m[0329 03:09:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.686
[32m[0329 03:09:35 @monitor.py:363][0m activation-summaries/output-rms: 0.04173
[32m[0329 03:09:35 @monitor.py:363][0m cross_entropy_loss: 1.5085
[32m[0329 03:09:35 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 03:09:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 03:09:35 @monitor.py:363][0m train-error-top1: 0.40654
[32m[0329 03:09:35 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0329 03:09:35 @monitor.py:363][0m val-utt-error: 0.090585
[32m[0329 03:09:35 @monitor.py:363][0m validation_cost: 1.5507
[32m[0329 03:09:35 @monitor.py:363][0m wd_cost: 1.8774e-19
[32m[0329 03:09:35 @group.py:42][0m Callbacks took 89.998 sec in total. InferenceRunner: 89.755sec
[32m[0329 03:09:35 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11738/173481[03:00<41:20,65.21it/s]  7%|7         |12362/173481[03:10<41:10,65.21it/s] 13%|#2        |22308/173481[06:00<40:46,61.79it/s] 13%|#3        |22941/173481[06:10<40:36,61.79it/s] 19%|#9        |33043/173481[09:00<38:33,60.69it/s] 19%|#9        |33632/173481[09:10<38:24,60.69it/s] 25%|##5       |44223/173481[12:00<35:05,61.39it/s] 26%|##5       |44892/173481[12:10<34:54,61.39it/s] 32%|###1      |55369/173481[15:00<31:55,61.66it/s] 32%|###2      |55987/173481[15:10<31:45,61.66it/s] 38%|###8      |66340/173481[18:00<29:07,61.30it/s] 39%|###8      |66997/173481[18:10<28:57,61.30it/s] 45%|####4     |77353/173481[21:00<26:09,61.24it/s] 45%|####4     |78007/173481[21:11<25:59,61.24it/s] 51%|#####     |88068/173481[24:00<23:34,60.36it/s] 51%|#####1    |88732/173481[24:11<23:23,60.36it/s] 57%|#####7    |99213/173481[27:00<20:14,61.13it/s] 58%|#####7    |99869/173481[27:11<20:04,61.13it/s] 63%|######3   |110017/173481[30:00<17:27,60.57it/s] 64%|######3   |110707/173481[30:11<17:16,60.57it/s] 70%|######9   |120830/173481[33:00<14:32,60.32it/s] 70%|#######   |121527/173481[33:11<14:21,60.32it/s] 76%|#######5  |131426/173481[36:00<11:45,59.58it/s] 76%|#######6  |132112/173481[36:11<11:34,59.58it/s] 82%|########2 |142308/173481[39:00<08:39,60.01it/s] 82%|########2 |143017/173481[39:11<08:27,60.01it/s] 88%|########8 |153331/173481[42:00<05:32,60.62it/s] 89%|########8 |154064/173481[42:11<05:20,60.62it/s] 95%|#########4|164270/173481[45:00<02:31,60.70it/s] 95%|#########5|165002/173481[45:12<02:19,60.70it/s]100%|##########|173481/173481[47:39<00:00,60.66it/s]
[32m[0329 03:57:15 @base.py:257][0m Epoch 19 (global_step 13704999) finished, time:2859.74 sec.
[32m[0329 03:57:15 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-13704999.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,208.62it/s]
18
[32m[0329 03:58:45 @monitor.py:363][0m QueueInput/queue_size: 0.49311
[32m[0329 03:58:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0329 03:58:45 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0329 03:58:45 @monitor.py:363][0m cross_entropy_loss: 1.5057
[32m[0329 03:58:45 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 03:58:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 03:58:45 @monitor.py:363][0m train-error-top1: 0.40851
[32m[0329 03:58:45 @monitor.py:363][0m val-error-top1: 0.41551
[32m[0329 03:58:45 @monitor.py:363][0m val-utt-error: 0.090054
[32m[0329 03:58:45 @monitor.py:363][0m validation_cost: 1.551
[32m[0329 03:58:45 @monitor.py:363][0m wd_cost: 1.8774e-19
[32m[0329 03:58:45 @group.py:42][0m Callbacks took 90.510 sec in total. InferenceRunner: 90.234sec
[32m[0329 03:58:45 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11067/173481[03:00<44:02,61.47it/s]  7%|6         |11666/173481[03:10<43:52,61.47it/s] 13%|#2        |21853/173481[06:00<41:38,60.69it/s] 13%|#2        |22401/173481[06:10<41:29,60.69it/s] 19%|#8        |32937/173481[09:00<38:19,61.13it/s] 19%|#9        |33612/173481[09:10<38:08,61.13it/s] 25%|##5       |44232/173481[12:00<34:47,61.93it/s] 26%|##5       |44891/173481[12:10<34:36,61.93it/s] 32%|###1      |55367/173481[15:00<31:48,61.89it/s] 32%|###2      |56031/173481[15:10<31:37,61.89it/s] 38%|###8      |66461/173481[18:00<28:52,61.76it/s] 39%|###8      |67145/173481[18:10<28:41,61.76it/s] 45%|####4     |77453/173481[21:00<26:03,61.41it/s] 45%|####5     |78119/173481[21:11<25:52,61.41it/s] 51%|#####1    |88482/173481[24:00<23:05,61.34it/s] 51%|#####1    |89153/173481[24:11<22:54,61.34it/s] 57%|#####7    |99362/173481[27:00<20:17,60.88it/s] 58%|#####7    |100076/173481[27:11<20:05,60.88it/s] 64%|######3   |110437/173481[30:00<17:10,61.20it/s] 64%|######4   |111111/173481[30:11<16:59,61.20it/s] 70%|######9   |121227/173481[33:00<14:22,60.56it/s] 70%|#######   |121916/173481[33:11<14:11,60.56it/s] 76%|#######6  |132132/173481[36:00<11:22,60.57it/s] 77%|#######6  |132803/173481[36:11<11:11,60.57it/s] 82%|########2 |142727/173481[39:00<08:35,59.70it/s] 83%|########2 |143430/173481[39:11<08:23,59.70it/s] 89%|########8 |153787/173481[42:00<05:25,60.56it/s] 89%|########9 |154556/173481[42:12<05:12,60.56it/s] 95%|#########5|165607/173481[45:00<02:04,63.01it/s] 96%|#########5|166406/173481[45:12<01:52,63.01it/s]100%|##########|173481/173481[46:50<00:00,61.74it/s]
[32m[0329 04:45:35 @base.py:257][0m Epoch 20 (global_step 13878480) finished, time:2810.04 sec.
[32m[0329 04:45:35 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-13878480.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,209.05it/s]
19
[32m[0329 04:47:06 @monitor.py:363][0m QueueInput/queue_size: 0.5423
[32m[0329 04:47:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.753
[32m[0329 04:47:06 @monitor.py:363][0m activation-summaries/output-rms: 0.04355
[32m[0329 04:47:06 @monitor.py:363][0m cross_entropy_loss: 1.4886
[32m[0329 04:47:06 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 04:47:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 04:47:06 @monitor.py:363][0m train-error-top1: 0.40585
[32m[0329 04:47:06 @monitor.py:363][0m val-error-top1: 0.41643
[32m[0329 04:47:06 @monitor.py:363][0m val-utt-error: 0.092604
[32m[0329 04:47:06 @monitor.py:363][0m validation_cost: 1.5522
[32m[0329 04:47:06 @monitor.py:363][0m wd_cost: 1.8774e-19
[32m[0329 04:47:06 @group.py:42][0m Callbacks took 90.423 sec in total. InferenceRunner: 90.050sec
[32m[0329 04:47:06 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15586/173481[03:00<30:23,86.58it/s]  9%|9         |16445/173481[03:10<30:13,86.58it/s] 16%|#5        |26910/173481[06:00<33:31,72.87it/s] 16%|#5        |27535/173481[06:10<33:22,72.87it/s] 22%|##1       |37381/173481[09:00<35:04,64.68it/s] 22%|##1       |37998/173481[09:10<34:54,64.68it/s] 28%|##7       |47966/173481[12:00<33:57,61.60it/s] 28%|##8       |48586/173481[12:10<33:47,61.60it/s] 34%|###3      |58666/173481[15:00<31:37,60.49it/s] 34%|###4      |59328/173481[15:10<31:26,60.49it/s] 40%|###9      |69298/173481[18:00<29:03,59.77it/s] 40%|####      |69900/173481[18:10<28:52,59.77it/s] 46%|####5     |79601/173481[21:00<26:45,58.47it/s] 46%|####6     |80253/173481[21:11<26:34,58.47it/s] 52%|#####1    |90172/173481[24:00<23:41,58.60it/s] 52%|#####2    |90840/173481[24:11<23:30,58.60it/s] 58%|#####8    |100671/173481[27:00<20:45,58.46it/s] 58%|#####8    |101320/173481[27:11<20:34,58.46it/s] 64%|######4   |111179/173481[30:00<17:46,58.42it/s] 64%|######4   |111863/173481[30:11<17:34,58.42it/s] 70%|#######   |121852/173481[33:00<14:37,58.85it/s] 71%|#######   |122516/173481[33:11<14:25,58.85it/s] 77%|#######6  |132730/173481[36:00<11:23,59.63it/s] 77%|#######6  |133439/173481[36:11<11:11,59.63it/s] 84%|########3 |145221/173481[39:00<07:20,64.14it/s] 84%|########4 |146305/173481[39:11<07:03,64.14it/s] 93%|#########3|161936/173481[42:00<02:32,75.87it/s] 94%|#########3|163040/173481[42:12<02:17,75.87it/s]100%|##########|173481/173481[44:07<00:00,65.54it/s]
[32m[0329 05:31:13 @base.py:257][0m Epoch 21 (global_step 14051961) finished, time:2647.06 sec.
[32m[0329 05:31:13 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-14051961.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,209.05it/s]
20
[32m[0329 05:32:43 @monitor.py:363][0m QueueInput/queue_size: 0.32699
[32m[0329 05:32:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.653
[32m[0329 05:32:43 @monitor.py:363][0m activation-summaries/output-rms: 0.042082
[32m[0329 05:32:43 @monitor.py:363][0m cross_entropy_loss: 1.5008
[32m[0329 05:32:43 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 05:32:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 05:32:43 @monitor.py:363][0m train-error-top1: 0.39935
[32m[0329 05:32:43 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0329 05:32:43 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0329 05:32:43 @monitor.py:363][0m validation_cost: 1.5514
[32m[0329 05:32:43 @monitor.py:363][0m wd_cost: 3.7548e-20
[32m[0329 05:32:43 @group.py:42][0m Callbacks took 90.324 sec in total. InferenceRunner: 90.050sec
[32m[0329 05:32:43 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11490/173481[03:00<42:17,63.83it/s]  7%|6         |12079/173481[03:10<42:08,63.83it/s] 13%|#2        |22335/173481[06:00<40:38,61.98it/s] 13%|#3        |22935/173481[06:10<40:28,61.98it/s] 19%|#8        |32665/173481[09:00<39:22,59.60it/s] 19%|#9        |33221/173481[09:10<39:13,59.60it/s] 24%|##4       |42345/173481[12:00<38:39,56.53it/s] 25%|##4       |42914/173481[12:10<38:29,56.53it/s] 30%|###       |52315/173481[15:00<36:05,55.94it/s] 31%|###       |52935/173481[15:10<35:54,55.94it/s] 36%|###6      |62922/173481[18:00<32:06,57.40it/s] 37%|###6      |63499/173481[18:10<31:56,57.40it/s] 42%|####2     |73320/173481[21:00<28:59,57.58it/s] 43%|####2     |73989/173481[21:10<28:47,57.58it/s] 48%|####8     |84065/173481[24:00<25:25,58.61it/s] 49%|####8     |84719/173481[24:11<25:14,58.61it/s] 55%|#####4    |94702/173481[27:00<22:18,58.85it/s] 55%|#####4    |95344/173481[27:11<22:07,58.85it/s] 61%|######    |105295/173481[30:00<19:18,58.85it/s] 61%|######1   |105939/173481[30:11<19:07,58.85it/s] 67%|######6   |115760/173481[33:00<16:27,58.47it/s] 67%|######7   |116389/173481[33:11<16:16,58.47it/s] 73%|#######2  |126095/173481[36:00<13:37,57.93it/s] 73%|#######3  |126754/173481[36:11<13:26,57.93it/s] 79%|#######8  |136555/173481[39:00<10:36,58.02it/s] 79%|#######9  |137239/173481[39:11<10:24,58.02it/s] 85%|########4 |147200/173481[42:00<07:28,58.57it/s] 85%|########5 |147889/173481[42:12<07:16,58.57it/s] 91%|#########1|157910/173481[45:00<04:23,59.03it/s] 91%|#########1|158584/173481[45:12<04:12,59.03it/s] 97%|#########7|168482/173481[48:00<01:24,58.88it/s] 98%|#########7|169194/173481[48:12<01:12,58.88it/s]100%|##########|173481/173481[49:23<00:00,58.55it/s]
[32m[0329 06:22:06 @base.py:257][0m Epoch 22 (global_step 14225442) finished, time:2963.17 sec.
[32m[0329 06:22:07 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-14225442.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,210.20it/s]
21
[32m[0329 06:23:36 @monitor.py:363][0m QueueInput/queue_size: 0.43571
[32m[0329 06:23:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.815
[32m[0329 06:23:36 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0329 06:23:36 @monitor.py:363][0m cross_entropy_loss: 1.5276
[32m[0329 06:23:36 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 06:23:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 06:23:36 @monitor.py:363][0m train-error-top1: 0.41299
[32m[0329 06:23:36 @monitor.py:363][0m val-error-top1: 0.41584
[32m[0329 06:23:36 @monitor.py:363][0m val-utt-error: 0.09032
[32m[0329 06:23:36 @monitor.py:363][0m validation_cost: 1.5502
[32m[0329 06:23:36 @monitor.py:363][0m wd_cost: 3.7548e-20
[32m[0329 06:23:36 @group.py:42][0m Callbacks took 90.110 sec in total. InferenceRunner: 89.558sec
[32m[0329 06:23:36 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13034/173481[03:00<36:55,72.40it/s]  8%|7         |13708/173481[03:10<36:46,72.40it/s] 14%|#3        |24249/173481[06:00<37:08,66.98it/s] 14%|#4        |24823/173481[06:10<36:59,66.98it/s] 20%|#9        |34579/173481[09:00<37:27,61.80it/s] 20%|##        |35261/173481[09:10<37:16,61.80it/s] 26%|##6       |45569/173481[12:00<34:42,61.43it/s] 27%|##6       |46358/173481[12:10<34:29,61.43it/s] 33%|###2      |56759/173481[15:00<31:29,61.79it/s] 33%|###3      |57371/173481[15:10<31:19,61.79it/s] 39%|###9      |67789/173481[18:00<28:37,61.53it/s] 39%|###9      |68439/173481[18:10<28:27,61.53it/s] 46%|####5     |79799/173481[21:00<24:23,64.01it/s] 46%|####6     |80448/173481[21:11<24:13,64.01it/s] 52%|#####2    |90649/173481[24:00<22:14,62.08it/s] 53%|#####2    |91323/173481[24:11<22:03,62.08it/s] 58%|#####8    |101261/173481[27:00<19:54,60.48it/s] 59%|#####8    |101902/173481[27:11<19:43,60.48it/s] 65%|######4   |112169/173481[30:00<16:52,60.53it/s] 65%|######5   |112905/173481[30:11<16:40,60.53it/s] 71%|#######1  |123294/173481[33:00<13:40,61.15it/s] 71%|#######1  |123969/173481[33:11<13:29,61.15it/s] 77%|#######7  |134344/173481[36:00<10:38,61.26it/s] 78%|#######7  |135043/173481[36:11<10:27,61.26it/s] 84%|########3 |145614/173481[39:00<07:30,61.91it/s] 84%|########4 |146317/173481[39:11<07:18,61.91it/s] 90%|######### |156764/173481[42:00<04:29,61.92it/s] 91%|######### |157478/173481[42:12<04:18,61.92it/s] 97%|#########6|167854/173481[45:00<01:31,61.76it/s] 97%|#########7|168594/173481[45:12<01:19,61.76it/s]100%|##########|173481/173481[46:32<00:00,62.13it/s]
[32m[0329 07:10:08 @base.py:257][0m Epoch 23 (global_step 14398923) finished, time:2792.13 sec.
[32m[0329 07:10:09 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-14398923.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,210.83it/s]
22
[32m[0329 07:11:38 @monitor.py:363][0m QueueInput/queue_size: 0.6866
[32m[0329 07:11:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.686
[32m[0329 07:11:38 @monitor.py:363][0m activation-summaries/output-rms: 0.04173
[32m[0329 07:11:38 @monitor.py:363][0m cross_entropy_loss: 1.5085
[32m[0329 07:11:38 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 07:11:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 07:11:38 @monitor.py:363][0m train-error-top1: 0.40654
[32m[0329 07:11:38 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0329 07:11:38 @monitor.py:363][0m val-utt-error: 0.090585
[32m[0329 07:11:38 @monitor.py:363][0m validation_cost: 1.5507
[32m[0329 07:11:38 @monitor.py:363][0m wd_cost: 3.7548e-20
[32m[0329 07:11:38 @group.py:42][0m Callbacks took 89.610 sec in total. InferenceRunner: 89.286sec
[32m[0329 07:11:38 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11498/173481[03:00<42:16,63.85it/s]  7%|6         |12107/173481[03:10<42:07,63.85it/s] 13%|#2        |21918/173481[06:00<41:36,60.72it/s] 13%|#2        |22532/173481[06:10<41:25,60.72it/s] 19%|#8        |32648/173481[09:00<39:00,60.16it/s] 19%|#9        |33227/173481[09:10<38:51,60.16it/s] 25%|##5       |43706/173481[12:00<35:34,60.79it/s] 26%|##5       |44332/173481[12:10<35:24,60.79it/s] 32%|###1      |54833/173481[15:00<32:15,61.29it/s] 32%|###1      |55451/173481[15:10<32:05,61.29it/s] 38%|###7      |65553/173481[18:00<29:46,60.41it/s] 38%|###8      |66216/173481[18:10<29:35,60.41it/s] 44%|####4     |76408/173481[21:00<26:48,60.35it/s] 44%|####4     |77089/173481[21:11<26:37,60.35it/s] 50%|#####     |87339/173481[24:00<23:42,60.54it/s] 51%|#####     |87982/173481[24:11<23:32,60.54it/s] 57%|#####6    |98278/173481[27:00<20:39,60.65it/s] 57%|#####7    |98964/173481[27:11<20:28,60.65it/s] 63%|######2   |109193/173481[30:00<17:40,60.64it/s] 63%|######3   |109902/173481[30:11<17:28,60.64it/s] 69%|######9   |120203/173481[33:00<14:35,60.88it/s] 70%|######9   |120905/173481[33:11<14:23,60.88it/s] 76%|#######5  |131063/173481[36:00<11:40,60.59it/s] 76%|#######5  |131724/173481[36:11<11:29,60.59it/s] 82%|########1 |141973/173481[39:00<08:39,60.60it/s] 82%|########2 |142667/173481[39:11<08:28,60.60it/s] 88%|########8 |153090/173481[42:00<05:33,61.17it/s] 89%|########8 |153803/173481[42:12<05:21,61.17it/s] 95%|#########4|164318/173481[45:00<02:28,61.77it/s] 95%|#########5|165052/173481[45:12<02:16,61.77it/s]100%|##########|173481/173481[47:34<00:00,60.78it/s]
[32m[0329 07:59:12 @base.py:257][0m Epoch 24 (global_step 14572404) finished, time:2854.33 sec.
[32m[0329 07:59:12 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-14572404.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,210.04it/s]
23
[32m[0329 08:00:42 @monitor.py:363][0m QueueInput/queue_size: 0.43304
[32m[0329 08:00:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0329 08:00:42 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0329 08:00:42 @monitor.py:363][0m cross_entropy_loss: 1.5057
[32m[0329 08:00:42 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 08:00:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 08:00:42 @monitor.py:363][0m train-error-top1: 0.40851
[32m[0329 08:00:42 @monitor.py:363][0m val-error-top1: 0.41551
[32m[0329 08:00:42 @monitor.py:363][0m val-utt-error: 0.090054
[32m[0329 08:00:42 @monitor.py:363][0m validation_cost: 1.551
[32m[0329 08:00:42 @monitor.py:363][0m wd_cost: 7.5097e-21
[32m[0329 08:00:42 @group.py:42][0m Callbacks took 89.887 sec in total. InferenceRunner: 89.623sec
[32m[0329 08:00:42 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11067/173481[03:00<44:01,61.48it/s]  7%|6         |11661/173481[03:10<43:52,61.48it/s] 13%|#2        |21862/173481[06:00<41:37,60.71it/s] 13%|#2        |22409/173481[06:10<41:28,60.71it/s] 19%|#8        |32744/173481[09:00<38:43,60.58it/s] 19%|#9        |33386/173481[09:10<38:32,60.58it/s] 25%|##5       |43810/173481[12:00<35:24,61.03it/s] 26%|##5       |44446/173481[12:10<35:14,61.03it/s] 32%|###1      |54972/173481[15:00<32:07,61.49it/s] 32%|###2      |55633/173481[15:10<31:56,61.49it/s] 38%|###8      |66037/173481[18:00<29:07,61.48it/s] 38%|###8      |66686/173481[18:10<28:57,61.48it/s] 44%|####4     |76772/173481[21:00<26:37,60.54it/s] 45%|####4     |77416/173481[21:11<26:26,60.54it/s] 51%|#####1    |88553/173481[24:00<22:30,62.90it/s] 52%|#####1    |89576/173481[24:11<22:13,62.90it/s] 59%|#####8    |102103/173481[27:00<17:21,68.53it/s] 59%|#####9    |102784/173481[27:11<17:11,68.53it/s] 65%|######5   |112842/173481[30:00<15:50,63.79it/s] 65%|######5   |113535/173481[30:11<15:39,63.79it/s] 71%|#######1  |123493/173481[33:00<13:34,61.39it/s] 72%|#######1  |124176/173481[33:11<13:23,61.39it/s] 78%|#######7  |134942/173481[36:00<10:16,62.48it/s] 78%|#######8  |135761/173481[36:11<10:03,62.48it/s] 87%|########6 |150078/173481[39:00<05:26,71.69it/s] 87%|########7 |151131/173481[39:11<05:11,71.69it/s] 96%|#########5|166322/173481[42:00<01:29,79.90it/s] 96%|#########6|167376/173481[42:12<01:16,79.90it/s]100%|##########|173481/173481[43:44<00:00,66.10it/s]
[32m[0329 08:44:27 @base.py:257][0m Epoch 25 (global_step 14745885) finished, time:2624.46 sec.
[32m[0329 08:44:27 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-14745885.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,211.45it/s]
24
[32m[0329 08:45:56 @monitor.py:363][0m QueueInput/queue_size: 0.30805
[32m[0329 08:45:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.753
[32m[0329 08:45:56 @monitor.py:363][0m activation-summaries/output-rms: 0.04355
[32m[0329 08:45:56 @monitor.py:363][0m cross_entropy_loss: 1.4886
[32m[0329 08:45:56 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 08:45:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 08:45:56 @monitor.py:363][0m train-error-top1: 0.40585
[32m[0329 08:45:56 @monitor.py:363][0m val-error-top1: 0.41643
[32m[0329 08:45:56 @monitor.py:363][0m val-utt-error: 0.092604
[32m[0329 08:45:56 @monitor.py:363][0m validation_cost: 1.5522
[32m[0329 08:45:56 @monitor.py:363][0m wd_cost: 7.5097e-21
[32m[0329 08:45:56 @group.py:42][0m Callbacks took 89.415 sec in total. InferenceRunner: 89.033sec
[32m[0329 08:45:56 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11726/173481[03:00<41:23,65.13it/s]  7%|7         |12361/173481[03:10<41:13,65.13it/s] 13%|#3        |22787/173481[06:00<39:43,63.23it/s] 13%|#3        |23396/173481[06:10<39:33,63.23it/s] 19%|#9        |33471/173481[09:00<38:06,61.23it/s] 20%|#9        |34085/173481[09:10<37:56,61.23it/s] 25%|##5       |44121/173481[12:00<35:49,60.18it/s] 26%|##5       |44735/173481[12:10<35:39,60.18it/s] 31%|###1      |54583/173481[15:00<33:30,59.13it/s] 32%|###1      |55200/173481[15:10<33:20,59.13it/s] 38%|###7      |65494/173481[18:00<30:03,59.86it/s] 38%|###8      |66170/173481[18:10<29:52,59.86it/s] 44%|####3     |75966/173481[21:00<27:32,59.00it/s] 44%|####4     |76586/173481[21:11<27:22,59.00it/s] 50%|####9     |86436/173481[24:00<24:45,58.58it/s] 50%|#####     |87065/173481[24:11<24:35,58.58it/s] 56%|#####5    |96887/173481[27:00<21:53,58.32it/s] 56%|#####6    |97547/173481[27:11<21:42,58.32it/s] 62%|######1   |107216/173481[30:00<19:05,57.84it/s] 62%|######2   |107870/173481[30:11<18:54,57.84it/s] 68%|######7   |117796/173481[33:00<15:55,58.30it/s] 68%|######8   |118445/173481[33:11<15:43,58.30it/s] 74%|#######4  |128396/173481[36:00<12:49,58.59it/s] 74%|#######4  |129098/173481[36:11<12:37,58.59it/s] 80%|########  |139121/173481[39:00<09:41,59.07it/s] 81%|########  |139795/173481[39:11<09:30,59.07it/s] 86%|########6 |149546/173481[42:00<06:49,58.48it/s] 87%|########6 |150215/173481[42:12<06:37,58.48it/s] 92%|#########2|159926/173481[45:00<03:53,58.06it/s] 93%|#########2|160591/173481[45:12<03:41,58.06it/s] 98%|#########8|170121/173481[48:00<00:58,57.34it/s] 98%|#########8|170825/173481[48:12<00:46,57.34it/s]100%|##########|173481/173481[48:59<00:00,59.03it/s]
[32m[0329 09:34:55 @base.py:257][0m Epoch 26 (global_step 14919366) finished, time:2939.02 sec.
[32m[0329 09:34:55 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-14919366.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:28<00:00,211.64it/s]
25
[32m[0329 09:36:24 @monitor.py:363][0m QueueInput/queue_size: 0.29969
[32m[0329 09:36:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.653
[32m[0329 09:36:24 @monitor.py:363][0m activation-summaries/output-rms: 0.042082
[32m[0329 09:36:24 @monitor.py:363][0m cross_entropy_loss: 1.5008
[32m[0329 09:36:24 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 09:36:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 09:36:24 @monitor.py:363][0m train-error-top1: 0.39935
[32m[0329 09:36:24 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0329 09:36:24 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0329 09:36:24 @monitor.py:363][0m validation_cost: 1.5514
[32m[0329 09:36:24 @monitor.py:363][0m wd_cost: 1.5019e-21
[32m[0329 09:36:24 @group.py:42][0m Callbacks took 89.257 sec in total. InferenceRunner: 88.945sec
[32m[0329 09:36:24 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11025/173481[03:00<44:13,61.23it/s]  7%|6         |11644/173481[03:10<44:02,61.23it/s] 13%|#2        |22515/173481[06:00<40:15,62.50it/s] 13%|#3        |23119/173481[06:10<40:05,62.50it/s] 19%|#8        |32957/173481[09:00<38:55,60.17it/s] 19%|#9        |33545/173481[09:10<38:45,60.17it/s] 26%|##6       |45733/173481[12:00<32:41,65.13it/s] 27%|##6       |46684/173481[12:10<32:26,65.13it/s] 34%|###4      |59740/173481[15:00<26:44,70.89it/s] 35%|###4      |60384/173481[15:10<26:35,70.89it/s] 41%|####      |70405/173481[18:00<26:37,64.54it/s] 41%|####      |71081/173481[18:10<26:26,64.54it/s] 47%|####6     |81397/173481[21:00<24:27,62.75it/s] 47%|####7     |82051/173481[21:11<24:16,62.75it/s] 53%|#####3    |92076/173481[24:00<22:14,60.99it/s] 53%|#####3    |92689/173481[24:11<22:04,60.99it/s] 59%|#####9    |102570/173481[27:00<19:49,59.61it/s] 60%|#####9    |103238/173481[27:11<19:38,59.61it/s] 65%|######5   |113183/173481[30:00<16:57,59.29it/s] 66%|######5   |113849/173481[30:11<16:45,59.29it/s] 71%|#######1  |123841/173481[33:00<13:57,59.25it/s] 72%|#######1  |124576/173481[33:11<13:45,59.25it/s] 80%|#######9  |138311/173481[36:00<08:35,68.22it/s] 80%|########  |139374/173481[36:11<08:19,68.22it/s] 89%|########9 |155015/173481[39:00<03:54,78.63it/s] 90%|########9 |156106/173481[39:11<03:40,78.63it/s] 99%|#########8|171635/173481[42:00<00:21,84.93it/s]100%|#########9|172775/173481[42:12<00:08,84.93it/s]100%|##########|173481/173481[42:19<00:00,68.32it/s]
[32m[0329 10:18:44 @base.py:257][0m Epoch 27 (global_step 15092847) finished, time:2539.28 sec.
[32m[0329 10:18:44 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-15092847.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,208.27it/s]
26
[32m[0329 10:20:14 @monitor.py:363][0m QueueInput/queue_size: 0.33202
[32m[0329 10:20:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.815
[32m[0329 10:20:14 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0329 10:20:14 @monitor.py:363][0m cross_entropy_loss: 1.5274
[32m[0329 10:20:14 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 10:20:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 10:20:14 @monitor.py:363][0m train-error-top1: 0.41303
[32m[0329 10:20:14 @monitor.py:363][0m val-error-top1: 0.41581
[32m[0329 10:20:14 @monitor.py:363][0m val-utt-error: 0.090214
[32m[0329 10:20:14 @monitor.py:363][0m validation_cost: 1.5501
[32m[0329 10:20:14 @monitor.py:363][0m wd_cost: 1.5019e-21
[32m[0329 10:20:14 @group.py:42][0m Callbacks took 90.633 sec in total. InferenceRunner: 90.385sec
[32m[0329 10:20:14 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13364/173481[03:00<35:56,74.24it/s]  8%|8         |14033/173481[03:10<35:47,74.24it/s] 14%|#4        |24574/173481[06:00<36:38,67.73it/s] 14%|#4        |25143/173481[06:10<36:30,67.73it/s] 20%|##        |35036/173481[09:00<36:53,62.56it/s] 21%|##        |35699/173481[09:10<36:42,62.56it/s] 27%|##6       |46259/173481[12:00<33:57,62.45it/s] 27%|##7       |46973/173481[12:10<33:45,62.45it/s] 33%|###3      |57299/173481[15:00<31:17,61.88it/s] 33%|###3      |57953/173481[15:10<31:07,61.88it/s] 39%|###9      |68399/173481[18:00<28:21,61.77it/s] 40%|###9      |69130/173481[18:10<28:09,61.77it/s] 46%|####6     |80534/173481[21:00<24:01,64.46it/s] 47%|####6     |81201/173481[21:11<23:51,64.46it/s] 53%|#####2    |91564/173481[24:00<21:43,62.82it/s] 53%|#####3    |92198/173481[24:11<21:33,62.82it/s] 59%|#####8    |102189/173481[27:00<19:31,60.86it/s] 59%|#####9    |102884/173481[27:11<19:19,60.86it/s] 65%|######5   |113299/173481[30:00<16:21,61.29it/s] 66%|######5   |113998/173481[30:11<16:10,61.29it/s] 72%|#######1  |124324/173481[33:00<13:22,61.26it/s] 72%|#######2  |125009/173481[33:11<13:11,61.26it/s] 78%|#######8  |135510/173481[36:00<10:15,61.70it/s] 79%|#######8  |136214/173481[36:11<10:04,61.70it/s] 84%|########4 |146424/173481[39:00<07:22,61.16it/s] 85%|########4 |147133/173481[39:11<07:10,61.16it/s] 91%|######### |157279/173481[42:00<04:26,60.72it/s] 91%|#########1|157968/173481[42:12<04:15,60.72it/s] 97%|#########7|168339/173481[45:00<01:24,61.08it/s] 97%|#########7|169063/173481[45:12<01:12,61.08it/s]100%|##########|173481/173481[46:24<00:00,62.30it/s]
[32m[0329 11:06:39 @base.py:257][0m Epoch 28 (global_step 15266328) finished, time:2784.64 sec.
[32m[0329 11:06:39 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-15266328.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,210.13it/s]
27
[32m[0329 11:08:09 @monitor.py:363][0m QueueInput/queue_size: 0.172
[32m[0329 11:08:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.686
[32m[0329 11:08:09 @monitor.py:363][0m activation-summaries/output-rms: 0.04173
[32m[0329 11:08:09 @monitor.py:363][0m cross_entropy_loss: 1.5085
[32m[0329 11:08:09 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 11:08:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 11:08:09 @monitor.py:363][0m train-error-top1: 0.40654
[32m[0329 11:08:09 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0329 11:08:09 @monitor.py:363][0m val-utt-error: 0.090585
[32m[0329 11:08:09 @monitor.py:363][0m validation_cost: 1.5507
[32m[0329 11:08:09 @monitor.py:363][0m wd_cost: 1.5019e-21
[32m[0329 11:08:09 @group.py:42][0m Callbacks took 90.004 sec in total. InferenceRunner: 89.588sec
[32m[0329 11:08:09 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11993/173481[03:00<40:24,66.60it/s]  7%|7         |12595/173481[03:10<40:15,66.60it/s] 13%|#2        |22428/173481[06:00<40:36,61.99it/s] 13%|#3        |23052/173481[06:10<40:26,61.99it/s] 19%|#9        |33118/173481[09:00<38:34,60.66it/s] 19%|#9        |33757/173481[09:10<38:23,60.66it/s] 25%|##5       |44063/173481[12:00<35:31,60.73it/s] 26%|##5       |44660/173481[12:10<35:21,60.73it/s] 32%|###1      |54813/173481[15:00<32:50,60.22it/s] 32%|###1      |55422/173481[15:10<32:40,60.22it/s] 38%|###7      |65538/173481[18:00<30:02,59.90it/s] 38%|###8      |66202/173481[18:10<29:51,59.90it/s] 44%|####4     |76333/173481[21:00<27:01,59.93it/s] 44%|####4     |76974/173481[21:11<26:50,59.93it/s] 50%|#####     |86973/173481[24:00<24:13,59.51it/s] 51%|#####     |87618/173481[24:11<24:02,59.51it/s] 56%|#####6    |97864/173481[27:00<21:00,60.00it/s] 57%|#####6    |98537/173481[27:11<20:48,60.00it/s] 63%|######2   |108738/173481[30:00<17:55,60.20it/s] 63%|######3   |109408/173481[30:11<17:44,60.20it/s] 69%|######8   |119528/173481[33:00<14:58,60.07it/s] 69%|######9   |120187/173481[33:11<14:47,60.07it/s] 75%|#######5  |130369/173481[36:00<11:56,60.15it/s] 76%|#######5  |131056/173481[36:11<11:45,60.15it/s] 81%|########1 |141334/173481[39:00<08:51,60.53it/s] 82%|########1 |142042/173481[39:11<08:39,60.53it/s] 88%|########7 |152382/173481[42:00<05:46,60.95it/s] 88%|########8 |153092/173481[42:12<05:34,60.95it/s] 94%|#########4|163468/173481[45:00<02:43,61.26it/s] 95%|#########4|164189/173481[45:12<02:31,61.26it/s]100%|##########|173481/173481[47:50<00:00,60.43it/s]
[32m[0329 11:56:00 @base.py:257][0m Epoch 29 (global_step 15439809) finished, time:2870.65 sec.
[32m[0329 11:56:00 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_True_preload/model-15439809.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,208.32it/s]
28
[32m[0329 11:57:30 @monitor.py:363][0m QueueInput/queue_size: 0.30662
[32m[0329 11:57:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0329 11:57:30 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0329 11:57:30 @monitor.py:363][0m cross_entropy_loss: 1.5057
[32m[0329 11:57:30 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0329 11:57:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0329 11:57:30 @monitor.py:363][0m train-error-top1: 0.40851
[32m[0329 11:57:30 @monitor.py:363][0m val-error-top1: 0.41551
[32m[0329 11:57:30 @monitor.py:363][0m val-utt-error: 0.090054
[32m[0329 11:57:30 @monitor.py:363][0m validation_cost: 1.551
[32m[0329 11:57:30 @monitor.py:363][0m wd_cost: 3.0039e-22
[32m[0329 11:57:30 @group.py:42][0m Callbacks took 90.711 sec in total. InferenceRunner: 90.362sec
[32m[0329 11:57:30 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11210/173481[03:00<43:25,62.28it/s]  7%|6         |11798/173481[03:10<43:16,62.28it/s] 13%|#2        |21947/173481[06:00<41:27,60.93it/s] 13%|#2        |22485/173481[06:10<41:18,60.93it/s] 19%|#8        |32742/173481[09:00<38:48,60.44it/s] 19%|#9        |33391/173481[09:10<38:37,60.44it/s] 25%|##5       |43697/173481[12:00<35:39,60.65it/s] 26%|##5       |44311/173481[12:10<35:29,60.65it/s] 31%|###1      |54639/173481[15:00<32:37,60.72it/s] 32%|###1      |55301/173481[15:10<32:26,60.72it/s] 38%|###7      |65667/173481[18:00<29:27,60.99it/s] 38%|###8      |66301/173481[18:10<29:17,60.99it/s] 44%|####4     |76507/173481[21:00<26:40,60.59it/s] 44%|####4     |77141/173481[21:10<26:29,60.59it/s] 50%|#####     |87557/173481[24:00<23:28,60.99it/s] 51%|#####     |88221/173481[24:11<23:17,60.99it/s] 57%|#####6    |98440/173481[27:00<20:35,60.72it/s] 57%|#####7    |99096/173481[27:11<20:24,60.72it/s] 63%|######2   |109052/173481[30:00<17:57,59.82it/s] 63%|######3   |109704/173481[30:11<17:46,59.82it/s] 69%|######8   |119643/173481[33:00<15:07,59.32it/s] 69%|######9   |120316/173481[33:11<14:56,59.32it/s] 75%|#######5  |130282/173481[36:00<12:09,59.21it/s] 75%|#######5  |130961/173481[36:11<11:58,59.21it/s] 81%|########1 |140902/173481[39:00<09:11,59.09it/s] 82%|########1 |141586/173481[39:11<08:59,59.09it/s]slurmstepd: *** JOB 85139 ON sls-tesla-1 CANCELLED AT 2018-03-29T12:39:06 ***
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 85139.0 ON sls-tesla-1 CANCELLED AT 2018-03-29T12:39:06 ***
