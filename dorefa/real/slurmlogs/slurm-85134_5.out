sls-sm-3 2
SLURM_JOBID=85134
SLURM_TASKID=5
[32m[0328 11:32:07 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=32 --bita=32 --quant_ends=True --load_ckpt=train_log/lcn_w_32_a_32_quant_ends_False/checkpoint
[32m[0328 11:32:26 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 11:32:26 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 11:32:27 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 11:32:27 @drf_run.py:166][0m Using host: sls-sm-3
[32m[0328 11:32:27 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 11:32:27 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 11:32:27 @drf_run.py:188][0m Using GPU: 2
[32m[0328 11:32:27 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 11:32:27 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 11:32:27 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 11:32:27 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0a/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0a/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0b/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0b/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0c/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0c/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0d/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0d/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0e/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0e/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0f/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0f/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0g/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0g/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0h/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0h/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0i/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0i/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0j/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0j/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:32:28 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 11:32:28 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:32:28 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 11:32:28 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:32:28 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 11:32:28 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:32:28 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 11:32:28 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:32:28 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0328 11:32:28 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 11:32:28 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0328 11:32:28 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0328 11:32:28 @base.py:196][0m Setup callbacks graph ...
[32m[0328 11:32:29 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0a/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0a/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0b/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0b/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0c/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0c/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0d/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0d/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0e/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0e/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0f/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0f/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0g/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0g/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0h/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0h/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0i/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0i/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0j/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight conv0j/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:32:29 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:32:29 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:32:29 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:32:29 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0328 11:32:29 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 11:32:29 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0328 11:32:31 @base.py:212][0m Creating the session ...
2018-03-28 11:32:31.536709: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-28 11:32:35.463501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:81:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-28 11:32:35.463554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:81:00.0, compute capability: 6.1)
[32m[0328 11:32:40 @base.py:220][0m Initializing the session ...
[32m[0328 11:32:40 @sessinit.py:116][0m Restoring checkpoint from train_log/lcn_w_32_a_32_quant_ends_False/model-10061898 ...
[32m[0328 11:32:41 @base.py:227][0m Graph Finalized.
[32m[0328 11:32:41 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 11:32:41 @steps.py:127][0m Start training with global_step=10061898
[32m[0328 11:32:45 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11569/173481[03:00<41:59,64.27it/s]  7%|7         |12164/173481[03:10<41:49,64.27it/s]  9%|9         |16331/173481[06:01<1:10:12,37.31it/s]  9%|9         |16375/173481[06:20<1:10:10,37.31it/s] 10%|9         |16726/173481[09:06<10:46:40, 4.04it/s] 10%|9         |16751/173481[09:20<10:46:34, 4.04it/s] 10%|9         |17161/173481[12:16<14:53:50, 2.91it/s] 10%|9         |17250/173481[12:30<14:53:19, 2.91it/s] 11%|#         |18271/173481[15:21<10:59:02, 3.93it/s] 11%|#         |18760/173481[15:40<10:56:58, 3.93it/s] 19%|#9        |33182/173481[18:21<5:11:58, 7.50it/s]  20%|##        |34933/173481[18:40<5:08:05, 7.50it/s] 29%|##8       |49472/173481[21:21<2:29:17,13.84it/s] 30%|##9       |51220/173481[21:40<2:27:11,13.84it/s] 38%|###7      |65621/173481[24:21<1:14:56,23.99it/s] 39%|###8      |67358/173481[24:41<1:13:44,23.99it/s] 47%|####7     |82040/173481[27:21<40:07,37.98it/s]   48%|####8     |83823/173481[27:41<39:20,37.98it/s] 57%|#####6    |98504/173481[30:21<23:16,53.68it/s] 58%|#####7    |100300/173481[30:41<22:43,53.68it/s] 66%|######6   |114906/173481[33:21<14:27,67.55it/s] 67%|######7   |116702/173481[33:41<14:00,67.55it/s] 73%|#######2  |126563/173481[36:21<11:49,66.13it/s] 74%|#######3  |127770/173481[36:41<11:31,66.13it/s] 79%|#######9  |137181/173481[39:21<09:42,62.35it/s] 79%|#######9  |137815/173481[39:31<09:32,62.35it/s] 85%|########5 |147755/173481[42:21<07:05,60.49it/s] 85%|########5 |148318/173481[42:31<06:55,60.49it/s] 91%|######### |157257/173481[45:21<04:47,56.38it/s] 91%|######### |157815/173481[45:32<04:37,56.38it/s] 96%|#########6|167066/173481[48:21<01:55,55.41it/s] 97%|#########6|167640/173481[48:32<01:45,55.41it/s]100%|##########|173481/173481[50:19<00:00,57.45it/s]
[32m[0328 12:23:05 @base.py:257][0m Epoch 1 (global_step 10235379) finished, time:3019.81 sec.
[32m[0328 12:23:05 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-10235379.
  0%|          |0/18822[00:00<?,?it/s] 51%|#####     |9558/18822[03:00<02:54,53.10it/s] 54%|#####3    |10154/18822[03:10<02:43,53.10it/s]100%|##########|18822/18822[05:17<00:00,59.20it/s]
0
[32m[0328 12:28:23 @monitor.py:363][0m QueueInput/queue_size: 3.2579
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.795
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/output-rms: 0.040903
[32m[0328 12:28:23 @monitor.py:363][0m cross_entropy_loss: 1.5901
[32m[0328 12:28:23 @monitor.py:363][0m lr: 4.7684e-10
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 12:28:23 @monitor.py:363][0m train-error-top1: 0.4224
[32m[0328 12:28:23 @monitor.py:363][0m val-error-top1: 0.43231
[32m[0328 12:28:23 @monitor.py:363][0m val-utt-error: 0.10137
[32m[0328 12:28:23 @monitor.py:363][0m validation_cost: 1.622
[32m[0328 12:28:23 @monitor.py:363][0m wd_cost: 9.7752e-15
[32m[0328 12:28:23 @group.py:42][0m Callbacks took 318.551 sec in total. InferenceRunner: 318.020sec
[32m[0328 12:28:23 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10595/173481[03:00<46:08,58.85it/s]  6%|6         |11129/173481[03:10<45:58,58.85it/s] 12%|#2        |20821/173481[06:00<44:00,57.81it/s] 12%|#2        |21419/173481[06:10<43:50,57.81it/s] 18%|#7        |30840/173481[09:00<41:55,56.71it/s] 18%|#8        |31394/173481[09:10<41:45,56.71it/s] 23%|##2       |39881/173481[12:00<41:47,53.27it/s] 23%|##3       |40414/173481[12:10<41:37,53.27it/s] 28%|##8       |49151/173481[15:00<39:34,52.37it/s] 29%|##8       |49717/173481[15:10<39:23,52.37it/s] 34%|###4      |59145/173481[18:00<35:21,53.89it/s] 34%|###4      |59744/173481[18:10<35:10,53.89it/s] 40%|###9      |68976/173481[21:00<32:06,54.25it/s] 40%|####      |69578/173481[21:11<31:55,54.25it/s] 45%|####5     |78776/173481[24:00<29:02,54.35it/s] 46%|####5     |79470/173481[24:11<28:49,54.35it/s] 52%|#####1    |89610/173481[27:00<24:28,57.11it/s] 52%|#####2    |90233/173481[27:11<24:17,57.11it/s] 57%|#####7    |99605/173481[30:00<21:52,56.31it/s] 58%|#####7    |100243/173481[30:11<21:40,56.31it/s] 63%|######3   |109535/173481[33:00<19:07,55.73it/s] 64%|######3   |110163/173481[33:11<18:56,55.73it/s] 69%|######9   |119776/173481[36:00<15:53,56.31it/s] 69%|######9   |120446/173481[36:11<15:41,56.31it/s] 75%|#######4  |129615/173481[39:00<13:10,55.46it/s] 75%|#######5  |130219/173481[39:11<13:00,55.46it/s] 80%|########  |139403/173481[42:00<10:20,54.91it/s] 81%|########  |140088/173481[42:12<10:08,54.91it/s] 86%|########6 |149455/173481[45:00<07:13,55.37it/s] 87%|########6 |150124/173481[45:12<07:01,55.37it/s] 92%|#########2|159630/173481[48:00<04:07,55.94it/s] 92%|#########2|160289/173481[48:12<03:55,55.94it/s] 98%|#########7|169710/173481[51:00<01:07,55.97it/s] 98%|#########8|170419/173481[51:12<00:54,55.97it/s]100%|##########|173481/173481[52:07<00:00,55.47it/s]
[32m[0328 13:20:31 @base.py:257][0m Epoch 2 (global_step 10408860) finished, time:3127.49 sec.
[32m[0328 13:20:31 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-10408860.
[32m[0328 13:20:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:35<00:00,120.68it/s]
1
[32m[0328 13:23:08 @monitor.py:363][0m QueueInput/queue_size: 0.56966
[32m[0328 13:23:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.969
[32m[0328 13:23:08 @monitor.py:363][0m activation-summaries/output-rms: 0.041179
[32m[0328 13:23:08 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0328 13:23:08 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 13:23:08 @monitor.py:363][0m train-error-top1: 0.43151
[32m[0328 13:23:08 @monitor.py:363][0m val-error-top1: 0.43234
[32m[0328 13:23:08 @monitor.py:363][0m val-utt-error: 0.099033
[32m[0328 13:23:08 @monitor.py:363][0m validation_cost: 1.6189
[32m[0328 13:23:08 @monitor.py:363][0m wd_cost: 9.7752e-15
[32m[0328 13:23:08 @group.py:42][0m Callbacks took 156.535 sec in total. InferenceRunner: 155.989sec
[32m[0328 13:23:08 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14649/173481[03:00<32:32,81.36it/s]  9%|8         |15257/173481[03:10<32:24,81.36it/s] 14%|#4        |25133/173481[06:00<36:25,67.89it/s] 15%|#4        |25655/173481[06:10<36:17,67.89it/s] 20%|#9        |34539/173481[09:00<39:12,59.05it/s] 20%|##        |35083/173481[09:10<39:03,59.05it/s] 25%|##5       |44029/173481[12:00<38:43,55.71it/s] 26%|##5       |44588/173481[12:10<38:33,55.71it/s] 31%|###       |53274/173481[15:00<37:29,53.44it/s] 31%|###1      |53818/173481[15:10<37:19,53.44it/s] 36%|###6      |62804/173481[18:00<34:40,53.19it/s] 37%|###6      |63367/173481[18:10<34:30,53.19it/s] 42%|####1     |72579/173481[21:00<31:17,53.74it/s] 42%|####2     |73159/173481[21:10<31:06,53.74it/s] 47%|####6     |80893/173481[24:00<31:03,49.68it/s] 47%|####6     |81329/173481[24:10<30:54,49.68it/s] 51%|#####     |88029/173481[27:00<32:18,44.09it/s] 51%|#####     |88468/173481[27:11<32:08,44.09it/s] 55%|#####4    |95126/173481[30:00<31:22,41.63it/s] 55%|#####5    |95559/173481[30:11<31:11,41.63it/s] 59%|#####9    |102463/173481[33:00<28:44,41.19it/s] 59%|#####9    |102914/173481[33:11<28:33,41.19it/s] 63%|######3   |110009/173481[36:00<25:27,41.55it/s] 64%|######3   |110490/173481[36:11<25:16,41.55it/s] 68%|######7   |117518/173481[39:00<22:24,41.63it/s] 68%|######8   |117970/173481[39:11<22:13,41.63it/s] 72%|#######1  |124836/173481[42:00<19:42,41.14it/s] 72%|#######2  |125263/173481[42:11<19:32,41.14it/s] 76%|#######6  |132384/173481[45:00<16:29,41.53it/s] 77%|#######6  |133098/173481[45:11<16:12,41.53it/s] 83%|########2 |143666/173481[48:00<09:56,49.96it/s] 83%|########3 |144433/173481[48:12<09:41,49.96it/s] 89%|########9 |155264/173481[51:00<05:23,56.28it/s] 90%|########9 |156036/173481[51:12<05:09,56.28it/s] 96%|#########6|166554/173481[54:00<01:56,59.32it/s] 96%|#########6|167321/173481[54:12<01:43,59.32it/s]100%|##########|173481/173481[55:48<00:00,51.81it/s]
[32m[0328 14:18:56 @base.py:257][0m Epoch 3 (global_step 10582341) finished, time:3348.34 sec.
[32m[0328 14:18:56 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 84%|########3 |15762/18822[03:00<00:34,87.56it/s] 93%|#########3|17516/18822[03:18<00:14,87.56it/s]100%|##########|18822/18822[03:32<00:00,88.68it/s]
2
[32m[0328 14:22:29 @monitor.py:363][0m QueueInput/queue_size: 0.58312
[32m[0328 14:22:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.808
[32m[0328 14:22:29 @monitor.py:363][0m activation-summaries/output-rms: 0.040718
[32m[0328 14:22:29 @monitor.py:363][0m cross_entropy_loss: 1.5815
[32m[0328 14:22:29 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 14:22:29 @monitor.py:363][0m train-error-top1: 0.42934
[32m[0328 14:22:29 @monitor.py:363][0m val-error-top1: 0.43266
[32m[0328 14:22:29 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0328 14:22:29 @monitor.py:363][0m validation_cost: 1.6203
[32m[0328 14:22:29 @monitor.py:363][0m wd_cost: 1.955e-15
[32m[0328 14:22:29 @group.py:42][0m Callbacks took 212.682 sec in total. InferenceRunner: 212.276sec
[32m[0328 14:22:29 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11853/173481[03:00<40:54,65.84it/s]  7%|7         |12502/173481[03:10<40:45,65.84it/s] 14%|#3        |23423/173481[06:00<38:27,65.04it/s] 14%|#3        |24067/173481[06:10<38:17,65.04it/s] 20%|##        |35136/173481[09:00<35:26,65.06it/s] 21%|##        |35826/173481[09:10<35:15,65.06it/s] 27%|##7       |46923/173481[12:00<32:19,65.27it/s] 27%|##7       |47607/173481[12:10<32:08,65.27it/s] 34%|###3      |58789/173481[15:00<29:08,65.59it/s] 34%|###4      |59509/173481[15:10<28:57,65.59it/s] 41%|####      |70456/173481[18:00<26:20,65.20it/s] 41%|####1     |71140/173481[18:10<26:09,65.20it/s] 47%|####7     |81968/173481[21:00<23:37,64.57it/s] 48%|####7     |82967/173481[21:10<23:21,64.57it/s] 57%|#####6    |98090/173481[24:00<16:44,75.04it/s] 57%|#####7    |99119/173481[24:11<16:30,75.04it/s] 66%|######6   |114758/173481[27:00<11:48,82.90it/s] 67%|######6   |115797/173481[27:11<11:35,82.90it/s] 73%|#######3  |126866/173481[30:00<10:27,74.27it/s] 74%|#######3  |127612/173481[30:11<10:17,74.27it/s] 80%|########  |138818/173481[33:00<08:14,70.11it/s] 80%|########  |139552/173481[33:11<08:03,70.11it/s] 86%|########5 |149183/173481[36:00<06:24,63.22it/s] 86%|########6 |149813/173481[36:11<06:14,63.22it/s] 92%|#########2|159613/173481[39:00<03:49,60.47it/s] 92%|#########2|160306/173481[39:11<03:37,60.47it/s] 98%|#########7|169448/173481[42:00<01:10,57.40it/s] 98%|#########7|169963/173481[42:11<01:01,57.40it/s]100%|##########|173481/173481[43:20<00:00,66.71it/s]
[32m[0328 15:05:49 @base.py:257][0m Epoch 4 (global_step 10755822) finished, time:2600.55 sec.
[32m[0328 15:05:49 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-10755822.
  0%|          |0/18822[00:00<?,?it/s] 97%|#########6|18219/18822[03:00<00:05,101.21it/s]100%|##########|18822/18822[03:05<00:00,101.39it/s]
3
[32m[0328 15:08:55 @monitor.py:363][0m QueueInput/queue_size: 0.77917
[32m[0328 15:08:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.76
[32m[0328 15:08:55 @monitor.py:363][0m activation-summaries/output-rms: 0.040878
[32m[0328 15:08:55 @monitor.py:363][0m cross_entropy_loss: 1.5884
[32m[0328 15:08:55 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 15:08:55 @monitor.py:363][0m train-error-top1: 0.42817
[32m[0328 15:08:55 @monitor.py:363][0m val-error-top1: 0.43206
[32m[0328 15:08:55 @monitor.py:363][0m val-utt-error: 0.099883
[32m[0328 15:08:55 @monitor.py:363][0m validation_cost: 1.6196
[32m[0328 15:08:55 @monitor.py:363][0m wd_cost: 1.955e-15
[32m[0328 15:08:55 @group.py:42][0m Callbacks took 185.984 sec in total. InferenceRunner: 185.655sec
[32m[0328 15:08:55 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12367/173481[03:00<39:05,68.69it/s]  8%|7         |13046/173481[03:10<38:55,68.69it/s] 14%|#3        |23962/173481[06:00<37:29,66.48it/s] 14%|#4        |24552/173481[06:10<37:20,66.48it/s] 20%|##        |34744/173481[09:00<36:41,63.02it/s] 20%|##        |35316/173481[09:10<36:32,63.02it/s] 26%|##5       |44566/173481[12:00<36:44,58.49it/s] 26%|##6       |45141/173481[12:10<36:34,58.49it/s] 32%|###1      |54702/173481[15:00<34:30,57.38it/s] 32%|###1      |55341/173481[15:10<34:18,57.38it/s] 38%|###7      |65097/173481[18:00<31:22,57.56it/s] 38%|###7      |65726/173481[18:10<31:12,57.56it/s] 43%|####3     |75033/173481[21:00<29:06,56.35it/s] 44%|####3     |75602/173481[21:10<28:56,56.35it/s] 49%|####8     |84313/173481[24:00<27:35,53.85it/s] 49%|####8     |84856/173481[24:11<27:25,53.85it/s] 54%|#####4    |94032/173481[27:00<24:33,53.91it/s] 55%|#####4    |94616/173481[27:11<24:22,53.91it/s] 60%|#####9    |103443/173481[30:00<21:59,53.08it/s] 60%|#####9    |104051/173481[30:11<21:47,53.08it/s] 65%|######5   |113022/173481[33:00<18:57,53.15it/s] 66%|######5   |113670/173481[33:11<18:45,53.15it/s] 71%|#######   |122872/173481[36:00<15:38,53.91it/s] 71%|#######1  |123456/173481[36:11<15:27,53.91it/s] 76%|#######6  |132672/173481[39:00<12:33,54.17it/s] 77%|#######6  |133279/173481[39:11<12:22,54.17it/s] 82%|########1 |142187/173481[42:00<09:44,53.50it/s] 82%|########2 |142836/173481[42:11<09:32,53.50it/s] 88%|########7 |152394/173481[45:00<06:23,55.05it/s] 88%|########8 |153051/173481[45:12<06:11,55.05it/s] 94%|#########3|162387/173481[48:00<03:20,55.28it/s] 94%|#########3|163031/173481[48:12<03:09,55.28it/s] 99%|#########8|171690/173481[51:00<00:33,53.42it/s] 99%|#########9|172311/173481[51:12<00:21,53.42it/s]100%|##########|173481/173481[51:34<00:00,56.05it/s]
[32m[0328 16:00:30 @base.py:257][0m Epoch 5 (global_step 10929303) finished, time:3094.98 sec.
[32m[0328 16:00:30 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-10929303.
[32m[0328 16:00:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.99it/s]
4
[32m[0328 16:02:15 @monitor.py:363][0m QueueInput/queue_size: 0.55719
[32m[0328 16:02:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.828
[32m[0328 16:02:15 @monitor.py:363][0m activation-summaries/output-rms: 0.042383
[32m[0328 16:02:15 @monitor.py:363][0m cross_entropy_loss: 1.5828
[32m[0328 16:02:15 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 16:02:15 @monitor.py:363][0m train-error-top1: 0.42347
[32m[0328 16:02:15 @monitor.py:363][0m val-error-top1: 0.4331
[32m[0328 16:02:15 @monitor.py:363][0m val-utt-error: 0.10026
[32m[0328 16:02:15 @monitor.py:363][0m validation_cost: 1.6233
[32m[0328 16:02:15 @monitor.py:363][0m wd_cost: 1.955e-15
[32m[0328 16:02:15 @group.py:42][0m Callbacks took 105.062 sec in total. InferenceRunner: 104.583sec
[32m[0328 16:02:15 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10999/173481[03:00<44:19,61.10it/s]  7%|6         |11608/173481[03:10<44:09,61.10it/s] 12%|#2        |21575/173481[06:00<42:15,59.91it/s] 13%|#2        |22165/173481[06:10<42:05,59.91it/s] 18%|#8        |31826/173481[09:00<40:26,58.38it/s] 19%|#8        |32355/173481[09:10<40:17,58.38it/s] 24%|##3       |40796/173481[12:00<41:08,53.76it/s] 24%|##3       |41321/173481[12:10<40:58,53.76it/s] 29%|##8       |49826/173481[15:00<39:42,51.89it/s] 29%|##9       |50354/173481[15:10<39:32,51.89it/s] 34%|###4      |59130/173481[18:00<36:47,51.79it/s] 34%|###4      |59740/173481[18:10<36:36,51.79it/s] 40%|###9      |69101/173481[21:00<32:30,53.52it/s] 40%|####      |69630/173481[21:10<32:20,53.52it/s] 45%|####5     |78326/173481[24:00<30:17,52.35it/s] 45%|####5     |78901/173481[24:11<30:06,52.35it/s] 50%|#####     |87326/173481[27:00<28:04,51.15it/s] 51%|#####     |87870/173481[27:11<27:53,51.15it/s] 56%|#####5    |96324/173481[30:00<25:26,50.56it/s] 56%|#####5    |96855/173481[30:11<25:15,50.56it/s] 61%|######    |105024/173481[33:00<23:05,49.42it/s] 61%|######    |105575/173481[33:11<22:54,49.42it/s] 66%|######5   |113871/173481[36:00<20:09,49.27it/s] 66%|######5   |114443/173481[36:11<19:58,49.27it/s] 71%|#######   |123166/173481[39:00<16:37,50.42it/s] 71%|#######1  |123764/173481[39:11<16:25,50.42it/s] 76%|#######6  |132262/173481[42:00<13:36,50.48it/s] 77%|#######6  |132820/173481[42:11<13:25,50.48it/s] 82%|########1 |141406/173481[45:00<10:33,50.64it/s] 82%|########1 |142020/173481[45:12<10:21,50.64it/s] 87%|########6 |150494/173481[48:00<07:34,50.56it/s] 87%|########7 |151146/173481[48:12<07:21,50.56it/s] 92%|#########2|160071/173481[51:00<04:18,51.84it/s] 93%|#########2|160680/173481[51:12<04:06,51.84it/s] 97%|#########7|168756/173481[54:00<01:34,49.97it/s] 98%|#########7|169333/173481[54:12<01:23,49.97it/s]100%|##########|173481/173481[55:39<00:00,51.94it/s]
[32m[0328 16:57:55 @base.py:257][0m Epoch 6 (global_step 11102784) finished, time:3339.82 sec.
[32m[0328 16:57:55 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s] 93%|#########2|17445/18822[03:00<00:14,96.91it/s] 98%|#########8|18539/18822[03:10<00:02,96.91it/s]100%|##########|18822/18822[03:12<00:00,97.63it/s]
5
[32m[0328 17:01:08 @monitor.py:363][0m QueueInput/queue_size: 0.6887
[32m[0328 17:01:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.795
[32m[0328 17:01:08 @monitor.py:363][0m activation-summaries/output-rms: 0.040903
[32m[0328 17:01:08 @monitor.py:363][0m cross_entropy_loss: 1.5901
[32m[0328 17:01:08 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 17:01:08 @monitor.py:363][0m train-error-top1: 0.4224
[32m[0328 17:01:08 @monitor.py:363][0m val-error-top1: 0.43231
[32m[0328 17:01:08 @monitor.py:363][0m val-utt-error: 0.10137
[32m[0328 17:01:08 @monitor.py:363][0m validation_cost: 1.622
[32m[0328 17:01:08 @monitor.py:363][0m wd_cost: 3.9101e-16
[32m[0328 17:01:08 @group.py:42][0m Callbacks took 193.110 sec in total. InferenceRunner: 192.812sec
[32m[0328 17:01:08 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12010/173481[03:00<40:20,66.72it/s]  7%|7         |12574/173481[03:10<40:11,66.72it/s] 13%|#2        |21828/173481[06:00<42:06,60.02it/s] 13%|#2        |22412/173481[06:10<41:57,60.02it/s] 19%|#8        |32939/173481[09:00<38:29,60.86it/s] 19%|#9        |33429/173481[09:10<38:21,60.86it/s] 24%|##3       |41200/173481[12:00<42:08,52.32it/s] 24%|##4       |41669/173481[12:10<41:59,52.32it/s] 29%|##8       |49604/173481[15:00<41:50,49.34it/s] 29%|##8       |50114/173481[15:10<41:40,49.34it/s] 34%|###3      |58571/173481[18:00<38:37,49.58it/s] 34%|###4      |59121/173481[18:10<38:26,49.58it/s] 39%|###8      |67490/173481[21:00<35:38,49.56it/s] 39%|###9      |68034/173481[21:10<35:27,49.56it/s] 44%|####4     |76830/173481[24:00<31:46,50.70it/s] 45%|####4     |77379/173481[24:11<31:35,50.70it/s] 50%|####9     |86045/173481[27:00<28:36,50.94it/s] 50%|####9     |86633/173481[27:11<28:24,50.94it/s] 55%|#####5    |95727/173481[30:00<24:46,52.32it/s] 56%|#####5    |96319/173481[30:11<24:34,52.32it/s] 61%|######    |105047/173481[33:00<21:54,52.05it/s] 61%|######    |105656/173481[33:11<21:43,52.05it/s] 66%|######5   |114245/173481[36:00<19:08,51.56it/s] 66%|######6   |114837/173481[36:11<18:57,51.56it/s] 71%|#######1  |123249/173481[39:00<16:29,50.78it/s] 71%|#######1  |123809/173481[39:11<16:18,50.78it/s] 76%|#######6  |132060/173481[42:00<13:51,49.84it/s] 76%|#######6  |132639/173481[42:11<13:39,49.84it/s] 81%|########1 |140823/173481[45:00<11:03,49.25it/s] 82%|########1 |141394/173481[45:12<10:51,49.25it/s] 86%|########6 |149855/173481[48:00<07:55,49.71it/s] 87%|########6 |150458/173481[48:12<07:43,49.71it/s] 92%|#########1|159101/173481[51:00<04:44,50.52it/s] 92%|#########2|159724/173481[51:12<04:32,50.52it/s] 97%|#########7|168580/173481[54:00<01:35,51.57it/s] 98%|#########7|169261/173481[54:12<01:21,51.57it/s]100%|##########|173481/173481[55:28<00:00,52.12it/s]
[32m[0328 17:56:36 @base.py:257][0m Epoch 7 (global_step 11276265) finished, time:3328.23 sec.
[32m[0328 17:56:37 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-11276265.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:51<00:00,110.04it/s]
6
[32m[0328 17:59:28 @monitor.py:363][0m QueueInput/queue_size: 0.84427
[32m[0328 17:59:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.969
[32m[0328 17:59:28 @monitor.py:363][0m activation-summaries/output-rms: 0.041179
[32m[0328 17:59:28 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0328 17:59:28 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 17:59:28 @monitor.py:363][0m train-error-top1: 0.43151
[32m[0328 17:59:28 @monitor.py:363][0m val-error-top1: 0.43234
[32m[0328 17:59:28 @monitor.py:363][0m val-utt-error: 0.099033
[32m[0328 17:59:28 @monitor.py:363][0m validation_cost: 1.6189
[32m[0328 17:59:28 @monitor.py:363][0m wd_cost: 3.9101e-16
[32m[0328 17:59:28 @group.py:42][0m Callbacks took 171.356 sec in total. InferenceRunner: 171.063sec
[32m[0328 17:59:28 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11449/173481[03:00<42:27,63.60it/s]  7%|6         |12033/173481[03:10<42:18,63.60it/s] 12%|#2        |21366/173481[06:00<42:56,59.04it/s] 13%|#2        |21958/173481[06:10<42:46,59.04it/s] 20%|#9        |34629/173481[09:00<35:18,65.55it/s] 20%|##        |35143/173481[09:10<35:10,65.55it/s] 25%|##5       |44224/173481[12:00<36:38,58.79it/s] 26%|##5       |44783/173481[12:10<36:28,58.79it/s] 31%|###1      |53824/173481[15:00<35:39,55.93it/s] 31%|###1      |54385/173481[15:10<35:29,55.93it/s] 36%|###6      |63054/173481[18:00<34:24,53.49it/s] 37%|###6      |63624/173481[18:10<34:13,53.49it/s] 42%|####1     |72824/173481[21:00<31:08,53.88it/s] 42%|####2     |73423/173481[21:11<30:57,53.88it/s] 48%|####7     |82430/173481[24:00<28:18,53.62it/s] 48%|####7     |82994/173481[24:11<28:07,53.62it/s] 53%|#####3    |92114/173481[27:00<25:15,53.70it/s] 53%|#####3    |92720/173481[27:11<25:03,53.70it/s] 59%|#####8    |101829/173481[30:00<22:10,53.83it/s] 59%|#####9    |102443/173481[30:11<21:59,53.83it/s] 64%|######4   |111664/173481[33:00<18:59,54.23it/s] 65%|######4   |112276/173481[33:11<18:48,54.23it/s] 71%|#######   |122574/173481[36:00<14:49,57.23it/s] 71%|#######1  |123220/173481[36:11<14:38,57.23it/s] 76%|#######6  |132669/173481[39:00<12:00,56.65it/s] 77%|#######6  |133343/173481[39:11<11:48,56.65it/s] 82%|########2 |143014/173481[42:00<08:53,57.05it/s] 83%|########2 |143643/173481[42:12<08:42,57.05it/s] 88%|########8 |152968/173481[45:00<06:05,56.16it/s] 89%|########8 |153628/173481[45:12<05:53,56.16it/s] 94%|#########3|162894/173481[48:00<03:10,55.64it/s] 94%|#########4|163553/173481[48:12<02:58,55.64it/s]100%|#########9|172919/173481[51:00<00:10,55.67it/s]100%|##########|173481/173481[51:10<00:00,56.49it/s]
[32m[0328 18:50:38 @base.py:257][0m Epoch 8 (global_step 11449746) finished, time:3070.80 sec.
[32m[0328 18:50:39 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:57<00:00,106.02it/s]
7
[32m[0328 18:53:36 @monitor.py:363][0m QueueInput/queue_size: 0.95072
[32m[0328 18:53:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.808
[32m[0328 18:53:36 @monitor.py:363][0m activation-summaries/output-rms: 0.040718
[32m[0328 18:53:36 @monitor.py:363][0m cross_entropy_loss: 1.5815
[32m[0328 18:53:36 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 18:53:36 @monitor.py:363][0m train-error-top1: 0.42934
[32m[0328 18:53:36 @monitor.py:363][0m val-error-top1: 0.43266
[32m[0328 18:53:36 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0328 18:53:36 @monitor.py:363][0m validation_cost: 1.6203
[32m[0328 18:53:36 @monitor.py:363][0m wd_cost: 3.9101e-16
[32m[0328 18:53:36 @group.py:42][0m Callbacks took 177.835 sec in total. InferenceRunner: 177.540sec
[32m[0328 18:53:36 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11823/173481[03:00<41:01,65.67it/s]  7%|7         |12354/173481[03:10<40:53,65.67it/s] 12%|#2        |21611/173481[06:00<42:32,59.49it/s] 13%|#2        |22172/173481[06:10<42:23,59.49it/s] 18%|#8        |31703/173481[09:00<40:56,57.72it/s] 19%|#8        |32274/173481[09:10<40:46,57.72it/s] 26%|##6       |45471/173481[12:00<32:25,65.79it/s] 27%|##6       |46388/173481[12:10<32:11,65.79it/s] 33%|###2      |57095/173481[15:00<29:45,65.18it/s] 33%|###3      |57699/173481[15:10<29:36,65.18it/s] 39%|###8      |67255/173481[18:00<29:15,60.50it/s] 39%|###9      |67868/173481[18:10<29:05,60.50it/s] 45%|####4     |77462/173481[21:00<27:20,58.54it/s] 45%|####5     |78077/173481[21:10<27:09,58.54it/s] 50%|#####     |87517/173481[24:00<25:03,57.17it/s] 51%|#####     |88147/173481[24:11<24:52,57.17it/s] 56%|#####6    |97893/173481[27:00<21:56,57.40it/s] 57%|#####6    |98517/173481[27:11<21:46,57.40it/s] 62%|######2   |108074/173481[30:00<19:08,56.97it/s] 63%|######2   |108830/173481[30:11<18:54,56.97it/s] 69%|######8   |119383/173481[33:00<15:05,59.75it/s] 69%|######9   |120036/173481[33:11<14:54,59.75it/s] 75%|#######4  |130093/173481[36:00<12:07,59.62it/s] 75%|#######5  |130883/173481[36:11<11:54,59.62it/s] 81%|########1 |140953/173481[39:00<09:02,59.97it/s] 82%|########1 |141591/173481[39:11<08:51,59.97it/s] 87%|########7 |151759/173481[42:00<06:02,60.00it/s] 88%|########7 |152482/173481[42:11<05:49,60.00it/s] 94%|#########3|162663/173481[45:00<02:59,60.28it/s] 94%|#########4|163301/173481[45:12<02:48,60.28it/s]100%|#########9|172653/173481[48:00<00:14,57.79it/s]100%|#########9|173318/173481[48:12<00:02,57.79it/s]100%|##########|173481/173481[48:15<00:00,59.92it/s]
[32m[0328 19:41:51 @base.py:257][0m Epoch 9 (global_step 11623227) finished, time:2895.01 sec.
[32m[0328 19:41:52 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-11623227.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########8|18486/18822[03:00<00:03,102.70it/s]100%|##########|18822/18822[03:02<00:00,102.94it/s]
8
[32m[0328 19:44:54 @monitor.py:363][0m QueueInput/queue_size: 0.70819
[32m[0328 19:44:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.76
[32m[0328 19:44:54 @monitor.py:363][0m activation-summaries/output-rms: 0.040878
[32m[0328 19:44:54 @monitor.py:363][0m cross_entropy_loss: 1.5884
[32m[0328 19:44:54 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 19:44:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 19:44:55 @monitor.py:363][0m train-error-top1: 0.42817
[32m[0328 19:44:55 @monitor.py:363][0m val-error-top1: 0.43206
[32m[0328 19:44:55 @monitor.py:363][0m val-utt-error: 0.099883
[32m[0328 19:44:55 @monitor.py:363][0m validation_cost: 1.6196
[32m[0328 19:44:55 @monitor.py:363][0m wd_cost: 7.8202e-17
[32m[0328 19:44:55 @group.py:42][0m Callbacks took 183.215 sec in total. InferenceRunner: 182.864sec
[32m[0328 19:44:55 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13059/173481[03:00<36:51,72.55it/s]  8%|7         |13761/173481[03:10<36:41,72.55it/s] 14%|#4        |24297/173481[06:00<37:02,67.11it/s] 14%|#4        |24916/173481[06:10<36:53,67.11it/s] 20%|##        |34832/173481[09:00<36:57,62.52it/s] 20%|##        |35446/173481[09:10<36:48,62.52it/s] 26%|##6       |45192/173481[12:00<35:40,59.93it/s] 26%|##6       |45770/173481[12:10<35:30,59.93it/s] 32%|###1      |55385/173481[15:00<33:48,58.23it/s] 32%|###2      |55965/173481[15:10<33:38,58.23it/s] 38%|###7      |65352/173481[18:00<31:44,56.77it/s] 38%|###8      |65952/173481[18:10<31:34,56.77it/s] 47%|####6     |80985/173481[21:00<22:27,68.66it/s] 47%|####7     |82024/173481[21:10<22:12,68.66it/s] 57%|#####6    |98302/173481[24:00<15:38,80.13it/s] 57%|#####7    |98927/173481[24:11<15:30,80.13it/s] 63%|######2   |108427/173481[27:00<16:24,66.10it/s] 63%|######2   |109054/173481[27:11<16:14,66.10it/s] 68%|######8   |118525/173481[30:00<15:05,60.69it/s] 69%|######8   |119166/173481[30:11<14:54,60.69it/s] 74%|#######4  |128667/173481[33:00<12:46,58.43it/s] 75%|#######4  |129286/173481[33:11<12:36,58.43it/s] 80%|#######9  |138697/173481[36:00<10:09,57.04it/s] 80%|########  |139330/173481[36:11<09:58,57.04it/s] 86%|########5 |148636/173481[39:00<07:22,56.11it/s] 86%|########6 |149266/173481[39:11<07:11,56.11it/s] 92%|#########2|160077/173481[42:00<03:44,59.60it/s] 93%|#########2|160723/173481[42:11<03:34,59.60it/s] 98%|#########8|170067/173481[45:00<00:59,57.48it/s] 98%|#########8|170728/173481[45:12<00:47,57.48it/s]100%|##########|173481/173481[46:00<00:00,62.83it/s]
[32m[0328 20:30:55 @base.py:257][0m Epoch 10 (global_step 11796708) finished, time:2760.92 sec.
[32m[0328 20:30:56 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-11796708.
[32m[0328 20:30:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 92%|#########2|17345/18822[03:00<00:15,96.36it/s] 98%|#########7|18441/18822[03:10<00:03,96.36it/s]100%|##########|18822/18822[03:13<00:00,97.20it/s]
9
[32m[0328 20:34:10 @monitor.py:363][0m QueueInput/queue_size: 0.64685
[32m[0328 20:34:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.828
[32m[0328 20:34:10 @monitor.py:363][0m activation-summaries/output-rms: 0.042383
[32m[0328 20:34:10 @monitor.py:363][0m cross_entropy_loss: 1.5828
[32m[0328 20:34:10 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 20:34:10 @monitor.py:363][0m train-error-top1: 0.42347
[32m[0328 20:34:10 @monitor.py:363][0m val-error-top1: 0.4331
[32m[0328 20:34:10 @monitor.py:363][0m val-utt-error: 0.10026
[32m[0328 20:34:10 @monitor.py:363][0m validation_cost: 1.6233
[32m[0328 20:34:10 @monitor.py:363][0m wd_cost: 7.8202e-17
[32m[0328 20:34:10 @group.py:42][0m Callbacks took 194.237 sec in total. InferenceRunner: 193.658sec
[32m[0328 20:34:10 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10766/173481[03:00<45:20,59.80it/s]  7%|6         |11329/173481[03:10<45:11,59.80it/s] 13%|#2        |22456/173481[06:00<40:25,62.26it/s] 13%|#3        |23170/173481[06:10<40:14,62.26it/s] 19%|#8        |32865/173481[09:00<39:05,59.96it/s] 19%|#9        |33445/173481[09:10<38:55,59.96it/s] 25%|##4       |43306/173481[12:00<36:47,58.96it/s] 25%|##5       |43925/173481[12:10<36:37,58.96it/s] 31%|###       |53487/173481[15:00<34:38,57.73it/s] 31%|###1      |54060/173481[15:10<34:28,57.73it/s] 37%|###6      |63358/173481[18:00<32:37,56.25it/s] 37%|###6      |63949/173481[18:10<32:27,56.25it/s] 42%|####2     |73276/173481[21:00<30:00,55.67it/s] 43%|####2     |73860/173481[21:10<29:49,55.67it/s] 48%|####7     |83264/173481[24:00<27:03,55.58it/s] 48%|####8     |83870/173481[24:11<26:52,55.58it/s] 54%|#####3    |93432/173481[27:00<23:48,56.03it/s] 54%|#####4    |94093/173481[27:11<23:36,56.03it/s] 63%|######3   |109893/173481[30:00<15:15,69.48it/s] 64%|######4   |111055/173481[30:11<14:58,69.48it/s] 73%|#######2  |126111/173481[33:00<10:03,78.45it/s] 73%|#######3  |126784/173481[33:11<09:55,78.45it/s] 79%|#######8  |136526/173481[36:00<09:14,66.60it/s] 79%|#######9  |137202/173481[36:11<09:04,66.60it/s] 85%|########4 |146971/173481[39:00<07:07,62.01it/s] 85%|########5 |147625/173481[39:11<06:56,62.01it/s] 91%|######### |157206/173481[42:00<04:34,59.31it/s] 91%|######### |157845/173481[42:11<04:23,59.31it/s] 96%|#########6|167333/173481[45:00<01:46,57.75it/s] 97%|#########6|168000/173481[45:12<01:34,57.75it/s]100%|##########|173481/173481[46:49<00:00,61.74it/s]
[32m[0328 21:21:00 @base.py:257][0m Epoch 11 (global_step 11970189) finished, time:2809.98 sec.
[32m[0328 21:21:00 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s] 93%|#########2|17433/18822[03:00<00:14,96.83it/s] 98%|#########8|18476/18822[03:10<00:03,96.83it/s]100%|##########|18822/18822[03:13<00:00,97.15it/s]
10
[32m[0328 21:24:14 @monitor.py:363][0m QueueInput/queue_size: 0.87794
[32m[0328 21:24:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.795
[32m[0328 21:24:14 @monitor.py:363][0m activation-summaries/output-rms: 0.040903
[32m[0328 21:24:14 @monitor.py:363][0m cross_entropy_loss: 1.5901
[32m[0328 21:24:14 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 21:24:14 @monitor.py:363][0m train-error-top1: 0.4224
[32m[0328 21:24:14 @monitor.py:363][0m val-error-top1: 0.43231
[32m[0328 21:24:14 @monitor.py:363][0m val-utt-error: 0.10137
[32m[0328 21:24:14 @monitor.py:363][0m validation_cost: 1.622
[32m[0328 21:24:14 @monitor.py:363][0m wd_cost: 7.8202e-17
[32m[0328 21:24:14 @group.py:42][0m Callbacks took 194.055 sec in total. InferenceRunner: 193.759sec
[32m[0328 21:24:14 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10916/173481[03:00<44:40,60.64it/s]  7%|6         |11622/173481[03:10<44:29,60.64it/s] 12%|#2        |21085/173481[06:00<43:25,58.49it/s] 12%|#2        |21639/173481[06:10<43:16,58.49it/s] 18%|#7        |31052/173481[09:00<41:43,56.89it/s] 18%|#8        |31646/173481[09:10<41:33,56.89it/s] 24%|##3       |41063/173481[12:00<39:14,56.24it/s] 24%|##4       |41644/173481[12:10<39:04,56.24it/s] 29%|##9       |51108/173481[15:00<36:24,56.02it/s] 30%|##9       |51692/173481[15:10<36:13,56.02it/s] 35%|###5      |61280/173481[18:00<33:14,56.26it/s] 36%|###5      |61889/173481[18:10<33:03,56.26it/s] 41%|####1     |71192/173481[21:00<30:37,55.66it/s] 41%|####1     |71774/173481[21:10<30:27,55.66it/s] 47%|####6     |81281/173481[24:00<27:30,55.85it/s] 47%|####7     |81919/173481[24:11<27:19,55.85it/s] 53%|#####2    |91256/173481[27:00<24:37,55.63it/s] 53%|#####2    |91892/173481[27:11<24:26,55.63it/s] 59%|#####8    |102313/173481[30:00<20:18,58.39it/s] 59%|#####9    |103079/173481[30:11<20:05,58.39it/s] 65%|######5   |113020/173481[33:00<17:06,58.93it/s] 66%|######5   |113649/173481[33:11<16:55,58.93it/s] 71%|#######   |122915/173481[36:00<14:49,56.88it/s] 71%|#######1  |123804/173481[36:11<14:33,56.88it/s] 81%|########  |139739/173481[39:00<07:57,70.72it/s] 81%|########1 |140841/173481[39:11<07:41,70.72it/s] 88%|########8 |153045/173481[42:00<04:42,72.28it/s] 89%|########8 |153702/173481[42:11<04:33,72.28it/s] 94%|#########3|162930/173481[45:00<02:49,62.41it/s] 94%|#########4|163577/173481[45:11<02:38,62.41it/s]100%|##########|173481/173481[47:52<00:00,60.39it/s]
[32m[0328 22:12:06 @base.py:257][0m Epoch 12 (global_step 12143670) finished, time:2872.64 sec.
[32m[0328 22:12:07 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-12143670.
  0%|          |0/18822[00:00<?,?it/s] 97%|#########6|18238/18822[03:00<00:05,101.32it/s]100%|##########|18822/18822[03:05<00:00,101.40it/s]
11
[32m[0328 22:15:12 @monitor.py:363][0m QueueInput/queue_size: 1.0227
[32m[0328 22:15:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.969
[32m[0328 22:15:12 @monitor.py:363][0m activation-summaries/output-rms: 0.041179
[32m[0328 22:15:12 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0328 22:15:12 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 22:15:12 @monitor.py:363][0m train-error-top1: 0.43151
[32m[0328 22:15:12 @monitor.py:363][0m val-error-top1: 0.43234
[32m[0328 22:15:12 @monitor.py:363][0m val-utt-error: 0.099033
[32m[0328 22:15:12 @monitor.py:363][0m validation_cost: 1.6189
[32m[0328 22:15:12 @monitor.py:363][0m wd_cost: 1.564e-17
[32m[0328 22:15:12 @group.py:42][0m Callbacks took 185.911 sec in total. InferenceRunner: 185.643sec
[32m[0328 22:15:12 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10658/173481[03:00<45:49,59.21it/s]  6%|6         |11218/173481[03:10<45:40,59.21it/s] 12%|#1        |20651/173481[06:00<44:27,57.30it/s] 12%|#2        |21227/173481[06:10<44:16,57.30it/s] 18%|#7        |30459/173481[09:00<42:40,55.86it/s] 18%|#7        |31028/173481[09:10<42:30,55.86it/s] 23%|##3       |40324/173481[12:00<40:07,55.32it/s] 24%|##3       |40903/173481[12:10<39:56,55.32it/s] 29%|##8       |50170/173481[15:00<37:21,55.01it/s] 29%|##9       |50748/173481[15:10<37:11,55.01it/s] 35%|###4      |60556/173481[18:00<33:25,56.32it/s] 35%|###5      |61185/173481[18:10<33:13,56.32it/s] 41%|####      |70724/173481[21:00<30:22,56.39it/s] 41%|####1     |71356/173481[21:10<30:10,56.39it/s] 47%|####6     |80969/173481[24:00<27:13,56.65it/s] 47%|####7     |81582/173481[24:11<27:02,56.65it/s] 53%|#####2    |91414/173481[27:00<23:51,57.32it/s] 53%|#####3    |92037/173481[27:11<23:40,57.32it/s] 59%|#####8    |101654/173481[30:00<20:57,57.10it/s] 59%|#####8    |102303/173481[30:11<20:46,57.10it/s] 65%|######4   |112024/173481[33:00<17:51,57.35it/s] 65%|######4   |112683/173481[33:11<17:40,57.35it/s] 70%|#######   |122249/173481[36:00<14:57,57.07it/s] 71%|#######   |122880/173481[36:11<14:46,57.07it/s] 76%|#######6  |132502/173481[39:00<11:58,57.01it/s] 77%|#######6  |133115/173481[39:11<11:48,57.01it/s] 82%|########2 |142624/173481[42:00<09:05,56.62it/s] 83%|########2 |143283/173481[42:11<08:53,56.62it/s] 90%|######### |156377/173481[45:00<04:22,65.04it/s] 91%|######### |157476/173481[45:12<04:06,65.04it/s]100%|##########|173481/173481[48:00<00:00,60.24it/s]
[32m[0328 23:03:12 @base.py:257][0m Epoch 13 (global_step 12317151) finished, time:2880.02 sec.
[32m[0328 23:03:12 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,109.33it/s]
12
[32m[0328 23:06:05 @monitor.py:363][0m QueueInput/queue_size: 0.90904
[32m[0328 23:06:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.808
[32m[0328 23:06:05 @monitor.py:363][0m activation-summaries/output-rms: 0.040718
[32m[0328 23:06:05 @monitor.py:363][0m cross_entropy_loss: 1.5815
[32m[0328 23:06:05 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0328 23:06:05 @monitor.py:363][0m train-error-top1: 0.42934
[32m[0328 23:06:05 @monitor.py:363][0m val-error-top1: 0.43266
[32m[0328 23:06:05 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0328 23:06:05 @monitor.py:363][0m validation_cost: 1.6203
[32m[0328 23:06:05 @monitor.py:363][0m wd_cost: 1.564e-17
[32m[0328 23:06:05 @group.py:42][0m Callbacks took 172.364 sec in total. InferenceRunner: 172.174sec
[32m[0328 23:06:05 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10418/173481[03:00<46:57,57.87it/s]  6%|6         |10973/173481[03:10<46:47,57.87it/s] 12%|#1        |20196/173481[06:00<45:35,56.04it/s] 12%|#1        |20754/173481[06:10<45:25,56.04it/s] 17%|#7        |30028/173481[09:00<43:13,55.32it/s] 18%|#7        |30612/173481[09:10<43:02,55.32it/s] 23%|##3       |40737/173481[12:00<38:35,57.33it/s] 24%|##3       |41423/173481[12:10<38:23,57.33it/s] 29%|##9       |50618/173481[15:00<36:30,56.09it/s] 30%|##9       |51217/173481[15:10<36:19,56.09it/s] 35%|###4      |60678/173481[18:00<33:34,55.98it/s] 35%|###5      |61282/173481[18:10<33:24,55.98it/s] 41%|####      |70792/173481[21:00<30:30,56.09it/s] 41%|####1     |71408/173481[21:10<30:19,56.09it/s] 47%|####7     |82088/173481[24:00<25:42,59.23it/s] 48%|####7     |82812/173481[24:11<25:30,59.23it/s] 53%|#####3    |92662/173481[27:00<22:50,58.99it/s] 54%|#####3    |93272/173481[27:11<22:39,58.99it/s] 59%|#####9    |102737/173481[30:00<20:31,57.44it/s] 60%|#####9    |103363/173481[30:11<20:20,57.44it/s] 65%|######4   |112088/173481[33:00<18:45,54.55it/s] 65%|######4   |112715/173481[33:11<18:33,54.55it/s] 70%|######9   |121278/173481[36:00<16:29,52.74it/s] 70%|#######   |121822/173481[36:11<16:19,52.74it/s] 75%|#######4  |129413/173481[39:00<15:05,48.67it/s] 75%|#######4  |129978/173481[39:11<14:53,48.67it/s] 79%|#######9  |137193/173481[42:00<13:12,45.78it/s] 79%|#######9  |137692/173481[42:11<13:01,45.78it/s] 84%|########3 |145163/173481[45:00<10:29,45.01it/s] 84%|########3 |145697/173481[45:12<10:17,45.01it/s] 88%|########8 |153343/173481[48:00<07:25,45.22it/s] 89%|########8 |153911/173481[48:12<07:12,45.22it/s] 93%|#########3|161671/173481[51:00<04:18,45.73it/s] 94%|#########3|162254/173481[51:12<04:05,45.73it/s] 99%|#########8|170923/173481[54:00<00:52,48.40it/s] 99%|#########8|171637/173481[54:12<00:38,48.40it/s]100%|##########|173481/173481[54:41<00:00,52.87it/s]
[32m[0329 00:00:46 @base.py:257][0m Epoch 14 (global_step 12490632) finished, time:3281.12 sec.
[32m[0329 00:00:46 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-12490632.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.30it/s]
13
[32m[0329 00:02:50 @monitor.py:363][0m QueueInput/queue_size: 1.1735
[32m[0329 00:02:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.76
[32m[0329 00:02:50 @monitor.py:363][0m activation-summaries/output-rms: 0.040878
[32m[0329 00:02:50 @monitor.py:363][0m cross_entropy_loss: 1.5884
[32m[0329 00:02:50 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 00:02:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 00:02:50 @monitor.py:363][0m train-error-top1: 0.42817
[32m[0329 00:02:50 @monitor.py:363][0m val-error-top1: 0.43206
[32m[0329 00:02:50 @monitor.py:363][0m val-utt-error: 0.099883
[32m[0329 00:02:50 @monitor.py:363][0m validation_cost: 1.6196
[32m[0329 00:02:50 @monitor.py:363][0m wd_cost: 3.1281e-18
[32m[0329 00:02:50 @group.py:42][0m Callbacks took 124.037 sec in total. InferenceRunner: 123.597sec
[32m[0329 00:02:50 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9277/173481[03:00<53:07,51.52it/s]  6%|5         |9731/173481[03:10<52:58,51.52it/s] 10%|#         |17477/173481[06:00<53:46,48.35it/s] 10%|#         |17941/173481[06:10<53:37,48.35it/s] 15%|#4        |25277/173481[09:00<54:02,45.70it/s] 15%|#4        |25720/173481[09:10<53:53,45.70it/s] 19%|#9        |33302/173481[12:00<51:45,45.13it/s] 19%|#9        |33763/173481[12:10<51:35,45.13it/s] 24%|##4       |42167/173481[15:00<46:28,47.09it/s] 25%|##4       |42681/173481[15:10<46:17,47.09it/s] 29%|##9       |50967/173481[18:00<42:33,47.97it/s] 30%|##9       |51513/173481[18:10<42:22,47.97it/s] 34%|###4      |59462/173481[21:00<39:56,47.57it/s] 35%|###4      |59931/173481[21:10<39:46,47.57it/s] 39%|###8      |67424/173481[24:00<38:33,45.84it/s] 39%|###9      |67957/173481[24:11<38:21,45.84it/s] 44%|####3     |76134/173481[27:00<34:27,47.08it/s] 44%|####4     |76655/173481[27:11<34:16,47.08it/s] 49%|####8     |84347/173481[30:00<32:03,46.34it/s] 49%|####8     |84816/173481[30:11<31:53,46.34it/s] 53%|#####3    |92372/173481[33:00<29:45,45.44it/s] 54%|#####3    |92879/173481[33:11<29:33,45.44it/s] 58%|#####7    |100222/173481[36:00<27:26,44.50it/s] 58%|#####8    |100731/173481[36:11<27:14,44.50it/s] 62%|######2   |108392/173481[39:00<24:08,44.94it/s] 63%|######2   |108891/173481[39:11<23:57,44.94it/s] 67%|######7   |116617/173481[42:00<20:54,45.31it/s] 68%|######7   |117142/173481[42:11<20:43,45.31it/s] 72%|#######1  |124618/173481[45:00<18:08,44.88it/s] 72%|#######2  |125144/173481[45:11<17:57,44.88it/s] 76%|#######6  |132702/173481[48:00<15:08,44.89it/s] 77%|#######6  |133186/173481[48:12<14:57,44.89it/s] 81%|########1 |140777/173481[51:00<12:08,44.87it/s] 81%|########1 |141314/173481[51:12<11:56,44.87it/s] 86%|########5 |148842/173481[54:00<09:09,44.84it/s] 86%|########6 |149353/173481[54:12<08:58,44.84it/s] 90%|######### |156982/173481[57:00<06:06,45.02it/s] 91%|######### |157596/173481[57:12<05:52,45.02it/s] 97%|#########7|168283/173481[1:00:00<01:39,52.44it/s] 97%|#########7|169081/173481[1:00:12<01:23,52.44it/s]100%|##########|173481/173481[1:01:34<00:00,46.95it/s]
[32m[0329 01:04:25 @base.py:257][0m Epoch 15 (global_step 12664113) finished, time:3694.90 sec.
[32m[0329 01:04:25 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:53<00:00,108.62it/s]
14
[32m[0329 01:07:18 @monitor.py:363][0m QueueInput/queue_size: 0.76602
[32m[0329 01:07:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.828
[32m[0329 01:07:18 @monitor.py:363][0m activation-summaries/output-rms: 0.042383
[32m[0329 01:07:18 @monitor.py:363][0m cross_entropy_loss: 1.5828
[32m[0329 01:07:18 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 01:07:18 @monitor.py:363][0m train-error-top1: 0.42347
[32m[0329 01:07:18 @monitor.py:363][0m val-error-top1: 0.4331
[32m[0329 01:07:18 @monitor.py:363][0m val-utt-error: 0.10026
[32m[0329 01:07:18 @monitor.py:363][0m validation_cost: 1.6233
[32m[0329 01:07:18 @monitor.py:363][0m wd_cost: 3.1281e-18
[32m[0329 01:07:18 @group.py:42][0m Callbacks took 173.594 sec in total. InferenceRunner: 173.303sec
[32m[0329 01:07:18 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9186/173481[03:00<53:40,51.02it/s]  6%|5         |9675/173481[03:10<53:30,51.02it/s] 10%|#         |18096/173481[06:00<51:32,50.24it/s] 11%|#         |18590/173481[06:10<51:22,50.24it/s] 16%|#5        |27201/173481[09:00<48:21,50.41it/s] 16%|#5        |27705/173481[09:10<48:11,50.41it/s] 21%|##        |35822/173481[12:00<46:42,49.12it/s] 21%|##        |36310/173481[12:10<46:32,49.12it/s] 26%|##5       |44325/173481[15:00<44:41,48.16it/s] 26%|##5       |44855/173481[15:10<44:30,48.16it/s] 30%|###       |52743/173481[18:00<42:24,47.45it/s] 31%|###       |53245/173481[18:10<42:13,47.45it/s] 35%|###5      |61134/173481[21:00<39:48,47.03it/s] 36%|###5      |61645/173481[21:11<39:37,47.03it/s] 40%|####      |69436/173481[24:00<37:14,46.56it/s] 40%|####      |69925/173481[24:11<37:04,46.56it/s] 45%|####4     |77536/173481[27:00<34:57,45.75it/s] 45%|####4     |78035/173481[27:11<34:46,45.75it/s] 49%|####9     |85836/173481[30:00<31:48,45.93it/s] 50%|####9     |86340/173481[30:11<31:37,45.93it/s] 54%|#####4    |94081/173481[33:00<28:51,45.86it/s] 55%|#####4    |94590/173481[33:11<28:40,45.86it/s] 59%|#####8    |102071/173481[36:00<26:23,45.11it/s] 59%|#####9    |102580/173481[36:11<26:11,45.11it/s] 63%|######3   |110116/173481[39:00<23:31,44.90it/s] 64%|######3   |110630/173481[39:11<23:19,44.90it/s] 68%|######8   |118101/173481[42:00<20:41,44.62it/s] 68%|######8   |118605/173481[42:11<20:29,44.62it/s] 73%|#######2  |126171/173481[45:00<17:37,44.72it/s] 73%|#######3  |126690/173481[45:12<17:26,44.72it/s] 77%|#######7  |134191/173481[48:00<14:40,44.64it/s] 78%|#######7  |134642/173481[48:12<14:30,44.64it/s] 82%|########1 |141916/173481[51:00<12:01,43.76it/s] 82%|########2 |142415/173481[51:12<11:49,43.76it/s] 86%|########6 |149812/173481[54:00<09:00,43.81it/s] 87%|########6 |150340/173481[54:12<08:48,43.81it/s] 92%|#########2|160376/173481[57:00<04:21,50.17it/s] 93%|#########2|161090/173481[57:12<04:06,50.17it/s] 97%|#########7|168661/173481[1:00:00<01:40,48.00it/s] 98%|#########7|169155/173481[1:00:12<01:30,48.00it/s]100%|##########|173481/173481[1:01:56<00:00,46.68it/s]
[32m[0329 02:09:15 @base.py:257][0m Epoch 16 (global_step 12837594) finished, time:3716.42 sec.
[32m[0329 02:09:15 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:51<00:00,109.54it/s]
15
[32m[0329 02:12:07 @monitor.py:363][0m QueueInput/queue_size: 0.7594
[32m[0329 02:12:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.795
[32m[0329 02:12:07 @monitor.py:363][0m activation-summaries/output-rms: 0.040903
[32m[0329 02:12:07 @monitor.py:363][0m cross_entropy_loss: 1.5901
[32m[0329 02:12:07 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 02:12:07 @monitor.py:363][0m train-error-top1: 0.4224
[32m[0329 02:12:07 @monitor.py:363][0m val-error-top1: 0.43231
[32m[0329 02:12:07 @monitor.py:363][0m val-utt-error: 0.10137
[32m[0329 02:12:07 @monitor.py:363][0m validation_cost: 1.622
[32m[0329 02:12:07 @monitor.py:363][0m wd_cost: 3.1281e-18
[32m[0329 02:12:07 @group.py:42][0m Callbacks took 172.100 sec in total. InferenceRunner: 171.842sec
[32m[0329 02:12:07 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9350/173481[03:00<52:40,51.93it/s]  6%|5         |9814/173481[03:10<52:31,51.93it/s] 10%|#         |17845/173481[06:00<52:27,49.44it/s] 11%|#         |18304/173481[06:10<52:18,49.44it/s] 15%|#5        |26244/173481[09:00<51:06,48.01it/s] 15%|#5        |26724/173481[09:10<50:56,48.01it/s] 20%|#9        |34580/173481[12:00<49:06,47.14it/s] 20%|##        |35034/173481[12:10<48:56,47.14it/s] 25%|##4       |42745/173481[15:00<47:07,46.23it/s] 25%|##4       |43239/173481[15:10<46:57,46.23it/s] 29%|##9       |51027/173481[18:00<44:15,46.12it/s] 30%|##9       |51514/173481[18:10<44:04,46.12it/s] 34%|###4      |59190/173481[21:00<41:39,45.73it/s] 34%|###4      |59693/173481[21:10<41:28,45.73it/s] 39%|###8      |67256/173481[24:00<39:06,45.27it/s] 39%|###9      |67763/173481[24:11<38:55,45.27it/s] 44%|####3     |75470/173481[27:00<35:56,45.45it/s] 44%|####3     |75994/173481[27:11<35:45,45.45it/s] 48%|####8     |84005/173481[30:00<32:08,46.41it/s] 49%|####8     |84628/173481[30:11<31:54,46.41it/s] 54%|#####4    |94107/173481[33:00<26:02,50.80it/s] 55%|#####4    |94757/173481[33:11<25:49,50.80it/s] 60%|######    |104130/173481[36:00<21:45,53.13it/s] 60%|######    |104755/173481[36:11<21:33,53.13it/s] 66%|######5   |114150/173481[39:00<18:11,54.37it/s] 66%|######6   |114797/173481[39:11<17:59,54.37it/s] 72%|#######1  |124086/173481[42:00<15:01,54.78it/s] 72%|#######1  |124724/173481[42:11<14:50,54.78it/s] 77%|#######7  |133731/173481[45:00<12:13,54.17it/s] 77%|#######7  |134266/173481[45:11<12:03,54.17it/s] 82%|########1 |141525/173481[48:00<11:04,48.12it/s] 82%|########1 |142043/173481[48:12<10:53,48.12it/s] 87%|########6 |150135/173481[51:00<08:06,47.98it/s] 87%|########6 |150886/173481[51:12<07:50,47.98it/s] 93%|#########2|161295/173481[54:00<03:45,54.09it/s] 93%|#########3|161779/173481[54:12<03:36,54.09it/s] 98%|#########7|169380/173481[57:00<01:23,49.07it/s] 98%|#########7|169959/173481[57:12<01:11,49.07it/s]100%|##########|173481/173481[58:27<00:00,49.45it/s]
[32m[0329 03:10:35 @base.py:257][0m Epoch 17 (global_step 13011075) finished, time:3507.98 sec.
[32m[0329 03:10:35 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-13011075.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:40<00:00,117.33it/s]
16
[32m[0329 03:13:15 @monitor.py:363][0m QueueInput/queue_size: 1.2019
[32m[0329 03:13:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.969
[32m[0329 03:13:15 @monitor.py:363][0m activation-summaries/output-rms: 0.041179
[32m[0329 03:13:15 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0329 03:13:15 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 03:13:15 @monitor.py:363][0m train-error-top1: 0.43151
[32m[0329 03:13:15 @monitor.py:363][0m val-error-top1: 0.43234
[32m[0329 03:13:15 @monitor.py:363][0m val-utt-error: 0.099033
[32m[0329 03:13:15 @monitor.py:363][0m validation_cost: 1.6189
[32m[0329 03:13:15 @monitor.py:363][0m wd_cost: 6.2561e-19
[32m[0329 03:13:15 @group.py:42][0m Callbacks took 160.694 sec in total. InferenceRunner: 160.431sec
[32m[0329 03:13:15 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8897/173481[03:00<55:29,49.43it/s]  5%|5         |9383/173481[03:10<55:19,49.43it/s] 10%|#         |17635/173481[06:00<53:01,48.98it/s] 10%|#         |18141/173481[06:10<52:51,48.98it/s] 15%|#5        |26325/173481[09:00<50:26,48.63it/s] 15%|#5        |26798/173481[09:10<50:16,48.63it/s] 20%|#9        |34449/173481[12:00<49:31,46.79it/s] 20%|##        |34908/173481[12:10<49:21,46.79it/s] 25%|##4       |43019/173481[15:00<46:04,47.20it/s] 25%|##5       |43603/173481[15:10<45:51,47.20it/s] 30%|###       |52761/173481[18:00<39:54,50.42it/s] 31%|###       |53211/173481[18:10<39:45,50.42it/s] 35%|###4      |60629/173481[21:00<40:10,46.81it/s] 35%|###5      |61095/173481[21:10<40:00,46.81it/s] 40%|###9      |68669/173481[24:00<38:13,45.70it/s] 40%|###9      |69162/173481[24:11<38:02,45.70it/s] 44%|####4     |76699/173481[27:00<35:43,45.15it/s] 44%|####4     |77178/173481[27:11<35:33,45.15it/s] 49%|####8     |84714/173481[30:00<33:00,44.82it/s] 49%|####9     |85182/173481[30:11<32:49,44.82it/s] 53%|#####3    |92676/173481[33:00<30:14,44.53it/s] 54%|#####3    |93171/173481[33:11<30:03,44.53it/s] 58%|#####7    |100579/173481[36:00<27:28,44.21it/s] 58%|#####8    |101078/173481[36:11<27:17,44.21it/s] 63%|######2   |108534/173481[39:00<24:29,44.19it/s] 63%|######2   |109003/173481[39:11<24:19,44.19it/s] 67%|######7   |116442/173481[42:00<21:34,44.06it/s] 67%|######7   |116938/173481[42:11<21:23,44.06it/s] 72%|#######1  |124694/173481[45:00<18:05,44.93it/s] 72%|#######2  |125192/173481[45:12<17:54,44.93it/s] 77%|#######6  |133127/173481[48:00<14:39,45.87it/s] 77%|#######7  |133633/173481[48:12<14:28,45.87it/s] 81%|########1 |141100/173481[51:00<11:58,45.07it/s] 82%|########1 |141627/173481[51:12<11:46,45.07it/s] 87%|########7 |150987/173481[54:00<07:34,49.51it/s] 87%|########7 |151720/173481[54:12<07:19,49.51it/s] 93%|#########2|161059/173481[57:00<03:56,52.54it/s] 93%|#########3|161553/173481[57:12<03:47,52.54it/s] 98%|#########7|169206/173481[1:00:00<01:27,48.63it/s] 98%|#########7|169728/173481[1:00:12<01:17,48.63it/s]100%|##########|173481/173481[1:01:38<00:00,46.91it/s]
[32m[0329 04:14:54 @base.py:257][0m Epoch 18 (global_step 13184556) finished, time:3698.09 sec.
[32m[0329 04:14:54 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:41<00:00,116.86it/s]
17
[32m[0329 04:17:35 @monitor.py:363][0m QueueInput/queue_size: 0.85801
[32m[0329 04:17:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.808
[32m[0329 04:17:35 @monitor.py:363][0m activation-summaries/output-rms: 0.040718
[32m[0329 04:17:35 @monitor.py:363][0m cross_entropy_loss: 1.5815
[32m[0329 04:17:35 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 04:17:35 @monitor.py:363][0m train-error-top1: 0.42934
[32m[0329 04:17:35 @monitor.py:363][0m val-error-top1: 0.43266
[32m[0329 04:17:35 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0329 04:17:35 @monitor.py:363][0m validation_cost: 1.6203
[32m[0329 04:17:35 @monitor.py:363][0m wd_cost: 6.2561e-19
[32m[0329 04:17:35 @group.py:42][0m Callbacks took 161.316 sec in total. InferenceRunner: 161.074sec
[32m[0329 04:17:35 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8713/173481[03:00<56:43,48.40it/s]  5%|5         |9169/173481[03:10<56:34,48.40it/s] 10%|9         |16520/173481[06:00<57:10,45.75it/s] 10%|9         |16957/173481[06:10<57:01,45.75it/s] 14%|#4        |24363/173481[09:00<55:41,44.63it/s] 14%|#4        |24822/173481[09:10<55:31,44.63it/s] 19%|#8        |32403/173481[12:00<52:40,44.64it/s] 19%|#8        |32862/173481[12:10<52:29,44.64it/s] 23%|##3       |40460/173481[15:00<49:35,44.70it/s] 24%|##3       |40942/173481[15:10<49:24,44.70it/s] 28%|##8       |48588/173481[18:00<46:19,44.93it/s] 28%|##8       |49060/173481[18:10<46:09,44.93it/s] 33%|###2      |56490/173481[21:00<43:54,44.41it/s] 33%|###2      |56972/173481[21:10<43:43,44.41it/s] 37%|###7      |64493/173481[24:00<40:53,44.43it/s] 37%|###7      |64972/173481[24:11<40:42,44.43it/s] 42%|####1     |72598/173481[27:00<37:35,44.72it/s] 42%|####2     |73107/173481[27:11<37:24,44.72it/s] 47%|####6     |80723/173481[30:00<34:24,44.92it/s] 47%|####6     |81242/173481[30:11<34:13,44.92it/s] 51%|#####1    |88856/173481[33:00<31:18,45.05it/s] 52%|#####1    |89362/173481[33:11<31:07,45.05it/s] 56%|#####5    |97032/173481[36:00<28:09,45.24it/s] 56%|#####6    |97538/173481[36:11<27:58,45.24it/s] 61%|######    |105128/173481[39:00<25:15,45.10it/s] 61%|######    |105637/173481[39:11<25:04,45.10it/s] 65%|######5   |113241/173481[42:00<22:16,45.09it/s] 66%|######5   |113777/173481[42:11<22:04,45.09it/s] 70%|#######   |121633/173481[45:00<18:51,45.84it/s] 70%|#######   |122147/173481[45:12<18:39,45.84it/s] 75%|#######4  |129753/173481[48:00<16:01,45.47it/s] 75%|#######5  |130297/173481[48:12<15:49,45.47it/s] 80%|#######9  |138488/173481[51:00<12:25,46.94it/s] 80%|########  |139242/173481[51:12<12:09,46.94it/s] 86%|########6 |149778/173481[54:00<07:21,53.69it/s] 87%|########6 |150522/173481[54:12<07:07,53.69it/s] 91%|#########1|158478/173481[57:00<04:54,50.87it/s] 92%|#########1|159054/173481[57:12<04:43,50.87it/s] 96%|#########6|166883/173481[1:00:00<02:15,48.69it/s] 96%|#########6|167402/173481[1:00:12<02:04,48.69it/s]100%|##########|173481/173481[1:02:28<00:00,46.28it/s]
[32m[0329 05:20:04 @base.py:257][0m Epoch 19 (global_step 13358037) finished, time:3748.65 sec.
[32m[0329 05:20:04 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:39<00:00,118.17it/s]
18
[32m[0329 05:22:43 @monitor.py:363][0m QueueInput/queue_size: 0.96661
[32m[0329 05:22:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.76
[32m[0329 05:22:43 @monitor.py:363][0m activation-summaries/output-rms: 0.040878
[32m[0329 05:22:43 @monitor.py:363][0m cross_entropy_loss: 1.5884
[32m[0329 05:22:43 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 05:22:43 @monitor.py:363][0m train-error-top1: 0.42817
[32m[0329 05:22:43 @monitor.py:363][0m val-error-top1: 0.43206
[32m[0329 05:22:43 @monitor.py:363][0m val-utt-error: 0.099883
[32m[0329 05:22:43 @monitor.py:363][0m validation_cost: 1.6196
[32m[0329 05:22:43 @monitor.py:363][0m wd_cost: 6.2561e-19
[32m[0329 05:22:43 @group.py:42][0m Callbacks took 159.510 sec in total. InferenceRunner: 159.290sec
[32m[0329 05:22:43 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8357/173481[03:00<59:17,46.42it/s]  5%|5         |8796/173481[03:10<59:07,46.42it/s]  9%|9         |16217/173481[06:00<58:15,44.99it/s] 10%|9         |16645/173481[06:10<58:06,44.99it/s] 14%|#3        |23878/173481[09:00<57:00,43.74it/s] 14%|#4        |24328/173481[09:10<56:49,43.74it/s] 18%|#8        |32047/173481[12:00<52:55,44.54it/s] 19%|#8        |32516/173481[12:10<52:44,44.54it/s] 23%|##3       |40327/173481[15:00<49:02,45.26it/s] 24%|##3       |40811/173481[15:10<48:51,45.26it/s] 28%|##7       |48380/173481[18:00<46:20,45.00it/s] 28%|##8       |48851/173481[18:10<46:09,45.00it/s] 33%|###2      |56983/173481[21:00<41:53,46.35it/s] 33%|###3      |57491/173481[21:10<41:42,46.35it/s] 38%|###7      |65662/173481[24:00<38:01,47.26it/s] 38%|###8      |66171/173481[24:11<37:50,47.26it/s] 43%|####2     |73942/173481[27:00<35:35,46.62it/s] 43%|####2     |74476/173481[27:11<35:23,46.62it/s] 47%|####7     |82337/173481[30:00<32:34,46.62it/s] 48%|####7     |82856/173481[30:11<32:23,46.62it/s] 52%|#####2    |90792/173481[33:00<29:27,46.79it/s] 53%|#####2    |91289/173481[33:11<29:16,46.79it/s] 57%|#####6    |98553/173481[36:00<27:49,44.88it/s] 57%|#####7    |98991/173481[36:11<27:39,44.88it/s] 61%|######1   |106417/173481[39:00<25:14,44.27it/s] 62%|######1   |106921/173481[39:11<25:03,44.27it/s] 66%|######5   |114087/173481[42:00<22:47,43.42it/s] 66%|######6   |114586/173481[42:11<22:36,43.42it/s] 70%|#######   |121467/173481[45:00<20:33,42.17it/s] 70%|#######   |121987/173481[45:12<20:21,42.17it/s] 75%|#######4  |129692/173481[48:00<16:38,43.86it/s] 75%|#######5  |130386/173481[48:12<16:22,43.86it/s] 81%|########  |140372/173481[51:00<10:56,50.43it/s] 81%|########1 |141116/173481[51:12<10:41,50.43it/s] 86%|########5 |148834/173481[54:00<08:26,48.66it/s] 86%|########6 |149333/173481[54:12<08:16,48.66it/s] 91%|######### |157177/173481[57:00<05:43,47.47it/s] 91%|######### |157736/173481[57:12<05:31,47.47it/s] 95%|#########5|165168/173481[1:00:00<03:01,45.88it/s] 96%|#########5|165687/173481[1:00:12<02:49,45.88it/s]100%|#########9|173025/173481[1:03:00<00:10,44.74it/s]100%|##########|173481/173481[1:03:11<00:00,45.76it/s]
[32m[0329 06:25:54 @base.py:257][0m Epoch 20 (global_step 13531518) finished, time:3791.07 sec.
[32m[0329 06:25:54 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-13531518.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:53<00:00,108.62it/s]
19
[32m[0329 06:28:48 @monitor.py:363][0m QueueInput/queue_size: 0.48901
[32m[0329 06:28:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.828
[32m[0329 06:28:48 @monitor.py:363][0m activation-summaries/output-rms: 0.042383
[32m[0329 06:28:48 @monitor.py:363][0m cross_entropy_loss: 1.5828
[32m[0329 06:28:48 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 06:28:48 @monitor.py:363][0m train-error-top1: 0.42347
[32m[0329 06:28:48 @monitor.py:363][0m val-error-top1: 0.4331
[32m[0329 06:28:48 @monitor.py:363][0m val-utt-error: 0.10026
[32m[0329 06:28:48 @monitor.py:363][0m validation_cost: 1.6233
[32m[0329 06:28:48 @monitor.py:363][0m wd_cost: 1.2512e-19
[32m[0329 06:28:48 @group.py:42][0m Callbacks took 173.760 sec in total. InferenceRunner: 173.521sec
[32m[0329 06:28:48 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8636/173481[03:00<57:15,47.98it/s]  5%|5         |9100/173481[03:10<57:06,47.98it/s] 10%|9         |16551/173481[06:00<56:59,45.89it/s] 10%|9         |17015/173481[06:10<56:49,45.89it/s] 15%|#4        |25975/173481[09:00<50:16,48.91it/s] 15%|#5        |26495/173481[09:10<50:05,48.91it/s] 20%|##        |34815/173481[12:00<47:09,49.01it/s] 20%|##        |35276/173481[12:10<47:00,49.01it/s] 25%|##4       |42939/173481[15:00<46:18,46.99it/s] 25%|##5       |43410/173481[15:10<46:07,46.99it/s] 30%|##9       |51506/173481[18:00<42:59,47.28it/s] 30%|##9       |51992/173481[18:10<42:49,47.28it/s] 34%|###4      |59617/173481[21:00<41:07,46.15it/s] 35%|###4      |60020/173481[21:10<40:58,46.15it/s] 39%|###8      |67076/173481[24:00<40:37,43.66it/s] 39%|###8      |67540/173481[24:11<40:26,43.66it/s] 43%|####3     |74770/173481[27:00<38:05,43.20it/s] 43%|####3     |75280/173481[27:11<37:53,43.20it/s] 48%|####7     |82921/173481[30:00<34:08,44.21it/s] 48%|####8     |83425/173481[30:11<33:56,44.21it/s] 52%|#####2    |90771/173481[33:00<31:24,43.90it/s] 53%|#####2    |91250/173481[33:11<31:13,43.90it/s] 57%|#####6    |98562/173481[36:00<28:38,43.59it/s] 57%|#####7    |99070/173481[36:11<28:27,43.59it/s] 61%|######1   |106313/173481[39:00<25:50,43.32it/s] 62%|######1   |106813/173481[39:11<25:38,43.32it/s] 66%|######5   |114253/173481[42:00<22:34,43.71it/s] 66%|######6   |114775/173481[42:11<22:22,43.71it/s] 71%|#######1  |123851/173481[45:00<17:13,48.04it/s] 72%|#######1  |124575/173481[45:12<16:58,48.04it/s] 77%|#######6  |133487/173481[48:00<13:09,50.64it/s] 77%|#######7  |134030/173481[48:12<12:59,50.64it/s] 82%|########1 |141969/173481[51:00<10:45,48.82it/s] 82%|########2 |142519/173481[51:12<10:34,48.82it/s] 86%|########6 |149746/173481[54:00<08:37,45.83it/s] 87%|########6 |150270/173481[54:12<08:26,45.83it/s] 91%|######### |157526/173481[57:00<05:58,44.48it/s] 91%|#########1|158100/173481[57:12<05:45,44.48it/s] 95%|#########5|165416/173481[1:00:00<03:02,44.15it/s] 96%|#########5|165949/173481[1:00:12<02:50,44.15it/s]100%|#########9|173156/173481[1:03:00<00:07,43.56it/s]100%|##########|173481/173481[1:03:08<00:00,45.79it/s]
[32m[0329 07:31:56 @base.py:257][0m Epoch 21 (global_step 13704999) finished, time:3788.47 sec.
[32m[0329 07:31:57 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-13704999.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:46<00:00,112.87it/s]
20
[32m[0329 07:34:43 @monitor.py:363][0m QueueInput/queue_size: 0.62718
[32m[0329 07:34:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.795
[32m[0329 07:34:43 @monitor.py:363][0m activation-summaries/output-rms: 0.040903
[32m[0329 07:34:43 @monitor.py:363][0m cross_entropy_loss: 1.5901
[32m[0329 07:34:43 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 07:34:43 @monitor.py:363][0m train-error-top1: 0.4224
[32m[0329 07:34:43 @monitor.py:363][0m val-error-top1: 0.43231
[32m[0329 07:34:43 @monitor.py:363][0m val-utt-error: 0.10137
[32m[0329 07:34:43 @monitor.py:363][0m validation_cost: 1.622
[32m[0329 07:34:43 @monitor.py:363][0m wd_cost: 1.2512e-19
[32m[0329 07:34:43 @group.py:42][0m Callbacks took 167.061 sec in total. InferenceRunner: 166.768sec
[32m[0329 07:34:43 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8614/173481[03:00<57:25,47.86it/s]  5%|5         |9075/173481[03:10<57:15,47.86it/s] 10%|9         |16790/173481[06:00<56:02,46.61it/s] 10%|9         |17262/173481[06:10<55:51,46.61it/s] 14%|#4        |25042/173481[09:00<53:31,46.22it/s] 15%|#4        |25509/173481[09:10<53:21,46.22it/s] 19%|#9        |33136/173481[12:00<51:18,45.59it/s] 19%|#9        |33589/173481[12:10<51:08,45.59it/s] 23%|##3       |40606/173481[15:00<50:58,43.45it/s] 24%|##3       |41041/173481[15:10<50:48,43.45it/s] 28%|##7       |48136/173481[18:00<49:00,42.62it/s] 28%|##8       |48589/173481[18:10<48:50,42.62it/s] 32%|###2      |55526/173481[21:00<47:00,41.82it/s] 32%|###2      |55994/173481[21:10<46:49,41.82it/s] 36%|###6      |63315/173481[24:00<43:10,42.53it/s] 37%|###6      |63767/173481[24:11<42:59,42.53it/s] 41%|####      |70965/173481[27:00<40:11,42.51it/s] 41%|####1     |71464/173481[27:11<39:59,42.51it/s] 46%|####5     |79050/173481[30:00<36:02,43.67it/s] 46%|####5     |79531/173481[30:11<35:51,43.67it/s] 50%|#####     |87163/173481[33:00<32:25,44.36it/s] 51%|#####     |87684/173481[33:11<32:14,44.36it/s] 55%|#####4    |95190/173481[36:00<29:20,44.47it/s] 55%|#####5    |95684/173481[36:11<29:09,44.47it/s] 59%|#####9    |103025/173481[39:00<26:41,43.99it/s] 60%|#####9    |103705/173481[39:11<26:25,43.99it/s] 65%|######5   |113606/173481[42:00<19:49,50.32it/s] 66%|######5   |114289/173481[42:11<19:36,50.32it/s] 71%|#######   |122326/173481[45:00<17:16,49.37it/s] 71%|#######   |122846/173481[45:11<17:05,49.37it/s] 75%|#######5  |130500/173481[48:00<15:08,47.30it/s] 76%|#######5  |131019/173481[48:12<14:57,47.30it/s] 80%|#######9  |138723/173481[51:00<12:27,46.48it/s] 80%|########  |139257/173481[51:12<12:16,46.48it/s] 85%|########4 |146720/173481[54:00<09:49,45.43it/s] 85%|########4 |147245/173481[54:12<09:37,45.43it/s] 89%|########9 |154541/173481[57:00<07:06,44.41it/s] 89%|########9 |155105/173481[57:12<06:53,44.41it/s] 94%|#########3|162975/173481[1:00:00<03:50,45.59it/s] 94%|#########4|163549/173481[1:00:12<03:37,45.59it/s] 99%|#########8|171341/173481[1:03:00<00:46,46.03it/s] 99%|#########9|171917/173481[1:03:12<00:33,46.03it/s]100%|##########|173481/173481[1:03:46<00:00,45.34it/s]
[32m[0329 08:38:30 @base.py:257][0m Epoch 22 (global_step 13878480) finished, time:3826.49 sec.
[32m[0329 08:38:30 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-13878480.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:47<00:00,112.23it/s]
21
[32m[0329 08:41:18 @monitor.py:363][0m QueueInput/queue_size: 0.79128
[32m[0329 08:41:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.969
[32m[0329 08:41:18 @monitor.py:363][0m activation-summaries/output-rms: 0.041179
[32m[0329 08:41:18 @monitor.py:363][0m cross_entropy_loss: 1.5919
[32m[0329 08:41:18 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 08:41:18 @monitor.py:363][0m train-error-top1: 0.43151
[32m[0329 08:41:18 @monitor.py:363][0m val-error-top1: 0.43234
[32m[0329 08:41:18 @monitor.py:363][0m val-utt-error: 0.099033
[32m[0329 08:41:18 @monitor.py:363][0m validation_cost: 1.6189
[32m[0329 08:41:18 @monitor.py:363][0m wd_cost: 1.2512e-19
[32m[0329 08:41:18 @group.py:42][0m Callbacks took 168.050 sec in total. InferenceRunner: 167.719sec
[32m[0329 08:41:18 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8845/173481[03:00<55:50,49.14it/s]  5%|5         |9338/173481[03:10<55:40,49.14it/s] 10%|#         |17406/173481[06:00<53:48,48.34it/s] 10%|#         |17890/173481[06:10<53:38,48.34it/s] 15%|#4        |25889/173481[09:00<51:32,47.72it/s] 15%|#5        |26368/173481[09:10<51:22,47.72it/s] 20%|#9        |34014/173481[12:00<50:06,46.38it/s] 20%|#9        |34483/173481[12:10<49:56,46.38it/s] 24%|##4       |42114/173481[15:00<47:55,45.68it/s] 25%|##4       |42588/173481[15:10<47:45,45.68it/s] 29%|##8       |49859/173481[18:00<46:30,44.30it/s] 29%|##9       |50316/173481[18:10<46:20,44.30it/s] 33%|###3      |57550/173481[21:00<44:25,43.50it/s] 33%|###3      |58004/173481[21:10<44:14,43.50it/s] 38%|###7      |65514/173481[24:00<41:01,43.86it/s] 38%|###8      |66002/173481[24:11<40:50,43.86it/s] 42%|####2     |73410/173481[27:00<38:01,43.87it/s] 43%|####2     |73888/173481[27:11<37:50,43.87it/s] 47%|####6     |81384/173481[30:00<34:49,44.08it/s] 47%|####7     |81853/173481[30:11<34:38,44.08it/s] 51%|#####1    |89196/173481[33:00<32:07,43.74it/s] 52%|#####1    |89653/173481[33:11<31:56,43.74it/s] 57%|#####6    |98730/173481[36:00<26:00,47.91it/s] 57%|#####7    |99371/173481[36:11<25:46,47.91it/s] 62%|######2   |108208/173481[39:00<21:41,50.17it/s] 63%|######2   |108725/173481[39:11<21:30,50.17it/s] 67%|######7   |116444/173481[42:00<19:51,47.86it/s] 67%|######7   |116968/173481[42:11<19:40,47.86it/s] 72%|#######1  |124524/173481[45:00<17:36,46.32it/s] 72%|#######2  |125018/173481[45:11<17:26,46.32it/s] 76%|#######6  |132389/173481[48:00<15:13,44.96it/s] 77%|#######6  |132888/173481[48:12<15:02,44.96it/s] 81%|########  |140394/173481[51:00<12:20,44.71it/s] 81%|########1 |140903/173481[51:12<12:08,44.71it/s] 86%|########5 |148394/173481[54:00<09:22,44.57it/s] 86%|########5 |148928/173481[54:12<09:10,44.57it/s] 90%|######### |156404/173481[57:00<06:23,44.53it/s] 90%|######### |156915/173481[57:12<06:12,44.53it/s] 95%|#########4|164319/173481[1:00:00<03:27,44.24it/s] 95%|#########5|164848/173481[1:00:12<03:15,44.24it/s] 99%|#########9|172189/173481[1:03:00<00:29,43.98it/s]100%|#########9|172704/173481[1:03:12<00:17,43.98it/s]100%|##########|173481/173481[1:03:31<00:00,45.51it/s]
[32m[0329 09:44:50 @base.py:257][0m Epoch 23 (global_step 14051961) finished, time:3811.83 sec.
[32m[0329 09:44:50 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-14051961.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:47<00:00,112.35it/s]
22
[32m[0329 09:47:38 @monitor.py:363][0m QueueInput/queue_size: 0.74243
[32m[0329 09:47:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.808
[32m[0329 09:47:38 @monitor.py:363][0m activation-summaries/output-rms: 0.040718
[32m[0329 09:47:38 @monitor.py:363][0m cross_entropy_loss: 1.5815
[32m[0329 09:47:38 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 09:47:38 @monitor.py:363][0m train-error-top1: 0.42934
[32m[0329 09:47:38 @monitor.py:363][0m val-error-top1: 0.43266
[32m[0329 09:47:38 @monitor.py:363][0m val-utt-error: 0.099777
[32m[0329 09:47:38 @monitor.py:363][0m validation_cost: 1.6203
[32m[0329 09:47:38 @monitor.py:363][0m wd_cost: 2.5025e-20
[32m[0329 09:47:38 @group.py:42][0m Callbacks took 167.758 sec in total. InferenceRunner: 167.545sec
[32m[0329 09:47:38 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8759/173481[03:00<56:25,48.66it/s]  5%|5         |9226/173481[03:10<56:15,48.66it/s] 10%|9         |16654/173481[06:00<56:39,46.14it/s] 10%|9         |17105/173481[06:10<56:29,46.14it/s] 14%|#4        |24550/173481[09:00<55:11,44.97it/s] 14%|#4        |25002/173481[09:10<55:01,44.97it/s] 19%|#8        |32518/173481[12:00<52:39,44.61it/s] 19%|#9        |32987/173481[12:10<52:29,44.61it/s] 23%|##3       |40503/173481[15:00<49:49,44.48it/s] 24%|##3       |40992/173481[15:10<49:38,44.48it/s] 28%|##7       |48205/173481[18:00<47:52,43.62it/s] 28%|##8       |48662/173481[18:10<47:41,43.62it/s] 32%|###2      |55673/173481[21:00<46:10,42.53it/s] 32%|###2      |56112/173481[21:10<45:59,42.53it/s] 37%|###6      |63440/173481[24:00<42:48,42.84it/s] 37%|###6      |63962/173481[24:11<42:36,42.84it/s] 42%|####1     |71996/173481[27:00<37:32,45.06it/s] 42%|####1     |72532/173481[27:11<37:20,45.06it/s] 46%|####6     |80343/173481[30:00<33:57,45.70it/s] 47%|####6     |80852/173481[30:11<33:46,45.70it/s] 52%|#####2    |90719/173481[33:00<27:03,50.98it/s] 53%|#####2    |91405/173481[33:11<26:49,50.98it/s] 57%|#####7    |99609/173481[36:00<24:32,50.17it/s] 58%|#####7    |100092/173481[36:11<24:22,50.17it/s] 62%|######1   |107153/173481[39:00<24:12,45.67it/s] 62%|######2   |107645/173481[39:11<24:01,45.67it/s] 66%|######6   |114741/173481[42:00<22:19,43.84it/s] 66%|######6   |115237/173481[42:11<22:08,43.84it/s] 71%|#######   |122342/173481[45:00<19:48,43.02it/s] 71%|#######   |122832/173481[45:11<19:37,43.02it/s] 75%|#######4  |129923/173481[48:00<17:03,42.56it/s] 75%|#######5  |130423/173481[48:12<16:51,42.56it/s] 79%|#######9  |137548/173481[51:00<14:06,42.46it/s] 80%|#######9  |138072/173481[51:12<13:53,42.46it/s] 84%|########3 |145120/173481[54:00<11:11,42.26it/s] 84%|########3 |145632/173481[54:12<10:58,42.26it/s] 88%|########8 |152753/173481[57:00<08:09,42.33it/s] 88%|########8 |153262/173481[57:12<07:57,42.33it/s] 92%|#########2|160348/173481[1:00:00<05:10,42.26it/s] 93%|#########2|160852/173481[1:00:12<04:58,42.26it/s] 97%|#########6|167783/173481[1:03:00<02:16,41.77it/s] 97%|#########7|168277/173481[1:03:12<02:04,41.77it/s]100%|##########|173481/173481[1:05:20<00:00,44.25it/s]
[32m[0329 10:52:58 @base.py:257][0m Epoch 24 (global_step 14225442) finished, time:3920.39 sec.
[32m[0329 10:52:58 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-14225442.
  0%|          |0/18822[00:00<?,?it/s] 90%|########9 |16935/18822[03:00<00:20,94.08it/s] 95%|#########5|17948/18822[03:10<00:09,94.08it/s]100%|##########|18822/18822[03:18<00:00,94.72it/s]
23
[32m[0329 10:56:17 @monitor.py:363][0m QueueInput/queue_size: 0.77548
[32m[0329 10:56:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.76
[32m[0329 10:56:17 @monitor.py:363][0m activation-summaries/output-rms: 0.040878
[32m[0329 10:56:17 @monitor.py:363][0m cross_entropy_loss: 1.5884
[32m[0329 10:56:17 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 10:56:17 @monitor.py:363][0m train-error-top1: 0.42817
[32m[0329 10:56:17 @monitor.py:363][0m val-error-top1: 0.43206
[32m[0329 10:56:17 @monitor.py:363][0m val-utt-error: 0.099883
[32m[0329 10:56:17 @monitor.py:363][0m validation_cost: 1.6196
[32m[0329 10:56:17 @monitor.py:363][0m wd_cost: 2.5025e-20
[32m[0329 10:56:17 @group.py:42][0m Callbacks took 198.977 sec in total. InferenceRunner: 198.731sec
[32m[0329 10:56:17 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7747/173481[03:00<1:04:11,43.03it/s]  5%|4         |8166/173481[03:10<1:04:01,43.03it/s]  9%|8         |15057/173481[06:00<1:03:11,41.78it/s]  9%|8         |15466/173481[06:10<1:03:02,41.78it/s] 13%|#2        |22352/173481[09:00<1:01:13,41.14it/s] 13%|#3        |22740/173481[09:10<1:01:03,41.14it/s] 17%|#7        |29842/173481[12:00<57:51,41.37it/s]   17%|#7        |30293/173481[12:10<57:40,41.37it/s] 22%|##1       |37482/173481[15:00<54:06,41.90it/s] 22%|##1       |37916/173481[15:10<53:55,41.90it/s] 27%|##7       |47292/173481[18:00<44:23,47.37it/s] 28%|##7       |47971/173481[18:10<44:09,47.37it/s] 33%|###3      |57752/173481[21:00<36:57,52.19it/s] 34%|###3      |58261/173481[21:10<36:47,52.19it/s] 38%|###8      |66267/173481[24:00<36:00,49.62it/s] 38%|###8      |66773/173481[24:11<35:50,49.62it/s] 43%|####2     |74532/173481[27:00<34:34,47.69it/s] 43%|####3     |75011/173481[27:11<34:24,47.69it/s] 48%|####7     |82712/173481[30:00<32:30,46.54it/s] 48%|####7     |83221/173481[30:11<32:19,46.54it/s] 52%|#####2    |90907/173481[33:00<29:54,46.02it/s] 53%|#####2    |91376/173481[33:11<29:43,46.02it/s] 57%|#####7    |98998/173481[36:00<27:17,45.48it/s] 57%|#####7    |99518/173481[36:11<27:06,45.48it/s] 62%|######1   |107122/173481[39:00<24:24,45.30it/s] 62%|######2   |107656/173481[39:11<24:13,45.30it/s] 66%|######6   |115207/173481[42:00<21:32,45.07it/s] 67%|######6   |115696/173481[42:11<21:22,45.07it/s] 71%|#######1  |123292/173481[45:00<18:35,44.99it/s] 71%|#######1  |123811/173481[45:12<18:24,44.99it/s] 76%|#######5  |131421/173481[48:00<15:33,45.07it/s] 76%|#######6  |131941/173481[48:12<15:21,45.07it/s] 80%|########  |139517/173481[51:00<12:34,45.02it/s] 81%|########  |140026/173481[51:12<12:23,45.02it/s] 85%|########5 |147722/173481[54:00<09:28,45.29it/s] 85%|########5 |148246/173481[54:12<09:17,45.29it/s] 90%|########9 |155832/173481[57:00<06:30,45.17it/s] 90%|######### |156381/173481[57:12<06:18,45.17it/s] 95%|#########4|164017/173481[1:00:00<03:28,45.32it/s] 95%|#########4|164566/173481[1:00:12<03:16,45.32it/s] 99%|#########9|172307/173481[1:03:00<00:25,45.68it/s]100%|#########9|172839/173481[1:03:12<00:14,45.68it/s]100%|##########|173481/173481[1:03:27<00:00,45.56it/s]
[32m[0329 11:59:45 @base.py:257][0m Epoch 25 (global_step 14398923) finished, time:3807.88 sec.
[32m[0329 11:59:45 @saver.py:84][0m Model saved to train_log/lcn_w_32_a_32_quant_ends_True_preload/model-14398923.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:50<00:00,110.28it/s]
24
[32m[0329 12:02:36 @monitor.py:363][0m QueueInput/queue_size: 0.76204
[32m[0329 12:02:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.828
[32m[0329 12:02:36 @monitor.py:363][0m activation-summaries/output-rms: 0.042383
[32m[0329 12:02:36 @monitor.py:363][0m cross_entropy_loss: 1.5828
[32m[0329 12:02:36 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48233
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1082e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35163
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.554e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45708
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.5491e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34408
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2445e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46828
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 9.8053e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34655
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6343e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46217
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6678e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.958e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4983
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 8.0519e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34788
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.7421e-06
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58226
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2957
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33904
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089448
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31707
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.087089
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30822
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.089052
[32m[0329 12:02:36 @monitor.py:363][0m train-error-top1: 0.42347
[32m[0329 12:02:36 @monitor.py:363][0m val-error-top1: 0.4331
[32m[0329 12:02:36 @monitor.py:363][0m val-utt-error: 0.10026
[32m[0329 12:02:36 @monitor.py:363][0m validation_cost: 1.6233
[32m[0329 12:02:36 @monitor.py:363][0m wd_cost: 2.5025e-20
[32m[0329 12:02:36 @group.py:42][0m Callbacks took 171.053 sec in total. InferenceRunner: 170.682sec
[32m[0329 12:02:36 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8681/173481[03:00<56:57,48.23it/s]  5%|5         |9150/173481[03:10<56:47,48.23it/s] 10%|9         |16961/173481[06:00<55:24,47.09it/s] 10%|#         |17440/173481[06:10<55:13,47.09it/s] 15%|#4        |25186/173481[09:00<53:17,46.38it/s] 15%|#4        |25655/173481[09:10<53:07,46.38it/s] 19%|#9        |33376/173481[12:00<50:50,45.93it/s] 19%|#9        |33819/173481[12:10<50:40,45.93it/s] 24%|##3       |41604/173481[15:00<47:58,45.82it/s] 24%|##4       |42245/173481[15:10<47:44,45.82it/s] 30%|###       |52282/173481[18:00<39:04,51.70it/s] 31%|###       |52925/173481[18:10<38:51,51.70it/s] 35%|###5      |60776/173481[21:00<38:04,49.34it/s] 35%|###5      |61270/173481[21:10<37:54,49.34it/s] 40%|###9      |68866/173481[24:00<37:04,47.03it/s] 40%|###9      |69340/173481[24:11<36:54,47.03it/s] 44%|####4     |76726/173481[27:00<35:36,45.28it/s] 45%|####4     |77225/173481[27:11<35:25,45.28it/s] 49%|####8     |84606/173481[30:00<33:16,44.51it/s] 49%|####9     |85087/173481[30:11<33:05,44.51it/s] 53%|#####3    |92601/173481[33:00<30:19,44.46it/s] 54%|#####3    |93110/173481[33:11<30:07,44.46it/s] 58%|#####8    |100701/173481[36:00<27:07,44.73it/s] 58%|#####8    |101205/173481[36:11<26:55,44.73it/s]slurmstepd: *** JOB 85134 ON sls-sm-3 CANCELLED AT 2018-03-29T12:39:03 ***
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 85134.0 ON sls-sm-3 CANCELLED AT 2018-03-29T12:39:03 ***
