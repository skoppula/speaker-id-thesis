sls-tesla-0 0
SLURM_JOBID=82582
SLURM_TASKID=1
[32m[0323 10:45:59 @logger.py:67][0m Existing log file 'train_log/lcn_w_2_a_32_quant_ends_False/log.log' backuped to 'train_log/lcn_w_2_a_32_quant_ends_False/log.log.0323-104559'
[32m[0323 10:45:59 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=2 --bita=32 --quant_ends=False
[32m[0323 10:46:18 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 10:46:18 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 10:46:18 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 10:46:18 @drf_run.py:166][0m Using host: sls-tesla-0
[32m[0323 10:46:18 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 10:46:18 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 10:46:18 @drf_run.py:188][0m Using GPU: 0
[32m[0323 10:46:18 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 10:46:18 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 10:46:18 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 10:46:18 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:19 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:19 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 10:46:19 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:19 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0323 10:46:19 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 10:46:19 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0323 10:46:21 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0323 10:46:21 @base.py:196][0m Setup callbacks graph ...
[32m[0323 10:46:22 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:22 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:22 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:22 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:22 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:22 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:22 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:22 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:22 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:22 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0323 10:46:22 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 10:46:22 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0323 10:46:23 @base.py:212][0m Creating the session ...
2018-03-23 10:46:24.381826: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2
2018-03-23 10:46:26.078533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-03-23 10:46:26.079088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN Black major: 3 minor: 5 memoryClockRate(GHz): 0.98
pciBusID: 0000:06:00.0
totalMemory: 5.94GiB freeMemory: 5.86GiB
2018-03-23 10:46:26.079126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:06:00.0, compute capability: 3.5)
[32m[0323 10:46:31 @base.py:220][0m Initializing the session ...
[32m[0323 10:46:31 @base.py:227][0m Graph Finalized.
[32m[0323 10:46:31 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 10:46:34 @monitor.py:251][0m Found existing JSON at train_log/lcn_w_2_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 10:46:34 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 10:46:34 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8827/173481[03:00<55:57,49.04it/s]  5%|5         |9341/173481[03:10<55:47,49.04it/s] 10%|#         |17954/173481[06:00<51:59,49.86it/s] 11%|#         |18482/173481[06:10<51:48,49.86it/s] 16%|#5        |27105/173481[09:00<48:27,50.34it/s] 16%|#5        |27634/173481[09:10<48:17,50.34it/s] 21%|##        |36333/173481[12:00<44:59,50.80it/s] 21%|##1       |36880/173481[12:10<44:49,50.80it/s] 26%|##6       |45601/173481[15:00<41:40,51.14it/s] 27%|##6       |46155/173481[15:10<41:29,51.14it/s] 32%|###1      |54821/173481[18:00<38:38,51.18it/s] 32%|###1      |55381/173481[18:11<38:27,51.18it/s] 37%|###6      |64051/173481[21:00<35:36,51.23it/s] 37%|###7      |64622/173481[21:11<35:25,51.23it/s] 42%|####2     |73275/173481[24:00<32:35,51.24it/s] 43%|####2     |73851/173481[24:11<32:24,51.24it/s] 47%|####7     |82388/173481[27:00<29:48,50.93it/s] 48%|####7     |82961/173481[27:11<29:37,50.93it/s] 53%|#####2    |91341/173481[30:00<27:12,50.33it/s] 53%|#####2    |91895/173481[30:11<27:01,50.33it/s] 58%|#####7    |100287/173481[33:00<24:23,50.01it/s] 58%|#####8    |100857/173481[33:11<24:12,50.01it/s] 63%|######2   |109219/173481[36:00<21:30,49.81it/s] 63%|######3   |109819/173481[36:12<21:17,49.81it/s] 68%|######8   |118263/173481[39:00<18:23,50.03it/s] 69%|######8   |118868/173481[39:12<18:11,50.03it/s] 73%|#######3  |127313/173481[42:00<15:20,50.15it/s] 74%|#######3  |127933/173481[42:12<15:08,50.15it/s] 79%|#######8  |136338/173481[45:00<12:20,50.14it/s] 79%|#######8  |136969/173481[45:12<12:08,50.14it/s] 84%|########3 |145369/173481[48:00<09:20,50.15it/s] 84%|########4 |145988/173481[48:12<09:08,50.15it/s] 89%|########8 |154374/173481[51:00<06:21,50.09it/s] 89%|########9 |155012/173481[51:12<06:08,50.09it/s] 94%|#########4|163365/173481[54:00<03:22,50.02it/s] 95%|#########4|163999/173481[54:13<03:09,50.02it/s] 99%|#########9|172345/173481[57:00<00:22,49.95it/s]100%|#########9|172990/173481[57:13<00:09,49.95it/s]100%|##########|173481/173481[57:23<00:00,50.37it/s]
[32m[0323 11:43:58 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:3443.98 sec.
[32m[0323 11:43:59 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s] 86%|########6 |16258/18822[03:00<00:28,90.32it/s] 91%|#########1|17198/18822[03:10<00:17,90.32it/s]100%|##########|18822/18822[03:28<00:00,90.48it/s]
0
[32m[0323 11:47:27 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 11:47:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8201
[32m[0323 11:47:27 @monitor.py:363][0m activation-summaries/output-rms: 0.025275
[32m[0323 11:47:27 @monitor.py:363][0m cross_entropy_loss: 2.9133
[32m[0323 11:47:27 @monitor.py:363][0m lr: 0.001
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.19716
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 4.0813e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.14746
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 2.1666e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.18357
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 4.1745e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.14398
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 2.2254e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.18704
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 3.0909e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14272
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 2.9349e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.18204
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 3.2276e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14388
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 2.6767e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.19745
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 3.2167e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.14692
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 2.2942e-06
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13078
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.71188
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.15621
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12143
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092939
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11904
[32m[0323 11:47:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087593
[32m[0323 11:47:27 @monitor.py:363][0m train-error-top1: 0.70192
[32m[0323 11:47:27 @monitor.py:363][0m val-error-top1: 0.76963
[32m[0323 11:47:27 @monitor.py:363][0m val-utt-error: 0.51567
[32m[0323 11:47:27 @monitor.py:363][0m validation_cost: 3.2985
[32m[0323 11:47:27 @monitor.py:363][0m wd_cost: 0.52852
[32m[0323 11:47:27 @group.py:42][0m Callbacks took 208.454 sec in total. InferenceRunner: 208.078sec
[32m[0323 11:47:27 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8994/173481[03:00<54:52,49.96it/s]  5%|5         |9504/173481[03:10<54:41,49.96it/s] 10%|#         |17953/173481[06:00<51:58,49.87it/s] 11%|#         |18465/173481[06:10<51:48,49.87it/s] 16%|#5        |26976/173481[09:00<48:50,49.99it/s] 16%|#5        |27495/173481[09:10<48:40,49.99it/s] 21%|##        |36101/173481[12:00<45:29,50.34it/s] 21%|##1       |36637/173481[12:10<45:18,50.34it/s] 26%|##6       |45238/173481[15:00<42:17,50.55it/s] 26%|##6       |45782/173481[15:10<42:06,50.55it/s] 31%|###1      |54340/173481[18:00<39:16,50.56it/s] 32%|###1      |54888/173481[18:10<39:05,50.56it/s] 37%|###6      |63525/173481[21:00<36:04,50.79it/s] 37%|###6      |64102/173481[21:11<35:53,50.79it/s] 42%|####1     |72815/173481[24:00<32:46,51.20it/s] 42%|####2     |73389/173481[24:11<32:35,51.20it/s] 47%|####7     |82008/173481[27:00<29:48,51.13it/s] 48%|####7     |82584/173481[27:11<29:37,51.13it/s] 53%|#####2    |91206/173481[30:00<26:49,51.12it/s] 53%|#####2    |91796/173481[30:11<26:38,51.12it/s] 58%|#####7    |100417/173481[33:00<23:48,51.14it/s] 58%|#####8    |101021/173481[33:11<23:36,51.14it/s] 63%|######3   |109697/173481[36:00<20:42,51.35it/s] 64%|######3   |110309/173481[36:11<20:30,51.35it/s] 69%|######8   |118995/173481[39:00<17:37,51.50it/s] 69%|######8   |119609/173481[39:12<17:26,51.50it/s] 74%|#######3  |128223/173481[42:00<14:40,51.38it/s] 74%|#######4  |128853/173481[42:12<14:28,51.38it/s] 79%|#######9  |137476/173481[45:00<11:40,51.39it/s] 80%|#######9  |138111/173481[45:12<11:28,51.39it/s] 85%|########4 |146756/173481[48:00<08:39,51.47it/s] 85%|########4 |147400/173481[48:12<08:26,51.47it/s] 90%|########9 |156047/173481[51:00<05:38,51.54it/s] 90%|######### |156696/173481[51:12<05:25,51.54it/s] 95%|#########5|165301/173481[54:00<02:38,51.48it/s] 96%|#########5|165958/173481[54:12<02:26,51.48it/s]100%|##########|173481/173481[56:38<00:00,51.05it/s]
[32m[0323 12:44:05 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:3398.15 sec.
[32m[0323 12:44:05 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-346962.
[32m[0323 12:44:06 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 86%|########5 |16100/18822[03:00<00:30,89.44it/s] 90%|######### |17026/18822[03:10<00:20,89.44it/s]100%|##########|18822/18822[03:30<00:00,89.51it/s]
1
[32m[0323 12:47:37 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 12:47:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9404
[32m[0323 12:47:37 @monitor.py:363][0m activation-summaries/output-rms: 0.025716
[32m[0323 12:47:37 @monitor.py:363][0m cross_entropy_loss: 2.8975
[32m[0323 12:47:37 @monitor.py:363][0m lr: 0.001
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.19629
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.0303e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.14821
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 2.5516e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.18331
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.4029e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.14491
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 3.9886e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.18626
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.4561e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14235
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.0547e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.18163
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.095e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14443
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.6275e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.19832
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.3826e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.14721
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 2.5043e-06
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13231
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.91589
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.15654
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12165
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092939
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.12163
[32m[0323 12:47:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087593
[32m[0323 12:47:37 @monitor.py:363][0m train-error-top1: 0.70079
[32m[0323 12:47:37 @monitor.py:363][0m val-error-top1: 0.76845
[32m[0323 12:47:37 @monitor.py:363][0m val-utt-error: 0.5153
[32m[0323 12:47:37 @monitor.py:363][0m validation_cost: 3.2984
[32m[0323 12:47:37 @monitor.py:363][0m wd_cost: 0.53624
[32m[0323 12:47:37 @group.py:42][0m Callbacks took 211.497 sec in total. InferenceRunner: 210.303sec
[32m[0323 12:47:37 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9261/173481[03:00<53:12,51.45it/s]  6%|5         |9793/173481[03:10<53:01,51.45it/s] 11%|#         |18502/173481[06:00<50:15,51.39it/s] 11%|#         |19029/173481[06:10<50:05,51.39it/s] 16%|#5        |27724/173481[09:00<47:20,51.31it/s] 16%|#6        |28250/173481[09:10<47:10,51.31it/s] 21%|##1       |37008/173481[12:00<44:12,51.44it/s] 22%|##1       |37556/173481[12:10<44:02,51.44it/s] 27%|##6       |46151/173481[15:00<41:31,51.11it/s] 27%|##6       |46704/173481[15:10<41:20,51.11it/s] 32%|###1      |55381/173481[18:00<38:26,51.20it/s] 32%|###2      |55938/173481[18:10<38:15,51.20it/s] 37%|###7      |64630/173481[21:00<35:22,51.29it/s] 38%|###7      |65182/173481[21:11<35:11,51.29it/s] 43%|####2     |73844/173481[24:00<32:24,51.24it/s] 43%|####2     |74434/173481[24:11<32:13,51.24it/s] 48%|####7     |83079/173481[27:00<29:23,51.27it/s] 48%|####8     |83660/173481[27:11<29:11,51.27it/s] 53%|#####3    |92359/173481[30:00<26:17,51.41it/s] 54%|#####3    |92946/173481[30:11<26:06,51.41it/s] 59%|#####8    |101605/173481[33:00<23:18,51.39it/s] 59%|#####8    |102201/173481[33:11<23:07,51.39it/s] 64%|######3   |110831/173481[36:00<20:20,51.32it/s] 64%|######4   |111432/173481[36:11<20:09,51.32it/s] 69%|######9   |120116/173481[39:00<17:17,51.45it/s] 70%|######9   |120734/173481[39:12<17:05,51.45it/s] 75%|#######4  |129347/173481[42:00<14:19,51.37it/s] 75%|#######4  |129971/173481[42:12<14:07,51.37it/s] 80%|#######9  |138600/173481[45:00<11:18,51.38it/s] 80%|########  |139244/173481[45:12<11:06,51.38it/s] 85%|########5 |147847/173481[48:00<08:18,51.38it/s] 86%|########5 |148486/173481[48:12<08:06,51.38it/s] 91%|######### |157096/173481[51:00<05:18,51.38it/s] 91%|######### |157747/173481[51:12<05:06,51.38it/s] 96%|#########5|166369/173481[54:00<02:18,51.45it/s] 96%|#########6|167018/173481[54:12<02:05,51.45it/s]100%|##########|173481/173481[56:19<00:00,51.33it/s]
[32m[0323 13:43:56 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:3379.81 sec.
[32m[0323 13:43:57 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-520443.
[32m[0323 13:43:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 72%|#######1  |13478/18822[03:00<01:11,74.87it/s] 75%|#######5  |14185/18822[03:10<01:01,74.87it/s]100%|##########|18822/18822[04:12<00:00,74.58it/s]
2
[32m[0323 13:48:09 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 13:48:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.3941
[32m[0323 13:48:09 @monitor.py:363][0m activation-summaries/output-rms: 0.029109
[32m[0323 13:48:09 @monitor.py:363][0m cross_entropy_loss: 2.4977
[32m[0323 13:48:09 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.27483
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1227e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.19721
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 4.0421e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.26192
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 8.397e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.19454
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.285e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.2648
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.6501e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.19212
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 3.9375e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.25583
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.1748e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.19309
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.037e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.27508
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.5346e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.19448
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3539e-06
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.18467
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0044
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.25042
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19624
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092939
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2006
[32m[0323 13:48:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087593
[32m[0323 13:48:09 @monitor.py:363][0m train-error-top1: 0.6298
[32m[0323 13:48:09 @monitor.py:363][0m val-error-top1: 0.70432
[32m[0323 13:48:09 @monitor.py:363][0m val-utt-error: 0.38816
[32m[0323 13:48:09 @monitor.py:363][0m validation_cost: 2.9215
[32m[0323 13:48:09 @monitor.py:363][0m wd_cost: 0.25515
[32m[0323 13:48:09 @group.py:42][0m Callbacks took 252.540 sec in total. InferenceRunner: 252.373sec
[32m[0323 13:48:09 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9247/173481[03:00<53:17,51.37it/s]  6%|5         |9764/173481[03:10<53:07,51.37it/s] 11%|#         |18465/173481[06:00<50:22,51.29it/s] 11%|#         |18993/173481[06:10<50:12,51.29it/s] 16%|#6        |27825/173481[09:00<47:00,51.64it/s] 16%|#6        |28370/173481[09:10<46:50,51.64it/s] 21%|##1       |37268/173481[12:00<43:37,52.04it/s] 22%|##1       |37825/173481[12:10<43:26,52.04it/s] 27%|##6       |46712/173481[15:00<40:26,52.25it/s] 27%|##7       |47266/173481[15:10<40:15,52.25it/s] 32%|###2      |56092/173481[18:00<37:29,52.18it/s] 33%|###2      |56653/173481[18:10<37:18,52.18it/s] 38%|###7      |65493/173481[21:00<34:28,52.20it/s] 38%|###8      |66066/173481[21:11<34:17,52.20it/s] 43%|####3     |74901/173481[24:00<31:27,52.23it/s] 44%|####3     |75484/173481[24:11<31:16,52.23it/s] 49%|####8     |84264/173481[27:00<28:31,52.12it/s] 49%|####8     |84858/173481[27:11<28:20,52.12it/s] 54%|#####3    |93643/173481[30:00<25:32,52.11it/s] 54%|#####4    |94240/173481[30:11<25:20,52.11it/s] 59%|#####9    |103030/173481[33:00<22:31,52.13it/s] 60%|#####9    |103634/173481[33:11<22:19,52.13it/s] 65%|######4   |112430/173481[36:00<19:30,52.18it/s] 65%|######5   |113045/173481[36:11<19:18,52.18it/s] 70%|#######   |121821/173481[39:00<16:30,52.17it/s] 71%|#######   |122446/173481[39:12<16:18,52.17it/s] 76%|#######5  |131235/173481[42:00<13:28,52.23it/s] 76%|#######6  |131858/173481[42:12<13:16,52.23it/s] 81%|########1 |140522/173481[45:00<10:34,51.91it/s] 81%|########1 |141152/173481[45:12<10:22,51.91it/s] 86%|########6 |149881/173481[48:00<07:34,51.95it/s] 87%|########6 |150525/173481[48:12<07:21,51.95it/s] 92%|#########1|159231/173481[51:00<04:34,51.95it/s] 92%|#########2|159883/173481[51:12<04:21,51.95it/s] 97%|#########7|168586/173481[54:00<01:34,51.96it/s] 98%|#########7|169253/173481[54:12<01:21,51.96it/s]100%|##########|173481/173481[55:34<00:00,52.03it/s]
[32m[0323 14:43:43 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:3334.10 sec.
[32m[0323 14:43:43 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-693924.
[32m[0323 14:43:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 94%|#########3|17683/18822[03:00<00:11,98.24it/s] 99%|#########9|18651/18822[03:10<00:01,98.24it/s]100%|##########|18822/18822[03:11<00:00,98.10it/s]
3
[32m[0323 14:46:55 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 14:46:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.5313
[32m[0323 14:46:55 @monitor.py:363][0m activation-summaries/output-rms: 0.029909
[32m[0323 14:46:55 @monitor.py:363][0m cross_entropy_loss: 2.4975
[32m[0323 14:46:55 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.29582
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0a/b-rms: 8.8714e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.21587
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0b/b-rms: 4.6117e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.27938
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3249e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.21163
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5309e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.28253
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.043e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.20819
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.5342e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.2734
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4278e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.2098
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.314e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.29731
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.5279e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.21191
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.0145e-06
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.2134
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0692
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29556
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.22911
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092939
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.23306
[32m[0323 14:46:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087593
[32m[0323 14:46:55 @monitor.py:363][0m train-error-top1: 0.63002
[32m[0323 14:46:55 @monitor.py:363][0m val-error-top1: 0.67762
[32m[0323 14:46:55 @monitor.py:363][0m val-utt-error: 0.35049
[32m[0323 14:46:55 @monitor.py:363][0m validation_cost: 2.7756
[32m[0323 14:46:55 @monitor.py:363][0m wd_cost: 0.34287
[32m[0323 14:46:55 @group.py:42][0m Callbacks took 192.153 sec in total. InferenceRunner: 191.889sec
[32m[0323 14:46:55 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9275/173481[03:00<53:06,51.53it/s]  6%|5         |9801/173481[03:10<52:56,51.53it/s] 11%|#         |18393/173481[06:00<50:35,51.09it/s] 11%|#         |18910/173481[06:10<50:25,51.09it/s] 16%|#5        |27590/173481[09:00<47:35,51.09it/s] 16%|#6        |28136/173481[09:10<47:24,51.09it/s] 21%|##1       |36975/173481[12:00<44:05,51.61it/s] 22%|##1       |37523/173481[12:10<43:54,51.61it/s] 27%|##6       |46334/173481[15:00<40:54,51.80it/s] 27%|##7       |46876/173481[15:10<40:44,51.80it/s] 32%|###2      |55671/173481[18:00<37:52,51.83it/s] 32%|###2      |56240/173481[18:10<37:41,51.83it/s] 37%|###7      |65024/173481[21:00<34:49,51.90it/s] 38%|###7      |65595/173481[21:11<34:38,51.90it/s] 43%|####2     |74376/173481[24:00<31:48,51.92it/s] 43%|####3     |74958/173481[24:11<31:37,51.92it/s] 48%|####8     |83756/173481[27:00<28:44,52.02it/s] 49%|####8     |84350/173481[27:11<28:33,52.02it/s] 54%|#####3    |93116/173481[30:00<25:45,52.01it/s] 54%|#####4    |93714/173481[30:11<25:33,52.01it/s] 59%|#####9    |102506/173481[33:00<22:42,52.09it/s] 59%|#####9    |103097/173481[33:11<22:31,52.09it/s] 64%|######4   |111869/173481[36:00<19:43,52.05it/s] 65%|######4   |112482/173481[36:11<19:31,52.05it/s] 70%|######9   |121308/173481[39:00<16:38,52.24it/s] 70%|#######   |121929/173481[39:12<16:26,52.24it/s] 75%|#######5  |130723/173481[42:00<13:37,52.27it/s] 76%|#######5  |131350/173481[42:12<13:25,52.27it/s] 81%|########  |140130/173481[45:00<10:38,52.27it/s] 81%|########1 |140760/173481[45:12<10:26,52.27it/s] 86%|########6 |149571/173481[48:00<07:36,52.36it/s] 87%|########6 |150222/173481[48:12<07:24,52.36it/s] 92%|#########1|159025/173481[51:00<04:35,52.44it/s] 92%|#########2|159682/173481[51:12<04:23,52.44it/s] 97%|#########7|168495/173481[54:00<01:34,52.52it/s] 98%|#########7|169165/173481[54:12<01:22,52.52it/s]100%|##########|173481/173481[55:34<00:00,52.03it/s]
[32m[0323 15:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:3334.56 sec.
[32m[0323 15:42:30 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-867405.
[32m[0323 15:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 91%|#########1|17140/18822[03:00<00:17,95.22it/s] 97%|#########6|18181/18822[03:10<00:06,95.22it/s]100%|##########|18822/18822[03:16<00:00,95.83it/s]
4
[32m[0323 15:45:48 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 15:45:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.7364
[32m[0323 15:45:48 @monitor.py:363][0m activation-summaries/output-rms: 0.035233
[32m[0323 15:45:48 @monitor.py:363][0m cross_entropy_loss: 2.0465
[32m[0323 15:45:48 @monitor.py:363][0m lr: 0.0005
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.23238
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.5645e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.17143
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 4.7045e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.22074
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3886e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.16813
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.8161e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.22222
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6332e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.16634
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.0525e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.21651
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.2162e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.166
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.8092e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.23342
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.6577e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.16865
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.8253e-06
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.17575
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1539
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27819
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21207
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092939
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.21311
[32m[0323 15:45:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087593
[32m[0323 15:45:48 @monitor.py:363][0m train-error-top1: 0.5277
[32m[0323 15:45:48 @monitor.py:363][0m val-error-top1: 0.67118
[32m[0323 15:45:48 @monitor.py:363][0m val-utt-error: 0.32988
[32m[0323 15:45:48 @monitor.py:363][0m validation_cost: 2.8036
[32m[0323 15:45:48 @monitor.py:363][0m wd_cost: 0.2776
[32m[0323 15:45:48 @group.py:42][0m Callbacks took 197.917 sec in total. InferenceRunner: 196.431sec
[32m[0323 15:45:48 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9445/173481[03:00<52:06,52.47it/s]  6%|5         |9977/173481[03:10<51:56,52.47it/s] 11%|#         |18856/173481[06:00<49:12,52.37it/s] 11%|#1        |19387/173481[06:10<49:02,52.37it/s] 16%|#6        |28254/173481[09:00<46:17,52.29it/s] 17%|#6        |28799/173481[09:10<46:06,52.29it/s] 22%|##1       |37654/173481[12:00<43:19,52.25it/s] 22%|##2       |38212/173481[12:10<43:08,52.25it/s] 27%|##7       |47081/173481[15:00<40:16,52.31it/s] 27%|##7       |47633/173481[15:10<40:05,52.31it/s] 33%|###2      |56399/173481[18:00<37:29,52.04it/s] 33%|###2      |56961/173481[18:10<37:19,52.04it/s] 38%|###7      |65795/173481[21:00<34:26,52.12it/s] 38%|###8      |66362/173481[21:11<34:15,52.12it/s] 43%|####3     |75133/173481[24:00<31:31,52.00it/s] 44%|####3     |75696/173481[24:11<31:20,52.00it/s] 49%|####8     |84315/173481[27:00<28:51,51.50it/s] 49%|####8     |84906/173481[27:11<28:39,51.50it/s] 54%|#####3    |93640/173481[30:00<25:45,51.65it/s] 54%|#####4    |94236/173481[30:11<25:34,51.65it/s] 59%|#####9    |102941/173481[33:00<22:45,51.66it/s] 60%|#####9    |103546/173481[33:11<22:33,51.66it/s] 65%|######4   |112237/173481[36:00<19:45,51.65it/s] 65%|######5   |112847/173481[36:11<19:33,51.65it/s] 70%|#######   |121526/173481[39:00<16:46,51.63it/s] 70%|#######   |122144/173481[39:12<16:34,51.63it/s] 75%|#######5  |130845/173481[42:00<13:44,51.70it/s] 76%|#######5  |131465/173481[42:12<13:32,51.70it/s] 81%|########  |140141/173481[45:00<10:45,51.67it/s] 81%|########1 |140772/173481[45:12<10:33,51.67it/s] 86%|########6 |149460/173481[48:00<07:44,51.72it/s] 87%|########6 |150099/173481[48:12<07:32,51.72it/s] 92%|#########1|158766/173481[51:00<04:44,51.71it/s] 92%|#########1|159415/173481[51:12<04:32,51.71it/s] 97%|#########6|168079/173481[54:00<01:44,51.72it/s] 97%|#########7|168730/173481[54:12<01:31,51.72it/s]100%|##########|173481/173481[55:44<00:00,51.86it/s]
[32m[0323 16:41:33 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:3344.98 sec.
[32m[0323 16:41:33 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-1040886.
[32m[0323 16:41:33 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 80%|########  |15092/18822[03:00<00:44,83.84it/s] 90%|########9 |16897/18822[03:19<00:22,83.84it/s]100%|##########|18822/18822[03:40<00:00,85.45it/s]
5
[32m[0323 16:45:13 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 16:45:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.096
[32m[0323 16:45:13 @monitor.py:363][0m activation-summaries/output-rms: 0.036111
[32m[0323 16:45:13 @monitor.py:363][0m cross_entropy_loss: 2.0209
[32m[0323 16:45:13 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.26103
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2426e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.18483
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.0779e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.24916
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0c/b-rms: 8.8825e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.18118
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.0017e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.2504
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8852e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.18
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9297e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.24513
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.2246e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.18056
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.4663e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.26522
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0i/b-rms: 7.018e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.18348
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6069e-06
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.19505
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1901
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3636
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27538
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092939
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28026
[32m[0323 16:45:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0323 16:45:13 @monitor.py:363][0m train-error-top1: 0.51812
[32m[0323 16:45:13 @monitor.py:363][0m val-error-top1: 0.65211
[32m[0323 16:45:13 @monitor.py:363][0m val-utt-error: 0.29784
[32m[0323 16:45:13 @monitor.py:363][0m validation_cost: 2.7009
[32m[0323 16:45:13 @monitor.py:363][0m wd_cost: 0.08913
[32m[0323 16:45:13 @group.py:42][0m Callbacks took 220.501 sec in total. InferenceRunner: 220.273sec
[32m[0323 16:45:13 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9439/173481[03:00<52:08,52.43it/s]  6%|5         |9963/173481[03:10<51:58,52.43it/s] 11%|#         |18815/173481[06:00<49:19,52.26it/s] 11%|#1        |19351/173481[06:10<49:09,52.26it/s] 16%|#6        |28146/173481[09:00<46:32,52.05it/s] 17%|#6        |28676/173481[09:10<46:22,52.05it/s] 22%|##1       |37419/173481[12:00<43:47,51.78it/s] 22%|##1       |37950/173481[12:10<43:37,51.78it/s] 27%|##6       |46436/173481[15:00<41:34,50.92it/s] 27%|##7       |46979/173481[15:10<41:24,50.92it/s] 32%|###2      |55558/173481[18:00<38:41,50.80it/s] 32%|###2      |56124/173481[18:10<38:30,50.80it/s] 37%|###7      |64942/173481[21:00<35:09,51.46it/s] 38%|###7      |65511/173481[21:11<34:58,51.46it/s] 43%|####2     |74305/173481[24:00<31:57,51.73it/s] 43%|####3     |74884/173481[24:11<31:45,51.73it/s] 48%|####8     |83625/173481[27:00<28:56,51.75it/s] 49%|####8     |84212/173481[27:11<28:44,51.75it/s] 54%|#####3    |92954/173481[30:00<25:54,51.79it/s] 54%|#####3    |93543/173481[30:11<25:43,51.79it/s] 59%|#####8    |102262/173481[33:00<22:56,51.75it/s] 59%|#####9    |102871/173481[33:11<22:44,51.75it/s] 64%|######4   |111586/173481[36:00<19:55,51.77it/s] 65%|######4   |112196/173481[36:11<19:43,51.77it/s] 70%|######9   |120926/173481[39:00<16:53,51.83it/s] 70%|#######   |121537/173481[39:12<16:42,51.83it/s] 75%|#######5  |130211/173481[42:00<13:56,51.70it/s] 75%|#######5  |130828/173481[42:12<13:44,51.70it/s] 80%|########  |139528/173481[45:00<10:56,51.73it/s] 81%|########  |140166/173481[45:12<10:43,51.73it/s] 86%|########5 |148854/173481[48:00<07:55,51.77it/s] 86%|########6 |149487/173481[48:12<07:43,51.77it/s] 91%|#########1|158175/173481[51:00<04:55,51.78it/s] 92%|#########1|158824/173481[51:12<04:43,51.78it/s] 97%|#########6|167502/173481[54:00<01:55,51.80it/s] 97%|#########6|168162/173481[54:12<01:42,51.80it/s]100%|##########|173481/173481[55:56<00:00,51.68it/s]
[32m[0323 17:41:10 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:3356.91 sec.
[32m[0323 17:41:11 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-1214367.
[32m[0323 17:41:11 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13924/18822[03:00<01:03,77.35it/s] 78%|#######8  |14699/18822[03:10<00:53,77.35it/s]100%|##########|18822/18822[04:05<00:00,76.65it/s]
6
[32m[0323 17:45:16 @monitor.py:363][0m QueueInput/queue_size: 49.976
[32m[0323 17:45:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.871
[32m[0323 17:45:16 @monitor.py:363][0m activation-summaries/output-rms: 0.033167
[32m[0323 17:45:16 @monitor.py:363][0m cross_entropy_loss: 2.1798
[32m[0323 17:45:16 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.31986
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.6829e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.2223
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.0312e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.30502
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0c/b-rms: 8.7785e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.2187
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.9579e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.30797
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0e/b-rms: 7.0205e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.21743
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.0501e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.30028
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.1346e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21801
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.4619e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.32425
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.86e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.22152
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4988e-06
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.23618
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1985
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.47608
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36822
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.37963
[32m[0323 17:45:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0323 17:45:16 @monitor.py:363][0m train-error-top1: 0.55621
[32m[0323 17:45:16 @monitor.py:363][0m val-error-top1: 0.64308
[32m[0323 17:45:16 @monitor.py:363][0m val-utt-error: 0.2877
[32m[0323 17:45:16 @monitor.py:363][0m validation_cost: 2.6084
[32m[0323 17:45:16 @monitor.py:363][0m wd_cost: 0.15318
[32m[0323 17:45:16 @group.py:42][0m Callbacks took 246.197 sec in total. InferenceRunner: 245.617sec
[32m[0323 17:45:16 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9214/173481[03:00<53:29,51.18it/s]  6%|5         |9732/173481[03:10<53:19,51.18it/s] 11%|#         |18537/173481[06:00<50:09,51.49it/s] 11%|#         |19069/173481[06:10<49:59,51.49it/s] 16%|#6        |27823/173481[09:00<47:06,51.54it/s] 16%|#6        |28355/173481[09:10<46:55,51.54it/s] 21%|##1       |36954/173481[12:00<44:30,51.13it/s] 22%|##1       |37490/173481[12:10<44:19,51.13it/s] 27%|##6       |46082/173481[15:00<41:42,50.92it/s] 27%|##6       |46628/173481[15:10<41:31,50.92it/s] 32%|###1      |55175/173481[18:00<38:52,50.71it/s] 32%|###2      |55719/173481[18:11<38:42,50.71it/s] 37%|###7      |64287/173481[21:00<35:55,50.67it/s] 37%|###7      |64855/173481[21:11<35:43,50.67it/s] 42%|####2     |73636/173481[24:00<32:26,51.29it/s] 43%|####2     |74218/173481[24:11<32:15,51.29it/s] 48%|####7     |82973/173481[27:00<29:14,51.58it/s] 48%|####8     |83570/173481[27:11<29:03,51.58it/s] 53%|#####3    |92291/173481[30:00<26:11,51.67it/s] 54%|#####3    |92890/173481[30:11<25:59,51.67it/s] 59%|#####8    |101602/173481[33:00<23:10,51.70it/s] 59%|#####8    |102194/173481[33:11<22:58,51.70it/s] 64%|######3   |110947/173481[36:00<20:07,51.80it/s] 64%|######4   |111565/173481[36:11<19:55,51.80it/s] 69%|######9   |120297/173481[39:00<17:05,51.87it/s] 70%|######9   |120932/173481[39:12<16:53,51.87it/s] 75%|#######4  |129718/173481[42:00<13:59,52.10it/s] 75%|#######5  |130348/173481[42:12<13:47,52.10it/s] 80%|########  |139062/173481[45:00<11:01,52.01it/s] 81%|########  |139698/173481[45:12<10:49,52.01it/s] 86%|########5 |148424/173481[48:00<08:01,52.01it/s] 86%|########5 |149070/173481[48:12<07:49,52.01it/s] 91%|######### |157774/173481[51:00<05:02,51.97it/s] 91%|#########1|158425/173481[51:12<04:49,51.97it/s] 96%|#########6|167111/173481[54:00<02:02,51.92it/s] 97%|#########6|167778/173481[54:13<01:49,51.92it/s]100%|##########|173481/173481[56:02<00:00,51.59it/s]
[32m[0323 18:41:19 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:3362.57 sec.
[32m[0323 18:41:19 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-1387848.
[32m[0323 18:41:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######9  |14945/18822[03:00<00:46,83.02it/s] 83%|########3 |15716/18822[03:10<00:37,83.02it/s]100%|##########|18822/18822[03:51<00:00,81.13it/s]
7
[32m[0323 18:45:11 @monitor.py:363][0m QueueInput/queue_size: 49.995
[32m[0323 18:45:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 17.46
[32m[0323 18:45:11 @monitor.py:363][0m activation-summaries/output-rms: 0.036882
[32m[0323 18:45:11 @monitor.py:363][0m cross_entropy_loss: 1.8549
[32m[0323 18:45:11 @monitor.py:363][0m lr: 0.00025
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.31918
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.375e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.22547
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.084e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.30359
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0c/b-rms: 8.7668e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.2208
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.0141e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.30627
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6091e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.22029
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9911e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.29851
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4325e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.22098
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.3918e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.32437
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8713e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.22437
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6409e-06
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26352
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2209
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.47848
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.37501
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.38095
[32m[0323 18:45:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0323 18:45:11 @monitor.py:363][0m train-error-top1: 0.4848
[32m[0323 18:45:11 @monitor.py:363][0m val-error-top1: 0.65089
[32m[0323 18:45:11 @monitor.py:363][0m val-utt-error: 0.29811
[32m[0323 18:45:11 @monitor.py:363][0m validation_cost: 2.7504
[32m[0323 18:45:11 @monitor.py:363][0m wd_cost: 0.15895
[32m[0323 18:45:11 @group.py:42][0m Callbacks took 232.417 sec in total. InferenceRunner: 232.008sec
[32m[0323 18:45:11 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9367/173481[03:00<52:33,52.04it/s]  6%|5         |9890/173481[03:10<52:23,52.04it/s] 11%|#         |18620/173481[06:00<49:54,51.72it/s] 11%|#1        |19126/173481[06:10<49:44,51.72it/s] 16%|#5        |27652/173481[09:00<47:43,50.93it/s] 16%|#6        |28191/173481[09:10<47:32,50.93it/s] 21%|##1       |36810/173481[12:00<44:44,50.91it/s] 22%|##1       |37349/173481[12:10<44:34,50.91it/s] 27%|##6       |46134/173481[15:00<41:20,51.35it/s] 27%|##6       |46698/173481[15:10<41:09,51.35it/s] 32%|###2      |55571/173481[18:00<37:52,51.88it/s] 32%|###2      |56120/173481[18:10<37:42,51.88it/s] 37%|###7      |64932/173481[21:00<34:49,51.94it/s] 38%|###7      |65506/173481[21:11<34:38,51.94it/s] 43%|####2     |74253/173481[24:00<31:53,51.86it/s] 43%|####3     |74837/173481[24:11<31:42,51.86it/s] 48%|####8     |83600/173481[27:00<28:52,51.89it/s] 49%|####8     |84183/173481[27:11<28:40,51.89it/s] 54%|#####3    |92817/173481[30:00<26:04,51.55it/s] 54%|#####3    |93417/173481[30:11<25:53,51.55it/s] 59%|#####8    |102196/173481[33:00<22:55,51.82it/s] 59%|#####9    |102808/173481[33:11<22:43,51.82it/s] 64%|######4   |111585/173481[36:00<19:50,51.99it/s] 65%|######4   |112201/173481[36:11<19:38,51.99it/s] 70%|######9   |120988/173481[39:00<16:47,52.11it/s] 70%|#######   |121614/173481[39:12<16:35,52.11it/s] 75%|#######5  |130371/173481[42:00<13:47,52.12it/s] 76%|#######5  |131005/173481[42:12<13:34,52.12it/s] 81%|########  |139756/173481[45:00<10:46,52.13it/s] 81%|########  |140406/173481[45:12<10:34,52.13it/s] 86%|########5 |149192/173481[48:00<07:44,52.27it/s] 86%|########6 |149864/173481[48:12<07:31,52.27it/s] 91%|#########1|158609/173481[51:00<04:44,52.29it/s] 92%|#########1|159271/173481[51:12<04:31,52.29it/s] 97%|#########6|167948/173481[54:00<01:46,52.09it/s] 97%|#########7|168606/173481[54:12<01:33,52.09it/s]100%|##########|173481/173481[55:47<00:00,51.83it/s]
[32m[0323 19:40:59 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:3347.26 sec.
[32m[0323 19:40:59 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-1561329.
  0%|          |0/18822[00:00<?,?it/s] 82%|########1 |15355/18822[03:00<00:40,85.30it/s] 86%|########6 |16225/18822[03:10<00:30,85.30it/s]100%|##########|18822/18822[03:42<00:00,84.67it/s]
8
[32m[0323 19:44:41 @monitor.py:363][0m QueueInput/queue_size: 49.994
[32m[0323 19:44:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 18.46
[32m[0323 19:44:41 @monitor.py:363][0m activation-summaries/output-rms: 0.035397
[32m[0323 19:44:41 @monitor.py:363][0m cross_entropy_loss: 1.9896
[32m[0323 19:44:41 @monitor.py:363][0m lr: 0.000125
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.33647
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.3616e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.23399
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.0175e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3198
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.1004e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.22986
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.2254e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.32313
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.5938e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.22836
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.8924e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.31587
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.5254e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.2291
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.4124e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.34283
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8588e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.23316
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.7135e-06
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.28504
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2269
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.55104
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090276
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.43059
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.44311
[32m[0323 19:44:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0323 19:44:41 @monitor.py:363][0m train-error-top1: 0.51312
[32m[0323 19:44:41 @monitor.py:363][0m val-error-top1: 0.6183
[32m[0323 19:44:41 @monitor.py:363][0m val-utt-error: 0.24695
[32m[0323 19:44:41 @monitor.py:363][0m validation_cost: 2.5008
[32m[0323 19:44:41 @monitor.py:363][0m wd_cost: 0.041411
[32m[0323 19:44:41 @group.py:42][0m Callbacks took 222.692 sec in total. InferenceRunner: 222.344sec
[32m[0323 19:44:41 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9349/173481[03:00<52:40,51.94it/s]  6%|5         |9874/173481[03:10<52:30,51.94it/s] 11%|#         |18709/173481[06:00<49:38,51.96it/s] 11%|#1        |19252/173481[06:10<49:27,51.96it/s] 16%|#6        |28090/173481[09:00<46:33,52.04it/s] 17%|#6        |28642/173481[09:10<46:23,52.04it/s] 22%|##1       |37528/173481[12:00<43:22,52.23it/s] 22%|##1       |38075/173481[12:10<43:12,52.23it/s] 27%|##7       |46908/173481[15:00<40:26,52.17it/s] 27%|##7       |47471/173481[15:10<40:15,52.17it/s] 32%|###2      |56364/173481[18:00<37:17,52.35it/s] 33%|###2      |56941/173481[18:10<37:06,52.35it/s] 38%|###7      |65823/173481[21:00<34:12,52.45it/s] 38%|###8      |66415/173481[21:11<34:01,52.45it/s] 43%|####3     |75303/173481[24:00<31:08,52.56it/s] 44%|####3     |75893/173481[24:11<30:56,52.56it/s] 49%|####8     |84728/173481[27:00<28:11,52.46it/s] 49%|####9     |85319/173481[27:11<28:00,52.46it/s] 54%|#####4    |94098/173481[30:00<25:19,52.25it/s] 55%|#####4    |94694/173481[30:11<25:07,52.25it/s] 60%|#####9    |103365/173481[33:00<22:31,51.86it/s] 60%|#####9    |103968/173481[33:11<22:20,51.86it/s] 65%|######4   |112740/173481[36:00<19:28,51.97it/s] 65%|######5   |113348/173481[36:11<19:17,51.97it/s] 70%|#######   |122130/173481[39:00<16:26,52.07it/s] 71%|#######   |122759/173481[39:12<16:14,52.07it/s] 76%|#######5  |131503/173481[42:00<13:26,52.07it/s] 76%|#######6  |132135/173481[42:12<13:14,52.07it/s] 81%|########1 |140866/173481[45:00<10:26,52.04it/s] 82%|########1 |141505/173481[45:12<10:14,52.04it/s] 87%|########6 |150221/173481[48:00<07:27,52.01it/s] 87%|########6 |150866/173481[48:12<07:14,52.01it/s] 92%|#########2|159604/173481[51:00<04:26,52.07it/s] 92%|#########2|160281/173481[51:12<04:13,52.07it/s] 97%|#########7|169013/173481[54:00<01:25,52.17it/s] 98%|#########7|169674/173481[54:13<01:12,52.17it/s]100%|##########|173481/173481[55:26<00:00,52.15it/s]
[32m[0323 20:40:08 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:3326.67 sec.
[32m[0323 20:40:08 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-1734810.
[32m[0323 20:40:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 61%|######    |11481/18822[03:00<01:55,63.78it/s] 69%|######8   |12962/18822[03:17<01:31,63.78it/s]100%|##########|18822/18822[04:29<00:00,69.72it/s]
9
[32m[0323 20:44:39 @monitor.py:363][0m QueueInput/queue_size: 49.979
[32m[0323 20:44:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.668
[32m[0323 20:44:39 @monitor.py:363][0m activation-summaries/output-rms: 0.036609
[32m[0323 20:44:39 @monitor.py:363][0m cross_entropy_loss: 2.0117
[32m[0323 20:44:39 @monitor.py:363][0m lr: 0.000125
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.35375
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1734e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.24348
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.0761e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.33588
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.1642e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.23913
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.2484e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3393
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7511e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.23796
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9145e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.33154
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.5668e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.23843
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5173e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.36072
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8408e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.24237
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6771e-06
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31203
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2323
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.62781
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.49165
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50983
[32m[0323 20:44:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0323 20:44:39 @monitor.py:363][0m train-error-top1: 0.51733
[32m[0323 20:44:39 @monitor.py:363][0m val-error-top1: 0.62838
[32m[0323 20:44:39 @monitor.py:363][0m val-utt-error: 0.27356
[32m[0323 20:44:39 @monitor.py:363][0m validation_cost: 2.5553
[32m[0323 20:44:39 @monitor.py:363][0m wd_cost: 0.053328
[32m[0323 20:44:39 @group.py:42][0m Callbacks took 270.605 sec in total. InferenceRunner: 270.016sec
[32m[0323 20:44:39 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9405/173481[03:00<52:20,52.25it/s]  6%|5         |9940/173481[03:10<52:10,52.25it/s] 11%|#         |18810/173481[06:00<49:20,52.25it/s] 11%|#1        |19343/173481[06:10<49:10,52.25it/s] 16%|#6        |28187/173481[09:00<46:25,52.17it/s] 17%|#6        |28731/173481[09:10<46:14,52.17it/s] 22%|##1       |37552/173481[12:00<43:29,52.10it/s] 22%|##1       |38109/173481[12:10<43:18,52.10it/s] 27%|##7       |46986/173481[15:00<40:20,52.25it/s] 27%|##7       |47556/173481[15:10<40:10,52.25it/s] 33%|###2      |56430/173481[18:00<37:15,52.36it/s] 33%|###2      |57002/173481[18:11<37:04,52.36it/s] 38%|###8      |65935/173481[21:00<34:05,52.58it/s] 38%|###8      |66530/173481[21:11<33:54,52.58it/s] 44%|####3     |75479/173481[24:00<30:56,52.80it/s] 44%|####3     |76072/173481[24:11<30:44,52.80it/s] 49%|####9     |85110/173481[27:00<27:42,53.15it/s] 49%|####9     |85714/173481[27:11<27:31,53.15it/s] 55%|#####4    |94623/173481[30:00<24:47,53.00it/s] 55%|#####4    |95233/173481[30:11<24:36,53.00it/s] 60%|######    |104303/173481[33:00<21:35,53.38it/s] 60%|######    |104930/173481[33:11<21:24,53.38it/s] 66%|######5   |113871/173481[36:00<18:39,53.27it/s] 66%|######5   |114496/173481[36:11<18:27,53.27it/s] 71%|#######1  |123200/173481[39:00<15:57,52.54it/s] 71%|#######1  |123843/173481[39:12<15:44,52.54it/s] 77%|#######6  |132802/173481[42:00<12:48,52.94it/s] 77%|#######6  |133439/173481[42:12<12:36,52.94it/s] 82%|########2 |142468/173481[45:00<09:41,53.31it/s] 83%|########2 |143125/173481[45:12<09:29,53.31it/s] 88%|########7 |152192/173481[48:00<06:36,53.66it/s] 88%|########8 |152851/173481[48:12<06:24,53.66it/s] 93%|#########3|161668/173481[51:00<03:42,53.15it/s] 94%|#########3|162326/173481[51:12<03:29,53.15it/s] 99%|#########8|171285/173481[54:00<00:41,53.29it/s] 99%|#########9|171957/173481[54:12<00:28,53.29it/s]100%|##########|173481/173481[54:41<00:00,52.87it/s]
[32m[0323 21:39:20 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3281.17 sec.
[32m[0323 21:39:20 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-1908291.
  0%|          |0/18822[00:00<?,?it/s] 86%|########6 |16224/18822[03:00<00:28,90.13it/s] 91%|######### |17094/18822[03:10<00:19,90.13it/s]100%|##########|18822/18822[03:30<00:00,89.57it/s]
10
[32m[0323 21:42:50 @monitor.py:363][0m QueueInput/queue_size: 49.968
[32m[0323 21:42:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.432
[32m[0323 21:42:50 @monitor.py:363][0m activation-summaries/output-rms: 0.035712
[32m[0323 21:42:50 @monitor.py:363][0m cross_entropy_loss: 1.9821
[32m[0323 21:42:50 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.3694
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.133e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.25266
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1076e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.35045
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3011e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.248
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3014e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.35399
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.6703e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.24634
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9981e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.34681
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.5789e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.24774
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5319e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.37736
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8425e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.2512
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6788e-06
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.33905
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2354
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.68241
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.54009
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.56191
[32m[0323 21:42:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0323 21:42:50 @monitor.py:363][0m train-error-top1: 0.51049
[32m[0323 21:42:50 @monitor.py:363][0m val-error-top1: 0.60587
[32m[0323 21:42:50 @monitor.py:363][0m val-utt-error: 0.2402
[32m[0323 21:42:50 @monitor.py:363][0m validation_cost: 2.4142
[32m[0323 21:42:50 @monitor.py:363][0m wd_cost: 0.063609
[32m[0323 21:42:50 @group.py:42][0m Callbacks took 210.481 sec in total. InferenceRunner: 210.155sec
[32m[0323 21:42:50 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9793/173481[03:00<50:08,54.40it/s]  6%|5         |10340/173481[03:10<49:58,54.40it/s] 11%|#1        |19528/173481[06:00<47:18,54.24it/s] 12%|#1        |20077/173481[06:10<47:08,54.24it/s] 17%|#6        |29233/173481[09:00<44:27,54.08it/s] 17%|#7        |29777/173481[09:10<44:17,54.08it/s] 22%|##2       |38195/173481[12:00<43:29,51.84it/s] 22%|##2       |38669/173481[12:10<43:20,51.84it/s] 27%|##7       |47181/173481[15:00<41:23,50.86it/s] 28%|##7       |47724/173481[15:10<41:12,50.86it/s] 33%|###2      |56615/173481[18:00<37:43,51.62it/s] 33%|###2      |57212/173481[18:10<37:32,51.62it/s] 38%|###8      |65992/173481[21:00<34:32,51.86it/s] 38%|###8      |66588/173481[21:11<34:21,51.86it/s] 44%|####3     |75839/173481[24:00<30:33,53.24it/s] 44%|####4     |76447/173481[24:11<30:22,53.24it/s] 49%|####9     |85698/173481[27:00<27:05,54.00it/s] 50%|####9     |86306/173481[27:11<26:54,54.00it/s] 55%|#####4    |95336/173481[30:00<24:13,53.77it/s] 55%|#####5    |95922/173481[30:11<24:02,53.77it/s] 60%|######    |104598/173481[33:00<21:49,52.58it/s] 61%|######    |105172/173481[33:11<21:39,52.58it/s] 66%|######5   |113991/173481[36:00<18:55,52.38it/s] 66%|######6   |114610/173481[36:11<18:43,52.38it/s] 71%|#######   |122760/173481[39:00<16:44,50.48it/s] 71%|#######1  |123304/173481[39:11<16:34,50.48it/s] 76%|#######5  |131323/173481[42:00<14:20,48.98it/s] 76%|#######6  |131923/173481[42:12<14:08,48.98it/s] 81%|########  |140426/173481[45:00<11:04,49.76it/s] 81%|########1 |141005/173481[45:12<10:52,49.76it/s] 86%|########6 |149446/173481[48:00<08:01,49.93it/s] 87%|########6 |150068/173481[48:12<07:48,49.93it/s] 91%|#########1|158309/173481[51:00<05:05,49.58it/s] 92%|#########1|158908/173481[51:12<04:53,49.58it/s] 96%|#########6|167318/173481[54:00<02:03,49.81it/s] 97%|#########6|167964/173481[54:12<01:50,49.81it/s]100%|##########|173481/173481[55:59<00:00,51.64it/s]
[32m[0323 22:38:50 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3359.76 sec.
[32m[0323 22:38:50 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-2081772.
[32m[0323 22:38:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 95%|#########5|17922/18822[03:00<00:09,99.56it/s]100%|##########|18822/18822[03:09<00:00,99.40it/s]
11
[32m[0323 22:42:06 @monitor.py:363][0m QueueInput/queue_size: 5.7702
[32m[0323 22:42:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 22.928
[32m[0323 22:42:06 @monitor.py:363][0m activation-summaries/output-rms: 0.033402
[32m[0323 22:42:06 @monitor.py:363][0m cross_entropy_loss: 2.1972
[32m[0323 22:42:06 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.38025
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1019e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.25793
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1746e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.36065
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.2846e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.25383
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3321e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.36407
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7914e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.25239
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9858e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.35582
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.5215e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.25373
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5364e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.38811
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8326e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.25693
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6793e-06
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.36011
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2339
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.741
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.58594
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.61255
[32m[0323 22:42:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0323 22:42:06 @monitor.py:363][0m train-error-top1: 0.56035
[32m[0323 22:42:06 @monitor.py:363][0m val-error-top1: 0.62124
[32m[0323 22:42:06 @monitor.py:363][0m val-utt-error: 0.27096
[32m[0323 22:42:06 @monitor.py:363][0m validation_cost: 2.4996
[32m[0323 22:42:06 @monitor.py:363][0m wd_cost: 0.014915
[32m[0323 22:42:06 @group.py:42][0m Callbacks took 195.981 sec in total. InferenceRunner: 189.365sec
[32m[0323 22:42:06 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9833/173481[03:00<49:55,54.63it/s]  6%|5         |10386/173481[03:10<49:45,54.63it/s] 11%|#1        |19607/173481[06:00<47:05,54.46it/s] 12%|#1        |20168/173481[06:10<46:55,54.46it/s] 16%|#6        |28474/173481[09:00<46:43,51.73it/s] 17%|#6        |28968/173481[09:10<46:33,51.73it/s] 22%|##1       |37557/173481[12:00<44:20,51.08it/s] 22%|##1       |38112/173481[12:10<44:09,51.08it/s] 27%|##6       |46761/173481[15:00<41:19,51.11it/s] 27%|##7       |47209/173481[15:10<41:10,51.11it/s] 32%|###2      |55732/173481[18:00<38:53,50.46it/s] 32%|###2      |56278/173481[18:10<38:42,50.46it/s] 37%|###7      |64931/173481[21:00<35:37,50.78it/s] 38%|###7      |65501/173481[21:11<35:26,50.78it/s] 43%|####3     |74634/173481[24:00<31:30,52.30it/s] 43%|####3     |75227/173481[24:11<31:18,52.30it/s] 49%|####8     |84410/173481[27:00<27:51,53.28it/s] 49%|####9     |85028/173481[27:11<27:40,53.28it/s] 54%|#####4    |94275/173481[30:00<24:25,54.03it/s] 55%|#####4    |94889/173481[30:11<24:14,54.03it/s] 60%|#####9    |104041/173481[33:00<21:22,54.14it/s] 60%|######    |104657/173481[33:11<21:11,54.14it/s] 66%|######5   |113836/173481[36:00<18:18,54.28it/s] 66%|######5   |114480/173481[36:11<18:07,54.28it/s] 71%|#######1  |123775/173481[39:00<15:08,54.74it/s] 72%|#######1  |124422/173481[39:11<14:56,54.74it/s] 77%|#######7  |133753/173481[42:00<12:01,55.08it/s] 77%|#######7  |134410/173481[42:12<11:49,55.08it/s] 83%|########2 |143719/173481[45:00<08:58,55.22it/s] 83%|########3 |144392/173481[45:12<08:46,55.22it/s] 89%|########8 |153648/173481[48:00<05:59,55.19it/s] 89%|########8 |154324/173481[48:12<05:47,55.19it/s] 94%|#########4|163536/173481[51:00<03:00,55.06it/s] 95%|#########4|164211/173481[51:12<02:48,55.06it/s]100%|#########9|173452/173481[54:00<00:00,55.07it/s]100%|##########|173481/173481[54:00<00:00,53.53it/s]
[32m[0323 23:36:07 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3240.77 sec.
[32m[0323 23:36:07 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-2255253.
  0%|          |0/18822[00:00<?,?it/s] 81%|########1 |15320/18822[03:00<00:41,85.11it/s] 86%|########5 |16180/18822[03:10<00:31,85.11it/s]100%|##########|18822/18822[03:42<00:00,84.59it/s]
12
[32m[0323 23:39:50 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0323 23:39:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 26.598
[32m[0323 23:39:50 @monitor.py:363][0m activation-summaries/output-rms: 0.037487
[32m[0323 23:39:50 @monitor.py:363][0m cross_entropy_loss: 1.985
[32m[0323 23:39:50 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.38924
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.1245e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.26263
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1818e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.36992
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3813e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.25901
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3445e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.37401
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8106e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.25753
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9898e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.36401
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.5068e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.25841
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5946e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.39813
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.81e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26181
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6424e-06
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.38592
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2365
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.79217
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.62689
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.6565
[32m[0323 23:39:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0323 23:39:50 @monitor.py:363][0m train-error-top1: 0.51576
[32m[0323 23:39:50 @monitor.py:363][0m val-error-top1: 0.61804
[32m[0323 23:39:50 @monitor.py:363][0m val-utt-error: 0.26214
[32m[0323 23:39:50 @monitor.py:363][0m validation_cost: 2.5036
[32m[0323 23:39:50 @monitor.py:363][0m wd_cost: 0.017044
[32m[0323 23:39:50 @group.py:42][0m Callbacks took 222.771 sec in total. InferenceRunner: 222.519sec
[32m[0323 23:39:50 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9955/173481[03:00<49:17,55.30it/s]  6%|6         |10516/173481[03:10<49:06,55.30it/s] 11%|#1        |19852/173481[06:00<46:26,55.14it/s] 12%|#1        |20413/173481[06:10<46:15,55.14it/s] 17%|#7        |29604/173481[09:00<43:52,54.65it/s] 17%|#7        |30175/173481[09:10<43:42,54.65it/s] 23%|##2       |39391/173481[12:00<40:59,54.51it/s] 23%|##3       |39964/173481[12:10<40:49,54.51it/s] 28%|##8       |49316/173481[15:00<37:44,54.82it/s] 29%|##8       |49896/173481[15:10<37:34,54.82it/s] 34%|###4      |59072/173481[18:00<34:58,54.51it/s] 34%|###4      |59667/173481[18:10<34:48,54.51it/s] 40%|###9      |68880/173481[21:00<31:59,54.50it/s] 40%|####      |69480/173481[21:11<31:48,54.50it/s] 45%|####5     |78614/173481[24:00<29:07,54.28it/s] 46%|####5     |79208/173481[24:11<28:56,54.28it/s] 51%|#####     |88147/173481[27:00<26:31,53.61it/s] 51%|#####1    |88728/173481[27:11<26:20,53.61it/s] 56%|#####6    |97384/173481[30:00<24:11,52.44it/s] 56%|#####6    |98007/173481[30:11<23:59,52.44it/s] 62%|######1   |106985/173481[33:00<20:57,52.88it/s] 62%|######2   |107566/173481[33:11<20:46,52.88it/s] 67%|######7   |116267/173481[36:00<18:15,52.21it/s] 67%|######7   |116870/173481[36:11<18:04,52.21it/s] 72%|#######2  |125621/173481[39:00<15:18,52.09it/s] 73%|#######2  |126221/173481[39:12<15:07,52.09it/s] 78%|#######7  |134912/173481[42:00<12:23,51.85it/s] 78%|#######8  |135532/173481[42:12<12:11,51.85it/s] 83%|########3 |144351/173481[45:00<09:18,52.14it/s] 84%|########3 |144984/173481[45:12<09:06,52.14it/s] 89%|########8 |153929/173481[48:00<06:11,52.67it/s] 89%|########9 |154584/173481[48:12<05:58,52.67it/s] 94%|#########4|163388/173481[51:00<03:11,52.61it/s] 95%|#########4|164069/173481[51:12<02:58,52.61it/s] 99%|#########9|172443/173481[54:00<00:20,51.43it/s]100%|#########9|173094/173481[54:12<00:07,51.43it/s]100%|##########|173481/173481[54:22<00:00,53.17it/s]
[32m[0324 00:34:13 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:3262.97 sec.
[32m[0324 00:34:13 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-2428734.
  0%|          |0/18822[00:00<?,?it/s] 84%|########3 |15723/18822[03:00<00:35,87.35it/s] 88%|########8 |16615/18822[03:10<00:25,87.35it/s]100%|##########|18822/18822[03:35<00:00,87.19it/s]
13
[32m[0324 00:37:49 @monitor.py:363][0m QueueInput/queue_size: 1.1493
[32m[0324 00:37:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 26.45
[32m[0324 00:37:49 @monitor.py:363][0m activation-summaries/output-rms: 0.033239
[32m[0324 00:37:49 @monitor.py:363][0m cross_entropy_loss: 2.1966
[32m[0324 00:37:49 @monitor.py:363][0m lr: 3.125e-05
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.39492
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2657e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.2658
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1816e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.37474
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3474e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26196
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3556e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.37931
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8795e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26046
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9467e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.36957
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4662e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26169
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5648e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.40433
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8188e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26495
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6057e-06
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.40182
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2365
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.83182
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.65866
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.69135
[32m[0324 00:37:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 00:37:49 @monitor.py:363][0m train-error-top1: 0.55991
[32m[0324 00:37:49 @monitor.py:363][0m val-error-top1: 0.61943
[32m[0324 00:37:49 @monitor.py:363][0m val-utt-error: 0.27032
[32m[0324 00:37:49 @monitor.py:363][0m validation_cost: 2.4851
[32m[0324 00:37:49 @monitor.py:363][0m wd_cost: 0.0037534
[32m[0324 00:37:49 @group.py:42][0m Callbacks took 216.539 sec in total. InferenceRunner: 215.959sec
[32m[0324 00:37:49 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9222/173481[03:00<53:26,51.23it/s]  6%|5         |9715/173481[03:10<53:16,51.23it/s] 11%|#         |18460/173481[06:00<50:23,51.27it/s] 11%|#         |19001/173481[06:10<50:12,51.27it/s] 16%|#6        |28048/173481[09:00<46:23,52.25it/s] 16%|#6        |28612/173481[09:10<46:12,52.25it/s] 22%|##1       |37799/173481[12:00<42:30,53.19it/s] 22%|##2       |38355/173481[12:10<42:20,53.19it/s] 27%|##7       |47308/173481[15:00<39:40,53.01it/s] 28%|##7       |47870/173481[15:10<39:29,53.01it/s] 33%|###2      |57077/173481[18:00<36:10,53.63it/s] 33%|###3      |57670/173481[18:10<35:59,53.63it/s] 38%|###8      |66790/173481[21:00<33:03,53.79it/s] 39%|###8      |67375/173481[21:11<32:52,53.79it/s] 44%|####3     |76231/173481[24:00<30:31,53.11it/s] 44%|####4     |76824/173481[24:11<30:19,53.11it/s] 50%|####9     |86066/173481[27:00<27:02,53.86it/s] 50%|####9     |86696/173481[27:11<26:51,53.86it/s] 55%|#####5    |96040/173481[30:00<23:37,54.62it/s] 56%|#####5    |96674/173481[30:11<23:26,54.62it/s] 61%|######1   |105895/173481[33:00<20:35,54.69it/s] 61%|######1   |106524/173481[33:11<20:24,54.69it/s] 67%|######6   |115625/173481[36:00<17:44,54.37it/s] 67%|######7   |116254/173481[36:11<17:32,54.37it/s] 72%|#######2  |125467/173481[39:00<14:40,54.52it/s] 73%|#######2  |126129/173481[39:12<14:28,54.52it/s] 78%|#######8  |135353/173481[42:00<11:36,54.72it/s] 78%|#######8  |136011/173481[42:12<11:24,54.72it/s] 84%|########3 |144881/173481[45:00<08:51,53.81it/s] 84%|########3 |145518/173481[45:12<08:39,53.81it/s] 89%|########9 |154457/173481[48:00<05:55,53.50it/s] 89%|########9 |155117/173481[48:12<05:43,53.50it/s] 95%|#########4|164146/173481[51:00<02:53,53.66it/s] 95%|#########5|164817/173481[51:12<02:41,53.66it/s]100%|##########|173481/173481[53:53<00:00,53.65it/s]
[32m[0324 01:31:43 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3233.69 sec.
[32m[0324 01:31:43 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-2602215.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14838/18822[03:00<00:48,82.43it/s] 83%|########3 |15675/18822[03:10<00:38,82.43it/s]100%|##########|18822/18822[03:47<00:00,82.56it/s]
14
[32m[0324 01:35:32 @monitor.py:363][0m QueueInput/queue_size: 35.258
[32m[0324 01:35:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.648
[32m[0324 01:35:32 @monitor.py:363][0m activation-summaries/output-rms: 0.038162
[32m[0324 01:35:32 @monitor.py:363][0m cross_entropy_loss: 1.7677
[32m[0324 01:35:32 @monitor.py:363][0m lr: 3.125e-05
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.39843
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.287e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.26741
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1551e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.37781
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.384e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26348
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3592e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38225
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8435e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26203
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9498e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.3724
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4438e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26325
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5495e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.40716
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.814e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26639
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6029e-06
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.41376
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2371
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.86063
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.68074
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.71555
[32m[0324 01:35:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 01:35:32 @monitor.py:363][0m train-error-top1: 0.45542
[32m[0324 01:35:32 @monitor.py:363][0m val-error-top1: 0.6005
[32m[0324 01:35:32 @monitor.py:363][0m val-utt-error: 0.24546
[32m[0324 01:35:32 @monitor.py:363][0m validation_cost: 2.4008
[32m[0324 01:35:32 @monitor.py:363][0m wd_cost: 0.0040083
[32m[0324 01:35:32 @group.py:42][0m Callbacks took 228.522 sec in total. InferenceRunner: 228.085sec
[32m[0324 01:35:32 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9729/173481[03:00<50:29,54.05it/s]  6%|5         |10283/173481[03:10<50:19,54.05it/s] 11%|#1        |19506/173481[06:00<47:21,54.18it/s] 12%|#1        |20068/173481[06:10<47:11,54.18it/s] 17%|#6        |29249/173481[09:00<44:23,54.15it/s] 17%|#7        |29819/173481[09:10<44:12,54.15it/s] 22%|##2       |38986/173481[12:00<41:25,54.12it/s] 23%|##2       |39562/173481[12:10<41:14,54.12it/s] 28%|##8       |48731/173481[15:00<38:24,54.13it/s] 28%|##8       |49319/173481[15:10<38:13,54.13it/s] 34%|###3      |58441/173481[18:00<35:29,54.03it/s] 34%|###4      |59027/173481[18:10<35:18,54.03it/s] 39%|###9      |68133/173481[21:00<32:33,53.94it/s] 40%|###9      |68726/173481[21:11<32:22,53.94it/s] 45%|####4     |77927/173481[24:00<29:23,54.17it/s] 45%|####5     |78525/173481[24:11<29:12,54.17it/s] 50%|#####     |87395/173481[27:00<26:52,53.37it/s] 51%|#####     |87999/173481[27:11<26:41,53.37it/s] 56%|#####5    |96576/173481[30:00<24:34,52.16it/s] 56%|#####6    |97180/173481[30:11<24:22,52.16it/s] 61%|######1   |105926/173481[33:00<21:37,52.05it/s] 61%|######1   |106538/173481[33:11<21:26,52.05it/s] 66%|######6   |115140/173481[36:00<18:50,51.61it/s] 67%|######6   |115716/173481[36:11<18:39,51.61it/s] 72%|#######1  |124060/173481[39:00<16:17,50.56it/s] 72%|#######1  |124676/173481[39:11<16:05,50.56it/s] 77%|#######6  |133471/173481[42:00<12:58,51.41it/s] 77%|#######7  |134077/173481[42:12<12:46,51.41it/s] 82%|########2 |142991/173481[45:00<09:44,52.14it/s] 83%|########2 |143646/173481[45:12<09:32,52.14it/s] 88%|########7 |152532/173481[48:00<06:38,52.57it/s] 88%|########8 |153137/173481[48:12<06:27,52.57it/s] 93%|#########3|161734/173481[51:00<03:46,51.83it/s] 94%|#########3|162366/173481[51:12<03:34,51.83it/s] 99%|#########8|171242/173481[54:00<00:42,52.32it/s] 99%|#########9|171909/173481[54:12<00:30,52.32it/s]100%|##########|173481/173481[54:42<00:00,52.84it/s]
[32m[0324 02:30:15 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:3283.01 sec.
[32m[0324 02:30:15 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-2775696.
[32m[0324 02:30:16 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 75%|#######5  |14132/18822[03:00<00:59,78.51it/s] 79%|#######9  |14903/18822[03:10<00:49,78.51it/s]100%|##########|18822/18822[04:01<00:00,78.10it/s]
15
[32m[0324 02:34:17 @monitor.py:363][0m QueueInput/queue_size: 36.976
[32m[0324 02:34:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.954
[32m[0324 02:34:17 @monitor.py:363][0m activation-summaries/output-rms: 0.034124
[32m[0324 02:34:17 @monitor.py:363][0m cross_entropy_loss: 2.1719
[32m[0324 02:34:17 @monitor.py:363][0m lr: 3.125e-05
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40107
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2679e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.26891
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1653e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.37983
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3472e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26452
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3732e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3846
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8382e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26339
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9546e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.3754
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4346e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26462
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5553e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41048
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8358e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26771
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.595e-06
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.42503
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2368
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.8909
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.70423
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.74139
[32m[0324 02:34:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 02:34:17 @monitor.py:363][0m train-error-top1: 0.55479
[32m[0324 02:34:17 @monitor.py:363][0m val-error-top1: 0.61485
[32m[0324 02:34:17 @monitor.py:363][0m val-utt-error: 0.27069
[32m[0324 02:34:17 @monitor.py:363][0m validation_cost: 2.4838
[32m[0324 02:34:17 @monitor.py:363][0m wd_cost: 0.0042849
[32m[0324 02:34:17 @group.py:42][0m Callbacks took 241.923 sec in total. InferenceRunner: 241.135sec
[32m[0324 02:34:17 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9771/173481[03:00<50:16,54.28it/s]  6%|5         |10323/173481[03:10<50:05,54.28it/s] 11%|#1        |19544/173481[06:00<47:15,54.28it/s] 12%|#1        |20101/173481[06:10<47:05,54.28it/s] 17%|#6        |29286/173481[09:00<44:20,54.20it/s] 17%|#7        |29856/173481[09:10<44:09,54.20it/s] 22%|##2       |38847/173481[12:00<41:49,53.65it/s] 23%|##2       |39389/173481[12:10<41:39,53.65it/s] 28%|##7       |47900/173481[15:00<40:18,51.92it/s] 28%|##7       |48458/173481[15:10<40:08,51.92it/s] 33%|###3      |57324/173481[18:00<37:07,52.14it/s] 33%|###3      |57900/173481[18:10<36:56,52.14it/s] 38%|###8      |66729/173481[21:00<34:05,52.19it/s] 39%|###8      |67311/173481[21:11<33:54,52.19it/s] 44%|####4     |76361/173481[24:00<30:38,52.84it/s] 44%|####4     |76962/173481[24:11<30:26,52.84it/s] 50%|####9     |86013/173481[27:00<27:23,53.23it/s] 50%|####9     |86605/173481[27:11<27:12,53.23it/s] 55%|#####5    |95539/173481[30:00<24:28,53.07it/s] 55%|#####5    |96154/173481[30:11<24:16,53.07it/s] 61%|######    |105135/173481[33:00<21:24,53.19it/s] 61%|######    |105763/173481[33:11<21:13,53.19it/s] 66%|######6   |114757/173481[36:00<18:21,53.32it/s] 67%|######6   |115383/173481[36:11<18:09,53.32it/s] 72%|#######1  |124400/173481[39:00<15:18,53.44it/s] 72%|#######2  |125034/173481[39:12<15:06,53.44it/s] 77%|#######7  |133925/173481[42:00<12:23,53.18it/s] 78%|#######7  |134554/173481[42:12<12:12,53.18it/s] 83%|########2 |143521/173481[45:00<09:22,53.24it/s] 83%|########3 |144180/173481[45:12<09:10,53.24it/s] 88%|########8 |153227/173481[48:00<06:18,53.58it/s] 89%|########8 |153912/173481[48:12<06:05,53.58it/s] 94%|#########3|162968/173481[51:00<03:15,53.84it/s] 94%|#########4|163634/173481[51:12<03:02,53.84it/s]100%|#########9|172719/173481[54:00<00:14,54.01it/s]100%|#########9|173383/173481[54:12<00:01,54.01it/s]100%|##########|173481/173481[54:15<00:00,53.29it/s]
[32m[0324 03:28:32 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:3255.66 sec.
[32m[0324 03:28:33 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-2949177.
  0%|          |0/18822[00:00<?,?it/s] 76%|#######5  |14215/18822[03:00<00:58,78.97it/s] 80%|#######9  |15025/18822[03:10<00:48,78.97it/s]100%|##########|18822/18822[03:59<00:00,78.61it/s]
16
[32m[0324 03:32:33 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 03:32:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.219
[32m[0324 03:32:33 @monitor.py:363][0m activation-summaries/output-rms: 0.03486
[32m[0324 03:32:33 @monitor.py:363][0m cross_entropy_loss: 1.8551
[32m[0324 03:32:33 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40271
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2739e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.26953
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1631e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38136
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3456e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26535
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3687e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38619
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8153e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26405
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9688e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37671
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4609e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.2654
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5653e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41225
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8082e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26822
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5861e-06
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.43373
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2377
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.90979
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.71884
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.75728
[32m[0324 03:32:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 03:32:33 @monitor.py:363][0m train-error-top1: 0.48118
[32m[0324 03:32:33 @monitor.py:363][0m val-error-top1: 0.59532
[32m[0324 03:32:33 @monitor.py:363][0m val-utt-error: 0.2335
[32m[0324 03:32:33 @monitor.py:363][0m validation_cost: 2.3553
[32m[0324 03:32:33 @monitor.py:363][0m wd_cost: 0.00089287
[32m[0324 03:32:33 @group.py:42][0m Callbacks took 240.100 sec in total. InferenceRunner: 239.508sec
[32m[0324 03:32:33 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9747/173481[03:00<50:23,54.15it/s]  6%|5         |10295/173481[03:10<50:13,54.15it/s] 11%|#1        |19505/173481[06:00<47:21,54.18it/s] 12%|#1        |20070/173481[06:10<47:11,54.18it/s] 17%|#6        |29354/173481[09:00<44:07,54.45it/s] 17%|#7        |29895/173481[09:10<43:57,54.45it/s] 22%|##2       |38843/173481[12:00<41:53,53.56it/s] 23%|##2       |39417/173481[12:10<41:42,53.56it/s] 28%|##7       |48439/173481[15:00<38:59,53.44it/s] 28%|##8       |49005/173481[15:10<38:49,53.44it/s] 33%|###3      |57635/173481[18:00<36:57,52.23it/s] 34%|###3      |58192/173481[18:10<36:47,52.23it/s] 39%|###8      |67275/173481[21:00<33:28,52.88it/s] 39%|###9      |67883/173481[21:11<33:16,52.88it/s] 45%|####4     |77203/173481[24:00<29:43,53.99it/s] 45%|####4     |77821/173481[24:11<29:31,53.99it/s] 50%|#####     |87056/173481[27:00<26:29,54.36it/s] 51%|#####     |87671/173481[27:11<26:18,54.36it/s] 56%|#####5    |96898/173481[30:00<23:24,54.52it/s] 56%|#####6    |97536/173481[30:11<23:12,54.52it/s] 62%|######1   |106740/173481[33:00<20:22,54.60it/s] 62%|######1   |107381/173481[33:11<20:10,54.60it/s] 67%|######7   |116662/173481[36:00<17:15,54.86it/s] 68%|######7   |117312/173481[36:11<17:03,54.86it/s] 73%|#######2  |126495/173481[39:00<14:18,54.74it/s] 73%|#######3  |127157/173481[39:12<14:06,54.74it/s] 79%|#######8  |136396/173481[42:00<11:15,54.87it/s] 79%|#######9  |137059/173481[42:12<11:03,54.87it/s] 84%|########4 |146327/173481[45:00<08:13,55.02it/s] 85%|########4 |146996/173481[45:12<08:01,55.02it/s] 90%|######### |156230/173481[48:00<05:13,55.02it/s] 90%|######### |156920/173481[48:12<05:01,55.02it/s] 96%|#########5|166126/173481[51:00<02:13,55.00it/s] 96%|#########6|166821/173481[51:12<02:01,55.00it/s]100%|##########|173481/173481[53:14<00:00,54.31it/s]
[32m[0324 04:25:47 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:3194.36 sec.
[32m[0324 04:25:47 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-3122658.
[32m[0324 04:25:48 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 56%|#####6    |10580/18822[03:00<02:20,58.71it/s] 63%|######2   |11834/18822[03:14<01:59,58.71it/s]100%|##########|18822/18822[04:38<00:00,67.46it/s]
17
[32m[0324 04:30:27 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 04:30:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.64
[32m[0324 04:30:27 @monitor.py:363][0m activation-summaries/output-rms: 0.035941
[32m[0324 04:30:27 @monitor.py:363][0m cross_entropy_loss: 1.9447
[32m[0324 04:30:27 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40353
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2611e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.26981
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1544e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38244
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3316e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26582
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3638e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38735
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.7978e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26452
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9674e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37739
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.472e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26563
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5536e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41326
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8215e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26858
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5854e-06
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.44144
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2397
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.92198
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.72804
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.76695
[32m[0324 04:30:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 04:30:27 @monitor.py:363][0m train-error-top1: 0.50297
[32m[0324 04:30:27 @monitor.py:363][0m val-error-top1: 0.62082
[32m[0324 04:30:27 @monitor.py:363][0m val-utt-error: 0.2631
[32m[0324 04:30:27 @monitor.py:363][0m validation_cost: 2.5351
[32m[0324 04:30:27 @monitor.py:363][0m wd_cost: 0.00091668
[32m[0324 04:30:27 @group.py:42][0m Callbacks took 279.699 sec in total. InferenceRunner: 279.116sec
[32m[0324 04:30:27 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9729/173481[03:00<50:29,54.05it/s]  6%|5         |10281/173481[03:10<50:19,54.05it/s] 11%|#1        |19566/173481[06:00<47:12,54.35it/s] 12%|#1        |20127/173481[06:10<47:01,54.35it/s] 17%|#6        |29340/173481[09:00<44:13,54.32it/s] 17%|#7        |29910/173481[09:10<44:02,54.32it/s] 23%|##2       |39227/173481[12:00<40:57,54.62it/s] 23%|##2       |39808/173481[12:10<40:47,54.62it/s] 28%|##8       |49088/173481[15:00<37:54,54.70it/s] 29%|##8       |49674/173481[15:10<37:43,54.70it/s] 34%|###3      |58970/173481[18:00<34:49,54.80it/s] 34%|###4      |59560/173481[18:10<34:38,54.80it/s] 40%|###9      |68884/173481[21:00<31:43,54.94it/s] 40%|####      |69495/173481[21:11<31:32,54.94it/s] 45%|####5     |78783/173481[24:00<28:42,54.97it/s] 46%|####5     |79393/173481[24:11<28:31,54.97it/s] 51%|#####1    |88636/173481[27:00<25:46,54.85it/s] 51%|#####1    |89256/173481[27:11<25:35,54.85it/s] 57%|#####6    |98468/173481[30:00<22:50,54.73it/s] 57%|#####7    |99098/173481[30:11<22:39,54.73it/s] 62%|######2   |108304/173481[33:00<19:51,54.69it/s] 63%|######2   |108929/173481[33:11<19:40,54.69it/s] 68%|######8   |118128/173481[36:00<16:53,54.63it/s] 68%|######8   |118770/173481[36:11<16:41,54.63it/s] 74%|#######3  |127951/173481[39:00<13:53,54.60it/s] 74%|#######4  |128611/173481[39:12<13:41,54.60it/s] 79%|#######9  |137820/173481[42:00<10:51,54.71it/s] 80%|#######9  |138474/173481[42:12<10:39,54.71it/s] 85%|########5 |147649/173481[45:00<07:52,54.66it/s] 85%|########5 |148322/173481[45:12<07:40,54.66it/s] 91%|######### |157503/173481[48:00<04:52,54.70it/s] 91%|#########1|158188/173481[48:12<04:39,54.70it/s] 96%|#########6|167332/173481[51:00<01:52,54.65it/s] 97%|#########6|168016/173481[51:12<01:39,54.65it/s]100%|##########|173481/173481[52:52<00:00,54.68it/s]
[32m[0324 05:23:20 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:3172.79 sec.
[32m[0324 05:23:20 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-3296139.
  0%|          |0/18822[00:00<?,?it/s] 96%|#########5|18036/18822[03:00<00:07,100.20it/s]100%|##########|18822/18822[03:08<00:00,99.82it/s] 
18
[32m[0324 05:26:28 @monitor.py:363][0m QueueInput/queue_size: 49.995
[32m[0324 05:26:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.109
[32m[0324 05:26:28 @monitor.py:363][0m activation-summaries/output-rms: 0.035164
[32m[0324 05:26:28 @monitor.py:363][0m cross_entropy_loss: 1.9481
[32m[0324 05:26:28 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40382
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2543e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27009
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1684e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38311
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3532e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26602
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3739e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38792
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8279e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26466
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9753e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37782
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4524e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26589
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5385e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4138
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8168e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26893
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5807e-06
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4464
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2408
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.93392
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.73692
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.77657
[32m[0324 05:26:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 05:26:28 @monitor.py:363][0m train-error-top1: 0.51078
[32m[0324 05:26:28 @monitor.py:363][0m val-error-top1: 0.61469
[32m[0324 05:26:28 @monitor.py:363][0m val-utt-error: 0.25911
[32m[0324 05:26:28 @monitor.py:363][0m validation_cost: 2.4992
[32m[0324 05:26:28 @monitor.py:363][0m wd_cost: 0.00093932
[32m[0324 05:26:28 @group.py:42][0m Callbacks took 188.863 sec in total. InferenceRunner: 188.572sec
[32m[0324 05:26:28 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9679/173481[03:00<50:46,53.77it/s]  6%|5         |10183/173481[03:10<50:37,53.77it/s] 11%|#1        |19335/173481[06:00<47:50,53.71it/s] 11%|#1        |19889/173481[06:10<47:39,53.71it/s] 17%|#6        |29256/173481[09:00<44:11,54.40it/s] 17%|#7        |29835/173481[09:10<44:00,54.40it/s] 23%|##2       |39176/173481[12:00<40:52,54.75it/s] 23%|##2       |39764/173481[12:10<40:42,54.75it/s] 28%|##8       |49105/173481[15:00<37:43,54.96it/s] 29%|##8       |49696/173481[15:10<37:32,54.96it/s] 34%|###4      |59017/173481[18:00<34:40,55.01it/s] 34%|###4      |59620/173481[18:10<34:29,55.01it/s] 40%|###9      |68938/173481[21:00<31:38,55.06it/s] 40%|####      |69550/173481[21:11<31:27,55.06it/s] 45%|####5     |78887/173481[24:00<28:34,55.17it/s] 46%|####5     |79508/173481[24:11<28:23,55.17it/s] 51%|#####1    |88849/173481[27:00<25:31,55.25it/s] 52%|#####1    |89479/173481[27:11<25:20,55.25it/s] 57%|#####6    |98814/173481[30:00<22:30,55.31it/s] 57%|#####7    |99444/173481[30:11<22:18,55.31it/s] 63%|######2   |108788/173481[33:00<19:28,55.36it/s] 63%|######3   |109429/173481[33:11<19:17,55.36it/s] 68%|######8   |118660/173481[36:00<16:34,55.10it/s] 69%|######8   |119309/173481[36:11<16:23,55.10it/s] 74%|#######4  |128572/173481[39:00<13:35,55.08it/s] 74%|#######4  |129235/173481[39:12<13:23,55.08it/s] 80%|#######9  |138499/173481[42:00<10:34,55.11it/s] 80%|########  |139162/173481[42:12<10:22,55.11it/s] 86%|########5 |148423/173481[45:00<07:34,55.12it/s] 86%|########5 |149100/173481[45:12<07:22,55.12it/s] 91%|#########1|158393/173481[48:00<04:33,55.25it/s] 92%|#########1|159086/173481[48:12<04:20,55.25it/s] 97%|#########7|168379/173481[51:00<01:32,55.36it/s] 97%|#########7|169073/173481[51:12<01:19,55.36it/s]100%|##########|173481/173481[52:31<00:00,55.04it/s]
[32m[0324 06:19:00 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:3151.99 sec.
[32m[0324 06:19:01 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-3469620.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######9  |14930/18822[03:00<00:46,82.94it/s] 84%|########3 |15774/18822[03:10<00:36,82.94it/s]100%|##########|18822/18822[03:46<00:00,83.23it/s]
19
[32m[0324 06:22:47 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 06:22:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.461
[32m[0324 06:22:47 @monitor.py:363][0m activation-summaries/output-rms: 0.035764
[32m[0324 06:22:47 @monitor.py:363][0m cross_entropy_loss: 2.0927
[32m[0324 06:22:47 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40425
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2448e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27014
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1724e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38325
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3496e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26609
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3724e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38803
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8255e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26481
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9766e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37795
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4554e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26605
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5442e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41385
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8163e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26903
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5799e-06
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.44832
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2407
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.94098
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.74223
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.78249
[32m[0324 06:22:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 06:22:47 @monitor.py:363][0m train-error-top1: 0.53607
[32m[0324 06:22:47 @monitor.py:363][0m val-error-top1: 0.60721
[32m[0324 06:22:47 @monitor.py:363][0m val-utt-error: 0.23908
[32m[0324 06:22:47 @monitor.py:363][0m validation_cost: 2.4203
[32m[0324 06:22:47 @monitor.py:363][0m wd_cost: 0.00019053
[32m[0324 06:22:47 @group.py:42][0m Callbacks took 226.593 sec in total. InferenceRunner: 226.210sec
[32m[0324 06:22:47 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9975/173481[03:00<49:10,55.42it/s]  6%|6         |10537/173481[03:10<49:00,55.42it/s] 12%|#1        |19967/173481[06:00<46:07,55.46it/s] 12%|#1        |20538/173481[06:10<45:57,55.46it/s] 17%|#7        |29994/173481[09:00<43:01,55.58it/s] 18%|#7        |30572/173481[09:10<42:51,55.58it/s] 23%|##3       |40000/173481[12:00<40:01,55.58it/s] 23%|##3       |40591/173481[12:10<39:50,55.58it/s] 29%|##8       |49987/173481[15:00<37:03,55.53it/s] 29%|##9       |50587/173481[15:10<36:53,55.53it/s] 35%|###4      |59970/173481[18:00<34:05,55.49it/s] 35%|###4      |60573/173481[18:10<33:54,55.49it/s] 40%|####      |69913/173481[21:00<31:10,55.36it/s] 41%|####      |70525/173481[21:11<30:59,55.36it/s] 46%|####6     |79845/173481[24:00<28:14,55.27it/s] 46%|####6     |80449/173481[24:11<28:03,55.27it/s] 52%|#####1    |89772/173481[27:00<25:16,55.21it/s] 52%|#####2    |90401/173481[27:11<25:04,55.21it/s] 57%|#####7    |99740/173481[30:00<22:13,55.29it/s] 58%|#####7    |100376/173481[30:11<22:02,55.29it/s] 63%|######3   |109717/173481[33:00<19:11,55.36it/s] 64%|######3   |110354/173481[33:11<19:00,55.36it/s] 69%|######8   |119696/173481[36:00<16:10,55.40it/s] 69%|######9   |120350/173481[36:11<15:59,55.40it/s] 75%|#######4  |129656/173481[39:00<13:11,55.36it/s] 75%|#######5  |130313/173481[39:12<12:59,55.36it/s] 80%|########  |139581/173481[42:00<10:13,55.25it/s] 81%|########  |140256/173481[42:12<10:01,55.25it/s] 86%|########6 |149576/173481[45:00<07:11,55.39it/s] 87%|########6 |150255/173481[45:12<06:59,55.39it/s] 92%|#########1|159500/173481[48:00<04:13,55.26it/s] 92%|#########2|160185/173481[48:12<04:00,55.26it/s] 98%|#########7|169479/173481[51:00<01:12,55.35it/s] 98%|#########8|170175/173481[51:12<00:59,55.35it/s]100%|##########|173481/173481[52:12<00:00,55.39it/s]
[32m[0324 07:14:59 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:3132.25 sec.
[32m[0324 07:15:00 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-3643101.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######6  |14472/18822[03:00<00:54,80.40it/s] 81%|########1 |15310/18822[03:10<00:43,80.40it/s]100%|##########|18822/18822[04:29<00:00,69.94it/s]
20
[32m[0324 07:19:29 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 07:19:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.551
[32m[0324 07:19:29 @monitor.py:363][0m activation-summaries/output-rms: 0.034951
[32m[0324 07:19:29 @monitor.py:363][0m cross_entropy_loss: 2.0918
[32m[0324 07:19:29 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40451
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.242e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27031
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1611e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38333
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3541e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26608
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3751e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38819
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8296e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26486
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9757e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37833
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4646e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26614
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5383e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41425
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8223e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26911
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5813e-06
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45086
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2407
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.94779
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.74744
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.78824
[32m[0324 07:19:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 07:19:29 @monitor.py:363][0m train-error-top1: 0.53357
[32m[0324 07:19:29 @monitor.py:363][0m val-error-top1: 0.60699
[32m[0324 07:19:29 @monitor.py:363][0m val-utt-error: 0.24466
[32m[0324 07:19:29 @monitor.py:363][0m validation_cost: 2.4255
[32m[0324 07:19:29 @monitor.py:363][0m wd_cost: 0.00019319
[32m[0324 07:19:29 @group.py:42][0m Callbacks took 269.473 sec in total. InferenceRunner: 269.144sec
[32m[0324 07:19:29 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9945/173481[03:00<49:19,55.25it/s]  6%|6         |10505/173481[03:10<49:09,55.25it/s] 11%|#1        |19907/173481[06:00<46:17,55.29it/s] 12%|#1        |20472/173481[06:10<46:07,55.29it/s] 17%|#7        |29886/173481[09:00<43:13,55.37it/s] 18%|#7        |30463/173481[09:10<43:03,55.37it/s] 23%|##2       |39816/173481[12:00<40:18,55.27it/s] 23%|##3       |40400/173481[12:10<40:08,55.27it/s] 29%|##8       |49757/173481[15:00<37:19,55.24it/s] 29%|##9       |50350/173481[15:10<37:08,55.24it/s] 34%|###4      |59687/173481[18:00<34:21,55.20it/s] 35%|###4      |60290/173481[18:10<34:10,55.20it/s] 40%|####      |69590/173481[21:00<31:25,55.11it/s] 40%|####      |70203/173481[21:11<31:14,55.11it/s] 46%|####5     |79441/173481[24:00<28:32,54.92it/s] 46%|####6     |80059/173481[24:11<28:21,54.92it/s] 51%|#####1    |89302/173481[27:00<25:34,54.85it/s] 52%|#####1    |89918/173481[27:11<25:23,54.85it/s] 57%|#####7    |99152/173481[30:00<22:36,54.78it/s] 58%|#####7    |99787/173481[30:11<22:25,54.78it/s] 63%|######2   |109072/173481[33:00<19:32,54.94it/s] 63%|######3   |109712/173481[33:11<19:20,54.94it/s] 69%|######8   |119026/173481[36:00<16:27,55.12it/s] 69%|######8   |119676/173481[36:11<16:16,55.12it/s] 74%|#######4  |128965/173481[39:00<13:26,55.17it/s] 75%|#######4  |129624/173481[39:11<13:14,55.17it/s] 80%|########  |138919/173481[42:00<10:25,55.23it/s] 80%|########  |139576/173481[42:12<10:13,55.23it/s] 86%|########5 |148819/173481[45:00<07:27,55.11it/s] 86%|########6 |149488/173481[45:12<07:15,55.11it/s] 91%|#########1|158731/173481[48:00<04:27,55.09it/s] 92%|#########1|159404/173481[48:12<04:15,55.09it/s] 97%|#########7|168617/173481[51:00<01:28,55.00it/s] 98%|#########7|169301/173481[51:12<01:15,55.00it/s]100%|##########|173481/173481[52:29<00:00,55.09it/s]
[32m[0324 08:11:58 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:3149.17 sec.
[32m[0324 08:11:59 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-3816582.
  0%|          |0/18822[00:00<?,?it/s] 84%|########3 |15771/18822[03:00<00:34,87.62it/s] 88%|########8 |16646/18822[03:10<00:24,87.62it/s]100%|##########|18822/18822[03:34<00:00,87.75it/s]
21
[32m[0324 08:15:33 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 08:15:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.945
[32m[0324 08:15:33 @monitor.py:363][0m activation-summaries/output-rms: 0.034561
[32m[0324 08:15:33 @monitor.py:363][0m cross_entropy_loss: 2.0774
[32m[0324 08:15:33 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40478
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2371e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27037
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1717e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3835
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3367e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26614
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3689e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38831
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8327e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26494
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9754e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37867
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4517e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26619
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5367e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41454
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8378e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26912
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5794e-06
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4533
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.241
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95368
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.75201
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.79328
[32m[0324 08:15:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 08:15:33 @monitor.py:363][0m train-error-top1: 0.53225
[32m[0324 08:15:33 @monitor.py:363][0m val-error-top1: 0.60924
[32m[0324 08:15:33 @monitor.py:363][0m val-utt-error: 0.25295
[32m[0324 08:15:33 @monitor.py:363][0m validation_cost: 2.4536
[32m[0324 08:15:33 @monitor.py:363][0m wd_cost: 0.00019553
[32m[0324 08:15:33 @group.py:42][0m Callbacks took 215.239 sec in total. InferenceRunner: 214.581sec
[32m[0324 08:15:33 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9834/173481[03:00<49:55,54.63it/s]  6%|5         |10388/173481[03:10<49:45,54.63it/s] 11%|#1        |19741/173481[06:00<46:43,54.83it/s] 12%|#1        |20304/173481[06:10<46:33,54.83it/s] 17%|#7        |29614/173481[09:00<43:43,54.84it/s] 17%|#7        |30182/173481[09:10<43:33,54.84it/s] 23%|##2       |39420/173481[12:00<40:52,54.66it/s] 23%|##3       |39995/173481[12:10<40:42,54.66it/s] 28%|##8       |49131/173481[15:00<38:10,54.30it/s] 29%|##8       |49711/173481[15:10<37:59,54.30it/s] 34%|###3      |58903/173481[18:00<35:10,54.29it/s] 34%|###4      |59492/173481[18:10<34:59,54.29it/s] 40%|###9      |68720/173481[21:00<32:05,54.41it/s] 40%|###9      |69333/173481[21:11<31:54,54.41it/s] 45%|####5     |78618/173481[24:00<28:54,54.70it/s] 46%|####5     |79234/173481[24:11<28:43,54.70it/s] 51%|#####1    |88538/173481[27:00<25:47,54.90it/s] 51%|#####1    |89159/173481[27:11<25:35,54.90it/s] 57%|#####6    |98450/173481[30:00<22:44,54.98it/s] 57%|#####7    |99076/173481[30:11<22:33,54.98it/s] 62%|######2   |108252/173481[33:00<19:52,54.72it/s] 63%|######2   |108891/173481[33:11<19:40,54.72it/s] 68%|######8   |118121/173481[36:00<16:50,54.77it/s] 68%|######8   |118765/173481[36:11<16:39,54.77it/s] 74%|#######3  |128025/173481[39:00<13:48,54.89it/s] 74%|#######4  |128680/173481[39:12<13:36,54.89it/s] 80%|#######9  |137945/173481[42:00<10:46,55.00it/s] 80%|#######9  |138609/173481[42:12<10:34,55.00it/s] 85%|########5 |147849/173481[45:00<07:45,55.01it/s] 86%|########5 |148517/173481[45:12<07:33,55.01it/s] 91%|######### |157759/173481[48:00<04:45,55.03it/s] 91%|#########1|158448/173481[48:12<04:33,55.03it/s] 97%|#########6|167683/173481[51:00<01:45,55.08it/s] 97%|#########7|168369/173481[51:12<01:32,55.08it/s]100%|##########|173481/173481[52:46<00:00,54.79it/s]
[32m[0324 09:08:19 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:3166.04 sec.
[32m[0324 09:08:20 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-3990063.
  0%|          |0/18822[00:00<?,?it/s] 73%|#######3  |13815/18822[03:00<01:05,76.75it/s] 77%|#######7  |14560/18822[03:10<00:55,76.75it/s]100%|##########|18822/18822[04:07<00:00,76.09it/s]
22
[32m[0324 09:12:28 @monitor.py:363][0m QueueInput/queue_size: 49.996
[32m[0324 09:12:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.881
[32m[0324 09:12:28 @monitor.py:363][0m activation-summaries/output-rms: 0.036877
[32m[0324 09:12:28 @monitor.py:363][0m cross_entropy_loss: 2.036
[32m[0324 09:12:28 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40491
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2398e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27036
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1733e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38352
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3371e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26623
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3681e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38841
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8304e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26497
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9707e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37862
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4532e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26623
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5357e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41465
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8311e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26917
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5809e-06
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45472
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2411
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95687
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.75456
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.79609
[32m[0324 09:12:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 09:12:28 @monitor.py:363][0m train-error-top1: 0.52403
[32m[0324 09:12:28 @monitor.py:363][0m val-error-top1: 0.60192
[32m[0324 09:12:28 @monitor.py:363][0m val-utt-error: 0.24546
[32m[0324 09:12:28 @monitor.py:363][0m validation_cost: 2.4004
[32m[0324 09:12:28 @monitor.py:363][0m wd_cost: 3.9368e-05
[32m[0324 09:12:28 @group.py:42][0m Callbacks took 248.078 sec in total. InferenceRunner: 247.498sec
[32m[0324 09:12:28 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9919/173481[03:00<49:28,55.10it/s]  6%|6         |10475/173481[03:10<49:18,55.10it/s] 11%|#1        |19807/173481[06:00<46:33,55.01it/s] 12%|#1        |20377/173481[06:10<46:22,55.01it/s] 17%|#7        |29722/173481[09:00<43:31,55.05it/s] 17%|#7        |30290/173481[09:10<43:21,55.05it/s] 23%|##2       |39625/173481[12:00<40:32,55.03it/s] 23%|##3       |40216/173481[12:10<40:21,55.03it/s] 29%|##8       |49555/173481[15:00<37:29,55.10it/s] 29%|##8       |50139/173481[15:10<37:18,55.10it/s] 34%|###4      |59459/173481[18:00<34:30,55.06it/s] 35%|###4      |60060/173481[18:11<34:19,55.06it/s] 40%|###9      |69330/173481[21:00<31:35,54.95it/s] 40%|####      |69937/173481[21:11<31:24,54.95it/s] 46%|####5     |79235/173481[24:00<28:33,54.99it/s] 46%|####6     |79865/173481[24:11<28:22,54.99it/s] 51%|#####1    |89106/173481[27:00<25:36,54.91it/s] 52%|#####1    |89728/173481[27:11<25:25,54.91it/s] 57%|#####7    |98988/173481[30:00<22:36,54.90it/s] 57%|#####7    |99632/173481[30:11<22:25,54.90it/s] 63%|######2   |108863/173481[33:00<19:37,54.88it/s] 63%|######3   |109503/173481[33:11<19:25,54.88it/s] 68%|######8   |118660/173481[36:00<16:43,54.65it/s] 69%|######8   |119304/173481[36:11<16:31,54.65it/s] 74%|#######4  |128528/173481[39:00<13:41,54.74it/s] 74%|#######4  |129193/173481[39:12<13:29,54.74it/s] 80%|#######9  |138449/173481[42:00<10:37,54.93it/s] 80%|########  |139117/173481[42:12<10:25,54.93it/s] 85%|########5 |148312/173481[45:00<07:38,54.86it/s] 86%|########5 |148985/173481[45:12<07:26,54.86it/s] 91%|#########1|158190/173481[48:00<04:38,54.87it/s] 92%|#########1|158876/173481[48:12<04:26,54.87it/s] 97%|#########6|168057/173481[51:00<01:38,54.84it/s] 97%|#########7|168744/173481[51:12<01:26,54.84it/s]100%|##########|173481/173481[52:39<00:00,54.91it/s]
[32m[0324 10:05:07 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:3159.44 sec.
[32m[0324 10:05:07 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-4163544.
  0%|          |0/18822[00:00<?,?it/s] 87%|########6 |16286/18822[03:00<00:28,90.47it/s] 91%|#########1|17203/18822[03:10<00:17,90.47it/s]100%|##########|18822/18822[03:27<00:00,90.63it/s]
23
[32m[0324 10:08:35 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 10:08:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.981
[32m[0324 10:08:35 @monitor.py:363][0m activation-summaries/output-rms: 0.035482
[32m[0324 10:08:35 @monitor.py:363][0m cross_entropy_loss: 2.0539
[32m[0324 10:08:35 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40495
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2358e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27038
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1738e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3836
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3326e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26625
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3652e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38851
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8326e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9719e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37868
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4589e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26626
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5345e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41474
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8349e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26922
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5826e-06
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45613
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2412
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96007
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.75714
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.79893
[32m[0324 10:08:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 10:08:35 @monitor.py:363][0m train-error-top1: 0.52975
[32m[0324 10:08:35 @monitor.py:363][0m val-error-top1: 0.6097
[32m[0324 10:08:35 @monitor.py:363][0m val-utt-error: 0.25561
[32m[0324 10:08:35 @monitor.py:363][0m validation_cost: 2.4565
[32m[0324 10:08:35 @monitor.py:363][0m wd_cost: 3.9632e-05
[32m[0324 10:08:35 @group.py:42][0m Callbacks took 208.096 sec in total. InferenceRunner: 207.721sec
[32m[0324 10:08:35 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9861/173481[03:00<49:46,54.78it/s]  6%|5         |10394/173481[03:10<49:36,54.78it/s] 11%|#1        |19581/173481[06:00<47:09,54.39it/s] 12%|#1        |20146/173481[06:10<46:59,54.39it/s] 17%|#6        |29340/173481[09:00<44:14,54.30it/s] 17%|#7        |29916/173481[09:10<44:03,54.30it/s] 23%|##2       |39213/173481[12:00<41:00,54.57it/s] 23%|##2       |39795/173481[12:10<40:49,54.57it/s] 28%|##8       |49106/173481[15:00<37:51,54.77it/s] 29%|##8       |49700/173481[15:10<37:40,54.77it/s] 34%|###4      |59016/173481[18:00<34:44,54.91it/s] 34%|###4      |59625/173481[18:10<34:33,54.91it/s] 40%|###9      |68949/173481[21:00<31:39,55.04it/s] 40%|####      |69557/173481[21:11<31:28,55.04it/s] 45%|####5     |78855/173481[24:00<28:39,55.04it/s] 46%|####5     |79470/173481[24:11<28:28,55.04it/s] 51%|#####1    |88754/173481[27:00<25:40,55.01it/s] 52%|#####1    |89380/173481[27:11<25:28,55.01it/s] 57%|#####6    |98640/173481[30:00<22:41,54.97it/s] 57%|#####7    |99273/173481[30:11<22:30,54.97it/s] 63%|######2   |108510/173481[33:00<19:43,54.90it/s] 63%|######2   |109151/173481[33:11<19:31,54.90it/s] 68%|######8   |118360/173481[36:00<16:45,54.81it/s] 69%|######8   |119009/173481[36:11<16:33,54.81it/s] 74%|#######3  |128264/173481[39:00<13:43,54.91it/s] 74%|#######4  |128930/173481[39:12<13:31,54.91it/s] 80%|#######9  |138098/173481[42:00<10:45,54.77it/s] 80%|#######9  |138766/173481[42:12<10:33,54.77it/s] 85%|########5 |147940/173481[45:00<07:46,54.72it/s] 86%|########5 |148615/173481[45:12<07:34,54.72it/s] 91%|######### |157831/173481[48:00<04:45,54.83it/s] 91%|#########1|158509/173481[48:12<04:33,54.83it/s] 97%|#########6|167687/173481[51:00<01:45,54.79it/s] 97%|#########7|168380/173481[51:12<01:33,54.79it/s]100%|##########|173481/173481[52:45<00:00,54.80it/s]
[32m[0324 11:01:21 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:3165.96 sec.
[32m[0324 11:01:22 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-4337025.
  0%|          |0/18822[00:00<?,?it/s] 86%|########6 |16246/18822[03:00<00:28,90.25it/s] 91%|#########1|17157/18822[03:10<00:18,90.25it/s]100%|##########|18822/18822[04:21<00:00,72.06it/s]
24
[32m[0324 11:05:43 @monitor.py:363][0m QueueInput/queue_size: 49.996
[32m[0324 11:05:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.793
[32m[0324 11:05:43 @monitor.py:363][0m activation-summaries/output-rms: 0.034868
[32m[0324 11:05:43 @monitor.py:363][0m cross_entropy_loss: 2.1243
[32m[0324 11:05:43 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40504
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2382e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27039
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1728e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3837
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3325e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3665e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38852
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8304e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26498
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9709e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37872
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4605e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5361e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41474
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8348e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26929
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5824e-06
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45708
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2413
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96236
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.75906
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80105
[32m[0324 11:05:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 11:05:43 @monitor.py:363][0m train-error-top1: 0.54885
[32m[0324 11:05:43 @monitor.py:363][0m val-error-top1: 0.61249
[32m[0324 11:05:43 @monitor.py:363][0m val-utt-error: 0.2505
[32m[0324 11:05:43 @monitor.py:363][0m validation_cost: 2.4379
[32m[0324 11:05:43 @monitor.py:363][0m wd_cost: 7.9648e-06
[32m[0324 11:05:43 @group.py:42][0m Callbacks took 261.923 sec in total. InferenceRunner: 261.327sec
[32m[0324 11:05:43 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9837/173481[03:00<49:54,54.65it/s]  6%|5         |10393/173481[03:10<49:44,54.65it/s] 11%|#1        |19716/173481[06:00<46:47,54.76it/s] 12%|#1        |20278/173481[06:10<46:37,54.76it/s] 17%|#7        |29623/173481[09:00<43:40,54.90it/s] 17%|#7        |30200/173481[09:10<43:29,54.90it/s] 23%|##2       |39446/173481[12:00<40:48,54.73it/s] 23%|##3       |40026/173481[12:10<40:38,54.73it/s] 28%|##8       |49298/173481[15:00<37:48,54.73it/s] 29%|##8       |49889/173481[15:10<37:38,54.73it/s] 34%|###4      |59194/173481[18:00<34:43,54.85it/s] 34%|###4      |59787/173481[18:10<34:32,54.85it/s] 40%|###9      |69080/173481[21:00<31:42,54.89it/s] 40%|####      |69696/173481[21:11<31:30,54.89it/s] 46%|####5     |78970/173481[24:00<28:41,54.92it/s] 46%|####5     |79584/173481[24:11<28:29,54.92it/s] 51%|#####1    |88790/173481[27:00<25:47,54.73it/s] 52%|#####1    |89410/173481[27:11<25:35,54.73it/s] 57%|#####6    |98581/173481[30:00<22:52,54.56it/s] 57%|#####7    |99198/173481[30:11<22:41,54.56it/s] 62%|######2   |108343/173481[33:00<19:57,54.40it/s] 63%|######2   |108982/173481[33:11<19:45,54.40it/s] 68%|######8   |118127/173481[36:00<16:58,54.37it/s] 68%|######8   |118768/173481[36:11<16:46,54.37it/s] 74%|#######3  |127918/173481[39:00<13:57,54.38it/s] 74%|#######4  |128572/173481[39:12<13:45,54.38it/s] 79%|#######9  |137659/173481[42:00<11:00,54.25it/s] 80%|#######9  |138333/173481[42:12<10:47,54.25it/s] 85%|########5 |147567/173481[45:00<07:54,54.64it/s] 85%|########5 |148234/173481[45:12<07:42,54.64it/s] 91%|######### |157425/173481[48:00<04:53,54.70it/s] 91%|#########1|158106/173481[48:12<04:41,54.70it/s] 96%|#########6|167186/173481[51:00<01:55,54.46it/s] 97%|#########6|167882/173481[51:12<01:42,54.46it/s]100%|##########|173481/173481[52:55<00:00,54.63it/s]
[32m[0324 11:58:39 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:3175.82 sec.
[32m[0324 11:58:39 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s] 80%|########  |15138/18822[03:00<00:43,84.10it/s] 85%|########4 |15993/18822[03:10<00:33,84.10it/s]100%|##########|18822/18822[03:43<00:00,84.23it/s]
25
[32m[0324 12:02:23 @monitor.py:363][0m QueueInput/queue_size: 49.996
[32m[0324 12:02:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.913
[32m[0324 12:02:23 @monitor.py:363][0m activation-summaries/output-rms: 0.035958
[32m[0324 12:02:23 @monitor.py:363][0m cross_entropy_loss: 1.9643
[32m[0324 12:02:23 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40516
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.239e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1734e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38373
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3334e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26624
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3657e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38855
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8314e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9728e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37881
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4629e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26627
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5371e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41483
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8329e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26929
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5839e-06
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45783
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2413
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96371
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76032
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80241
[32m[0324 12:02:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 12:02:23 @monitor.py:363][0m train-error-top1: 0.49619
[32m[0324 12:02:23 @monitor.py:363][0m val-error-top1: 0.61668
[32m[0324 12:02:23 @monitor.py:363][0m val-utt-error: 0.25842
[32m[0324 12:02:23 @monitor.py:363][0m validation_cost: 2.4791
[32m[0324 12:02:23 @monitor.py:363][0m wd_cost: 7.9894e-06
[32m[0324 12:02:23 @group.py:42][0m Callbacks took 223.911 sec in total. InferenceRunner: 223.485sec
[32m[0324 12:02:23 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9871/173481[03:00<49:43,54.84it/s]  6%|6         |10421/173481[03:10<49:33,54.84it/s] 11%|#1        |19767/173481[06:00<46:39,54.90it/s] 12%|#1        |20336/173481[06:10<46:29,54.90it/s] 17%|#7        |29631/173481[09:00<43:42,54.85it/s] 17%|#7        |30195/173481[09:10<43:32,54.85it/s] 22%|##2       |38865/173481[12:00<42:19,53.01it/s] 23%|##2       |39409/173481[12:10<42:09,53.01it/s] 28%|##7       |47886/173481[15:00<40:37,51.52it/s] 28%|##7       |48449/173481[15:10<40:26,51.52it/s] 33%|###3      |57435/173481[18:00<36:59,52.27it/s] 33%|###3      |58021/173481[18:10<36:48,52.27it/s] 39%|###8      |66956/173481[21:00<33:45,52.58it/s] 39%|###8      |67550/173481[21:11<33:34,52.58it/s] 44%|####4     |76616/173481[24:00<30:23,53.12it/s] 45%|####4     |77217/173481[24:11<30:12,53.12it/s] 50%|####9     |86267/173481[27:00<27:14,53.37it/s] 50%|#####     |86871/173481[27:11<27:02,53.37it/s] 55%|#####5    |95989/173481[30:00<24:03,53.69it/s] 56%|#####5    |96609/173481[30:11<23:51,53.69it/s] 61%|######    |105645/173481[33:00<21:04,53.66it/s] 61%|######1   |106279/173481[33:11<20:52,53.66it/s] 67%|######6   |115400/173481[36:00<17:57,53.93it/s] 67%|######6   |116044/173481[36:11<17:45,53.93it/s] 72%|#######2  |125043/173481[39:00<15:01,53.75it/s] 72%|#######2  |125685/173481[39:12<14:49,53.75it/s] 78%|#######7  |134596/173481[42:00<12:08,53.40it/s] 78%|#######7  |135231/173481[42:12<11:56,53.40it/s] 83%|########3 |144025/173481[45:00<09:16,52.89it/s] 83%|########3 |144683/173481[45:12<09:04,52.89it/s] 89%|########8 |153575/173481[48:00<06:15,52.97it/s] 89%|########8 |154256/173481[48:12<06:02,52.97it/s] 94%|#########4|163257/173481[51:00<03:11,53.37it/s] 94%|#########4|163933/173481[51:12<02:58,53.37it/s]100%|#########9|173024/173481[54:00<00:08,53.81it/s]100%|##########|173481/173481[54:09<00:00,53.39it/s]
[32m[0324 12:56:32 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:3249.42 sec.
[32m[0324 12:56:33 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-4683987.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######8  |14766/18822[03:00<00:49,82.03it/s] 83%|########3 |15637/18822[03:10<00:38,82.03it/s]100%|##########|18822/18822[03:49<00:00,82.09it/s]
26
[32m[0324 13:00:22 @monitor.py:363][0m QueueInput/queue_size: 25.051
[32m[0324 13:00:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.974
[32m[0324 13:00:22 @monitor.py:363][0m activation-summaries/output-rms: 0.033765
[32m[0324 13:00:22 @monitor.py:363][0m cross_entropy_loss: 2.1806
[32m[0324 13:00:22 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40522
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2427e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1742e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38372
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3362e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26623
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3654e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38851
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8339e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.265
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9734e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37881
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4655e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5374e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41491
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8334e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5828e-06
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45849
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2413
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96521
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76168
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80392
[32m[0324 13:00:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 13:00:22 @monitor.py:363][0m train-error-top1: 0.55225
[32m[0324 13:00:22 @monitor.py:363][0m val-error-top1: 0.61393
[32m[0324 13:00:22 @monitor.py:363][0m val-utt-error: 0.26071
[32m[0324 13:00:22 @monitor.py:363][0m validation_cost: 2.4597
[32m[0324 13:00:22 @monitor.py:363][0m wd_cost: 8.016e-06
[32m[0324 13:00:22 @group.py:42][0m Callbacks took 229.848 sec in total. InferenceRunner: 229.340sec
[32m[0324 13:00:22 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9857/173481[03:00<49:48,54.75it/s]  6%|6         |10415/173481[03:10<49:38,54.75it/s] 11%|#1        |19659/173481[06:00<46:57,54.60it/s] 12%|#1        |20223/173481[06:10<46:46,54.60it/s] 17%|#6        |29059/173481[09:00<45:05,53.38it/s] 17%|#7        |29579/173481[09:10<44:55,53.38it/s] 22%|##2       |38333/173481[12:00<42:57,52.43it/s] 22%|##2       |38891/173481[12:10<42:46,52.43it/s] 28%|##7       |47805/173481[15:00<39:52,52.53it/s] 28%|##7       |48377/173481[15:10<39:41,52.53it/s] 33%|###2      |56935/173481[18:00<37:38,51.61it/s] 33%|###3      |57513/173481[18:10<37:27,51.61it/s] 38%|###8      |66593/173481[21:00<33:51,52.61it/s] 39%|###8      |67206/173481[21:11<33:40,52.61it/s] 44%|####4     |76456/173481[24:00<30:07,53.68it/s] 44%|####4     |77059/173481[24:11<29:56,53.68it/s] 50%|####9     |86290/173481[27:00<26:50,54.15it/s] 50%|#####     |86910/173481[27:11<26:38,54.15it/s] 55%|#####5    |96167/173481[30:00<23:38,54.51it/s] 56%|#####5    |96792/173481[30:11<23:26,54.51it/s] 61%|######1   |106062/173481[33:00<20:31,54.74it/s] 62%|######1   |106694/173481[33:11<20:20,54.74it/s] 67%|######6   |115919/173481[36:00<17:31,54.75it/s] 67%|######7   |116563/173481[36:11<17:19,54.75it/s] 72%|#######2  |125766/173481[39:00<14:31,54.73it/s] 73%|#######2  |126419/173481[39:12<14:19,54.73it/s] 78%|#######8  |135630/173481[42:00<11:31,54.76it/s] 79%|#######8  |136292/173481[42:12<11:19,54.76it/s] 84%|########3 |145533/173481[45:00<08:29,54.89it/s] 84%|########4 |146198/173481[45:12<08:17,54.89it/s] 90%|########9 |155351/173481[48:00<05:31,54.72it/s] 90%|########9 |156032/173481[48:12<05:18,54.72it/s] 95%|#########5|165250/173481[51:00<02:30,54.85it/s] 96%|#########5|165932/173481[51:12<02:17,54.85it/s]100%|##########|173481/173481[53:30<00:00,54.04it/s]
[32m[0324 13:53:53 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:3210.21 sec.
[32m[0324 13:53:53 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-4857468.
  0%|          |0/18822[00:00<?,?it/s] 89%|########9 |16777/18822[03:00<00:21,93.20it/s] 94%|#########4|17749/18822[03:10<00:11,93.20it/s]100%|##########|18822/18822[03:21<00:00,93.42it/s]
27
[32m[0324 13:57:14 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 13:57:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.151
[32m[0324 13:57:14 @monitor.py:363][0m activation-summaries/output-rms: 0.036154
[32m[0324 13:57:14 @monitor.py:363][0m cross_entropy_loss: 1.9187
[32m[0324 13:57:14 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40536
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2419e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27041
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1745e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3356e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3667e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38867
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8364e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9733e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37887
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4657e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26627
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5373e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41504
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8328e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5837e-06
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45925
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2415
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.9658
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76232
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.8046
[32m[0324 13:57:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 13:57:14 @monitor.py:363][0m train-error-top1: 0.50087
[32m[0324 13:57:14 @monitor.py:363][0m val-error-top1: 0.61192
[32m[0324 13:57:14 @monitor.py:363][0m val-utt-error: 0.25651
[32m[0324 13:57:14 @monitor.py:363][0m validation_cost: 2.4813
[32m[0324 13:57:14 @monitor.py:363][0m wd_cost: 1.6058e-06
[32m[0324 13:57:14 @group.py:42][0m Callbacks took 201.912 sec in total. InferenceRunner: 201.527sec
[32m[0324 13:57:14 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9842/173481[03:00<49:53,54.67it/s]  6%|5         |10393/173481[03:10<49:42,54.67it/s] 11%|#1        |19635/173481[06:00<47:00,54.54it/s] 12%|#1        |20175/173481[06:10<46:51,54.54it/s] 17%|#6        |29331/173481[09:00<44:19,54.20it/s] 17%|#7        |29908/173481[09:10<44:09,54.20it/s] 23%|##2       |39190/173481[12:00<41:04,54.48it/s] 23%|##2       |39764/173481[12:10<40:54,54.48it/s] 28%|##8       |49099/173481[15:00<37:51,54.76it/s] 29%|##8       |49690/173481[15:10<37:40,54.76it/s] 34%|###4      |59084/173481[18:00<34:35,55.11it/s] 34%|###4      |59687/173481[18:10<34:24,55.11it/s] 40%|###9      |69039/173481[21:00<31:31,55.21it/s] 40%|####      |69653/173481[21:11<31:20,55.21it/s] 46%|####5     |79013/173481[24:00<28:28,55.31it/s] 46%|####5     |79626/173481[24:11<28:16,55.31it/s] 51%|#####1    |88960/173481[27:00<25:28,55.28it/s] 52%|#####1    |89586/173481[27:11<25:17,55.28it/s] 57%|#####7    |98892/173481[30:00<22:30,55.23it/s] 57%|#####7    |99530/173481[30:11<22:18,55.23it/s] 63%|######2   |108870/173481[33:00<19:27,55.33it/s] 63%|######3   |109511/173481[33:11<19:16,55.33it/s] 68%|######8   |118811/173481[36:00<16:29,55.28it/s] 69%|######8   |119452/173481[36:11<16:17,55.28it/s] 74%|#######4  |128756/173481[39:00<13:29,55.26it/s] 75%|#######4  |129410/173481[39:11<13:17,55.26it/s] 80%|#######9  |138745/173481[42:00<10:27,55.38it/s] 80%|########  |139413/173481[42:12<10:15,55.38it/s] 86%|########5 |148694/173481[45:00<07:28,55.32it/s] 86%|########6 |149358/173481[45:12<07:16,55.32it/s] 91%|#########1|158637/173481[48:00<04:28,55.28it/s] 92%|#########1|159317/173481[48:12<04:16,55.28it/s] 97%|#########7|168554/173481[51:00<01:29,55.18it/s] 98%|#########7|169236/173481[51:12<01:16,55.18it/s]100%|##########|173481/173481[52:30<00:00,55.06it/s]
[32m[0324 14:49:45 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:3150.98 sec.
[32m[0324 14:49:46 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-5030949.
  0%|          |0/18822[00:00<?,?it/s] 91%|######### |17124/18822[03:00<00:17,95.13it/s] 96%|#########6|18100/18822[03:10<00:07,95.13it/s]100%|##########|18822/18822[03:17<00:00,95.21it/s]
28
[32m[0324 14:53:03 @monitor.py:363][0m QueueInput/queue_size: 46.61
[32m[0324 14:53:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.321
[32m[0324 14:53:03 @monitor.py:363][0m activation-summaries/output-rms: 0.034556
[32m[0324 14:53:03 @monitor.py:363][0m cross_entropy_loss: 2.1749
[32m[0324 14:53:03 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40533
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2417e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.174e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3838
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26627
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.366e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38867
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8362e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9741e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37887
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4654e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26627
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5372e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41505
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.834e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.583e-06
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45957
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2415
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96621
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76288
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80519
[32m[0324 14:53:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 14:53:03 @monitor.py:363][0m train-error-top1: 0.55494
[32m[0324 14:53:03 @monitor.py:363][0m val-error-top1: 0.62201
[32m[0324 14:53:03 @monitor.py:363][0m val-utt-error: 0.27973
[32m[0324 14:53:03 @monitor.py:363][0m validation_cost: 2.5331
[32m[0324 14:53:03 @monitor.py:363][0m wd_cost: 1.6077e-06
[32m[0324 14:53:03 @group.py:42][0m Callbacks took 197.939 sec in total. InferenceRunner: 197.707sec
[32m[0324 14:53:03 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9521/173481[03:00<51:39,52.89it/s]  6%|5         |10060/173481[03:10<51:29,52.89it/s] 11%|#         |19043/173481[06:00<48:39,52.89it/s] 11%|#1        |19596/173481[06:10<48:29,52.89it/s] 16%|#6        |28588/173481[09:00<45:35,52.96it/s] 17%|#6        |29139/173481[09:10<45:25,52.96it/s] 22%|##2       |38198/173481[12:00<42:24,53.17it/s] 22%|##2       |38756/173481[12:10<42:13,53.17it/s] 28%|##7       |47758/173481[15:00<39:25,53.14it/s] 28%|##7       |48328/173481[15:10<39:15,53.14it/s] 33%|###3      |57327/173481[18:00<36:25,53.15it/s] 33%|###3      |57909/173481[18:11<36:14,53.15it/s] 39%|###8      |66876/173481[21:00<33:27,53.10it/s] 39%|###8      |67467/173481[21:11<33:16,53.10it/s] 44%|####4     |76406/173481[24:00<30:30,53.02it/s] 44%|####4     |77012/173481[24:11<30:19,53.02it/s] 50%|####9     |85938/173481[27:00<27:32,52.98it/s] 50%|####9     |86536/173481[27:11<27:20,52.98it/s] 55%|#####5    |95469/173481[30:00<24:32,52.97it/s] 55%|#####5    |96074/173481[30:11<24:21,52.97it/s] 61%|######    |104961/173481[33:00<21:36,52.85it/s] 61%|######    |105583/173481[33:11<21:24,52.85it/s] 66%|######5   |114447/173481[36:00<18:38,52.77it/s] 66%|######6   |115078/173481[36:12<18:26,52.77it/s] 71%|#######1  |123941/173481[39:00<15:38,52.76it/s] 72%|#######1  |124580/173481[39:12<15:26,52.76it/s] 77%|#######6  |133460/173481[42:00<12:37,52.82it/s] 77%|#######7  |134099/173481[42:12<12:25,52.82it/s] 82%|########2 |142980/173481[45:00<09:37,52.85it/s] 83%|########2 |143628/173481[45:12<09:24,52.85it/s] 88%|########7 |152471/173481[48:00<06:38,52.79it/s] 88%|########8 |153124/173481[48:12<06:25,52.79it/s] 93%|#########3|161966/173481[51:00<03:38,52.77it/s] 94%|#########3|162629/173481[51:12<03:25,52.77it/s] 99%|#########8|171453/173481[54:00<00:38,52.73it/s] 99%|#########9|172116/173481[54:13<00:25,52.73it/s]100%|##########|173481/173481[54:39<00:00,52.90it/s]
[32m[0324 15:47:43 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:3279.29 sec.
[32m[0324 15:47:43 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-5204430.
  0%|          |0/18822[00:00<?,?it/s] 57%|#####6    |10639/18822[03:00<02:18,59.10it/s] 61%|######    |11462/18822[03:11<02:04,59.10it/s]100%|##########|18822/18822[04:37<00:00,67.84it/s]
29
[32m[0324 15:52:21 @monitor.py:363][0m QueueInput/queue_size: 49.996
[32m[0324 15:52:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.003
[32m[0324 15:52:21 @monitor.py:363][0m activation-summaries/output-rms: 0.034408
[32m[0324 15:52:21 @monitor.py:363][0m cross_entropy_loss: 2.1534
[32m[0324 15:52:21 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40535
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1738e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38378
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3378e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3662e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38866
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9736e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37888
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4659e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26629
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5372e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41503
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8338e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26928
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5829e-06
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45972
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96661
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76344
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80579
[32m[0324 15:52:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 15:52:21 @monitor.py:363][0m train-error-top1: 0.55712
[32m[0324 15:52:21 @monitor.py:363][0m val-error-top1: 0.61546
[32m[0324 15:52:21 @monitor.py:363][0m val-utt-error: 0.25353
[32m[0324 15:52:21 @monitor.py:363][0m validation_cost: 2.447
[32m[0324 15:52:21 @monitor.py:363][0m wd_cost: 1.6096e-06
[32m[0324 15:52:21 @group.py:42][0m Callbacks took 277.905 sec in total. InferenceRunner: 277.485sec
[32m[0324 15:52:21 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9489/173481[03:00<51:51,52.71it/s]  6%|5         |10019/173481[03:10<51:41,52.71it/s] 11%|#         |18996/173481[06:00<48:47,52.76it/s] 11%|#1        |19533/173481[06:10<48:37,52.76it/s] 16%|#6        |28485/173481[09:00<45:49,52.74it/s] 17%|#6        |29029/173481[09:10<45:38,52.74it/s] 22%|##1       |37991/173481[12:00<42:47,52.77it/s] 22%|##2       |38542/173481[12:10<42:36,52.77it/s] 27%|##7       |47460/173481[15:00<39:51,52.69it/s] 28%|##7       |48027/173481[15:10<39:41,52.69it/s] 33%|###2      |56990/173481[18:00<36:45,52.81it/s] 33%|###3      |57558/173481[18:10<36:34,52.81it/s] 38%|###8      |66481/173481[21:00<33:47,52.77it/s] 39%|###8      |67060/173481[21:11<33:36,52.77it/s] 44%|####3     |75953/173481[24:00<30:50,52.69it/s] 44%|####4     |76542/173481[24:11<30:39,52.69it/s] 49%|####9     |85447/173481[27:00<27:49,52.72it/s] 50%|####9     |86044/173481[27:11<27:38,52.72it/s] 55%|#####4    |94859/173481[30:00<24:57,52.50it/s] 55%|#####4    |95385/173481[30:11<24:47,52.50it/s] 60%|#####9    |103261/173481[33:00<23:40,49.42it/s] 60%|#####9    |103790/173481[33:11<23:30,49.42it/s] 64%|######4   |111892/173481[36:00<21:05,48.67it/s] 65%|######4   |112448/173481[36:11<20:54,48.67it/s] 70%|######9   |120841/173481[39:00<17:50,49.19it/s] 70%|#######   |121454/173481[39:11<17:37,49.19it/s] 75%|#######4  |129731/173481[42:00<14:47,49.29it/s] 75%|#######5  |130295/173481[42:12<14:36,49.29it/s] 80%|#######9  |138456/173481[45:00<11:56,48.88it/s] 80%|########  |139066/173481[45:12<11:44,48.88it/s] 85%|########4 |147075/173481[48:00<09:05,48.37it/s] 85%|########5 |147664/173481[48:12<08:53,48.37it/s] 90%|######### |156189/173481[51:00<05:49,49.48it/s] 90%|######### |156806/173481[51:12<05:37,49.48it/s] 95%|#########5|164873/173481[54:00<02:56,48.85it/s] 95%|#########5|165456/173481[54:12<02:44,48.85it/s]100%|#########9|173096/173481[57:00<00:08,47.21it/s]100%|##########|173481/173481[57:09<00:00,50.59it/s]
[32m[0324 16:49:30 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:3429.33 sec.
[32m[0324 16:49:30 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-5377911.
  0%|          |0/18822[00:00<?,?it/s] 85%|########4 |15939/18822[03:00<00:32,88.55it/s] 90%|########9 |16874/18822[03:10<00:22,88.55it/s]100%|##########|18822/18822[03:31<00:00,88.85it/s]
30
[32m[0324 16:53:03 @monitor.py:363][0m QueueInput/queue_size: 1.4087
[32m[0324 16:53:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.967
[32m[0324 16:53:03 @monitor.py:363][0m activation-summaries/output-rms: 0.033994
[32m[0324 16:53:03 @monitor.py:363][0m cross_entropy_loss: 2.1209
[32m[0324 16:53:03 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40536
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2418e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1732e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38378
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.337e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38865
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8348e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9736e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37889
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4664e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5373e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41503
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8348e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26928
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5827e-06
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45982
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.9668
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76366
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80601
[32m[0324 16:53:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 16:53:03 @monitor.py:363][0m train-error-top1: 0.53997
[32m[0324 16:53:03 @monitor.py:363][0m val-error-top1: 0.60805
[32m[0324 16:53:03 @monitor.py:363][0m val-utt-error: 0.25476
[32m[0324 16:53:03 @monitor.py:363][0m validation_cost: 2.4396
[32m[0324 16:53:03 @monitor.py:363][0m wd_cost: 3.2206e-07
[32m[0324 16:53:03 @group.py:42][0m Callbacks took 212.509 sec in total. InferenceRunner: 211.996sec
[32m[0324 16:53:03 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9091/173481[03:00<54:15,50.50it/s]  6%|5         |9572/173481[03:10<54:05,50.50it/s] 10%|#         |17884/173481[06:00<52:13,49.66it/s] 11%|#         |18376/173481[06:10<52:03,49.66it/s] 15%|#5        |26430/173481[09:00<50:29,48.54it/s] 16%|#5        |26901/173481[09:10<50:19,48.54it/s] 20%|#9        |34608/173481[12:00<49:18,46.94it/s] 20%|##        |35034/173481[12:10<49:09,46.94it/s] 25%|##4       |42542/173481[15:00<48:00,45.46it/s] 25%|##4       |43025/173481[15:10<47:49,45.46it/s] 29%|##9       |50648/173481[18:00<45:14,45.24it/s] 29%|##9       |51117/173481[18:10<45:04,45.24it/s] 34%|###4      |59126/173481[21:00<41:17,46.15it/s] 34%|###4      |59674/173481[21:11<41:05,46.15it/s] 39%|###8      |67570/173481[24:00<37:56,46.53it/s] 39%|###9      |68099/173481[24:11<37:44,46.53it/s] 44%|####4     |76476/173481[27:00<33:42,47.96it/s] 44%|####4     |76998/173481[27:11<33:31,47.96it/s] 49%|####9     |85284/173481[30:00<30:20,48.44it/s] 49%|####9     |85819/173481[30:11<30:09,48.44it/s] 54%|#####4    |94266/173481[33:00<26:51,49.16it/s] 55%|#####4    |94849/173481[33:11<26:39,49.16it/s] 59%|#####9    |103129/173481[36:00<23:50,49.20it/s] 60%|#####9    |103736/173481[36:11<23:37,49.20it/s] 65%|######4   |112195/173481[39:00<20:31,49.77it/s] 65%|######5   |112801/173481[39:11<20:19,49.77it/s] 70%|#######   |121450/173481[42:00<17:08,50.58it/s] 70%|#######   |122085/173481[42:12<16:56,50.58it/s] 75%|#######5  |130692/173481[45:00<13:59,50.96it/s] 76%|#######5  |131307/173481[45:12<13:47,50.96it/s] 81%|########  |140144/173481[48:00<10:44,51.72it/s] 81%|########1 |140807/173481[48:12<10:31,51.72it/s] 86%|########6 |149880/173481[51:00<07:26,52.88it/s] 87%|########6 |150564/173481[51:12<07:13,52.88it/s] 92%|#########2|159614/173481[54:00<04:19,53.47it/s] 92%|#########2|160278/173481[54:12<04:06,53.47it/s] 98%|#########7|169412/173481[57:00<01:15,53.95it/s] 98%|#########8|170112/173481[57:12<01:02,53.95it/s]100%|##########|173481/173481[58:14<00:00,49.64it/s]
[32m[0324 17:51:17 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:3494.80 sec.
[32m[0324 17:51:18 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######7  |14635/18822[03:00<00:51,81.30it/s] 82%|########2 |15461/18822[03:10<00:41,81.30it/s]100%|##########|18822/18822[03:52<00:00,80.83it/s]
31
[32m[0324 17:55:11 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 17:55:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.067
[32m[0324 17:55:11 @monitor.py:363][0m activation-summaries/output-rms: 0.035462
[32m[0324 17:55:11 @monitor.py:363][0m cross_entropy_loss: 1.9836
[32m[0324 17:55:11 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40537
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2422e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27043
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1732e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38378
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3377e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.366e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38864
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8357e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9741e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37891
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4667e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5372e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41506
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8355e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5824e-06
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45998
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96699
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.7639
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80625
[32m[0324 17:55:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 17:55:11 @monitor.py:363][0m train-error-top1: 0.50894
[32m[0324 17:55:11 @monitor.py:363][0m val-error-top1: 0.60017
[32m[0324 17:55:11 @monitor.py:363][0m val-utt-error: 0.23882
[32m[0324 17:55:11 @monitor.py:363][0m validation_cost: 2.3987
[32m[0324 17:55:11 @monitor.py:363][0m wd_cost: 3.2223e-07
[32m[0324 17:55:11 @group.py:42][0m Callbacks took 233.327 sec in total. InferenceRunner: 232.885sec
[32m[0324 17:55:11 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9898/173481[03:00<49:35,54.98it/s]  6%|6         |10449/173481[03:10<49:25,54.98it/s] 11%|#1        |19758/173481[06:00<46:41,54.88it/s] 12%|#1        |20320/173481[06:10<46:30,54.88it/s] 17%|#7        |29572/173481[09:00<43:50,54.70it/s] 17%|#7        |30113/173481[09:10<43:41,54.70it/s] 23%|##2       |39170/173481[12:00<41:27,54.00it/s] 23%|##2       |39741/173481[12:10<41:16,54.00it/s] 28%|##8       |48830/173481[15:00<38:35,53.83it/s] 28%|##8       |49399/173481[15:10<38:25,53.83it/s] 34%|###3      |58450/173481[18:00<35:44,53.64it/s] 34%|###4      |59021/173481[18:10<35:34,53.64it/s] 39%|###9      |68136/173481[21:00<32:40,53.72it/s] 40%|###9      |68700/173481[21:11<32:30,53.72it/s] 45%|####4     |77910/173481[24:00<29:29,54.01it/s] 45%|####5     |78525/173481[24:11<29:18,54.01it/s] 51%|#####     |87800/173481[27:00<26:12,54.47it/s] 51%|#####     |88421/173481[27:11<26:01,54.47it/s] 56%|#####6    |97674/173481[30:00<23:06,54.66it/s] 57%|#####6    |98302/173481[30:11<22:55,54.66it/s] 62%|######2   |107575/173481[33:00<20:01,54.83it/s] 62%|######2   |108211/173481[33:11<19:50,54.83it/s] 68%|######7   |117466/173481[36:00<17:00,54.89it/s] 68%|######8   |118113/173481[36:11<16:48,54.89it/s] 73%|#######3  |127374/173481[39:00<13:58,54.97it/s] 74%|#######3  |128025/173481[39:12<13:46,54.97it/s] 79%|#######9  |137245/173481[42:00<11:00,54.90it/s] 79%|#######9  |137905/173481[42:12<10:48,54.90it/s] 85%|########4 |147147/173481[45:00<07:59,54.95it/s] 85%|########5 |147813/173481[45:12<07:47,54.95it/s] 91%|######### |157057/173481[48:00<04:58,55.00it/s] 91%|######### |157743/173481[48:12<04:46,55.00it/s] 96%|#########6|167053/173481[51:00<01:56,55.27it/s] 97%|#########6|167722/173481[51:12<01:44,55.27it/s]100%|##########|173481/173481[52:59<00:00,54.57it/s]
[32m[0324 18:48:10 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:3179.20 sec.
[32m[0324 18:48:11 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-5724873.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14850/18822[03:00<00:48,82.50it/s] 83%|########3 |15673/18822[03:10<00:38,82.50it/s]100%|##########|18822/18822[04:42<00:00,66.65it/s]
32
[32m[0324 18:52:53 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 18:52:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.11
[32m[0324 18:52:53 @monitor.py:363][0m activation-summaries/output-rms: 0.035166
[32m[0324 18:52:53 @monitor.py:363][0m cross_entropy_loss: 2.0757
[32m[0324 18:52:53 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4054
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38378
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3371e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3659e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38866
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8351e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.974e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.3789
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4669e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26629
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5371e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41507
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8355e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4601
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96713
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76407
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80642
[32m[0324 18:52:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 18:52:53 @monitor.py:363][0m train-error-top1: 0.53943
[32m[0324 18:52:53 @monitor.py:363][0m val-error-top1: 0.60947
[32m[0324 18:52:53 @monitor.py:363][0m val-utt-error: 0.25316
[32m[0324 18:52:53 @monitor.py:363][0m validation_cost: 2.4426
[32m[0324 18:52:53 @monitor.py:363][0m wd_cost: 3.2236e-07
[32m[0324 18:52:53 @group.py:42][0m Callbacks took 283.299 sec in total. InferenceRunner: 282.572sec
[32m[0324 18:52:53 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9947/173481[03:00<49:19,55.26it/s]  6%|6         |10503/173481[03:10<49:09,55.26it/s] 11%|#1        |19856/173481[06:00<46:25,55.15it/s] 12%|#1        |20416/173481[06:10<46:15,55.15it/s] 17%|#7        |29671/173481[09:00<43:42,54.84it/s] 17%|#7        |30253/173481[09:10<43:31,54.84it/s] 23%|##2       |39574/173481[12:00<40:37,54.93it/s] 23%|##3       |40161/173481[12:10<40:27,54.93it/s] 29%|##8       |49516/173481[15:00<37:30,55.08it/s] 29%|##8       |50112/173481[15:10<37:19,55.08it/s] 34%|###4      |59433/173481[18:00<34:30,55.09it/s] 35%|###4      |60040/173481[18:11<34:19,55.09it/s] 40%|####      |69414/173481[21:00<31:23,55.26it/s] 40%|####      |70019/173481[21:11<31:12,55.26it/s] 46%|####5     |79218/173481[24:00<28:38,54.86it/s] 46%|####6     |79833/173481[24:11<28:27,54.86it/s] 51%|#####1    |89131/173481[27:00<25:34,54.97it/s] 52%|#####1    |89758/173481[27:11<25:23,54.97it/s] 57%|#####7    |99036/173481[30:00<22:33,55.00it/s] 57%|#####7    |99669/173481[30:11<22:22,55.00it/s] 63%|######2   |108933/173481[33:00<19:33,54.99it/s] 63%|######3   |109586/173481[33:11<19:21,54.99it/s] 69%|######8   |118921/173481[36:00<16:27,55.24it/s] 69%|######8   |119573/173481[36:11<16:15,55.24it/s] 74%|#######4  |128848/173481[39:00<13:28,55.19it/s] 75%|#######4  |129505/173481[39:12<13:16,55.19it/s] 80%|#######9  |138767/173481[42:00<10:29,55.15it/s] 80%|########  |139431/173481[42:12<10:17,55.15it/s] 86%|########5 |148707/173481[45:00<07:28,55.18it/s] 86%|########6 |149388/173481[45:12<07:16,55.18it/s] 91%|#########1|158677/173481[48:00<04:27,55.28it/s] 92%|#########1|159370/173481[48:12<04:15,55.28it/s] 97%|#########7|168589/173481[51:00<01:28,55.17it/s] 98%|#########7|169280/173481[51:12<01:16,55.17it/s]100%|##########|173481/173481[52:29<00:00,55.08it/s]
[32m[0324 19:45:23 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:3149.73 sec.
[32m[0324 19:45:23 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s] 91%|#########1|17190/18822[03:00<00:17,95.50it/s] 97%|#########6|18241/18822[03:10<00:06,95.50it/s]100%|##########|18822/18822[03:15<00:00,96.21it/s]
33
[32m[0324 19:48:39 @monitor.py:363][0m QueueInput/queue_size: 49.994
[32m[0324 19:48:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.002
[32m[0324 19:48:39 @monitor.py:363][0m activation-summaries/output-rms: 0.035415
[32m[0324 19:48:39 @monitor.py:363][0m cross_entropy_loss: 2.0627
[32m[0324 19:48:39 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4054
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2415e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.173e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38378
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3372e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.366e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38867
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8353e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.974e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37891
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4669e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26629
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5371e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41508
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8353e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5826e-06
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46012
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96721
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76415
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.8065
[32m[0324 19:48:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 19:48:39 @monitor.py:363][0m train-error-top1: 0.53232
[32m[0324 19:48:39 @monitor.py:363][0m val-error-top1: 0.61445
[32m[0324 19:48:39 @monitor.py:363][0m val-utt-error: 0.26745
[32m[0324 19:48:39 @monitor.py:363][0m validation_cost: 2.474
[32m[0324 19:48:39 @monitor.py:363][0m wd_cost: 6.4482e-08
[32m[0324 19:48:39 @group.py:42][0m Callbacks took 195.933 sec in total. InferenceRunner: 195.647sec
[32m[0324 19:48:39 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9915/173481[03:00<49:29,55.08it/s]  6%|6         |10473/173481[03:10<49:19,55.08it/s] 11%|#1        |19658/173481[06:00<46:57,54.60it/s] 12%|#1        |20225/173481[06:10<46:47,54.60it/s] 17%|#7        |29546/173481[09:00<43:48,54.76it/s] 17%|#7        |30120/173481[09:10<43:37,54.76it/s] 23%|##2       |39424/173481[12:00<40:45,54.82it/s] 23%|##3       |39999/173481[12:10<40:34,54.82it/s] 28%|##8       |49315/173481[15:00<37:42,54.88it/s] 29%|##8       |49900/173481[15:10<37:31,54.88it/s] 34%|###4      |59126/173481[18:00<34:50,54.69it/s] 34%|###4      |59716/173481[18:10<34:40,54.69it/s] 40%|###9      |68983/173481[21:00<31:49,54.73it/s] 40%|####      |69593/173481[21:11<31:38,54.73it/s] 45%|####5     |78844/173481[24:00<28:48,54.75it/s] 46%|####5     |79462/173481[24:11<28:37,54.75it/s] 51%|#####1    |88730/173481[27:00<25:45,54.84it/s] 52%|#####1    |89357/173481[27:11<25:34,54.84it/s] 57%|#####6    |98598/173481[30:00<22:45,54.83it/s] 57%|#####7    |99240/173481[30:11<22:34,54.83it/s] 63%|######2   |108561/173481[33:00<19:38,55.09it/s] 63%|######2   |109201/173481[33:11<19:26,55.09it/s] 68%|######8   |118542/173481[36:00<16:34,55.26it/s] 69%|######8   |119195/173481[36:11<16:22,55.26it/s] 74%|#######4  |128466/173481[39:00<13:35,55.20it/s] 74%|#######4  |129118/173481[39:12<13:23,55.20it/s] 80%|#######9  |138348/173481[42:00<10:38,55.05it/s] 80%|########  |139005/173481[42:12<10:26,55.05it/s] 85%|########5 |148243/173481[45:00<07:38,55.01it/s] 86%|########5 |148914/173481[45:12<07:26,55.01it/s] 91%|#########1|158182/173481[48:00<04:37,55.11it/s] 92%|#########1|158870/173481[48:12<04:25,55.11it/s] 97%|#########6|168109/173481[51:00<01:37,55.13it/s] 97%|#########7|168802/173481[51:12<01:24,55.13it/s]100%|##########|173481/173481[52:38<00:00,54.93it/s]
[32m[0324 20:41:17 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:3158.44 sec.
[32m[0324 20:41:18 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-6071835.
  0%|          |0/18822[00:00<?,?it/s] 81%|########  |15227/18822[03:00<00:42,84.59it/s] 85%|########5 |16086/18822[03:10<00:32,84.59it/s]100%|##########|18822/18822[03:42<00:00,84.57it/s]
34
[32m[0324 20:45:01 @monitor.py:363][0m QueueInput/queue_size: 49.99
[32m[0324 20:45:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.021
[32m[0324 20:45:01 @monitor.py:363][0m activation-summaries/output-rms: 0.035773
[32m[0324 20:45:01 @monitor.py:363][0m cross_entropy_loss: 2.0398
[32m[0324 20:45:01 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40542
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2413e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.173e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3838
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3369e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26627
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38869
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8354e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.974e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37893
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26629
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.537e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41509
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8351e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26928
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46018
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96727
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76422
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80657
[32m[0324 20:45:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 20:45:01 @monitor.py:363][0m train-error-top1: 0.5258
[32m[0324 20:45:01 @monitor.py:363][0m val-error-top1: 0.59759
[32m[0324 20:45:01 @monitor.py:363][0m val-utt-error: 0.2335
[32m[0324 20:45:01 @monitor.py:363][0m validation_cost: 2.3712
[32m[0324 20:45:01 @monitor.py:363][0m wd_cost: 6.4493e-08
[32m[0324 20:45:01 @group.py:42][0m Callbacks took 223.131 sec in total. InferenceRunner: 222.576sec
[32m[0324 20:45:01 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9838/173481[03:00<49:54,54.65it/s]  6%|5         |10400/173481[03:10<49:44,54.65it/s] 11%|#1        |19732/173481[06:00<46:45,54.81it/s] 12%|#1        |20299/173481[06:10<46:34,54.81it/s] 17%|#7        |29658/173481[09:00<43:36,54.97it/s] 17%|#7        |30232/173481[09:10<43:25,54.97it/s] 23%|##2       |39576/173481[12:00<40:33,55.03it/s] 23%|##3       |40158/173481[12:10<40:22,55.03it/s] 28%|##8       |49392/173481[15:00<37:45,54.78it/s] 29%|##8       |49989/173481[15:10<37:34,54.78it/s] 34%|###4      |59150/173481[18:00<34:58,54.49it/s] 34%|###4      |59745/173481[18:11<34:47,54.49it/s] 40%|###9      |69029/173481[21:00<31:50,54.69it/s] 40%|####      |69643/173481[21:11<31:38,54.69it/s] 46%|####5     |78970/173481[24:00<28:39,54.95it/s] 46%|####5     |79594/173481[24:11<28:28,54.95it/s] 51%|#####1    |88907/173481[27:00<25:35,55.08it/s] 52%|#####1    |89534/173481[27:11<25:24,55.08it/s] 57%|#####6    |98831/173481[30:00<22:34,55.11it/s] 57%|#####7    |99461/173481[30:11<22:23,55.11it/s] 63%|######2   |108721/173481[33:00<19:36,55.02it/s] 63%|######3   |109359/173481[33:11<19:25,55.02it/s] 68%|######8   |118639/173481[36:00<16:36,55.06it/s] 69%|######8   |119289/173481[36:11<16:24,55.06it/s] 74%|#######4  |128652/173481[39:00<13:30,55.34it/s] 75%|#######4  |129310/173481[39:12<13:18,55.34it/s] 80%|#######9  |138580/173481[42:00<10:31,55.25it/s] 80%|########  |139243/173481[42:12<10:19,55.25it/s] 86%|########5 |148512/173481[45:00<07:32,55.21it/s] 86%|########5 |149187/173481[45:12<07:20,55.21it/s] 91%|#########1|158448/173481[48:00<04:32,55.20it/s] 92%|#########1|159132/173481[48:12<04:19,55.20it/s] 97%|#########7|168349/173481[51:00<01:33,55.10it/s] 97%|#########7|169044/173481[51:12<01:20,55.10it/s]100%|##########|173481/173481[52:32<00:00,55.02it/s]
[32m[0324 21:37:34 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:3152.97 sec.
[32m[0324 21:37:34 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s] 87%|########6 |16306/18822[03:00<00:27,90.47it/s] 96%|#########6|18080/18822[03:20<00:08,90.47it/s]100%|##########|18822/18822[03:28<00:00,90.29it/s]
35
[32m[0324 21:41:02 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 21:41:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.201
[32m[0324 21:41:02 @monitor.py:363][0m activation-summaries/output-rms: 0.037201
[32m[0324 21:41:02 @monitor.py:363][0m cross_entropy_loss: 2.0158
[32m[0324 21:41:02 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2413e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27043
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3366e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.366e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.38869
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8351e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.974e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26629
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.537e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8351e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26928
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46015
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96731
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76426
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80661
[32m[0324 21:41:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 21:41:02 @monitor.py:363][0m train-error-top1: 0.5196
[32m[0324 21:41:02 @monitor.py:363][0m val-error-top1: 0.60562
[32m[0324 21:41:02 @monitor.py:363][0m val-utt-error: 0.23717
[32m[0324 21:41:02 @monitor.py:363][0m validation_cost: 2.4188
[32m[0324 21:41:02 @monitor.py:363][0m wd_cost: 1.29e-08
[32m[0324 21:41:02 @group.py:42][0m Callbacks took 208.765 sec in total. InferenceRunner: 208.489sec
[32m[0324 21:41:02 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9886/173481[03:00<49:38,54.92it/s]  6%|6         |10442/173481[03:10<49:28,54.92it/s] 11%|#1        |19722/173481[06:00<46:46,54.78it/s] 12%|#1        |20294/173481[06:10<46:36,54.78it/s] 17%|#7        |29597/173481[09:00<43:44,54.82it/s] 17%|#7        |30165/173481[09:10<43:34,54.82it/s] 23%|##2       |39443/173481[12:00<40:47,54.76it/s] 23%|##3       |40019/173481[12:10<40:37,54.76it/s] 28%|##8       |49340/173481[15:00<37:42,54.87it/s] 29%|##8       |49927/173481[15:10<37:31,54.87it/s] 34%|###4      |59213/173481[18:00<34:42,54.86it/s] 34%|###4      |59809/173481[18:10<34:32,54.86it/s] 40%|###9      |69093/173481[21:00<31:42,54.87it/s] 40%|####      |69690/173481[21:11<31:31,54.87it/s] 46%|####5     |79005/173481[24:00<28:38,54.97it/s] 46%|####5     |79605/173481[24:11<28:27,54.97it/s] 51%|#####1    |88772/173481[27:00<25:51,54.61it/s] 52%|#####1    |89381/173481[27:11<25:39,54.61it/s] 57%|#####6    |98584/173481[30:00<22:52,54.56it/s] 57%|#####7    |99202/173481[30:11<22:41,54.56it/s] 62%|######2   |108351/173481[33:00<19:57,54.41it/s] 63%|######2   |108989/173481[33:11<19:45,54.41it/s] 68%|######8   |118116/173481[36:00<16:59,54.33it/s] 68%|######8   |118753/173481[36:11<16:47,54.33it/s] 74%|#######3  |127865/173481[39:00<14:00,54.24it/s] 74%|#######4  |128476/173481[39:11<13:49,54.24it/s] 79%|#######9  |137511/173481[42:00<11:07,53.91it/s] 80%|#######9  |138157/173481[42:12<10:55,53.91it/s] 85%|########4 |147325/173481[45:00<08:02,54.21it/s] 85%|########5 |147967/173481[45:12<07:50,54.21it/s] 90%|######### |156964/173481[48:00<05:06,53.88it/s] 91%|######### |157609/173481[48:12<04:54,53.88it/s] 96%|#########5|165983/173481[51:00<02:24,51.92it/s] 96%|#########6|166643/173481[51:12<02:11,51.92it/s]100%|##########|173481/173481[53:24<00:00,54.14it/s]
[32m[0324 22:34:27 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:3204.49 sec.
[32m[0324 22:34:27 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s] 81%|########1 |15303/18822[03:00<00:41,85.01it/s] 86%|########5 |16186/18822[03:10<00:31,85.01it/s]100%|##########|18822/18822[03:48<00:00,82.53it/s]
36
[32m[0324 22:38:15 @monitor.py:363][0m QueueInput/queue_size: 48.401
[32m[0324 22:38:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.27
[32m[0324 22:38:15 @monitor.py:363][0m activation-summaries/output-rms: 0.034492
[32m[0324 22:38:15 @monitor.py:363][0m cross_entropy_loss: 2.0298
[32m[0324 22:38:15 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3365e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.366e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4671e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.537e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.41511
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8351e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26928
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46006
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96732
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76428
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80663
[32m[0324 22:38:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 22:38:15 @monitor.py:363][0m train-error-top1: 0.51678
[32m[0324 22:38:15 @monitor.py:363][0m val-error-top1: 0.59668
[32m[0324 22:38:15 @monitor.py:363][0m val-utt-error: 0.23504
[32m[0324 22:38:15 @monitor.py:363][0m validation_cost: 2.3667
[32m[0324 22:38:15 @monitor.py:363][0m wd_cost: 1.29e-08
[32m[0324 22:38:15 @group.py:42][0m Callbacks took 228.492 sec in total. InferenceRunner: 228.068sec
[32m[0324 22:38:15 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9847/173481[03:00<49:51,54.70it/s]  6%|5         |10396/173481[03:10<49:41,54.70it/s] 11%|#1        |19749/173481[06:00<46:42,54.86it/s] 12%|#1        |20312/173481[06:10<46:32,54.86it/s] 17%|#6        |28825/173481[09:00<45:53,52.54it/s] 17%|#6        |29313/173481[09:10<45:43,52.54it/s] 22%|##1       |37346/173481[12:00<45:33,49.80it/s] 22%|##1       |37838/173481[12:10<45:23,49.80it/s] 27%|##6       |46009/173481[15:00<43:24,48.95it/s] 27%|##6       |46522/173481[15:10<43:13,48.95it/s] 32%|###1      |55330/173481[18:00<39:07,50.33it/s] 32%|###2      |55900/173481[18:10<38:56,50.33it/s] 37%|###7      |64941/173481[21:00<34:54,51.81it/s] 38%|###7      |65540/173481[21:11<34:43,51.81it/s] 43%|####3     |74838/173481[24:00<30:48,53.35it/s] 43%|####3     |75455/173481[24:11<30:37,53.35it/s] 49%|####8     |84744/173481[27:00<27:17,54.18it/s] 49%|####9     |85365/173481[27:11<27:06,54.18it/s] 55%|#####4    |94660/173481[30:00<24:02,54.63it/s] 55%|#####4    |95291/173481[30:11<23:51,54.63it/s] 60%|######    |104546/173481[33:00<20:58,54.77it/s] 61%|######    |105192/173481[33:11<20:46,54.77it/s] 66%|######5   |114454/173481[36:00<17:55,54.91it/s] 66%|######6   |115102/173481[36:11<17:43,54.91it/s] 72%|#######1  |124310/173481[39:00<14:56,54.83it/s] 72%|#######2  |124963/173481[39:12<14:44,54.83it/s] 77%|#######7  |134216/173481[42:00<11:54,54.93it/s] 78%|#######7  |134877/173481[42:12<11:42,54.93it/s] 83%|########3 |144077/173481[45:00<08:56,54.86it/s] 83%|########3 |144742/173481[45:12<08:43,54.86it/s] 89%|########8 |153943/173481[48:00<05:56,54.83it/s] 89%|########9 |154630/173481[48:12<05:43,54.83it/s] 94%|#########4|163819/173481[51:00<02:56,54.85it/s] 95%|#########4|164499/173481[51:12<02:43,54.85it/s]100%|##########|173481/173481[53:55<00:00,53.61it/s]
[32m[0324 23:32:11 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:3236.00 sec.
[32m[0324 23:32:12 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-6592278.
  0%|          |0/18822[00:00<?,?it/s] 87%|########6 |16310/18822[03:00<00:27,90.61it/s] 92%|#########1|17240/18822[03:10<00:17,90.61it/s]100%|##########|18822/18822[03:27<00:00,90.81it/s]
37
[32m[0324 23:35:39 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0324 23:35:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.133
[32m[0324 23:35:39 @monitor.py:363][0m activation-summaries/output-rms: 0.035601
[32m[0324 23:35:39 @monitor.py:363][0m cross_entropy_loss: 2.0623
[32m[0324 23:35:39 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1732e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4671e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.537e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26928
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45996
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2413
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96733
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.7643
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80665
[32m[0324 23:35:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0324 23:35:39 @monitor.py:363][0m train-error-top1: 0.53599
[32m[0324 23:35:39 @monitor.py:363][0m val-error-top1: 0.61697
[32m[0324 23:35:39 @monitor.py:363][0m val-utt-error: 0.27027
[32m[0324 23:35:39 @monitor.py:363][0m validation_cost: 2.4943
[32m[0324 23:35:39 @monitor.py:363][0m wd_cost: 1.29e-08
[32m[0324 23:35:39 @group.py:42][0m Callbacks took 207.683 sec in total. InferenceRunner: 207.289sec
[32m[0324 23:35:39 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9848/173481[03:00<49:50,54.71it/s]  6%|5         |10407/173481[03:10<49:40,54.71it/s] 11%|#1        |19706/173481[06:00<46:49,54.74it/s] 12%|#1        |20264/173481[06:10<46:39,54.74it/s] 17%|#7        |29509/173481[09:00<43:57,54.60it/s] 17%|#7        |30084/173481[09:10<43:46,54.60it/s] 23%|##2       |39298/173481[12:00<41:02,54.49it/s] 23%|##2       |39880/173481[12:10<40:51,54.49it/s] 28%|##8       |49135/173481[15:00<37:58,54.57it/s] 29%|##8       |49709/173481[15:10<37:48,54.57it/s] 34%|###4      |58988/173481[18:00<34:54,54.65it/s] 34%|###4      |59577/173481[18:10<34:44,54.65it/s] 40%|###9      |68847/173481[21:00<31:52,54.71it/s] 40%|####      |69451/173481[21:11<31:41,54.71it/s] 45%|####5     |78690/173481[24:00<28:53,54.70it/s] 46%|####5     |79294/173481[24:11<28:41,54.70it/s] 51%|#####1    |88540/173481[27:00<25:52,54.71it/s] 51%|#####1    |89164/173481[27:11<25:41,54.71it/s] 57%|#####6    |98406/173481[30:00<22:51,54.76it/s] 57%|#####7    |99039/173481[30:11<22:39,54.76it/s] 62%|######2   |108302/173481[33:00<19:47,54.87it/s] 63%|######2   |108937/173481[33:11<19:36,54.87it/s] 68%|######8   |118168/173481[36:00<16:48,54.84it/s] 68%|######8   |118818/173481[36:11<16:36,54.84it/s] 74%|#######3  |127994/173481[39:00<13:51,54.71it/s] 74%|#######4  |128654/173481[39:11<13:39,54.71it/s] 79%|#######9  |137867/173481[42:00<10:50,54.78it/s] 80%|#######9  |138528/173481[42:12<10:38,54.78it/s] 85%|########5 |147822/173481[45:00<07:46,55.04it/s] 86%|########5 |148488/173481[45:12<07:34,55.04it/s] 91%|######### |157707/173481[48:00<04:46,54.98it/s] 91%|#########1|158388/173481[48:12<04:34,54.98it/s] 97%|#########6|167632/173481[51:00<01:46,55.06it/s] 97%|#########7|168314/173481[51:12<01:33,55.06it/s]100%|##########|173481/173481[52:46<00:00,54.78it/s]
[32m[0325 00:28:26 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:3166.93 sec.
[32m[0325 00:28:26 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s] 85%|########4 |15953/18822[03:00<00:32,88.63it/s] 90%|########9 |16849/18822[03:10<00:22,88.63it/s]100%|##########|18822/18822[03:32<00:00,88.65it/s]
38
[32m[0325 00:31:59 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0325 00:31:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.01
[32m[0325 00:31:59 @monitor.py:363][0m activation-summaries/output-rms: 0.035875
[32m[0325 00:31:59 @monitor.py:363][0m cross_entropy_loss: 2.053
[32m[0325 00:31:59 @monitor.py:363][0m lr: 6.1035e-08
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1732e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4671e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45973
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80665
[32m[0325 00:31:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 00:31:59 @monitor.py:363][0m train-error-top1: 0.53207
[32m[0325 00:31:59 @monitor.py:363][0m val-error-top1: 0.60887
[32m[0325 00:31:59 @monitor.py:363][0m val-utt-error: 0.2597
[32m[0325 00:31:59 @monitor.py:363][0m validation_cost: 2.4428
[32m[0325 00:31:59 @monitor.py:363][0m wd_cost: 2.5797e-09
[32m[0325 00:31:59 @group.py:42][0m Callbacks took 212.873 sec in total. InferenceRunner: 212.338sec
[32m[0325 00:31:59 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9883/173481[03:00<49:39,54.90it/s]  6%|6         |10421/173481[03:10<49:29,54.90it/s] 11%|#1        |19624/173481[06:00<47:02,54.51it/s] 12%|#1        |20188/173481[06:10<46:52,54.51it/s] 17%|#6        |29451/173481[09:00<44:00,54.55it/s] 17%|#7        |30023/173481[09:10<43:49,54.55it/s] 23%|##2       |39367/173481[12:00<40:46,54.82it/s] 23%|##3       |39942/173481[12:10<40:36,54.82it/s] 28%|##8       |49231/173481[15:00<37:47,54.81it/s] 29%|##8       |49814/173481[15:10<37:36,54.81it/s] 34%|###4      |59176/173481[18:00<34:37,55.03it/s] 34%|###4      |59771/173481[18:10<34:26,55.03it/s] 40%|###9      |69099/173481[21:00<31:35,55.07it/s] 40%|####      |69701/173481[21:11<31:24,55.07it/s] 46%|####5     |79043/173481[24:00<28:32,55.16it/s] 46%|####5     |79662/173481[24:11<28:20,55.16it/s] 51%|#####1    |88967/173481[27:00<25:32,55.14it/s] 52%|#####1    |89588/173481[27:11<25:21,55.14it/s] 57%|#####6    |98685/173481[30:00<22:50,54.56it/s] 57%|#####7    |99312/173481[30:11<22:39,54.56it/s] 62%|######2   |108411/173481[33:00<19:58,54.29it/s] 63%|######2   |109044/173481[33:11<19:46,54.29it/s] 68%|######7   |117926/173481[36:00<17:17,53.57it/s] 68%|######8   |118523/173481[36:11<17:05,53.57it/s] 73%|#######3  |127494/173481[39:00<14:21,53.36it/s] 74%|#######3  |128128/173481[39:11<14:09,53.36it/s] 79%|#######9  |137175/173481[42:00<11:17,53.57it/s] 79%|#######9  |137830/173481[42:12<11:05,53.57it/s] 85%|########4 |146941/173481[45:00<08:12,53.91it/s] 85%|########5 |147600/173481[45:12<08:00,53.91it/s] 90%|######### |156782/173481[48:00<05:07,54.29it/s] 91%|######### |157462/173481[48:12<04:55,54.29it/s] 96%|#########5|166535/173481[51:00<02:08,54.23it/s] 96%|#########6|167184/173481[51:12<01:56,54.23it/s]100%|##########|173481/173481[53:13<00:00,54.32it/s]
[32m[0325 01:25:13 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:3194.04 sec.
[32m[0325 01:25:13 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-6939240.
  0%|          |0/18822[00:00<?,?it/s] 86%|########5 |16182/18822[03:00<00:29,89.90it/s] 91%|######### |17068/18822[03:10<00:19,89.90it/s]100%|##########|18822/18822[03:29<00:00,89.73it/s]
39
[32m[0325 01:28:43 @monitor.py:363][0m QueueInput/queue_size: 11.291
[32m[0325 01:28:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.998
[32m[0325 01:28:43 @monitor.py:363][0m activation-summaries/output-rms: 0.035495
[32m[0325 01:28:43 @monitor.py:363][0m cross_entropy_loss: 2.1006
[32m[0325 01:28:43 @monitor.py:363][0m lr: 6.1035e-08
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8351e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.4671e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4595
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80665
[32m[0325 01:28:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 01:28:43 @monitor.py:363][0m train-error-top1: 0.5417
[32m[0325 01:28:43 @monitor.py:363][0m val-error-top1: 0.6065
[32m[0325 01:28:43 @monitor.py:363][0m val-utt-error: 0.25183
[32m[0325 01:28:43 @monitor.py:363][0m validation_cost: 2.4289
[32m[0325 01:28:43 @monitor.py:363][0m wd_cost: 2.5795e-09
[32m[0325 01:28:43 @group.py:42][0m Callbacks took 210.316 sec in total. InferenceRunner: 209.833sec
[32m[0325 01:28:43 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9697/173481[03:00<50:40,53.87it/s]  6%|5         |10248/173481[03:10<50:30,53.87it/s] 11%|#1        |19444/173481[06:00<47:32,54.01it/s] 12%|#1        |20004/173481[06:10<47:21,54.01it/s] 17%|#6        |29191/173481[09:00<44:28,54.08it/s] 17%|#7        |29763/173481[09:10<44:17,54.08it/s] 22%|##2       |38940/173481[12:00<41:26,54.12it/s] 23%|##2       |39517/173481[12:10<41:15,54.12it/s] 28%|##8       |48720/173481[15:00<38:20,54.22it/s] 28%|##8       |49308/173481[15:10<38:09,54.22it/s] 34%|###3      |58527/173481[18:00<35:14,54.35it/s] 34%|###4      |59118/173481[18:11<35:04,54.35it/s] 39%|###9      |68332/173481[21:00<32:12,54.41it/s] 40%|###9      |68938/173481[21:11<32:01,54.41it/s] 45%|####5     |78145/173481[24:00<29:10,54.46it/s] 45%|####5     |78752/173481[24:11<28:59,54.46it/s] 51%|#####     |87972/173481[27:00<26:08,54.53it/s] 51%|#####1    |88597/173481[27:11<25:56,54.53it/s] 56%|#####6    |97791/173481[30:00<23:07,54.54it/s] 57%|#####6    |98414/173481[30:11<22:56,54.54it/s] 62%|######2   |107582/173481[33:00<20:09,54.47it/s] 62%|######2   |108220/173481[33:11<19:58,54.47it/s] 68%|######7   |117404/173481[36:00<17:08,54.51it/s] 68%|######8   |118056/173481[36:12<16:56,54.51it/s] 73%|#######3  |127213/173481[39:00<14:08,54.50it/s] 74%|#######3  |127874/173481[39:12<13:56,54.50it/s] 79%|#######9  |137057/173481[42:00<11:07,54.59it/s] 79%|#######9  |137716/173481[42:12<10:55,54.59it/s] 85%|########4 |146874/173481[45:00<08:07,54.57it/s] 85%|########5 |147549/173481[45:12<07:55,54.57it/s] 90%|######### |156671/173481[48:00<05:08,54.49it/s] 91%|######### |157345/173481[48:12<04:56,54.49it/s] 96%|#########5|166512/173481[51:00<02:07,54.58it/s] 96%|#########6|167203/173481[51:12<01:55,54.58it/s]100%|##########|173481/173481[53:07<00:00,54.43it/s]
[32m[0325 02:21:51 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:3187.47 sec.
[32m[0325 02:21:51 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s] 90%|######### |16945/18822[03:00<00:19,94.14it/s] 95%|#########5|17924/18822[03:10<00:09,94.14it/s]100%|##########|18822/18822[03:55<00:00,79.91it/s]
40
[32m[0325 02:25:47 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0325 02:25:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.11
[32m[0325 02:25:47 @monitor.py:363][0m activation-summaries/output-rms: 0.03449
[32m[0325 02:25:47 @monitor.py:363][0m cross_entropy_loss: 2.0872
[32m[0325 02:25:47 @monitor.py:363][0m lr: 3.0518e-08
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45928
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80665
[32m[0325 02:25:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 02:25:47 @monitor.py:363][0m train-error-top1: 0.53309
[32m[0325 02:25:47 @monitor.py:363][0m val-error-top1: 0.57059
[32m[0325 02:25:47 @monitor.py:363][0m val-utt-error: 0.21098
[32m[0325 02:25:47 @monitor.py:363][0m validation_cost: 2.225
[32m[0325 02:25:47 @monitor.py:363][0m wd_cost: 2.5793e-09
[32m[0325 02:25:47 @group.py:42][0m Callbacks took 235.844 sec in total. InferenceRunner: 235.550sec
[32m[0325 02:25:47 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9792/173481[03:00<50:09,54.40it/s]  6%|5         |10345/173481[03:10<49:58,54.40it/s] 11%|#1        |19597/173481[06:00<47:07,54.43it/s] 12%|#1        |20158/173481[06:10<46:56,54.43it/s] 17%|#6        |29399/173481[09:00<44:06,54.44it/s] 17%|#7        |29964/173481[09:10<43:56,54.44it/s] 23%|##2       |39175/173481[12:00<41:09,54.38it/s] 23%|##2       |39750/173481[12:10<40:59,54.38it/s] 28%|##8       |48960/173481[15:00<38:10,54.36it/s] 29%|##8       |49494/173481[15:10<38:00,54.36it/s] 34%|###3      |58513/173481[18:00<35:40,53.71it/s] 34%|###4      |59094/173481[18:10<35:29,53.71it/s] 39%|###9      |67905/173481[21:00<33:14,52.93it/s] 39%|###9      |68448/173481[21:11<33:04,52.93it/s] 45%|####4     |77681/173481[24:00<29:46,53.61it/s] 45%|####5     |78277/173481[24:11<29:35,53.61it/s] 50%|#####     |87367/173481[27:00<26:43,53.71it/s] 51%|#####     |87973/173481[27:11<26:32,53.71it/s] 56%|#####6    |97289/173481[30:00<23:20,54.41it/s] 56%|#####6    |97924/173481[30:11<23:08,54.41it/s] 62%|######1   |107175/173481[33:00<20:13,54.66it/s] 62%|######2   |107805/173481[33:11<20:01,54.66it/s] 67%|######7   |117008/173481[36:00<17:13,54.64it/s] 68%|######7   |117648/173481[36:11<17:01,54.64it/s] 73%|#######3  |126669/173481[39:00<14:24,54.15it/s] 73%|#######3  |127320/173481[39:12<14:12,54.15it/s] 79%|#######8  |136223/173481[42:00<11:34,53.61it/s] 79%|#######8  |136867/173481[42:12<11:22,53.61it/s] 84%|########4 |145860/173481[45:00<08:35,53.57it/s] 84%|########4 |146517/173481[45:12<08:23,53.57it/s] 90%|########9 |155595/173481[48:00<05:32,53.82it/s] 90%|######### |156280/173481[48:12<05:19,53.82it/s] 95%|#########5|164969/173481[51:00<02:40,52.93it/s] 95%|#########5|165621/173481[51:12<02:28,52.93it/s]100%|##########|173481/173481[53:39<00:00,53.88it/s]
[32m[0325 03:19:26 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3219.63 sec.
[32m[0325 03:19:27 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-7286202.
[32m[0325 03:19:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 81%|########1 |15248/18822[03:00<00:42,84.71it/s] 86%|########5 |16121/18822[03:10<00:31,84.71it/s]100%|##########|18822/18822[03:41<00:00,84.89it/s]
41
[32m[0325 03:23:09 @monitor.py:363][0m QueueInput/queue_size: 23.747
[32m[0325 03:23:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.191
[32m[0325 03:23:09 @monitor.py:363][0m activation-summaries/output-rms: 0.034928
[32m[0325 03:23:09 @monitor.py:363][0m cross_entropy_loss: 2.1319
[32m[0325 03:23:09 @monitor.py:363][0m lr: 3.0518e-08
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4591
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80665
[32m[0325 03:23:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 03:23:09 @monitor.py:363][0m train-error-top1: 0.54571
[32m[0325 03:23:09 @monitor.py:363][0m val-error-top1: 0.57828
[32m[0325 03:23:09 @monitor.py:363][0m val-utt-error: 0.21916
[32m[0325 03:23:09 @monitor.py:363][0m validation_cost: 2.2862
[32m[0325 03:23:09 @monitor.py:363][0m wd_cost: 5.1582e-10
[32m[0325 03:23:09 @group.py:42][0m Callbacks took 222.570 sec in total. InferenceRunner: 221.728sec
[32m[0325 03:23:09 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9876/173481[03:00<49:42,54.86it/s]  6%|6         |10422/173481[03:10<49:32,54.86it/s] 11%|#1        |19532/173481[06:00<47:18,54.24it/s] 12%|#1        |20108/173481[06:10<47:07,54.24it/s] 16%|#6        |28491/173481[09:00<46:33,51.91it/s] 17%|#6        |28961/173481[09:10<46:24,51.91it/s] 22%|##1       |37604/173481[12:00<44:10,51.26it/s] 22%|##1       |38143/173481[12:10<44:00,51.26it/s] 27%|##6       |46309/173481[15:00<42:35,49.76it/s] 27%|##6       |46839/173481[15:10<42:24,49.76it/s] 32%|###1      |55447/173481[18:00<39:08,50.26it/s] 32%|###2      |55988/173481[18:10<38:57,50.26it/s] 37%|###7      |64872/173481[21:00<35:17,51.29it/s] 38%|###7      |65465/173481[21:11<35:06,51.29it/s] 43%|####2     |74395/173481[24:00<31:42,52.08it/s] 43%|####3     |74932/173481[24:11<31:32,52.08it/s] 48%|####8     |84041/173481[27:00<28:13,52.82it/s] 49%|####8     |84647/173481[27:11<28:01,52.82it/s] 54%|#####4    |93911/173481[30:00<24:38,53.81it/s] 54%|#####4    |94501/173481[30:11<24:27,53.81it/s] 60%|#####9    |103627/173481[33:00<21:36,53.89it/s] 60%|######    |104256/173481[33:11<21:24,53.89it/s] 65%|######5   |113601/173481[36:00<18:15,54.64it/s] 66%|######5   |114249/173481[36:11<18:04,54.64it/s] 71%|#######1  |123530/173481[39:00<15:09,54.90it/s] 72%|#######1  |124163/173481[39:11<14:58,54.90it/s] 77%|#######6  |133387/173481[42:00<12:11,54.83it/s] 77%|#######7  |134026/173481[42:12<11:59,54.83it/s] 83%|########2 |143346/173481[45:00<09:07,55.08it/s] 83%|########3 |144013/173481[45:12<08:55,55.08it/s] 88%|########8 |153450/173481[48:00<06:00,55.60it/s] 89%|########8 |154135/173481[48:12<05:47,55.60it/s] 94%|#########4|163518/173481[51:00<02:58,55.76it/s] 95%|#########4|164207/173481[51:12<02:46,55.76it/s]100%|##########|173481/173481[54:00<00:00,55.53it/s]
[32m[0325 04:17:09 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3240.38 sec.
[32m[0325 04:17:10 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s] 84%|########4 |15820/18822[03:00<00:34,87.89it/s] 89%|########8 |16733/18822[03:10<00:23,87.89it/s]100%|##########|18822/18822[03:33<00:00,88.02it/s]
42
[32m[0325 04:20:44 @monitor.py:363][0m QueueInput/queue_size: 49.995
[32m[0325 04:20:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.14
[32m[0325 04:20:44 @monitor.py:363][0m activation-summaries/output-rms: 0.035785
[32m[0325 04:20:44 @monitor.py:363][0m cross_entropy_loss: 2.0232
[32m[0325 04:20:44 @monitor.py:363][0m lr: 3.0518e-08
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45893
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80665
[32m[0325 04:20:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 04:20:44 @monitor.py:363][0m train-error-top1: 0.52235
[32m[0325 04:20:44 @monitor.py:363][0m val-error-top1: 0.57395
[32m[0325 04:20:44 @monitor.py:363][0m val-utt-error: 0.21347
[32m[0325 04:20:44 @monitor.py:363][0m validation_cost: 2.2637
[32m[0325 04:20:44 @monitor.py:363][0m wd_cost: 5.1579e-10
[32m[0325 04:20:44 @group.py:42][0m Callbacks took 214.495 sec in total. InferenceRunner: 213.870sec
[32m[0325 04:20:44 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10109/173481[03:00<48:29,56.15it/s]  6%|6         |10675/173481[03:10<48:19,56.15it/s] 11%|#1        |19628/173481[06:00<47:04,54.47it/s] 12%|#1        |20142/173481[06:10<46:55,54.47it/s] 17%|#6        |29288/173481[09:00<44:27,54.06it/s] 17%|#7        |29853/173481[09:10<44:16,54.06it/s] 23%|##2       |39104/173481[12:00<41:14,54.30it/s] 23%|##2       |39679/173481[12:10<41:04,54.30it/s] 28%|##8       |49088/173481[15:00<37:46,54.87it/s] 29%|##8       |49692/173481[15:10<37:35,54.87it/s] 34%|###4      |59001/173481[18:00<34:42,54.97it/s] 34%|###4      |59615/173481[18:10<34:31,54.97it/s] 40%|###9      |68820/173481[21:00<31:51,54.76it/s] 40%|####      |69431/173481[21:11<31:40,54.76it/s] 45%|####5     |78678/173481[24:00<28:51,54.76it/s] 46%|####5     |79283/173481[24:11<28:40,54.76it/s] 51%|#####1    |88607/173481[27:00<25:44,54.96it/s] 51%|#####1    |89230/173481[27:11<25:33,54.96it/s] 57%|#####6    |98698/173481[30:00<22:27,55.50it/s] 57%|#####7    |99343/173481[30:11<22:15,55.50it/s] 62%|######2   |108304/173481[33:00<19:57,54.41it/s] 63%|######2   |108891/173481[33:11<19:47,54.41it/s] 68%|######7   |117492/173481[36:00<17:42,52.67it/s] 68%|######8   |118097/173481[36:11<17:31,52.67it/s] 73%|#######3  |126987/173481[39:00<14:42,52.71it/s] 74%|#######3  |127638/173481[39:12<14:29,52.71it/s] 79%|#######8  |136806/173481[42:00<11:24,53.61it/s] 79%|#######9  |137445/173481[42:12<11:12,53.61it/s] 84%|########4 |146098/173481[45:00<08:40,52.60it/s] 85%|########4 |146734/173481[45:12<08:28,52.60it/s] 90%|########9 |155496/173481[48:00<05:43,52.40it/s] 90%|######### |156148/173481[48:12<05:30,52.40it/s] 95%|#########5|165257/173481[51:00<02:34,53.30it/s] 96%|#########5|165943/173481[51:12<02:21,53.30it/s]100%|##########|173481/173481[53:47<00:00,53.74it/s]
[32m[0325 05:14:32 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3228.02 sec.
[32m[0325 05:14:32 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-7633164.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14867/18822[03:00<00:47,82.59it/s] 83%|########3 |15716/18822[03:10<00:37,82.59it/s]100%|##########|18822/18822[03:47<00:00,82.63it/s]
43
[32m[0325 05:18:20 @monitor.py:363][0m QueueInput/queue_size: 1.2981
[32m[0325 05:18:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.08
[32m[0325 05:18:20 @monitor.py:363][0m activation-summaries/output-rms: 0.03429
[32m[0325 05:18:20 @monitor.py:363][0m cross_entropy_loss: 2.0595
[32m[0325 05:18:20 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45881
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80666
[32m[0325 05:18:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 05:18:20 @monitor.py:363][0m train-error-top1: 0.53493
[32m[0325 05:18:20 @monitor.py:363][0m val-error-top1: 0.55849
[32m[0325 05:18:20 @monitor.py:363][0m val-utt-error: 0.19807
[32m[0325 05:18:20 @monitor.py:363][0m validation_cost: 2.1772
[32m[0325 05:18:20 @monitor.py:363][0m wd_cost: 5.1576e-10
[32m[0325 05:18:20 @group.py:42][0m Callbacks took 228.099 sec in total. InferenceRunner: 227.831sec
[32m[0325 05:18:20 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10031/173481[03:00<48:53,55.73it/s]  6%|6         |10582/173481[03:10<48:43,55.73it/s] 11%|#1        |19490/173481[06:00<47:26,54.09it/s] 12%|#1        |20053/173481[06:10<47:16,54.09it/s] 17%|#6        |29321/173481[09:00<44:12,54.35it/s] 17%|#7        |29910/173481[09:10<44:01,54.35it/s] 23%|##2       |39412/173481[12:00<40:29,55.19it/s] 23%|##3       |40005/173481[12:10<40:18,55.19it/s] 29%|##8       |49470/173481[15:00<37:13,55.53it/s] 29%|##8       |50070/173481[15:10<37:02,55.53it/s] 34%|###4      |59619/173481[18:00<33:55,55.95it/s] 35%|###4      |60234/173481[18:10<33:44,55.95it/s] 40%|####      |69726/173481[21:00<30:51,56.05it/s] 41%|####      |70346/173481[21:11<30:40,56.05it/s] 46%|####6     |79890/173481[24:00<27:43,56.25it/s] 46%|####6     |80516/173481[24:11<27:32,56.25it/s] 52%|#####1    |90029/173481[27:00<24:42,56.29it/s] 52%|#####2    |90661/173481[27:11<24:31,56.29it/s] 58%|#####7    |100081/173481[30:00<21:49,56.07it/s] 58%|#####8    |100725/173481[30:11<21:37,56.07it/s] 64%|######3   |110190/173481[33:00<18:47,56.11it/s] 64%|######3   |110851/173481[33:11<18:36,56.11it/s] 69%|######9   |120364/173481[36:00<15:43,56.31it/s] 70%|######9   |121029/173481[36:11<15:31,56.31it/s] 75%|#######5  |130547/173481[39:00<12:40,56.44it/s] 76%|#######5  |131211/173481[39:12<12:28,56.44it/s] 81%|########1 |140641/173481[42:00<09:43,56.26it/s] 81%|########1 |141315/173481[42:12<09:31,56.26it/s] 87%|########6 |150779/173481[45:00<06:43,56.29it/s] 87%|########7 |151467/173481[45:12<06:31,56.29it/s] 93%|#########2|160933/173481[48:00<03:42,56.35it/s] 93%|#########3|161629/173481[48:12<03:30,56.35it/s] 98%|#########8|170831/173481[51:00<00:47,55.66it/s] 99%|#########8|171511/173481[51:12<00:35,55.66it/s]100%|##########|173481/173481[51:49<00:00,55.79it/s]
[32m[0325 06:10:09 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:3109.45 sec.
[32m[0325 06:10:10 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-7806645.
[32m[0325 06:10:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######9  |14945/18822[03:00<00:46,83.03it/s] 84%|########4 |15847/18822[03:10<00:35,83.03it/s]100%|##########|18822/18822[03:43<00:00,84.09it/s]
44
[32m[0325 06:13:55 @monitor.py:363][0m QueueInput/queue_size: 17.795
[32m[0325 06:13:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.027
[32m[0325 06:13:55 @monitor.py:363][0m activation-summaries/output-rms: 0.036074
[32m[0325 06:13:55 @monitor.py:363][0m cross_entropy_loss: 2.0249
[32m[0325 06:13:55 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45877
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80666
[32m[0325 06:13:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 06:13:55 @monitor.py:363][0m train-error-top1: 0.52156
[32m[0325 06:13:55 @monitor.py:363][0m val-error-top1: 0.56066
[32m[0325 06:13:55 @monitor.py:363][0m val-utt-error: 0.20226
[32m[0325 06:13:55 @monitor.py:363][0m validation_cost: 2.1981
[32m[0325 06:13:55 @monitor.py:363][0m wd_cost: 1.0315e-10
[32m[0325 06:13:55 @group.py:42][0m Callbacks took 225.370 sec in total. InferenceRunner: 223.947sec
[32m[0325 06:13:55 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10060/173481[03:00<48:44,55.88it/s]  6%|6         |10613/173481[03:10<48:34,55.88it/s] 12%|#1        |20157/173481[06:00<45:38,55.99it/s] 12%|#1        |20733/173481[06:10<45:28,55.99it/s] 17%|#7        |30202/173481[09:00<42:43,55.90it/s] 18%|#7        |30770/173481[09:10<42:33,55.90it/s] 23%|##3       |40125/173481[12:00<40:02,55.51it/s] 23%|##3       |40711/173481[12:10<39:51,55.51it/s] 29%|##8       |50040/173481[15:00<37:12,55.29it/s] 29%|##9       |50631/173481[15:10<37:01,55.29it/s] 35%|###4      |59913/173481[18:00<34:22,55.07it/s] 35%|###4      |60516/173481[18:10<34:11,55.07it/s] 40%|####      |69869/173481[21:00<31:17,55.19it/s] 41%|####      |70478/173481[21:11<31:06,55.19it/s] 46%|####5     |79525/173481[24:00<28:46,54.41it/s] 46%|####6     |80118/173481[24:11<28:36,54.41it/s] 51%|#####1    |89276/173481[27:00<25:51,54.29it/s] 52%|#####1    |89889/173481[27:11<25:39,54.29it/s] 57%|#####7    |98960/173481[30:00<22:58,54.04it/s] 57%|#####7    |99572/173481[30:11<22:47,54.04it/s] 63%|######2   |108740/173481[33:00<19:54,54.19it/s] 63%|######3   |109368/173481[33:11<19:43,54.19it/s] 68%|######8   |118503/173481[36:00<16:54,54.21it/s] 69%|######8   |119126/173481[36:11<16:42,54.21it/s] 74%|#######3  |128231/173481[39:00<13:56,54.13it/s] 74%|#######4  |128860/173481[39:11<13:44,54.13it/s] 79%|#######9  |137887/173481[42:00<11:00,53.88it/s] 80%|#######9  |138545/173481[42:12<10:48,53.88it/s] 85%|########5 |147757/173481[45:00<07:53,54.35it/s] 86%|########5 |148401/173481[45:12<07:41,54.35it/s] 91%|######### |157436/173481[48:00<04:56,54.06it/s] 91%|#########1|158091/173481[48:12<04:44,54.06it/s] 96%|#########6|167019/173481[51:00<02:00,53.64it/s] 97%|#########6|167682/173481[51:12<01:48,53.64it/s]100%|##########|173481/173481[53:01<00:00,54.53it/s]
[32m[0325 07:06:56 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:3181.15 sec.
[32m[0325 07:06:57 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-7980126.
  0%|          |0/18822[00:00<?,?it/s] 59%|#####9    |11114/18822[03:00<02:04,61.74it/s] 64%|######3   |12028/18822[03:10<01:50,61.74it/s]100%|##########|18822/18822[04:29<00:00,69.73it/s]
45
[32m[0325 07:11:27 @monitor.py:363][0m QueueInput/queue_size: 35.647
[32m[0325 07:11:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.03
[32m[0325 07:11:27 @monitor.py:363][0m activation-summaries/output-rms: 0.035042
[32m[0325 07:11:27 @monitor.py:363][0m cross_entropy_loss: 2.0406
[32m[0325 07:11:27 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45872
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80666
[32m[0325 07:11:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 07:11:27 @monitor.py:363][0m train-error-top1: 0.52407
[32m[0325 07:11:27 @monitor.py:363][0m val-error-top1: 0.56068
[32m[0325 07:11:27 @monitor.py:363][0m val-utt-error: 0.2012
[32m[0325 07:11:27 @monitor.py:363][0m validation_cost: 2.1909
[32m[0325 07:11:27 @monitor.py:363][0m wd_cost: 1.0315e-10
[32m[0325 07:11:27 @group.py:42][0m Callbacks took 270.815 sec in total. InferenceRunner: 270.067sec
[32m[0325 07:11:27 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9982/173481[03:00<49:08,55.45it/s]  6%|6         |10513/173481[03:10<48:58,55.45it/s] 11%|#1        |19726/173481[06:00<46:46,54.78it/s] 12%|#1        |20292/173481[06:10<46:36,54.78it/s] 17%|#6        |29449/173481[09:00<44:07,54.40it/s] 17%|#7        |30026/173481[09:10<43:57,54.40it/s] 22%|##2       |38717/173481[12:00<42:27,52.90it/s] 23%|##2       |39258/173481[12:10<42:17,52.90it/s] 28%|##7       |47923/173481[15:00<40:14,52.01it/s] 28%|##7       |48474/173481[15:10<40:03,52.01it/s] 33%|###3      |57464/173481[18:00<36:49,52.50it/s] 33%|###3      |58044/173481[18:10<36:38,52.50it/s] 39%|###8      |67014/173481[21:00<33:37,52.77it/s] 39%|###8      |67583/173481[21:11<33:26,52.77it/s] 44%|####4     |76855/173481[24:00<29:59,53.70it/s] 45%|####4     |77457/173481[24:11<29:48,53.70it/s] 50%|####9     |86518/173481[27:00<26:59,53.69it/s] 50%|#####     |87128/173481[27:11<26:48,53.69it/s] 55%|#####5    |96250/173481[30:00<23:53,53.88it/s] 56%|#####5    |96875/173481[30:11<23:41,53.88it/s] 61%|######1   |105883/173481[33:00<20:58,53.70it/s] 61%|######1   |106504/173481[33:11<20:47,53.70it/s] 67%|######6   |115476/173481[36:00<18:04,53.49it/s] 67%|######6   |116062/173481[36:11<17:53,53.49it/s] 72%|#######1  |124883/173481[39:00<15:19,52.87it/s] 72%|#######2  |125441/173481[39:12<15:08,52.87it/s] 77%|#######7  |134165/173481[42:00<12:33,52.21it/s] 78%|#######7  |134809/173481[42:12<12:20,52.21it/s] 83%|########2 |143686/173481[45:00<09:27,52.55it/s] 83%|########3 |144338/173481[45:12<09:14,52.55it/s] 88%|########8 |153266/173481[48:00<06:22,52.88it/s] 89%|########8 |153921/173481[48:12<06:09,52.88it/s] 94%|#########3|162340/173481[51:00<03:35,51.61it/s] 94%|#########3|162935/173481[51:12<03:24,51.61it/s] 99%|#########9|171841/173481[54:00<00:31,52.19it/s] 99%|#########9|172444/173481[54:12<00:19,52.19it/s]100%|##########|173481/173481[54:34<00:00,52.98it/s]
[32m[0325 08:06:01 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:3274.16 sec.
[32m[0325 08:06:02 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-8153607.
  0%|          |0/18822[00:00<?,?it/s] 81%|########  |15224/18822[03:00<00:42,84.58it/s] 85%|########5 |16077/18822[03:10<00:32,84.58it/s]100%|##########|18822/18822[03:42<00:00,84.78it/s]
46
[32m[0325 08:09:44 @monitor.py:363][0m QueueInput/queue_size: 1.7272
[32m[0325 08:09:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.167
[32m[0325 08:09:44 @monitor.py:363][0m activation-summaries/output-rms: 0.035152
[32m[0325 08:09:44 @monitor.py:363][0m cross_entropy_loss: 2.0821
[32m[0325 08:09:44 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.45871
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80666
[32m[0325 08:09:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 08:09:44 @monitor.py:363][0m train-error-top1: 0.53623
[32m[0325 08:09:44 @monitor.py:363][0m val-error-top1: 0.55596
[32m[0325 08:09:44 @monitor.py:363][0m val-utt-error: 0.18909
[32m[0325 08:09:44 @monitor.py:363][0m validation_cost: 2.1681
[32m[0325 08:09:44 @monitor.py:363][0m wd_cost: 1.0315e-10
[32m[0325 08:09:44 @group.py:42][0m Callbacks took 222.610 sec in total. InferenceRunner: 222.037sec
[32m[0325 08:09:44 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9729/173481[03:00<50:29,54.05it/s]  6%|5         |10266/173481[03:10<50:19,54.05it/s] 11%|#1        |19373/173481[06:00<47:44,53.81it/s] 11%|#1        |19934/173481[06:10<47:33,53.81it/s] 16%|#6        |28539/173481[09:00<46:10,52.32it/s] 17%|#6        |29033/173481[09:10<46:00,52.32it/s] 22%|##1       |37713/173481[12:00<43:49,51.63it/s] 22%|##2       |38233/173481[12:10<43:39,51.63it/s] 27%|##6       |46581/173481[15:00<41:56,50.42it/s] 27%|##7       |47112/173481[15:10<41:46,50.42it/s] 32%|###2      |55533/173481[18:00<39:15,50.08it/s] 32%|###2      |56099/173481[18:10<39:04,50.08it/s] 37%|###7      |64669/173481[21:00<35:58,50.41it/s] 38%|###7      |65261/173481[21:11<35:46,50.41it/s] 43%|####2     |74284/173481[24:00<31:52,51.87it/s] 43%|####3     |74883/173481[24:11<31:40,51.87it/s] 48%|####8     |84017/173481[27:00<28:09,52.95it/s] 49%|####8     |84614/173481[27:11<27:58,52.95it/s] 54%|#####4    |93843/173481[30:00<24:41,53.75it/s] 54%|#####4    |94470/173481[30:11<24:29,53.75it/s] 60%|#####9    |103527/173481[33:00<21:40,53.77it/s] 60%|######    |104153/173481[33:11<21:29,53.77it/s] 65%|######5   |113272/173481[36:00<18:35,53.95it/s] 66%|######5   |113911/173481[36:11<18:24,53.95it/s] 71%|#######   |123052/173481[39:00<15:31,54.14it/s] 71%|#######1  |123686/173481[39:11<15:19,54.14it/s] 77%|#######6  |132807/173481[42:00<12:30,54.17it/s] 77%|#######6  |133464/173481[42:12<12:18,54.17it/s] 82%|########2 |142737/173481[45:00<09:22,54.66it/s] 83%|########2 |143406/173481[45:12<09:10,54.66it/s] 88%|########8 |152785/173481[48:00<06:14,55.23it/s] 88%|########8 |153477/173481[48:12<06:02,55.23it/s] 94%|#########3|162874/173481[51:00<03:10,55.64it/s] 94%|#########4|163562/173481[51:12<02:58,55.64it/s]100%|#########9|172793/173481[54:00<00:12,55.37it/s]100%|#########9|173480/173481[54:12<00:00,55.37it/s]100%|##########|173481/173481[54:13<00:00,53.33it/s]
[32m[0325 09:03:57 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:3253.04 sec.
[32m[0325 09:03:57 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-8327088.
[32m[0325 09:03:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 82%|########2 |15469/18822[03:00<00:39,85.94it/s] 87%|########6 |16350/18822[03:10<00:28,85.94it/s]100%|##########|18822/18822[03:40<00:00,85.53it/s]
47
[32m[0325 09:07:38 @monitor.py:363][0m QueueInput/queue_size: 49.996
[32m[0325 09:07:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.115
[32m[0325 09:07:38 @monitor.py:363][0m activation-summaries/output-rms: 0.035024
[32m[0325 09:07:38 @monitor.py:363][0m cross_entropy_loss: 1.9698
[32m[0325 09:07:38 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4587
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80666
[32m[0325 09:07:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 09:07:38 @monitor.py:363][0m train-error-top1: 0.51191
[32m[0325 09:07:38 @monitor.py:363][0m val-error-top1: 0.55357
[32m[0325 09:07:38 @monitor.py:363][0m val-utt-error: 0.19142
[32m[0325 09:07:38 @monitor.py:363][0m validation_cost: 2.156
[32m[0325 09:07:38 @monitor.py:363][0m wd_cost: 2.063e-11
[32m[0325 09:07:38 @group.py:42][0m Callbacks took 220.967 sec in total. InferenceRunner: 220.102sec
[32m[0325 09:07:38 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10107/173481[03:00<48:29,56.15it/s]  6%|6         |10678/173481[03:10<48:19,56.15it/s] 12%|#1        |19952/173481[06:00<46:10,55.41it/s] 12%|#1        |20496/173481[06:10<46:00,55.41it/s] 17%|#7        |29809/173481[09:00<43:28,55.08it/s] 18%|#7        |30392/173481[09:10<43:17,55.08it/s] 23%|##2       |39899/173481[12:00<40:04,55.56it/s] 23%|##3       |40497/173481[12:10<39:53,55.56it/s] 29%|##8       |50038/173481[15:00<36:46,55.94it/s] 29%|##9       |50640/173481[15:10<36:35,55.94it/s] 35%|###4      |60126/173481[18:00<33:44,55.99it/s] 35%|###5      |60734/173481[18:10<33:33,55.99it/s] 40%|####      |70117/173481[21:00<30:54,55.75it/s] 41%|####      |70735/173481[21:11<30:43,55.75it/s] 46%|####6     |80078/173481[24:00<28:01,55.54it/s] 47%|####6     |80700/173481[24:11<27:50,55.54it/s] 52%|#####1    |90020/173481[27:00<25:06,55.39it/s] 52%|#####2    |90643/173481[27:11<24:55,55.39it/s] 58%|#####7    |100090/173481[30:00<21:58,55.66it/s] 58%|#####8    |100728/173481[30:11<21:47,55.66it/s] 63%|######3   |110139/173481[33:00<18:56,55.74it/s] 64%|######3   |110786/173481[33:11<18:44,55.74it/s] 69%|######9   |120255/173481[36:00<15:51,55.97it/s] 70%|######9   |120910/173481[36:11<15:39,55.97it/s] 75%|#######5  |130352/173481[39:00<12:49,56.03it/s] 76%|#######5  |131015/173481[39:11<12:37,56.03it/s] 81%|########  |140310/173481[42:00<09:55,55.67it/s] 81%|########1 |140947/173481[42:12<09:44,55.67it/s] 86%|########6 |150015/173481[45:00<07:08,54.78it/s] 87%|########6 |150682/173481[45:12<06:56,54.78it/s] 92%|#########2|160045/173481[48:00<04:03,55.24it/s] 93%|#########2|160725/173481[48:12<03:50,55.24it/s] 98%|#########7|169763/173481[51:00<01:08,54.61it/s] 98%|#########8|170340/173481[51:12<00:57,54.61it/s]100%|##########|173481/173481[52:15<00:00,55.32it/s]
[32m[0325 09:59:54 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:3135.96 sec.
[32m[0325 09:59:54 @saver.py:84][0m Model saved to train_log/lcn_w_2_a_32_quant_ends_False/model-8500569.
[32m[0325 09:59:55 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 80%|########  |15114/18822[03:00<00:44,83.97it/s] 84%|########3 |15789/18822[04:02<00:36,83.97it/s]100%|##########|18822/18822[04:38<00:00,67.68it/s]
48
[32m[0325 10:04:33 @monitor.py:363][0m QueueInput/queue_size: 2.2283
[32m[0325 10:04:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.984
[32m[0325 10:04:33 @monitor.py:363][0m activation-summaries/output-rms: 0.034472
[32m[0325 10:04:33 @monitor.py:363][0m cross_entropy_loss: 2.0515
[32m[0325 10:04:33 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40543
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0a/b-rms: 9.2412e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.27042
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1731e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.38381
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0c/b-rms: 9.3364e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.26626
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0d/b-rms: 5.3661e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.3887
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0e/b-rms: 6.8352e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.26499
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.9739e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.37894
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.467e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.26628
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0h/b-rms: 5.5369e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.4151
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.835e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.26927
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5825e-06
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4587
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2414
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.96734
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090275
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76431
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.09294
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80666
[32m[0325 10:04:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.087594
[32m[0325 10:04:33 @monitor.py:363][0m train-error-top1: 0.53015
[32m[0325 10:04:33 @monitor.py:363][0m val-error-top1: 0.55746
[32m[0325 10:04:33 @monitor.py:363][0m val-utt-error: 0.19796
[32m[0325 10:04:33 @monitor.py:363][0m validation_cost: 2.1767
[32m[0325 10:04:33 @monitor.py:363][0m wd_cost: 2.063e-11
[32m[0325 10:04:33 @group.py:42][0m Callbacks took 279.069 sec in total. InferenceRunner: 278.169sec
[32m[0325 10:04:33 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10070/173481[03:00<48:41,55.94it/s]  6%|6         |10622/173481[03:10<48:31,55.94it/s] 11%|#1        |19587/173481[06:00<47:10,54.36it/s] 12%|#1        |20160/173481[06:10<47:00,54.36it/s] 17%|#6        |29324/173481[09:00<44:18,54.23it/s] 17%|#7        |29903/173481[09:10<44:07,54.23it/s] 23%|##2       |39388/173481[12:00<40:35,55.05it/s] 23%|##3       |39970/173481[12:10<40:25,55.05it/s] 28%|##8       |49423/173481[15:00<37:19,55.40it/s] 29%|##8       |50017/173481[15:10<37:08,55.40it/s] 34%|###4      |59464/173481[18:00<34:11,55.59it/s] 35%|###4      |60068/173481[18:10<34:00,55.59it/s] 40%|####      |69571/173481[21:00<31:00,55.87it/s] 40%|####      |70187/173481[21:11<30:48,55.87it/s] 46%|####5     |79464/173481[24:00<28:16,55.41it/s] 46%|####6     |80086/173481[24:11<28:05,55.41it/s] 52%|#####1    |89487/173481[27:00<25:12,55.54it/s] 52%|#####1    |90114/173481[27:11<25:00,55.54it/s] 57%|#####7    |99408/173481[30:00<22:18,55.33it/s] 58%|#####7    |100054/173481[30:11<22:07,55.33it/s] 63%|######3   |109514/173481[33:00<19:07,55.73it/s] 64%|######3   |110167/173481[33:11<18:56,55.73it/s] 69%|######8   |119565/173481[36:00<16:06,55.78it/s] 69%|######9   |120217/173481[36:11<15:54,55.78it/s] 75%|#######4  |129638/173481[39:00<13:04,55.87it/s] 75%|#######5  |130307/173481[39:12<12:52,55.87it/s]slurmstepd: *** STEP 82582.0 ON sls-tesla-0 CANCELLED AT 2018-03-25T10:45:36 DUE TO TIME LIMIT ***
srun: error: sls-tesla-0: task 0: Terminated
srun: Force Terminated job step 82582.0
