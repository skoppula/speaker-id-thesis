sls-titan-10 0
SLURM_JOBID=82364
SLURM_TASKID=2
[32m[0322 10:59:18 @logger.py:74][0m Argv: drf_run.py --model_name=cnn --bitw=4 --bita=4 --quant_ends=True --load_ckpt=train_log/cnn_w_4_a_32_quant_ends_True_preload/checkpoint
[32m[0322 10:59:24 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0322 10:59:24 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0322 10:59:24 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0322 10:59:24 @drf_run.py:166][0m Using host: sls-titan-10
[32m[0322 10:59:24 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0322 10:59:24 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0322 10:59:25 @drf_run.py:188][0m Using GPU: 0
[32m[0322 10:59:25 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0322 10:59:25 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0322 10:59:25 @training.py:108][0m Building graph for training tower 0 ...
[32m[0322 10:59:25 @registry.py:122][0m conv0 input: [None, 50, 20, 1]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight conv0/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight conv0/b
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing conv0/bn/beta
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing conv0/bn/gamma
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing conv0/bn/mean/EMA
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing conv0/bn/variance/EMA
[32m[0322 10:59:25 @registry.py:130][0m conv0 output: [None, 10, 4, 6]
[32m[0322 10:59:25 @registry.py:122][0m linear0 input: [None, 10, 4, 6]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 10:59:25 @registry.py:130][0m linear0 output: [None, 256]
[32m[0322 10:59:25 @registry.py:122][0m linear1 input: [None, 256]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 10:59:25 @registry.py:130][0m linear1 output: [None, 256]
[32m[0322 10:59:25 @registry.py:122][0m linear2 input: [None, 256]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 10:59:25 @registry.py:130][0m linear2 output: [None, 256]
[32m[0322 10:59:25 @registry.py:122][0m last_linear input: [None, 256]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 10:59:25 @registry.py:130][0m last_linear output: [None, 255]
[32m[0322 10:59:25 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 10:59:25 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0322 10:59:25 @regularize.py:18][0m Applying regularizer for conv0/W:0, linear0/W:0, linear1/W:0, linear2/W:0, last_linear/W:0
[32m[0322 10:59:25 @drf_run.py:123][0m Parameter count: {'mults': 265808, 'weights': 259979}
[32m[0322 10:59:26 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  ------------  -----
conv0/W:0           [5, 5, 1, 6]    150
conv0/b:0           [6]               6
conv0/bn/beta:0     [6]               6
conv0/bn/gamma:0    [6]               6
linear0/W:0         [240, 256]    61440
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=260519, size=0.99MB[0m
[32m[0322 10:59:26 @base.py:196][0m Setup callbacks graph ...
[32m[0322 10:59:26 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight conv0/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight conv0/b
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing conv0/bn/beta
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing conv0/bn/gamma
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing conv0/bn/mean/EMA
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing conv0/bn/variance/EMA
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 10:59:26 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 10:59:26 @drf_run.py:123][0m Parameter count: {'mults': 531616, 'weights': 519958}
[32m[0322 10:59:26 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0322 10:59:26 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0322 10:59:27 @base.py:212][0m Creating the session ...
2018-03-22 10:59:27.620514: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-22 10:59:30.250676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:02:00.0
totalMemory: 11.92GiB freeMemory: 11.81GiB
2018-03-22 10:59:30.250703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0, compute capability: 5.2)
[32m[0322 10:59:34 @base.py:220][0m Initializing the session ...
[32m[0322 10:59:34 @sessinit.py:116][0m Restoring checkpoint from train_log/cnn_w_4_a_32_quant_ends_True_preload/model-7112721 ...
[32m[0322 10:59:35 @base.py:227][0m Graph Finalized.
[32m[0322 10:59:35 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0322 10:59:35 @steps.py:127][0m Start training with global_step=7112721
[32m[0322 10:59:40 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10171/173481[03:00<48:10,56.49it/s]  6%|6         |10774/173481[03:10<48:00,56.49it/s] 12%|#2        |21094/173481[06:00<43:24,58.50it/s] 13%|#2        |21713/173481[06:10<43:14,58.50it/s] 18%|#8        |31551/173481[09:00<40:34,58.30it/s] 18%|#8        |32045/173481[09:10<40:26,58.30it/s] 23%|##3       |40531/173481[12:00<41:12,53.76it/s] 24%|##3       |41045/173481[12:10<41:03,53.76it/s] 29%|##8       |50035/173481[15:00<38:37,53.28it/s] 29%|##9       |50610/173481[15:10<38:26,53.28it/s] 35%|###4      |59910/173481[18:00<35:00,54.06it/s] 35%|###4      |60502/173481[18:10<34:50,54.06it/s] 40%|####      |69811/173481[21:00<31:41,54.51it/s] 41%|####      |70414/173481[21:11<31:30,54.51it/s] 46%|####5     |79632/173481[24:00<28:40,54.54it/s] 46%|####6     |80285/173481[24:11<28:28,54.54it/s] 52%|#####1    |89508/173481[27:00<25:35,54.70it/s] 52%|#####1    |90110/173481[27:11<25:24,54.70it/s] 57%|#####6    |98386/173481[30:00<24:08,51.86it/s] 57%|#####7    |98920/173481[30:11<23:57,51.86it/s] 62%|######1   |107196/173481[33:00<21:56,50.36it/s] 62%|######2   |107794/173481[33:11<21:44,50.36it/s] 67%|######7   |116412/173481[36:00<18:44,50.77it/s] 67%|######7   |117004/173481[36:11<18:32,50.77it/s] 73%|#######2  |125861/173481[39:00<15:22,51.62it/s] 73%|#######2  |126490/173481[39:12<15:10,51.62it/s] 78%|#######8  |135335/173481[42:00<12:11,52.12it/s] 78%|#######8  |135945/173481[42:12<12:00,52.12it/s] 83%|########3 |144600/173481[45:00<09:17,51.79it/s] 84%|########3 |145190/173481[45:12<09:06,51.79it/s] 88%|########8 |153156/173481[48:00<06:50,49.57it/s] 89%|########8 |153701/173481[48:12<06:39,49.57it/s] 93%|#########2|161191/173481[51:00<04:21,46.97it/s] 93%|#########3|161764/173481[51:12<04:09,46.97it/s] 98%|#########7|169531/173481[54:00<01:24,46.64it/s] 98%|#########8|170120/173481[54:12<01:12,46.64it/s]100%|##########|173481/173481[55:19<00:00,52.26it/s]
[32m[0322 11:54:59 @base.py:257][0m Epoch 1 (global_step 7286202) finished, time:3319.48 sec.
[32m[0322 11:54:59 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-7286202.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######8  |14758/18822[03:00<00:49,81.99it/s] 82%|########2 |15485/18822[03:10<00:40,81.99it/s]100%|##########|18822/18822[03:55<00:00,79.99it/s]
0
[32m[0322 11:58:55 @monitor.py:363][0m QueueInput/queue_size: 1.4503
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.438
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/output-rms: 0.01027
[32m[0322 11:58:55 @monitor.py:363][0m cross_entropy_loss: 6.2028
[32m[0322 11:58:55 @monitor.py:363][0m lr: 3.0518e-08
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/conv0/W-rms: 0.7408
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00020415
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72273
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3968
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.5125
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41326
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40006
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 11:58:55 @monitor.py:363][0m train-error-top1: 0.9892
[32m[0322 11:58:55 @monitor.py:363][0m val-error-top1: 0.98974
[32m[0322 11:58:55 @monitor.py:363][0m val-utt-error: 0.98316
[32m[0322 11:58:55 @monitor.py:363][0m validation_cost: 6.2606
[32m[0322 11:58:55 @monitor.py:363][0m wd_cost: 2.3593e-10
[32m[0322 11:58:55 @group.py:42][0m Callbacks took 235.444 sec in total. InferenceRunner: 235.311sec
[32m[0322 11:58:55 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8900/173481[03:00<55:28,49.44it/s]  5%|5         |9399/173481[03:10<55:18,49.44it/s] 10%|#         |18124/173481[06:00<51:27,50.33it/s] 11%|#         |18659/173481[06:10<51:16,50.33it/s] 16%|#5        |27455/173481[09:00<47:39,51.07it/s] 16%|#6        |28004/173481[09:10<47:28,51.07it/s] 21%|##        |36308/173481[12:00<45:37,50.11it/s] 21%|##1       |36814/173481[12:10<45:27,50.11it/s] 26%|##5       |44645/173481[15:00<44:36,48.13it/s] 26%|##6       |45154/173481[15:10<44:26,48.13it/s] 31%|###       |53199/173481[18:00<41:55,47.82it/s] 31%|###       |53719/173481[18:10<41:44,47.82it/s] 36%|###5      |62205/173481[21:00<37:55,48.90it/s] 36%|###6      |62794/173481[21:11<37:43,48.90it/s] 41%|####      |70506/173481[24:00<36:09,47.47it/s] 41%|####      |71059/173481[24:11<35:57,47.47it/s] 46%|####6     |79975/173481[27:00<31:13,49.90it/s] 46%|####6     |80589/173481[27:11<31:01,49.90it/s] 51%|#####1    |89313/173481[30:00<27:34,50.87it/s] 52%|#####1    |89901/173481[30:11<27:23,50.87it/s] 57%|#####7    |99121/173481[33:00<23:33,52.62it/s] 57%|#####7    |99703/173481[33:11<23:22,52.62it/s] 63%|######2   |108570/173481[36:00<20:35,52.55it/s] 63%|######2   |109163/173481[36:11<20:23,52.55it/s] 68%|######7   |117185/173481[39:00<18:43,50.09it/s] 68%|######7   |117749/173481[39:12<18:32,50.09it/s] 73%|#######2  |126305/173481[42:00<15:36,50.38it/s] 73%|#######3  |126909/173481[42:12<15:24,50.38it/s] 78%|#######8  |135386/173481[45:00<12:35,50.41it/s] 78%|#######8  |136084/173481[45:12<12:21,50.41it/s] 84%|########3 |144923/173481[48:00<09:12,51.67it/s] 84%|########3 |145514/173481[48:12<09:01,51.67it/s] 89%|########8 |153685/173481[51:00<06:35,50.11it/s] 89%|########8 |154249/173481[51:12<06:23,50.11it/s] 94%|#########3|162854/173481[54:00<03:30,50.52it/s] 94%|#########4|163489/173481[54:12<03:17,50.52it/s]100%|#########9|172635/173481[57:00<00:16,52.36it/s]100%|#########9|173434/173481[57:13<00:00,52.36it/s]100%|##########|173481/173481[57:13<00:00,50.52it/s]
[32m[0322 12:56:09 @base.py:257][0m Epoch 2 (global_step 7459683) finished, time:3433.88 sec.
[32m[0322 12:56:09 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-7459683.
[32m[0322 12:56:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:40<00:00,117.08it/s]
1
[32m[0322 12:58:50 @monitor.py:363][0m QueueInput/queue_size: 0.9334
[32m[0322 12:58:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.437
[32m[0322 12:58:50 @monitor.py:363][0m activation-summaries/output-rms: 0.0096593
[32m[0322 12:58:50 @monitor.py:363][0m cross_entropy_loss: 6.0687
[32m[0322 12:58:50 @monitor.py:363][0m lr: 3.0518e-08
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/conv0/W-rms: 0.7408
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00020255
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72258
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.5125
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41325
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 12:58:50 @monitor.py:363][0m train-error-top1: 0.99089
[32m[0322 12:58:50 @monitor.py:363][0m val-error-top1: 0.98914
[32m[0322 12:58:50 @monitor.py:363][0m val-utt-error: 0.97997
[32m[0322 12:58:50 @monitor.py:363][0m validation_cost: 6.1433
[32m[0322 12:58:50 @monitor.py:363][0m wd_cost: 2.3588e-10
[32m[0322 12:58:50 @group.py:42][0m Callbacks took 161.027 sec in total. InferenceRunner: 160.776sec
[32m[0322 12:58:50 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12229/173481[03:00<39:34,67.92it/s]  7%|7         |12813/173481[03:10<39:25,67.92it/s] 13%|#2        |22375/173481[06:00<40:52,61.60it/s] 13%|#3        |22948/173481[06:10<40:43,61.60it/s] 18%|#7        |30935/173481[09:00<44:15,53.68it/s] 18%|#8        |31423/173481[09:10<44:06,53.68it/s] 23%|##3       |40114/173481[12:00<42:30,52.29it/s] 23%|##3       |40603/173481[12:10<42:21,52.29it/s] 28%|##8       |48839/173481[15:00<41:17,50.31it/s] 28%|##8       |49406/173481[15:10<41:06,50.31it/s] 34%|###3      |58304/173481[18:00<37:20,51.42it/s] 34%|###3      |58878/173481[18:10<37:08,51.42it/s] 39%|###8      |67619/173481[21:00<34:12,51.58it/s] 39%|###9      |68199/173481[21:11<34:01,51.58it/s] 45%|####4     |78041/173481[24:00<29:09,54.55it/s] 45%|####5     |78693/173481[24:11<28:57,54.55it/s] 51%|#####     |87954/173481[27:00<26:00,54.80it/s] 51%|#####1    |88563/173481[27:11<25:49,54.80it/s] 56%|#####6    |97455/173481[30:00<23:33,53.77it/s] 57%|#####6    |98043/173481[30:11<23:22,53.77it/s] 62%|######1   |106952/173481[33:00<20:49,53.26it/s] 62%|######2   |107603/173481[33:11<20:36,53.26it/s] 67%|######7   |116685/173481[36:00<17:38,53.66it/s] 68%|######7   |117338/173481[36:11<17:26,53.66it/s] 73%|#######2  |126429/173481[39:00<14:33,53.90it/s] 73%|#######3  |127108/173481[39:12<14:20,53.90it/s] 79%|#######8  |137022/173481[42:00<10:48,56.26it/s] 79%|#######9  |137698/173481[42:12<10:35,56.26it/s] 85%|########4 |147104/173481[45:00<07:49,56.13it/s] 85%|########5 |147806/173481[45:12<07:37,56.13it/s] 91%|######### |157293/173481[48:00<04:47,56.36it/s] 91%|#########1|157963/173481[48:12<04:35,56.36it/s] 96%|#########6|166909/173481[51:00<01:59,54.84it/s] 97%|#########6|167618/173481[51:12<01:46,54.84it/s]100%|##########|173481/173481[52:56<00:00,54.62it/s]
[32m[0322 13:51:46 @base.py:257][0m Epoch 3 (global_step 7633164) finished, time:3176.10 sec.
[32m[0322 13:51:46 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-7633164.
[32m[0322 13:51:46 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:51<00:00,110.07it/s]
2
[32m[0322 13:54:37 @monitor.py:363][0m QueueInput/queue_size: 1.0429
[32m[0322 13:54:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.471
[32m[0322 13:54:37 @monitor.py:363][0m activation-summaries/output-rms: 0.0097303
[32m[0322 13:54:37 @monitor.py:363][0m cross_entropy_loss: 6.0289
[32m[0322 13:54:37 @monitor.py:363][0m lr: 1.5259e-08
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/conv0/W-rms: 0.7408
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00020149
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.7225
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.5125
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 13:54:37 @monitor.py:363][0m train-error-top1: 0.98777
[32m[0322 13:54:37 @monitor.py:363][0m val-error-top1: 0.98885
[32m[0322 13:54:37 @monitor.py:363][0m val-utt-error: 0.9796
[32m[0322 13:54:37 @monitor.py:363][0m validation_cost: 6.0797
[32m[0322 13:54:37 @monitor.py:363][0m wd_cost: 2.3585e-10
[32m[0322 13:54:37 @group.py:42][0m Callbacks took 171.701 sec in total. InferenceRunner: 171.020sec
[32m[0322 13:54:37 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13123/173481[03:00<36:39,72.90it/s]  8%|7         |13660/173481[03:10<36:32,72.90it/s] 13%|#3        |23015/173481[06:00<40:00,62.67it/s] 14%|#3        |23607/173481[06:10<39:51,62.67it/s] 19%|#9        |33808/173481[09:00<37:59,61.28it/s] 20%|#9        |34467/173481[09:10<37:48,61.28it/s] 26%|##5       |44613/173481[12:00<35:25,60.64it/s] 26%|##6       |45207/173481[12:10<35:15,60.64it/s] 31%|###1      |54591/173481[15:00<34:12,57.92it/s] 32%|###1      |55141/173481[15:10<34:03,57.92it/s] 37%|###7      |64468/173481[18:00<32:14,56.35it/s] 37%|###7      |65016/173481[18:10<32:04,56.35it/s] 43%|####3     |74758/173481[21:00<28:59,56.75it/s] 43%|####3     |75433/173481[21:11<28:47,56.75it/s] 49%|####9     |85591/173481[24:00<25:04,58.42it/s] 50%|####9     |86212/173481[24:11<24:53,58.42it/s] 55%|#####5    |95804/173481[27:00<22:29,57.57it/s] 56%|#####5    |96487/173481[27:11<22:17,57.57it/s] 61%|######1   |106508/173481[30:00<19:04,58.50it/s] 62%|######1   |107187/173481[30:11<18:53,58.50it/s] 67%|######7   |116718/173481[33:00<16:25,57.60it/s] 68%|######7   |117422/173481[33:11<16:13,57.60it/s] 73%|#######3  |127455/173481[36:00<13:05,58.60it/s] 74%|#######3  |128164/173481[36:11<12:53,58.60it/s] 80%|#######9  |138388/173481[39:00<09:48,59.65it/s] 80%|########  |139123/173481[39:12<09:36,59.65it/s] 86%|########5 |148508/173481[42:00<07:11,57.88it/s] 86%|########5 |149112/173481[42:12<07:01,57.88it/s] 92%|#########1|158823/173481[45:00<04:14,57.59it/s] 92%|#########1|159561/173481[45:12<04:01,57.59it/s] 97%|#########7|169123/173481[48:00<01:15,57.40it/s] 98%|#########7|169662/173481[48:12<01:06,57.40it/s][32m[0322 14:44:01 @base.py:257][0m Epoch 4 (global_step 7806645) finished, time:2963.94 sec.
100%|##########|173481/173481[49:23<00:00,58.53it/s]
[32m[0322 14:44:01 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-7806645.
[32m[0322 14:44:02 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.59it/s]
3
[32m[0322 14:45:55 @monitor.py:363][0m QueueInput/queue_size: 0.73744
[32m[0322 14:45:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.514
[32m[0322 14:45:55 @monitor.py:363][0m activation-summaries/output-rms: 0.0092522
[32m[0322 14:45:55 @monitor.py:363][0m cross_entropy_loss: 6.0098
[32m[0322 14:45:55 @monitor.py:363][0m lr: 1.5259e-08
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00020053
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72248
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.5125
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 14:45:55 @monitor.py:363][0m train-error-top1: 0.98812
[32m[0322 14:45:55 @monitor.py:363][0m val-error-top1: 0.9888
[32m[0322 14:45:55 @monitor.py:363][0m val-utt-error: 0.9779
[32m[0322 14:45:55 @monitor.py:363][0m validation_cost: 6.0618
[32m[0322 14:45:55 @monitor.py:363][0m wd_cost: 4.7169e-11
[32m[0322 14:45:55 @group.py:42][0m Callbacks took 113.296 sec in total. InferenceRunner: 112.996sec
[32m[0322 14:45:55 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10803/173481[03:00<45:10,60.01it/s]  7%|6         |11316/173481[03:10<45:02,60.01it/s] 12%|#1        |20317/173481[06:00<45:25,56.20it/s] 12%|#1        |20786/173481[06:10<45:17,56.20it/s] 17%|#7        |30031/173481[09:00<43:25,55.06it/s] 18%|#7        |30611/173481[09:10<43:14,55.06it/s] 23%|##3       |40652/173481[12:00<38:52,56.95it/s] 24%|##3       |41306/173481[12:10<38:40,56.95it/s] 30%|##9       |51312/173481[15:00<35:04,58.06it/s] 30%|##9       |51921/173481[15:10<34:53,58.06it/s] 36%|###5      |62073/173481[18:00<31:31,58.91it/s] 36%|###6      |62703/173481[18:10<31:20,58.91it/s] 42%|####1     |72786/173481[21:00<28:20,59.21it/s] 42%|####2     |73421/173481[21:11<28:09,59.21it/s] 48%|####7     |83209/173481[24:00<25:41,58.55it/s] 48%|####8     |83856/173481[24:11<25:30,58.55it/s] 54%|#####3    |93391/173481[27:00<23:11,57.54it/s] 54%|#####4    |94016/173481[27:11<23:01,57.54it/s] 60%|#####9    |103702/173481[30:00<20:15,57.41it/s] 60%|######    |104397/173481[30:11<20:03,57.41it/s] 66%|######5   |114155/173481[33:00<17:07,57.74it/s] 66%|######6   |114803/173481[33:11<16:56,57.74it/s] 72%|#######1  |124381/173481[36:00<14:17,57.27it/s] 72%|#######2  |125055/173481[36:11<14:05,57.27it/s] 77%|#######7  |134396/173481[39:00<11:32,56.44it/s] 78%|#######7  |135066/173481[39:12<11:20,56.44it/s] 83%|########3 |144665/173481[42:00<08:27,56.74it/s] 84%|########3 |145366/173481[42:12<08:15,56.74it/s] 89%|########9 |155032/173481[45:00<05:22,57.16it/s] 90%|########9 |155618/173481[45:12<05:12,57.16it/s] 95%|#########4|164636/173481[48:00<02:40,55.19it/s] 95%|#########5|165290/173481[48:12<02:28,55.19it/s]100%|##########|173481/173481[50:42<00:00,57.03it/s]
[32m[0322 15:36:37 @base.py:257][0m Epoch 5 (global_step 7980126) finished, time:3042.13 sec.
[32m[0322 15:36:37 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-7980126.
[32m[0322 15:36:37 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.21it/s]
4
[32m[0322 15:38:45 @monitor.py:363][0m QueueInput/queue_size: 1.1381
[32m[0322 15:38:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.49
[32m[0322 15:38:45 @monitor.py:363][0m activation-summaries/output-rms: 0.009173
[32m[0322 15:38:45 @monitor.py:363][0m cross_entropy_loss: 5.9453
[32m[0322 15:38:45 @monitor.py:363][0m lr: 1.5259e-08
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00020026
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.5125
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 15:38:45 @monitor.py:363][0m train-error-top1: 0.9851
[32m[0322 15:38:45 @monitor.py:363][0m val-error-top1: 0.9888
[32m[0322 15:38:45 @monitor.py:363][0m val-utt-error: 0.97885
[32m[0322 15:38:45 @monitor.py:363][0m validation_cost: 6.0451
[32m[0322 15:38:45 @monitor.py:363][0m wd_cost: 4.7168e-11
[32m[0322 15:38:45 @group.py:42][0m Callbacks took 128.091 sec in total. InferenceRunner: 127.863sec
[32m[0322 15:38:45 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11078/173481[03:00<43:58,61.54it/s]  7%|6         |11565/173481[03:10<43:50,61.54it/s] 12%|#1        |20561/173481[06:00<44:53,56.77it/s] 12%|#2        |21115/173481[06:10<44:44,56.77it/s] 18%|#7        |30366/173481[09:00<42:54,55.59it/s] 18%|#7        |30960/173481[09:10<42:43,55.59it/s] 23%|##3       |40441/173481[12:00<39:45,55.78it/s] 24%|##3       |41020/173481[12:10<39:34,55.78it/s] 29%|##9       |50581/173481[15:00<36:32,56.05it/s] 29%|##9       |51150/173481[15:10<36:22,56.05it/s] 35%|###5      |60745/173481[18:00<33:23,56.26it/s] 35%|###5      |61345/173481[18:10<33:13,56.26it/s] 41%|####      |70551/173481[21:00<30:59,55.35it/s] 41%|####1     |71155/173481[21:11<30:48,55.35it/s] 46%|####6     |80286/173481[24:00<28:23,54.70it/s] 47%|####6     |80945/173481[24:11<28:11,54.70it/s] 52%|#####1    |90176/173481[27:00<25:19,54.82it/s] 52%|#####2    |90805/173481[27:11<25:08,54.82it/s] 58%|#####7    |99755/173481[30:00<22:45,54.01it/s] 58%|#####7    |100402/173481[30:11<22:33,54.01it/s] 63%|######2   |109022/173481[33:00<20:22,52.71it/s] 63%|######3   |109694/173481[33:11<20:10,52.71it/s] 68%|######8   |118811/173481[36:00<17:01,53.53it/s] 69%|######8   |119395/173481[36:11<16:50,53.53it/s] 74%|#######4  |129016/173481[39:00<13:27,55.06it/s] 75%|#######4  |129682/173481[39:12<13:15,55.06it/s] 80%|########  |138956/173481[42:00<10:26,55.14it/s] 81%|########  |139660/173481[42:12<10:13,55.14it/s] 86%|########6 |149276/173481[45:00<07:10,56.21it/s] 86%|########6 |149945/173481[45:12<06:58,56.21it/s] 91%|#########1|158717/173481[48:00<04:32,54.26it/s] 92%|#########1|159352/173481[48:12<04:20,54.26it/s] 97%|#########7|168321/173481[51:00<01:35,53.80it/s] 97%|#########7|168972/173481[51:12<01:23,53.80it/s]100%|##########|173481/173481[52:36<00:00,54.96it/s]
[32m[0322 16:31:21 @base.py:257][0m Epoch 6 (global_step 8153607) finished, time:3156.40 sec.
[32m[0322 16:31:21 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-8153607.
[32m[0322 16:31:21 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:30<00:00,124.66it/s]
5
[32m[0322 16:33:52 @monitor.py:363][0m QueueInput/queue_size: 0.60043
[32m[0322 16:33:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.708
[32m[0322 16:33:52 @monitor.py:363][0m activation-summaries/output-rms: 0.0091846
[32m[0322 16:33:52 @monitor.py:363][0m cross_entropy_loss: 5.9537
[32m[0322 16:33:52 @monitor.py:363][0m lr: 7.6294e-09
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/conv0/b-rms: 0.0002002
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40004
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 16:33:52 @monitor.py:363][0m train-error-top1: 0.98915
[32m[0322 16:33:52 @monitor.py:363][0m val-error-top1: 0.98875
[32m[0322 16:33:52 @monitor.py:363][0m val-utt-error: 0.97848
[32m[0322 16:33:52 @monitor.py:363][0m validation_cost: 6.0333
[32m[0322 16:33:52 @monitor.py:363][0m wd_cost: 4.7167e-11
[32m[0322 16:33:52 @group.py:42][0m Callbacks took 151.288 sec in total. InferenceRunner: 150.998sec
[32m[0322 16:33:52 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12182/173481[03:00<39:43,67.68it/s]  7%|7         |12701/173481[03:10<39:35,67.68it/s] 13%|#2        |22125/173481[06:00<41:28,60.82it/s] 13%|#3        |22704/173481[06:10<41:19,60.82it/s] 19%|#8        |32345/173481[09:00<40:03,58.72it/s] 19%|#8        |32844/173481[09:10<39:55,58.72it/s] 23%|##3       |40325/173481[12:00<43:55,50.52it/s] 24%|##3       |40824/173481[12:10<43:45,50.52it/s] 29%|##8       |49543/173481[15:00<40:36,50.86it/s] 29%|##8       |50106/173481[15:10<40:25,50.86it/s] 34%|###4      |59460/173481[18:00<35:56,52.88it/s] 35%|###4      |60060/173481[18:10<35:44,52.88it/s] 40%|###9      |69019/173481[21:00<32:51,52.99it/s] 40%|####      |69644/173481[21:11<32:39,52.99it/s] 45%|####5     |78900/173481[24:00<29:14,53.92it/s] 46%|####5     |79449/173481[24:11<29:03,53.92it/s] 51%|#####     |88417/173481[27:00<26:33,53.39it/s] 51%|#####1    |89075/173481[27:11<26:20,53.39it/s] 57%|#####6    |98443/173481[30:00<22:56,54.52it/s] 57%|#####7    |99047/173481[30:11<22:45,54.52it/s] 63%|######2   |108584/173481[33:00<19:31,55.41it/s] 63%|######2   |109200/173481[33:11<19:20,55.41it/s] 68%|######8   |118198/173481[36:00<16:56,54.39it/s] 68%|######8   |118808/173481[36:11<16:45,54.39it/s] 74%|#######3  |127550/173481[39:00<14:24,53.14it/s] 74%|#######3  |128180/173481[39:12<14:12,53.14it/s] 79%|#######8  |136723/173481[42:00<11:46,52.03it/s] 79%|#######9  |137364/173481[42:12<11:34,52.03it/s] 84%|########4 |146386/173481[45:00<08:32,52.84it/s] 85%|########4 |147047/173481[45:12<08:20,52.84it/s] 88%|########8 |152675/173481[48:00<08:14,42.06it/s] 88%|########8 |153365/173481[48:12<07:58,42.06it/s] 94%|#########3|162781/173481[51:00<03:42,48.09it/s] 94%|#########4|163209/173481[51:12<03:33,48.09it/s]100%|#########9|172879/173481[54:00<00:11,51.79it/s]100%|##########|173481/173481[54:10<00:00,53.36it/s]
[32m[0322 17:28:03 @base.py:257][0m Epoch 7 (global_step 8327088) finished, time:3250.89 sec.
[32m[0322 17:28:03 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-8327088.
[32m[0322 17:28:04 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:12<00:00,142.18it/s]
6
[32m[0322 17:30:16 @monitor.py:363][0m QueueInput/queue_size: 0.76015
[32m[0322 17:30:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.569
[32m[0322 17:30:16 @monitor.py:363][0m activation-summaries/output-rms: 0.0090629
[32m[0322 17:30:16 @monitor.py:363][0m cross_entropy_loss: 5.96
[32m[0322 17:30:16 @monitor.py:363][0m lr: 7.6294e-09
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00020003
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 17:30:17 @monitor.py:363][0m train-error-top1: 0.99172
[32m[0322 17:30:17 @monitor.py:363][0m val-error-top1: 0.98872
[32m[0322 17:30:17 @monitor.py:363][0m val-utt-error: 0.97859
[32m[0322 17:30:17 @monitor.py:363][0m validation_cost: 6.0336
[32m[0322 17:30:17 @monitor.py:363][0m wd_cost: 9.4335e-12
[32m[0322 17:30:17 @group.py:42][0m Callbacks took 133.118 sec in total. InferenceRunner: 132.392sec
[32m[0322 17:30:17 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12518/173481[03:00<38:34,69.54it/s]  8%|7         |13138/173481[03:10<38:25,69.54it/s] 13%|#3        |23144/173481[06:00<39:14,63.86it/s] 14%|#3        |23730/173481[06:10<39:05,63.86it/s] 19%|#9        |32978/173481[09:00<39:46,58.88it/s] 19%|#9        |33578/173481[09:10<39:35,58.88it/s] 25%|##4       |43159/173481[12:00<37:38,57.70it/s] 25%|##5       |43749/173481[12:10<37:28,57.70it/s] 31%|###       |53599/173481[15:00<34:32,57.84it/s] 31%|###1      |54280/173481[15:10<34:20,57.84it/s] 37%|###6      |63809/173481[18:00<31:54,57.27it/s] 37%|###7      |64488/173481[18:10<31:43,57.27it/s] 43%|####2     |73787/173481[21:00<29:29,56.34it/s] 43%|####2     |74362/173481[21:11<29:19,56.34it/s] 48%|####8     |83770/173481[24:00<26:45,55.89it/s] 49%|####8     |84319/173481[24:11<26:35,55.89it/s] 54%|#####4    |94334/173481[27:00<23:02,57.25it/s] 55%|#####4    |94963/173481[27:11<22:51,57.25it/s] 60%|######    |104924/173481[30:00<19:41,58.02it/s] 61%|######    |105547/173481[30:11<19:30,58.02it/s] 67%|######6   |116187/173481[33:00<15:51,60.21it/s] 67%|######7   |116870/173481[33:11<15:40,60.21it/s] 73%|#######3  |126929/173481[36:00<12:56,59.94it/s] 74%|#######3  |127643/173481[36:11<12:44,59.94it/s] 79%|#######9  |137529/173481[39:00<10:05,59.40it/s] 80%|#######9  |138234/173481[39:12<09:53,59.40it/s] 85%|########5 |148174/173481[42:00<07:07,59.26it/s] 86%|########5 |148843/173481[42:12<06:55,59.26it/s] 92%|#########1|158977/173481[45:00<04:03,59.64it/s] 92%|#########2|159714/173481[45:12<03:50,59.64it/s] 98%|#########7|169877/173481[48:00<00:59,60.09it/s] 98%|#########8|170628/173481[48:12<00:47,60.09it/s]100%|##########|173481/173481[49:01<00:00,58.98it/s]
[32m[0322 18:19:18 @base.py:257][0m Epoch 8 (global_step 8500569) finished, time:2941.42 sec.
[32m[0322 18:19:18 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-8500569.
[32m[0322 18:19:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.69it/s]
7
[32m[0322 18:21:22 @monitor.py:363][0m QueueInput/queue_size: 1.0565
[32m[0322 18:21:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.536
[32m[0322 18:21:22 @monitor.py:363][0m activation-summaries/output-rms: 0.0092132
[32m[0322 18:21:22 @monitor.py:363][0m cross_entropy_loss: 5.9714
[32m[0322 18:21:22 @monitor.py:363][0m lr: 3.8147e-09
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019992
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 18:21:22 @monitor.py:363][0m train-error-top1: 0.98941
[32m[0322 18:21:22 @monitor.py:363][0m val-error-top1: 0.98858
[32m[0322 18:21:22 @monitor.py:363][0m val-utt-error: 0.97981
[32m[0322 18:21:22 @monitor.py:363][0m validation_cost: 6.0226
[32m[0322 18:21:22 @monitor.py:363][0m wd_cost: 9.4334e-12
[32m[0322 18:21:22 @group.py:42][0m Callbacks took 123.700 sec in total. InferenceRunner: 122.482sec
[32m[0322 18:21:22 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12223/173481[03:00<39:34,67.90it/s]  7%|7         |12744/173481[03:10<39:27,67.90it/s] 13%|#2        |22168/173481[06:00<41:23,60.92it/s] 13%|#3        |22682/173481[06:10<41:15,60.92it/s] 18%|#8        |31729/173481[09:00<41:37,56.75it/s] 19%|#8        |32349/173481[09:10<41:26,56.75it/s] 24%|##4       |42288/173481[12:00<37:54,57.68it/s] 25%|##4       |42867/173481[12:10<37:44,57.68it/s] 31%|###       |53218/173481[15:00<33:53,59.15it/s] 31%|###1      |53847/173481[15:10<33:42,59.15it/s] 36%|###6      |62903/173481[18:00<32:42,56.35it/s] 37%|###6      |63512/173481[18:10<32:31,56.35it/s] 42%|####2     |73724/173481[21:00<28:34,58.17it/s] 43%|####2     |74392/173481[21:11<28:23,58.17it/s] 49%|####8     |84598/173481[24:00<24:59,59.27it/s] 49%|####9     |85297/173481[24:11<24:47,59.27it/s] 55%|#####5    |95668/173481[27:00<21:29,60.36it/s] 56%|#####5    |96322/173481[27:11<21:18,60.36it/s] 61%|######1   |106668/173481[30:00<18:20,60.72it/s] 62%|######1   |107352/173481[30:11<18:09,60.72it/s] 68%|######7   |117831/173481[33:00<15:06,61.36it/s] 68%|######8   |118464/173481[33:11<14:56,61.36it/s] 74%|#######4  |128529/173481[36:00<12:24,60.38it/s] 74%|#######4  |129236/173481[36:11<12:12,60.38it/s] 80%|########  |139298/173481[39:00<09:28,60.09it/s] 81%|########  |139949/173481[39:12<09:17,60.09it/s] 86%|########6 |149663/173481[42:00<06:45,58.81it/s] 87%|########6 |150344/173481[42:12<06:33,58.81it/s] 92%|#########2|160278/173481[45:00<03:44,58.89it/s] 93%|#########2|160957/173481[45:12<03:32,58.89it/s] 98%|#########8|170276/173481[48:00<00:56,57.17it/s] 99%|#########8|170881/173481[48:12<00:45,57.17it/s]100%|##########|173481/173481[49:01<00:00,58.99it/s]
[32m[0322 19:10:23 @base.py:257][0m Epoch 9 (global_step 8674050) finished, time:2941.10 sec.
[32m[0322 19:10:23 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-8674050.
[32m[0322 19:10:23 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:20<00:00,133.56it/s]
8
[32m[0322 19:12:44 @monitor.py:363][0m QueueInput/queue_size: 0.14678
[32m[0322 19:12:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.552
[32m[0322 19:12:44 @monitor.py:363][0m activation-summaries/output-rms: 0.0090707
[32m[0322 19:12:44 @monitor.py:363][0m cross_entropy_loss: 5.9724
[32m[0322 19:12:44 @monitor.py:363][0m lr: 3.8147e-09
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019993
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 19:12:44 @monitor.py:363][0m train-error-top1: 0.99086
[32m[0322 19:12:44 @monitor.py:363][0m val-error-top1: 0.98859
[32m[0322 19:12:44 @monitor.py:363][0m val-utt-error: 0.97747
[32m[0322 19:12:44 @monitor.py:363][0m validation_cost: 6.0229
[32m[0322 19:12:44 @monitor.py:363][0m wd_cost: 1.8867e-12
[32m[0322 19:12:44 @group.py:42][0m Callbacks took 141.225 sec in total. InferenceRunner: 140.933sec
[32m[0322 19:12:44 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11947/173481[03:00<40:34,66.35it/s]  7%|7         |12522/173481[03:10<40:25,66.35it/s] 13%|#2        |22138/173481[06:00<41:17,61.10it/s] 13%|#3        |22611/173481[06:10<41:09,61.10it/s] 19%|#8        |32490/173481[09:00<39:39,59.25it/s] 19%|#9        |33042/173481[09:10<39:30,59.25it/s] 25%|##5       |44221/173481[12:00<34:42,62.07it/s] 26%|##5       |44942/173481[12:10<34:30,62.07it/s] 33%|###2      |57230/173481[15:00<29:00,66.78it/s] 34%|###3      |58238/173481[15:10<28:45,66.78it/s] 41%|####      |70787/173481[18:00<24:10,70.79it/s] 41%|####1     |71468/173481[18:10<24:01,70.79it/s] 48%|####8     |83507/173481[21:00<21:12,70.72it/s] 49%|####8     |84258/173481[21:11<21:01,70.72it/s] 55%|#####5    |96127/173481[24:00<18:18,70.41it/s] 56%|#####5    |96916/173481[24:11<18:07,70.41it/s] 62%|######2   |108234/173481[27:00<15:48,68.80it/s] 63%|######2   |108997/173481[27:11<15:37,68.80it/s] 70%|######9   |120802/173481[30:00<12:40,69.31it/s] 70%|#######   |121601/173481[30:11<12:28,69.31it/s] 77%|#######6  |133535/173481[33:00<09:30,70.01it/s] 77%|#######7  |134304/173481[33:11<09:19,70.01it/s] 84%|########4 |146200/173481[36:00<06:28,70.19it/s] 85%|########4 |146983/173481[36:11<06:17,70.19it/s] 91%|#########1|158352/173481[39:00<03:39,68.82it/s] 92%|#########1|159181/173481[39:12<03:27,68.82it/s] 99%|#########8|170885/173481[42:00<00:37,69.22it/s] 99%|#########9|171849/173481[42:12<00:23,69.22it/s]100%|##########|173481/173481[42:32<00:00,67.97it/s]
[32m[0322 19:55:16 @base.py:257][0m Epoch 10 (global_step 8847531) finished, time:2552.40 sec.
[32m[0322 19:55:16 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-8847531.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:09<00:00,145.38it/s]
9
[32m[0322 19:57:26 @monitor.py:363][0m QueueInput/queue_size: 0.91396
[32m[0322 19:57:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.484
[32m[0322 19:57:26 @monitor.py:363][0m activation-summaries/output-rms: 0.0090569
[32m[0322 19:57:26 @monitor.py:363][0m cross_entropy_loss: 5.9184
[32m[0322 19:57:26 @monitor.py:363][0m lr: 3.8147e-09
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019985
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 19:57:26 @monitor.py:363][0m train-error-top1: 0.98669
[32m[0322 19:57:26 @monitor.py:363][0m val-error-top1: 0.98865
[32m[0322 19:57:26 @monitor.py:363][0m val-utt-error: 0.97838
[32m[0322 19:57:26 @monitor.py:363][0m validation_cost: 6.0238
[32m[0322 19:57:26 @monitor.py:363][0m wd_cost: 1.8867e-12
[32m[0322 19:57:26 @group.py:42][0m Callbacks took 129.567 sec in total. InferenceRunner: 129.477sec
[32m[0322 19:57:26 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15462/173481[03:00<30:39,85.90it/s]  9%|9         |16327/173481[03:10<30:29,85.90it/s] 17%|#7        |30286/173481[06:00<28:23,84.08it/s] 18%|#7        |30873/173481[06:10<28:16,84.08it/s] 23%|##3       |40653/173481[09:00<32:23,68.36it/s] 24%|##3       |41255/173481[09:10<32:14,68.36it/s] 30%|##9       |51381/173481[12:00<31:57,63.67it/s] 30%|##9       |51935/173481[12:10<31:48,63.67it/s] 36%|###5      |62146/173481[15:00<30:05,61.67it/s] 36%|###6      |62740/173481[15:10<29:55,61.67it/s] 42%|####1     |72507/173481[18:00<28:15,59.55it/s] 42%|####2     |73095/173481[18:10<28:05,59.55it/s] 48%|####7     |82946/173481[21:00<25:40,58.75it/s] 48%|####8     |83579/173481[21:11<25:30,58.75it/s] 54%|#####3    |93015/173481[24:00<23:24,57.31it/s] 54%|#####3    |93674/173481[24:11<23:12,57.31it/s] 60%|#####9    |103266/173481[27:00<20:29,57.13it/s] 60%|#####9    |103910/173481[27:11<20:17,57.13it/s] 66%|######5   |113671/173481[30:00<17:20,57.46it/s] 66%|######5   |114370/173481[30:11<17:08,57.46it/s] 71%|#######1  |124026/173481[33:00<14:20,57.49it/s] 72%|#######1  |124726/173481[33:11<14:08,57.49it/s] 77%|#######7  |134281/173481[36:00<11:24,57.23it/s] 78%|#######7  |134990/173481[36:11<11:12,57.23it/s] 84%|########3 |145086/173481[39:00<08:04,58.58it/s] 84%|########4 |145753/173481[39:12<07:53,58.58it/s] 90%|########9 |155452/173481[42:00<05:10,58.08it/s] 90%|########9 |156114/173481[42:12<04:59,58.08it/s] 96%|#########5|165675/173481[45:00<02:15,57.43it/s] 96%|#########5|166318/173481[45:12<02:04,57.43it/s]100%|##########|173481/173481[47:15<00:00,61.18it/s]
[32m[0322 20:44:41 @base.py:257][0m Epoch 11 (global_step 9021012) finished, time:2835.51 sec.
[32m[0322 20:44:42 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-9021012.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:06<00:00,148.64it/s]
10
[32m[0322 20:46:48 @monitor.py:363][0m QueueInput/queue_size: 0.88787
[32m[0322 20:46:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.708
[32m[0322 20:46:48 @monitor.py:363][0m activation-summaries/output-rms: 0.0089994
[32m[0322 20:46:48 @monitor.py:363][0m cross_entropy_loss: 5.9434
[32m[0322 20:46:48 @monitor.py:363][0m lr: 1.9073e-09
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019981
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 20:46:48 @monitor.py:363][0m train-error-top1: 0.98954
[32m[0322 20:46:48 @monitor.py:363][0m val-error-top1: 0.98864
[32m[0322 20:46:48 @monitor.py:363][0m val-utt-error: 0.97917
[32m[0322 20:46:48 @monitor.py:363][0m validation_cost: 6.0203
[32m[0322 20:46:48 @monitor.py:363][0m wd_cost: 1.8867e-12
[32m[0322 20:46:48 @group.py:42][0m Callbacks took 126.742 sec in total. InferenceRunner: 126.644sec
[32m[0322 20:46:48 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11795/173481[03:00<41:07,65.52it/s]  7%|7         |12349/173481[03:10<40:59,65.52it/s] 13%|#2        |22364/173481[06:00<40:39,61.93it/s] 13%|#3        |22926/173481[06:10<40:30,61.93it/s] 19%|#8        |32535/173481[09:00<39:46,59.07it/s] 19%|#9        |33090/173481[09:10<39:36,59.07it/s] 24%|##4       |42043/173481[12:00<39:16,55.77it/s] 25%|##4       |42569/173481[12:10<39:07,55.77it/s] 30%|##9       |51859/173481[15:00<36:45,55.14it/s] 30%|###       |52414/173481[15:10<36:35,55.14it/s] 36%|###5      |62072/173481[18:00<33:11,55.93it/s] 36%|###6      |62658/173481[18:10<33:01,55.93it/s] 41%|####1     |71897/173481[21:00<30:38,55.25it/s] 42%|####1     |72531/173481[21:11<30:27,55.25it/s] 47%|####7     |82235/173481[24:00<27:00,56.32it/s] 48%|####7     |82864/173481[24:11<26:48,56.32it/s] 53%|#####3    |92372/173481[27:00<24:00,56.32it/s] 54%|#####3    |93005/173481[27:11<23:48,56.32it/s] 59%|#####9    |102675/173481[30:00<20:47,56.77it/s] 60%|#####9    |103326/173481[30:11<20:35,56.77it/s] 65%|######5   |112941/173481[33:00<17:43,56.90it/s] 65%|######5   |113584/173481[33:11<17:32,56.90it/s] 71%|#######   |122850/173481[36:00<15:04,55.95it/s] 71%|#######1  |123519/173481[36:11<14:52,55.95it/s] 77%|#######6  |132850/173481[39:00<12:08,55.75it/s] 77%|#######6  |133534/173481[39:12<11:56,55.75it/s] 82%|########2 |142891/173481[42:00<09:08,55.77it/s] 83%|########2 |143584/173481[42:12<08:56,55.77it/s] 88%|########8 |153380/173481[45:00<05:52,56.99it/s] 89%|########8 |154114/173481[45:12<05:39,56.99it/s] 95%|#########4|164291/173481[48:00<02:36,58.75it/s] 95%|#########5|165021/173481[48:12<02:24,58.75it/s]100%|##########|173481/173481[50:29<00:00,57.26it/s]
[32m[0322 21:37:18 @base.py:257][0m Epoch 12 (global_step 9194493) finished, time:3029.78 sec.
[32m[0322 21:37:18 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-9194493.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:30<00:00,125.01it/s]
11
[32m[0322 21:39:49 @monitor.py:363][0m QueueInput/queue_size: 1.0571
[32m[0322 21:39:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.563
[32m[0322 21:39:49 @monitor.py:363][0m activation-summaries/output-rms: 0.0091143
[32m[0322 21:39:49 @monitor.py:363][0m cross_entropy_loss: 5.9407
[32m[0322 21:39:49 @monitor.py:363][0m lr: 1.9073e-09
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019975
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 21:39:49 @monitor.py:363][0m train-error-top1: 0.99062
[32m[0322 21:39:49 @monitor.py:363][0m val-error-top1: 0.98872
[32m[0322 21:39:49 @monitor.py:363][0m val-utt-error: 0.97917
[32m[0322 21:39:49 @monitor.py:363][0m validation_cost: 6.0234
[32m[0322 21:39:49 @monitor.py:363][0m wd_cost: 3.7734e-13
[32m[0322 21:39:49 @group.py:42][0m Callbacks took 150.695 sec in total. InferenceRunner: 150.577sec
[32m[0322 21:39:49 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14094/173481[03:00<33:55,78.30it/s]  8%|8         |14723/173481[03:10<33:47,78.30it/s] 14%|#4        |25139/173481[06:00<35:56,68.80it/s] 15%|#4        |25713/173481[06:10<35:47,68.80it/s] 20%|##        |35089/173481[09:00<37:37,61.30it/s] 21%|##        |35703/173481[09:10<37:27,61.30it/s] 26%|##6       |45497/173481[12:00<35:50,59.51it/s] 27%|##6       |46127/173481[12:10<35:40,59.51it/s] 32%|###2      |55698/173481[15:00<33:48,58.06it/s] 32%|###2      |56333/173481[15:10<33:37,58.06it/s] 38%|###8      |66364/173481[18:00<30:26,58.64it/s] 39%|###8      |67079/173481[18:10<30:14,58.64it/s] 45%|####4     |77766/173481[21:00<26:11,60.90it/s] 45%|####5     |78481/173481[21:11<25:59,60.90it/s] 51%|#####1    |89254/173481[24:00<22:31,62.32it/s] 52%|#####1    |89948/173481[24:11<22:20,62.32it/s] 58%|#####7    |100439/173481[27:00<19:33,62.22it/s] 58%|#####8    |101122/173481[27:11<19:22,62.22it/s] 64%|######4   |111494/173481[30:00<16:42,61.82it/s] 65%|######4   |112220/173481[30:11<16:31,61.82it/s] 72%|#######1  |124144/173481[33:00<12:30,65.78it/s] 72%|#######2  |125048/173481[33:11<12:16,65.78it/s] 81%|########  |139806/173481[36:00<07:29,74.92it/s] 81%|########1 |140818/173481[36:11<07:15,74.92it/s] 90%|########9 |155835/173481[39:00<03:36,81.37it/s] 90%|######### |156867/173481[39:12<03:24,81.37it/s] 98%|#########8|170853/173481[42:00<00:31,82.39it/s] 99%|#########8|171663/173481[42:12<00:22,82.39it/s]100%|##########|173481/173481[42:42<00:00,67.71it/s]
[32m[0322 22:22:31 @base.py:257][0m Epoch 13 (global_step 9367974) finished, time:2562.01 sec.
[32m[0322 22:22:31 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-9367974.
  0%|          |0/18822[00:00<?,?it/s] 95%|#########4|17856/18822[03:00<00:09,99.20it/s]100%|##########|18822/18822[03:08<00:00,100.02it/s]
12
[32m[0322 22:25:39 @monitor.py:363][0m QueueInput/queue_size: 0.86194
[32m[0322 22:25:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.572
[32m[0322 22:25:39 @monitor.py:363][0m activation-summaries/output-rms: 0.0093411
[32m[0322 22:25:39 @monitor.py:363][0m cross_entropy_loss: 5.9668
[32m[0322 22:25:39 @monitor.py:363][0m lr: 1.9073e-09
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019974
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 22:25:39 @monitor.py:363][0m train-error-top1: 0.98698
[32m[0322 22:25:39 @monitor.py:363][0m val-error-top1: 0.98867
[32m[0322 22:25:39 @monitor.py:363][0m val-utt-error: 0.97843
[32m[0322 22:25:39 @monitor.py:363][0m validation_cost: 6.0175
[32m[0322 22:25:39 @monitor.py:363][0m wd_cost: 3.7734e-13
[32m[0322 22:25:39 @group.py:42][0m Callbacks took 188.336 sec in total. InferenceRunner: 188.206sec
[32m[0322 22:25:39 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16313/173481[03:00<28:54,90.61it/s] 10%|9         |16862/173481[03:10<28:48,90.61it/s] 15%|#5        |26848/173481[06:00<34:21,71.11it/s] 16%|#5        |27498/173481[06:10<34:12,71.11it/s] 22%|##2       |38496/173481[09:00<33:12,67.76it/s] 23%|##2       |39115/173481[09:10<33:02,67.76it/s] 29%|##8       |49828/173481[12:00<31:34,65.26it/s] 29%|##9       |50477/173481[12:10<31:24,65.26it/s] 35%|###5      |61018/173481[15:00<29:26,63.67it/s] 36%|###5      |61692/173481[15:10<29:15,63.67it/s] 42%|####1     |72098/173481[18:00<26:59,62.59it/s] 42%|####1     |72802/173481[18:10<26:48,62.59it/s] 48%|####7     |83093/173481[21:00<24:22,61.82it/s] 48%|####8     |83789/173481[21:11<24:10,61.82it/s] 54%|#####4    |94485/173481[24:00<21:03,62.55it/s] 55%|#####4    |95216/173481[24:11<20:51,62.55it/s] 61%|######1   |106019/173481[27:00<17:45,63.30it/s] 62%|######1   |106732/173481[27:11<17:34,63.30it/s] 68%|######7   |117326/173481[30:00<14:50,63.05it/s] 68%|######8   |118037/173481[30:11<14:39,63.05it/s] 74%|#######4  |128938/173481[33:00<11:38,63.77it/s] 75%|#######4  |129647/173481[33:11<11:27,63.77it/s] 81%|########1 |140604/173481[36:00<08:31,64.28it/s] 81%|########1 |141362/173481[36:11<08:19,64.28it/s] 88%|########7 |152138/173481[39:00<05:32,64.18it/s] 88%|########8 |152917/173481[39:12<05:20,64.18it/s] 94%|#########4|163554/173481[42:00<02:35,63.80it/s] 95%|#########4|164293/173481[42:12<02:24,63.80it/s]100%|##########|173481/173481[44:46<00:00,64.58it/s]
[32m[0322 23:10:25 @base.py:257][0m Epoch 14 (global_step 9541455) finished, time:2686.48 sec.
[32m[0322 23:10:26 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-9541455.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:28<00:00,126.73it/s]
13
[32m[0322 23:12:54 @monitor.py:363][0m QueueInput/queue_size: 0.81418
[32m[0322 23:12:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.556
[32m[0322 23:12:54 @monitor.py:363][0m activation-summaries/output-rms: 0.0092049
[32m[0322 23:12:54 @monitor.py:363][0m cross_entropy_loss: 5.9706
[32m[0322 23:12:54 @monitor.py:363][0m lr: 9.5367e-10
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019972
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 23:12:54 @monitor.py:363][0m train-error-top1: 0.98946
[32m[0322 23:12:54 @monitor.py:363][0m val-error-top1: 0.98857
[32m[0322 23:12:54 @monitor.py:363][0m val-utt-error: 0.97806
[32m[0322 23:12:54 @monitor.py:363][0m validation_cost: 6.0196
[32m[0322 23:12:54 @monitor.py:363][0m wd_cost: 3.7734e-13
[32m[0322 23:12:54 @group.py:42][0m Callbacks took 148.802 sec in total. InferenceRunner: 148.531sec
[32m[0322 23:12:54 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13410/173481[03:00<35:48,74.50it/s]  8%|8         |14027/173481[03:10<35:40,74.50it/s] 14%|#3        |24052/173481[06:00<37:46,65.93it/s] 14%|#4        |24636/173481[06:10<37:37,65.93it/s] 20%|##        |35157/173481[09:00<36:10,63.74it/s] 21%|##        |35817/173481[09:10<35:59,63.74it/s] 27%|##7       |46947/173481[12:00<32:38,64.61it/s] 27%|##7       |47626/173481[12:10<32:28,64.61it/s] 34%|###3      |58922/173481[15:00<29:07,65.55it/s] 34%|###4      |59626/173481[15:10<28:56,65.55it/s] 41%|####      |70387/173481[18:00<26:35,64.61it/s] 41%|####      |71078/173481[18:10<26:24,64.61it/s] 51%|#####1    |88570/173481[21:00<17:57,78.81it/s] 52%|#####1    |89738/173481[21:11<17:42,78.81it/s] 61%|######    |105627/173481[24:00<13:08,86.05it/s] 61%|######1   |106504/173481[24:11<12:58,86.05it/s] 69%|######9   |119904/173481[27:00<10:49,82.54it/s] 70%|######9   |120776/173481[27:11<10:38,82.54it/s] 77%|#######6  |133075/173481[30:00<08:40,77.57it/s] 77%|#######7  |133884/173481[30:11<08:30,77.57it/s] 85%|########4 |146922/173481[33:00<05:43,77.25it/s] 85%|########5 |147814/173481[33:11<05:32,77.25it/s] 94%|#########4|163816/173481[36:00<01:54,84.74it/s] 95%|#########5|164866/173481[36:11<01:41,84.74it/s][32m[0322 23:51:09 @base.py:257][0m Epoch 15 (global_step 9714936) finished, time:2294.55 sec.
100%|##########|173481/173481[38:14<00:00,75.61it/s]
[32m[0322 23:51:09 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-9714936.
[32m[0322 23:51:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:16<00:00,138.36it/s]
14
[32m[0322 23:53:25 @monitor.py:363][0m QueueInput/queue_size: 0.82456
[32m[0322 23:53:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.516
[32m[0322 23:53:25 @monitor.py:363][0m activation-summaries/output-rms: 0.0089273
[32m[0322 23:53:25 @monitor.py:363][0m cross_entropy_loss: 5.9263
[32m[0322 23:53:25 @monitor.py:363][0m lr: 9.5367e-10
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/conv0/b-rms: 0.0001997
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0322 23:53:25 @monitor.py:363][0m train-error-top1: 0.98699
[32m[0322 23:53:25 @monitor.py:363][0m val-error-top1: 0.98869
[32m[0322 23:53:25 @monitor.py:363][0m val-utt-error: 0.97907
[32m[0322 23:53:25 @monitor.py:363][0m validation_cost: 6.0209
[32m[0322 23:53:25 @monitor.py:363][0m wd_cost: 7.5468e-14
[32m[0322 23:53:25 @group.py:42][0m Callbacks took 136.282 sec in total. InferenceRunner: 136.054sec
[32m[0322 23:53:25 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11704/173481[03:00<41:28,65.02it/s]  7%|7         |12295/173481[03:10<41:18,65.02it/s] 13%|#2        |22511/173481[06:00<40:18,62.43it/s] 13%|#3        |23132/173481[06:10<40:08,62.43it/s] 19%|#8        |32570/173481[09:00<39:49,58.97it/s] 19%|#9        |33137/173481[09:10<39:39,58.97it/s] 24%|##4       |41749/173481[12:00<40:08,54.69it/s] 24%|##4       |42295/173481[12:10<39:58,54.69it/s] 29%|##9       |51165/173481[15:00<38:07,53.47it/s] 30%|##9       |51718/173481[15:10<37:57,53.47it/s] 35%|###5      |60894/173481[18:00<34:54,53.76it/s] 35%|###5      |61585/173481[18:10<34:41,53.76it/s] 41%|####1     |71391/173481[21:00<30:24,55.94it/s] 41%|####1     |71949/173481[21:11<30:14,55.94it/s] 47%|####6     |80986/173481[24:00<28:14,54.59it/s] 47%|####7     |81576/173481[24:11<28:03,54.59it/s] 52%|#####2    |90577/173481[27:00<25:37,53.93it/s] 53%|#####2    |91241/173481[27:11<25:25,53.93it/s] 58%|#####7    |100016/173481[30:00<23:02,53.13it/s] 58%|#####7    |100610/173481[30:11<22:51,53.13it/s] 63%|######2   |109271/173481[33:00<20:28,52.26it/s] 63%|######3   |109860/173481[33:11<20:17,52.26it/s] 68%|######8   |118466/173481[36:00<17:44,51.66it/s] 69%|######8   |119109/173481[36:11<17:32,51.66it/s] 74%|#######3  |128012/173481[39:00<14:28,52.34it/s] 74%|#######4  |128630/173481[39:11<14:16,52.34it/s] 79%|#######9  |137404/173481[42:00<11:30,52.26it/s] 80%|#######9  |138055/173481[42:12<11:17,52.26it/s] 85%|########4 |146872/173481[45:00<08:27,52.43it/s] 85%|########5 |147480/173481[45:12<08:15,52.43it/s] 90%|######### |156674/173481[48:00<05:14,53.42it/s] 91%|######### |157305/173481[48:12<05:02,53.42it/s] 96%|#########5|165936/173481[51:00<02:23,52.42it/s] 96%|#########6|166545/173481[51:12<02:12,52.42it/s]100%|##########|173481/173481[53:33<00:00,53.98it/s]
[32m[0323 00:46:59 @base.py:257][0m Epoch 16 (global_step 9888417) finished, time:3213.66 sec.
[32m[0323 00:46:59 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:08<00:00,147.00it/s]
15
[32m[0323 00:49:07 @monitor.py:363][0m QueueInput/queue_size: 0.83112
[32m[0323 00:49:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.696
[32m[0323 00:49:07 @monitor.py:363][0m activation-summaries/output-rms: 0.0090754
[32m[0323 00:49:07 @monitor.py:363][0m cross_entropy_loss: 5.9463
[32m[0323 00:49:07 @monitor.py:363][0m lr: 9.5367e-10
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019969
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 00:49:07 @monitor.py:363][0m train-error-top1: 0.99049
[32m[0323 00:49:07 @monitor.py:363][0m val-error-top1: 0.98859
[32m[0323 00:49:07 @monitor.py:363][0m val-utt-error: 0.97726
[32m[0323 00:49:07 @monitor.py:363][0m validation_cost: 6.0184
[32m[0323 00:49:07 @monitor.py:363][0m wd_cost: 7.5468e-14
[32m[0323 00:49:07 @group.py:42][0m Callbacks took 128.565 sec in total. InferenceRunner: 128.048sec
[32m[0323 00:49:07 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10690/173481[03:00<45:41,59.37it/s]  6%|6         |11243/173481[03:10<45:32,59.37it/s] 12%|#1        |20112/173481[06:00<45:56,55.64it/s] 12%|#1        |20656/173481[06:10<45:46,55.64it/s] 17%|#7        |29657/173481[09:00<44:08,54.30it/s] 17%|#7        |30164/173481[09:10<43:59,54.30it/s] 22%|##2       |38300/173481[12:00<44:12,50.96it/s] 22%|##2       |38798/173481[12:10<44:02,50.96it/s] 27%|##6       |46769/173481[15:00<43:09,48.93it/s] 27%|##7       |47269/173481[15:10<42:59,48.93it/s] 32%|###2      |55535/173481[18:00<40:16,48.80it/s] 32%|###2      |56090/173481[18:10<40:05,48.80it/s] 37%|###7      |64506/173481[21:00<36:49,49.31it/s] 37%|###7      |65027/173481[21:11<36:39,49.31it/s] 42%|####2     |73660/173481[24:00<33:13,50.07it/s] 43%|####2     |74244/173481[24:11<33:01,50.07it/s] 48%|####7     |83082/173481[27:00<29:26,51.18it/s] 48%|####8     |83634/173481[27:11<29:15,51.18it/s] 53%|#####3    |92455/173481[30:00<26:09,51.62it/s] 54%|#####3    |93065/173481[30:11<25:57,51.62it/s] 59%|#####8    |101845/173481[33:00<23:00,51.88it/s] 59%|#####9    |102483/173481[33:11<22:48,51.88it/s] 64%|######4   |111525/173481[36:00<19:33,52.81it/s] 65%|######4   |112070/173481[36:11<19:22,52.81it/s] 69%|######9   |120568/173481[39:00<17:07,51.49it/s] 70%|######9   |121180/173481[39:12<16:55,51.49it/s] 75%|#######4  |129850/173481[42:00<14:06,51.52it/s] 75%|#######5  |130464/173481[42:12<13:55,51.52it/s] 80%|########  |139110/173481[45:00<11:07,51.48it/s] 81%|########  |139744/173481[45:12<10:55,51.48it/s] 86%|########5 |148623/173481[48:00<07:56,52.15it/s] 86%|########6 |149284/173481[48:12<07:43,52.15it/s] 91%|#########1|158275/173481[51:00<04:47,52.86it/s] 92%|#########1|158918/173481[51:12<04:35,52.86it/s] 97%|#########6|167470/173481[54:00<01:55,51.95it/s] 97%|#########6|168129/173481[54:12<01:43,51.95it/s]100%|##########|173481/173481[55:55<00:00,51.71it/s]
[32m[0323 01:45:02 @base.py:257][0m Epoch 17 (global_step 10061898) finished, time:3355.15 sec.
[32m[0323 01:45:03 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-10061898.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.06it/s]
16
[32m[0323 01:46:58 @monitor.py:363][0m QueueInput/queue_size: 0.85458
[32m[0323 01:46:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.563
[32m[0323 01:46:58 @monitor.py:363][0m activation-summaries/output-rms: 0.0091213
[32m[0323 01:46:58 @monitor.py:363][0m cross_entropy_loss: 5.9381
[32m[0323 01:46:58 @monitor.py:363][0m lr: 4.7684e-10
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019968
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 01:46:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 01:46:58 @monitor.py:363][0m train-error-top1: 0.99098
[32m[0323 01:46:58 @monitor.py:363][0m val-error-top1: 0.98866
[32m[0323 01:46:58 @monitor.py:363][0m val-utt-error: 0.97811
[32m[0323 01:46:58 @monitor.py:363][0m validation_cost: 6.0225
[32m[0323 01:46:58 @monitor.py:363][0m wd_cost: 7.5468e-14
[32m[0323 01:46:58 @group.py:42][0m Callbacks took 115.017 sec in total. InferenceRunner: 114.733sec
[32m[0323 01:46:58 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10956/173481[03:00<44:30,60.87it/s]  7%|6         |11548/173481[03:10<44:20,60.87it/s] 13%|#2        |21799/173481[06:00<41:45,60.55it/s] 13%|#2        |22363/173481[06:10<41:35,60.55it/s] 18%|#7        |31191/173481[09:00<42:18,56.05it/s] 18%|#8        |31708/173481[09:10<42:09,56.05it/s] 23%|##3       |40289/173481[12:00<41:45,53.15it/s] 24%|##3       |40818/173481[12:10<41:35,53.15it/s] 31%|###       |53104/173481[15:00<32:57,60.86it/s] 31%|###1      |53912/173481[15:10<32:44,60.86it/s] 40%|###9      |68754/173481[18:00<24:22,71.59it/s] 40%|###9      |69373/173481[18:10<24:14,71.59it/s] 45%|####5     |78845/173481[21:00<25:05,62.88it/s] 46%|####5     |79399/173481[21:11<24:56,62.88it/s] 51%|#####     |88159/173481[24:00<25:03,56.76it/s] 51%|#####1    |88769/173481[24:11<24:52,56.76it/s] 56%|#####6    |97461/173481[27:00<23:25,54.10it/s] 57%|#####6    |98050/173481[27:11<23:14,54.10it/s] 62%|######1   |106888/173481[30:00<20:51,53.22it/s] 62%|######1   |107533/173481[30:11<20:39,53.22it/s] 67%|######7   |116862/173481[33:00<17:22,54.29it/s] 68%|######7   |117458/173481[33:11<17:11,54.29it/s] 73%|#######3  |126724/173481[36:00<14:17,54.53it/s] 73%|#######3  |127393/173481[36:11<14:05,54.53it/s] 79%|#######9  |137494/173481[39:00<10:30,57.06it/s] 80%|#######9  |138193/173481[39:11<10:18,57.06it/s] 85%|########5 |148089/173481[42:00<07:18,57.94it/s] 86%|########5 |148808/173481[42:12<07:05,57.94it/s] 92%|#########1|158813/173481[45:00<04:09,58.75it/s] 92%|#########1|159508/173481[45:12<03:57,58.75it/s] 98%|#########7|169469/173481[48:00<01:08,58.97it/s] 98%|#########8|170172/173481[48:12<00:56,58.97it/s]100%|##########|173481/173481[49:08<00:00,58.83it/s]
[32m[0323 02:36:06 @base.py:257][0m Epoch 18 (global_step 10235379) finished, time:2948.72 sec.
[32m[0323 02:36:06 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-10235379.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,156.98it/s]
17
[32m[0323 02:38:06 @monitor.py:363][0m QueueInput/queue_size: 0.7764
[32m[0323 02:38:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.548
[32m[0323 02:38:06 @monitor.py:363][0m activation-summaries/output-rms: 0.0093587
[32m[0323 02:38:06 @monitor.py:363][0m cross_entropy_loss: 5.9533
[32m[0323 02:38:06 @monitor.py:363][0m lr: 4.7684e-10
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019967
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 02:38:06 @monitor.py:363][0m train-error-top1: 0.9876
[32m[0323 02:38:06 @monitor.py:363][0m val-error-top1: 0.98858
[32m[0323 02:38:06 @monitor.py:363][0m val-utt-error: 0.97848
[32m[0323 02:38:06 @monitor.py:363][0m validation_cost: 6.0162
[32m[0323 02:38:06 @monitor.py:363][0m wd_cost: 1.5094e-14
[32m[0323 02:38:06 @group.py:42][0m Callbacks took 120.050 sec in total. InferenceRunner: 119.915sec
[32m[0323 02:38:06 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16580/173481[03:00<28:23,92.10it/s] 10%|#         |17494/173481[03:10<28:13,92.10it/s] 17%|#7        |29973/173481[06:00<29:03,82.31it/s] 18%|#7        |30669/173481[06:10<28:54,82.31it/s] 24%|##4       |42253/173481[09:00<29:18,74.61it/s] 25%|##4       |42912/173481[09:10<29:10,74.61it/s] 31%|###1      |54152/173481[12:00<28:22,70.10it/s] 32%|###1      |54816/173481[12:10<28:12,70.10it/s] 38%|###7      |65563/173481[15:00<27:01,66.57it/s] 38%|###8      |66285/173481[15:10<26:50,66.57it/s] 44%|####4     |77047/173481[18:00<24:40,65.16it/s] 45%|####4     |77653/173481[18:10<24:30,65.16it/s] 51%|#####     |88433/173481[21:00<22:04,64.19it/s] 51%|#####1    |89125/173481[21:11<21:54,64.19it/s] 58%|#####7    |100028/173481[24:00<19:02,64.30it/s] 58%|#####8    |100735/173481[24:11<18:51,64.30it/s] 64%|######4   |111253/173481[27:00<16:22,63.31it/s] 65%|######4   |111987/173481[27:11<16:11,63.31it/s] 71%|#######   |122853/173481[30:00<13:12,63.87it/s] 71%|#######1  |123604/173481[30:11<13:00,63.87it/s] 78%|#######7  |134465/173481[33:00<10:07,64.18it/s] 78%|#######7  |135203/173481[33:11<09:56,64.18it/s] 84%|########3 |145701/173481[36:00<07:18,63.29it/s] 84%|########4 |146486/173481[36:11<07:06,63.29it/s] 91%|######### |157287/173481[39:00<04:13,63.82it/s] 91%|#########1|158067/173481[39:11<04:01,63.82it/s] 97%|#########6|167580/173481[42:00<01:37,60.32it/s] 97%|#########6|168252/173481[42:12<01:26,60.32it/s]100%|##########|173481/173481[43:43<00:00,66.13it/s]
[32m[0323 03:21:50 @base.py:257][0m Epoch 19 (global_step 10408860) finished, time:2623.43 sec.
[32m[0323 03:21:50 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-10408860.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.44it/s]
18
[32m[0323 03:23:51 @monitor.py:363][0m QueueInput/queue_size: 1.3002
[32m[0323 03:23:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.542
[32m[0323 03:23:51 @monitor.py:363][0m activation-summaries/output-rms: 0.0091993
[32m[0323 03:23:51 @monitor.py:363][0m cross_entropy_loss: 5.9686
[32m[0323 03:23:51 @monitor.py:363][0m lr: 2.3842e-10
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019967
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 03:23:51 @monitor.py:363][0m train-error-top1: 0.98887
[32m[0323 03:23:51 @monitor.py:363][0m val-error-top1: 0.98859
[32m[0323 03:23:51 @monitor.py:363][0m val-utt-error: 0.97827
[32m[0323 03:23:51 @monitor.py:363][0m validation_cost: 6.019
[32m[0323 03:23:51 @monitor.py:363][0m wd_cost: 1.5094e-14
[32m[0323 03:23:51 @group.py:42][0m Callbacks took 121.264 sec in total. InferenceRunner: 121.097sec
[32m[0323 03:23:51 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16951/173481[03:00<27:42,94.17it/s] 10%|#         |17996/173481[03:10<27:31,94.17it/s] 16%|#6        |28263/173481[06:00<32:06,75.38it/s] 17%|#6        |28866/173481[06:10<31:58,75.38it/s] 23%|##2       |39096/173481[09:00<33:27,66.93it/s] 23%|##2       |39766/173481[09:10<33:17,66.93it/s] 29%|##9       |50465/173481[12:00<31:32,64.99it/s] 29%|##9       |51082/173481[12:10<31:23,64.99it/s] 35%|###5      |61272/173481[15:00<29:57,62.41it/s] 36%|###5      |61971/173481[15:10<29:46,62.41it/s] 42%|####2     |73003/173481[18:00<26:15,63.76it/s] 43%|####2     |74176/173481[18:10<25:57,63.76it/s] 53%|#####3    |92635/173481[21:00<16:44,80.48it/s] 54%|#####4    |93778/173481[21:11<16:30,80.48it/s] 62%|######2   |108290/173481[24:00<12:59,83.60it/s] 63%|######2   |109195/173481[24:11<12:48,83.60it/s] 70%|######9   |120892/173481[27:00<11:30,76.20it/s] 70%|#######   |121643/173481[27:11<11:20,76.20it/s] 77%|#######6  |132893/173481[30:00<09:30,71.12it/s] 77%|#######7  |133624/173481[30:11<09:20,71.12it/s] 84%|########4 |146122/173481[33:00<06:18,72.28it/s] 85%|########4 |146988/173481[33:11<06:06,72.28it/s] 94%|#########3|162699/173481[36:00<02:13,80.99it/s] 94%|#########4|163821/173481[36:11<01:59,80.99it/s]100%|##########|173481/173481[38:33<00:00,74.98it/s]
[32m[0323 04:02:25 @base.py:257][0m Epoch 20 (global_step 10582341) finished, time:2313.84 sec.
[32m[0323 04:02:25 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.14it/s]
19
[32m[0323 04:04:22 @monitor.py:363][0m QueueInput/queue_size: 0.92562
[32m[0323 04:04:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.522
[32m[0323 04:04:22 @monitor.py:363][0m activation-summaries/output-rms: 0.0089774
[32m[0323 04:04:22 @monitor.py:363][0m cross_entropy_loss: 5.923
[32m[0323 04:04:22 @monitor.py:363][0m lr: 2.3842e-10
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019967
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 04:04:22 @monitor.py:363][0m train-error-top1: 0.98622
[32m[0323 04:04:22 @monitor.py:363][0m val-error-top1: 0.9887
[32m[0323 04:04:22 @monitor.py:363][0m val-utt-error: 0.97885
[32m[0323 04:04:22 @monitor.py:363][0m validation_cost: 6.0217
[32m[0323 04:04:22 @monitor.py:363][0m wd_cost: 3.0187e-15
[32m[0323 04:04:22 @group.py:42][0m Callbacks took 116.996 sec in total. InferenceRunner: 116.822sec
[32m[0323 04:04:22 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13699/173481[03:00<34:59,76.10it/s]  8%|8         |14343/173481[03:10<34:51,76.10it/s] 14%|#4        |24964/173481[06:00<36:02,68.68it/s] 15%|#4        |25601/173481[06:10<35:53,68.68it/s] 21%|##        |36210/173481[09:00<34:57,65.43it/s] 21%|##1       |36860/173481[09:10<34:47,65.43it/s] 27%|##7       |46986/173481[12:00<33:43,62.52it/s] 27%|##7       |47570/173481[12:10<33:33,62.52it/s] 33%|###3      |57893/173481[15:00<31:18,61.54it/s] 34%|###3      |58609/173481[15:10<31:06,61.54it/s] 40%|###9      |68906/173481[18:00<28:24,61.36it/s] 40%|####      |69539/173481[18:10<28:14,61.36it/s] 46%|####5     |79386/173481[21:00<26:15,59.74it/s] 46%|####6     |80042/173481[21:11<26:04,59.74it/s] 52%|#####1    |90066/173481[24:00<23:21,59.53it/s] 52%|#####2    |90735/173481[24:11<23:09,59.53it/s] 58%|#####8    |100740/173481[27:00<20:24,59.42it/s] 58%|#####8    |101480/173481[27:11<20:11,59.42it/s] 64%|######4   |111447/173481[30:00<17:23,59.45it/s] 65%|######4   |112125/173481[30:11<17:12,59.45it/s] 70%|#######   |122095/173481[33:00<14:26,59.30it/s] 71%|#######   |122785/173481[33:11<14:14,59.30it/s] 77%|#######6  |132994/173481[36:00<11:15,59.92it/s] 77%|#######7  |133705/173481[36:11<11:03,59.92it/s] 83%|########3 |144236/173481[39:00<07:58,61.16it/s] 84%|########3 |144939/173481[39:12<07:46,61.16it/s] 89%|########9 |154491/173481[42:00<05:21,58.99it/s] 89%|########9 |155175/173481[42:12<05:10,58.99it/s] 95%|#########4|164801/173481[45:00<02:29,58.11it/s] 95%|#########5|165485/173481[45:12<02:17,58.11it/s]100%|##########|173481/173481[47:28<00:00,60.89it/s]
[32m[0323 04:51:51 @base.py:257][0m Epoch 21 (global_step 10755822) finished, time:2848.90 sec.
[32m[0323 04:51:51 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-10755822.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,170.45it/s]
20
[32m[0323 04:53:41 @monitor.py:363][0m QueueInput/queue_size: 0.667
[32m[0323 04:53:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.681
[32m[0323 04:53:41 @monitor.py:363][0m activation-summaries/output-rms: 0.0089667
[32m[0323 04:53:41 @monitor.py:363][0m cross_entropy_loss: 5.9403
[32m[0323 04:53:41 @monitor.py:363][0m lr: 2.3842e-10
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019966
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 04:53:41 @monitor.py:363][0m train-error-top1: 0.99055
[32m[0323 04:53:41 @monitor.py:363][0m val-error-top1: 0.98859
[32m[0323 04:53:41 @monitor.py:363][0m val-utt-error: 0.978
[32m[0323 04:53:41 @monitor.py:363][0m validation_cost: 6.0174
[32m[0323 04:53:41 @monitor.py:363][0m wd_cost: 3.0187e-15
[32m[0323 04:53:41 @group.py:42][0m Callbacks took 110.593 sec in total. InferenceRunner: 110.437sec
[32m[0323 04:53:41 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17423/173481[03:00<26:52,96.79it/s] 10%|#         |18059/173481[03:10<26:45,96.79it/s] 16%|#6        |28210/173481[06:00<32:42,74.02it/s] 17%|#6        |28874/173481[06:10<32:33,74.02it/s] 22%|##2       |38599/173481[09:00<34:39,64.86it/s] 23%|##2       |39154/173481[09:10<34:31,64.86it/s] 28%|##7       |48131/173481[12:00<35:49,58.30it/s] 28%|##8       |48734/173481[12:10<35:39,58.30it/s] 34%|###3      |58604/173481[15:00<32:52,58.24it/s] 34%|###4      |59240/173481[15:10<32:41,58.24it/s] 40%|###9      |69250/173481[18:00<29:36,58.68it/s] 40%|####      |69919/173481[18:10<29:24,58.68it/s] 46%|####6     |80101/173481[21:00<26:10,59.47it/s] 47%|####6     |80794/173481[21:11<25:58,59.47it/s] 52%|#####2    |90920/173481[24:00<23:01,59.77it/s] 53%|#####2    |91599/173481[24:11<22:49,59.77it/s] 59%|#####8    |101585/173481[27:00<20:08,59.50it/s] 59%|#####8    |102264/173481[27:11<19:56,59.50it/s] 65%|######4   |112390/173481[30:00<17:02,59.76it/s] 65%|######5   |113064/173481[30:11<16:51,59.76it/s] 71%|#######   |122570/173481[33:00<14:36,58.11it/s] 71%|#######1  |123201/173481[33:11<14:25,58.11it/s] 76%|#######6  |132560/173481[36:00<12:00,56.77it/s] 77%|#######6  |133204/173481[36:11<11:49,56.77it/s] 82%|########2 |143040/173481[39:00<08:49,57.48it/s] 83%|########2 |143741/173481[39:12<08:37,57.48it/s] 89%|########8 |153650/173481[42:00<05:40,58.20it/s] 89%|########8 |154309/173481[42:12<05:29,58.20it/s] 94%|#########4|163710/173481[45:00<02:51,57.02it/s] 95%|#########4|164369/173481[45:12<02:39,57.02it/s]100%|##########|173481/173481[47:52<00:00,60.40it/s]
[32m[0323 05:41:34 @base.py:257][0m Epoch 22 (global_step 10929303) finished, time:2872.32 sec.
[32m[0323 05:41:34 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,168.02it/s]
21
[32m[0323 05:43:26 @monitor.py:363][0m QueueInput/queue_size: 0.48375
[32m[0323 05:43:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.586
[32m[0323 05:43:26 @monitor.py:363][0m activation-summaries/output-rms: 0.0090864
[32m[0323 05:43:26 @monitor.py:363][0m cross_entropy_loss: 5.9392
[32m[0323 05:43:26 @monitor.py:363][0m lr: 1.1921e-10
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019966
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 05:43:26 @monitor.py:363][0m train-error-top1: 0.99154
[32m[0323 05:43:26 @monitor.py:363][0m val-error-top1: 0.98861
[32m[0323 05:43:26 @monitor.py:363][0m val-utt-error: 0.97832
[32m[0323 05:43:26 @monitor.py:363][0m validation_cost: 6.0225
[32m[0323 05:43:26 @monitor.py:363][0m wd_cost: 3.0187e-15
[32m[0323 05:43:26 @group.py:42][0m Callbacks took 112.159 sec in total. InferenceRunner: 112.034sec
[32m[0323 05:43:26 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17276/173481[03:00<27:07,95.98it/s] 11%|#         |18324/173481[03:10<26:56,95.98it/s] 17%|#6        |29059/173481[06:00<30:55,77.83it/s] 17%|#7        |29626/173481[06:10<30:48,77.83it/s] 23%|##2       |39149/173481[09:00<34:21,65.16it/s] 23%|##2       |39713/173481[09:10<34:12,65.16it/s] 30%|###       |52073/173481[12:00<29:37,68.32it/s] 30%|###       |52819/173481[12:10<29:26,68.32it/s] 39%|###8      |67086/173481[15:00<23:36,75.11it/s] 39%|###9      |68094/173481[15:10<23:23,75.11it/s] 46%|####5     |78955/173481[18:00<22:26,70.23it/s] 46%|####5     |79633/173481[18:10<22:16,70.23it/s] 52%|#####1    |90162/173481[21:00<21:02,66.00it/s] 52%|#####2    |90863/173481[21:11<20:51,66.00it/s] 58%|#####8    |101188/173481[24:00<18:57,63.54it/s] 59%|#####8    |101828/173481[24:11<18:47,63.54it/s] 65%|######4   |112249/173481[27:00<16:20,62.47it/s] 65%|######5   |112969/173481[27:11<16:08,62.47it/s] 71%|#######1  |123224/173481[30:00<13:34,61.70it/s] 71%|#######1  |123884/173481[30:11<13:23,61.70it/s] 77%|#######7  |134279/173481[33:00<10:36,61.56it/s] 78%|#######7  |134956/173481[33:11<10:25,61.56it/s] 84%|########3 |145289/173481[36:00<07:39,61.36it/s] 84%|########4 |145983/173481[36:11<07:28,61.36it/s] 90%|######### |156230/173481[39:00<04:42,61.07it/s] 90%|######### |156983/173481[39:12<04:30,61.07it/s] 97%|#########6|167426/173481[42:00<01:38,61.63it/s] 97%|#########6|168157/173481[42:12<01:26,61.63it/s]100%|##########|173481/173481[43:39<00:00,66.22it/s]
[32m[0323 06:27:06 @base.py:257][0m Epoch 23 (global_step 11102784) finished, time:2619.75 sec.
[32m[0323 06:27:06 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:48<00:00,173.97it/s]
22
[32m[0323 06:28:54 @monitor.py:363][0m QueueInput/queue_size: 0.88603
[32m[0323 06:28:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.563
[32m[0323 06:28:54 @monitor.py:363][0m activation-summaries/output-rms: 0.0093638
[32m[0323 06:28:54 @monitor.py:363][0m cross_entropy_loss: 5.9559
[32m[0323 06:28:54 @monitor.py:363][0m lr: 1.1921e-10
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019966
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 06:28:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 06:28:54 @monitor.py:363][0m train-error-top1: 0.98726
[32m[0323 06:28:54 @monitor.py:363][0m val-error-top1: 0.98853
[32m[0323 06:28:54 @monitor.py:363][0m val-utt-error: 0.97652
[32m[0323 06:28:54 @monitor.py:363][0m validation_cost: 6.0162
[32m[0323 06:28:54 @monitor.py:363][0m wd_cost: 6.0374e-16
[32m[0323 06:28:54 @group.py:42][0m Callbacks took 108.317 sec in total. InferenceRunner: 108.199sec
[32m[0323 06:28:54 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16903/173481[03:00<27:47,93.90it/s] 10%|#         |17873/173481[03:10<27:37,93.90it/s] 17%|#7        |29638/173481[06:00<29:42,80.70it/s] 18%|#7        |30371/173481[06:10<29:33,80.70it/s] 25%|##4       |42583/173481[09:00<28:41,76.05it/s] 25%|##4       |43327/173481[09:10<28:31,76.05it/s] 32%|###2      |55620/173481[12:00<26:28,74.19it/s] 32%|###2      |56247/173481[12:10<26:20,74.19it/s] 39%|###9      |68321/173481[15:00<24:13,72.33it/s] 40%|###9      |69127/173481[15:10<24:02,72.33it/s] 47%|####6     |81433/173481[18:00<21:08,72.58it/s] 47%|####7     |82170/173481[18:10<20:58,72.58it/s] 55%|#####4    |94673/173481[21:00<17:58,73.06it/s] 55%|#####5    |95523/173481[21:11<17:46,73.06it/s] 62%|######2   |108150/173481[24:00<14:43,73.96it/s] 63%|######2   |108884/173481[24:11<14:33,73.96it/s] 69%|######9   |119740/173481[27:00<13:00,68.84it/s] 69%|######9   |120492/173481[27:11<12:49,68.84it/s] 76%|#######5  |131353/173481[30:00<10:32,66.61it/s] 76%|#######6  |132052/173481[30:11<10:22,66.61it/s] 82%|########2 |142446/173481[33:00<08:04,64.02it/s] 82%|########2 |143077/173481[33:11<07:54,64.02it/s] 88%|########8 |153495/173481[36:00<05:18,62.67it/s] 89%|########8 |154303/173481[36:11<05:06,62.67it/s] 95%|#########5|164928/173481[39:00<02:15,63.08it/s] 95%|#########5|165653/173481[39:12<02:04,63.08it/s]100%|##########|173481/173481[41:34<00:00,69.55it/s]
[32m[0323 07:10:28 @base.py:257][0m Epoch 24 (global_step 11276265) finished, time:2494.36 sec.
[32m[0323 07:10:28 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-11276265.
[32m[0323 07:10:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,166.41it/s]
23
[32m[0323 07:12:22 @monitor.py:363][0m QueueInput/queue_size: 0.85223
[32m[0323 07:12:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.56
[32m[0323 07:12:22 @monitor.py:363][0m activation-summaries/output-rms: 0.0091528
[32m[0323 07:12:22 @monitor.py:363][0m cross_entropy_loss: 5.9715
[32m[0323 07:12:22 @monitor.py:363][0m lr: 1.1921e-10
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019966
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 07:12:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 07:12:22 @monitor.py:363][0m train-error-top1: 0.98947
[32m[0323 07:12:22 @monitor.py:363][0m val-error-top1: 0.98862
[32m[0323 07:12:22 @monitor.py:363][0m val-utt-error: 0.97774
[32m[0323 07:12:22 @monitor.py:363][0m validation_cost: 6.018
[32m[0323 07:12:22 @monitor.py:363][0m wd_cost: 6.0374e-16
[32m[0323 07:12:22 @group.py:42][0m Callbacks took 113.752 sec in total. InferenceRunner: 113.114sec
[32m[0323 07:12:22 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17661/173481[03:00<26:28,98.11it/s] 11%|#         |18756/173481[03:10<26:16,98.11it/s] 17%|#6        |29112/173481[06:00<31:10,77.17it/s] 17%|#7        |29766/173481[06:10<31:02,77.17it/s] 23%|##3       |40652/173481[09:00<31:36,70.04it/s] 24%|##3       |41431/173481[09:10<31:25,70.04it/s] 30%|###       |52203/173481[12:00<30:10,66.98it/s] 30%|###       |52888/173481[12:10<30:00,66.98it/s] 37%|###6      |63759/173481[15:00<27:53,65.56it/s] 37%|###7      |64456/173481[15:10<27:43,65.56it/s] 43%|####3     |74792/173481[18:00<25:58,63.34it/s] 43%|####3     |75444/173481[18:10<25:47,63.34it/s] 51%|#####1    |89007/173481[21:00<20:01,70.30it/s] 52%|#####1    |90190/173481[21:11<19:44,70.30it/s] 60%|#####9    |103592/173481[24:00<15:28,75.28it/s] 60%|######    |104272/173481[24:11<15:19,75.28it/s] 66%|######6   |114945/173481[27:00<14:12,68.64it/s] 67%|######6   |115635/173481[27:11<14:02,68.64it/s] 73%|#######3  |127178/173481[30:00<11:17,68.29it/s] 74%|#######3  |128148/173481[30:11<11:03,68.29it/s] 80%|########  |139198/173481[33:00<08:27,67.53it/s] 81%|########  |139921/173481[33:11<08:16,67.53it/s] 87%|########6 |150502/173481[36:00<05:53,65.05it/s] 87%|########7 |151244/173481[36:11<05:41,65.05it/s] 93%|#########3|161407/173481[39:00<03:12,62.73it/s] 93%|#########3|162121/173481[39:12<03:01,62.73it/s] 99%|#########9|172436/173481[42:00<00:16,61.99it/s]100%|#########9|173122/173481[42:12<00:05,61.99it/s]100%|##########|173481/173481[42:18<00:00,68.35it/s]
[32m[0323 07:54:40 @base.py:257][0m Epoch 25 (global_step 11449746) finished, time:2538.02 sec.
[32m[0323 07:54:40 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.90it/s]
24
[32m[0323 07:56:47 @monitor.py:363][0m QueueInput/queue_size: 0.87318
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.51
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/output-rms: 0.0089197
[32m[0323 07:56:47 @monitor.py:363][0m cross_entropy_loss: 5.9253
[32m[0323 07:56:47 @monitor.py:363][0m lr: 5.9605e-11
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019966
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 07:56:47 @monitor.py:363][0m train-error-top1: 0.98692
[32m[0323 07:56:47 @monitor.py:363][0m val-error-top1: 0.98867
[32m[0323 07:56:47 @monitor.py:363][0m val-utt-error: 0.97933
[32m[0323 07:56:47 @monitor.py:363][0m validation_cost: 6.0205
[32m[0323 07:56:47 @monitor.py:363][0m wd_cost: 6.0374e-16
[32m[0323 07:56:47 @group.py:42][0m Callbacks took 127.350 sec in total. InferenceRunner: 127.266sec
[32m[0323 07:56:47 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12884/173481[03:00<37:23,71.58it/s]  8%|7         |13532/173481[03:10<37:14,71.58it/s] 14%|#3        |24218/173481[06:00<37:07,66.99it/s] 14%|#4        |24865/173481[06:10<36:58,66.99it/s] 20%|##        |35419/173481[09:00<35:39,64.52it/s] 21%|##        |36050/173481[09:10<35:29,64.52it/s] 27%|##6       |46426/173481[12:00<33:43,62.78it/s] 27%|##7       |47045/173481[12:10<33:33,62.78it/s] 33%|###2      |57066/173481[15:00<31:51,60.89it/s] 33%|###3      |57711/173481[15:10<31:41,60.89it/s] 39%|###9      |68146/173481[18:00<28:40,61.22it/s] 40%|###9      |68795/173481[18:10<28:29,61.22it/s] 45%|####5     |78793/173481[21:00<26:13,60.17it/s] 46%|####5     |79431/173481[21:11<26:03,60.17it/s] 52%|#####1    |89373/173481[24:00<23:34,59.46it/s] 52%|#####1    |90025/173481[24:11<23:23,59.46it/s] 58%|#####7    |99804/173481[27:00<20:55,58.70it/s] 58%|#####7    |100475/173481[27:11<20:43,58.70it/s] 64%|######3   |110440/173481[30:00<17:50,58.89it/s] 64%|######4   |111090/173481[30:11<17:39,58.89it/s] 70%|######9   |120816/173481[33:00<15:04,58.25it/s] 70%|#######   |121500/173481[33:11<14:52,58.25it/s] 76%|#######5  |131521/173481[36:00<11:53,58.84it/s] 76%|#######6  |132188/173481[36:11<11:41,58.84it/s] 82%|########1 |142221/173481[39:00<08:48,59.13it/s] 82%|########2 |142934/173481[39:12<08:36,59.13it/s] 88%|########8 |152778/173481[42:00<05:51,58.89it/s] 88%|########8 |153496/173481[42:12<05:39,58.89it/s] 94%|#########4|163281/173481[45:00<02:54,58.61it/s] 95%|#########4|163975/173481[45:12<02:42,58.61it/s]100%|##########|173481/173481[47:54<00:00,60.34it/s]
[32m[0323 08:44:42 @base.py:257][0m Epoch 26 (global_step 11623227) finished, time:2874.90 sec.
[32m[0323 08:44:42 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-11623227.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.98it/s]
25
[32m[0323 08:46:47 @monitor.py:363][0m QueueInput/queue_size: 0.50898
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.691
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/output-rms: 0.008986
[32m[0323 08:46:47 @monitor.py:363][0m cross_entropy_loss: 5.946
[32m[0323 08:46:47 @monitor.py:363][0m lr: 5.9605e-11
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019966
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 08:46:47 @monitor.py:363][0m train-error-top1: 0.98958
[32m[0323 08:46:47 @monitor.py:363][0m val-error-top1: 0.98859
[32m[0323 08:46:47 @monitor.py:363][0m val-utt-error: 0.97769
[32m[0323 08:46:47 @monitor.py:363][0m validation_cost: 6.0175
[32m[0323 08:46:47 @monitor.py:363][0m wd_cost: 1.2075e-16
[32m[0323 08:46:47 @group.py:42][0m Callbacks took 124.771 sec in total. InferenceRunner: 124.676sec
[32m[0323 08:46:47 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16630/173481[03:00<28:17,92.38it/s] 10%|#         |17516/173481[03:10<28:08,92.38it/s] 16%|#6        |27790/173481[06:00<32:43,74.19it/s] 16%|#6        |28356/173481[06:10<32:36,74.19it/s] 21%|##1       |37105/173481[09:00<37:17,60.96it/s] 22%|##1       |37644/173481[09:10<37:08,60.96it/s] 27%|##6       |46755/173481[12:00<37:01,57.05it/s] 27%|##7       |47334/173481[12:10<36:51,57.05it/s] 33%|###2      |57101/173481[15:00<33:52,57.26it/s] 33%|###3      |57778/173481[15:10<33:40,57.26it/s] 39%|###9      |68108/173481[18:00<29:41,59.14it/s] 40%|###9      |68769/173481[18:11<29:30,59.14it/s] 46%|####5     |79205/173481[21:00<26:01,60.37it/s] 46%|####6     |79879/173481[21:11<25:50,60.37it/s] 52%|#####2    |90517/173481[24:00<22:27,61.58it/s] 53%|#####2    |91209/173481[24:11<22:16,61.58it/s] 58%|#####8    |101420/173481[27:00<19:40,61.07it/s] 59%|#####8    |102099/173481[27:11<19:28,61.07it/s] 65%|######4   |112544/173481[30:00<16:31,61.43it/s] 65%|######5   |113256/173481[30:11<16:20,61.43it/s] 71%|#######1  |123426/173481[33:00<13:41,60.94it/s] 72%|#######1  |124134/173481[33:11<13:29,60.94it/s] 77%|#######7  |134305/173481[36:00<10:45,60.69it/s] 78%|#######7  |134977/173481[36:11<10:34,60.69it/s] 84%|########3 |145270/173481[39:00<07:43,60.80it/s] 84%|########4 |145934/173481[39:12<07:33,60.80it/s] 90%|######### |156137/173481[42:00<04:46,60.58it/s] 90%|######### |156925/173481[42:12<04:33,60.58it/s] 96%|#########6|167263/173481[45:00<01:41,61.19it/s] 97%|#########6|168014/173481[45:12<01:29,61.19it/s]100%|##########|173481/173481[46:39<00:00,61.96it/s]
[32m[0323 09:33:27 @base.py:257][0m Epoch 27 (global_step 11796708) finished, time:2799.73 sec.
[32m[0323 09:33:27 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.60it/s]
26
[32m[0323 09:35:26 @monitor.py:363][0m QueueInput/queue_size: 0.8069
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.561
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/output-rms: 0.0092384
[32m[0323 09:35:26 @monitor.py:363][0m cross_entropy_loss: 5.9467
[32m[0323 09:35:26 @monitor.py:363][0m lr: 5.9605e-11
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019966
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 09:35:26 @monitor.py:363][0m train-error-top1: 0.99065
[32m[0323 09:35:26 @monitor.py:363][0m val-error-top1: 0.98864
[32m[0323 09:35:26 @monitor.py:363][0m val-utt-error: 0.97912
[32m[0323 09:35:26 @monitor.py:363][0m validation_cost: 6.0223
[32m[0323 09:35:26 @monitor.py:363][0m wd_cost: 1.2075e-16
[32m[0323 09:35:26 @group.py:42][0m Callbacks took 118.801 sec in total. InferenceRunner: 118.684sec
[32m[0323 09:35:26 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16560/173481[03:00<28:25,92.00it/s] 10%|#         |17542/173481[03:10<28:15,92.00it/s] 17%|#7        |30114/173481[06:00<28:51,82.81it/s] 18%|#7        |30744/173481[06:10<28:43,82.81it/s] 24%|##3       |41354/173481[09:00<30:55,71.20it/s] 24%|##4       |42020/173481[09:10<30:46,71.20it/s] 32%|###2      |56267/173481[12:00<25:30,76.58it/s] 33%|###2      |57192/173481[12:10<25:18,76.58it/s] 42%|####2     |73443/173481[15:00<19:37,84.97it/s] 43%|####2     |74472/173481[15:10<19:25,84.97it/s] 52%|#####1    |89838/173481[18:00<15:51,87.92it/s] 52%|#####2    |90803/173481[18:10<15:40,87.92it/s] 61%|######1   |105985/173481[21:00<12:40,88.80it/s] 62%|######1   |107017/173481[21:11<12:28,88.80it/s] 70%|#######   |122269/173481[24:00<09:31,89.62it/s] 71%|#######1  |123320/173481[24:11<09:19,89.62it/s] 80%|#######9  |138482/173481[27:00<06:29,89.85it/s] 80%|########  |139584/173481[27:11<06:17,89.85it/s] 88%|########7 |152044/173481[30:00<04:21,81.95it/s] 88%|########8 |152783/173481[30:11<04:12,81.95it/s] 94%|#########4|163616/173481[33:00<02:16,72.05it/s] 95%|#########4|164363/173481[33:11<02:06,72.05it/s]100%|##########|173481/173481[35:22<00:00,81.73it/s]
[32m[0323 10:10:48 @base.py:257][0m Epoch 28 (global_step 11970189) finished, time:2122.53 sec.
[32m[0323 10:10:48 @saver.py:84][0m Model saved to train_log/cnn_w_4_a_4_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,149.60it/s]
27
[32m[0323 10:12:54 @monitor.py:363][0m QueueInput/queue_size: 0.88935
[32m[0323 10:12:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.545
[32m[0323 10:12:54 @monitor.py:363][0m activation-summaries/output-rms: 0.0094182
[32m[0323 10:12:54 @monitor.py:363][0m cross_entropy_loss: 5.9592
[32m[0323 10:12:54 @monitor.py:363][0m lr: 2.9802e-11
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/conv0/W-rms: 0.74079
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00019967
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72246
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3967
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51249
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.084925
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41324
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090032
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40005
[32m[0323 10:12:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089217
[32m[0323 10:12:54 @monitor.py:363][0m train-error-top1: 0.98603
[32m[0323 10:12:54 @monitor.py:363][0m val-error-top1: 0.98859
[32m[0323 10:12:54 @monitor.py:363][0m val-utt-error: 0.97832
[32m[0323 10:12:54 @monitor.py:363][0m validation_cost: 6.016
[32m[0323 10:12:54 @monitor.py:363][0m wd_cost: 1.2075e-16
[32m[0323 10:12:54 @group.py:42][0m Callbacks took 125.929 sec in total. InferenceRunner: 125.824sec
[32m[0323 10:12:54 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16802/173481[03:00<27:58,93.34it/s] 10%|#         |17722/173481[03:10<27:48,93.34it/s] 20%|#9        |33833/173481[06:00<24:46,93.97it/s] 20%|#9        |34552/173481[06:10<24:38,93.97it/s] 27%|##6       |46663/173481[09:00<26:04,81.07it/s] 27%|##7       |47442/173481[09:10<25:54,81.07it/s] 35%|###4      |59933/173481[12:00<24:30,77.22it/s] 35%|###5      |60728/173481[12:10<24:20,77.22it/s] 43%|####2     |73784/173481[15:00<21:33,77.08it/s] 43%|####2     |74587/173481[15:10<21:22,77.08it/s] 51%|#####     |87723/173481[18:00<18:30,77.25it/s] 51%|#####1    |88554/173481[18:10<18:19,77.25it/s] 59%|#####8    |101850/173481[21:00<15:19,77.86it/s] 59%|#####9    |102738/173481[21:11<15:08,77.86it/s] 67%|######7   |116770/173481[24:00<11:46,80.29it/s] 68%|######7   |117739/173481[24:11<11:34,80.29it/s]srun: got SIGCONT
slurmstepd: *** JOB 82364 ON sls-titan-10 CANCELLED AT 2018-03-23T10:38:12 ***
srun: forcing job termination
slurmstepd: *** STEP 82364.0 ON sls-titan-10 CANCELLED AT 2018-03-23T10:38:12 ***
