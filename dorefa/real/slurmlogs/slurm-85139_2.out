sls-titan-10 0
SLURM_JOBID=85141
SLURM_TASKID=2
[32m[0328 11:37:17 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=4 --bita=32 --quant_ends=True --load_ckpt=train_log/fcn1_w_4_a_32_quant_ends_False/checkpoint
[32m[0328 11:37:26 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 11:37:26 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 11:37:26 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 11:37:26 @drf_run.py:166][0m Using host: sls-titan-10
[32m[0328 11:37:26 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 11:37:26 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 11:37:26 @drf_run.py:188][0m Using GPU: 0
[32m[0328 11:37:26 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 11:37:26 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 11:37:26 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 11:37:26 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear0 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear1 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:37:26 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 11:37:26 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:37:26 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0328 11:37:26 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 11:37:26 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0328 11:37:27 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0328 11:37:27 @base.py:196][0m Setup callbacks graph ...
[32m[0328 11:37:27 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:37:28 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:37:28 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0328 11:37:28 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 11:37:28 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0328 11:37:28 @base.py:212][0m Creating the session ...
2018-03-28 11:37:28.872547: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-28 11:37:31.736518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:02:00.0
totalMemory: 11.92GiB freeMemory: 11.81GiB
2018-03-28 11:37:31.737188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0, compute capability: 5.2)
[32m[0328 11:37:36 @base.py:220][0m Initializing the session ...
[32m[0328 11:37:36 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn1_w_4_a_32_quant_ends_False/model-10408860 ...
[32m[0328 11:37:36 @base.py:227][0m Graph Finalized.
[32m[0328 11:37:36 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 11:37:36 @steps.py:127][0m Start training with global_step=10408860
[32m[0328 11:37:39 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13947/173481[03:00<34:19,77.48it/s]  9%|8         |14807/173481[03:10<34:07,77.48it/s] 16%|#6        |28180/173481[06:00<30:56,78.27it/s] 17%|#6        |28938/173481[06:10<30:46,78.27it/s] 25%|##4       |42694/173481[09:00<27:26,79.43it/s] 25%|##5       |43506/173481[09:10<27:16,79.43it/s] 33%|###2      |56692/173481[12:00<24:46,78.59it/s] 33%|###3      |57510/173481[12:10<24:35,78.59it/s] 40%|###9      |69196/173481[15:00<23:34,73.74it/s] 40%|####      |69831/173481[15:10<23:25,73.74it/s] 46%|####5     |79501/173481[18:00<24:18,64.45it/s] 46%|####6     |80154/173481[18:11<24:08,64.45it/s] 52%|#####1    |90060/173481[21:00<22:38,61.42it/s] 52%|#####2    |90692/173481[21:11<22:27,61.42it/s] 58%|#####7    |100562/173481[24:00<20:18,59.84it/s] 58%|#####8    |101250/173481[24:11<20:07,59.84it/s] 64%|######4   |111191/173481[27:00<17:27,59.44it/s] 64%|######4   |111882/173481[27:11<17:16,59.44it/s] 70%|#######   |121570/173481[30:00<14:46,58.54it/s] 70%|#######   |122240/173481[30:11<14:35,58.54it/s] 76%|#######6  |132121/173481[33:00<11:46,58.57it/s] 77%|#######6  |132829/173481[33:11<11:34,58.57it/s] 82%|########2 |142831/173481[36:00<08:39,59.03it/s] 83%|########2 |143547/173481[36:12<08:27,59.03it/s] 88%|########8 |152756/173481[39:00<06:03,57.02it/s] 88%|########8 |153385/173481[39:12<05:52,57.02it/s] 94%|#########3|162233/173481[42:00<03:25,54.74it/s] 94%|#########3|162918/173481[42:12<03:12,54.74it/s] 99%|#########9|172425/173481[45:00<00:18,55.67it/s]100%|#########9|173120/173481[45:12<00:06,55.67it/s]100%|##########|173481/173481[45:19<00:00,63.79it/s]
[32m[0328 12:22:59 @base.py:257][0m Epoch 1 (global_step 10582341) finished, time:2719.49 sec.
[32m[0328 12:22:59 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 49%|####8     |9202/18822[03:00<03:08,51.12it/s] 52%|#####1    |9785/18822[03:10<02:56,51.12it/s]100%|##########|18822/18822[05:24<00:00,58.06it/s]
0
[32m[0328 12:28:23 @monitor.py:363][0m QueueInput/queue_size: 1.1961
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.094
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/output-rms: 0.035052
[32m[0328 12:28:23 @monitor.py:363][0m cross_entropy_loss: 2.4335
[32m[0328 12:28:23 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 12:28:23 @monitor.py:363][0m train-error-top1: 0.61999
[32m[0328 12:28:23 @monitor.py:363][0m val-error-top1: 0.61771
[32m[0328 12:28:23 @monitor.py:363][0m val-utt-error: 0.23892
[32m[0328 12:28:23 @monitor.py:363][0m validation_cost: 2.5038
[32m[0328 12:28:23 @monitor.py:363][0m wd_cost: 3.3414e-15
[32m[0328 12:28:23 @group.py:42][0m Callbacks took 324.546 sec in total. InferenceRunner: 324.200sec
[32m[0328 12:28:23 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10588/173481[03:00<46:09,58.82it/s]  6%|6         |11124/173481[03:10<46:00,58.82it/s] 12%|#1        |20809/173481[06:00<44:02,57.78it/s] 12%|#2        |21417/173481[06:10<43:51,57.78it/s] 18%|#7        |30829/173481[09:00<41:55,56.70it/s] 18%|#8        |31394/173481[09:10<41:45,56.70it/s] 23%|##2       |39870/173481[12:00<41:48,53.27it/s] 23%|##3       |40414/173481[12:10<41:37,53.27it/s] 28%|##8       |49145/173481[15:00<39:34,52.37it/s] 29%|##8       |49717/173481[15:10<39:23,52.37it/s] 34%|###4      |59160/173481[18:00<35:18,53.96it/s] 34%|###4      |59789/173481[18:11<35:07,53.96it/s] 40%|###9      |69120/173481[21:00<31:50,54.63it/s] 40%|####      |69739/173481[21:11<31:38,54.63it/s] 46%|####5     |79368/173481[24:00<28:07,55.76it/s] 46%|####6     |80024/173481[24:11<27:56,55.76it/s] 52%|#####1    |89616/173481[27:00<24:48,56.34it/s] 52%|#####2    |90255/173481[27:11<24:37,56.34it/s] 58%|#####7    |99756/173481[30:00<21:48,56.33it/s] 58%|#####7    |100409/173481[30:11<21:37,56.33it/s] 63%|######3   |109859/173481[33:00<18:51,56.23it/s] 64%|######3   |110514/173481[33:12<18:39,56.23it/s] 69%|######9   |119774/173481[36:00<16:05,55.65it/s] 69%|######9   |120443/173481[36:12<15:53,55.65it/s] 75%|#######4  |129611/173481[39:00<13:15,55.14it/s] 75%|#######5  |130242/173481[39:12<13:04,55.14it/s] 80%|########  |139416/173481[42:00<10:21,54.80it/s] 81%|########  |140134/173481[42:12<10:08,54.80it/s] 86%|########6 |149452/173481[45:00<07:14,55.27it/s] 87%|########6 |150159/173481[45:12<07:01,55.27it/s] 92%|#########1|159601/173481[48:00<04:08,55.82it/s] 92%|#########2|160324/173481[48:12<03:55,55.82it/s] 98%|#########7|169770/173481[51:00<01:06,56.15it/s] 98%|#########8|170508/173481[51:13<00:52,56.15it/s]100%|##########|173481/173481[52:04<00:00,55.52it/s]
[32m[0328 13:20:28 @base.py:257][0m Epoch 2 (global_step 10755822) finished, time:3124.80 sec.
[32m[0328 13:20:28 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-10755822.
[32m[0328 13:20:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,140.96it/s]
1
[32m[0328 13:22:42 @monitor.py:363][0m QueueInput/queue_size: 0.59846
[32m[0328 13:22:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.231
[32m[0328 13:22:42 @monitor.py:363][0m activation-summaries/output-rms: 0.034688
[32m[0328 13:22:42 @monitor.py:363][0m cross_entropy_loss: 2.5155
[32m[0328 13:22:42 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 13:22:42 @monitor.py:363][0m train-error-top1: 0.62141
[32m[0328 13:22:42 @monitor.py:363][0m val-error-top1: 0.61806
[32m[0328 13:22:42 @monitor.py:363][0m val-utt-error: 0.23738
[32m[0328 13:22:42 @monitor.py:363][0m validation_cost: 2.5061
[32m[0328 13:22:42 @monitor.py:363][0m wd_cost: 3.3414e-15
[32m[0328 13:22:42 @group.py:42][0m Callbacks took 134.052 sec in total. InferenceRunner: 133.541sec
[32m[0328 13:22:42 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13169/173481[03:00<36:31,73.16it/s]  8%|7         |13746/173481[03:10<36:23,73.16it/s] 14%|#3        |23829/173481[06:00<38:06,65.44it/s] 14%|#4        |24368/173481[06:10<37:58,65.44it/s] 19%|#9        |33194/173481[09:00<40:20,57.96it/s] 19%|#9        |33752/173481[09:10<40:10,57.96it/s] 25%|##4       |42699/173481[12:00<39:26,55.26it/s] 25%|##4       |43248/173481[12:10<39:16,55.26it/s] 30%|###       |52049/173481[15:00<37:47,53.55it/s] 30%|###       |52554/173481[15:10<37:38,53.55it/s] 35%|###5      |61424/173481[18:00<35:22,52.80it/s] 36%|###5      |62018/173481[18:10<35:11,52.80it/s] 41%|####1     |71719/173481[21:00<30:53,54.90it/s] 42%|####1     |72323/173481[21:11<30:42,54.90it/s] 47%|####7     |81941/173481[24:00<27:19,55.83it/s] 48%|####7     |82550/173481[24:11<27:08,55.83it/s] 53%|#####3    |92369/173481[27:00<23:46,56.86it/s] 54%|#####3    |93018/173481[27:11<23:35,56.86it/s] 59%|#####9    |102671/173481[30:00<20:41,57.05it/s] 60%|#####9    |103352/173481[30:11<20:29,57.05it/s] 65%|######5   |113174/173481[33:00<17:25,57.68it/s] 66%|######5   |113815/173481[33:11<17:14,57.68it/s] 71%|#######1  |123518/173481[36:00<14:27,57.57it/s] 72%|#######1  |124168/173481[36:11<14:16,57.57it/s] 77%|#######7  |133864/173481[39:00<11:28,57.52it/s] 78%|#######7  |134505/173481[39:12<11:17,57.52it/s] 83%|########3 |144426/173481[42:00<08:20,58.09it/s] 84%|########3 |145153/173481[42:12<08:07,58.09it/s] 89%|########9 |155029/173481[45:00<05:15,58.48it/s] 90%|########9 |155728/173481[45:12<05:03,58.48it/s] 96%|#########5|165799/173481[48:00<02:09,59.15it/s] 96%|#########5|166538/173481[48:12<01:57,59.15it/s]100%|##########|173481/173481[50:06<00:00,57.70it/s]
[32m[0328 14:12:49 @base.py:257][0m Epoch 3 (global_step 10929303) finished, time:3006.36 sec.
[32m[0328 14:12:49 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,140.41it/s]
2
[32m[0328 14:15:03 @monitor.py:363][0m QueueInput/queue_size: 0.52739
[32m[0328 14:15:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.208
[32m[0328 14:15:03 @monitor.py:363][0m activation-summaries/output-rms: 0.03501
[32m[0328 14:15:03 @monitor.py:363][0m cross_entropy_loss: 2.4511
[32m[0328 14:15:03 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 14:15:03 @monitor.py:363][0m train-error-top1: 0.61781
[32m[0328 14:15:03 @monitor.py:363][0m val-error-top1: 0.61713
[32m[0328 14:15:03 @monitor.py:363][0m val-utt-error: 0.23563
[32m[0328 14:15:03 @monitor.py:363][0m validation_cost: 2.4981
[32m[0328 14:15:03 @monitor.py:363][0m wd_cost: 3.3414e-15
[32m[0328 14:15:03 @group.py:42][0m Callbacks took 134.301 sec in total. InferenceRunner: 134.060sec
[32m[0328 14:15:03 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13013/173481[03:00<37:00,72.28it/s]  8%|7         |13579/173481[03:10<36:52,72.28it/s] 13%|#2        |22469/173481[06:00<41:22,60.84it/s] 13%|#3        |23035/173481[06:10<41:12,60.84it/s] 18%|#8        |31903/173481[09:00<41:54,56.31it/s] 19%|#8        |32512/173481[09:10<41:43,56.31it/s] 24%|##4       |42033/173481[12:00<38:55,56.29it/s] 25%|##4       |42587/173481[12:10<38:45,56.29it/s] 30%|###       |52342/173481[15:00<35:33,56.78it/s] 31%|###       |53015/173481[15:10<35:21,56.78it/s] 36%|###5      |61833/173481[18:00<34:02,54.67it/s] 36%|###5      |62441/173481[18:10<33:51,54.67it/s] 41%|####1     |71989/173481[21:00<30:27,55.53it/s] 42%|####1     |72611/173481[21:11<30:16,55.53it/s] 47%|####7     |82163/173481[24:00<27:10,56.00it/s] 48%|####7     |82783/173481[24:11<26:59,56.00it/s] 53%|#####2    |91843/173481[27:00<24:47,54.87it/s] 53%|#####3    |92401/173481[27:11<24:37,54.87it/s] 59%|#####8    |101848/173481[30:00<21:37,55.22it/s] 59%|#####9    |102547/173481[30:11<21:24,55.22it/s] 65%|######4   |112743/173481[33:00<17:31,57.75it/s] 65%|######5   |113467/173481[33:11<17:19,57.75it/s] 71%|#######1  |123582/173481[36:00<14:06,58.96it/s] 72%|#######1  |124277/173481[36:11<13:54,58.96it/s] 77%|#######7  |134214/173481[39:00<11:05,59.01it/s] 78%|#######7  |134892/173481[39:12<10:53,59.01it/s] 83%|########3 |144447/173481[42:00<08:21,57.91it/s] 84%|########3 |145109/173481[42:12<08:09,57.91it/s] 89%|########9 |154696/173481[45:00<05:27,57.42it/s] 90%|########9 |155355/173481[45:12<05:15,57.42it/s] 95%|#########5|165084/173481[48:00<02:25,57.56it/s] 96%|#########5|165782/173481[48:12<02:13,57.56it/s]100%|##########|173481/173481[50:46<00:00,56.95it/s]
[32m[0328 15:05:49 @base.py:257][0m Epoch 4 (global_step 11102784) finished, time:3046.17 sec.
[32m[0328 15:05:49 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-11102784.
[32m[0328 15:05:50 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.59it/s]
3
[32m[0328 15:07:58 @monitor.py:363][0m QueueInput/queue_size: 0.67326
[32m[0328 15:07:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.069
[32m[0328 15:07:58 @monitor.py:363][0m activation-summaries/output-rms: 0.035093
[32m[0328 15:07:58 @monitor.py:363][0m cross_entropy_loss: 2.4953
[32m[0328 15:07:58 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 15:07:58 @monitor.py:363][0m train-error-top1: 0.62437
[32m[0328 15:07:58 @monitor.py:363][0m val-error-top1: 0.6145
[32m[0328 15:07:58 @monitor.py:363][0m val-utt-error: 0.23377
[32m[0328 15:07:58 @monitor.py:363][0m validation_cost: 2.4851
[32m[0328 15:07:58 @monitor.py:363][0m wd_cost: 6.6828e-16
[32m[0328 15:07:58 @group.py:42][0m Callbacks took 128.491 sec in total. InferenceRunner: 127.553sec
[32m[0328 15:07:58 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10983/173481[03:00<44:23,61.02it/s]  7%|6         |11507/173481[03:10<44:14,61.02it/s] 12%|#2        |21045/173481[06:00<43:32,58.35it/s] 12%|#2        |21556/173481[06:10<43:23,58.35it/s] 18%|#8        |31307/173481[09:00<41:05,57.66it/s] 18%|#8        |31950/173481[09:10<40:54,57.66it/s] 24%|##3       |41499/173481[12:00<38:29,57.14it/s] 24%|##4       |42083/173481[12:10<38:19,57.14it/s] 30%|##9       |51270/173481[15:00<36:35,55.67it/s] 30%|##9       |51936/173481[15:10<36:23,55.67it/s] 36%|###5      |61822/173481[18:00<32:35,57.11it/s] 36%|###5      |62451/173481[18:10<32:24,57.11it/s] 41%|####1     |71944/173481[21:00<29:51,56.67it/s] 42%|####1     |72561/173481[21:11<29:40,56.67it/s] 47%|####6     |81406/173481[24:00<28:08,54.54it/s] 47%|####7     |81972/173481[24:11<27:57,54.54it/s] 52%|#####2    |90795/173481[27:00<25:50,53.32it/s] 53%|#####2    |91421/173481[27:11<25:38,53.32it/s] 58%|#####7    |100349/173481[30:00<22:54,53.20it/s] 58%|#####8    |100946/173481[30:11<22:43,53.20it/s] 63%|######3   |109947/173481[33:00<19:52,53.26it/s] 64%|######3   |110586/173481[33:11<19:40,53.26it/s] 69%|######9   |119837/173481[36:00<16:31,54.09it/s] 69%|######9   |120476/173481[36:11<16:19,54.09it/s] 75%|#######4  |129565/173481[39:00<13:32,54.07it/s] 75%|#######5  |130251/173481[39:12<13:19,54.07it/s] 80%|########  |139002/173481[42:00<10:47,53.23it/s] 81%|########  |139666/173481[42:12<10:35,53.23it/s] 86%|########5 |149125/173481[45:00<07:25,54.69it/s] 86%|########6 |149825/173481[45:12<07:12,54.69it/s] 92%|#########1|159222/173481[48:00<04:17,55.38it/s] 92%|#########2|159850/173481[48:12<04:06,55.38it/s] 97%|#########7|168629/173481[51:00<01:30,53.78it/s] 98%|#########7|169286/173481[51:12<01:18,53.78it/s]100%|##########|173481/173481[52:32<00:00,55.03it/s]
[32m[0328 16:00:30 @base.py:257][0m Epoch 5 (global_step 11276265) finished, time:3152.50 sec.
[32m[0328 16:00:30 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-11276265.
[32m[0328 16:00:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.30it/s]
4
[32m[0328 16:02:36 @monitor.py:363][0m QueueInput/queue_size: 0.92603
[32m[0328 16:02:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.223
[32m[0328 16:02:36 @monitor.py:363][0m activation-summaries/output-rms: 0.036901
[32m[0328 16:02:36 @monitor.py:363][0m cross_entropy_loss: 2.428
[32m[0328 16:02:36 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 16:02:36 @monitor.py:363][0m train-error-top1: 0.60985
[32m[0328 16:02:36 @monitor.py:363][0m val-error-top1: 0.61501
[32m[0328 16:02:36 @monitor.py:363][0m val-utt-error: 0.23738
[32m[0328 16:02:36 @monitor.py:363][0m validation_cost: 2.4861
[32m[0328 16:02:36 @monitor.py:363][0m wd_cost: 6.6828e-16
[32m[0328 16:02:36 @group.py:42][0m Callbacks took 126.381 sec in total. InferenceRunner: 125.244sec
[32m[0328 16:02:36 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12228/173481[03:00<39:33,67.93it/s]  7%|7         |12835/173481[03:10<39:24,67.93it/s] 13%|#3        |22806/173481[06:00<39:50,63.02it/s] 14%|#3        |23435/173481[06:10<39:41,63.02it/s] 19%|#8        |32908/173481[09:00<39:27,59.37it/s] 19%|#9        |33448/173481[09:10<39:18,59.37it/s] 24%|##4       |41875/173481[12:00<40:29,54.17it/s] 24%|##4       |42405/173481[12:10<40:19,54.17it/s] 29%|##9       |50876/173481[15:00<39:17,52.01it/s] 30%|##9       |51398/173481[15:10<39:07,52.01it/s] 35%|###4      |60226/173481[18:00<36:19,51.96it/s] 35%|###5      |60847/173481[18:11<36:07,51.96it/s] 40%|####      |70137/173481[21:00<32:12,53.47it/s] 41%|####      |70681/173481[21:11<32:02,53.47it/s] 46%|####5     |79431/173481[24:00<29:50,52.53it/s] 46%|####6     |80028/173481[24:11<29:38,52.53it/s] 51%|#####     |88351/173481[27:00<27:49,51.00it/s] 51%|#####1    |88891/173481[27:11<27:38,51.00it/s] 56%|#####6    |97346/173481[30:00<25:08,50.48it/s] 56%|#####6    |97883/173481[30:11<24:57,50.48it/s] 61%|######1   |106063/173481[33:00<22:43,49.43it/s] 61%|######1   |106630/173481[33:11<22:32,49.43it/s] 66%|######6   |114931/173481[36:00<19:46,49.35it/s] 67%|######6   |115533/173481[36:11<19:34,49.35it/s] 72%|#######1  |124286/173481[39:00<16:11,50.62it/s] 72%|#######1  |124900/173481[39:12<15:59,50.62it/s] 77%|#######6  |133306/173481[42:00<13:17,50.36it/s] 77%|#######7  |133889/173481[42:12<13:06,50.36it/s] 82%|########2 |142481/173481[45:00<10:11,50.66it/s] 83%|########2 |143134/173481[45:12<09:58,50.66it/s] 87%|########7 |151639/173481[48:00<07:10,50.77it/s] 88%|########7 |152315/173481[48:12<06:56,50.77it/s] 93%|#########2|161141/173481[51:00<03:58,51.75it/s] 93%|#########3|161745/173481[51:12<03:46,51.75it/s] 98%|#########7|169761/173481[54:00<01:14,49.74it/s] 98%|#########8|170335/173481[54:12<01:03,49.74it/s]100%|##########|173481/173481[55:18<00:00,52.28it/s]
[32m[0328 16:57:55 @base.py:257][0m Epoch 6 (global_step 11449746) finished, time:3318.32 sec.
[32m[0328 16:57:55 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.47it/s]
5
[32m[0328 17:00:00 @monitor.py:363][0m QueueInput/queue_size: 0.7948
[32m[0328 17:00:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.081
[32m[0328 17:00:00 @monitor.py:363][0m activation-summaries/output-rms: 0.034977
[32m[0328 17:00:00 @monitor.py:363][0m cross_entropy_loss: 2.4076
[32m[0328 17:00:00 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 17:00:00 @monitor.py:363][0m train-error-top1: 0.61764
[32m[0328 17:00:00 @monitor.py:363][0m val-error-top1: 0.61366
[32m[0328 17:00:00 @monitor.py:363][0m val-utt-error: 0.23223
[32m[0328 17:00:00 @monitor.py:363][0m validation_cost: 2.4772
[32m[0328 17:00:00 @monitor.py:363][0m wd_cost: 6.6828e-16
[32m[0328 17:00:00 @group.py:42][0m Callbacks took 124.702 sec in total. InferenceRunner: 124.277sec
[32m[0328 17:00:00 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11160/173481[03:00<43:38,61.99it/s]  7%|6         |11704/173481[03:10<43:29,61.99it/s] 12%|#1        |20313/173481[06:00<45:41,55.87it/s] 12%|#2        |20833/173481[06:10<45:32,55.87it/s] 17%|#6        |29485/173481[09:00<45:02,53.29it/s] 17%|#7        |30041/173481[09:10<44:51,53.29it/s] 22%|##1       |38068/173481[12:00<44:50,50.33it/s] 22%|##2       |38549/173481[12:10<44:41,50.33it/s] 27%|##6       |46410/173481[15:00<43:53,48.25it/s] 27%|##7       |46917/173481[15:10<43:42,48.25it/s] 32%|###1      |55090/173481[18:00<40:54,48.23it/s] 32%|###2      |55634/173481[18:10<40:43,48.23it/s] 37%|###6      |64090/173481[21:00<37:07,49.10it/s] 37%|###7      |64582/173481[21:11<36:57,49.10it/s] 42%|####2     |73265/173481[24:00<33:23,50.02it/s] 43%|####2     |73849/173481[24:11<33:11,50.02it/s] 48%|####7     |82550/173481[27:00<29:50,50.78it/s] 48%|####7     |83149/173481[27:11<29:38,50.78it/s] 53%|#####3    |92043/173481[30:00<26:13,51.74it/s] 53%|#####3    |92636/173481[30:11<26:02,51.74it/s] 58%|#####8    |101472/173481[33:00<23:03,52.06it/s] 59%|#####8    |102059/173481[33:11<22:52,52.06it/s] 64%|######3   |110819/173481[36:00<20:05,51.99it/s] 64%|######4   |111410/173481[36:11<19:53,51.99it/s] 69%|######9   |119760/173481[39:00<17:37,50.79it/s] 69%|######9   |120331/173481[39:12<17:26,50.79it/s] 74%|#######4  |128760/173481[42:00<14:47,50.39it/s] 75%|#######4  |129344/173481[42:12<14:35,50.39it/s] 79%|#######9  |137512/173481[45:00<12:06,49.49it/s] 80%|#######9  |138094/173481[45:12<11:55,49.49it/s] 84%|########4 |146400/173481[48:00<09:07,49.43it/s] 85%|########4 |147014/173481[48:12<08:55,49.43it/s] 90%|########9 |155523/173481[51:00<05:58,50.05it/s] 90%|######### |156175/173481[51:12<05:45,50.05it/s] 95%|#########5|164985/173481[54:00<02:45,51.27it/s] 95%|#########5|165661/173481[54:12<02:32,51.27it/s]100%|##########|173481/173481[56:32<00:00,51.14it/s]
[32m[0328 17:56:32 @base.py:257][0m Epoch 7 (global_step 11623227) finished, time:3392.57 sec.
[32m[0328 17:56:33 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-11623227.
[32m[0328 17:56:33 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,151.82it/s]
6
[32m[0328 17:58:37 @monitor.py:363][0m QueueInput/queue_size: 0.69821
[32m[0328 17:58:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.221
[32m[0328 17:58:37 @monitor.py:363][0m activation-summaries/output-rms: 0.034594
[32m[0328 17:58:37 @monitor.py:363][0m cross_entropy_loss: 2.503
[32m[0328 17:58:37 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 17:58:37 @monitor.py:363][0m train-error-top1: 0.62167
[32m[0328 17:58:37 @monitor.py:363][0m val-error-top1: 0.61629
[32m[0328 17:58:37 @monitor.py:363][0m val-utt-error: 0.23621
[32m[0328 17:58:37 @monitor.py:363][0m validation_cost: 2.4937
[32m[0328 17:58:37 @monitor.py:363][0m wd_cost: 1.3366e-16
[32m[0328 17:58:37 @group.py:42][0m Callbacks took 124.804 sec in total. InferenceRunner: 124.008sec
[32m[0328 17:58:37 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13184/173481[03:00<36:29,73.23it/s]  8%|7         |13748/173481[03:10<36:21,73.23it/s] 13%|#3        |23249/173481[06:00<39:29,63.41it/s] 14%|#3        |23763/173481[06:10<39:21,63.41it/s] 19%|#8        |32104/173481[09:00<42:31,55.40it/s] 19%|#8        |32633/173481[09:10<42:22,55.40it/s] 24%|##3       |41546/173481[12:00<40:48,53.89it/s] 24%|##4       |42098/173481[12:10<40:38,53.89it/s] 29%|##9       |51168/173481[15:00<37:58,53.67it/s] 30%|##9       |51709/173481[15:10<37:48,53.67it/s] 35%|###4      |60396/173481[18:00<35:56,52.44it/s] 35%|###5      |60958/173481[18:11<35:45,52.44it/s] 41%|####      |70365/173481[21:00<31:54,53.87it/s] 41%|####      |71119/173481[21:11<31:40,53.87it/s] 47%|####6     |81199/173481[24:00<27:03,56.85it/s] 47%|####7     |81798/173481[24:11<26:52,56.85it/s] 52%|#####2    |90743/173481[27:00<25:07,54.87it/s] 53%|#####2    |91365/173481[27:11<24:56,54.87it/s] 58%|#####7    |100255/173481[30:00<22:40,53.84it/s] 58%|#####8    |100871/173481[30:11<22:28,53.84it/s] 63%|######3   |109783/173481[33:00<19:53,53.38it/s] 64%|######3   |110413/173481[33:11<19:41,53.38it/s] 69%|######9   |119759/173481[36:00<16:28,54.37it/s] 69%|######9   |120404/173481[36:12<16:16,54.37it/s] 75%|#######4  |129823/173481[39:00<13:11,55.13it/s] 75%|#######5  |130493/173481[39:12<12:59,55.13it/s] 81%|########  |140159/173481[42:00<09:52,56.25it/s] 81%|########1 |140813/173481[42:12<09:40,56.25it/s] 87%|########6 |150170/173481[45:00<06:56,55.93it/s] 87%|########6 |150826/173481[45:12<06:45,55.93it/s] 92%|#########2|160104/173481[48:00<04:00,55.55it/s] 93%|#########2|160807/173481[48:12<03:48,55.55it/s] 98%|#########8|170084/173481[51:00<01:01,55.50it/s] 98%|#########8|170785/173481[51:12<00:48,55.50it/s]100%|##########|173481/173481[52:01<00:00,55.58it/s]
[32m[0328 18:50:38 @base.py:257][0m Epoch 8 (global_step 11796708) finished, time:3121.40 sec.
[32m[0328 18:50:39 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,162.19it/s]
7
[32m[0328 18:52:35 @monitor.py:363][0m QueueInput/queue_size: 0.89917
[32m[0328 18:52:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.202
[32m[0328 18:52:35 @monitor.py:363][0m activation-summaries/output-rms: 0.035014
[32m[0328 18:52:35 @monitor.py:363][0m cross_entropy_loss: 2.4401
[32m[0328 18:52:35 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 18:52:35 @monitor.py:363][0m train-error-top1: 0.61672
[32m[0328 18:52:35 @monitor.py:363][0m val-error-top1: 0.6148
[32m[0328 18:52:35 @monitor.py:363][0m val-utt-error: 0.23303
[32m[0328 18:52:35 @monitor.py:363][0m validation_cost: 2.484
[32m[0328 18:52:35 @monitor.py:363][0m wd_cost: 1.3366e-16
[32m[0328 18:52:35 @group.py:42][0m Callbacks took 116.382 sec in total. InferenceRunner: 116.060sec
[32m[0328 18:52:35 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11916/173481[03:00<40:40,66.20it/s]  7%|7         |12456/173481[03:10<40:32,66.20it/s] 12%|#2        |21025/173481[06:00<44:17,57.36it/s] 12%|#2        |21582/173481[06:10<44:08,57.36it/s] 18%|#7        |31147/173481[09:00<41:46,56.79it/s] 18%|#8        |31722/173481[09:10<41:36,56.79it/s] 24%|##4       |41768/173481[12:00<37:55,57.87it/s] 24%|##4       |42457/173481[12:10<37:43,57.87it/s] 31%|###       |53469/173481[15:00<32:39,61.23it/s] 31%|###1      |54118/173481[15:10<32:29,61.23it/s] 37%|###7      |64636/173481[18:00<29:26,61.63it/s] 38%|###7      |65330/173481[18:10<29:14,61.63it/s] 44%|####3     |75903/173481[21:00<26:11,62.10it/s] 44%|####4     |76616/173481[21:11<25:59,62.10it/s] 50%|####9     |86698/173481[24:00<23:42,61.01it/s] 50%|#####     |87359/173481[24:11<23:31,61.01it/s] 56%|#####6    |97779/173481[27:00<20:35,61.28it/s] 57%|#####6    |98472/173481[27:11<20:24,61.28it/s] 63%|######2   |108839/173481[30:00<17:33,61.36it/s] 63%|######3   |109540/173481[30:11<17:22,61.36it/s] 69%|######9   |119888/173481[33:00<14:33,61.37it/s] 70%|######9   |120613/173481[33:11<14:21,61.37it/s] 75%|#######5  |130923/173481[36:00<11:33,61.33it/s] 76%|#######5  |131667/173481[36:12<11:21,61.33it/s] 82%|########1 |142230/173481[39:00<08:23,62.07it/s] 82%|########2 |142989/173481[39:12<08:11,62.07it/s] 88%|########8 |153516/173481[42:00<05:20,62.38it/s] 89%|########8 |154301/173481[42:12<05:07,62.38it/s] 95%|#########4|164766/173481[45:00<02:19,62.44it/s] 95%|#########5|165468/173481[45:12<02:08,62.44it/s]100%|##########|173481/173481[47:30<00:00,60.86it/s]
[32m[0328 19:40:05 @base.py:257][0m Epoch 9 (global_step 11970189) finished, time:2850.41 sec.
[32m[0328 19:40:06 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.65it/s]
8
[32m[0328 19:42:09 @monitor.py:363][0m QueueInput/queue_size: 0.12645
[32m[0328 19:42:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.073
[32m[0328 19:42:09 @monitor.py:363][0m activation-summaries/output-rms: 0.035098
[32m[0328 19:42:09 @monitor.py:363][0m cross_entropy_loss: 2.4904
[32m[0328 19:42:09 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 19:42:09 @monitor.py:363][0m train-error-top1: 0.62597
[32m[0328 19:42:09 @monitor.py:363][0m val-error-top1: 0.61339
[32m[0328 19:42:09 @monitor.py:363][0m val-utt-error: 0.23281
[32m[0328 19:42:09 @monitor.py:363][0m validation_cost: 2.4781
[32m[0328 19:42:09 @monitor.py:363][0m wd_cost: 1.3366e-16
[32m[0328 19:42:09 @group.py:42][0m Callbacks took 124.176 sec in total. InferenceRunner: 123.306sec
[32m[0328 19:42:09 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13077/173481[03:00<36:48,72.64it/s]  8%|7         |13701/173481[03:10<36:39,72.64it/s] 14%|#3        |23782/173481[06:00<38:08,65.40it/s] 14%|#4        |24426/173481[06:10<37:59,65.40it/s] 20%|##        |35047/173481[09:00<36:04,63.96it/s] 21%|##        |35709/173481[09:10<35:54,63.96it/s] 27%|##6       |46228/173481[12:00<33:39,63.02it/s] 27%|##7       |46866/173481[12:10<33:29,63.02it/s] 33%|###2      |57032/173481[15:00<31:34,61.48it/s] 33%|###3      |57656/173481[15:10<31:23,61.48it/s] 39%|###9      |67777/173481[18:00<29:05,60.57it/s] 39%|###9      |68439/173481[18:11<28:54,60.57it/s] 45%|####5     |78757/173481[21:00<25:58,60.78it/s] 46%|####5     |79462/173481[21:11<25:46,60.78it/s] 52%|#####1    |90008/173481[24:00<22:34,61.63it/s] 52%|#####2    |90661/173481[24:11<22:23,61.63it/s] 58%|#####7    |100270/173481[27:00<20:36,59.23it/s] 58%|#####8    |100935/173481[27:11<20:24,59.23it/s] 64%|######3   |110532/173481[30:00<18:03,58.09it/s] 64%|######4   |111166/173481[30:11<17:52,58.09it/s] 69%|######9   |120407/173481[33:00<15:40,56.43it/s] 70%|######9   |121075/173481[33:11<15:28,56.43it/s] 75%|#######5  |130471/173481[36:00<12:45,56.17it/s] 76%|#######5  |131156/173481[36:12<12:33,56.17it/s] 81%|########1 |141149/173481[39:00<09:20,57.70it/s] 82%|########1 |141851/173481[39:12<09:08,57.70it/s] 88%|########7 |152192/173481[42:00<05:57,59.47it/s] 88%|########8 |152928/173481[42:12<05:45,59.47it/s] 94%|#########3|162848/173481[45:00<02:59,59.33it/s] 94%|#########4|163526/173481[45:12<02:47,59.33it/s]100%|#########9|172982/173481[48:00<00:08,57.77it/s]100%|##########|173481/173481[48:09<00:00,60.03it/s]
[32m[0328 20:30:19 @base.py:257][0m Epoch 10 (global_step 12143670) finished, time:2889.74 sec.
[32m[0328 20:30:19 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-12143670.
[32m[0328 20:30:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.88it/s]
9
[32m[0328 20:32:23 @monitor.py:363][0m QueueInput/queue_size: 0.32087
[32m[0328 20:32:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.22
[32m[0328 20:32:23 @monitor.py:363][0m activation-summaries/output-rms: 0.036907
[32m[0328 20:32:23 @monitor.py:363][0m cross_entropy_loss: 2.4246
[32m[0328 20:32:23 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 20:32:23 @monitor.py:363][0m train-error-top1: 0.61217
[32m[0328 20:32:23 @monitor.py:363][0m val-error-top1: 0.61428
[32m[0328 20:32:23 @monitor.py:363][0m val-utt-error: 0.2377
[32m[0328 20:32:23 @monitor.py:363][0m validation_cost: 2.4817
[32m[0328 20:32:23 @monitor.py:363][0m wd_cost: 2.6731e-17
[32m[0328 20:32:23 @group.py:42][0m Callbacks took 123.543 sec in total. InferenceRunner: 123.125sec
[32m[0328 20:32:23 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13191/173481[03:00<36:27,73.28it/s]  8%|7         |13822/173481[03:10<36:18,73.28it/s] 14%|#4        |24314/173481[06:00<37:04,67.05it/s] 14%|#4        |24951/173481[06:10<36:55,67.05it/s] 20%|##        |35257/173481[09:00<36:07,63.77it/s] 21%|##        |35877/173481[09:10<35:57,63.77it/s] 26%|##6       |45915/173481[12:00<34:37,61.40it/s] 27%|##6       |46560/173481[12:10<34:26,61.40it/s] 33%|###2      |56573/173481[15:00<32:19,60.29it/s] 33%|###3      |57250/173481[15:10<32:07,60.29it/s] 39%|###8      |67558/173481[18:00<29:06,60.65it/s] 39%|###9      |68190/173481[18:10<28:55,60.65it/s] 45%|####4     |77881/173481[21:00<27:01,58.96it/s] 45%|####5     |78546/173481[21:11<26:50,58.96it/s] 51%|#####     |88349/173481[24:00<24:13,58.55it/s] 51%|#####1    |88989/173481[24:11<24:03,58.55it/s] 57%|#####6    |98731/173481[27:00<21:26,58.10it/s] 57%|#####7    |99350/173481[27:11<21:15,58.10it/s] 63%|######2   |109007/173481[30:00<18:39,57.59it/s] 63%|######3   |109705/173481[30:11<18:27,57.59it/s] 69%|######8   |119698/173481[33:00<15:19,58.48it/s] 69%|######9   |120380/173481[33:11<15:08,58.48it/s] 75%|#######5  |130377/173481[36:00<12:11,58.90it/s] 76%|#######5  |131055/173481[36:12<12:00,58.90it/s] 81%|########1 |141106/173481[39:00<09:06,59.25it/s] 82%|########1 |141840/173481[39:12<08:54,59.25it/s] 87%|########7 |151531/173481[42:00<06:14,58.57it/s] 88%|########7 |152255/173481[42:12<06:02,58.57it/s] 93%|#########3|161911/173481[45:00<03:19,58.11it/s] 94%|#########3|162605/173481[45:12<03:07,58.11it/s] 99%|#########9|171996/173481[48:00<00:26,57.04it/s]100%|#########9|172687/173481[48:12<00:13,57.04it/s]100%|##########|173481/173481[48:27<00:00,59.67it/s]
[32m[0328 21:20:50 @base.py:257][0m Epoch 11 (global_step 12317151) finished, time:2907.29 sec.
[32m[0328 21:20:50 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.69it/s]
10
[32m[0328 21:22:47 @monitor.py:363][0m QueueInput/queue_size: 0.46442
[32m[0328 21:22:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.078
[32m[0328 21:22:47 @monitor.py:363][0m activation-summaries/output-rms: 0.034975
[32m[0328 21:22:47 @monitor.py:363][0m cross_entropy_loss: 2.4057
[32m[0328 21:22:47 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 21:22:47 @monitor.py:363][0m train-error-top1: 0.61616
[32m[0328 21:22:47 @monitor.py:363][0m val-error-top1: 0.61316
[32m[0328 21:22:47 @monitor.py:363][0m val-utt-error: 0.23287
[32m[0328 21:22:47 @monitor.py:363][0m validation_cost: 2.4746
[32m[0328 21:22:47 @monitor.py:363][0m wd_cost: 2.6731e-17
[32m[0328 21:22:47 @group.py:42][0m Callbacks took 116.716 sec in total. InferenceRunner: 116.420sec
[32m[0328 21:22:47 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12469/173481[03:00<38:44,69.27it/s]  8%|7         |13061/173481[03:10<38:35,69.27it/s] 13%|#3        |23079/173481[06:00<39:21,63.69it/s] 14%|#3        |23716/173481[06:10<39:11,63.69it/s] 19%|#9        |33655/173481[09:00<38:08,61.11it/s] 20%|#9        |34245/173481[09:10<37:58,61.11it/s] 25%|##4       |43270/173481[12:00<38:04,57.00it/s] 25%|##5       |43874/173481[12:10<37:53,57.00it/s] 31%|###       |53445/173481[15:00<35:14,56.76it/s] 31%|###1      |54099/173481[15:10<35:03,56.76it/s] 37%|###6      |64115/173481[18:00<31:26,57.99it/s] 37%|###7      |64693/173481[18:10<31:16,57.99it/s] 43%|####3     |75059/173481[21:00<27:38,59.36it/s] 44%|####3     |75711/173481[21:11<27:27,59.36it/s] 49%|####9     |85615/173481[24:00<24:49,58.99it/s] 50%|####9     |86265/173481[24:11<24:38,58.99it/s] 55%|#####5    |96164/173481[27:00<21:54,58.80it/s] 56%|#####5    |96795/173481[27:11<21:44,58.80it/s] 61%|######1   |106440/173481[30:00<19:17,57.93it/s] 62%|######1   |107089/173481[30:11<19:06,57.93it/s] 67%|######7   |116715/173481[33:00<16:27,57.50it/s] 68%|######7   |117354/173481[33:11<16:16,57.50it/s] 73%|#######3  |126815/173481[36:00<13:41,56.79it/s] 73%|#######3  |127470/173481[36:11<13:30,56.79it/s] 79%|#######9  |137335/173481[39:00<10:27,57.60it/s] 80%|#######9  |138049/173481[39:12<10:15,57.60it/s] 85%|########5 |148135/173481[42:00<07:11,58.77it/s] 86%|########5 |148818/173481[42:12<06:59,58.77it/s] 92%|#########1|158842/173481[45:00<04:07,59.12it/s] 92%|#########1|159574/173481[45:12<03:55,59.12it/s] 98%|#########7|169430/173481[48:00<01:08,58.97it/s] 98%|#########8|170133/173481[48:12<00:56,58.97it/s]100%|##########|173481/173481[49:10<00:00,58.81it/s]
[32m[0328 22:11:57 @base.py:257][0m Epoch 12 (global_step 12490632) finished, time:2950.04 sec.
[32m[0328 22:11:57 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-12490632.
[32m[0328 22:11:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.42it/s]
11
[32m[0328 22:13:59 @monitor.py:363][0m QueueInput/queue_size: 1.1155
[32m[0328 22:13:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.224
[32m[0328 22:13:59 @monitor.py:363][0m activation-summaries/output-rms: 0.034547
[32m[0328 22:13:59 @monitor.py:363][0m cross_entropy_loss: 2.505
[32m[0328 22:13:59 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 22:13:59 @monitor.py:363][0m train-error-top1: 0.62104
[32m[0328 22:13:59 @monitor.py:363][0m val-error-top1: 0.61547
[32m[0328 22:13:59 @monitor.py:363][0m val-utt-error: 0.23414
[32m[0328 22:13:59 @monitor.py:363][0m validation_cost: 2.4888
[32m[0328 22:13:59 @monitor.py:363][0m wd_cost: 5.3462e-18
[32m[0328 22:13:59 @group.py:42][0m Callbacks took 122.496 sec in total. InferenceRunner: 121.895sec
[32m[0328 22:13:59 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14034/173481[03:00<34:05,77.94it/s]  8%|8         |14668/173481[03:10<33:57,77.94it/s] 14%|#4        |24685/173481[06:00<36:51,67.27it/s] 15%|#4        |25209/173481[06:10<36:44,67.27it/s] 20%|#9        |34390/173481[09:00<38:43,59.86it/s] 20%|##        |35012/173481[09:10<38:33,59.86it/s] 26%|##5       |44640/173481[12:00<36:47,58.36it/s] 26%|##6       |45274/173481[12:10<36:36,58.36it/s] 32%|###1      |55207/173481[15:00<33:40,58.53it/s] 32%|###2      |55828/173481[15:10<33:30,58.53it/s] 38%|###7      |65829/173481[18:00<30:31,58.77it/s] 38%|###8      |66564/173481[18:11<30:19,58.77it/s] 45%|####4     |77675/173481[21:00<25:43,62.09it/s] 45%|####5     |78433/173481[21:11<25:30,62.09it/s] 51%|#####1    |88715/173481[24:00<22:53,61.71it/s] 52%|#####1    |89393/173481[24:11<22:42,61.71it/s] 57%|#####7    |99242/173481[27:00<20:36,60.05it/s] 58%|#####7    |99925/173481[27:11<20:24,60.05it/s] 63%|######3   |109878/173481[30:00<17:47,59.57it/s] 64%|######3   |110568/173481[30:11<17:36,59.57it/s] 70%|######9   |120736/173481[33:00<14:39,59.94it/s] 70%|#######   |121443/173481[33:11<14:28,59.94it/s] 76%|#######5  |131500/173481[36:00<11:41,59.87it/s] 76%|#######6  |132242/173481[36:12<11:28,59.87it/s] 82%|########2 |142514/173481[39:00<08:31,60.52it/s] 83%|########2 |143253/173481[39:12<08:19,60.52it/s] 89%|########8 |153610/173481[42:00<05:25,61.08it/s] 89%|########8 |154393/173481[42:12<05:12,61.08it/s] 95%|#########5|164954/173481[45:00<02:17,62.03it/s] 96%|#########5|165744/173481[45:12<02:04,62.03it/s]100%|##########|173481/173481[47:11<00:00,61.27it/s]
[32m[0328 23:01:10 @base.py:257][0m Epoch 13 (global_step 12664113) finished, time:2831.21 sec.
[32m[0328 23:01:11 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.04it/s]
12
[32m[0328 23:03:14 @monitor.py:363][0m QueueInput/queue_size: 0.83914
[32m[0328 23:03:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.198
[32m[0328 23:03:14 @monitor.py:363][0m activation-summaries/output-rms: 0.035003
[32m[0328 23:03:14 @monitor.py:363][0m cross_entropy_loss: 2.4402
[32m[0328 23:03:14 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 23:03:14 @monitor.py:363][0m train-error-top1: 0.61513
[32m[0328 23:03:14 @monitor.py:363][0m val-error-top1: 0.61468
[32m[0328 23:03:14 @monitor.py:363][0m val-utt-error: 0.2335
[32m[0328 23:03:14 @monitor.py:363][0m validation_cost: 2.4836
[32m[0328 23:03:14 @monitor.py:363][0m wd_cost: 5.3462e-18
[32m[0328 23:03:14 @group.py:42][0m Callbacks took 124.044 sec in total. InferenceRunner: 123.805sec
[32m[0328 23:03:14 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13556/173481[03:00<35:23,75.31it/s]  8%|8         |14209/173481[03:10<35:14,75.31it/s] 14%|#3        |24279/173481[06:00<37:22,66.52it/s] 14%|#4        |24882/173481[06:10<37:13,66.52it/s] 20%|##        |35277/173481[09:00<36:09,63.69it/s] 21%|##        |35922/173481[09:10<35:59,63.69it/s] 27%|##6       |46555/173481[12:00<33:29,63.17it/s] 27%|##7       |47249/173481[12:10<33:18,63.17it/s] 33%|###3      |57777/173481[15:00<30:43,62.75it/s] 34%|###3      |58452/173481[15:10<30:33,62.75it/s] 40%|###9      |69143/173481[18:00<27:37,62.94it/s] 40%|####      |69847/173481[18:11<27:26,62.94it/s] 46%|####6     |80525/173481[21:00<24:33,63.09it/s] 47%|####6     |81214/173481[21:11<24:22,63.09it/s] 53%|#####2    |91778/173481[24:00<21:41,62.80it/s] 53%|#####3    |92459/173481[24:11<21:30,62.80it/s] 59%|#####9    |103017/173481[27:00<18:45,62.62it/s] 60%|#####9    |103678/173481[27:11<18:34,62.62it/s] 66%|######5   |114158/173481[30:00<15:52,62.25it/s] 66%|######6   |114849/173481[30:11<15:41,62.25it/s] 72%|#######2  |125039/173481[33:00<13:09,61.33it/s] 72%|#######2  |125757/173481[33:11<12:58,61.33it/s] 78%|#######8  |136169/173481[36:00<10:05,61.58it/s] 79%|#######8  |136889/173481[36:11<09:54,61.58it/s] 85%|########5 |147488/173481[39:00<06:57,62.21it/s] 85%|########5 |148223/173481[39:12<06:45,62.21it/s] 92%|#########1|158833/173481[42:00<03:53,62.62it/s] 92%|#########1|159602/173481[42:12<03:41,62.62it/s] 98%|#########7|169688/173481[45:00<01:01,61.43it/s] 98%|#########8|170379/173481[45:12<00:50,61.43it/s]100%|##########|173481/173481[46:05<00:00,62.72it/s]
[32m[0328 23:49:20 @base.py:257][0m Epoch 14 (global_step 12837594) finished, time:2765.79 sec.
[32m[0328 23:49:20 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.71it/s]
13
[32m[0328 23:51:24 @monitor.py:363][0m QueueInput/queue_size: 0.6548
[32m[0328 23:51:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.077
[32m[0328 23:51:24 @monitor.py:363][0m activation-summaries/output-rms: 0.035083
[32m[0328 23:51:24 @monitor.py:363][0m cross_entropy_loss: 2.487
[32m[0328 23:51:24 @monitor.py:363][0m lr: 7.4506e-12
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0328 23:51:24 @monitor.py:363][0m train-error-top1: 0.62583
[32m[0328 23:51:24 @monitor.py:363][0m val-error-top1: 0.61282
[32m[0328 23:51:24 @monitor.py:363][0m val-utt-error: 0.23138
[32m[0328 23:51:24 @monitor.py:363][0m validation_cost: 2.4752
[32m[0328 23:51:24 @monitor.py:363][0m wd_cost: 5.3462e-18
[32m[0328 23:51:24 @group.py:42][0m Callbacks took 123.711 sec in total. InferenceRunner: 123.263sec
[32m[0328 23:51:24 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13262/173481[03:00<36:15,73.66it/s]  8%|7         |13875/173481[03:10<36:06,73.66it/s] 14%|#3        |24137/173481[06:00<37:29,66.38it/s] 14%|#4        |24789/173481[06:10<37:20,66.38it/s] 21%|##        |35757/173481[09:00<35:04,65.45it/s] 21%|##1       |36439/173481[09:10<34:53,65.45it/s] 27%|##7       |46874/173481[12:00<33:12,63.55it/s] 27%|##7       |47493/173481[12:10<33:02,63.55it/s] 33%|###3      |58022/173481[15:00<30:40,62.72it/s] 34%|###3      |58681/173481[15:10<30:30,62.72it/s] 40%|###9      |69272/173481[18:00<27:44,62.61it/s] 40%|####      |69931/173481[18:11<27:33,62.61it/s] 46%|####6     |80202/173481[21:00<25:13,61.65it/s] 47%|####6     |80861/173481[21:11<25:02,61.65it/s] 53%|#####2    |91142/173481[24:00<22:25,61.20it/s] 53%|#####2    |91788/173481[24:11<22:14,61.20it/s] 59%|#####8    |101953/173481[27:00<19:39,60.63it/s] 59%|#####9    |102643/173481[27:11<19:28,60.63it/s] 65%|######4   |112607/173481[30:00<16:56,59.90it/s] 65%|######5   |113283/173481[30:11<16:45,59.90it/s] 71%|#######1  |123272/173481[33:00<14:02,59.57it/s] 71%|#######1  |123994/173481[33:11<13:50,59.57it/s] 77%|#######7  |134147/173481[36:00<10:55,59.98it/s] 78%|#######7  |134876/173481[36:11<10:43,59.98it/s] 84%|########3 |145050/173481[39:00<07:51,60.28it/s] 84%|########4 |145771/173481[39:12<07:39,60.28it/s] 90%|########9 |156039/173481[42:00<04:47,60.66it/s] 90%|######### |156780/173481[42:12<04:35,60.66it/s] 96%|#########6|166937/173481[45:00<01:47,60.60it/s] 97%|#########6|167686/173481[45:12<01:35,60.60it/s]100%|##########|173481/173481[46:51<00:00,61.71it/s]
[32m[0329 00:38:15 @base.py:257][0m Epoch 15 (global_step 13011075) finished, time:2811.05 sec.
[32m[0329 00:38:15 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-13011075.
[32m[0329 00:38:15 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.72it/s]
14
[32m[0329 00:40:20 @monitor.py:363][0m QueueInput/queue_size: 1.2192
[32m[0329 00:40:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.221
[32m[0329 00:40:20 @monitor.py:363][0m activation-summaries/output-rms: 0.036921
[32m[0329 00:40:20 @monitor.py:363][0m cross_entropy_loss: 2.4312
[32m[0329 00:40:20 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 00:40:20 @monitor.py:363][0m train-error-top1: 0.61233
[32m[0329 00:40:20 @monitor.py:363][0m val-error-top1: 0.61285
[32m[0329 00:40:20 @monitor.py:363][0m val-utt-error: 0.23462
[32m[0329 00:40:20 @monitor.py:363][0m validation_cost: 2.4734
[32m[0329 00:40:20 @monitor.py:363][0m wd_cost: 1.0692e-18
[32m[0329 00:40:20 @group.py:42][0m Callbacks took 124.731 sec in total. InferenceRunner: 124.071sec
[32m[0329 00:40:20 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13467/173481[03:00<35:38,74.82it/s]  8%|8         |14074/173481[03:10<35:30,74.82it/s] 14%|#3        |24274/173481[06:00<37:19,66.62it/s] 14%|#4        |24900/173481[06:10<37:10,66.62it/s] 20%|##        |34870/173481[09:00<36:57,62.50it/s] 20%|##        |35488/173481[09:10<36:47,62.50it/s] 26%|##6       |45286/173481[12:00<35:33,60.08it/s] 26%|##6       |45880/173481[12:10<35:23,60.08it/s] 32%|###2      |55536/173481[15:00<33:37,58.46it/s] 32%|###2      |56180/173481[15:10<33:26,58.46it/s] 38%|###8      |66236/173481[18:00<30:19,58.94it/s] 39%|###8      |66915/173481[18:11<30:07,58.94it/s] 44%|####4     |76495/173481[21:00<27:53,57.95it/s] 44%|####4     |77130/173481[21:11<27:42,57.95it/s] 50%|#####     |87075/173481[24:00<24:40,58.36it/s] 51%|#####     |87755/173481[24:11<24:28,58.36it/s] 56%|#####6    |97618/173481[27:00<21:37,58.47it/s] 57%|#####6    |98283/173481[27:11<21:26,58.47it/s] 62%|######2   |108107/173481[30:00<18:40,58.37it/s] 63%|######2   |108770/173481[30:11<18:28,58.37it/s] 69%|######8   |118854/173481[33:00<15:25,59.03it/s] 69%|######8   |119580/173481[33:11<15:13,59.03it/s] 75%|#######4  |129666/173481[36:00<12:15,59.54it/s] 75%|#######5  |130364/173481[36:12<12:04,59.54it/s] 81%|########1 |140556/173481[39:00<09:08,60.01it/s] 81%|########1 |141320/173481[39:12<08:55,60.01it/s] 87%|########7 |151311/173481[42:00<06:10,59.87it/s] 88%|########7 |152023/173481[42:12<05:58,59.87it/s] 93%|#########3|161581/173481[45:00<03:23,58.43it/s] 94%|#########3|162280/173481[45:12<03:11,58.43it/s] 99%|#########9|171921/173481[48:00<00:26,57.93it/s]100%|#########9|172630/173481[48:12<00:14,57.93it/s]100%|##########|173481/173481[48:27<00:00,59.67it/s]
[32m[0329 01:28:47 @base.py:257][0m Epoch 16 (global_step 13184556) finished, time:2907.16 sec.
[32m[0329 01:28:47 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.22it/s]
15
[32m[0329 01:30:53 @monitor.py:363][0m QueueInput/queue_size: 0.49067
[32m[0329 01:30:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.078
[32m[0329 01:30:53 @monitor.py:363][0m activation-summaries/output-rms: 0.034984
[32m[0329 01:30:53 @monitor.py:363][0m cross_entropy_loss: 2.4052
[32m[0329 01:30:53 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 01:30:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 01:30:53 @monitor.py:363][0m train-error-top1: 0.61566
[32m[0329 01:30:53 @monitor.py:363][0m val-error-top1: 0.6132
[32m[0329 01:30:53 @monitor.py:363][0m val-utt-error: 0.23271
[32m[0329 01:30:53 @monitor.py:363][0m validation_cost: 2.4751
[32m[0329 01:30:53 @monitor.py:363][0m wd_cost: 1.0692e-18
[32m[0329 01:30:53 @group.py:42][0m Callbacks took 125.732 sec in total. InferenceRunner: 125.305sec
[32m[0329 01:30:53 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13014/173481[03:00<36:59,72.30it/s]  8%|7         |13620/173481[03:10<36:51,72.30it/s] 14%|#3        |23550/173481[06:00<38:37,64.68it/s] 14%|#3        |24142/173481[06:10<38:28,64.68it/s] 19%|#9        |33680/173481[09:00<38:42,60.18it/s] 20%|#9        |34254/173481[09:10<38:33,60.18it/s] 25%|##4       |43245/173481[12:00<38:28,56.43it/s] 25%|##5       |43819/173481[12:10<38:17,56.43it/s] 31%|###       |53210/173481[15:00<35:52,55.89it/s] 31%|###1      |53832/173481[15:10<35:40,55.89it/s] 37%|###6      |63535/173481[18:00<32:22,56.61it/s] 37%|###6      |64104/173481[18:11<32:12,56.61it/s] 43%|####2     |74030/173481[21:00<28:51,57.45it/s] 43%|####3     |74695/173481[21:11<28:39,57.45it/s] 49%|####8     |84590/173481[24:00<25:31,58.04it/s] 49%|####9     |85215/173481[24:11<25:20,58.04it/s] 55%|#####4    |95173/173481[27:00<22:20,58.42it/s] 55%|#####5    |95838/173481[27:11<22:09,58.42it/s] 61%|######    |105597/173481[30:00<19:27,58.16it/s] 61%|######1   |106284/173481[30:11<19:15,58.16it/s] 67%|######6   |116102/173481[33:00<16:24,58.26it/s] 67%|######7   |116761/173481[33:11<16:13,58.26it/s] 73%|#######2  |126628/173481[36:00<13:22,58.37it/s] 73%|#######3  |127319/173481[36:12<13:10,58.37it/s] 79%|#######9  |137240/173481[39:00<10:17,58.66it/s] 80%|#######9  |137944/173481[39:12<10:05,58.66it/s] 85%|########5 |147829/173481[42:00<07:16,58.74it/s] 86%|########5 |148569/173481[42:12<07:04,58.74it/s] 92%|#########1|158795/173481[45:00<04:05,59.81it/s] 92%|#########1|159566/173481[45:12<03:52,59.81it/s] 98%|#########7|169899/173481[48:00<00:58,60.73it/s] 98%|#########8|170650/173481[48:12<00:46,60.73it/s]100%|##########|173481/173481[48:57<00:00,59.05it/s]
[32m[0329 02:19:50 @base.py:257][0m Epoch 17 (global_step 13358037) finished, time:2937.64 sec.
[32m[0329 02:19:50 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,159.45it/s]
16
[32m[0329 02:21:49 @monitor.py:363][0m QueueInput/queue_size: 1.3062
[32m[0329 02:21:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.225
[32m[0329 02:21:49 @monitor.py:363][0m activation-summaries/output-rms: 0.034539
[32m[0329 02:21:49 @monitor.py:363][0m cross_entropy_loss: 2.4997
[32m[0329 02:21:49 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 02:21:49 @monitor.py:363][0m train-error-top1: 0.61994
[32m[0329 02:21:49 @monitor.py:363][0m val-error-top1: 0.61502
[32m[0329 02:21:49 @monitor.py:363][0m val-utt-error: 0.23441
[32m[0329 02:21:49 @monitor.py:363][0m validation_cost: 2.4874
[32m[0329 02:21:49 @monitor.py:363][0m wd_cost: 1.0692e-18
[32m[0329 02:21:49 @group.py:42][0m Callbacks took 118.419 sec in total. InferenceRunner: 118.052sec
[32m[0329 02:21:49 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15000/173481[03:00<31:41,83.33it/s]  9%|9         |15649/173481[03:10<31:34,83.33it/s] 15%|#4        |25994/173481[06:00<34:52,70.48it/s] 15%|#5        |26614/173481[06:10<34:43,70.48it/s] 21%|##        |36359/173481[09:00<36:03,63.37it/s] 21%|##1       |36973/173481[09:10<35:54,63.37it/s] 27%|##7       |47445/173481[12:00<33:37,62.46it/s] 28%|##7       |48111/173481[12:10<33:27,62.46it/s] 33%|###3      |58089/173481[15:00<31:39,60.75it/s] 34%|###3      |58756/173481[15:10<31:28,60.75it/s] 40%|###9      |69261/173481[18:00<28:17,61.40it/s] 40%|####      |69964/173481[18:10<28:05,61.40it/s] 47%|####6     |81190/173481[21:00<24:07,63.74it/s] 47%|####7     |81834/173481[21:11<23:57,63.74it/s] 53%|#####3    |92009/173481[24:00<21:57,61.86it/s] 53%|#####3    |92653/173481[24:11<21:46,61.86it/s] 59%|#####9    |102554/173481[27:00<19:38,60.17it/s] 60%|#####9    |103242/173481[27:11<19:27,60.17it/s] 65%|######5   |113447/173481[30:00<16:34,60.34it/s] 66%|######5   |114123/173481[30:11<16:23,60.34it/s] 72%|#######1  |124366/173481[33:00<13:31,60.50it/s] 72%|#######2  |125055/173481[33:11<13:20,60.50it/s] 78%|#######8  |135340/173481[36:00<10:28,60.73it/s] 78%|#######8  |136078/173481[36:11<10:15,60.73it/s] 84%|########4 |146464/173481[39:00<07:21,61.26it/s] 85%|########4 |147188/173481[39:12<07:09,61.26it/s] 91%|######### |157588/173481[42:00<04:18,61.53it/s] 91%|#########1|158318/173481[42:12<04:06,61.53it/s] 97%|#########7|168869/173481[45:00<01:14,62.09it/s] 98%|#########7|169600/173481[45:12<01:02,62.09it/s]100%|##########|173481/173481[46:16<00:00,62.49it/s]
[32m[0329 03:08:05 @base.py:257][0m Epoch 18 (global_step 13531518) finished, time:2776.23 sec.
[32m[0329 03:08:05 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-13531518.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.52it/s]
17
[32m[0329 03:10:09 @monitor.py:363][0m QueueInput/queue_size: 0.70334
[32m[0329 03:10:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.199
[32m[0329 03:10:09 @monitor.py:363][0m activation-summaries/output-rms: 0.035027
[32m[0329 03:10:09 @monitor.py:363][0m cross_entropy_loss: 2.4395
[32m[0329 03:10:09 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 03:10:09 @monitor.py:363][0m train-error-top1: 0.61618
[32m[0329 03:10:09 @monitor.py:363][0m val-error-top1: 0.61467
[32m[0329 03:10:09 @monitor.py:363][0m val-utt-error: 0.23324
[32m[0329 03:10:09 @monitor.py:363][0m validation_cost: 2.4832
[32m[0329 03:10:09 @monitor.py:363][0m wd_cost: 2.1385e-19
[32m[0329 03:10:09 @group.py:42][0m Callbacks took 124.551 sec in total. InferenceRunner: 124.233sec
[32m[0329 03:10:09 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13853/173481[03:00<34:34,76.94it/s]  8%|8         |14495/173481[03:10<34:26,76.94it/s] 14%|#4        |24294/173481[06:00<37:35,66.14it/s] 14%|#4        |24864/173481[06:10<37:26,66.14it/s] 20%|##        |35138/173481[09:00<36:34,63.05it/s] 21%|##        |35777/173481[09:10<36:24,63.05it/s] 27%|##6       |46387/173481[12:00<33:44,62.77it/s] 27%|##7       |47052/173481[12:10<33:34,62.77it/s] 33%|###3      |57404/173481[15:00<31:12,61.98it/s] 33%|###3      |58047/173481[15:10<31:02,61.98it/s] 39%|###9      |68448/173481[18:00<28:23,61.66it/s] 40%|###9      |69138/173481[18:10<28:12,61.66it/s] 46%|####5     |79409/173481[21:00<25:35,61.27it/s] 46%|####6     |80050/173481[21:11<25:24,61.27it/s] 52%|#####1    |90184/173481[24:00<22:55,60.56it/s] 52%|#####2    |90828/173481[24:11<22:44,60.56it/s] 58%|#####8    |101304/173481[27:00<19:40,61.16it/s] 59%|#####8    |101967/173481[27:11<19:29,61.16it/s] 65%|######4   |112140/173481[30:00<16:50,60.68it/s] 65%|######5   |112807/173481[30:11<16:39,60.68it/s] 71%|#######   |122863/173481[33:00<14:01,60.12it/s] 71%|#######1  |123513/173481[33:11<13:51,60.12it/s] 77%|#######6  |133463/173481[36:00<11:12,59.50it/s] 77%|#######7  |134177/173481[36:11<11:00,59.50it/s] 83%|########3 |144387/173481[39:00<08:04,60.09it/s] 84%|########3 |145137/173481[39:11<07:51,60.09it/s] 90%|########9 |155438/173481[42:00<04:57,60.73it/s] 90%|######### |156140/173481[42:12<04:45,60.73it/s] 96%|#########5|166307/173481[45:00<01:58,60.56it/s] 96%|#########6|166983/173481[45:12<01:47,60.56it/s]100%|##########|173481/173481[47:05<00:00,61.41it/s]
[32m[0329 03:57:15 @base.py:257][0m Epoch 19 (global_step 13704999) finished, time:2825.18 sec.
[32m[0329 03:57:15 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-13704999.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.37it/s]
18
[32m[0329 03:59:20 @monitor.py:363][0m QueueInput/queue_size: 0.62546
[32m[0329 03:59:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.077
[32m[0329 03:59:20 @monitor.py:363][0m activation-summaries/output-rms: 0.03508
[32m[0329 03:59:20 @monitor.py:363][0m cross_entropy_loss: 2.4867
[32m[0329 03:59:20 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 03:59:20 @monitor.py:363][0m train-error-top1: 0.6253
[32m[0329 03:59:20 @monitor.py:363][0m val-error-top1: 0.61295
[32m[0329 03:59:20 @monitor.py:363][0m val-utt-error: 0.2317
[32m[0329 03:59:20 @monitor.py:363][0m validation_cost: 2.4758
[32m[0329 03:59:20 @monitor.py:363][0m wd_cost: 2.1385e-19
[32m[0329 03:59:20 @group.py:42][0m Callbacks took 125.539 sec in total. InferenceRunner: 125.182sec
[32m[0329 03:59:20 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13172/173481[03:00<36:31,73.16it/s]  8%|7         |13776/173481[03:10<36:22,73.16it/s] 14%|#3        |23757/173481[06:00<38:16,65.20it/s] 14%|#4        |24390/173481[06:10<38:06,65.20it/s] 20%|##        |35157/173481[09:00<35:52,64.25it/s] 21%|##        |35820/173481[09:10<35:42,64.25it/s] 27%|##6       |46412/173481[12:00<33:25,63.37it/s] 27%|##7       |47016/173481[12:10<33:15,63.37it/s] 33%|###3      |57529/173481[15:00<30:53,62.56it/s] 34%|###3      |58176/173481[15:10<30:43,62.56it/s] 40%|###9      |68584/173481[18:00<28:12,61.98it/s] 40%|###9      |69247/173481[18:11<28:01,61.98it/s] 46%|####5     |79570/173481[21:00<25:26,61.50it/s] 46%|####6     |80269/173481[21:11<25:15,61.50it/s] 52%|#####2    |90613/173481[24:00<22:29,61.42it/s] 53%|#####2    |91286/173481[24:11<22:18,61.42it/s] 59%|#####8    |101577/173481[27:00<19:35,61.16it/s] 59%|#####8    |102277/173481[27:11<19:24,61.16it/s] 65%|######4   |112532/173481[30:00<16:39,61.01it/s] 65%|######5   |113226/173481[30:11<16:27,61.01it/s] 71%|#######1  |123350/173481[33:00<13:47,60.55it/s] 72%|#######1  |124064/173481[33:11<13:36,60.55it/s] 77%|#######7  |134188/173481[36:00<10:50,60.38it/s] 78%|#######7  |134893/173481[36:12<10:39,60.38it/s] 84%|########3 |144862/173481[39:00<07:58,59.82it/s] 84%|########3 |145586/173481[39:12<07:46,59.82it/s] 90%|########9 |156055/173481[42:00<04:45,60.98it/s] 90%|######### |156849/173481[42:12<04:32,60.98it/s] 97%|#########6|168019/173481[45:00<01:25,63.60it/s] 97%|#########7|168911/173481[45:12<01:11,63.60it/s]100%|##########|173481/173481[46:15<00:00,62.51it/s]
[32m[0329 04:45:35 @base.py:257][0m Epoch 20 (global_step 13878480) finished, time:2775.04 sec.
[32m[0329 04:45:35 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-13878480.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.85it/s]
19
[32m[0329 04:47:40 @monitor.py:363][0m QueueInput/queue_size: 0.91694
[32m[0329 04:47:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.224
[32m[0329 04:47:40 @monitor.py:363][0m activation-summaries/output-rms: 0.036898
[32m[0329 04:47:40 @monitor.py:363][0m cross_entropy_loss: 2.4227
[32m[0329 04:47:40 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 04:47:40 @monitor.py:363][0m train-error-top1: 0.61008
[32m[0329 04:47:40 @monitor.py:363][0m val-error-top1: 0.61406
[32m[0329 04:47:40 @monitor.py:363][0m val-utt-error: 0.23611
[32m[0329 04:47:40 @monitor.py:363][0m validation_cost: 2.4802
[32m[0329 04:47:40 @monitor.py:363][0m wd_cost: 2.1385e-19
[32m[0329 04:47:40 @group.py:42][0m Callbacks took 125.163 sec in total. InferenceRunner: 124.801sec
[32m[0329 04:47:40 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16368/173481[03:00<28:47,90.93it/s] 10%|9         |17293/173481[03:10<28:37,90.93it/s] 17%|#6        |28996/173481[06:00<30:24,79.19it/s] 17%|#7        |29585/173481[06:10<30:17,79.19it/s] 23%|##2       |39386/173481[09:00<33:28,66.76it/s] 23%|##3       |39993/173481[09:10<33:19,66.76it/s] 29%|##8       |50001/173481[12:00<32:51,62.63it/s] 29%|##9       |50614/173481[12:10<32:41,62.63it/s] 35%|###5      |60776/173481[15:00<30:41,61.21it/s] 35%|###5      |61412/173481[15:10<30:30,61.21it/s] 41%|####1     |71266/173481[18:00<28:32,59.70it/s] 41%|####1     |71879/173481[18:11<28:21,59.70it/s] 47%|####7     |81690/173481[21:00<26:01,58.79it/s] 47%|####7     |82338/173481[21:11<25:50,58.79it/s] 53%|#####3    |92236/173481[24:00<23:04,58.68it/s] 54%|#####3    |92882/173481[24:11<22:53,58.68it/s] 59%|#####9    |102686/173481[27:00<20:12,58.36it/s] 60%|#####9    |103324/173481[27:11<20:02,58.36it/s] 65%|######5   |113241/173481[30:00<17:09,58.50it/s] 66%|######5   |113905/173481[30:11<16:58,58.50it/s] 71%|#######1  |123915/173481[33:00<14:01,58.89it/s] 72%|#######1  |124655/173481[33:11<13:49,58.89it/s] 78%|#######7  |134873/173481[36:00<10:44,59.87it/s] 78%|#######8  |135611/173481[36:11<10:32,59.87it/s] 85%|########5 |148303/173481[39:00<06:19,66.43it/s] 86%|########6 |149331/173481[39:12<06:03,66.43it/s] 95%|#########4|164049/173481[42:00<02:04,75.51it/s] 95%|#########5|165071/173481[42:12<01:51,75.51it/s]100%|##########|173481/173481[43:47<00:00,66.03it/s]
[32m[0329 05:31:27 @base.py:257][0m Epoch 21 (global_step 14051961) finished, time:2627.11 sec.
[32m[0329 05:31:28 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-14051961.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.17it/s]
20
[32m[0329 05:33:32 @monitor.py:363][0m QueueInput/queue_size: 49.866
[32m[0329 05:33:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.055
[32m[0329 05:33:32 @monitor.py:363][0m activation-summaries/output-rms: 0.035547
[32m[0329 05:33:32 @monitor.py:363][0m cross_entropy_loss: 2.4227
[32m[0329 05:33:32 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 05:33:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 05:33:32 @monitor.py:363][0m train-error-top1: 0.60922
[32m[0329 05:33:32 @monitor.py:363][0m val-error-top1: 0.61302
[32m[0329 05:33:32 @monitor.py:363][0m val-utt-error: 0.23356
[32m[0329 05:33:32 @monitor.py:363][0m validation_cost: 2.4742
[32m[0329 05:33:32 @monitor.py:363][0m wd_cost: 4.277e-20
[32m[0329 05:33:32 @group.py:42][0m Callbacks took 124.868 sec in total. InferenceRunner: 124.521sec
[32m[0329 05:33:32 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14424/173481[03:00<33:04,80.13it/s]  9%|8         |15044/173481[03:10<32:57,80.13it/s] 15%|#4        |25228/173481[06:00<36:00,68.63it/s] 15%|#4        |25834/173481[06:10<35:51,68.63it/s] 20%|##        |35315/173481[09:00<37:19,61.70it/s] 21%|##        |35872/173481[09:10<37:10,61.70it/s] 26%|##5       |45065/173481[12:00<37:06,57.68it/s] 26%|##6       |45665/173481[12:10<36:56,57.68it/s] 32%|###1      |55195/173481[15:00<34:36,56.96it/s] 32%|###2      |55819/173481[15:10<34:25,56.96it/s] 38%|###7      |65600/173481[18:00<31:20,57.38it/s] 38%|###8      |66252/173481[18:11<31:08,57.38it/s] 44%|####3     |76322/173481[21:00<27:42,58.45it/s] 44%|####4     |76951/173481[21:11<27:31,58.45it/s] 50%|#####     |86905/173481[24:00<24:37,58.62it/s] 50%|#####     |87560/173481[24:11<24:25,58.62it/s] 56%|#####6    |97582/173481[27:00<21:27,58.96it/s] 57%|#####6    |98234/173481[27:11<21:16,58.96it/s] 62%|######2   |108175/173481[30:00<18:28,58.90it/s] 63%|######2   |108849/173481[30:11<18:17,58.90it/s] 68%|######8   |118570/173481[33:00<15:41,58.30it/s] 69%|######8   |119201/173481[33:11<15:30,58.30it/s] 74%|#######4  |128920/173481[36:00<12:49,57.89it/s] 75%|#######4  |129584/173481[36:11<12:38,57.89it/s] 80%|########  |139434/173481[39:00<09:45,58.15it/s] 81%|########  |140135/173481[39:12<09:33,58.15it/s] 87%|########6 |150126/173481[42:00<06:37,58.77it/s] 87%|########6 |150839/173481[42:12<06:25,58.77it/s] 93%|#########2|160793/173481[45:00<03:35,59.01it/s] 93%|#########3|161514/173481[45:12<03:22,59.01it/s] 99%|#########8|171425/173481[48:00<00:34,59.04it/s] 99%|#########9|172129/173481[48:12<00:22,59.04it/s]100%|##########|173481/173481[48:33<00:00,59.54it/s]
[32m[0329 06:22:06 @base.py:257][0m Epoch 22 (global_step 14225442) finished, time:2913.74 sec.
[32m[0329 06:22:06 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-14225442.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.88it/s]
21
[32m[0329 06:24:11 @monitor.py:363][0m QueueInput/queue_size: 1.9327
[32m[0329 06:24:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.225
[32m[0329 06:24:11 @monitor.py:363][0m activation-summaries/output-rms: 0.034548
[32m[0329 06:24:11 @monitor.py:363][0m cross_entropy_loss: 2.5005
[32m[0329 06:24:11 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 06:24:11 @monitor.py:363][0m train-error-top1: 0.61991
[32m[0329 06:24:11 @monitor.py:363][0m val-error-top1: 0.61475
[32m[0329 06:24:11 @monitor.py:363][0m val-utt-error: 0.2335
[32m[0329 06:24:11 @monitor.py:363][0m validation_cost: 2.485
[32m[0329 06:24:11 @monitor.py:363][0m wd_cost: 4.277e-20
[32m[0329 06:24:11 @group.py:42][0m Callbacks took 125.127 sec in total. InferenceRunner: 124.786sec
[32m[0329 06:24:11 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15319/173481[03:00<30:58,85.10it/s]  9%|9         |15958/173481[03:10<30:50,85.10it/s] 15%|#5        |26225/173481[06:00<34:40,70.78it/s] 15%|#5        |26814/173481[06:10<34:32,70.78it/s] 21%|##1       |36681/173481[09:00<35:43,63.81it/s] 21%|##1       |37260/173481[09:10<35:34,63.81it/s] 28%|##7       |47918/173481[12:00<33:09,63.11it/s] 28%|##8       |48663/173481[12:10<32:57,63.11it/s] 34%|###3      |58882/173481[15:00<30:48,61.99it/s] 34%|###4      |59553/173481[15:10<30:37,61.99it/s] 40%|####      |70063/173481[18:00<27:46,62.05it/s] 41%|####      |70857/173481[18:11<27:33,62.05it/s] 47%|####7     |81903/173481[21:00<23:54,63.86it/s] 48%|####7     |82522/173481[21:11<23:44,63.86it/s] 53%|#####3    |92679/173481[24:00<21:47,61.80it/s] 54%|#####3    |93359/173481[24:11<21:36,61.80it/s] 60%|#####9    |103318/173481[27:00<19:21,60.42it/s] 60%|#####9    |103973/173481[27:11<19:10,60.42it/s] 66%|######5   |114359/173481[30:00<16:11,60.87it/s] 66%|######6   |115097/173481[30:11<15:59,60.87it/s] 72%|#######2  |125369/173481[33:00<13:08,61.02it/s] 73%|#######2  |126062/173481[33:11<12:57,61.02it/s] 79%|#######8  |136526/173481[36:00<10:00,61.50it/s] 79%|#######9  |137258/173481[36:12<09:49,61.50it/s] 85%|########5 |147728/173481[39:00<06:56,61.86it/s] 86%|########5 |148458/173481[39:12<06:44,61.86it/s] 92%|#########1|158872/173481[42:00<03:56,61.89it/s] 92%|#########2|159642/173481[42:12<03:43,61.89it/s] 98%|#########7|170003/173481[45:00<00:56,61.86it/s] 98%|#########8|170773/173481[45:12<00:43,61.86it/s]100%|##########|173481/173481[45:57<00:00,62.92it/s]
[32m[0329 07:10:08 @base.py:257][0m Epoch 23 (global_step 14398923) finished, time:2757.14 sec.
[32m[0329 07:10:09 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-14398923.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.39it/s]
22
[32m[0329 07:12:14 @monitor.py:363][0m QueueInput/queue_size: 0.96411
[32m[0329 07:12:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.197
[32m[0329 07:12:14 @monitor.py:363][0m activation-summaries/output-rms: 0.035013
[32m[0329 07:12:14 @monitor.py:363][0m cross_entropy_loss: 2.439
[32m[0329 07:12:14 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 07:12:14 @monitor.py:363][0m train-error-top1: 0.61512
[32m[0329 07:12:14 @monitor.py:363][0m val-error-top1: 0.61458
[32m[0329 07:12:14 @monitor.py:363][0m val-utt-error: 0.23361
[32m[0329 07:12:14 @monitor.py:363][0m validation_cost: 2.4824
[32m[0329 07:12:14 @monitor.py:363][0m wd_cost: 4.277e-20
[32m[0329 07:12:14 @group.py:42][0m Callbacks took 125.440 sec in total. InferenceRunner: 125.170sec
[32m[0329 07:12:14 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13638/173481[03:00<35:09,75.76it/s]  8%|8         |14253/173481[03:10<35:01,75.76it/s] 14%|#3        |24028/173481[06:00<38:01,65.52it/s] 14%|#4        |24622/173481[06:10<37:52,65.52it/s] 20%|##        |34804/173481[09:00<36:56,62.56it/s] 20%|##        |35416/173481[09:10<36:46,62.56it/s] 26%|##6       |45940/173481[12:00<34:10,62.21it/s] 27%|##6       |46569/173481[12:10<33:59,62.21it/s] 33%|###2      |56897/173481[15:00<31:34,61.53it/s] 33%|###3      |57537/173481[15:10<31:24,61.53it/s] 39%|###9      |67708/173481[18:00<29:00,60.79it/s] 39%|###9      |68344/173481[18:10<28:49,60.79it/s] 45%|####5     |78584/173481[21:00<26:05,60.60it/s] 46%|####5     |79265/173481[21:11<25:54,60.60it/s] 52%|#####1    |89473/173481[24:00<23:07,60.54it/s] 52%|#####1    |90153/173481[24:11<22:56,60.54it/s] 58%|#####7    |100423/173481[27:00<20:03,60.68it/s] 58%|#####8    |101110/173481[27:11<19:52,60.68it/s] 64%|######4   |111398/173481[30:00<17:00,60.82it/s] 65%|######4   |112135/173481[30:11<16:48,60.82it/s] 71%|#######   |122408/173481[33:00<13:57,60.99it/s] 71%|#######   |123097/173481[33:11<13:46,60.99it/s] 77%|#######6  |133208/173481[36:00<11:05,60.48it/s] 77%|#######7  |133927/173481[36:11<10:53,60.48it/s] 83%|########3 |144143/173481[39:00<08:04,60.61it/s] 84%|########3 |144857/173481[39:12<07:52,60.61it/s] 90%|########9 |155283/173481[42:00<04:57,61.24it/s] 90%|########9 |156018/173481[42:12<04:45,61.24it/s] 96%|#########5|166493/173481[45:00<01:53,61.74it/s] 96%|#########6|167190/173481[45:12<01:41,61.74it/s]100%|##########|173481/173481[46:58<00:00,61.55it/s]
[32m[0329 07:59:12 @base.py:257][0m Epoch 24 (global_step 14572404) finished, time:2818.50 sec.
[32m[0329 07:59:13 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-14572404.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.66it/s]
23
[32m[0329 08:01:17 @monitor.py:363][0m QueueInput/queue_size: 0.683
[32m[0329 08:01:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.073
[32m[0329 08:01:17 @monitor.py:363][0m activation-summaries/output-rms: 0.035094
[32m[0329 08:01:17 @monitor.py:363][0m cross_entropy_loss: 2.4864
[32m[0329 08:01:17 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 08:01:17 @monitor.py:363][0m train-error-top1: 0.62639
[32m[0329 08:01:17 @monitor.py:363][0m val-error-top1: 0.61314
[32m[0329 08:01:17 @monitor.py:363][0m val-utt-error: 0.23218
[32m[0329 08:01:17 @monitor.py:363][0m validation_cost: 2.4769
[32m[0329 08:01:17 @monitor.py:363][0m wd_cost: 8.5539e-21
[32m[0329 08:01:17 @group.py:42][0m Callbacks took 124.393 sec in total. InferenceRunner: 124.126sec
[32m[0329 08:01:17 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13192/173481[03:00<36:27,73.28it/s]  8%|7         |13796/173481[03:10<36:19,73.28it/s] 14%|#3        |23702/173481[06:00<38:24,64.99it/s] 14%|#4        |24326/173481[06:10<38:14,64.99it/s] 20%|##        |34907/173481[09:00<36:19,63.59it/s] 20%|##        |35552/173481[09:10<36:09,63.59it/s] 26%|##6       |45909/173481[12:00<34:06,62.33it/s] 27%|##6       |46554/173481[12:10<33:56,62.33it/s] 33%|###2      |57111/173481[15:00<31:08,62.28it/s] 33%|###3      |57761/173481[15:10<30:58,62.28it/s] 39%|###9      |68113/173481[18:00<28:27,61.70it/s] 40%|###9      |68771/173481[18:10<28:17,61.70it/s] 45%|####5     |78826/173481[21:00<26:02,60.58it/s] 46%|####5     |79518/173481[21:11<25:50,60.58it/s] 53%|#####2    |91388/173481[24:00<21:05,64.86it/s] 53%|#####3    |92355/173481[24:11<20:50,64.86it/s] 60%|######    |104191/173481[27:00<17:01,67.85it/s] 60%|######    |104836/173481[27:11<16:51,67.85it/s] 66%|######6   |114899/173481[30:00<15:24,63.39it/s] 67%|######6   |115566/173481[30:11<15:13,63.39it/s] 72%|#######2  |125539/173481[33:00<13:03,61.18it/s] 73%|#######2  |126224/173481[33:11<12:52,61.18it/s] 79%|#######9  |137489/173481[36:00<09:25,63.68it/s] 80%|#######9  |138403/173481[36:11<09:10,63.68it/s] 88%|########8 |152808/173481[39:00<04:43,72.85it/s] 89%|########8 |153871/173481[39:12<04:29,72.85it/s] 97%|#########7|168644/173481[42:00<01:00,79.70it/s] 98%|#########7|169691/173481[42:12<00:47,79.70it/s]100%|##########|173481/173481[43:09<00:00,66.98it/s]
[32m[0329 08:44:27 @base.py:257][0m Epoch 25 (global_step 14745885) finished, time:2589.92 sec.
[32m[0329 08:44:27 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-14745885.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.34it/s]
24
[32m[0329 08:46:31 @monitor.py:363][0m QueueInput/queue_size: 0.86488
[32m[0329 08:46:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.222
[32m[0329 08:46:31 @monitor.py:363][0m activation-summaries/output-rms: 0.036888
[32m[0329 08:46:31 @monitor.py:363][0m cross_entropy_loss: 2.4226
[32m[0329 08:46:31 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 08:46:31 @monitor.py:363][0m train-error-top1: 0.61053
[32m[0329 08:46:31 @monitor.py:363][0m val-error-top1: 0.61382
[32m[0329 08:46:31 @monitor.py:363][0m val-utt-error: 0.23664
[32m[0329 08:46:31 @monitor.py:363][0m validation_cost: 2.48
[32m[0329 08:46:31 @monitor.py:363][0m wd_cost: 8.5539e-21
[32m[0329 08:46:31 @group.py:42][0m Callbacks took 124.703 sec in total. InferenceRunner: 124.380sec
[32m[0329 08:46:31 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13926/173481[03:00<34:22,77.36it/s]  8%|8         |14520/173481[03:10<34:14,77.36it/s] 14%|#4        |24891/173481[06:00<36:20,68.16it/s] 15%|#4        |25525/173481[06:10<36:10,68.16it/s] 21%|##        |35580/173481[09:00<36:12,63.46it/s] 21%|##        |36206/173481[09:10<36:03,63.46it/s] 27%|##6       |46206/173481[12:00<34:40,61.16it/s] 27%|##6       |46827/173481[12:10<34:30,61.16it/s] 33%|###2      |56693/173481[15:00<32:37,59.68it/s] 33%|###3      |57347/173481[15:10<32:26,59.68it/s] 39%|###9      |67671/173481[18:00<29:14,60.32it/s] 39%|###9      |68311/173481[18:11<29:03,60.32it/s] 45%|####4     |77990/173481[21:00<27:04,58.79it/s] 45%|####5     |78645/173481[21:11<26:53,58.79it/s] 51%|#####1    |88511/173481[24:00<24:09,58.61it/s] 51%|#####1    |89156/173481[24:11<23:58,58.61it/s] 57%|#####7    |98906/173481[27:00<21:22,58.17it/s] 57%|#####7    |99580/173481[27:11<21:10,58.17it/s] 63%|######2   |109276/173481[30:00<18:29,57.88it/s] 63%|######3   |109952/173481[30:11<18:17,57.88it/s] 69%|######9   |119847/173481[33:00<15:19,58.30it/s] 69%|######9   |120515/173481[33:11<15:08,58.30it/s] 75%|#######5  |130478/173481[36:00<12:12,58.68it/s] 76%|#######5  |131163/173481[36:12<12:01,58.68it/s] 81%|########1 |141172/173481[39:00<09:07,59.04it/s] 82%|########1 |141890/173481[39:12<08:55,59.04it/s] 87%|########7 |151541/173481[42:00<06:16,58.31it/s] 88%|########7 |152206/173481[42:12<06:04,58.31it/s] 93%|#########3|161881/173481[45:00<03:20,57.87it/s] 94%|#########3|162558/173481[45:12<03:08,57.87it/s] 99%|#########9|172171/173481[48:00<00:22,57.51it/s]100%|#########9|172884/173481[48:12<00:10,57.51it/s]100%|##########|173481/173481[48:23<00:00,59.74it/s]
[32m[0329 09:34:55 @base.py:257][0m Epoch 26 (global_step 14919366) finished, time:2903.75 sec.
[32m[0329 09:34:55 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-14919366.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.09it/s]
25
[32m[0329 09:37:00 @monitor.py:363][0m QueueInput/queue_size: 0.76524
[32m[0329 09:37:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.077
[32m[0329 09:37:00 @monitor.py:363][0m activation-summaries/output-rms: 0.034987
[32m[0329 09:37:00 @monitor.py:363][0m cross_entropy_loss: 2.405
[32m[0329 09:37:00 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 09:37:00 @monitor.py:363][0m train-error-top1: 0.61651
[32m[0329 09:37:00 @monitor.py:363][0m val-error-top1: 0.61288
[32m[0329 09:37:00 @monitor.py:363][0m val-utt-error: 0.23138
[32m[0329 09:37:00 @monitor.py:363][0m validation_cost: 2.4737
[32m[0329 09:37:00 @monitor.py:363][0m wd_cost: 1.7108e-21
[32m[0329 09:37:00 @group.py:42][0m Callbacks took 124.853 sec in total. InferenceRunner: 124.582sec
[32m[0329 09:37:00 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13150/173481[03:00<36:34,73.04it/s]  8%|7         |13794/173481[03:10<36:26,73.04it/s] 14%|#4        |24670/173481[06:00<36:21,68.22it/s] 15%|#4        |25269/173481[06:10<36:12,68.22it/s] 20%|##        |34855/173481[09:00<37:20,61.86it/s] 20%|##        |35409/173481[09:10<37:12,61.86it/s] 28%|##8       |48838/173481[12:00<30:09,68.87it/s] 29%|##8       |49819/173481[12:10<29:55,68.87it/s] 36%|###5      |61915/173481[15:00<26:18,70.70it/s] 36%|###6      |62553/173481[15:10<26:09,70.70it/s] 42%|####1     |72606/173481[18:00<26:02,64.55it/s] 42%|####2     |73274/173481[18:11<25:52,64.55it/s] 48%|####8     |83493/173481[21:00<24:00,62.45it/s] 49%|####8     |84180/173481[21:11<23:49,62.45it/s] 54%|#####4    |94145/173481[24:00<21:45,60.76it/s] 55%|#####4    |94784/173481[24:11<21:35,60.76it/s] 60%|######    |104667/173481[27:00<19:14,59.59it/s] 61%|######    |105344/173481[27:11<19:03,59.59it/s] 66%|######6   |115295/173481[30:00<16:20,59.31it/s] 67%|######6   |115959/173481[30:11<16:09,59.31it/s] 73%|#######2  |126160/173481[33:00<13:10,59.83it/s] 73%|#######3  |126959/173481[33:11<12:57,59.83it/s] 81%|########1 |141099/173481[36:00<07:45,69.53it/s] 82%|########1 |142083/173481[36:12<07:31,69.53it/s] 90%|######### |156964/173481[39:00<03:32,77.74it/s] 91%|#########1|158024/173481[39:12<03:18,77.74it/s]100%|#########9|172614/173481[42:00<00:10,82.08it/s]100%|##########|173481/173481[42:09<00:00,68.58it/s]
[32m[0329 10:19:10 @base.py:257][0m Epoch 27 (global_step 15092847) finished, time:2529.66 sec.
[32m[0329 10:19:10 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-15092847.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.49it/s]
26
[32m[0329 10:21:13 @monitor.py:363][0m QueueInput/queue_size: 49.979
[32m[0329 10:21:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.089
[32m[0329 10:21:13 @monitor.py:363][0m activation-summaries/output-rms: 0.036588
[32m[0329 10:21:13 @monitor.py:363][0m cross_entropy_loss: 2.5059
[32m[0329 10:21:13 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 10:21:13 @monitor.py:363][0m train-error-top1: 0.62376
[32m[0329 10:21:13 @monitor.py:363][0m val-error-top1: 0.61299
[32m[0329 10:21:13 @monitor.py:363][0m val-utt-error: 0.23329
[32m[0329 10:21:13 @monitor.py:363][0m validation_cost: 2.478
[32m[0329 10:21:13 @monitor.py:363][0m wd_cost: 1.7108e-21
[32m[0329 10:21:13 @group.py:42][0m Callbacks took 123.724 sec in total. InferenceRunner: 123.451sec
[32m[0329 10:21:13 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15012/173481[03:00<31:40,83.40it/s]  9%|9         |15913/173481[03:10<31:29,83.40it/s] 16%|#6        |27927/173481[06:00<31:26,77.14it/s] 16%|#6        |28507/173481[06:10<31:19,77.14it/s] 22%|##2       |38624/173481[09:00<33:28,67.13it/s] 23%|##2       |39225/173481[09:10<33:19,67.13it/s] 29%|##8       |50105/173481[12:00<31:26,65.41it/s] 29%|##9       |50756/173481[12:10<31:16,65.41it/s] 35%|###5      |60850/173481[15:00<30:04,62.42it/s] 35%|###5      |61483/173481[15:10<29:54,62.42it/s] 42%|####1     |72565/173481[18:00<26:23,63.72it/s] 42%|####2     |73223/173481[18:11<26:13,63.72it/s] 48%|####8     |84084/173481[21:00<23:20,63.85it/s] 49%|####8     |84749/173481[21:11<23:09,63.85it/s] 55%|#####4    |95054/173481[24:00<20:57,62.36it/s] 55%|#####5    |95720/173481[24:11<20:46,62.36it/s] 61%|######    |105768/173481[27:00<18:31,60.91it/s] 61%|######1   |106480/173481[27:11<18:20,60.91it/s] 67%|######7   |116899/173481[30:00<15:22,61.37it/s] 68%|######7   |117603/173481[30:11<15:10,61.37it/s] 74%|#######3  |127964/173481[33:00<12:21,61.42it/s] 74%|#######4  |128768/173481[33:11<12:08,61.42it/s] 80%|########  |139094/173481[36:00<09:18,61.62it/s] 81%|########  |139817/173481[36:12<09:06,61.62it/s] 86%|########6 |149929/173481[39:00<06:26,60.90it/s] 87%|########6 |150633/173481[39:12<06:15,60.90it/s] 93%|#########2|160855/173481[42:00<03:27,60.80it/s] 93%|#########3|161597/173481[42:12<03:15,60.80it/s] 99%|#########9|171941/173481[45:00<00:25,61.19it/s]100%|#########9|172723/173481[45:12<00:12,61.19it/s]100%|##########|173481/173481[45:25<00:00,63.65it/s]
[32m[0329 11:06:39 @base.py:257][0m Epoch 28 (global_step 15266328) finished, time:2725.57 sec.
[32m[0329 11:06:39 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-15266328.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.50it/s]
27
[32m[0329 11:08:38 @monitor.py:363][0m QueueInput/queue_size: 1.1421
[32m[0329 11:08:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.198
[32m[0329 11:08:38 @monitor.py:363][0m activation-summaries/output-rms: 0.035007
[32m[0329 11:08:38 @monitor.py:363][0m cross_entropy_loss: 2.4394
[32m[0329 11:08:38 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 11:08:38 @monitor.py:363][0m train-error-top1: 0.61539
[32m[0329 11:08:38 @monitor.py:363][0m val-error-top1: 0.61472
[32m[0329 11:08:38 @monitor.py:363][0m val-utt-error: 0.23382
[32m[0329 11:08:38 @monitor.py:363][0m validation_cost: 2.4842
[32m[0329 11:08:38 @monitor.py:363][0m wd_cost: 1.7108e-21
[32m[0329 11:08:38 @group.py:42][0m Callbacks took 119.177 sec in total. InferenceRunner: 118.758sec
[32m[0329 11:08:38 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13748/173481[03:00<34:51,76.37it/s]  8%|8         |14377/173481[03:10<34:43,76.37it/s] 14%|#3        |24106/173481[06:00<37:55,65.63it/s] 14%|#4        |24685/173481[06:10<37:47,65.63it/s] 20%|##        |34933/173481[09:00<36:47,62.76it/s] 20%|##        |35536/173481[09:10<36:37,62.76it/s] 26%|##6       |45808/173481[12:00<34:34,61.56it/s] 27%|##6       |46447/173481[12:10<34:23,61.56it/s] 33%|###2      |56468/173481[15:00<32:18,60.36it/s] 33%|###2      |57102/173481[15:10<32:08,60.36it/s] 39%|###8      |67313/173481[18:00<29:20,60.30it/s] 39%|###9      |67975/173481[18:11<29:09,60.30it/s] 45%|####4     |78042/173481[21:00<26:31,59.95it/s] 45%|####5     |78726/173481[21:11<26:20,59.95it/s] 51%|#####1    |88698/173481[24:00<23:43,59.57it/s] 52%|#####1    |89377/173481[24:11<23:31,59.57it/s] 57%|#####7    |99622/173481[27:00<20:28,60.12it/s] 58%|#####7    |100282/173481[27:11<20:17,60.12it/s] 64%|######3   |110503/173481[30:00<17:24,60.28it/s] 64%|######4   |111167/173481[30:11<17:13,60.28it/s] 70%|######9   |121274/173481[33:00<14:29,60.06it/s] 70%|#######   |121982/173481[33:11<14:17,60.06it/s] 76%|#######6  |132133/173481[36:00<11:26,60.19it/s] 77%|#######6  |132855/173481[36:12<11:14,60.19it/s] 82%|########2 |143097/173481[39:00<08:21,60.55it/s] 83%|########2 |143827/173481[39:12<08:09,60.55it/s] 89%|########8 |154180/173481[42:00<05:16,61.05it/s] 89%|########9 |154919/173481[42:12<05:04,61.05it/s] 95%|#########5|165278/173481[45:00<02:13,61.35it/s] 96%|#########5|166012/173481[45:12<02:01,61.35it/s]100%|##########|173481/173481[47:21<00:00,61.05it/s]
[32m[0329 11:56:00 @base.py:257][0m Epoch 29 (global_step 15439809) finished, time:2841.58 sec.
[32m[0329 11:56:00 @saver.py:84][0m Model saved to train_log/fcn1_w_4_a_32_quant_ends_True_preload/model-15439809.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.79it/s]
28
[32m[0329 11:58:05 @monitor.py:363][0m QueueInput/queue_size: 0.51665
[32m[0329 11:58:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.074
[32m[0329 11:58:05 @monitor.py:363][0m activation-summaries/output-rms: 0.035099
[32m[0329 11:58:05 @monitor.py:363][0m cross_entropy_loss: 2.4872
[32m[0329 11:58:05 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59721
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.267
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33113
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.092618
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41239
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091713
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36673
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088756
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35701
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.080759
[32m[0329 11:58:05 @monitor.py:363][0m train-error-top1: 0.62711
[32m[0329 11:58:05 @monitor.py:363][0m val-error-top1: 0.61273
[32m[0329 11:58:05 @monitor.py:363][0m val-utt-error: 0.23218
[32m[0329 11:58:05 @monitor.py:363][0m validation_cost: 2.4747
[32m[0329 11:58:05 @monitor.py:363][0m wd_cost: 3.4216e-22
[32m[0329 11:58:05 @group.py:42][0m Callbacks took 125.179 sec in total. InferenceRunner: 124.830sec
[32m[0329 11:58:05 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13316/173481[03:00<36:05,73.98it/s]  8%|8         |13914/173481[03:10<35:56,73.98it/s] 14%|#3        |23817/173481[06:00<38:14,65.23it/s] 14%|#4        |24435/173481[06:10<38:04,65.23it/s] 20%|##        |34865/173481[09:00<36:31,63.25it/s] 20%|##        |35495/173481[09:10<36:21,63.25it/s] 26%|##6       |45777/173481[12:00<34:23,61.90it/s] 27%|##6       |46435/173481[12:10<34:12,61.90it/s] 33%|###2      |56770/173481[15:00<31:38,61.48it/s] 33%|###3      |57426/173481[15:10<31:27,61.48it/s] 39%|###9      |67707/173481[18:00<28:50,61.12it/s] 39%|###9      |68371/173481[18:10<28:39,61.12it/s] 45%|####5     |78564/173481[21:00<26:03,60.71it/s] 46%|####5     |79256/173481[21:11<25:51,60.71it/s] 52%|#####1    |89667/173481[24:00<22:49,61.19it/s] 52%|#####2    |90376/173481[24:11<22:38,61.19it/s] 58%|#####7    |100472/173481[27:00<20:04,60.59it/s] 58%|#####8    |101161/173481[27:11<19:53,60.59it/s] 64%|######4   |111061/173481[30:00<17:25,59.69it/s] 64%|######4   |111737/173481[30:11<17:14,59.69it/s] 70%|#######   |121683/173481[33:00<14:32,59.35it/s] 71%|#######   |122356/173481[33:11<14:21,59.35it/s] 76%|#######6  |132321/173481[36:00<11:34,59.22it/s] 77%|#######6  |132996/173481[36:11<11:23,59.22it/s] 82%|########2 |142960/173481[39:00<08:35,59.16it/s] 83%|########2 |143676/173481[39:12<08:23,59.16it/s]slurmstepd: *** JOB 85141 ON sls-titan-10 CANCELLED AT 2018-03-29T12:39:05 ***
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 85141.0 ON sls-titan-10 CANCELLED AT 2018-03-29T12:39:05 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
