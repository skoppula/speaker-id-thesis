sls-sm-3 3
SLURM_JOBID=82216
SLURM_TASKID=1
[32m[0321 13:36:45 @logger.py:67][0m Existing log file 'train_log/fcn2_w_2_a_32_quant_ends_True/log.log' backuped to 'train_log/fcn2_w_2_a_32_quant_ends_True/log.log.0321-133645'
[32m[0321 13:36:45 @logger.py:74][0m Argv: drf_run.py --model_name=fcn2 --bitw=2 --bita=32 --quant_ends=True
[32m[0321 13:36:50 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0321 13:36:50 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0321 13:36:50 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0321 13:36:50 @drf_run.py:166][0m Using host: sls-sm-3
[32m[0321 13:36:50 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0321 13:36:50 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0321 13:36:50 @drf_run.py:188][0m Using GPU: 3
[32m[0321 13:36:50 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0321 13:36:50 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0321 13:36:50 @training.py:108][0m Building graph for training tower 0 ...
[32m[0321 13:36:50 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0321 13:36:50 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0321 13:36:50 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0321 13:36:51 @registry.py:130][0m linear0 output: [None, 504]
[32m[0321 13:36:51 @registry.py:122][0m linear1 input: [None, 504]
[32m[0321 13:36:51 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0321 13:36:51 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0321 13:36:51 @registry.py:130][0m linear1 output: [None, 504]
[32m[0321 13:36:51 @registry.py:122][0m linear2 input: [None, 504]
[32m[0321 13:36:51 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0321 13:36:51 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0321 13:36:51 @registry.py:130][0m linear2 output: [None, 504]
[32m[0321 13:36:51 @registry.py:122][0m linear3 input: [None, 504]
[32m[0321 13:36:51 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0321 13:36:51 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0321 13:36:51 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0321 13:36:51 @registry.py:130][0m linear3 output: [None, 504]
[32m[0321 13:36:51 @registry.py:122][0m last_linear input: [None, 504]
[32m[0321 13:36:51 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0321 13:36:51 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0321 13:36:51 @registry.py:130][0m last_linear output: [None, 255]
[32m[0321 13:36:51 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0321 13:36:51 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0321 13:36:51 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0321 13:36:51 @drf_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0321 13:36:52 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=1400871, size=5.34MB[0m
[32m[0321 13:36:52 @base.py:196][0m Setup callbacks graph ...
[32m[0321 13:36:52 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0321 13:36:52 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0321 13:36:52 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0321 13:36:52 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0321 13:36:52 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0321 13:36:52 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0321 13:36:52 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0321 13:36:52 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0321 13:36:52 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0321 13:36:53 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0321 13:36:53 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0321 13:36:53 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0321 13:36:53 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0321 13:36:53 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0321 13:36:53 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0321 13:36:53 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0321 13:36:53 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0321 13:36:53 @drf_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0321 13:36:53 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0321 13:36:53 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0321 13:36:53 @base.py:212][0m Creating the session ...
2018-03-21 13:36:54.074032: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-21 13:36:55.577982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:82:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-21 13:36:55.578035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:82:00.0, compute capability: 6.1)
[32m[0321 13:37:04 @base.py:220][0m Initializing the session ...
[32m[0321 13:37:04 @base.py:227][0m Graph Finalized.
[32m[0321 13:37:04 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0321 13:37:07 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10761/173481[03:00<45:22,59.78it/s]  7%|6         |11391/173481[03:10<45:11,59.78it/s] 12%|#2        |21336/173481[06:00<42:47,59.26it/s] 13%|#2        |21865/173481[06:10<42:38,59.26it/s] 16%|#6        |28256/173481[09:00<51:54,46.63it/s] 17%|#6        |28821/173481[09:10<51:42,46.63it/s] 22%|##1       |37798/173481[12:00<45:34,49.62it/s] 22%|##2       |38311/173481[12:10<45:24,49.62it/s] 28%|##7       |48002/173481[15:00<39:31,52.92it/s] 28%|##8       |48615/173481[15:10<39:19,52.92it/s] 33%|###3      |57826/173481[18:00<35:52,53.73it/s] 34%|###3      |58465/173481[18:10<35:40,53.73it/s] 39%|###9      |68271/173481[21:00<31:25,55.80it/s] 40%|###9      |68897/173481[21:11<31:14,55.80it/s] 45%|####4     |77531/173481[24:00<29:52,53.53it/s] 45%|####5     |78150/173481[24:11<29:40,53.53it/s] 50%|#####     |87496/173481[27:00<26:19,54.42it/s] 51%|#####     |88101/173481[27:11<26:08,54.42it/s] 56%|#####6    |97301/173481[30:00<23:19,54.44it/s] 56%|#####6    |97945/173481[30:11<23:07,54.44it/s] 62%|######1   |107411/173481[33:00<19:55,55.29it/s] 62%|######2   |108060/173481[33:11<19:43,55.29it/s] 67%|######7   |116401/173481[36:00<18:07,52.47it/s] 67%|######7   |116995/173481[36:11<17:56,52.47it/s] 73%|#######2  |126177/173481[39:00<14:46,53.38it/s] 73%|#######3  |126855/173481[39:12<14:33,53.38it/s] 79%|#######8  |136231/173481[42:00<11:22,54.58it/s] 79%|#######8  |136840/173481[42:12<11:11,54.58it/s] 84%|########4 |145920/173481[45:00<08:28,54.20it/s] 84%|########4 |146570/173481[45:12<08:16,54.20it/s] 89%|########9 |155067/173481[48:00<05:51,52.45it/s] 90%|########9 |155709/173481[48:12<05:38,52.45it/s] 95%|#########4|164410/173481[51:00<02:53,52.18it/s] 95%|#########5|165111/173481[51:12<02:40,52.18it/s]100%|##########|173481/173481[53:56<00:00,53.61it/s]
[32m[0321 14:31:03 @base.py:257][0m Epoch 1 (global_step 173481) finished, time:3236.13 sec.
[32m[0321 14:31:04 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:43<00:00,115.39it/s]
0
[32m[0321 14:33:47 @monitor.py:363][0m QueueInput/queue_size: 1.1053
[32m[0321 14:33:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 2.7907
[32m[0321 14:33:47 @monitor.py:363][0m activation-summaries/output-rms: 0.022625
[32m[0321 14:33:47 @monitor.py:363][0m cross_entropy_loss: 3.2686
[32m[0321 14:33:47 @monitor.py:363][0m lr: 0.001
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.10813
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.74717
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.071913
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.080944
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.071546
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.068362
[32m[0321 14:33:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 14:33:47 @monitor.py:363][0m train-error-top1: 0.75561
[32m[0321 14:33:47 @monitor.py:363][0m val-error-top1: 0.85349
[32m[0321 14:33:47 @monitor.py:363][0m val-utt-error: 0.66353
[32m[0321 14:33:47 @monitor.py:363][0m validation_cost: 3.9441
[32m[0321 14:33:47 @monitor.py:363][0m wd_cost: 0.82595
[32m[0321 14:33:47 @group.py:42][0m Callbacks took 163.608 sec in total. InferenceRunner: 163.125sec
[32m[0321 14:33:47 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10614/173481[03:00<46:02,58.97it/s]  6%|6         |11159/173481[03:10<45:52,58.97it/s] 12%|#1        |20656/173481[06:00<44:25,57.33it/s] 12%|#2        |21154/173481[06:10<44:16,57.33it/s] 17%|#7        |30165/173481[09:00<43:26,54.98it/s] 18%|#7        |30734/173481[09:10<43:16,54.98it/s] 23%|##2       |39582/173481[12:00<41:37,53.61it/s] 23%|##3       |40137/173481[12:10<41:27,53.61it/s] 28%|##8       |49230/173481[15:00<38:38,53.60it/s] 29%|##8       |49779/173481[15:10<38:27,53.60it/s] 34%|###4      |59506/173481[18:00<34:21,55.29it/s] 35%|###4      |60140/173481[18:11<34:09,55.29it/s] 40%|###9      |68965/173481[21:00<32:19,53.88it/s] 40%|####      |69609/173481[21:11<32:07,53.88it/s] 46%|####5     |79267/173481[24:00<28:17,55.51it/s] 46%|####6     |79914/173481[24:11<28:05,55.51it/s] 51%|#####1    |89318/173481[27:00<25:11,55.67it/s] 52%|#####1    |89944/173481[27:11<25:00,55.67it/s] 57%|#####7    |99391/173481[30:00<22:07,55.82it/s] 58%|#####7    |100031/173481[30:11<21:55,55.82it/s] 63%|######3   |109550/173481[33:00<18:59,56.11it/s] 64%|######3   |110209/173481[33:11<18:47,56.11it/s] 69%|######8   |119360/173481[36:00<16:18,55.29it/s] 69%|######9   |119999/173481[36:12<16:07,55.29it/s] 75%|#######4  |129353/173481[39:00<13:16,55.40it/s] 75%|#######4  |129998/173481[39:12<13:04,55.40it/s] 80%|########  |139580/173481[42:00<10:04,56.10it/s] 81%|########  |140294/173481[42:12<09:51,56.10it/s] 86%|########6 |149960/173481[45:00<06:53,56.86it/s] 87%|########6 |150647/173481[45:12<06:41,56.86it/s] 92%|#########2|160209/173481[48:00<03:53,56.90it/s] 93%|#########2|160919/173481[48:12<03:40,56.90it/s] 98%|#########8|170715/173481[51:00<00:48,57.62it/s] 99%|#########8|171491/173481[51:12<00:34,57.62it/s]100%|##########|173481/173481[51:46<00:00,55.85it/s]
[32m[0321 15:25:33 @base.py:257][0m Epoch 2 (global_step 346962) finished, time:3106.37 sec.
[32m[0321 15:25:34 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-346962.
[32m[0321 15:25:34 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:28<00:00,126.76it/s]
1
[32m[0321 15:28:03 @monitor.py:363][0m QueueInput/queue_size: 0.67847
[32m[0321 15:28:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 2.8393
[32m[0321 15:28:03 @monitor.py:363][0m activation-summaries/output-rms: 0.022372
[32m[0321 15:28:03 @monitor.py:363][0m cross_entropy_loss: 3.2825
[32m[0321 15:28:03 @monitor.py:363][0m lr: 0.001
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.10861
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0228
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.071273
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.081079
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.071652
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.068127
[32m[0321 15:28:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 15:28:03 @monitor.py:363][0m train-error-top1: 0.75163
[32m[0321 15:28:03 @monitor.py:363][0m val-error-top1: 0.86751
[32m[0321 15:28:03 @monitor.py:363][0m val-utt-error: 0.69987
[32m[0321 15:28:03 @monitor.py:363][0m validation_cost: 4.1131
[32m[0321 15:28:03 @monitor.py:363][0m wd_cost: 0.82278
[32m[0321 15:28:03 @group.py:42][0m Callbacks took 149.275 sec in total. InferenceRunner: 148.496sec
[32m[0321 15:28:03 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16559/173481[03:00<28:25,91.99it/s] 10%|#         |17451/173481[03:10<28:16,91.99it/s] 17%|#6        |29104/173481[06:00<30:20,79.29it/s] 17%|#7        |29668/173481[06:10<30:13,79.29it/s] 22%|##2       |38824/173481[09:00<34:56,64.24it/s] 23%|##2       |39384/173481[09:10<34:47,64.24it/s] 28%|##7       |48489/173481[12:00<35:37,58.49it/s] 28%|##8       |49059/173481[12:10<35:27,58.49it/s] 34%|###3      |58238/173481[15:00<34:09,56.24it/s] 34%|###3      |58776/173481[15:10<33:59,56.24it/s] 40%|###9      |68549/173481[18:00<30:48,56.75it/s] 40%|###9      |69253/173481[18:10<30:36,56.75it/s] 46%|####5     |79425/173481[21:00<26:47,58.53it/s] 46%|####6     |80100/173481[21:11<26:35,58.53it/s] 52%|#####2    |90211/173481[24:00<23:26,59.22it/s] 52%|#####2    |90862/173481[24:11<23:15,59.22it/s] 58%|#####7    |100387/173481[27:00<21:03,57.84it/s] 58%|#####8    |101018/173481[27:11<20:52,57.84it/s] 64%|######4   |111129/173481[30:00<17:41,58.74it/s] 64%|######4   |111763/173481[30:11<17:30,58.74it/s] 70%|#######   |121824/173481[33:00<14:34,59.07it/s] 71%|#######   |122508/173481[33:11<14:22,59.07it/s] 76%|#######6  |132423/173481[36:00<11:36,58.97it/s] 77%|#######6  |133114/173481[36:11<11:24,58.97it/s] 82%|########2 |143078/173481[39:00<08:34,59.08it/s] 83%|########2 |143782/173481[39:12<08:22,59.08it/s] 89%|########8 |153914/173481[42:00<05:28,59.63it/s] 89%|########9 |154652/173481[42:12<05:15,59.63it/s] 95%|#########5|164824/173481[45:00<02:24,60.12it/s] 95%|#########5|165567/173481[45:12<02:11,60.12it/s]100%|##########|173481/173481[47:15<00:00,61.19it/s]
[32m[0321 16:15:18 @base.py:257][0m Epoch 3 (global_step 520443) finished, time:2835.27 sec.
[32m[0321 16:15:18 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-520443.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:18<00:00,135.94it/s]
2
[32m[0321 16:17:37 @monitor.py:363][0m QueueInput/queue_size: 0.24749
[32m[0321 16:17:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.5323
[32m[0321 16:17:37 @monitor.py:363][0m activation-summaries/output-rms: 0.027215
[32m[0321 16:17:37 @monitor.py:363][0m cross_entropy_loss: 2.7882
[32m[0321 16:17:37 @monitor.py:363][0m lr: 0.0005
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.19513
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2166
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.1229
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13268
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11754
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11069
[32m[0321 16:17:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 16:17:37 @monitor.py:363][0m train-error-top1: 0.6621
[32m[0321 16:17:37 @monitor.py:363][0m val-error-top1: 0.76092
[32m[0321 16:17:37 @monitor.py:363][0m val-utt-error: 0.45633
[32m[0321 16:17:37 @monitor.py:363][0m validation_cost: 3.2856
[32m[0321 16:17:37 @monitor.py:363][0m wd_cost: 0.47194
[32m[0321 16:17:37 @group.py:42][0m Callbacks took 138.805 sec in total. InferenceRunner: 138.488sec
[32m[0321 16:17:37 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16526/173481[03:00<28:29,91.81it/s] 10%|#         |17398/173481[03:10<28:20,91.81it/s] 19%|#8        |32153/173481[06:00<26:23,89.24it/s] 19%|#9        |33094/173481[06:10<26:13,89.24it/s] 27%|##6       |46628/173481[09:00<24:59,84.60it/s] 27%|##7       |47542/173481[09:10<24:48,84.60it/s] 34%|###4      |59667/173481[12:00<24:18,78.05it/s] 35%|###4      |60262/173481[12:10<24:10,78.05it/s] 41%|####      |70273/173481[15:00<25:37,67.14it/s] 41%|####      |70947/173481[15:10<25:27,67.14it/s] 47%|####6     |81033/173481[18:00<24:21,63.24it/s] 47%|####7     |81657/173481[18:11<24:11,63.24it/s] 52%|#####2    |90353/173481[21:00<24:20,56.94it/s] 52%|#####2    |91015/173481[21:11<24:08,56.94it/s] 58%|#####8    |101262/173481[24:00<20:30,58.71it/s] 59%|#####8    |101953/173481[24:11<20:18,58.71it/s] 64%|######4   |111443/173481[27:00<17:56,57.62it/s] 65%|######4   |112138/173481[27:11<17:44,57.62it/s] 70%|#######   |122251/173481[30:00<14:31,58.80it/s] 71%|#######   |122942/173481[30:11<14:19,58.80it/s] 76%|#######6  |132561/173481[33:00<11:45,58.03it/s] 77%|#######6  |133242/173481[33:11<11:33,58.03it/s] 83%|########2 |143468/173481[36:00<08:26,59.28it/s] 83%|########3 |144147/173481[36:11<08:14,59.28it/s] 89%|########8 |154171/173481[39:00<05:25,59.37it/s] 89%|########9 |154879/173481[39:12<05:13,59.37it/s] 95%|#########4|164726/173481[42:00<02:28,59.00it/s] 95%|#########5|165461/173481[42:12<02:15,59.00it/s]100%|##########|173481/173481[44:36<00:00,64.81it/s]
[32m[0321 17:02:13 @base.py:257][0m Epoch 4 (global_step 693924) finished, time:2676.61 sec.
[32m[0321 17:02:14 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-693924.
[32m[0321 17:02:14 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.01it/s]
3
[32m[0321 17:04:18 @monitor.py:363][0m QueueInput/queue_size: 0.43932
[32m[0321 17:04:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.2107
[32m[0321 17:04:18 @monitor.py:363][0m activation-summaries/output-rms: 0.029929
[32m[0321 17:04:18 @monitor.py:363][0m cross_entropy_loss: 2.6146
[32m[0321 17:04:18 @monitor.py:363][0m lr: 0.0005
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21882
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3381
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.13546
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.15674
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.14113
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.13454
[32m[0321 17:04:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 17:04:18 @monitor.py:363][0m train-error-top1: 0.64087
[32m[0321 17:04:18 @monitor.py:363][0m val-error-top1: 0.73338
[32m[0321 17:04:18 @monitor.py:363][0m val-utt-error: 0.40814
[32m[0321 17:04:18 @monitor.py:363][0m validation_cost: 3.1228
[32m[0321 17:04:18 @monitor.py:363][0m wd_cost: 0.626
[32m[0321 17:04:18 @group.py:42][0m Callbacks took 124.647 sec in total. InferenceRunner: 123.840sec
[32m[0321 17:04:18 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16159/173481[03:00<29:12,89.77it/s] 10%|9         |17043/173481[03:10<29:02,89.77it/s] 16%|#5        |27273/173481[06:00<33:18,73.17it/s] 16%|#6        |27877/173481[06:10<33:10,73.17it/s] 22%|##1       |37447/173481[09:00<35:33,63.77it/s] 22%|##1       |37982/173481[09:10<35:24,63.77it/s] 28%|##7       |47757/173481[12:00<34:43,60.35it/s] 28%|##7       |48411/173481[12:10<34:32,60.35it/s] 34%|###3      |58449/173481[15:00<32:01,59.87it/s] 34%|###4      |59079/173481[15:10<31:50,59.87it/s] 40%|###9      |68942/173481[18:00<29:29,59.07it/s] 40%|####      |69583/173481[18:10<29:18,59.07it/s] 46%|####5     |79302/173481[21:00<26:55,58.30it/s] 46%|####6     |79976/173481[21:11<26:43,58.30it/s] 52%|#####1    |90075/173481[24:00<23:32,59.06it/s] 52%|#####2    |90736/173481[24:11<23:20,59.06it/s] 58%|#####7    |100469/173481[27:00<20:50,58.39it/s] 58%|#####8    |101123/173481[27:11<20:39,58.39it/s] 64%|######3   |110757/173481[30:00<18:05,57.76it/s] 64%|######4   |111424/173481[30:11<17:54,57.76it/s] 69%|######9   |120527/173481[33:00<15:46,55.97it/s] 70%|######9   |121211/173481[33:11<15:33,55.97it/s] 75%|#######5  |130247/173481[36:00<13:06,54.95it/s] 75%|#######5  |130866/173481[36:11<12:55,54.95it/s] 80%|########  |139097/173481[39:00<11:02,51.90it/s] 81%|########  |139780/173481[39:12<10:49,51.90it/s] 86%|########6 |149303/173481[42:00<07:26,54.19it/s] 86%|########6 |149951/173481[42:12<07:14,54.19it/s] 92%|#########2|159674/173481[45:00<04:07,55.85it/s] 92%|#########2|160414/173481[45:12<03:53,55.85it/s] 98%|#########8|170067/173481[48:00<01:00,56.77it/s] 98%|#########8|170741/173481[48:12<00:48,56.77it/s]100%|##########|173481/173481[49:00<00:00,59.00it/s]
[32m[0321 17:53:18 @base.py:257][0m Epoch 5 (global_step 867405) finished, time:2940.15 sec.
[32m[0321 17:53:18 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-867405.
[32m[0321 17:53:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:09<00:00,145.71it/s]
4
[32m[0321 17:55:28 @monitor.py:363][0m QueueInput/queue_size: 0.65155
[32m[0321 17:55:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.2757
[32m[0321 17:55:28 @monitor.py:363][0m activation-summaries/output-rms: 0.031211
[32m[0321 17:55:28 @monitor.py:363][0m cross_entropy_loss: 2.5088
[32m[0321 17:55:28 @monitor.py:363][0m lr: 0.0005
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.22231
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4614
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.13682
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.16004
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.14547
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.13882
[32m[0321 17:55:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 17:55:28 @monitor.py:363][0m train-error-top1: 0.61274
[32m[0321 17:55:28 @monitor.py:363][0m val-error-top1: 0.72789
[32m[0321 17:55:28 @monitor.py:363][0m val-utt-error: 0.40872
[32m[0321 17:55:28 @monitor.py:363][0m validation_cost: 3.1176
[32m[0321 17:55:28 @monitor.py:363][0m wd_cost: 0.65125
[32m[0321 17:55:28 @group.py:42][0m Callbacks took 129.974 sec in total. InferenceRunner: 129.193sec
[32m[0321 17:55:28 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9806/173481[03:00<50:04,54.47it/s]  6%|5         |10345/173481[03:10<49:54,54.47it/s] 11%|#         |18651/173481[06:00<49:56,51.66it/s] 11%|#1        |19145/173481[06:10<49:47,51.66it/s] 16%|#6        |27995/173481[09:00<46:49,51.79it/s] 16%|#6        |28555/173481[09:10<46:38,51.79it/s] 22%|##1       |37347/173481[12:00<43:44,51.87it/s] 22%|##1       |37896/173481[12:10<43:33,51.87it/s] 27%|##6       |46520/173481[15:00<41:09,51.41it/s] 27%|##7       |47070/173481[15:10<40:58,51.41it/s] 32%|###2      |55626/173481[18:00<38:31,50.99it/s] 32%|###2      |56245/173481[18:10<38:19,50.99it/s] 38%|###7      |65611/173481[21:00<33:50,53.14it/s] 38%|###8      |66229/173481[21:11<33:38,53.14it/s] 43%|####2     |74453/173481[24:00<32:19,51.05it/s] 43%|####3     |75412/173481[24:11<32:01,51.05it/s] 49%|####8     |84355/173481[27:00<28:03,52.96it/s] 49%|####8     |84910/173481[27:11<27:52,52.96it/s] 54%|#####3    |93598/173481[30:00<25:32,52.14it/s] 54%|#####4    |94167/173481[30:11<25:21,52.14it/s] 59%|#####9    |102576/173481[33:00<23:10,50.98it/s] 59%|#####9    |103160/173481[33:11<22:59,50.98it/s] 64%|######4   |111707/173481[36:00<20:14,50.85it/s] 65%|######4   |112276/173481[36:11<20:03,50.85it/s] 70%|######9   |120780/173481[39:00<17:20,50.63it/s] 70%|######9   |121435/173481[39:12<17:08,50.63it/s] 75%|#######5  |130293/173481[42:00<13:55,51.71it/s] 75%|#######5  |130916/173481[42:12<13:43,51.71it/s] 80%|########  |139554/173481[45:00<10:57,51.58it/s] 81%|########  |140173/173481[45:12<10:45,51.58it/s] 86%|########5 |148763/173481[48:00<08:01,51.37it/s] 86%|########6 |149337/173481[48:12<07:50,51.37it/s] 90%|######### |156681/173481[51:00<05:54,47.39it/s] 91%|######### |157275/173481[51:12<05:41,47.39it/s] 95%|#########5|165124/173481[54:00<02:57,47.14it/s] 96%|#########5|165750/173481[54:12<02:43,47.14it/s]100%|##########|173481/173481[56:53<00:00,50.82it/s]
[32m[0321 18:52:22 @base.py:257][0m Epoch 6 (global_step 1040886) finished, time:3413.77 sec.
[32m[0321 18:52:22 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-1040886.
[32m[0321 18:52:23 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:11<00:00,143.04it/s]
5
[32m[0321 18:54:34 @monitor.py:363][0m QueueInput/queue_size: 0.31104
[32m[0321 18:54:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.2381
[32m[0321 18:54:34 @monitor.py:363][0m activation-summaries/output-rms: 0.034971
[32m[0321 18:54:34 @monitor.py:363][0m cross_entropy_loss: 2.1239
[32m[0321 18:54:34 @monitor.py:363][0m lr: 0.00025
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.34156
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.5388
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.22095
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.23491
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21433
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20584
[32m[0321 18:54:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 18:54:34 @monitor.py:363][0m train-error-top1: 0.54135
[32m[0321 18:54:34 @monitor.py:363][0m val-error-top1: 0.63845
[32m[0321 18:54:34 @monitor.py:363][0m val-utt-error: 0.25396
[32m[0321 18:54:34 @monitor.py:363][0m validation_cost: 2.604
[32m[0321 18:54:34 @monitor.py:363][0m wd_cost: 0.30416
[32m[0321 18:54:34 @group.py:42][0m Callbacks took 132.514 sec in total. InferenceRunner: 131.602sec
[32m[0321 18:54:34 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15503/173481[03:00<30:34,86.13it/s]  9%|9         |16380/173481[03:10<30:24,86.13it/s] 15%|#4        |25254/173481[06:00<37:08,66.51it/s] 15%|#4        |25759/173481[06:10<37:01,66.51it/s] 20%|#9        |34090/173481[09:00<41:07,56.48it/s] 20%|#9        |34591/173481[09:10<40:59,56.48it/s] 25%|##4       |42684/173481[12:00<42:07,51.75it/s] 25%|##4       |43229/173481[12:10<41:57,51.75it/s] 30%|##9       |51742/173481[15:00<39:45,51.02it/s] 30%|###       |52284/173481[15:10<39:35,51.02it/s] 35%|###5      |60975/173481[18:00<36:39,51.16it/s] 35%|###5      |61534/173481[18:11<36:28,51.16it/s] 40%|####      |69925/173481[21:00<34:13,50.42it/s] 41%|####      |70501/173481[21:11<34:02,50.42it/s] 46%|####6     |79874/173481[24:00<29:35,52.74it/s] 46%|####6     |80514/173481[24:11<29:22,52.74it/s] 52%|#####1    |89945/173481[27:00<25:38,54.29it/s] 52%|#####2    |90585/173481[27:11<25:26,54.29it/s] 58%|#####7    |100195/173481[30:00<21:58,55.58it/s] 58%|#####8    |100892/173481[30:11<21:46,55.58it/s] 63%|######3   |110005/173481[33:00<19:13,55.03it/s] 64%|######3   |110678/173481[33:11<19:01,55.03it/s] 69%|######9   |119970/173481[36:00<16:09,55.19it/s] 70%|######9   |120619/173481[36:11<15:57,55.19it/s] 75%|#######4  |129701/173481[39:00<13:21,54.62it/s] 75%|#######5  |130294/173481[39:12<13:10,54.62it/s] 80%|########  |139555/173481[42:00<10:20,54.68it/s] 81%|########  |140264/173481[42:12<10:07,54.68it/s] 86%|########6 |149892/173481[45:00<07:01,56.02it/s] 87%|########6 |150604/173481[45:12<06:48,56.02it/s] 93%|#########2|160597/173481[48:00<03:43,57.69it/s] 93%|#########3|161340/173481[48:12<03:30,57.69it/s] 99%|#########8|171471/173481[51:00<00:34,59.02it/s] 99%|#########9|172228/173481[51:12<00:21,59.02it/s]100%|##########|173481/173481[51:33<00:00,56.08it/s]
[32m[0321 19:46:08 @base.py:257][0m Epoch 7 (global_step 1214367) finished, time:3093.55 sec.
[32m[0321 19:46:08 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-1214367.
[32m[0321 19:46:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:16<00:00,138.33it/s]
6
[32m[0321 19:48:25 @monitor.py:363][0m QueueInput/queue_size: 0.70433
[32m[0321 19:48:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.3785
[32m[0321 19:48:25 @monitor.py:363][0m activation-summaries/output-rms: 0.03593
[32m[0321 19:48:25 @monitor.py:363][0m cross_entropy_loss: 2.0911
[32m[0321 19:48:25 @monitor.py:363][0m lr: 0.00025
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.40832
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.5902
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.25368
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29078
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26845
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25541
[32m[0321 19:48:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 19:48:25 @monitor.py:363][0m train-error-top1: 0.52987
[32m[0321 19:48:25 @monitor.py:363][0m val-error-top1: 0.62522
[32m[0321 19:48:25 @monitor.py:363][0m val-utt-error: 0.25066
[32m[0321 19:48:25 @monitor.py:363][0m validation_cost: 2.5349
[32m[0321 19:48:25 @monitor.py:363][0m wd_cost: 0.44086
[32m[0321 19:48:25 @group.py:42][0m Callbacks took 137.027 sec in total. InferenceRunner: 136.092sec
[32m[0321 19:48:25 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16277/173481[03:00<28:58,90.42it/s] 10%|9         |17114/173481[03:10<28:49,90.42it/s] 17%|#6        |28749/173481[06:00<30:45,78.44it/s] 17%|#6        |29303/173481[06:10<30:37,78.44it/s] 22%|##2       |38534/173481[09:00<35:01,64.22it/s] 23%|##2       |39117/173481[09:10<34:52,64.22it/s] 28%|##7       |48204/173481[12:00<35:41,58.50it/s] 28%|##8       |48783/173481[12:10<35:31,58.50it/s] 33%|###3      |58073/173481[15:00<33:58,56.60it/s] 34%|###3      |58674/173481[15:10<33:48,56.60it/s] 39%|###9      |68498/173481[18:00<30:33,57.25it/s] 40%|###9      |69128/173481[18:11<30:22,57.25it/s] 46%|####5     |78979/173481[21:00<27:17,57.73it/s] 46%|####5     |79633/173481[21:11<27:05,57.73it/s] 51%|#####1    |89332/173481[24:00<24:20,57.62it/s] 52%|#####1    |89908/173481[24:11<24:10,57.62it/s] 57%|#####7    |99224/173481[27:00<22:00,56.25it/s] 58%|#####7    |99860/173481[27:11<21:48,56.25it/s] 63%|######3   |109550/173481[30:00<18:45,56.80it/s] 64%|######3   |110233/173481[30:11<18:33,56.80it/s] 69%|######9   |120307/173481[33:00<15:12,58.24it/s] 70%|######9   |120947/173481[33:11<15:01,58.24it/s] 75%|#######5  |130704/173481[36:00<12:17,58.00it/s] 76%|#######5  |131368/173481[36:11<12:06,58.00it/s] 81%|########1 |141250/173481[39:00<09:12,58.29it/s] 82%|########1 |141979/173481[39:12<09:00,58.29it/s] 87%|########7 |151374/173481[42:00<06:26,57.25it/s] 88%|########7 |152088/173481[42:12<06:13,57.25it/s] 93%|#########3|161934/173481[45:00<03:19,57.94it/s] 94%|#########3|162638/173481[45:12<03:07,57.94it/s]100%|#########9|172744/173481[48:00<00:12,58.98it/s]100%|#########9|173474/173481[48:12<00:00,58.98it/s]100%|##########|173481/173481[48:12<00:00,59.97it/s]
[32m[0321 20:36:38 @base.py:257][0m Epoch 8 (global_step 1387848) finished, time:2892.67 sec.
[32m[0321 20:36:38 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-1387848.
[32m[0321 20:36:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,151.95it/s]
7
[32m[0321 20:38:42 @monitor.py:363][0m QueueInput/queue_size: 0.58512
[32m[0321 20:38:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.0048
[32m[0321 20:38:42 @monitor.py:363][0m activation-summaries/output-rms: 0.035897
[32m[0321 20:38:42 @monitor.py:363][0m cross_entropy_loss: 2.0533
[32m[0321 20:38:42 @monitor.py:363][0m lr: 0.00025
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.41956
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6361
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.25747
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30416
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28164
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26683
[32m[0321 20:38:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 20:38:42 @monitor.py:363][0m train-error-top1: 0.52063
[32m[0321 20:38:42 @monitor.py:363][0m val-error-top1: 0.61487
[32m[0321 20:38:42 @monitor.py:363][0m val-utt-error: 0.24631
[32m[0321 20:38:42 @monitor.py:363][0m validation_cost: 2.4919
[32m[0321 20:38:42 @monitor.py:363][0m wd_cost: 0.47107
[32m[0321 20:38:42 @group.py:42][0m Callbacks took 124.706 sec in total. InferenceRunner: 123.880sec
[32m[0321 20:38:42 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15697/173481[03:00<30:09,87.20it/s]  9%|9         |16262/173481[03:10<30:02,87.20it/s] 15%|#4        |25733/173481[06:00<36:12,68.01it/s] 15%|#5        |26332/173481[06:10<36:03,68.01it/s] 21%|##        |36343/173481[09:00<36:11,63.15it/s] 21%|##1       |36972/173481[09:10<36:01,63.15it/s] 27%|##7       |47168/173481[12:00<34:10,61.60it/s] 28%|##7       |47783/173481[12:10<34:00,61.60it/s] 33%|###3      |57558/173481[15:00<32:25,59.60it/s] 34%|###3      |58182/173481[15:10<32:14,59.60it/s] 39%|###9      |67891/173481[18:00<30:05,58.48it/s] 39%|###9      |68477/173481[18:11<29:55,58.48it/s] 45%|####4     |77613/173481[21:00<28:27,56.15it/s] 45%|####5     |78253/173481[21:11<28:15,56.15it/s] 51%|#####     |87936/173481[24:00<25:07,56.74it/s] 51%|#####1    |88582/173481[24:11<24:56,56.74it/s] 57%|#####6    |98395/173481[27:00<21:47,57.42it/s] 57%|#####7    |99084/173481[27:11<21:35,57.42it/s] 63%|######2   |108948/173481[30:00<18:32,58.01it/s] 63%|######3   |109627/173481[30:11<18:20,58.01it/s] 69%|######8   |119388/173481[33:00<15:32,58.00it/s] 69%|######9   |120027/173481[33:11<15:21,58.00it/s] 75%|#######4  |129567/173481[36:00<12:46,57.26it/s] 75%|#######5  |130237/173481[36:11<12:35,57.26it/s] 81%|########  |139998/173481[39:00<09:41,57.60it/s] 81%|########1 |140677/173481[39:12<09:29,57.60it/s] 87%|########6 |150398/173481[42:00<06:40,57.69it/s] 87%|########7 |151081/173481[42:12<06:28,57.69it/s] 93%|#########2|160768/173481[45:00<03:40,57.64it/s] 93%|#########3|161502/173481[45:12<03:27,57.64it/s] 98%|#########8|170708/173481[48:00<00:49,56.40it/s] 99%|#########8|171377/173481[48:12<00:37,56.40it/s]100%|##########|173481/173481[48:50<00:00,59.19it/s]
[32m[0321 21:27:33 @base.py:257][0m Epoch 9 (global_step 1561329) finished, time:2930.85 sec.
[32m[0321 21:27:33 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-1561329.
[32m[0321 21:27:34 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.09it/s]
8
[32m[0321 21:29:29 @monitor.py:363][0m QueueInput/queue_size: 0.47827
[32m[0321 21:29:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 9.4307
[32m[0321 21:29:29 @monitor.py:363][0m activation-summaries/output-rms: 0.038233
[32m[0321 21:29:29 @monitor.py:363][0m cross_entropy_loss: 1.9063
[32m[0321 21:29:29 @monitor.py:363][0m lr: 0.000125
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.51531
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6596
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33614
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.35832
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.33144
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.31491
[32m[0321 21:29:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0321 21:29:29 @monitor.py:363][0m train-error-top1: 0.48897
[32m[0321 21:29:29 @monitor.py:363][0m val-error-top1: 0.58272
[32m[0321 21:29:29 @monitor.py:363][0m val-utt-error: 0.21517
[32m[0321 21:29:29 @monitor.py:363][0m validation_cost: 2.355
[32m[0321 21:29:29 @monitor.py:363][0m wd_cost: 0.14142
[32m[0321 21:29:29 @group.py:42][0m Callbacks took 115.436 sec in total. InferenceRunner: 114.714sec
[32m[0321 21:29:29 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16309/173481[03:00<28:54,90.60it/s] 10%|9         |16914/173481[03:10<28:48,90.60it/s]srun: error: slurm_receive_msg: Socket timed out on send/recv operation
srun: error: slurm_receive_msg[5.101.40.8]: Socket timed out on send/recv operation
 15%|#5        |26212/173481[06:00<35:51,68.46it/s] 15%|#5        |26811/173481[06:10<35:42,68.46it/s] 21%|##1       |36823/173481[09:00<35:57,63.35it/s] 22%|##1       |37447/173481[09:10<35:47,63.35it/s] 27%|##7       |46897/173481[12:00<35:31,59.39it/s] 27%|##7       |47516/173481[12:10<35:20,59.39it/s] 33%|###3      |57687/173481[15:00<32:20,59.66it/s] 34%|###3      |58316/173481[15:10<32:10,59.66it/s] 39%|###9      |68437/173481[18:00<29:19,59.69it/s] 40%|###9      |69048/173481[18:11<29:09,59.69it/s] 45%|####5     |78919/173481[21:00<26:44,58.95it/s] 46%|####5     |79571/173481[21:11<26:33,58.95it/s] 52%|#####1    |89437/173481[24:00<23:52,58.69it/s] 52%|#####1    |90116/173481[24:11<23:40,58.69it/s] 58%|#####7    |99912/173481[27:00<20:58,58.44it/s] 58%|#####7    |100586/173481[27:11<20:47,58.44it/s] 63%|######3   |110078/173481[30:00<18:23,57.44it/s] 64%|######3   |110736/173481[30:11<18:12,57.44it/s] 69%|######9   |120408/173481[33:00<15:24,57.41it/s] 70%|######9   |121071/173481[33:11<15:12,57.41it/s] 75%|#######5  |130762/173481[36:00<12:23,57.46it/s] 76%|#######5  |131470/173481[36:11<12:11,57.46it/s] 82%|########1 |141533/173481[39:00<09:04,58.63it/s] 82%|########1 |142226/173481[39:12<08:53,58.63it/s] 88%|########7 |151977/173481[42:00<06:08,58.31it/s] 88%|########7 |152614/173481[42:12<05:57,58.31it/s] 94%|#########3|162273/173481[45:00<03:14,57.75it/s] 94%|#########3|162965/173481[45:12<03:02,57.75it/s]100%|#########9|172652/173481[48:00<00:14,57.70it/s]100%|#########9|173334/173481[48:12<00:02,57.70it/s]100%|##########|173481/173481[48:15<00:00,59.92it/s]
[32m[0321 22:17:44 @base.py:257][0m Epoch 10 (global_step 1734810) finished, time:2895.04 sec.
[32m[0321 22:17:44 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-1734810.
[32m[0321 22:17:44 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,155.77it/s]
9
[32m[0321 22:19:45 @monitor.py:363][0m QueueInput/queue_size: 0.90475
[32m[0321 22:19:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.022
[32m[0321 22:19:45 @monitor.py:363][0m activation-summaries/output-rms: 0.040164
[32m[0321 22:19:45 @monitor.py:363][0m cross_entropy_loss: 1.8407
[32m[0321 22:19:45 @monitor.py:363][0m lr: 0.000125
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60439
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6763
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.39282
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41584
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.38668
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36832
[32m[0321 22:19:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061344
[32m[0321 22:19:45 @monitor.py:363][0m train-error-top1: 0.48213
[32m[0321 22:19:45 @monitor.py:363][0m val-error-top1: 0.56845
[32m[0321 22:19:45 @monitor.py:363][0m val-utt-error: 0.19977
[32m[0321 22:19:45 @monitor.py:363][0m validation_cost: 2.2675
[32m[0321 22:19:45 @monitor.py:363][0m wd_cost: 0.19286
[32m[0321 22:19:45 @group.py:42][0m Callbacks took 121.643 sec in total. InferenceRunner: 120.845sec
[32m[0321 22:19:45 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11386/173481[03:00<42:43,63.24it/s]  7%|6         |11975/173481[03:10<42:33,63.24it/s] 13%|#2        |21856/173481[06:00<41:42,60.59it/s] 13%|#2        |22472/173481[06:10<41:32,60.59it/s] 19%|#8        |32214/173481[09:00<39:53,59.03it/s] 19%|#8        |32798/173481[09:10<39:43,59.03it/s] 25%|##4       |42531/173481[12:00<37:31,58.15it/s] 25%|##4       |42792/173481[12:10<37:27,58.15it/s] 30%|###       |52491/173481[15:00<35:33,56.70it/s] 31%|###       |53091/173481[15:10<35:23,56.70it/s] 36%|###6      |62612/173481[18:00<32:43,56.46it/s] 36%|###6      |63210/173481[18:10<32:33,56.46it/s] 42%|####1     |72353/173481[21:00<30:29,55.26it/s] 42%|####2     |72945/173481[21:11<30:19,55.26it/s] 47%|####7     |82238/173481[24:00<27:36,55.09it/s] 48%|####7     |82865/173481[24:11<27:24,55.09it/s] 52%|#####1    |89906/173481[27:00<28:59,48.04it/s] 52%|#####1    |90085/173481[27:11<28:55,48.04it/s] 59%|#####8    |101836/173481[30:00<21:26,55.70it/s] 59%|#####9    |102470/173481[30:11<21:14,55.70it/s] 65%|######4   |111912/173481[33:00<18:22,55.84it/s] 65%|######4   |112570/173481[33:11<18:10,55.84it/s] 70%|#######   |122063/173481[36:00<15:16,56.12it/s] 71%|#######   |122713/173481[36:11<15:04,56.12it/s] 76%|#######6  |132377/173481[39:00<12:04,56.70it/s] 77%|#######6  |132985/173481[39:12<11:54,56.70it/s] 82%|########2 |142884/173481[42:00<08:51,57.52it/s] 83%|########2 |143590/173481[42:12<08:39,57.52it/s] 88%|########8 |152919/173481[45:00<06:03,56.62it/s] 89%|########8 |153570/173481[45:12<05:51,56.62it/s] 94%|#########3|162841/173481[48:00<03:10,55.86it/s] 94%|#########4|163515/173481[48:12<02:58,55.86it/s]100%|#########9|172911/173481[51:00<00:10,55.89it/s]100%|##########|173481/173481[51:10<00:00,56.50it/s]
[32m[0321 23:10:56 @base.py:257][0m Epoch 11 (global_step 1908291) finished, time:3070.21 sec.
[32m[0321 23:10:56 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-1908291.
[32m[0321 23:10:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.63it/s]
10
[32m[0321 23:12:49 @monitor.py:363][0m QueueInput/queue_size: 0.5303
[32m[0321 23:12:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.538
[32m[0321 23:12:49 @monitor.py:363][0m activation-summaries/output-rms: 0.039329
[32m[0321 23:12:49 @monitor.py:363][0m cross_entropy_loss: 1.7446
[32m[0321 23:12:49 @monitor.py:363][0m lr: 6.25e-05
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.65107
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.6936
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.41457
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.45107
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.42256
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.4031
[32m[0321 23:12:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0321 23:12:49 @monitor.py:363][0m train-error-top1: 0.45447
[32m[0321 23:12:49 @monitor.py:363][0m val-error-top1: 0.52689
[32m[0321 23:12:49 @monitor.py:363][0m val-utt-error: 0.15285
[32m[0321 23:12:49 @monitor.py:363][0m validation_cost: 2.0492
[32m[0321 23:12:49 @monitor.py:363][0m wd_cost: 0.22353
[32m[0321 23:12:49 @group.py:42][0m Callbacks took 113.956 sec in total. InferenceRunner: 112.968sec
[32m[0321 23:12:49 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15301/173481[03:00<31:00,85.00it/s]  9%|9         |15894/173481[03:10<30:53,85.00it/s] 15%|#4        |25475/173481[06:00<36:19,67.89it/s] 15%|#5        |26045/173481[06:10<36:11,67.89it/s] 20%|##        |35175/173481[09:00<38:22,60.07it/s] 21%|##        |35684/173481[09:10<38:13,60.07it/s] 26%|##5       |44535/173481[12:00<38:33,55.73it/s] 26%|##5       |45084/173481[12:10<38:23,55.73it/s] 31%|###1      |54094/173481[15:00<36:35,54.38it/s] 32%|###1      |54700/173481[15:10<36:24,54.38it/s] 37%|###7      |64427/173481[18:00<32:32,55.85it/s] 37%|###7      |65025/173481[18:11<32:21,55.85it/s] 44%|####3     |75545/173481[21:00<27:49,58.66it/s] 44%|####3     |76240/173481[21:11<27:37,58.66it/s] 50%|####9     |85890/173481[24:00<25:08,58.06it/s] 50%|####9     |86530/173481[24:11<24:57,58.06it/s] 56%|#####5    |96646/173481[27:00<21:44,58.89it/s] 56%|#####6    |97324/173481[27:11<21:33,58.89it/s] 62%|######1   |106910/173481[30:00<19:09,57.93it/s] 62%|######2   |107598/173481[30:11<18:57,57.93it/s] 68%|######7   |117195/173481[33:00<16:18,57.53it/s] 68%|######7   |117872/173481[33:11<16:06,57.53it/s] 73%|#######3  |127353/173481[36:00<13:29,56.98it/s] 74%|#######3  |128004/173481[36:11<13:18,56.98it/s] 79%|#######9  |137420/173481[39:00<10:38,56.44it/s] 80%|#######9  |138074/173481[39:12<10:27,56.44it/s] 85%|########4 |147400/173481[42:00<07:46,55.94it/s] 85%|########5 |148054/173481[42:12<07:34,55.94it/s] 91%|######### |157785/173481[45:00<04:36,56.80it/s] 91%|#########1|158489/173481[45:12<04:23,56.80it/s] 97%|#########7|168382/173481[48:00<01:28,57.81it/s] 97%|#########7|169121/173481[48:12<01:15,57.81it/s]100%|##########|173481/173481[49:27<00:00,58.47it/s]
[32m[0322 00:02:17 @base.py:257][0m Epoch 12 (global_step 2081772) finished, time:2967.23 sec.
[32m[0322 00:02:17 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-2081772.
[32m[0322 00:02:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.87it/s]
11
[32m[0322 00:04:10 @monitor.py:363][0m QueueInput/queue_size: 0.45053
[32m[0322 00:04:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 11.315
[32m[0322 00:04:10 @monitor.py:363][0m activation-summaries/output-rms: 0.039603
[32m[0322 00:04:10 @monitor.py:363][0m cross_entropy_loss: 1.7533
[32m[0322 00:04:10 @monitor.py:363][0m lr: 6.25e-05
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.71672
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7024
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.46748
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.48546
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061268
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.45529
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.43497
[32m[0322 00:04:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 00:04:10 @monitor.py:363][0m train-error-top1: 0.45346
[32m[0322 00:04:10 @monitor.py:363][0m val-error-top1: 0.53342
[32m[0322 00:04:10 @monitor.py:363][0m val-utt-error: 0.15848
[32m[0322 00:04:10 @monitor.py:363][0m validation_cost: 2.0931
[32m[0322 00:04:10 @monitor.py:363][0m wd_cost: 0.053877
[32m[0322 00:04:10 @group.py:42][0m Callbacks took 113.671 sec in total. InferenceRunner: 112.809sec
[32m[0322 00:04:10 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10999/173481[03:00<44:19,61.10it/s]  7%|6         |11647/173481[03:10<44:08,61.10it/s] 13%|#2        |21821/173481[06:00<41:42,60.61it/s] 13%|#2        |22439/173481[06:10<41:32,60.61it/s] 18%|#8        |32054/173481[09:00<40:10,58.67it/s] 19%|#8        |32648/173481[09:10<40:00,58.67it/s] 24%|##4       |42264/173481[12:00<37:55,57.67it/s] 25%|##4       |42863/173481[12:10<37:44,57.67it/s] 30%|###       |52609/173481[15:00<34:59,57.56it/s] 31%|###       |53198/173481[15:10<34:49,57.56it/s] 36%|###5      |61879/173481[18:00<34:12,54.36it/s] 36%|###6      |62539/173481[18:11<34:00,54.36it/s] 41%|####1     |71834/173481[21:00<30:54,54.82it/s] 42%|####1     |72423/173481[21:11<30:43,54.82it/s] 47%|####6     |80864/173481[24:00<29:27,52.39it/s] 47%|####7     |81543/173481[24:11<29:14,52.39it/s] 53%|#####2    |91497/173481[27:00<24:36,55.53it/s] 53%|#####3    |92133/173481[27:11<24:24,55.53it/s] 59%|#####8    |101604/173481[30:00<21:27,55.83it/s] 59%|#####8    |102253/173481[30:11<21:15,55.83it/s] 64%|######4   |111597/173481[33:00<18:31,55.67it/s] 65%|######4   |112313/173481[33:11<18:18,55.67it/s] 71%|#######   |122309/173481[36:00<14:49,57.53it/s] 71%|#######   |123003/173481[36:11<14:37,57.53it/s] 76%|#######6  |132279/173481[39:00<12:10,56.44it/s] 77%|#######6  |132918/173481[39:12<11:58,56.44it/s] 82%|########2 |142924/173481[42:00<08:49,57.75it/s] 83%|########2 |143673/173481[42:12<08:36,57.75it/s] 88%|########8 |153119/173481[45:00<05:56,57.19it/s] 89%|########8 |153777/173481[45:12<05:44,57.19it/s] 94%|#########3|162574/173481[48:00<03:19,54.75it/s] 94%|#########4|163253/173481[48:12<03:06,54.75it/s]100%|##########|173481/173481[50:58<00:00,56.71it/s]
[32m[0322 00:55:09 @base.py:257][0m Epoch 13 (global_step 2255253) finished, time:3058.92 sec.
[32m[0322 00:55:10 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-2255253.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,166.27it/s]
12
[32m[0322 00:57:03 @monitor.py:363][0m QueueInput/queue_size: 0.71407
[32m[0322 00:57:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 11.28
[32m[0322 00:57:03 @monitor.py:363][0m activation-summaries/output-rms: 0.039868
[32m[0322 00:57:03 @monitor.py:363][0m cross_entropy_loss: 1.7219
[32m[0322 00:57:03 @monitor.py:363][0m lr: 6.25e-05
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.77734
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7108
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.51185
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.51931
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.48789
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.46675
[32m[0322 00:57:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 00:57:03 @monitor.py:363][0m train-error-top1: 0.4555
[32m[0322 00:57:03 @monitor.py:363][0m val-error-top1: 0.52768
[32m[0322 00:57:03 @monitor.py:363][0m val-utt-error: 0.14866
[32m[0322 00:57:03 @monitor.py:363][0m validation_cost: 2.0452
[32m[0322 00:57:03 @monitor.py:363][0m wd_cost: 0.06304
[32m[0322 00:57:03 @group.py:42][0m Callbacks took 113.576 sec in total. InferenceRunner: 113.217sec
[32m[0322 00:57:03 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10978/173481[03:00<44:25,60.97it/s]  7%|6         |11562/173481[03:10<44:15,60.97it/s] 11%|#1        |19546/173481[06:00<47:59,53.46it/s] 12%|#1        |20017/173481[06:10<47:50,53.46it/s] 17%|#6        |28998/173481[09:00<45:27,52.98it/s] 17%|#7        |29516/173481[09:10<45:17,52.98it/s] 22%|##2       |38578/173481[12:00<42:20,53.10it/s] 23%|##2       |39152/173481[12:10<42:09,53.10it/s] 28%|##7       |48473/173481[15:00<38:34,54.01it/s] 28%|##8       |49067/173481[15:10<38:23,54.01it/s] 33%|###2      |56778/173481[18:00<39:05,49.76it/s] 33%|###3      |57367/173481[18:10<38:53,49.76it/s] 38%|###8      |66211/173481[21:00<35:01,51.05it/s] 38%|###8      |66653/173481[21:11<34:52,51.05it/s] 44%|####3     |76005/173481[24:00<30:50,52.67it/s] 44%|####4     |76576/173481[24:11<30:39,52.67it/s] 49%|####9     |85571/173481[27:00<27:41,52.91it/s] 50%|####9     |86063/173481[27:11<27:32,52.91it/s] 55%|#####5    |95615/173481[30:00<23:53,54.32it/s] 55%|#####5    |95982/173481[30:11<23:46,54.32it/s] 60%|######    |104878/173481[33:00<21:38,52.84it/s] 61%|######    |105389/173481[33:11<21:28,52.84it/s] 65%|######5   |113128/173481[36:00<20:29,49.09it/s] 66%|######5   |113798/173481[36:11<20:15,49.09it/s] 70%|#######   |122224/173481[39:00<17:09,49.80it/s] 71%|#######   |122668/173481[39:12<17:00,49.80it/s] 76%|#######5  |131448/173481[42:00<13:52,50.51it/s] 76%|#######6  |132109/173481[42:12<13:39,50.51it/s] 81%|########1 |140577/173481[45:00<10:50,50.61it/s] 81%|########1 |141180/173481[45:12<10:38,50.61it/s] 86%|########6 |149509/173481[48:00<07:58,50.11it/s] 87%|########6 |150147/173481[48:12<07:45,50.11it/s] 92%|#########1|159068/173481[51:00<04:39,51.56it/s] 92%|#########2|159807/173481[51:12<04:25,51.56it/s] 97%|#########7|168744/173481[54:00<01:29,52.64it/s] 98%|#########7|169392/173481[54:12<01:17,52.64it/s]100%|##########|173481/173481[55:37<00:00,51.98it/s]
[32m[0322 01:52:40 @base.py:257][0m Epoch 14 (global_step 2428734) finished, time:3337.59 sec.
[32m[0322 01:52:42 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-2428734.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.49it/s]
13
[32m[0322 01:54:43 @monitor.py:363][0m QueueInput/queue_size: 0.68923
[32m[0322 01:54:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 11.859
[32m[0322 01:54:43 @monitor.py:363][0m activation-summaries/output-rms: 0.040194
[32m[0322 01:54:43 @monitor.py:363][0m cross_entropy_loss: 1.7192
[32m[0322 01:54:43 @monitor.py:363][0m lr: 3.125e-05
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.82091
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7177
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.54059
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.54404
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.51205
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.49038
[32m[0322 01:54:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 01:54:43 @monitor.py:363][0m train-error-top1: 0.45516
[32m[0322 01:54:43 @monitor.py:363][0m val-error-top1: 0.51134
[32m[0322 01:54:43 @monitor.py:363][0m val-utt-error: 0.1383
[32m[0322 01:54:43 @monitor.py:363][0m validation_cost: 1.9774
[32m[0322 01:54:43 @monitor.py:363][0m wd_cost: 0.013976
[32m[0322 01:54:43 @group.py:42][0m Callbacks took 122.221 sec in total. InferenceRunner: 121.058sec
[32m[0322 01:54:43 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9662/173481[03:00<50:52,53.66it/s]  6%|5         |10163/173481[03:10<50:43,53.66it/s] 11%|#1        |19307/173481[06:00<47:55,53.62it/s] 11%|#1        |19914/173481[06:10<47:44,53.62it/s] 17%|#6        |28832/173481[09:00<45:15,53.26it/s] 17%|#6        |29401/173481[09:10<45:05,53.26it/s] 22%|##2       |38680/173481[12:00<41:37,53.98it/s] 23%|##2       |39296/173481[12:10<41:26,53.98it/s] 28%|##7       |47827/173481[15:00<40:00,52.34it/s] 28%|##7       |48463/173481[15:10<39:48,52.34it/s] 34%|###3      |58427/173481[18:00<34:36,55.42it/s] 34%|###4      |59091/173481[18:10<34:24,55.42it/s] 40%|###9      |68724/173481[21:00<31:00,56.30it/s] 40%|###9      |69306/173481[21:11<30:50,56.30it/s] 45%|####5     |78622/173481[24:00<28:25,55.62it/s] 46%|####5     |79261/173481[24:11<28:13,55.62it/s] 51%|#####     |88412/173481[27:00<25:46,55.00it/s] 51%|#####1    |89086/173481[27:11<25:34,55.00it/s] 57%|#####6    |98222/173481[30:00<22:54,54.75it/s] 57%|#####6    |98846/173481[30:11<22:43,54.75it/s] 63%|######2   |108557/173481[33:00<19:18,56.04it/s] 63%|######2   |109181/173481[33:11<19:07,56.04it/s] 68%|######8   |118357/173481[36:00<16:38,55.23it/s] 69%|######8   |118996/173481[36:11<16:26,55.23it/s] 74%|#######3  |128122/173481[39:00<13:48,54.73it/s] 74%|#######4  |128771/173481[39:12<13:36,54.73it/s] 80%|#######9  |138258/173481[42:00<10:34,55.51it/s] 80%|########  |138920/173481[42:12<10:22,55.51it/s] 85%|########5 |148212/173481[45:00<07:36,55.40it/s] 86%|########5 |148890/173481[45:12<07:23,55.40it/s] 91%|#########1|158276/173481[48:00<04:33,55.65it/s] 92%|#########1|158916/173481[48:12<04:21,55.65it/s] 97%|#########6|167879/173481[51:00<01:42,54.48it/s] 97%|#########7|168523/173481[51:12<01:31,54.48it/s]100%|##########|173481/173481[53:00<00:00,54.55it/s]
[32m[0322 02:47:43 @base.py:257][0m Epoch 15 (global_step 2602215) finished, time:3180.06 sec.
[32m[0322 02:47:43 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-2602215.
[32m[0322 02:47:44 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,170.41it/s]
14
[32m[0322 02:49:34 @monitor.py:363][0m QueueInput/queue_size: 0.4784
[32m[0322 02:49:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 11.94
[32m[0322 02:49:34 @monitor.py:363][0m activation-summaries/output-rms: 0.041051
[32m[0322 02:49:34 @monitor.py:363][0m cross_entropy_loss: 1.7015
[32m[0322 02:49:34 @monitor.py:363][0m lr: 3.125e-05
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.85594
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7212
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.56716
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.5619
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.52925
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.50716
[32m[0322 02:49:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 02:49:34 @monitor.py:363][0m train-error-top1: 0.44629
[32m[0322 02:49:34 @monitor.py:363][0m val-error-top1: 0.51471
[32m[0322 02:49:34 @monitor.py:363][0m val-utt-error: 0.14467
[32m[0322 02:49:34 @monitor.py:363][0m validation_cost: 1.9964
[32m[0322 02:49:34 @monitor.py:363][0m wd_cost: 0.015135
[32m[0322 02:49:34 @group.py:42][0m Callbacks took 111.475 sec in total. InferenceRunner: 110.465sec
[32m[0322 02:49:34 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10996/173481[03:01<44:40,60.61it/s]  7%|6         |12074/173481[03:20<44:23,60.61it/s] 12%|#2        |21583/173481[06:01<42:24,59.70it/s] 13%|#3        |22625/173481[06:20<42:07,59.70it/s] 18%|#8        |31707/173481[09:01<40:47,57.92it/s] 19%|#8        |32806/173481[09:20<40:28,57.92it/s] 24%|##4       |42024/173481[12:01<38:01,57.62it/s] 25%|##4       |43179/173481[12:20<37:41,57.62it/s] 30%|###       |52386/173481[15:01<35:02,57.58it/s] 31%|###       |53409/173481[15:20<34:45,57.58it/s] 36%|###6      |62836/173481[18:01<31:53,57.81it/s] 37%|###6      |63985/173481[18:20<31:33,57.81it/s] 42%|####2     |73066/173481[21:01<29:11,57.32it/s] 43%|####2     |74005/173481[21:21<28:55,57.32it/s] 48%|####7     |82526/173481[24:01<27:40,54.77it/s] 48%|####8     |83471/173481[24:21<27:23,54.77it/s] 52%|#####1    |89531/173481[27:01<30:45,45.49it/s] 52%|#####2    |90605/173481[27:21<30:21,45.49it/s] 57%|#####7    |99531/173481[30:02<24:38,50.02it/s] 58%|#####7    |100570/173481[30:21<24:17,50.02it/s] 63%|######3   |109777/173481[33:02<19:56,53.25it/s] 64%|######3   |110926/173481[33:21<19:34,53.25it/s] 69%|######9   |120002/173481[36:02<16:12,54.97it/s] 70%|######9   |121165/173481[36:21<15:51,54.97it/s] 75%|#######4  |130026/173481[39:02<13:05,55.32it/s] 75%|#######5  |130525/173481[39:12<12:56,55.32it/s] 81%|########  |140106/173481[42:02<09:59,55.65it/s] 81%|########1 |140676/173481[42:12<09:49,55.65it/s] 87%|########6 |150284/173481[45:02<06:53,56.09it/s] 87%|########6 |150899/173481[45:12<06:42,56.09it/s] 93%|#########2|160541/173481[48:02<03:48,56.53it/s] 93%|#########2|161147/173481[48:12<03:38,56.53it/s] 98%|#########8|170826/173481[51:02<00:46,56.83it/s] 99%|#########8|171438/173481[51:12<00:35,56.83it/s]100%|##########|173481/173481[51:48<00:00,55.81it/s]
[32m[0322 03:41:23 @base.py:257][0m Epoch 16 (global_step 2775696) finished, time:3108.39 sec.
[32m[0322 03:41:23 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-2775696.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.61it/s]
15
[32m[0322 03:43:22 @monitor.py:363][0m QueueInput/queue_size: 0.72999
[32m[0322 03:43:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 11.872
[32m[0322 03:43:22 @monitor.py:363][0m activation-summaries/output-rms: 0.039975
[32m[0322 03:43:22 @monitor.py:363][0m cross_entropy_loss: 1.6896
[32m[0322 03:43:22 @monitor.py:363][0m lr: 3.125e-05
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.88976
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.725
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.59203
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.57971
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.54646
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.52397
[32m[0322 03:43:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 03:43:22 @monitor.py:363][0m train-error-top1: 0.44436
[32m[0322 03:43:22 @monitor.py:363][0m val-error-top1: 0.52034
[32m[0322 03:43:22 @monitor.py:363][0m val-utt-error: 0.15556
[32m[0322 03:43:22 @monitor.py:363][0m validation_cost: 2.0249
[32m[0322 03:43:22 @monitor.py:363][0m wd_cost: 0.016299
[32m[0322 03:43:22 @group.py:42][0m Callbacks took 119.054 sec in total. InferenceRunner: 118.685sec
[32m[0322 03:43:22 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10472/173481[03:00<46:42,58.18it/s]  6%|6         |11059/173481[03:10<46:31,58.18it/s] 12%|#2        |20960/173481[06:00<43:39,58.22it/s] 12%|#2        |21535/173481[06:10<43:29,58.22it/s] 18%|#7        |30800/173481[09:00<42:10,56.38it/s] 18%|#8        |31350/173481[09:10<42:00,56.38it/s] 23%|##2       |39270/173481[12:00<43:37,51.28it/s] 23%|##2       |39799/173481[12:10<43:27,51.28it/s] 28%|##7       |48286/173481[15:00<41:10,50.68it/s] 28%|##8       |48818/173481[15:10<41:00,50.68it/s] 33%|###3      |57827/173481[18:00<37:12,51.81it/s] 34%|###3      |58429/173481[18:10<37:00,51.81it/s] 39%|###8      |67370/173481[21:00<33:44,52.41it/s] 39%|###9      |67974/173481[21:11<33:33,52.41it/s] 45%|####4     |77779/173481[24:00<29:00,54.98it/s] 45%|####5     |78415/173481[24:11<28:49,54.98it/s] 50%|#####     |87274/173481[27:00<26:41,53.84it/s] 51%|#####     |87924/173481[27:11<26:29,53.84it/s] 56%|#####6    |97265/173481[30:00<23:14,54.66it/s] 56%|#####6    |97892/173481[30:11<23:02,54.66it/s] 62%|######1   |107325/173481[33:00<19:57,55.26it/s] 62%|######2   |107965/173481[33:11<19:45,55.26it/s] 68%|######7   |117366/173481[36:00<16:50,55.52it/s] 68%|######8   |117999/173481[36:11<16:39,55.52it/s] 73%|#######3  |127355/173481[39:00<13:51,55.50it/s] 74%|#######3  |128004/173481[39:11<13:39,55.50it/s] 79%|#######8  |136320/173481[42:00<11:47,52.49it/s] 79%|#######8  |136939/173481[42:12<11:36,52.49it/s] 84%|########4 |145933/173481[45:00<08:40,52.94it/s] 85%|########4 |146619/173481[45:12<08:27,52.94it/s] 90%|########9 |155904/173481[48:00<05:24,54.14it/s] 90%|######### |156599/173481[48:12<05:11,54.14it/s] 96%|#########5|166231/173481[51:00<02:10,55.71it/s] 96%|#########6|166948/173481[51:12<01:57,55.71it/s]100%|##########|173481/173481[53:21<00:00,54.20it/s]
[32m[0322 04:36:43 @base.py:257][0m Epoch 17 (global_step 2949177) finished, time:3201.01 sec.
[32m[0322 04:36:43 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-2949177.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.83it/s]
16
[32m[0322 04:38:46 @monitor.py:363][0m QueueInput/queue_size: 0.64799
[32m[0322 04:38:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.325
[32m[0322 04:38:46 @monitor.py:363][0m activation-summaries/output-rms: 0.040133
[32m[0322 04:38:46 @monitor.py:363][0m cross_entropy_loss: 1.7034
[32m[0322 04:38:46 @monitor.py:363][0m lr: 1.5625e-05
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.91165
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7278
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/linear0/W-rms: 0.60759
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59096
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.55732
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.53459
[32m[0322 04:38:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 04:38:46 @monitor.py:363][0m train-error-top1: 0.45336
[32m[0322 04:38:46 @monitor.py:363][0m val-error-top1: 0.50947
[32m[0322 04:38:46 @monitor.py:363][0m val-utt-error: 0.13856
[32m[0322 04:38:46 @monitor.py:363][0m validation_cost: 1.9717
[32m[0322 04:38:46 @monitor.py:363][0m wd_cost: 0.0034117
[32m[0322 04:38:46 @group.py:42][0m Callbacks took 123.451 sec in total. InferenceRunner: 123.178sec
[32m[0322 04:38:46 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11418/173481[03:00<42:35,63.43it/s]  7%|6         |12090/173481[03:10<42:24,63.43it/s] 13%|#2        |22429/173481[06:00<40:25,62.28it/s] 13%|#3        |23073/173481[06:10<40:15,62.28it/s] 18%|#8        |31478/173481[09:00<42:32,55.63it/s] 18%|#8        |32049/173481[09:10<42:22,55.63it/s] 23%|##3       |40444/173481[12:00<42:11,52.56it/s] 24%|##3       |41013/173481[12:10<42:00,52.56it/s] 29%|##8       |50049/173481[15:00<38:51,52.95it/s] 29%|##9       |50590/173481[15:10<38:40,52.95it/s] 34%|###4      |59534/173481[18:00<35:57,52.82it/s] 35%|###4      |60118/173481[18:10<35:46,52.82it/s] 40%|####      |69810/173481[21:00<31:29,54.87it/s] 41%|####      |70365/173481[21:11<31:19,54.87it/s] 46%|####6     |80454/173481[24:00<27:14,56.92it/s] 47%|####6     |81142/173481[24:11<27:02,56.92it/s] 52%|#####2    |90634/173481[27:00<24:20,56.73it/s] 53%|#####2    |91325/173481[27:11<24:08,56.73it/s] 58%|#####8    |100954/173481[30:00<21:12,57.02it/s] 59%|#####8    |101573/173481[30:11<21:01,57.02it/s] 64%|######4   |111319/173481[33:00<18:05,57.28it/s] 65%|######4   |112010/173481[33:11<17:53,57.28it/s] 70%|#######   |122024/173481[36:00<14:41,58.36it/s] 71%|#######   |122643/173481[36:11<14:31,58.36it/s] 76%|#######6  |131914/173481[39:00<12:14,56.60it/s] 76%|#######6  |132593/173481[39:12<12:02,56.60it/s] 82%|########1 |141659/173481[42:00<09:35,55.34it/s] 82%|########2 |142373/173481[42:12<09:22,55.34it/s] 88%|########7 |152597/173481[45:00<06:00,57.92it/s] 88%|########8 |153310/173481[45:12<05:48,57.92it/s] 94%|#########4|163340/173481[48:00<02:52,58.79it/s] 95%|#########4|164126/173481[48:12<02:39,58.79it/s]100%|##########|173481/173481[50:45<00:00,56.97it/s]
[32m[0322 05:29:31 @base.py:257][0m Epoch 18 (global_step 3122658) finished, time:3045.07 sec.
[32m[0322 05:29:32 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-3122658.
[32m[0322 05:29:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.52it/s]
17
[32m[0322 05:31:31 @monitor.py:363][0m QueueInput/queue_size: 0.85344
[32m[0322 05:31:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.144
[32m[0322 05:31:31 @monitor.py:363][0m activation-summaries/output-rms: 0.040082
[32m[0322 05:31:31 @monitor.py:363][0m cross_entropy_loss: 1.6682
[32m[0322 05:31:31 @monitor.py:363][0m lr: 1.5625e-05
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.92897
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7297
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.62024
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.59972
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.56577
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.54287
[32m[0322 05:31:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 05:31:31 @monitor.py:363][0m train-error-top1: 0.44117
[32m[0322 05:31:31 @monitor.py:363][0m val-error-top1: 0.50459
[32m[0322 05:31:31 @monitor.py:363][0m val-utt-error: 0.13256
[32m[0322 05:31:31 @monitor.py:363][0m validation_cost: 1.9396
[32m[0322 05:31:31 @monitor.py:363][0m wd_cost: 0.0035349
[32m[0322 05:31:31 @group.py:42][0m Callbacks took 119.627 sec in total. InferenceRunner: 118.750sec
[32m[0322 05:31:31 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11502/173481[03:00<42:14,63.90it/s]  7%|6         |12101/173481[03:10<42:05,63.90it/s] 13%|#2        |22328/173481[06:00<40:39,61.96it/s] 13%|#3        |22997/173481[06:10<40:28,61.96it/s] 19%|#8        |32782/173481[09:00<39:06,59.95it/s] 19%|#9        |33354/173481[09:10<38:57,59.95it/s] 25%|##5       |43610/173481[12:00<36:02,60.05it/s] 26%|##5       |44267/173481[12:10<35:51,60.05it/s] 31%|###1      |54337/173481[15:00<33:11,59.82it/s] 32%|###1      |54937/173481[15:10<33:01,59.82it/s] 38%|###7      |65197/173481[18:00<30:02,60.08it/s] 38%|###7      |65852/173481[18:10<29:51,60.08it/s] 44%|####3     |75895/173481[21:00<27:13,59.75it/s] 44%|####4     |76577/173481[21:11<27:01,59.75it/s] 50%|####9     |86708/173481[24:00<24:08,59.91it/s] 50%|#####     |87424/173481[24:11<23:56,59.91it/s] 56%|#####5    |96973/173481[27:00<21:49,58.43it/s] 56%|#####6    |97627/173481[27:11<21:38,58.43it/s] 62%|######2   |108308/173481[30:00<17:55,60.61it/s] 63%|######2   |109030/173481[30:11<17:43,60.61it/s] 69%|######9   |119718/173481[33:00<14:27,61.97it/s] 69%|######9   |120402/173481[33:11<14:16,61.97it/s] 75%|#######5  |130773/173481[36:00<11:32,61.68it/s] 76%|#######5  |131496/173481[36:11<11:20,61.68it/s] 82%|########1 |141933/173481[39:00<08:30,61.83it/s] 82%|########2 |142652/173481[39:12<08:18,61.83it/s] 88%|########7 |152218/173481[42:00<05:58,59.39it/s] 88%|########8 |152975/173481[42:12<05:45,59.39it/s] 94%|#########4|163378/173481[45:00<02:46,60.66it/s] 95%|#########4|164076/173481[45:12<02:35,60.66it/s]100%|##########|173481/173481[47:59<00:00,60.26it/s]
[32m[0322 06:19:30 @base.py:257][0m Epoch 19 (global_step 3296139) finished, time:2879.05 sec.
[32m[0322 06:19:30 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-3296139.
[32m[0322 06:19:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,171.55it/s]
18
[32m[0322 06:21:21 @monitor.py:363][0m QueueInput/queue_size: 0.51686
[32m[0322 06:21:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.184
[32m[0322 06:21:21 @monitor.py:363][0m activation-summaries/output-rms: 0.040491
[32m[0322 06:21:21 @monitor.py:363][0m cross_entropy_loss: 1.7003
[32m[0322 06:21:21 @monitor.py:363][0m lr: 1.5625e-05
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.9461
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7317
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/linear0/W-rms: 0.63265
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.60856
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.57433
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.55121
[32m[0322 06:21:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 06:21:21 @monitor.py:363][0m train-error-top1: 0.44964
[32m[0322 06:21:21 @monitor.py:363][0m val-error-top1: 0.50665
[32m[0322 06:21:21 @monitor.py:363][0m val-utt-error: 0.13452
[32m[0322 06:21:21 @monitor.py:363][0m validation_cost: 1.9588
[32m[0322 06:21:21 @monitor.py:363][0m wd_cost: 0.0036595
[32m[0322 06:21:21 @group.py:42][0m Callbacks took 110.718 sec in total. InferenceRunner: 109.733sec
[32m[0322 06:21:21 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10952/173481[03:00<44:31,60.83it/s]  7%|6         |11550/173481[03:10<44:21,60.83it/s] 12%|#2        |21240/173481[06:00<43:03,58.94it/s] 13%|#2        |21815/173481[06:10<42:53,58.94it/s] 18%|#8        |32055/173481[09:00<39:36,59.50it/s] 19%|#8        |32696/173481[09:10<39:25,59.50it/s] 25%|##4       |43250/173481[12:00<35:41,60.82it/s] 25%|##5       |43906/173481[12:10<35:30,60.82it/s] 31%|###1      |54333/173481[15:00<32:27,61.19it/s] 32%|###1      |55006/173481[15:10<32:16,61.19it/s] 37%|###7      |64860/173481[18:00<30:16,59.81it/s] 38%|###7      |65584/173481[18:10<30:04,59.81it/s] 44%|####3     |76185/173481[21:00<26:26,61.32it/s] 44%|####4     |76889/173481[21:11<26:15,61.32it/s] 50%|#####     |87280/173481[24:00<23:22,61.48it/s] 51%|#####     |87926/173481[24:11<23:11,61.48it/s] 57%|#####6    |98319/173481[27:00<20:24,61.40it/s] 57%|#####7    |99061/173481[27:11<20:12,61.40it/s] 63%|######3   |109572/173481[30:00<17:11,61.94it/s] 64%|######3   |110291/173481[30:11<17:00,61.94it/s] 69%|######9   |120109/173481[33:00<14:46,60.19it/s] 70%|######9   |120866/173481[33:11<14:34,60.19it/s] 76%|#######5  |131420/173481[36:00<11:24,61.49it/s] 76%|#######6  |132146/173481[36:11<11:12,61.49it/s] 82%|########2 |142583/173481[39:00<08:20,61.75it/s] 83%|########2 |143356/173481[39:12<08:07,61.75it/s] 89%|########8 |154312/173481[42:00<05:02,63.41it/s] 89%|########9 |155106/173481[42:12<04:49,63.41it/s] 95%|#########5|164965/173481[45:00<02:19,61.22it/s] 95%|#########5|165635/173481[45:12<02:08,61.22it/s]100%|##########|173481/173481[47:26<00:00,60.94it/s]
[32m[0322 07:08:48 @base.py:257][0m Epoch 20 (global_step 3469620) finished, time:2846.94 sec.
[32m[0322 07:08:48 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-3469620.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,174.68it/s]
19
[32m[0322 07:10:36 @monitor.py:363][0m QueueInput/queue_size: 0.69956
[32m[0322 07:10:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.424
[32m[0322 07:10:36 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0322 07:10:36 @monitor.py:363][0m cross_entropy_loss: 1.6479
[32m[0322 07:10:36 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.95484
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7327
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.63874
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.61289
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.57848
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.55528
[32m[0322 07:10:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 07:10:36 @monitor.py:363][0m train-error-top1: 0.42935
[32m[0322 07:10:36 @monitor.py:363][0m val-error-top1: 0.50268
[32m[0322 07:10:36 @monitor.py:363][0m val-utt-error: 0.13431
[32m[0322 07:10:36 @monitor.py:363][0m validation_cost: 1.9428
[32m[0322 07:10:36 @monitor.py:363][0m wd_cost: 0.00074438
[32m[0322 07:10:36 @group.py:42][0m Callbacks took 108.019 sec in total. InferenceRunner: 107.764sec
[32m[0322 07:10:36 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11761/173481[03:00<41:15,65.32it/s]  7%|7         |12394/173481[03:10<41:05,65.32it/s] 13%|#3        |22981/173481[06:00<39:19,63.78it/s] 14%|#3        |23640/173481[06:10<39:09,63.78it/s] 19%|#9        |33293/173481[09:00<38:42,60.36it/s] 20%|#9        |33880/173481[09:10<38:32,60.36it/s] 25%|##5       |43540/173481[12:00<36:57,58.59it/s] 25%|##5       |44159/173481[12:10<36:47,58.59it/s] 31%|###       |53674/173481[15:00<34:46,57.42it/s] 31%|###1      |54307/173481[15:10<34:35,57.42it/s] 37%|###7      |64712/173481[18:00<30:34,59.31it/s] 38%|###7      |65391/173481[18:10<30:22,59.31it/s] 43%|####3     |75196/173481[21:00<27:52,58.76it/s] 44%|####3     |75834/173481[21:11<27:41,58.76it/s] 49%|####8     |84924/173481[24:00<26:12,56.30it/s] 49%|####9     |85555/173481[24:11<26:01,56.30it/s] 55%|#####4    |95007/173481[27:00<23:17,56.16it/s] 55%|#####5    |95705/173481[27:11<23:04,56.16it/s] 61%|######1   |105996/173481[30:00<19:13,58.50it/s] 61%|######1   |106683/173481[30:11<19:01,58.50it/s] 67%|######7   |116441/173481[33:00<16:19,58.26it/s] 68%|######7   |117102/173481[33:11<16:07,58.26it/s] 73%|#######2  |125931/173481[36:00<14:19,55.35it/s] 73%|#######3  |126661/173481[36:11<14:05,55.35it/s] 79%|#######9  |137161/173481[39:00<10:19,58.66it/s] 79%|#######9  |137916/173481[39:12<10:06,58.66it/s] 85%|########5 |148264/173481[42:00<06:59,60.13it/s] 86%|########5 |149007/173481[42:12<06:47,60.13it/s] 92%|#########1|159371/173481[45:00<03:51,60.91it/s] 92%|#########2|160144/173481[45:12<03:38,60.91it/s] 98%|#########8|170366/173481[48:00<00:51,60.99it/s] 99%|#########8|171110/173481[48:12<00:38,60.99it/s]100%|##########|173481/173481[48:52<00:00,59.15it/s]
[32m[0322 07:59:28 @base.py:257][0m Epoch 21 (global_step 3643101) finished, time:2932.82 sec.
[32m[0322 07:59:29 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-3643101.
[32m[0322 07:59:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,169.47it/s]
20
[32m[0322 08:01:20 @monitor.py:363][0m QueueInput/queue_size: 0.45645
[32m[0322 08:01:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.298
[32m[0322 08:01:20 @monitor.py:363][0m activation-summaries/output-rms: 0.040776
[32m[0322 08:01:20 @monitor.py:363][0m cross_entropy_loss: 1.6964
[32m[0322 08:01:20 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.96328
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7337
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64474
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.61716
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.58262
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.55932
[32m[0322 08:01:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 08:01:20 @monitor.py:363][0m train-error-top1: 0.44414
[32m[0322 08:01:20 @monitor.py:363][0m val-error-top1: 0.50626
[32m[0322 08:01:20 @monitor.py:363][0m val-utt-error: 0.13622
[32m[0322 08:01:20 @monitor.py:363][0m validation_cost: 1.9564
[32m[0322 08:01:20 @monitor.py:363][0m wd_cost: 0.00075674
[32m[0322 08:01:20 @group.py:42][0m Callbacks took 112.104 sec in total. InferenceRunner: 111.080sec
[32m[0322 08:01:20 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12425/173481[03:00<38:53,69.02it/s]  8%|7         |13046/173481[03:10<38:44,69.02it/s] 14%|#3        |24005/173481[06:00<37:24,66.59it/s] 14%|#4        |24599/173481[06:10<37:15,66.59it/s] 20%|#9        |34660/173481[09:00<36:55,62.67it/s] 20%|##        |35169/173481[09:10<36:46,62.67it/s] 26%|##5       |44582/173481[12:00<36:37,58.65it/s] 26%|##6       |45144/173481[12:10<36:28,58.65it/s] 32%|###1      |55234/173481[15:00<33:27,58.91it/s] 32%|###2      |55906/173481[15:10<33:15,58.91it/s] 38%|###8      |66384/173481[18:00<29:33,60.39it/s] 39%|###8      |67066/173481[18:11<29:22,60.39it/s] 45%|####4     |77900/173481[21:00<25:38,62.13it/s] 45%|####5     |78574/173481[21:11<25:27,62.13it/s] 51%|#####1    |88710/173481[24:00<23:08,61.06it/s] 52%|#####1    |89414/173481[24:11<22:56,61.06it/s] 58%|#####7    |99845/173481[27:00<19:58,61.46it/s] 58%|#####7    |100539/173481[27:11<19:46,61.46it/s] 64%|######4   |111440/173481[30:00<16:26,62.90it/s] 65%|######4   |112149/173481[30:11<16:15,62.90it/s] 71%|#######   |122645/173481[33:00<13:32,62.57it/s] 71%|#######1  |123384/173481[33:11<13:20,62.57it/s] 77%|#######7  |133684/173481[36:00<10:42,61.94it/s] 77%|#######7  |134309/173481[36:11<10:32,61.94it/s] 83%|########3 |144808/173481[39:00<07:43,61.87it/s] 84%|########3 |145521/173481[39:12<07:31,61.87it/s] 90%|######### |156261/173481[42:00<04:34,62.74it/s] 90%|######### |156994/173481[42:12<04:22,62.74it/s] 97%|#########6|167497/173481[45:00<01:35,62.58it/s] 97%|#########7|168291/173481[45:12<01:22,62.58it/s]100%|##########|173481/173481[46:32<00:00,62.12it/s]
[32m[0322 08:47:53 @base.py:257][0m Epoch 22 (global_step 3816582) finished, time:2792.81 sec.
[32m[0322 08:47:54 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-3816582.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.68it/s]
21
[32m[0322 08:49:46 @monitor.py:363][0m QueueInput/queue_size: 0.38987
[32m[0322 08:49:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.646
[32m[0322 08:49:46 @monitor.py:363][0m activation-summaries/output-rms: 0.040488
[32m[0322 08:49:46 @monitor.py:363][0m cross_entropy_loss: 1.6672
[32m[0322 08:49:46 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.97067
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7345
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/linear0/W-rms: 0.64992
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.62091
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.58625
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.56286
[32m[0322 08:49:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 08:49:46 @monitor.py:363][0m train-error-top1: 0.43966
[32m[0322 08:49:46 @monitor.py:363][0m val-error-top1: 0.49677
[32m[0322 08:49:46 @monitor.py:363][0m val-utt-error: 0.12953
[32m[0322 08:49:46 @monitor.py:363][0m validation_cost: 1.9069
[32m[0322 08:49:46 @monitor.py:363][0m wd_cost: 0.0007676
[32m[0322 08:49:46 @group.py:42][0m Callbacks took 112.558 sec in total. InferenceRunner: 112.259sec
[32m[0322 08:49:46 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11952/173481[03:00<40:32,66.40it/s]  7%|7         |12623/173481[03:10<40:22,66.40it/s] 14%|#3        |23764/173481[06:00<37:48,66.00it/s] 14%|#4        |24378/173481[06:10<37:39,66.00it/s] 20%|#9        |34599/173481[09:00<36:46,62.96it/s] 20%|##        |35243/173481[09:10<36:35,62.96it/s] 26%|##6       |45487/173481[12:00<34:34,61.70it/s] 27%|##6       |46111/173481[12:10<34:24,61.70it/s] 32%|###2      |56220/173481[15:00<32:13,60.64it/s] 33%|###2      |56893/173481[15:10<32:02,60.64it/s] 39%|###8      |67377/173481[18:00<28:50,61.31it/s] 39%|###9      |68065/173481[18:11<28:39,61.31it/s] 46%|####5     |79296/173481[21:00<24:39,63.67it/s] 46%|####6     |80028/173481[21:11<24:27,63.67it/s] 52%|#####2    |90824/173481[24:00<21:34,63.85it/s] 53%|#####2    |91584/173481[24:11<21:22,63.85it/s]srun: error: slurm_receive_msg: Socket timed out on send/recv operation
srun: error: slurm_receive_msg[5.101.40.8]: Socket timed out on send/recv operation
 59%|#####8    |102210/173481[27:00<18:41,63.55it/s] 59%|#####9    |102973/173481[27:11<18:29,63.55it/s] 66%|######5   |114039/173481[30:00<15:20,64.61it/s] 66%|######6   |114805/173481[30:11<15:08,64.61it/s] 72%|#######2  |125094/173481[33:00<12:48,62.96it/s] 73%|#######2  |125799/173481[33:11<12:37,62.96it/s] 79%|#######8  |136634/173481[36:00<09:39,63.53it/s] 79%|#######9  |137413/173481[36:12<09:27,63.53it/s] 86%|########5 |148431/173481[39:00<06:28,64.52it/s] 86%|########6 |149219/173481[39:12<06:16,64.52it/s] 92%|#########2|160429/173481[42:00<03:19,65.57it/s] 93%|#########2|161238/173481[42:12<03:06,65.57it/s] 99%|#########9|172389/173481[45:00<00:16,66.00it/s]100%|#########9|173125/173481[45:12<00:05,66.00it/s]100%|##########|173481/173481[45:17<00:00,63.83it/s]
[32m[0322 09:35:04 @base.py:257][0m Epoch 23 (global_step 3990063) finished, time:2717.95 sec.
[32m[0322 09:35:04 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-3990063.
[32m[0322 09:35:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,168.34it/s]
22
[32m[0322 09:36:56 @monitor.py:363][0m QueueInput/queue_size: 0.58202
[32m[0322 09:36:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.394
[32m[0322 09:36:56 @monitor.py:363][0m activation-summaries/output-rms: 0.040343
[32m[0322 09:36:56 @monitor.py:363][0m cross_entropy_loss: 1.6649
[32m[0322 09:36:56 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.97471
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.735
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.65267
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.62294
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.58821
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.56479
[32m[0322 09:36:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 09:36:56 @monitor.py:363][0m train-error-top1: 0.45249
[32m[0322 09:36:56 @monitor.py:363][0m val-error-top1: 0.49611
[32m[0322 09:36:56 @monitor.py:363][0m val-utt-error: 0.12517
[32m[0322 09:36:56 @monitor.py:363][0m validation_cost: 1.9034
[32m[0322 09:36:56 @monitor.py:363][0m wd_cost: 0.0001547
[32m[0322 09:36:56 @group.py:42][0m Callbacks took 112.598 sec in total. InferenceRunner: 111.826sec
[32m[0322 09:36:56 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11715/173481[03:00<41:25,65.08it/s]  7%|7         |12387/173481[03:10<41:15,65.08it/s] 13%|#3        |22716/173481[06:00<39:51,63.04it/s] 13%|#3        |23372/173481[06:10<39:41,63.04it/s] 20%|#9        |34128/173481[09:00<36:44,63.22it/s] 20%|##        |34872/173481[09:10<36:32,63.22it/s] 27%|##6       |46139/173481[12:00<32:41,64.92it/s] 27%|##7       |46882/173481[12:10<32:29,64.92it/s] 33%|###3      |57948/173481[15:00<29:30,65.26it/s] 34%|###3      |58662/173481[15:10<29:19,65.26it/s] 41%|####      |70383/173481[18:00<25:36,67.11it/s] 41%|####1     |71133/173481[18:11<25:25,67.11it/s] 48%|####7     |82583/173481[21:00<22:27,67.44it/s] 48%|####8     |83282/173481[21:11<22:17,67.44it/s] 54%|#####4    |94178/173481[24:00<20:03,65.89it/s] 55%|#####4    |94927/173481[24:11<19:52,65.89it/s] 61%|######1   |106105/173481[27:00<16:59,66.07it/s] 62%|######1   |106863/173481[27:11<16:48,66.07it/s] 68%|######8   |117968/173481[30:00<14:01,65.95it/s] 68%|######8   |118752/173481[30:11<13:49,65.95it/s] 75%|#######4  |129758/173481[33:00<11:05,65.73it/s] 75%|#######5  |130557/173481[33:11<10:53,65.73it/s] 82%|########1 |141958/173481[36:00<07:52,66.73it/s] 82%|########2 |142672/173481[36:12<07:41,66.73it/s] 89%|########8 |153873/173481[39:00<04:55,66.45it/s] 89%|########9 |154583/173481[39:12<04:44,66.45it/s] 95%|#########5|165573/173481[42:00<02:00,65.71it/s] 96%|#########5|166276/173481[42:12<01:49,65.71it/s]100%|##########|173481/173481[44:09<00:00,65.47it/s]
[32m[0322 10:21:06 @base.py:257][0m Epoch 24 (global_step 4163544) finished, time:2649.94 sec.
[32m[0322 10:21:07 @saver.py:84][0m Model saved to train_log/fcn2_w_2_a_32_quant_ends_True/model-4163544.
[32m[0322 10:21:07 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,170.89it/s]
23
[32m[0322 10:22:57 @monitor.py:363][0m QueueInput/queue_size: 0.42824
[32m[0322 10:22:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.434
[32m[0322 10:22:57 @monitor.py:363][0m activation-summaries/output-rms: 0.040832
[32m[0322 10:22:57 @monitor.py:363][0m cross_entropy_loss: 1.6705
[32m[0322 10:22:57 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.97877
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.7356
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.65546
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.062847
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.62502
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061267
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.59023
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061906
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.56677
[32m[0322 10:22:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.061345
[32m[0322 10:22:57 @monitor.py:363][0m train-error-top1: 0.43787
[32m[0322 10:22:57 @monitor.py:363][0m val-error-top1: 0.50561
[32m[0322 10:22:57 @monitor.py:363][0m val-utt-error: 0.13298
[32m[0322 10:22:57 @monitor.py:363][0m validation_cost: 1.948
[32m[0322 10:22:57 @monitor.py:363][0m wd_cost: 0.0001559
[32m[0322 10:22:57 @group.py:42][0m Callbacks took 110.865 sec in total. InferenceRunner: 110.151sec
[32m[0322 10:22:57 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11337/173481[03:00<42:54,62.98it/s]  7%|6         |11931/173481[03:10<42:44,62.98it/s] 13%|#2        |22532/173481[06:00<40:11,62.59it/s] 13%|#3        |23088/173481[06:10<40:02,62.59it/s] 20%|#9        |34237/173481[09:00<36:23,63.78it/s] 20%|##        |34922/173481[09:10<36:12,63.78it/s] 27%|##6       |46167/173481[12:00<32:38,65.00it/s] 27%|##7       |46861/173481[12:10<32:27,65.00it/s] 34%|###3      |58337/173481[15:00<28:57,66.28it/s] 34%|###4      |59083/173481[15:10<28:45,66.28it/s] 41%|####      |70294/173481[18:00<25:55,66.35it/s] 41%|####      |71016/173481[18:11<25:44,66.35it/s] 47%|####7     |82067/173481[21:00<23:07,65.87it/s] 48%|####7     |82741/173481[21:11<22:57,65.87it/s] 54%|#####4    |94017/173481[24:00<20:01,66.12it/s] 55%|#####4    |94721/173481[24:11<19:51,66.12it/s]srun: got SIGCONT
slurmstepd: *** STEP 82216.0 ON sls-sm-3 CANCELLED AT 2018-03-22T10:49:09 ***
slurmstepd: *** JOB 82216 ON sls-sm-3 CANCELLED AT 2018-03-22T10:49:09 ***
srun: forcing job termination
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
