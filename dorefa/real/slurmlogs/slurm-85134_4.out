sls-sm-3 1
SLURM_JOBID=85138
SLURM_TASKID=4
[32m[0328 11:32:07 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=16 --bita=32 --quant_ends=True --load_ckpt=train_log/lcn_w_16_a_32_quant_ends_False/checkpoint
[32m[0328 11:32:26 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 11:32:26 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 11:32:27 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 11:32:27 @drf_run.py:166][0m Using host: sls-sm-3
[32m[0328 11:32:27 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 11:32:27 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 11:32:27 @drf_run.py:188][0m Using GPU: 1
[32m[0328 11:32:27 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 11:32:27 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 11:32:27 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 11:32:27 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0a/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0a/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0b/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0b/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0c/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0c/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0d/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0d/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0e/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0e/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0f/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0f/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0g/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0g/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0h/W
[32m[0328 11:32:27 @drf_run.py:70][0m Quantizing weight conv0h/b
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0328 11:32:27 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0328 11:32:27 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0328 11:32:27 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight conv0i/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight conv0i/b
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0328 11:32:28 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0328 11:32:28 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight conv0j/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight conv0j/b
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0328 11:32:28 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0328 11:32:28 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:32:28 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 11:32:28 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:32:28 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 11:32:28 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:32:28 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:32:28 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 11:32:28 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:32:28 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:32:28 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 11:32:28 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:32:28 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0328 11:32:28 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 11:32:28 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0328 11:32:30 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0328 11:32:30 @base.py:196][0m Setup callbacks graph ...
[32m[0328 11:32:31 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0a/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0a/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0b/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0b/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0c/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0c/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0d/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0d/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0e/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0e/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0f/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0f/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0g/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0g/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0h/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0h/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0i/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0i/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0j/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight conv0j/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:32:31 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:32:31 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:32:31 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:32:31 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0328 11:32:31 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 11:32:31 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0328 11:32:33 @base.py:212][0m Creating the session ...
2018-03-28 11:32:33.979364: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-28 11:32:35.472360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:03:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-28 11:32:35.472398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
[32m[0328 11:32:40 @base.py:220][0m Initializing the session ...
[32m[0328 11:32:40 @sessinit.py:116][0m Restoring checkpoint from train_log/lcn_w_16_a_32_quant_ends_False/model-9194493 ...
[32m[0328 11:32:41 @base.py:227][0m Graph Finalized.
[32m[0328 11:32:41 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 11:32:41 @steps.py:127][0m Start training with global_step=9194493
[32m[0328 11:32:45 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10207/173481[03:00<47:59,56.70it/s]  6%|6         |10808/173481[03:10<47:48,56.70it/s]  9%|9         |16331/173481[06:01<1:01:50,42.36it/s]  9%|9         |16375/173481[06:20<1:01:49,42.36it/s] 10%|9         |16726/173481[09:06<10:42:32, 4.07it/s] 10%|9         |16751/173481[09:20<10:42:26, 4.07it/s] 10%|9         |17161/173481[12:11<14:34:15, 2.98it/s] 10%|9         |17250/173481[12:30<14:33:45, 2.98it/s] 10%|#         |18201/173481[15:11<10:58:11, 3.93it/s] 11%|#         |18320/173481[15:30<10:57:40, 3.93it/s] 15%|#5        |26653/173481[18:11<5:37:14, 7.26it/s]  16%|#5        |27737/173481[18:31<5:34:45, 7.26it/s] 21%|##        |36429/173481[21:11<2:58:25,12.80it/s] 21%|##1       |36970/173481[21:21<2:57:43,12.80it/s] 27%|##6       |46149/173481[24:11<1:42:32,20.70it/s] 27%|##6       |46696/173481[24:21<1:42:05,20.70it/s] 32%|###2      |55789/173481[27:11<1:05:42,29.86it/s] 32%|###2      |56334/173481[27:21<1:05:23,29.86it/s] 38%|###7      |65445/173481[30:11<46:56,38.36it/s]   38%|###8      |66013/173481[30:21<46:41,38.36it/s] 43%|####3     |75296/173481[33:11<36:16,45.10it/s] 44%|####3     |75880/173481[33:21<36:03,45.10it/s] 49%|####9     |85040/173481[36:11<29:57,49.21it/s] 49%|####9     |85610/173481[36:21<29:45,49.21it/s] 55%|#####4    |94817/173481[39:11<25:23,51.63it/s] 55%|#####4    |95413/173481[39:22<25:11,51.63it/s] 60%|######    |104609/173481[42:11<21:39,52.98it/s] 61%|######    |105211/173481[42:22<21:28,52.98it/s] 66%|######5   |114406/173481[45:11<18:20,53.69it/s] 66%|######6   |115013/173481[45:22<18:08,53.69it/s] 72%|#######1  |124252/173481[48:11<15:08,54.19it/s] 72%|#######1  |124868/173481[48:22<14:57,54.19it/s] 77%|#######7  |134017/173481[51:11<12:07,54.22it/s] 78%|#######7  |134617/173481[51:22<11:56,54.22it/s] 83%|########2 |143576/173481[54:11<09:17,53.66it/s] 83%|########3 |144188/173481[54:22<09:05,53.66it/s] 88%|########8 |153221/173481[57:11<06:17,53.62it/s] 89%|########8 |153846/173481[57:22<06:06,53.62it/s] 94%|#########3|162958/173481[1:00:11<03:15,53.86it/s] 94%|#########4|163598/173481[1:00:23<03:03,53.86it/s]100%|#########9|172933/173481[1:03:11<00:10,54.62it/s]100%|##########|173481/173481[1:03:22<00:00,45.62it/s]
[32m[0328 12:36:08 @base.py:257][0m Epoch 1 (global_step 9367974) finished, time:3802.65 sec.
[32m[0328 12:36:08 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-9367974.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13911/18822[03:00<01:03,77.28it/s] 78%|#######7  |14674/18822[03:10<00:53,77.28it/s]100%|##########|18822/18822[04:03<00:00,77.16it/s]
0
[32m[0328 12:40:13 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 12:40:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.785
[32m[0328 12:40:13 @monitor.py:363][0m activation-summaries/output-rms: 0.035236
[32m[0328 12:40:13 @monitor.py:363][0m cross_entropy_loss: 2.4126
[32m[0328 12:40:13 @monitor.py:363][0m lr: 1.9073e-09
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5572e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9061e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9075e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1671e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5521e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5978e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4507e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.891e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8852e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4764e-06
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 12:40:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 12:40:13 @monitor.py:363][0m train-error-top1: 0.60132
[32m[0328 12:40:13 @monitor.py:363][0m val-error-top1: 0.60784
[32m[0328 12:40:13 @monitor.py:363][0m val-utt-error: 0.26097
[32m[0328 12:40:13 @monitor.py:363][0m validation_cost: 2.424
[32m[0328 12:40:13 @monitor.py:363][0m wd_cost: 2.4505e-13
[32m[0328 12:40:13 @group.py:42][0m Callbacks took 244.740 sec in total. InferenceRunner: 244.087sec
[32m[0328 12:40:13 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9744/173481[03:00<50:24,54.13it/s]  6%|5         |10285/173481[03:10<50:14,54.13it/s] 11%|#1        |19541/173481[06:00<47:16,54.28it/s] 12%|#1        |20099/173481[06:10<47:05,54.28it/s] 17%|#6        |29433/173481[09:00<43:57,54.61it/s] 17%|#7        |30013/173481[09:10<43:47,54.61it/s] 23%|##2       |39367/173481[12:00<40:43,54.90it/s] 23%|##3       |39948/173481[12:10<40:32,54.90it/s] 28%|##8       |49169/173481[15:00<37:53,54.67it/s] 29%|##8       |49744/173481[15:10<37:43,54.67it/s] 34%|###4      |59032/173481[18:00<34:51,54.73it/s] 34%|###4      |59616/173481[18:10<34:40,54.73it/s] 40%|###9      |68954/173481[21:00<31:43,54.92it/s] 40%|####      |69552/173481[21:10<31:32,54.92it/s] 45%|####5     |78862/173481[24:00<28:40,54.98it/s] 46%|####5     |79464/173481[24:11<28:29,54.98it/s] 51%|#####1    |88655/173481[27:00<25:51,54.69it/s] 51%|#####1    |89262/173481[27:11<25:39,54.69it/s] 57%|#####6    |98519/173481[30:00<22:49,54.74it/s] 57%|#####7    |99136/173481[30:11<22:38,54.74it/s] 62%|######2   |108420/173481[33:00<19:45,54.87it/s] 63%|######2   |109044/173481[33:11<19:34,54.87it/s] 68%|######8   |118215/173481[36:00<16:51,54.64it/s] 69%|######8   |118842/173481[36:11<16:39,54.64it/s] 74%|#######3  |128099/173481[39:00<13:48,54.78it/s] 74%|#######4  |128745/173481[39:11<13:36,54.78it/s] 80%|#######9  |138110/173481[42:00<10:40,55.19it/s] 80%|#######9  |138772/173481[42:11<10:28,55.19it/s] 85%|########5 |148069/173481[45:00<07:39,55.26it/s] 86%|########5 |148712/173481[45:12<07:28,55.26it/s] 91%|######### |157836/173481[48:00<04:45,54.75it/s] 91%|#########1|158492/173481[48:12<04:33,54.75it/s] 97%|#########6|167758/173481[51:00<01:44,54.94it/s] 97%|#########7|168430/173481[51:12<01:31,54.94it/s]100%|##########|173481/173481[52:43<00:00,54.84it/s]
[32m[0328 13:32:56 @base.py:257][0m Epoch 2 (global_step 9541455) finished, time:3163.30 sec.
[32m[0328 13:32:56 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-9541455.
[32m[0328 13:32:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 45%|####5     |8545/18822[03:00<03:36,47.46it/s] 47%|####7     |8873/18822[03:10<03:29,47.46it/s] 76%|#######6  |14346/18822[06:00<01:56,38.39it/s] 78%|#######7  |14669/18822[06:10<01:48,38.39it/s]100%|##########|18822/18822[08:20<00:00,37.61it/s]
1
[32m[0328 13:41:17 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0328 13:41:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.561
[32m[0328 13:41:17 @monitor.py:363][0m activation-summaries/output-rms: 0.03533
[32m[0328 13:41:17 @monitor.py:363][0m cross_entropy_loss: 2.4538
[32m[0328 13:41:17 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5542e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.915e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.915e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.172e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5539e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.601e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.4666e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9021e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8857e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4962e-06
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 13:41:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 13:41:17 @monitor.py:363][0m train-error-top1: 0.61292
[32m[0328 13:41:17 @monitor.py:363][0m val-error-top1: 0.61035
[32m[0328 13:41:17 @monitor.py:363][0m val-utt-error: 0.26326
[32m[0328 13:41:17 @monitor.py:363][0m validation_cost: 2.441
[32m[0328 13:41:17 @monitor.py:363][0m wd_cost: 2.4505e-13
[32m[0328 13:41:17 @group.py:42][0m Callbacks took 501.151 sec in total. InferenceRunner: 500.532sec
[32m[0328 13:41:17 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9940/173481[03:00<49:21,55.22it/s]  6%|6         |10489/173481[03:10<49:11,55.22it/s] 11%|#         |18362/173481[06:00<51:02,50.65it/s] 11%|#         |18738/173481[06:10<50:54,50.65it/s] 14%|#4        |25060/173481[09:00<57:39,42.90it/s] 15%|#4        |25447/173481[09:10<57:30,42.90it/s] 18%|#8        |31742/173481[12:00<59:20,39.80it/s] 19%|#8        |32138/173481[12:10<59:11,39.80it/s] 22%|##2       |38727/173481[15:00<57:09,39.30it/s] 23%|##2       |39157/173481[15:10<56:58,39.30it/s] 27%|##6       |46019/173481[18:00<53:15,39.89it/s] 27%|##6       |46445/173481[18:10<53:04,39.89it/s] 31%|###       |53139/173481[21:00<50:29,39.72it/s] 31%|###       |53555/173481[21:10<50:19,39.72it/s] 35%|###4      |60209/173481[24:00<47:48,39.49it/s] 35%|###4      |60649/173481[24:11<47:37,39.49it/s] 39%|###9      |67704/173481[27:00<43:29,40.54it/s] 39%|###9      |68299/173481[27:11<43:14,40.54it/s] 45%|####4     |77634/173481[30:00<34:11,46.73it/s] 45%|####5     |78261/173481[30:11<33:57,46.73it/s] 51%|#####     |87635/173481[33:00<28:11,50.76it/s] 51%|#####     |88260/173481[33:11<27:58,50.76it/s] 56%|#####6    |97558/173481[36:00<23:56,52.85it/s] 57%|#####6    |98172/173481[36:11<23:44,52.85it/s] 62%|######2   |107588/173481[39:00<20:14,54.25it/s] 62%|######2   |108220/173481[39:11<20:02,54.25it/s] 68%|######7   |117589/173481[42:00<16:58,54.90it/s] 68%|######8   |118238/173481[42:11<16:46,54.90it/s] 74%|#######3  |127530/173481[45:00<13:54,55.06it/s] 74%|#######3  |128184/173481[45:11<13:42,55.06it/s] 79%|#######9  |137467/173481[48:00<10:53,55.13it/s] 80%|#######9  |138130/173481[48:12<10:41,55.13it/s] 85%|########4 |147418/173481[51:00<07:52,55.21it/s] 85%|########5 |148086/173481[51:12<07:40,55.21it/s] 89%|########9 |154734/173481[54:00<06:40,46.81it/s] 89%|########9 |155198/173481[54:12<06:30,46.81it/s] 93%|#########3|161734/173481[57:00<04:36,42.48it/s] 94%|#########3|162208/173481[57:12<04:25,42.48it/s] 97%|#########7|168929/173481[1:00:00<01:50,41.19it/s] 98%|#########7|169388/173481[1:00:12<01:39,41.19it/s]100%|##########|173481/173481[1:01:55<00:00,46.70it/s]
[32m[0328 14:43:12 @base.py:257][0m Epoch 3 (global_step 9714936) finished, time:3715.14 sec.
[32m[0328 14:43:12 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-9714936.
  0%|          |0/18822[00:00<?,?it/s] 45%|####4     |8388/18822[03:00<03:43,46.60it/s] 47%|####7     |8863/18822[03:10<03:33,46.60it/s] 91%|#########1|17221/18822[06:00<00:33,47.80it/s] 97%|#########7|18262/18822[06:19<00:11,47.80it/s]100%|##########|18822/18822[06:30<00:00,48.17it/s]
2
[32m[0328 14:49:43 @monitor.py:363][0m QueueInput/queue_size: 1.1486
[32m[0328 14:49:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.817
[32m[0328 14:49:43 @monitor.py:363][0m activation-summaries/output-rms: 0.035633
[32m[0328 14:49:43 @monitor.py:363][0m cross_entropy_loss: 2.4133
[32m[0328 14:49:43 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5537e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.919e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9111e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1819e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5608e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5957e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5084e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9059e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8832e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5294e-06
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 14:49:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 14:49:43 @monitor.py:363][0m train-error-top1: 0.60696
[32m[0328 14:49:43 @monitor.py:363][0m val-error-top1: 0.61045
[32m[0328 14:49:43 @monitor.py:363][0m val-utt-error: 0.26241
[32m[0328 14:49:43 @monitor.py:363][0m validation_cost: 2.4382
[32m[0328 14:49:43 @monitor.py:363][0m wd_cost: 4.901e-14
[32m[0328 14:49:43 @group.py:42][0m Callbacks took 391.116 sec in total. InferenceRunner: 390.802sec
[32m[0328 14:49:43 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7511/173481[03:00<1:06:17,41.73it/s]  5%|4         |7901/173481[03:10<1:06:08,41.73it/s]  8%|8         |14437/173481[06:00<1:06:12,40.04it/s]  9%|8         |14832/173481[06:10<1:06:02,40.04it/s] 12%|#2        |21515/173481[09:00<1:03:50,39.67it/s] 13%|#2        |21931/173481[09:10<1:03:39,39.67it/s] 17%|#6        |28651/173481[12:00<1:00:51,39.66it/s] 17%|#6        |29085/173481[12:10<1:00:40,39.66it/s] 21%|##        |36063/173481[15:00<56:41,40.40it/s]   21%|##1       |36532/173481[15:10<56:30,40.40it/s] 26%|##6       |45379/173481[18:00<47:03,45.38it/s] 27%|##6       |45982/173481[18:10<46:49,45.38it/s] 31%|###1      |54526/173481[21:00<41:21,47.94it/s] 32%|###1      |54937/173481[21:10<41:12,47.94it/s] 35%|###5      |61523/173481[24:00<43:27,42.93it/s] 36%|###5      |61954/173481[24:11<43:17,42.93it/s] 40%|###9      |68710/173481[27:00<42:12,41.37it/s] 40%|###9      |69177/173481[27:11<42:01,41.37it/s] 44%|####3     |76101/173481[30:00<39:22,41.21it/s] 44%|####4     |76567/173481[30:11<39:11,41.21it/s] 48%|####8     |83632/173481[33:00<36:03,41.52it/s] 48%|####8     |84093/173481[33:11<35:52,41.52it/s] 52%|#####2    |90808/173481[36:00<33:52,40.68it/s] 53%|#####2    |91285/173481[36:11<33:40,40.68it/s] 57%|#####6    |98203/173481[39:00<30:41,40.88it/s] 57%|#####6    |98690/173481[39:11<30:29,40.88it/s] 61%|######    |105757/173481[42:00<27:15,41.41it/s] 61%|######1   |106283/173481[42:11<27:02,41.41it/s] 65%|######5   |113428/173481[45:00<23:49,42.00it/s] 66%|######5   |113928/173481[45:12<23:37,42.00it/s] 70%|######9   |120908/173481[48:00<20:58,41.78it/s] 70%|######9   |121417/173481[48:12<20:46,41.78it/s] 74%|#######3  |128329/173481[51:00<18:07,41.50it/s] 74%|#######4  |128812/173481[51:12<17:56,41.50it/s] 78%|#######8  |135693/173481[54:00<15:17,41.20it/s] 79%|#######8  |136207/173481[54:12<15:04,41.20it/s] 83%|########2 |143279/173481[57:00<12:04,41.67it/s] 83%|########2 |143762/173481[57:12<11:53,41.67it/s] 87%|########6 |150768/173481[1:00:00<09:05,41.63it/s] 87%|########7 |151287/173481[1:00:12<08:53,41.63it/s] 91%|#########1|158118/173481[1:03:00<06:12,41.23it/s] 91%|#########1|158644/173481[1:03:12<05:59,41.23it/s] 95%|#########5|165503/173481[1:06:00<03:13,41.13it/s] 96%|#########5|166007/173481[1:06:13<03:01,41.13it/s]100%|#########9|172621/173481[1:09:00<00:21,40.32it/s]100%|#########9|173116/173481[1:09:13<00:09,40.32it/s]100%|##########|173481/173481[1:09:22<00:00,41.67it/s]
[32m[0328 15:59:06 @base.py:257][0m Epoch 4 (global_step 9888417) finished, time:4162.74 sec.
[32m[0328 15:59:06 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-9888417.
  0%|          |0/18822[00:00<?,?it/s] 87%|########6 |16306/18822[03:00<00:27,90.58it/s] 93%|#########2|17488/18822[03:10<00:14,90.58it/s]100%|##########|18822/18822[03:27<00:00,90.66it/s]
3
[32m[0328 16:02:34 @monitor.py:363][0m QueueInput/queue_size: 1.1186
[32m[0328 16:02:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.75
[32m[0328 16:02:34 @monitor.py:363][0m activation-summaries/output-rms: 0.035316
[32m[0328 16:02:34 @monitor.py:363][0m cross_entropy_loss: 2.4584
[32m[0328 16:02:34 @monitor.py:363][0m lr: 9.5367e-10
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5479e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9214e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9104e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1684e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.564e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.599e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5263e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9049e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8891e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5552e-06
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 16:02:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 16:02:34 @monitor.py:363][0m train-error-top1: 0.61178
[32m[0328 16:02:34 @monitor.py:363][0m val-error-top1: 0.60985
[32m[0328 16:02:34 @monitor.py:363][0m val-utt-error: 0.26326
[32m[0328 16:02:34 @monitor.py:363][0m validation_cost: 2.4368
[32m[0328 16:02:34 @monitor.py:363][0m wd_cost: 4.901e-14
[32m[0328 16:02:34 @group.py:42][0m Callbacks took 207.870 sec in total. InferenceRunner: 207.616sec
[32m[0328 16:02:34 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7654/173481[03:00<1:04:59,42.52it/s]  5%|4         |8059/173481[03:10<1:04:50,42.52it/s]  8%|8         |14681/173481[06:00<1:05:01,40.70it/s]  9%|8         |15081/173481[06:10<1:04:51,40.70it/s] 13%|#2        |21737/173481[09:00<1:03:19,39.93it/s] 13%|#2        |22146/173481[09:10<1:03:09,39.93it/s] 17%|#6        |28792/173481[12:00<1:00:57,39.56it/s] 17%|#6        |29221/173481[12:10<1:00:47,39.56it/s] 21%|##        |36267/173481[15:00<56:26,40.51it/s]   21%|##1       |36709/173481[15:10<56:16,40.51it/s] 25%|##5       |43942/173481[18:00<51:57,41.55it/s] 26%|##5       |44413/173481[18:10<51:46,41.55it/s] 30%|##9       |51305/173481[21:00<49:23,41.22it/s] 30%|##9       |51772/173481[21:10<49:12,41.22it/s] 34%|###3      |58735/173481[24:00<46:21,41.25it/s] 34%|###4      |59200/173481[24:11<46:10,41.25it/s] 38%|###8      |66437/173481[27:00<42:28,42.00it/s] 39%|###8      |66926/173481[27:11<42:16,42.00it/s] 43%|####2     |74214/173481[30:00<38:50,42.59it/s] 43%|####3     |74706/173481[30:11<38:38,42.59it/s] 47%|####7     |82202/173481[33:00<35:00,43.46it/s] 48%|####7     |82701/173481[33:11<34:48,43.46it/s] 52%|#####2    |90221/173481[36:00<31:32,44.00it/s] 52%|#####2    |90703/173481[36:11<31:21,44.00it/s] 57%|#####6    |98057/173481[39:00<28:43,43.76it/s] 57%|#####6    |98546/173481[39:11<28:32,43.76it/s] 61%|######1   |105893/173481[42:00<25:48,43.65it/s] 61%|######1   |106391/173481[42:11<25:37,43.65it/s] 65%|######5   |113619/173481[45:00<23:03,43.28it/s] 66%|######5   |114124/173481[45:12<22:51,43.28it/s] 70%|#######   |121957/173481[48:00<19:11,44.74it/s] 71%|#######   |122583/173481[48:12<18:57,44.74it/s] 76%|#######5  |131305/173481[51:00<14:37,48.07it/s] 76%|#######6  |131931/173481[51:12<14:24,48.07it/s] 81%|########1 |140590/173481[54:00<11:00,49.76it/s] 81%|########1 |141239/173481[54:12<10:47,49.76it/s] 87%|########6 |150435/173481[57:00<07:22,52.11it/s] 87%|########7 |151134/173481[57:12<07:08,52.11it/s] 92%|#########2|159883/173481[1:00:00<04:20,52.30it/s] 92%|#########2|160352/173481[1:00:12<04:11,52.30it/s] 97%|#########7|168510/173481[1:03:00<01:39,50.02it/s] 98%|#########7|169153/173481[1:03:12<01:26,50.02it/s]100%|##########|173481/173481[1:04:36<00:00,44.75it/s]
[32m[0328 17:07:10 @base.py:257][0m Epoch 5 (global_step 10061898) finished, time:3876.29 sec.
[32m[0328 17:07:10 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-10061898.
  0%|          |0/18822[00:00<?,?it/s] 70%|#######   |13198/18822[03:00<01:16,73.32it/s] 75%|#######4  |14057/18822[03:10<01:04,73.32it/s]100%|##########|18822/18822[04:03<00:00,77.14it/s]
4
[32m[0328 17:11:14 @monitor.py:363][0m QueueInput/queue_size: 1.0331
[32m[0328 17:11:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.89
[32m[0328 17:11:14 @monitor.py:363][0m activation-summaries/output-rms: 0.036069
[32m[0328 17:11:14 @monitor.py:363][0m cross_entropy_loss: 2.4076
[32m[0328 17:11:14 @monitor.py:363][0m lr: 4.7684e-10
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5463e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9271e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9107e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1602e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.565e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.6007e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5563e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9129e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.889e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.557e-06
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 17:11:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 17:11:14 @monitor.py:363][0m train-error-top1: 0.61371
[32m[0328 17:11:14 @monitor.py:363][0m val-error-top1: 0.60729
[32m[0328 17:11:14 @monitor.py:363][0m val-utt-error: 0.26177
[32m[0328 17:11:14 @monitor.py:363][0m validation_cost: 2.4201
[32m[0328 17:11:14 @monitor.py:363][0m wd_cost: 4.901e-14
[32m[0328 17:11:14 @group.py:42][0m Callbacks took 244.256 sec in total. InferenceRunner: 244.010sec
[32m[0328 17:11:14 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9914/173481[03:00<49:29,55.07it/s]  6%|6         |10479/173481[03:10<49:19,55.07it/s] 11%|#1        |19842/173481[06:00<46:27,55.11it/s] 12%|#1        |20409/173481[06:10<46:17,55.11it/s] 17%|#7        |29765/173481[09:00<43:27,55.12it/s] 17%|#7        |30326/173481[09:10<43:17,55.12it/s] 23%|##2       |39645/173481[12:00<40:33,55.00it/s] 23%|##3       |40224/173481[12:10<40:22,55.00it/s] 29%|##8       |49668/173481[15:00<37:17,55.34it/s] 29%|##8       |50259/173481[15:10<37:06,55.34it/s] 34%|###4      |59524/173481[18:00<34:30,55.04it/s] 35%|###4      |60079/173481[18:10<34:20,55.04it/s] 40%|###9      |68821/173481[21:00<32:43,53.29it/s] 40%|####      |69394/173481[21:10<32:33,53.29it/s] 45%|####5     |78140/173481[24:00<30:15,52.52it/s] 45%|####5     |78704/173481[24:11<30:04,52.52it/s] 50%|#####     |87402/173481[27:00<27:36,51.98it/s] 51%|#####     |87996/173481[27:11<27:24,51.98it/s] 56%|#####5    |96698/173481[30:00<24:42,51.81it/s] 56%|#####6    |97277/173481[30:11<24:30,51.81it/s] 61%|######1   |105991/173481[33:00<21:45,51.71it/s] 61%|######1   |106579/173481[33:11<21:33,51.71it/s] 66%|######6   |115251/173481[36:00<18:49,51.57it/s] 67%|######6   |115847/173481[36:11<18:37,51.57it/s] 72%|#######1  |124590/173481[39:00<15:45,51.72it/s] 72%|#######2  |125185/173481[39:11<15:33,51.72it/s] 77%|#######7  |133871/173481[42:00<12:47,51.64it/s] 78%|#######7  |134468/173481[42:11<12:35,51.64it/s] 82%|########2 |143107/173481[45:00<09:50,51.47it/s] 83%|########2 |143715/173481[45:12<09:38,51.47it/s] 88%|########8 |153092/173481[48:00<06:21,53.40it/s] 89%|########8 |153766/173481[48:12<06:09,53.40it/s] 93%|#########3|161618/173481[51:00<03:56,50.20it/s] 94%|#########3|162226/173481[51:12<03:44,50.20it/s] 99%|#########8|170923/173481[54:00<00:50,50.93it/s] 99%|#########8|171536/173481[54:12<00:38,50.93it/s]100%|##########|173481/173481[54:50<00:00,52.73it/s]
[32m[0328 18:06:05 @base.py:257][0m Epoch 6 (global_step 10235379) finished, time:3290.09 sec.
[32m[0328 18:06:05 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-10235379.
[32m[0328 18:06:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 63%|######3   |11890/18822[03:00<01:44,66.05it/s] 68%|######7   |12730/18822[03:10<01:32,66.05it/s]100%|##########|18822/18822[04:27<00:00,70.37it/s]
5
[32m[0328 18:10:33 @monitor.py:363][0m QueueInput/queue_size: 2.3675
[32m[0328 18:10:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.784
[32m[0328 18:10:33 @monitor.py:363][0m activation-summaries/output-rms: 0.035252
[32m[0328 18:10:33 @monitor.py:363][0m cross_entropy_loss: 2.3896
[32m[0328 18:10:33 @monitor.py:363][0m lr: 4.7684e-10
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.548e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9265e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9107e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.163e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5643e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5991e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.558e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9225e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8903e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5735e-06
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 18:10:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 18:10:33 @monitor.py:363][0m train-error-top1: 0.59926
[32m[0328 18:10:33 @monitor.py:363][0m val-error-top1: 0.60708
[32m[0328 18:10:33 @monitor.py:363][0m val-utt-error: 0.26225
[32m[0328 18:10:33 @monitor.py:363][0m validation_cost: 2.4185
[32m[0328 18:10:33 @monitor.py:363][0m wd_cost: 9.8021e-15
[32m[0328 18:10:33 @group.py:42][0m Callbacks took 268.408 sec in total. InferenceRunner: 267.494sec
[32m[0328 18:10:33 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9907/173481[03:00<49:32,55.04it/s]  6%|6         |10471/173481[03:10<49:21,55.04it/s] 12%|#1        |19956/173481[06:00<46:09,55.43it/s] 12%|#1        |20532/173481[06:10<45:59,55.43it/s] 17%|#7        |29978/173481[09:00<43:03,55.55it/s] 18%|#7        |30517/173481[09:10<42:53,55.55it/s] 23%|##3       |39935/173481[12:00<40:09,55.43it/s] 23%|##3       |40498/173481[12:10<39:59,55.43it/s] 29%|##8       |49944/173481[15:00<37:05,55.52it/s] 29%|##9       |50523/173481[15:10<36:54,55.52it/s] 34%|###4      |59693/173481[18:00<34:35,54.83it/s] 35%|###4      |60279/173481[18:10<34:24,54.83it/s] 40%|####      |69582/173481[21:00<31:33,54.88it/s] 40%|####      |70188/173481[21:10<31:22,54.88it/s] 46%|####5     |79658/173481[24:00<28:12,55.42it/s] 46%|####6     |80285/173481[24:10<28:01,55.42it/s] 52%|#####1    |89746/173481[27:00<25:02,55.73it/s] 52%|#####2    |90364/173481[27:11<24:51,55.73it/s] 58%|#####7    |99833/173481[30:00<21:57,55.88it/s] 58%|#####7    |100434/173481[30:11<21:47,55.88it/s] 63%|######2   |109257/173481[33:00<19:47,54.06it/s] 63%|######3   |109875/173481[33:11<19:36,54.06it/s] 68%|######8   |118790/173481[36:00<17:02,53.50it/s] 69%|######8   |119392/173481[36:11<16:50,53.50it/s] 74%|#######3  |128316/173481[39:00<14:08,53.21it/s] 74%|#######4  |128912/173481[39:11<13:57,53.21it/s] 80%|#######9  |138424/173481[42:00<10:41,54.64it/s] 80%|########  |139095/173481[42:11<10:29,54.64it/s] 85%|########4 |147202/173481[45:00<08:29,51.54it/s] 85%|########5 |147819/173481[45:11<08:17,51.54it/s] 90%|######### |156697/173481[48:00<05:21,52.13it/s] 91%|######### |157301/173481[48:11<05:10,52.13it/s] 96%|#########5|166175/173481[51:00<02:19,52.39it/s] 96%|#########6|166811/173481[51:12<02:07,52.39it/s]100%|##########|173481/173481[53:17<00:00,54.25it/s]
[32m[0328 19:03:51 @base.py:257][0m Epoch 7 (global_step 10408860) finished, time:3197.74 sec.
[32m[0328 19:03:51 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-10408860.
[32m[0328 19:03:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 62%|######1   |11579/18822[03:00<01:52,64.33it/s] 66%|######5   |12406/18822[03:10<01:39,64.33it/s]100%|##########|18822/18822[04:27<00:00,70.37it/s]
6
[32m[0328 19:08:19 @monitor.py:363][0m QueueInput/queue_size: 1.2867
[32m[0328 19:08:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.867
[32m[0328 19:08:19 @monitor.py:363][0m activation-summaries/output-rms: 0.035287
[32m[0328 19:08:19 @monitor.py:363][0m cross_entropy_loss: 2.4599
[32m[0328 19:08:19 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5466e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9294e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9079e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1624e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5649e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5968e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5787e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9239e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8884e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5945e-06
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 19:08:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 19:08:19 @monitor.py:363][0m train-error-top1: 0.61865
[32m[0328 19:08:19 @monitor.py:363][0m val-error-top1: 0.61186
[32m[0328 19:08:19 @monitor.py:363][0m val-utt-error: 0.26501
[32m[0328 19:08:19 @monitor.py:363][0m validation_cost: 2.45
[32m[0328 19:08:19 @monitor.py:363][0m wd_cost: 9.8021e-15
[32m[0328 19:08:19 @group.py:42][0m Callbacks took 268.126 sec in total. InferenceRunner: 267.494sec
[32m[0328 19:08:19 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10018/173481[03:00<48:57,55.65it/s]  6%|6         |10568/173481[03:10<48:47,55.65it/s] 12%|#1        |20066/173481[06:00<45:52,55.74it/s] 12%|#1        |20634/173481[06:10<45:42,55.74it/s] 17%|#7        |30142/173481[09:00<42:46,55.85it/s] 18%|#7        |30728/173481[09:10<42:35,55.85it/s] 23%|##3       |40407/173481[12:00<39:18,56.43it/s] 24%|##3       |41003/173481[12:10<39:07,56.43it/s] 29%|##9       |50593/173481[15:00<36:14,56.51it/s] 30%|##9       |51179/173481[15:10<36:04,56.51it/s] 34%|###3      |58848/173481[18:00<37:44,50.63it/s] 34%|###4      |59351/173481[18:10<37:34,50.63it/s] 39%|###9      |67862/173481[21:00<34:57,50.35it/s] 39%|###9      |68419/173481[21:10<34:46,50.35it/s] 44%|####4     |76481/173481[24:00<32:56,49.08it/s] 44%|####4     |77087/173481[24:10<32:43,49.08it/s] 49%|####9     |85303/173481[27:00<29:57,49.05it/s] 49%|####9     |85830/173481[27:11<29:47,49.05it/s] 54%|#####4    |93899/173481[30:00<27:24,48.39it/s] 54%|#####4    |94308/173481[30:11<27:16,48.39it/s] 60%|#####9    |103557/173481[33:00<22:54,50.88it/s] 60%|######    |104177/173481[33:11<22:41,50.88it/s] 66%|######5   |113735/173481[36:00<18:35,53.56it/s] 66%|######5   |114378/173481[36:11<18:23,53.56it/s] 71%|#######1  |123691/173481[39:00<15:14,54.42it/s] 72%|#######1  |124163/173481[39:11<15:06,54.42it/s] 76%|#######6  |132087/173481[42:00<13:44,50.23it/s] 76%|#######6  |132698/173481[42:11<13:31,50.23it/s] 82%|########1 |141591/173481[45:00<10:19,51.48it/s] 82%|########1 |142197/173481[45:11<10:07,51.48it/s] 87%|########7 |151073/173481[48:00<07:10,52.07it/s] 87%|########7 |151652/173481[48:12<06:59,52.07it/s] 93%|#########2|160516/173481[51:00<04:08,52.27it/s] 93%|#########2|161135/173481[51:12<03:56,52.27it/s] 98%|#########7|169952/173481[54:00<01:07,52.34it/s] 98%|#########8|170586/173481[54:12<00:55,52.34it/s]100%|##########|173481/173481[55:07<00:00,52.45it/s]
[32m[0328 20:03:26 @base.py:257][0m Epoch 8 (global_step 10582341) finished, time:3307.54 sec.
[32m[0328 20:03:27 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 54%|#####3    |10084/18822[03:00<02:35,56.02it/s] 57%|#####6    |10686/18822[03:10<02:25,56.02it/s]100%|##########|18822/18822[05:25<00:00,57.84it/s]
7
[32m[0328 20:08:52 @monitor.py:363][0m QueueInput/queue_size: 6.2893
[32m[0328 20:08:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.817
[32m[0328 20:08:52 @monitor.py:363][0m activation-summaries/output-rms: 0.035635
[32m[0328 20:08:52 @monitor.py:363][0m cross_entropy_loss: 2.4107
[32m[0328 20:08:52 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5464e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9293e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9079e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.161e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5654e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5952e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5819e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9263e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8876e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5969e-06
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 20:08:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 20:08:52 @monitor.py:363][0m train-error-top1: 0.60667
[32m[0328 20:08:52 @monitor.py:363][0m val-error-top1: 0.61002
[32m[0328 20:08:52 @monitor.py:363][0m val-utt-error: 0.26241
[32m[0328 20:08:52 @monitor.py:363][0m validation_cost: 2.4357
[32m[0328 20:08:52 @monitor.py:363][0m wd_cost: 1.9604e-15
[32m[0328 20:08:52 @group.py:42][0m Callbacks took 325.728 sec in total. InferenceRunner: 325.404sec
[32m[0328 20:08:52 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9950/173481[03:00<49:18,55.28it/s]  6%|6         |10503/173481[03:10<49:08,55.28it/s] 12%|#1        |19971/173481[06:00<46:07,55.47it/s] 12%|#1        |20540/173481[06:10<45:57,55.47it/s] 17%|#7        |30046/173481[09:00<42:54,55.72it/s] 18%|#7        |30626/173481[09:10<42:43,55.72it/s] 23%|##3       |40300/173481[12:00<39:24,56.33it/s] 24%|##3       |40899/173481[12:10<39:13,56.33it/s] 29%|##9       |50507/173481[15:00<36:15,56.52it/s] 29%|##9       |51111/173481[15:10<36:05,56.52it/s] 35%|###4      |60624/173481[18:00<33:22,56.36it/s] 35%|###5      |61217/173481[18:10<33:11,56.36it/s] 41%|####      |70612/173481[21:00<30:39,55.92it/s] 41%|####1     |71212/173481[21:11<30:28,55.92it/s] 46%|####6     |80610/173481[24:00<27:46,55.73it/s] 47%|####6     |81238/173481[24:11<27:35,55.73it/s] 52%|#####2    |90581/173481[27:00<24:52,55.56it/s] 53%|#####2    |91200/173481[27:11<24:40,55.56it/s] 58%|#####7    |100614/173481[30:00<21:49,55.65it/s] 58%|#####8    |101258/173481[30:11<21:37,55.65it/s] 64%|######3   |110691/173481[33:00<18:44,55.81it/s] 64%|######4   |111341/173481[33:11<18:33,55.81it/s] 70%|######9   |120798/173481[36:00<15:41,55.98it/s] 70%|######9   |121415/173481[36:11<15:30,55.98it/s] 75%|#######5  |130288/173481[39:00<13:15,54.30it/s] 75%|#######5  |130905/173481[39:11<13:04,54.30it/s] 81%|########  |139826/173481[42:00<10:27,53.63it/s] 81%|########  |140435/173481[42:12<10:16,53.63it/s] 86%|########6 |149290/173481[45:00<07:35,53.10it/s] 86%|########6 |149914/173481[45:12<07:23,53.10it/s] 91%|#########1|158722/173481[48:00<04:39,52.74it/s] 92%|#########1|159362/173481[48:12<04:27,52.74it/s] 97%|#########6|168221/173481[51:00<01:39,52.76it/s] 97%|#########7|168880/173481[51:12<01:27,52.76it/s]100%|##########|173481/173481[52:40<00:00,54.88it/s]
[32m[0328 21:01:33 @base.py:257][0m Epoch 9 (global_step 10755822) finished, time:3160.88 sec.
[32m[0328 21:01:33 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-10755822.
  0%|          |0/18822[00:00<?,?it/s] 52%|#####2    |9812/18822[03:00<02:45,54.51it/s] 55%|#####5    |10410/18822[03:10<02:34,54.51it/s]100%|##########|18822/18822[05:21<00:00,58.61it/s]
8
[32m[0328 21:06:54 @monitor.py:363][0m QueueInput/queue_size: 1.821
[32m[0328 21:06:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.75
[32m[0328 21:06:54 @monitor.py:363][0m activation-summaries/output-rms: 0.035317
[32m[0328 21:06:54 @monitor.py:363][0m cross_entropy_loss: 2.4571
[32m[0328 21:06:54 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5448e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.93e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9071e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.156e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5674e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5957e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5956e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9278e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8893e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6128e-06
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 21:06:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 21:06:54 @monitor.py:363][0m train-error-top1: 0.61232
[32m[0328 21:06:54 @monitor.py:363][0m val-error-top1: 0.60961
[32m[0328 21:06:54 @monitor.py:363][0m val-utt-error: 0.26299
[32m[0328 21:06:54 @monitor.py:363][0m validation_cost: 2.4356
[32m[0328 21:06:54 @monitor.py:363][0m wd_cost: 1.9604e-15
[32m[0328 21:06:54 @group.py:42][0m Callbacks took 321.447 sec in total. InferenceRunner: 321.160sec
[32m[0328 21:06:54 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9900/173481[03:00<49:34,55.00it/s]  6%|6         |10459/173481[03:10<49:24,55.00it/s] 11%|#1        |19822/173481[06:00<46:30,55.06it/s] 12%|#1        |20378/173481[06:10<46:20,55.06it/s] 17%|#7        |29797/173481[09:00<43:21,55.24it/s] 18%|#7        |30372/173481[09:10<43:10,55.24it/s] 23%|##2       |39827/173481[12:00<40:09,55.48it/s] 23%|##3       |40420/173481[12:10<39:58,55.48it/s] 29%|##8       |49863/173481[15:00<37:02,55.61it/s] 29%|##9       |50461/173481[15:10<36:52,55.61it/s] 35%|###4      |59970/173481[18:00<33:51,55.88it/s] 35%|###4      |60564/173481[18:10<33:40,55.88it/s] 40%|####      |70046/173481[21:00<30:49,55.93it/s] 41%|####      |70656/173481[21:10<30:38,55.93it/s] 46%|####6     |80097/173481[24:00<27:51,55.88it/s] 47%|####6     |80709/173481[24:11<27:40,55.88it/s] 52%|#####1    |90155/173481[27:00<24:51,55.88it/s] 52%|#####2    |90785/173481[27:11<24:39,55.88it/s] 58%|#####7    |100092/173481[30:00<22:01,55.54it/s] 58%|#####8    |100682/173481[30:11<21:50,55.54it/s] 63%|######3   |109550/173481[33:00<19:43,54.00it/s] 63%|######3   |110137/173481[33:11<19:33,54.00it/s] 69%|######8   |118942/173481[36:00<17:07,53.07it/s] 69%|######8   |119556/173481[36:11<16:56,53.07it/s] 74%|#######4  |128490/173481[39:00<14:07,53.06it/s] 74%|#######4  |129112/173481[39:11<13:56,53.06it/s] 80%|#######9  |137980/173481[42:00<11:11,52.89it/s] 80%|#######9  |138598/173481[42:11<10:59,52.89it/s] 85%|########4 |147435/173481[45:00<08:14,52.71it/s] 85%|########5 |148063/173481[45:12<08:02,52.71it/s] 91%|######### |157163/173481[48:00<05:05,53.37it/s] 91%|######### |157641/173481[48:12<04:56,53.37it/s] 96%|#########5|166347/173481[51:00<02:16,52.17it/s] 96%|#########6|166999/173481[51:12<02:04,52.17it/s]100%|##########|173481/173481[53:15<00:00,54.28it/s]
[32m[0328 22:00:10 @base.py:257][0m Epoch 10 (global_step 10929303) finished, time:3195.83 sec.
[32m[0328 22:00:10 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s] 52%|#####2    |9873/18822[03:00<02:43,54.84it/s] 56%|#####5    |10465/18822[03:10<02:32,54.84it/s]100%|##########|18822/18822[05:17<00:00,59.34it/s]
9
[32m[0328 22:05:28 @monitor.py:363][0m QueueInput/queue_size: 1.7439
[32m[0328 22:05:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.89
[32m[0328 22:05:28 @monitor.py:363][0m activation-summaries/output-rms: 0.036071
[32m[0328 22:05:28 @monitor.py:363][0m cross_entropy_loss: 2.4068
[32m[0328 22:05:28 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5447e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9315e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9065e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1538e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5686e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.595e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5949e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9301e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8885e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6177e-06
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 22:05:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 22:05:28 @monitor.py:363][0m train-error-top1: 0.61356
[32m[0328 22:05:28 @monitor.py:363][0m val-error-top1: 0.60714
[32m[0328 22:05:28 @monitor.py:363][0m val-utt-error: 0.26124
[32m[0328 22:05:28 @monitor.py:363][0m validation_cost: 2.4193
[32m[0328 22:05:28 @monitor.py:363][0m wd_cost: 1.9604e-15
[32m[0328 22:05:28 @group.py:42][0m Callbacks took 317.392 sec in total. InferenceRunner: 317.184sec
[32m[0328 22:05:28 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10009/173481[03:00<48:59,55.60it/s]  6%|6         |10581/173481[03:10<48:49,55.60it/s] 12%|#1        |20078/173481[06:00<45:50,55.77it/s] 12%|#1        |20643/173481[06:10<45:40,55.77it/s] 17%|#7        |30181/173481[09:00<42:41,55.95it/s] 18%|#7        |30765/173481[09:10<42:30,55.95it/s] 23%|##3       |40215/173481[12:00<39:46,55.84it/s] 24%|##3       |40790/173481[12:10<39:36,55.84it/s] 29%|##8       |50301/173481[15:00<36:42,55.94it/s] 29%|##9       |50894/173481[15:10<36:31,55.94it/s] 35%|###4      |60371/173481[18:00<33:41,55.94it/s] 35%|###5      |60970/173481[18:10<33:31,55.94it/s] 41%|####      |70407/173481[21:00<30:45,55.85it/s] 41%|####      |71018/173481[21:10<30:34,55.85it/s] 46%|####6     |80460/173481[24:00<27:45,55.85it/s] 47%|####6     |81069/173481[24:11<27:34,55.85it/s] 52%|#####2    |90500/173481[27:00<24:46,55.81it/s] 53%|#####2    |91112/173481[27:11<24:35,55.81it/s] 58%|#####7    |100556/173481[30:00<21:46,55.84it/s] 58%|#####8    |101135/173481[30:11<21:35,55.84it/s] 63%|######3   |110018/173481[33:00<19:31,54.15it/s] 64%|######3   |110651/173481[33:11<19:20,54.15it/s] 69%|######8   |119554/173481[36:00<16:46,53.56it/s] 69%|######9   |120144/173481[36:11<16:35,53.56it/s] 74%|#######4  |129017/173481[39:00<13:58,53.06it/s] 75%|#######4  |129619/173481[39:11<13:46,53.06it/s] 80%|#######9  |138548/173481[42:00<10:59,53.00it/s] 80%|########  |139161/173481[42:11<10:47,53.00it/s] 85%|########5 |148035/173481[45:00<08:01,52.85it/s] 86%|########5 |148661/173481[45:11<07:49,52.85it/s] 91%|######### |157504/173481[48:00<05:03,52.73it/s] 91%|#########1|158118/173481[48:12<04:51,52.73it/s] 96%|#########6|167053/173481[51:00<02:01,52.89it/s] 97%|#########6|167725/173481[51:12<01:48,52.89it/s]100%|##########|173481/173481[53:00<00:00,54.54it/s]
[32m[0328 22:58:28 @base.py:257][0m Epoch 11 (global_step 11102784) finished, time:3180.77 sec.
[32m[0328 22:58:29 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s] 52%|#####2    |9870/18822[03:00<02:43,54.83it/s] 56%|#####5    |10460/18822[03:10<02:32,54.83it/s]100%|##########|18822/18822[05:11<00:00,60.48it/s]
10
[32m[0328 23:03:40 @monitor.py:363][0m QueueInput/queue_size: 1.7163
[32m[0328 23:03:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.784
[32m[0328 23:03:40 @monitor.py:363][0m activation-summaries/output-rms: 0.035253
[32m[0328 23:03:40 @monitor.py:363][0m cross_entropy_loss: 2.389
[32m[0328 23:03:40 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5437e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9307e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9071e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1552e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5693e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5942e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.5945e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9301e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8889e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6204e-06
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0328 23:03:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0328 23:03:40 @monitor.py:363][0m train-error-top1: 0.59914
[32m[0328 23:03:40 @monitor.py:363][0m val-error-top1: 0.60697
[32m[0328 23:03:40 @monitor.py:363][0m val-utt-error: 0.26198
[32m[0328 23:03:40 @monitor.py:363][0m validation_cost: 2.418
[32m[0328 23:03:40 @monitor.py:363][0m wd_cost: 3.9208e-16
[32m[0328 23:03:40 @group.py:42][0m Callbacks took 311.683 sec in total. InferenceRunner: 311.218sec
[32m[0328 23:03:40 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10045/173481[03:00<48:48,55.80it/s]  6%|6         |10598/173481[03:10<48:38,55.80it/s] 11%|#1        |19924/173481[06:00<46:15,55.34it/s] 12%|#1        |20486/173481[06:10<46:04,55.34it/s] 17%|#7        |29849/173481[09:00<43:20,55.24it/s] 18%|#7        |30422/173481[09:10<43:09,55.24it/s] 23%|##2       |39858/173481[12:00<40:11,55.42it/s] 23%|##3       |40454/173481[12:10<40:00,55.42it/s] 28%|##8       |49374/173481[15:00<38:13,54.11it/s] 29%|##8       |49959/173481[15:10<38:02,54.11it/s] 34%|###4      |59359/173481[18:00<34:43,54.78it/s] 35%|###4      |59950/173481[18:10<34:32,54.78it/s] 40%|###9      |68863/173481[21:00<32:25,53.77it/s] 40%|####      |69423/173481[21:10<32:15,53.77it/s] 45%|####5     |78295/173481[24:00<29:53,53.07it/s] 45%|####5     |78875/173481[24:11<29:42,53.07it/s] 50%|####9     |85935/173481[27:00<30:56,47.16it/s] 50%|####9     |86396/173481[27:11<30:46,47.16it/s] 55%|#####5    |95665/173481[30:00<25:44,50.37it/s] 56%|#####5    |96297/173481[30:11<25:32,50.37it/s] 61%|######    |105521/173481[33:00<21:35,52.47it/s] 61%|######1   |106109/173481[33:11<21:23,52.47it/s] 66%|######6   |114638/173481[36:00<19:01,51.54it/s] 66%|######6   |115164/173481[36:11<18:51,51.54it/s] 71%|#######   |123072/173481[39:00<17:06,49.09it/s] 71%|#######1  |123606/173481[39:11<16:56,49.09it/s] 76%|#######6  |132445/173481[42:00<13:32,50.53it/s] 77%|#######6  |133103/173481[42:11<13:19,50.53it/s] 82%|########2 |142311/173481[45:00<09:52,52.59it/s] 82%|########2 |142939/173481[45:12<09:40,52.59it/s] 88%|########7 |151828/173481[48:00<06:50,52.73it/s] 88%|########7 |152457/173481[48:12<06:38,52.73it/s] 93%|#########2|161127/173481[51:00<03:56,52.19it/s] 93%|#########3|161725/173481[51:12<03:45,52.19it/s] 98%|#########8|170086/173481[54:00<01:06,50.95it/s] 98%|#########8|170768/173481[54:12<00:53,50.95it/s]100%|##########|173481/173481[55:04<00:00,52.50it/s]
[32m[0328 23:58:45 @base.py:257][0m Epoch 12 (global_step 11276265) finished, time:3304.18 sec.
[32m[0328 23:58:45 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-11276265.
[32m[0328 23:58:45 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 88%|########7 |16514/18822[03:00<00:25,91.74it/s] 94%|#########4|17776/18822[03:10<00:11,91.74it/s]100%|##########|18822/18822[03:18<00:00,94.68it/s]
11
[32m[0329 00:02:04 @monitor.py:363][0m QueueInput/queue_size: 0.93336
[32m[0329 00:02:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.867
[32m[0329 00:02:04 @monitor.py:363][0m activation-summaries/output-rms: 0.035287
[32m[0329 00:02:04 @monitor.py:363][0m cross_entropy_loss: 2.4596
[32m[0329 00:02:04 @monitor.py:363][0m lr: 1.1921e-10
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5437e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9302e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9059e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1541e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5688e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.594e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.601e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9317e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8901e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6264e-06
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 00:02:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 00:02:04 @monitor.py:363][0m train-error-top1: 0.61865
[32m[0329 00:02:04 @monitor.py:363][0m val-error-top1: 0.6118
[32m[0329 00:02:04 @monitor.py:363][0m val-utt-error: 0.2649
[32m[0329 00:02:04 @monitor.py:363][0m validation_cost: 2.4497
[32m[0329 00:02:04 @monitor.py:363][0m wd_cost: 3.9208e-16
[32m[0329 00:02:04 @group.py:42][0m Callbacks took 199.357 sec in total. InferenceRunner: 198.816sec
[32m[0329 00:02:04 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9535/173481[03:00<51:35,52.97it/s]  6%|5         |10028/173481[03:10<51:25,52.97it/s] 11%|#         |18456/173481[06:00<50:27,51.20it/s] 11%|#         |18981/173481[06:10<50:17,51.20it/s] 16%|#6        |27874/173481[09:00<46:53,51.75it/s] 16%|#6        |28418/173481[09:10<46:43,51.75it/s] 22%|##1       |37341/173481[12:00<43:29,52.17it/s] 22%|##1       |37884/173481[12:10<43:19,52.17it/s] 27%|##6       |46043/173481[15:00<42:19,50.18it/s] 27%|##6       |46535/173481[15:10<42:09,50.18it/s] 31%|###1      |54225/173481[18:00<41:40,47.70it/s] 32%|###1      |54713/173481[18:10<41:29,47.70it/s] 36%|###6      |62682/173481[21:00<39:00,47.34it/s] 36%|###6      |63291/173481[21:10<38:47,47.34it/s] 42%|####1     |72783/173481[24:00<32:40,51.35it/s] 42%|####2     |73386/173481[24:11<32:29,51.35it/s] 47%|####7     |81800/173481[27:00<30:07,50.72it/s] 47%|####7     |82308/173481[27:11<29:57,50.72it/s] 52%|#####2    |90965/173481[30:00<27:03,50.81it/s] 53%|#####2    |91498/173481[30:11<26:53,50.81it/s] 58%|#####7    |100348/173481[33:00<23:41,51.46it/s] 58%|#####8    |100927/173481[33:11<23:29,51.46it/s] 63%|######3   |109418/173481[36:00<20:58,50.92it/s] 63%|######3   |109969/173481[36:11<20:47,50.92it/s] 68%|######8   |118458/173481[39:00<18:08,50.57it/s] 69%|######8   |119037/173481[39:11<17:56,50.57it/s] 73%|#######3  |127261/173481[42:00<15:29,49.72it/s] 74%|#######3  |127828/173481[42:11<15:18,49.72it/s] 78%|#######8  |136086/173481[45:00<12:37,49.37it/s] 79%|#######8  |136674/173481[45:12<12:25,49.37it/s] 84%|########3 |144864/173481[48:00<09:43,49.07it/s] 84%|########3 |145443/173481[48:12<09:31,49.07it/s] 89%|########8 |153570/173481[51:00<06:48,48.71it/s] 89%|########8 |154162/173481[51:12<06:36,48.71it/s] 94%|#########3|162339/173481[54:00<03:48,48.71it/s] 94%|#########3|162924/173481[54:12<03:36,48.71it/s] 99%|#########8|171161/173481[57:00<00:47,48.86it/s] 99%|#########9|171808/173481[57:12<00:34,48.86it/s]100%|##########|173481/173481[57:45<00:00,50.06it/s]
[32m[0329 00:59:50 @base.py:257][0m Epoch 13 (global_step 11449746) finished, time:3465.61 sec.
[32m[0329 00:59:50 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######7  |14504/18822[03:00<00:53,80.57it/s] 82%|########1 |15359/18822[03:10<00:42,80.57it/s]100%|##########|18822/18822[03:52<00:00,81.06it/s]
12
[32m[0329 01:03:42 @monitor.py:363][0m QueueInput/queue_size: 13.378
[32m[0329 01:03:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.817
[32m[0329 01:03:42 @monitor.py:363][0m activation-summaries/output-rms: 0.035635
[32m[0329 01:03:42 @monitor.py:363][0m cross_entropy_loss: 2.4106
[32m[0329 01:03:42 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5429e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9299e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9051e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1541e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5691e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5941e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6048e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9306e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8903e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6289e-06
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 01:03:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 01:03:42 @monitor.py:363][0m train-error-top1: 0.60665
[32m[0329 01:03:42 @monitor.py:363][0m val-error-top1: 0.60999
[32m[0329 01:03:42 @monitor.py:363][0m val-utt-error: 0.26219
[32m[0329 01:03:42 @monitor.py:363][0m validation_cost: 2.4355
[32m[0329 01:03:42 @monitor.py:363][0m wd_cost: 3.9208e-16
[32m[0329 01:03:42 @group.py:42][0m Callbacks took 232.556 sec in total. InferenceRunner: 232.231sec
[32m[0329 01:03:42 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10180/173481[03:00<48:07,56.55it/s]  6%|6         |10752/173481[03:10<47:57,56.55it/s] 11%|#1        |19793/173481[06:00<46:37,54.93it/s] 12%|#1        |20288/173481[06:10<46:28,54.93it/s] 16%|#6        |28353/173481[09:00<47:26,50.98it/s] 17%|#6        |28864/173481[09:10<47:16,50.98it/s] 22%|##1       |37411/173481[12:00<44:46,50.65it/s] 22%|##1       |37934/173481[12:10<44:36,50.65it/s] 27%|##6       |46536/173481[15:00<41:45,50.67it/s] 27%|##7       |47064/173481[15:10<41:35,50.67it/s] 32%|###2      |55660/173481[18:00<38:44,50.68it/s] 32%|###2      |56202/173481[18:10<38:34,50.68it/s] 37%|###7      |64673/173481[21:00<36:00,50.37it/s] 38%|###7      |65239/173481[21:10<35:48,50.37it/s] 42%|####2     |73489/173481[24:00<33:33,49.66it/s] 43%|####2     |74010/173481[24:11<33:22,49.66it/s] 47%|####7     |82308/173481[27:00<30:48,49.32it/s] 48%|####7     |82850/173481[27:11<30:37,49.32it/s] 53%|#####2    |91101/173481[30:00<27:58,49.08it/s] 53%|#####2    |91642/173481[30:11<27:47,49.08it/s] 58%|#####7    |100068/173481[33:00<24:44,49.45it/s] 58%|#####8    |100675/173481[33:11<24:32,49.45it/s] 63%|######2   |108974/173481[36:00<21:44,49.46it/s] 63%|######3   |109552/173481[36:11<21:32,49.46it/s] 68%|######7   |117790/173481[39:00<18:51,49.22it/s] 68%|######8   |118344/173481[39:11<18:40,49.22it/s] 73%|#######2  |126473/173481[42:00<16:04,48.72it/s] 73%|#######3  |127041/173481[42:11<15:53,48.72it/s] 78%|#######7  |135213/173481[45:00<13:06,48.64it/s] 78%|#######8  |135787/173481[45:12<12:55,48.64it/s] 83%|########3 |144010/173481[48:00<10:04,48.75it/s] 83%|########3 |144593/173481[48:12<09:52,48.75it/s] 88%|########8 |152868/173481[51:00<07:00,48.98it/s] 88%|########8 |153468/173481[51:12<06:48,48.98it/s] 94%|#########3|162345/173481[54:00<03:39,50.75it/s] 94%|#########3|162990/173481[54:12<03:26,50.75it/s] 99%|#########8|171611/173481[57:00<00:36,51.11it/s] 99%|#########9|172199/173481[57:12<00:25,51.11it/s]100%|##########|173481/173481[57:37<00:00,50.17it/s]
[32m[0329 02:01:20 @base.py:257][0m Epoch 14 (global_step 11623227) finished, time:3457.90 sec.
[32m[0329 02:01:20 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-11623227.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######9  |14935/18822[03:00<00:46,82.97it/s] 84%|########3 |15807/18822[03:10<00:36,82.97it/s]100%|##########|18822/18822[03:45<00:00,83.36it/s]
13
[32m[0329 02:05:06 @monitor.py:363][0m QueueInput/queue_size: 4.4474
[32m[0329 02:05:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.75
[32m[0329 02:05:06 @monitor.py:363][0m activation-summaries/output-rms: 0.035318
[32m[0329 02:05:06 @monitor.py:363][0m cross_entropy_loss: 2.457
[32m[0329 02:05:06 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5427e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9299e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9053e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1529e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5694e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5939e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6058e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9304e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8901e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6299e-06
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 02:05:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 02:05:06 @monitor.py:363][0m train-error-top1: 0.61232
[32m[0329 02:05:06 @monitor.py:363][0m val-error-top1: 0.6096
[32m[0329 02:05:06 @monitor.py:363][0m val-utt-error: 0.26283
[32m[0329 02:05:06 @monitor.py:363][0m validation_cost: 2.4355
[32m[0329 02:05:06 @monitor.py:363][0m wd_cost: 7.8417e-17
[32m[0329 02:05:06 @group.py:42][0m Callbacks took 226.056 sec in total. InferenceRunner: 225.814sec
[32m[0329 02:05:06 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9901/173481[03:00<49:33,55.01it/s]  6%|6         |10465/173481[03:10<49:23,55.01it/s] 12%|#1        |20109/173481[06:00<45:46,55.84it/s] 12%|#1        |20693/173481[06:10<45:35,55.84it/s] 17%|#7        |30255/173481[09:00<42:32,56.10it/s] 18%|#7        |30827/173481[09:10<42:22,56.10it/s] 23%|##3       |39934/173481[12:00<40:31,54.91it/s] 23%|##3       |40475/173481[12:10<40:22,54.91it/s] 28%|##8       |48867/173481[15:00<39:50,52.13it/s] 28%|##8       |49403/173481[15:10<39:39,52.13it/s] 33%|###3      |58017/173481[18:00<37:23,51.47it/s] 34%|###3      |58577/173481[18:10<37:12,51.47it/s] 39%|###8      |67249/173481[21:00<34:27,51.38it/s] 39%|###9      |67799/173481[21:10<34:16,51.38it/s] 44%|####3     |76142/173481[24:00<32:12,50.37it/s] 44%|####4     |76681/173481[24:11<32:01,50.37it/s] 49%|####8     |84869/173481[27:00<29:53,49.41it/s] 49%|####9     |85409/173481[27:11<29:42,49.41it/s] 54%|#####4    |93727/173481[30:00<26:57,49.31it/s] 54%|#####4    |94283/173481[30:11<26:46,49.31it/s] 59%|#####9    |102442/173481[33:00<24:14,48.86it/s] 59%|#####9    |103009/173481[33:11<24:02,48.86it/s] 64%|######4   |111165/173481[36:00<21:20,48.66it/s] 64%|######4   |111736/173481[36:11<21:09,48.66it/s] 69%|######9   |119779/173481[39:00<18:32,48.25it/s] 69%|######9   |120351/173481[39:11<18:21,48.25it/s] 74%|#######3  |128352/173481[42:00<15:41,47.93it/s] 74%|#######4  |128917/173481[42:11<15:29,47.93it/s] 79%|#######8  |136850/173481[45:00<12:50,47.57it/s] 79%|#######9  |137423/173481[45:12<12:38,47.57it/s] 84%|########4 |145922/173481[48:00<09:23,48.93it/s] 84%|########4 |146492/173481[48:12<09:11,48.93it/s] 89%|########9 |154609/173481[51:00<06:28,48.59it/s] 89%|########9 |155187/173481[51:12<06:16,48.59it/s] 94%|#########4|163534/173481[54:00<03:22,49.08it/s] 95%|#########4|164219/173481[54:12<03:08,49.08it/s]100%|#########9|172943/173481[57:00<00:10,50.63it/s]100%|##########|173481/173481[57:11<00:00,50.56it/s]
[32m[0329 03:02:17 @base.py:257][0m Epoch 15 (global_step 11796708) finished, time:3431.21 sec.
[32m[0329 03:02:17 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######7  |14675/18822[03:00<00:50,81.52it/s] 83%|########2 |15534/18822[03:10<00:40,81.52it/s]100%|##########|18822/18822[03:48<00:00,82.34it/s]
14
[32m[0329 03:06:06 @monitor.py:363][0m QueueInput/queue_size: 1.3446
[32m[0329 03:06:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.89
[32m[0329 03:06:06 @monitor.py:363][0m activation-summaries/output-rms: 0.036071
[32m[0329 03:06:06 @monitor.py:363][0m cross_entropy_loss: 2.4067
[32m[0329 03:06:06 @monitor.py:363][0m lr: 5.9605e-11
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5429e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9293e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9044e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1519e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5697e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5938e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6079e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9311e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8902e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.632e-06
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 03:06:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 03:06:06 @monitor.py:363][0m train-error-top1: 0.6134
[32m[0329 03:06:06 @monitor.py:363][0m val-error-top1: 0.60713
[32m[0329 03:06:06 @monitor.py:363][0m val-utt-error: 0.26118
[32m[0329 03:06:06 @monitor.py:363][0m validation_cost: 2.4193
[32m[0329 03:06:06 @monitor.py:363][0m wd_cost: 7.8417e-17
[32m[0329 03:06:06 @group.py:42][0m Callbacks took 228.843 sec in total. InferenceRunner: 228.606sec
[32m[0329 03:06:06 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9905/173481[03:00<49:32,55.03it/s]  6%|6         |10466/173481[03:10<49:22,55.03it/s] 12%|#1        |20220/173481[06:00<45:29,56.14it/s] 12%|#1        |20813/173481[06:10<45:19,56.14it/s] 17%|#7        |30314/173481[09:00<42:31,56.11it/s] 18%|#7        |30905/173481[09:10<42:21,56.11it/s] 23%|##2       |39126/173481[12:00<42:49,52.29it/s] 23%|##2       |39627/173481[12:10<42:40,52.29it/s] 27%|##7       |47700/173481[15:00<42:03,49.85it/s] 28%|##7       |48210/173481[15:10<41:52,49.85it/s] 32%|###2      |56316/173481[18:00<39:59,48.84it/s] 33%|###2      |56840/173481[18:10<39:48,48.84it/s] 38%|###7      |65337/173481[21:00<36:26,49.47it/s] 38%|###7      |65876/173481[21:10<36:15,49.47it/s] 43%|####2     |74476/173481[24:00<32:55,50.10it/s] 43%|####3     |74981/173481[24:11<32:45,50.10it/s] 48%|####7     |82886/173481[27:00<31:13,48.35it/s] 48%|####8     |83417/173481[27:11<31:02,48.35it/s] 53%|#####2    |91550/173481[30:00<28:18,48.24it/s] 53%|#####3    |92071/173481[30:11<28:07,48.24it/s] 58%|#####7    |99996/173481[33:00<25:44,47.57it/s] 58%|#####7    |100535/173481[33:11<25:33,47.57it/s] 63%|######2   |108472/173481[36:00<22:53,47.33it/s] 63%|######2   |109002/173481[36:11<22:42,47.33it/s] 67%|######7   |116920/173481[39:00<20:00,47.13it/s] 68%|######7   |117472/173481[39:11<19:48,47.13it/s] 72%|#######2  |125401/173481[42:00<17:00,47.12it/s] 73%|#######2  |125941/173481[42:11<16:48,47.12it/s] 77%|#######7  |133845/173481[45:00<14:03,47.01it/s] 77%|#######7  |134391/173481[45:12<13:51,47.01it/s] 82%|########2 |142521/173481[48:00<10:50,47.60it/s] 82%|########2 |143070/173481[48:12<10:38,47.60it/s] 87%|########6 |150842/173481[51:00<08:02,46.90it/s] 87%|########7 |151397/173481[51:12<07:50,46.90it/s] 92%|#########1|159132/173481[54:00<05:08,46.47it/s] 92%|#########2|159697/173481[54:12<04:56,46.47it/s] 97%|#########6|167470/173481[57:00<02:09,46.40it/s] 97%|#########6|168039/173481[57:12<01:57,46.40it/s]100%|##########|173481/173481[59:11<00:00,48.85it/s]
[32m[0329 04:05:18 @base.py:257][0m Epoch 16 (global_step 11970189) finished, time:3551.49 sec.
[32m[0329 04:05:18 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######7  |14585/18822[03:00<00:52,81.02it/s] 82%|########2 |15441/18822[03:10<00:41,81.02it/s]100%|##########|18822/18822[03:50<00:00,81.58it/s]
15
[32m[0329 04:09:09 @monitor.py:363][0m QueueInput/queue_size: 1.0925
[32m[0329 04:09:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.784
[32m[0329 04:09:09 @monitor.py:363][0m activation-summaries/output-rms: 0.035254
[32m[0329 04:09:09 @monitor.py:363][0m cross_entropy_loss: 2.389
[32m[0329 04:09:09 @monitor.py:363][0m lr: 2.9802e-11
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5429e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9293e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9046e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1522e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5697e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5938e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6082e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9307e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8903e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6325e-06
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 04:09:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 04:09:09 @monitor.py:363][0m train-error-top1: 0.59914
[32m[0329 04:09:09 @monitor.py:363][0m val-error-top1: 0.60697
[32m[0329 04:09:09 @monitor.py:363][0m val-utt-error: 0.26193
[32m[0329 04:09:09 @monitor.py:363][0m validation_cost: 2.4179
[32m[0329 04:09:09 @monitor.py:363][0m wd_cost: 7.8417e-17
[32m[0329 04:09:09 @group.py:42][0m Callbacks took 230.964 sec in total. InferenceRunner: 230.733sec
[32m[0329 04:09:09 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9217/173481[03:00<53:27,51.21it/s]  6%|5         |9704/173481[03:10<53:18,51.21it/s] 10%|#         |17657/173481[06:00<53:03,48.95it/s] 11%|#         |18245/173481[06:10<52:51,48.95it/s] 16%|#6        |27860/173481[09:00<46:12,52.53it/s] 16%|#6        |28349/173481[09:10<46:02,52.53it/s] 21%|##1       |36608/173481[12:00<45:11,50.49it/s] 21%|##1       |37155/173481[12:10<45:00,50.49it/s] 26%|##6       |45767/173481[15:00<41:59,50.68it/s] 27%|##6       |46297/173481[15:10<41:49,50.68it/s] 32%|###1      |54760/173481[18:00<39:19,50.32it/s] 32%|###1      |55297/173481[18:10<39:08,50.32it/s] 37%|###6      |63849/173481[21:00<36:15,50.40it/s] 37%|###7      |64394/173481[21:10<36:04,50.40it/s] 42%|####2     |73002/173481[24:00<33:04,50.62it/s] 42%|####2     |73569/173481[24:11<32:53,50.62it/s] 47%|####7     |82219/173481[27:00<29:52,50.91it/s] 48%|####7     |82772/173481[27:11<29:41,50.91it/s] 53%|#####2    |91361/173481[30:00<26:54,50.85it/s] 53%|#####2    |91940/173481[30:11<26:43,50.85it/s] 58%|#####7    |99985/173481[33:00<24:49,49.33it/s] 58%|#####7    |100524/173481[33:11<24:38,49.33it/s] 63%|######2   |108470/173481[36:00<22:28,48.21it/s] 63%|######2   |109015/173481[36:11<22:17,48.21it/s] 67%|######7   |116985/173481[39:00<19:43,47.75it/s] 68%|######7   |117550/173481[39:11<19:31,47.75it/s] 72%|#######2  |125515/173481[42:00<16:48,47.56it/s] 73%|#######2  |126044/173481[42:11<16:37,47.56it/s] 77%|#######7  |134030/173481[45:00<13:51,47.43it/s] 78%|#######7  |134588/173481[45:11<13:40,47.43it/s] 82%|########2 |142506/173481[48:00<10:55,47.26it/s] 82%|########2 |143085/173481[48:12<10:43,47.26it/s] 87%|########7 |151122/173481[51:00<07:50,47.56it/s] 87%|########7 |151704/173481[51:12<07:37,47.56it/s] 92%|#########2|159872/173481[54:00<04:43,48.08it/s] 92%|#########2|160458/173481[54:12<04:30,48.08it/s] 97%|#########7|168590/173481[57:00<01:41,48.25it/s] 98%|#########7|169160/173481[57:12<01:29,48.25it/s]100%|##########|173481/173481[58:41<00:00,49.27it/s]
[32m[0329 05:07:50 @base.py:257][0m Epoch 17 (global_step 12143670) finished, time:3521.03 sec.
[32m[0329 05:07:50 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-12143670.
[32m[0329 05:07:50 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 77%|#######7  |14519/18822[03:00<00:53,80.66it/s] 82%|########1 |15363/18822[03:10<00:42,80.66it/s]100%|##########|18822/18822[03:52<00:00,81.01it/s]
16
[32m[0329 05:11:43 @monitor.py:363][0m QueueInput/queue_size: 1.7166
[32m[0329 05:11:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.867
[32m[0329 05:11:43 @monitor.py:363][0m activation-summaries/output-rms: 0.035287
[32m[0329 05:11:43 @monitor.py:363][0m cross_entropy_loss: 2.4596
[32m[0329 05:11:43 @monitor.py:363][0m lr: 2.9802e-11
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5428e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9295e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9042e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.152e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5697e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5936e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6092e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9309e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8904e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6334e-06
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 05:11:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 05:11:43 @monitor.py:363][0m train-error-top1: 0.61865
[32m[0329 05:11:43 @monitor.py:363][0m val-error-top1: 0.6118
[32m[0329 05:11:43 @monitor.py:363][0m val-utt-error: 0.2649
[32m[0329 05:11:43 @monitor.py:363][0m validation_cost: 2.4497
[32m[0329 05:11:43 @monitor.py:363][0m wd_cost: 1.5683e-17
[32m[0329 05:11:43 @group.py:42][0m Callbacks took 233.111 sec in total. InferenceRunner: 232.354sec
[32m[0329 05:11:43 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8969/173481[03:00<55:01,49.83it/s]  5%|5         |9474/173481[03:10<54:51,49.83it/s] 10%|#         |17830/173481[06:00<52:22,49.53it/s] 11%|#         |18341/173481[06:10<52:12,49.53it/s] 15%|#5        |26853/173481[09:00<49:03,49.82it/s] 16%|#5        |27435/173481[09:10<48:51,49.82it/s] 21%|##1       |36544/173481[12:00<44:05,51.75it/s] 21%|##1       |37063/173481[12:10<43:55,51.75it/s] 26%|##5       |44997/173481[15:00<43:29,49.24it/s] 26%|##6       |45500/173481[15:10<43:19,49.24it/s] 31%|###1      |54016/173481[18:00<40:05,49.67it/s] 31%|###1      |54623/173481[18:10<39:53,49.67it/s] 36%|###6      |63006/173481[21:00<36:58,49.80it/s] 37%|###6      |63529/173481[21:10<36:47,49.80it/s] 41%|####1     |71591/173481[24:00<34:51,48.72it/s] 42%|####1     |72136/173481[24:11<34:39,48.72it/s] 46%|####6     |80204/173481[27:00<32:12,48.28it/s] 47%|####6     |80743/173481[27:11<32:00,48.28it/s] 51%|#####1    |88764/173481[30:00<29:28,47.91it/s] 51%|#####1    |89303/173481[30:11<29:17,47.91it/s] 56%|#####6    |97340/173481[33:00<26:33,47.77it/s] 56%|#####6    |97903/173481[33:11<26:21,47.77it/s] 61%|######1   |105907/173481[36:00<23:37,47.68it/s] 61%|######1   |106445/173481[36:11<23:25,47.68it/s] 66%|######6   |114588/173481[39:00<20:28,47.95it/s] 66%|######6   |115145/173481[39:11<20:16,47.95it/s] 71%|#######1  |123209/173481[42:00<17:29,47.92it/s] 71%|#######1  |123757/173481[42:11<17:17,47.92it/s] 76%|#######6  |131931/173481[45:00<14:22,48.19it/s] 76%|#######6  |132510/173481[45:12<14:10,48.19it/s] 81%|########1 |141321/173481[48:00<10:41,50.10it/s] 82%|########1 |141979/173481[48:12<10:28,50.10it/s] 87%|########6 |150522/173481[51:00<07:33,50.60it/s] 87%|########7 |151156/173481[51:12<07:21,50.60it/s] 92%|#########1|159435/173481[54:00<04:40,50.05it/s] 92%|#########2|160128/173481[54:12<04:26,50.05it/s] 97%|#########7|169047/173481[57:00<01:25,51.67it/s] 98%|#########7|169678/173481[57:12<01:13,51.67it/s]100%|##########|173481/173481[58:27<00:00,49.46it/s]
[32m[0329 06:10:10 @base.py:257][0m Epoch 18 (global_step 12317151) finished, time:3507.70 sec.
[32m[0329 06:10:11 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######9  |14939/18822[03:00<00:46,82.99it/s] 84%|########3 |15798/18822[03:10<00:36,82.99it/s]100%|##########|18822/18822[03:45<00:00,83.30it/s]
17
[32m[0329 06:13:57 @monitor.py:363][0m QueueInput/queue_size: 2.2152
[32m[0329 06:13:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.817
[32m[0329 06:13:57 @monitor.py:363][0m activation-summaries/output-rms: 0.035635
[32m[0329 06:13:57 @monitor.py:363][0m cross_entropy_loss: 2.4105
[32m[0329 06:13:57 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.543e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9296e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9038e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1519e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5698e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5937e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6098e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.931e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8906e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6343e-06
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 06:13:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 06:13:57 @monitor.py:363][0m train-error-top1: 0.60665
[32m[0329 06:13:57 @monitor.py:363][0m val-error-top1: 0.60998
[32m[0329 06:13:57 @monitor.py:363][0m val-utt-error: 0.26214
[32m[0329 06:13:57 @monitor.py:363][0m validation_cost: 2.4355
[32m[0329 06:13:57 @monitor.py:363][0m wd_cost: 1.5683e-17
[32m[0329 06:13:57 @group.py:42][0m Callbacks took 226.245 sec in total. InferenceRunner: 225.968sec
[32m[0329 06:13:57 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8868/173481[03:00<55:41,49.26it/s]  5%|5         |9346/173481[03:10<55:32,49.26it/s] 10%|9         |17339/173481[06:00<54:04,48.13it/s] 10%|#         |17818/173481[06:10<53:54,48.13it/s] 15%|#4        |25751/173481[09:00<51:55,47.42it/s] 15%|#5        |26253/173481[09:10<51:44,47.42it/s] 20%|#9        |34339/173481[12:00<48:45,47.56it/s] 20%|##        |34856/173481[12:10<48:34,47.56it/s] 26%|##5       |44706/173481[15:00<41:11,52.10it/s] 26%|##6       |45281/173481[15:10<41:00,52.10it/s] 31%|###       |53696/173481[18:00<39:08,51.00it/s] 31%|###1      |54178/173481[18:10<38:59,51.00it/s] 36%|###6      |62628/173481[21:00<36:43,50.30it/s] 36%|###6      |63234/173481[21:10<36:31,50.30it/s] 41%|####1     |71883/173481[24:00<33:17,50.85it/s] 42%|####1     |72438/173481[24:11<33:07,50.85it/s] 47%|####6     |80839/173481[27:00<30:41,50.29it/s] 47%|####6     |81363/173481[27:11<30:31,50.29it/s] 52%|#####1    |89411/173481[30:00<28:38,48.92it/s] 52%|#####1    |89958/173481[30:11<28:27,48.92it/s] 57%|#####6    |98202/173481[33:00<25:40,48.88it/s] 57%|#####6    |98759/173481[33:11<25:28,48.88it/s] 62%|######1   |107356/173481[36:00<22:06,49.85it/s] 62%|######2   |107988/173481[36:11<21:53,49.85it/s] 68%|######7   |117247/173481[39:00<17:55,52.27it/s] 68%|######7   |117883/173481[39:11<17:43,52.27it/s] 73%|#######3  |127248/173481[42:00<14:18,53.87it/s] 74%|#######3  |127900/173481[42:11<14:06,53.87it/s] 78%|#######8  |135969/173481[45:00<12:15,51.01it/s] 79%|#######8  |136527/173481[45:12<12:04,51.01it/s] 83%|########3 |144669/173481[48:00<09:40,49.63it/s] 84%|########3 |145256/173481[48:12<09:28,49.63it/s] 88%|########8 |153469/173481[51:00<06:46,49.26it/s] 89%|########8 |154072/173481[51:12<06:34,49.26it/s] 94%|#########3|162284/173481[54:00<03:47,49.11it/s] 94%|#########3|162878/173481[54:12<03:35,49.11it/s] 99%|#########8|171013/173481[57:00<00:50,48.80it/s] 99%|#########8|171586/173481[57:12<00:38,48.80it/s]100%|##########|173481/173481[57:51<00:00,49.97it/s]
[32m[0329 07:11:48 @base.py:257][0m Epoch 19 (global_step 12490632) finished, time:3471.60 sec.
[32m[0329 07:11:48 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-12490632.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######9  |14934/18822[03:00<00:46,82.96it/s] 84%|########3 |15803/18822[03:10<00:36,82.96it/s]100%|##########|18822/18822[03:45<00:00,83.55it/s]
18
[32m[0329 07:15:34 @monitor.py:363][0m QueueInput/queue_size: 1.1278
[32m[0329 07:15:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.75
[32m[0329 07:15:34 @monitor.py:363][0m activation-summaries/output-rms: 0.035318
[32m[0329 07:15:34 @monitor.py:363][0m cross_entropy_loss: 2.457
[32m[0329 07:15:34 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5428e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9296e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9039e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1516e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5697e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5937e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6095e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9311e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8906e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6345e-06
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 07:15:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 07:15:34 @monitor.py:363][0m train-error-top1: 0.61268
[32m[0329 07:15:34 @monitor.py:363][0m val-error-top1: 0.6096
[32m[0329 07:15:34 @monitor.py:363][0m val-utt-error: 0.26283
[32m[0329 07:15:34 @monitor.py:363][0m validation_cost: 2.4354
[32m[0329 07:15:34 @monitor.py:363][0m wd_cost: 3.1367e-18
[32m[0329 07:15:34 @group.py:42][0m Callbacks took 225.523 sec in total. InferenceRunner: 225.283sec
[32m[0329 07:15:34 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8793/173481[03:00<56:11,48.85it/s]  5%|5         |9250/173481[03:10<56:01,48.85it/s] 10%|#         |17453/173481[06:00<53:38,48.48it/s] 10%|#         |17973/173481[06:10<53:27,48.48it/s] 15%|#5        |26644/173481[09:00<49:12,49.73it/s] 16%|#5        |27151/173481[09:10<49:02,49.73it/s] 21%|##        |35697/173481[12:00<45:55,50.01it/s] 21%|##        |36253/173481[12:10<45:43,50.01it/s] 26%|##5       |44435/173481[15:00<43:39,49.27it/s] 26%|##5       |44951/173481[15:10<43:28,49.27it/s] 31%|###1      |53980/173481[18:00<38:59,51.08it/s] 31%|###1      |54594/173481[18:10<38:47,51.08it/s] 37%|###6      |64088/173481[21:00<34:04,53.49it/s] 37%|###7      |64688/173481[21:10<33:53,53.49it/s] 42%|####2     |73201/173481[24:00<32:07,52.02it/s] 43%|####2     |73736/173481[24:11<31:57,52.02it/s] 47%|####7     |82218/173481[27:00<29:48,51.04it/s] 48%|####7     |82767/173481[27:11<29:37,51.04it/s] 53%|#####2    |91182/173481[30:00<27:12,50.41it/s] 53%|#####2    |91719/173481[30:11<27:02,50.41it/s] 58%|#####7    |99794/173481[33:00<25:01,49.09it/s] 58%|#####7    |100345/173481[33:11<24:49,49.09it/s] 63%|######2   |108457/173481[36:00<22:17,48.60it/s] 63%|######2   |109011/173481[36:11<22:06,48.60it/s] 68%|######7   |117154/173481[39:00<19:22,48.46it/s] 68%|######7   |117798/173481[39:11<19:09,48.46it/s] 73%|#######2  |126634/173481[42:00<15:28,50.47it/s] 73%|#######3  |127227/173481[42:11<15:16,50.47it/s] 78%|#######8  |135629/173481[45:00<12:33,50.22it/s] 79%|#######8  |136273/173481[45:12<12:20,50.22it/s] 83%|########3 |144272/173481[48:00<09:55,49.09it/s] 83%|########3 |144837/173481[48:12<09:43,49.09it/s] 88%|########8 |152926/173481[51:00<07:03,48.58it/s] 89%|########8 |153576/173481[51:12<06:49,48.58it/s] 93%|#########3|162002/173481[54:00<03:51,49.48it/s] 94%|#########3|162605/173481[54:12<03:39,49.48it/s] 98%|#########8|170642/173481[57:00<00:58,48.73it/s] 99%|#########8|171241/173481[57:12<00:45,48.73it/s]100%|##########|173481/173481[58:00<00:00,49.85it/s]
[32m[0329 08:13:34 @base.py:257][0m Epoch 20 (global_step 12664113) finished, time:3480.19 sec.
[32m[0329 08:13:34 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######7  |14673/18822[03:00<00:50,81.52it/s] 83%|########2 |15530/18822[03:10<00:40,81.52it/s]100%|##########|18822/18822[03:48<00:00,82.20it/s]
19
[32m[0329 08:17:23 @monitor.py:363][0m QueueInput/queue_size: 0.95013
[32m[0329 08:17:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.89
[32m[0329 08:17:23 @monitor.py:363][0m activation-summaries/output-rms: 0.036071
[32m[0329 08:17:23 @monitor.py:363][0m cross_entropy_loss: 2.4067
[32m[0329 08:17:23 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5427e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9295e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9039e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1517e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5697e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5936e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6098e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9312e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8906e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6347e-06
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 08:17:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 08:17:23 @monitor.py:363][0m train-error-top1: 0.6134
[32m[0329 08:17:23 @monitor.py:363][0m val-error-top1: 0.60713
[32m[0329 08:17:23 @monitor.py:363][0m val-utt-error: 0.26118
[32m[0329 08:17:23 @monitor.py:363][0m validation_cost: 2.4193
[32m[0329 08:17:23 @monitor.py:363][0m wd_cost: 3.1367e-18
[32m[0329 08:17:23 @group.py:42][0m Callbacks took 229.291 sec in total. InferenceRunner: 228.994sec
[32m[0329 08:17:23 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8854/173481[03:00<55:46,49.19it/s]  5%|5         |9320/173481[03:10<55:37,49.19it/s] 10%|#         |17588/173481[06:00<53:11,48.85it/s] 10%|#         |18148/173481[06:10<52:59,48.85it/s] 16%|#5        |27309/173481[09:00<47:29,51.30it/s] 16%|#6        |27888/173481[09:10<47:18,51.30it/s] 21%|##1       |37259/173481[12:00<42:39,53.21it/s] 22%|##1       |37835/173481[12:10<42:29,53.21it/s] 27%|##7       |47218/173481[15:00<38:47,54.25it/s] 28%|##7       |47813/173481[15:10<38:36,54.25it/s] 33%|###2      |56816/173481[18:00<36:09,53.78it/s] 33%|###3      |57351/173481[18:10<35:59,53.78it/s] 38%|###7      |65296/173481[21:00<35:54,50.22it/s] 38%|###7      |65828/173481[21:11<35:43,50.22it/s] 44%|####3     |75794/173481[24:00<30:10,53.97it/s] 44%|####4     |76364/173481[24:11<29:59,53.97it/s] 49%|####8     |84184/173481[27:00<29:45,50.02it/s] 49%|####8     |84685/173481[27:11<29:35,50.02it/s] 53%|#####3    |92496/173481[30:00<28:06,48.02it/s] 54%|#####3    |93020/173481[30:11<27:55,48.02it/s] 58%|#####8    |100837/173481[33:00<25:40,47.16it/s] 58%|#####8    |101366/173481[33:11<25:28,47.16it/s] 63%|######2   |109175/173481[36:00<22:55,46.74it/s] 63%|######3   |109737/173481[36:11<22:43,46.74it/s] 68%|######7   |117615/173481[39:00<19:53,46.81it/s] 68%|######8   |118157/173481[39:11<19:41,46.81it/s] 73%|#######2  |126507/173481[42:00<16:17,48.07it/s] 73%|#######3  |127120/173481[42:11<16:04,48.07it/s] 78%|#######8  |135331/173481[45:00<13:05,48.54it/s] 78%|#######8  |135941/173481[45:12<12:53,48.54it/s] 83%|########3 |144531/173481[48:00<09:41,49.79it/s] 84%|########3 |145145/173481[48:12<09:29,49.79it/s] 88%|########8 |153481/173481[51:00<06:41,49.75it/s] 89%|########8 |154081/173481[51:12<06:29,49.75it/s] 94%|#########3|162487/173481[54:00<03:40,49.89it/s] 94%|#########4|163128/173481[54:12<03:27,49.89it/s] 99%|#########8|171218/173481[57:00<00:46,49.19it/s] 99%|#########9|171827/173481[57:12<00:33,49.19it/s]100%|##########|173481/173481[57:48<00:00,50.02it/s]
[32m[0329 09:15:11 @base.py:257][0m Epoch 21 (global_step 12837594) finished, time:3468.11 sec.
[32m[0329 09:15:12 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s] 80%|#######9  |14969/18822[03:00<00:46,83.16it/s] 84%|########4 |15832/18822[03:10<00:35,83.16it/s]100%|##########|18822/18822[03:45<00:00,83.45it/s]
20
[32m[0329 09:18:57 @monitor.py:363][0m QueueInput/queue_size: 1.1224
[32m[0329 09:18:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.784
[32m[0329 09:18:57 @monitor.py:363][0m activation-summaries/output-rms: 0.035254
[32m[0329 09:18:57 @monitor.py:363][0m cross_entropy_loss: 2.389
[32m[0329 09:18:57 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5427e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9295e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9039e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1519e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5697e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5937e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6099e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.931e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8907e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6351e-06
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 09:18:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 09:18:57 @monitor.py:363][0m train-error-top1: 0.59914
[32m[0329 09:18:57 @monitor.py:363][0m val-error-top1: 0.60697
[32m[0329 09:18:57 @monitor.py:363][0m val-utt-error: 0.26193
[32m[0329 09:18:57 @monitor.py:363][0m validation_cost: 2.4179
[32m[0329 09:18:57 @monitor.py:363][0m wd_cost: 3.1367e-18
[32m[0329 09:18:57 @group.py:42][0m Callbacks took 225.810 sec in total. InferenceRunner: 225.552sec
[32m[0329 09:18:57 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8833/173481[03:00<55:55,49.07it/s]  5%|5         |9282/173481[03:10<55:46,49.07it/s] 10%|9         |17165/173481[06:00<54:41,47.63it/s] 10%|#         |17630/173481[06:10<54:32,47.63it/s] 15%|#4        |25746/173481[09:00<51:40,47.65it/s] 15%|#5        |26231/173481[09:10<51:30,47.65it/s] 20%|#9        |34091/173481[12:00<49:26,47.00it/s] 20%|#9        |34552/173481[12:10<49:16,47.00it/s] 24%|##4       |42115/173481[15:00<47:51,45.75it/s] 25%|##4       |42589/173481[15:10<47:40,45.75it/s] 29%|##9       |50351/173481[18:00<44:51,45.75it/s] 29%|##9       |50829/173481[18:10<44:40,45.75it/s] 34%|###3      |58825/173481[21:00<41:10,46.40it/s] 34%|###4      |59335/173481[21:10<40:59,46.40it/s] 39%|###8      |67194/173481[24:00<38:08,46.45it/s] 39%|###9      |67715/173481[24:11<37:57,46.45it/s] 44%|####4     |76422/173481[27:00<33:11,48.74it/s] 44%|####4     |77088/173481[27:11<32:57,48.74it/s] 50%|####9     |86274/173481[30:00<28:11,51.56it/s] 50%|#####     |86799/173481[30:11<28:01,51.56it/s] 55%|#####4    |94993/173481[33:00<26:11,49.95it/s] 55%|#####5    |95574/173481[33:11<25:59,49.95it/s] 60%|#####9    |103880/173481[36:00<23:21,49.66it/s] 60%|######    |104415/173481[36:11<23:10,49.66it/s] 65%|######4   |112344/173481[39:00<21:05,48.30it/s] 65%|######5   |112872/173481[39:11<20:54,48.30it/s] 70%|######9   |120649/173481[42:00<18:39,47.19it/s] 70%|######9   |121179/173481[42:11<18:28,47.19it/s] 74%|#######4  |129239/173481[45:00<15:32,47.46it/s] 75%|#######4  |129887/173481[45:11<15:18,47.46it/s] 80%|########  |139120/173481[48:00<11:15,50.90it/s] 81%|########  |139773/173481[48:12<11:02,50.90it/s] 86%|########5 |149000/173481[51:00<07:43,52.82it/s] 86%|########6 |149667/173481[51:12<07:30,52.82it/s] 92%|#########1|158949/173481[54:00<04:29,54.01it/s] 92%|#########2|159628/173481[54:12<04:16,54.01it/s] 97%|#########6|167609/173481[57:00<01:55,50.89it/s] 97%|#########6|168179/173481[57:12<01:44,50.89it/s]100%|##########|173481/173481[59:05<00:00,48.93it/s]
[32m[0329 10:18:02 @base.py:257][0m Epoch 22 (global_step 13011075) finished, time:3545.25 sec.
[32m[0329 10:18:03 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-13011075.
[32m[0329 10:18:03 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######7  |14627/18822[03:00<00:51,81.26it/s] 82%|########2 |15471/18822[03:10<00:41,81.26it/s]100%|##########|18822/18822[03:50<00:00,81.83it/s]
21
[32m[0329 10:21:53 @monitor.py:363][0m QueueInput/queue_size: 1.0172
[32m[0329 10:21:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.867
[32m[0329 10:21:53 @monitor.py:363][0m activation-summaries/output-rms: 0.035287
[32m[0329 10:21:53 @monitor.py:363][0m cross_entropy_loss: 2.4596
[32m[0329 10:21:53 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5427e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9295e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9039e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.152e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5697e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5937e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6101e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9311e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8907e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.635e-06
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 10:21:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 10:21:53 @monitor.py:363][0m train-error-top1: 0.61865
[32m[0329 10:21:53 @monitor.py:363][0m val-error-top1: 0.6118
[32m[0329 10:21:53 @monitor.py:363][0m val-utt-error: 0.2649
[32m[0329 10:21:53 @monitor.py:363][0m validation_cost: 2.4497
[32m[0329 10:21:53 @monitor.py:363][0m wd_cost: 6.2733e-19
[32m[0329 10:21:53 @group.py:42][0m Callbacks took 230.821 sec in total. InferenceRunner: 230.018sec
[32m[0329 10:21:53 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9885/173481[03:00<49:39,54.91it/s]  6%|6         |10452/173481[03:10<49:28,54.91it/s] 11%|#1        |19844/173481[06:00<46:27,55.12it/s] 12%|#1        |20407/173481[06:10<46:17,55.12it/s] 17%|#7        |29757/173481[09:00<43:28,55.09it/s] 17%|#7        |30337/173481[09:10<43:18,55.09it/s] 23%|##2       |39707/173481[12:00<40:24,55.18it/s] 23%|##3       |40291/173481[12:10<40:13,55.18it/s] 29%|##8       |49640/173481[15:00<37:24,55.18it/s] 29%|##8       |50231/173481[15:10<37:13,55.18it/s] 34%|###4      |59595/173481[18:00<34:21,55.24it/s] 35%|###4      |60191/173481[18:10<34:10,55.24it/s] 40%|####      |69494/173481[21:00<31:26,55.12it/s] 40%|####      |70093/173481[21:11<31:15,55.12it/s] 46%|####5     |79387/173481[24:00<28:29,55.04it/s] 46%|####6     |79998/173481[24:11<28:18,55.04it/s] 51%|#####1    |89328/173481[27:00<25:26,55.13it/s] 52%|#####1    |89950/173481[27:11<25:15,55.13it/s] 57%|#####7    |99265/173481[30:00<22:25,55.17it/s] 58%|#####7    |99891/173481[30:11<22:13,55.17it/s] 63%|######2   |109272/173481[33:00<19:19,55.38it/s] 63%|######3   |109918/173481[33:11<19:07,55.38it/s] 69%|######8   |119236/173481[36:00<16:19,55.37it/s] 69%|######9   |119876/173481[36:11<16:08,55.37it/s] 74%|#######4  |129141/173481[39:00<13:23,55.20it/s] 75%|#######4  |129793/173481[39:11<13:11,55.20it/s] 80%|########  |139073/173481[42:00<10:23,55.18it/s] 81%|########  |139726/173481[42:11<10:11,55.18it/s] 86%|########5 |149000/173481[45:00<07:23,55.17it/s] 86%|########6 |149657/173481[45:12<07:11,55.17it/s] 92%|#########1|158960/173481[48:00<04:22,55.25it/s] 92%|#########2|159624/173481[48:12<04:10,55.25it/s] 97%|#########7|168901/173481[51:00<01:22,55.24it/s] 98%|#########7|169581/173481[51:12<01:10,55.24it/s]100%|##########|173481/173481[52:21<00:00,55.23it/s]
[32m[0329 11:14:15 @base.py:257][0m Epoch 23 (global_step 13184556) finished, time:3141.25 sec.
[32m[0329 11:14:15 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s] 68%|######7   |12786/18822[03:00<01:24,71.02it/s] 71%|#######   |13295/18822[03:10<01:17,71.02it/s]100%|##########|18822/18822[04:58<00:00,63.08it/s]
22
[32m[0329 11:19:13 @monitor.py:363][0m QueueInput/queue_size: 50
[32m[0329 11:19:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.59
[32m[0329 11:19:13 @monitor.py:363][0m activation-summaries/output-rms: 0.03493
[32m[0329 11:19:13 @monitor.py:363][0m cross_entropy_loss: 2.4023
[32m[0329 11:19:13 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5425e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9295e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9039e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1518e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5698e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5936e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6101e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9312e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8906e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6351e-06
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 11:19:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 11:19:13 @monitor.py:363][0m train-error-top1: 0.60356
[32m[0329 11:19:13 @monitor.py:363][0m val-error-top1: 0.60697
[32m[0329 11:19:13 @monitor.py:363][0m val-utt-error: 0.26209
[32m[0329 11:19:13 @monitor.py:363][0m validation_cost: 2.4181
[32m[0329 11:19:13 @monitor.py:363][0m wd_cost: 6.2733e-19
[32m[0329 11:19:13 @group.py:42][0m Callbacks took 298.620 sec in total. InferenceRunner: 298.387sec
[32m[0329 11:19:13 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9956/173481[03:00<49:16,55.31it/s]  6%|6         |10524/173481[03:10<49:06,55.31it/s] 11%|#1        |19916/173481[06:00<46:15,55.32it/s] 12%|#1        |20478/173481[06:10<46:05,55.32it/s] 17%|#7        |29902/173481[09:00<43:11,55.40it/s] 18%|#7        |30480/173481[09:10<43:01,55.40it/s] 23%|##2       |39868/173481[12:00<40:12,55.38it/s] 23%|##3       |40461/173481[12:10<40:01,55.38it/s] 29%|##8       |49840/173481[15:00<37:12,55.39it/s] 29%|##9       |50433/173481[15:10<37:01,55.39it/s] 34%|###4      |59622/173481[18:00<34:35,54.86it/s] 35%|###4      |60136/173481[18:10<34:26,54.86it/s] 39%|###9      |68123/173481[21:00<34:35,50.76it/s] 40%|###9      |68625/173481[21:11<34:25,50.76it/s] 44%|####4     |76615/173481[24:00<33:00,48.90it/s] 44%|####4     |77112/173481[24:11<32:50,48.90it/s] 49%|####8     |84964/173481[27:00<30:59,47.61it/s] 49%|####9     |85482/173481[27:11<30:48,47.61it/s] 54%|#####3    |93297/173481[30:00<28:28,46.94it/s] 54%|#####4    |93832/173481[30:11<28:16,46.94it/s] 59%|#####8    |101639/173481[33:00<25:40,46.64it/s] 59%|#####8    |102166/173481[33:11<25:29,46.64it/s] 63%|######3   |109910/173481[36:00<22:53,46.29it/s] 64%|######3   |110462/173481[36:11<22:41,46.29it/s] 68%|######8   |118310/173481[39:00<19:47,46.48it/s] 68%|######8   |118832/173481[39:11<19:35,46.48it/s] 74%|#######3  |127687/173481[42:00<15:32,49.12it/s] 74%|#######3  |128373/173481[42:11<15:18,49.12it/s] 79%|#######9  |137414/173481[45:00<11:40,51.46it/s] 80%|#######9  |137962/173481[45:12<11:30,51.46it/s] 84%|########4 |145804/173481[48:00<09:25,48.92it/s] 84%|########4 |146380/173481[48:12<09:14,48.92it/s] 89%|########8 |154365/173481[51:00<06:36,48.23it/s] 89%|########9 |154945/173481[51:12<06:24,48.23it/s] 94%|#########3|162913/173481[54:00<03:40,47.85it/s] 94%|#########4|163486/173481[54:12<03:28,47.85it/s] 99%|#########8|171143/173481[57:00<00:50,46.76it/s] 99%|#########8|171714/173481[57:12<00:37,46.76it/s]100%|##########|173481/173481[57:49<00:00,50.00it/s]
[32m[0329 12:17:03 @base.py:257][0m Epoch 24 (global_step 13358037) finished, time:3469.78 sec.
[32m[0329 12:17:03 @saver.py:84][0m Model saved to train_log/lcn_w_16_a_32_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14791/18822[03:00<00:49,82.17it/s] 83%|########3 |15652/18822[03:10<00:38,82.17it/s]100%|##########|18822/18822[03:47<00:00,82.89it/s]
23
[32m[0329 12:20:50 @monitor.py:363][0m QueueInput/queue_size: 1.1326
[32m[0329 12:20:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.75
[32m[0329 12:20:50 @monitor.py:363][0m activation-summaries/output-rms: 0.035318
[32m[0329 12:20:50 @monitor.py:363][0m cross_entropy_loss: 2.457
[32m[0329 12:20:50 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48476
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0a/b-rms: 7.5424e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35873
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.9296e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46398
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0c/b-rms: 6.9039e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35056
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1518e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46931
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.5698e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.35112
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5936e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46713
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.6102e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34942
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.9312e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49234
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0i/b-rms: 6.8905e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35599
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.6352e-06
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59394
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2664
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32431
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089455
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31418
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089033
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3057
[32m[0329 12:20:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.091887
[32m[0329 12:20:50 @monitor.py:363][0m train-error-top1: 0.61268
[32m[0329 12:20:50 @monitor.py:363][0m val-error-top1: 0.6096
[32m[0329 12:20:50 @monitor.py:363][0m val-utt-error: 0.26283
[32m[0329 12:20:50 @monitor.py:363][0m validation_cost: 2.4354
[32m[0329 12:20:50 @monitor.py:363][0m wd_cost: 6.2733e-19
[32m[0329 12:20:50 @group.py:42][0m Callbacks took 227.315 sec in total. InferenceRunner: 227.088sec
[32m[0329 12:20:50 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8742/173481[03:00<56:35,48.51it/s]  6%|5         |9611/173481[03:20<56:17,48.51it/s] 10%|9         |16961/173481[06:00<55:27,47.04it/s] 10%|#         |17428/173481[06:10<55:17,47.04it/s] 15%|#4        |25189/173481[09:00<53:18,46.37it/s] 15%|#4        |25676/173481[09:10<53:07,46.37it/s] 19%|#9        |33712/173481[12:00<49:43,46.85it/s] 20%|#9        |34203/173481[12:10<49:32,46.85it/s] 24%|##4       |42152/173481[15:00<46:42,46.87it/s] 25%|##4       |42635/173481[15:10<46:31,46.87it/s] 29%|##9       |50726/173481[18:00<43:18,47.25it/s] 30%|##9       |51217/173481[18:10<43:07,47.25it/s]slurmstepd: *** JOB 85138 ON sls-sm-3 CANCELLED AT 2018-03-29T12:39:03 ***
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 85138.0 ON sls-sm-3 CANCELLED AT 2018-03-29T12:39:03 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
