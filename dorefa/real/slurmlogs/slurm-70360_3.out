sls-sm-11 0
SLURM_JOBID=70363
SLURM_TASKID=3
[32m[0320 11:46:09 @logger.py:67][0m Existing log file 'train_log/fcn2_w_8_a_32_quant_ends_False/log.log' backuped to 'train_log/fcn2_w_8_a_32_quant_ends_False/log.log.0320-114609'
[32m[0320 11:46:09 @logger.py:74][0m Argv: drf_run.py --model_name=fcn2 --bitw=8 --bita=32 --quant_ends=False
[32m[0320 11:46:19 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0320 11:46:19 @drf_run.py:140][0m Using 6 threads
('whole utterance size', 75290)
[32m[0320 11:46:19 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0320 11:46:19 @drf_run.py:166][0m Using host: sls-sm-11
[32m[0320 11:46:19 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0320 11:46:19 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0320 11:46:19 @drf_run.py:188][0m Using GPU: 0
[32m[0320 11:46:19 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0320 11:46:19 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0320 11:46:19 @training.py:108][0m Building graph for training tower 0 ...
[32m[0320 11:46:19 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0320 11:46:19 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0320 11:46:19 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0320 11:46:19 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0320 11:46:19 @registry.py:130][0m linear0 output: [None, 504]
[32m[0320 11:46:19 @registry.py:122][0m linear1 input: [None, 504]
[32m[0320 11:46:19 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear1 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m linear2 input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear2 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m linear3 input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear3 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m last_linear input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0320 11:46:20 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0320 11:46:20 @registry.py:130][0m last_linear output: [None, 255]
[32m[0320 11:46:20 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0320 11:46:20 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0320 11:46:20 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0320 11:46:20 @drf_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0320 11:46:20 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=1400871, size=5.34MB[0m
[32m[0320 11:46:20 @base.py:196][0m Setup callbacks graph ...
[32m[0320 11:46:21 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0320 11:46:21 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0320 11:46:21 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0320 11:46:21 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0320 11:46:21 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0320 11:46:21 @drf_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0320 11:46:21 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0320 11:46:21 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0320 11:46:22 @base.py:212][0m Creating the session ...
2018-03-20 11:46:22.192999: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-20 11:46:23.178501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:02:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-03-20 11:46:23.178543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
[32m[0320 11:46:29 @base.py:220][0m Initializing the session ...
[32m[0320 11:46:29 @base.py:227][0m Graph Finalized.
[32m[0320 11:46:29 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0320 11:46:38 @monitor.py:251][0m Found existing JSON at train_log/fcn2_w_8_a_32_quant_ends_False/stat.json, will append to it.
[32m[0320 11:46:38 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0320 11:46:38 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11463/173481[03:00<42:24,63.68it/s]  7%|6         |12125/173481[03:10<42:13,63.68it/s] 13%|#3        |23161/173481[06:00<38:56,64.33it/s] 14%|#3        |23848/173481[06:10<38:46,64.33it/s] 20%|##        |34795/173481[09:00<35:51,64.47it/s] 20%|##        |35472/173481[09:10<35:40,64.47it/s] 27%|##6       |46327/173481[12:00<32:58,64.26it/s] 27%|##7       |47022/173481[12:10<32:47,64.26it/s] 34%|###3      |58356/173481[15:00<29:17,65.52it/s] 34%|###4      |59082/173481[15:10<29:06,65.52it/s] 41%|####      |70489/173481[18:00<25:50,66.45it/s] 41%|####1     |71298/173481[18:10<25:37,66.45it/s] 48%|####7     |82590/173481[21:00<22:39,66.83it/s] 48%|####8     |83310/173481[21:11<22:29,66.83it/s] 54%|#####4    |94333/173481[24:00<19:58,66.02it/s] 55%|#####4    |95107/173481[24:11<19:47,66.02it/s] 61%|######    |105260/173481[27:00<17:58,63.25it/s] 61%|######1   |105972/173481[27:11<17:47,63.25it/s] 66%|######6   |115315/173481[30:00<16:20,59.33it/s] 67%|######6   |115964/173481[30:11<16:09,59.33it/s] 73%|#######2  |126025/173481[33:00<13:18,59.41it/s] 73%|#######3  |126768/173481[33:11<13:06,59.41it/s] 79%|#######9  |137884/173481[36:00<09:29,62.48it/s] 80%|########  |139101/173481[36:11<09:10,62.48it/s] 90%|######### |156743/173481[39:00<03:33,78.28it/s] 91%|#########1|157968/173481[39:11<03:18,78.28it/s] 98%|#########7|169309/173481[42:00<00:56,73.80it/s] 98%|#########8|170070/173481[42:11<00:46,73.80it/s]100%|##########|173481/173481[43:04<00:00,67.11it/s]
[32m[0320 12:29:43 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2585.03 sec.
[32m[0320 12:29:43 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########7|18424/18822[03:00<00:03,102.35it/s]100%|##########|18822/18822[03:04<00:00,102.17it/s]
0
[32m[0320 12:32:47 @monitor.py:363][0m QueueInput/queue_size: 1.0321
[32m[0320 12:32:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8049
[32m[0320 12:32:47 @monitor.py:363][0m activation-summaries/output-rms: 0.028697
[32m[0320 12:32:47 @monitor.py:363][0m cross_entropy_loss: 2.6536
[32m[0320 12:32:47 @monitor.py:363][0m lr: 0.001
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.1103
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.67017
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.081298
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.086298
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.073089
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.073074
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 12:32:47 @monitor.py:363][0m train-error-top1: 0.6416
[32m[0320 12:32:47 @monitor.py:363][0m val-error-top1: 0.73833
[32m[0320 12:32:47 @monitor.py:363][0m val-utt-error: 0.41722
[32m[0320 12:32:47 @monitor.py:363][0m validation_cost: 3.1789
[32m[0320 12:32:47 @monitor.py:363][0m wd_cost: 0.95008
[32m[0320 12:32:47 @group.py:42][0m Callbacks took 184.906 sec in total. InferenceRunner: 184.229sec
[32m[0320 12:32:47 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12126/173481[03:00<39:55,67.37it/s]  7%|7         |12730/173481[03:10<39:46,67.37it/s] 12%|#2        |21520/173481[06:00<43:04,58.81it/s] 13%|#2        |22092/173481[06:10<42:54,58.81it/s] 19%|#8        |32218/173481[09:00<39:49,59.11it/s] 19%|#8        |32895/173481[09:10<39:38,59.11it/s] 25%|##5       |43799/173481[12:00<35:04,61.61it/s] 26%|##5       |44508/173481[12:10<34:53,61.61it/s] 32%|###2      |55738/173481[15:00<30:43,63.88it/s] 33%|###2      |56505/173481[15:10<30:31,63.88it/s] 39%|###8      |67614/173481[18:00<27:10,64.91it/s] 39%|###9      |68341/173481[18:10<26:59,64.91it/s] 46%|####5     |79723/173481[21:00<23:39,66.07it/s] 46%|####6     |80481/173481[21:11<23:27,66.07it/s] 53%|#####2    |91594/173481[24:00<20:40,66.01it/s] 53%|#####3    |92368/173481[24:11<20:28,66.01it/s] 60%|#####9    |103538/173481[27:00<17:36,66.18it/s] 60%|######    |104344/173481[27:11<17:24,66.18it/s] 67%|######6   |115480/173481[30:00<14:35,66.26it/s] 67%|######7   |116324/173481[30:11<14:22,66.26it/s] 74%|#######3  |127600/173481[33:00<11:26,66.78it/s] 74%|#######4  |128381/173481[33:11<11:15,66.78it/s] 80%|########  |139270/173481[36:00<08:40,65.79it/s] 81%|########  |140058/173481[36:11<08:28,65.79it/s] 91%|######### |157104/173481[39:00<03:27,79.07it/s] 91%|#########1|158338/173481[39:11<03:11,79.07it/s] 98%|#########8|170290/173481[42:00<00:41,76.05it/s] 99%|#########8|171079/173481[42:12<00:31,76.05it/s]100%|##########|173481/173481[42:49<00:00,67.50it/s]
[32m[0320 13:15:37 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2569.99 sec.
[32m[0320 13:15:38 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-346962.
[32m[0320 13:15:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|#########9|18739/18822[03:00<00:00,104.10it/s]100%|##########|18822/18822[03:01<00:00,103.78it/s]
1
[32m[0320 13:18:41 @monitor.py:363][0m QueueInput/queue_size: 0.42635
[32m[0320 13:18:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8763
[32m[0320 13:18:41 @monitor.py:363][0m activation-summaries/output-rms: 0.030291
[32m[0320 13:18:41 @monitor.py:363][0m cross_entropy_loss: 2.5779
[32m[0320 13:18:41 @monitor.py:363][0m lr: 0.001
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.11091
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.89088
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.081042
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.086004
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.071863
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.07271
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 13:18:41 @monitor.py:363][0m train-error-top1: 0.6286
[32m[0320 13:18:41 @monitor.py:363][0m val-error-top1: 0.73618
[32m[0320 13:18:41 @monitor.py:363][0m val-utt-error: 0.40394
[32m[0320 13:18:41 @monitor.py:363][0m validation_cost: 3.1562
[32m[0320 13:18:41 @monitor.py:363][0m wd_cost: 0.94268
[32m[0320 13:18:41 @group.py:42][0m Callbacks took 183.474 sec in total. InferenceRunner: 181.387sec
[32m[0320 13:18:41 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11479/173481[03:00<42:20,63.76it/s]  7%|6         |12119/173481[03:10<42:10,63.76it/s] 13%|#2        |22512/173481[06:00<40:15,62.50it/s] 13%|#3        |23137/173481[06:10<40:05,62.50it/s] 20%|#9        |34186/173481[09:00<36:28,63.66it/s] 20%|##        |34914/173481[09:10<36:16,63.66it/s] 26%|##6       |45589/173481[12:00<33:34,63.49it/s] 27%|##6       |46182/173481[12:10<33:25,63.49it/s] 33%|###2      |56984/173481[15:00<30:37,63.40it/s] 33%|###3      |57696/173481[15:10<30:26,63.40it/s] 40%|###9      |68932/173481[18:00<26:52,64.85it/s] 40%|####      |69660/173481[18:10<26:40,64.85it/s] 47%|####6     |80774/173481[21:00<23:39,65.32it/s] 47%|####6     |81528/173481[21:11<23:27,65.32it/s] 54%|#####3    |92945/173481[24:00<20:12,66.45it/s] 54%|#####3    |93654/173481[24:11<20:01,66.45it/s] 60%|#####9    |103639/173481[27:00<18:33,62.72it/s] 60%|######    |104235/173481[27:11<18:24,62.72it/s] 65%|######5   |113521/173481[30:00<17:04,58.55it/s] 66%|######5   |114198/173481[30:11<16:52,58.55it/s] 71%|#######1  |123607/173481[33:00<14:30,57.26it/s] 72%|#######1  |124338/173481[33:11<14:18,57.26it/s] 78%|#######8  |135512/173481[36:00<10:18,61.38it/s] 79%|#######8  |136320/173481[36:11<10:05,61.38it/s] 86%|########6 |149973/173481[39:00<05:37,69.59it/s] 87%|########7 |151206/173481[39:11<05:20,69.59it/s] 96%|#########6|167065/173481[42:00<01:19,80.32it/s] 97%|#########6|167839/173481[42:12<01:10,80.32it/s]100%|##########|173481/173481[43:36<00:00,66.30it/s]
[32m[0320 14:02:18 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2616.79 sec.
[32m[0320 14:02:18 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-520443.
[32m[0320 14:02:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########8|18623/18822[03:00<00:01,103.46it/s]100%|##########|18822/18822[03:01<00:00,103.56it/s]
2
[32m[0320 14:05:21 @monitor.py:363][0m QueueInput/queue_size: 0.58928
[32m[0320 14:05:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.2274
[32m[0320 14:05:21 @monitor.py:363][0m activation-summaries/output-rms: 0.03673
[32m[0320 14:05:21 @monitor.py:363][0m cross_entropy_loss: 2.0532
[32m[0320 14:05:21 @monitor.py:363][0m lr: 0.0005
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.17316
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.99545
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear0/W-rms: 0.11686
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.12172
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.10647
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.10992
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 14:05:21 @monitor.py:363][0m train-error-top1: 0.52868
[32m[0320 14:05:21 @monitor.py:363][0m val-error-top1: 0.58781
[32m[0320 14:05:21 @monitor.py:363][0m val-utt-error: 0.2071
[32m[0320 14:05:21 @monitor.py:363][0m validation_cost: 2.3444
[32m[0320 14:05:21 @monitor.py:363][0m wd_cost: 0.40894
[32m[0320 14:05:21 @group.py:42][0m Callbacks took 183.684 sec in total. InferenceRunner: 181.762sec
[32m[0320 14:05:21 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12197/173481[03:00<39:40,67.76it/s]  7%|7         |12876/173481[03:10<39:30,67.76it/s] 14%|#3        |24220/173481[06:00<36:58,67.27it/s] 14%|#4        |24876/173481[06:10<36:48,67.27it/s] 21%|##        |35950/173481[09:00<34:37,66.20it/s] 21%|##1       |36498/173481[09:10<34:29,66.20it/s] 27%|##7       |47584/173481[12:00<32:05,65.40it/s] 28%|##7       |48327/173481[12:10<31:53,65.40it/s] 34%|###4      |59126/173481[15:00<29:25,64.75it/s] 35%|###4      |59919/173481[15:10<29:13,64.75it/s] 41%|####1     |71374/173481[18:00<25:38,66.35it/s] 42%|####1     |72261/173481[18:10<25:25,66.35it/s] 48%|####8     |83338/173481[21:00<22:37,66.41it/s] 48%|####8     |84066/173481[21:11<22:26,66.41it/s] 55%|#####4    |95307/173481[24:00<19:36,66.45it/s] 55%|#####5    |96058/173481[24:11<19:25,66.45it/s] 62%|######1   |107150/173481[27:00<16:43,66.12it/s] 62%|######2   |107853/173481[27:11<16:32,66.12it/s] 69%|######8   |119078/173481[30:00<13:41,66.19it/s] 69%|######9   |119835/173481[30:11<13:30,66.19it/s] 76%|#######5  |131218/173481[33:00<10:32,66.81it/s] 76%|#######6  |131998/173481[33:11<10:20,66.81it/s] 83%|########2 |143905/173481[36:00<07:11,68.60it/s] 83%|########3 |144729/173481[36:11<06:59,68.60it/s] 90%|######### |156735/173481[39:00<03:59,69.91it/s] 91%|######### |157605/173481[39:11<03:47,69.91it/s]100%|#########9|173384/173481[42:00<00:01,79.63it/s]100%|##########|173481/173481[42:01<00:00,68.81it/s]
[32m[0320 14:47:22 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2521.05 sec.
[32m[0320 14:47:23 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-693924.
[32m[0320 14:47:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 83%|########2 |15584/18822[03:00<00:37,86.57it/s] 86%|########5 |16114/18822[03:10<00:31,86.57it/s]100%|##########|18822/18822[03:46<00:00,83.01it/s]
3
[32m[0320 14:51:11 @monitor.py:363][0m QueueInput/queue_size: 0.75645
[32m[0320 14:51:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.507
[32m[0320 14:51:11 @monitor.py:363][0m activation-summaries/output-rms: 0.038687
[32m[0320 14:51:11 @monitor.py:363][0m cross_entropy_loss: 1.8676
[32m[0320 14:51:11 @monitor.py:363][0m lr: 0.0005
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.1964
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0413
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12377
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13709
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12773
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.12803
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 14:51:11 @monitor.py:363][0m train-error-top1: 0.47936
[32m[0320 14:51:11 @monitor.py:363][0m val-error-top1: 0.54135
[32m[0320 14:51:11 @monitor.py:363][0m val-utt-error: 0.16029
[32m[0320 14:51:11 @monitor.py:363][0m validation_cost: 2.1296
[32m[0320 14:51:11 @monitor.py:363][0m wd_cost: 0.51521
[32m[0320 14:51:11 @group.py:42][0m Callbacks took 228.459 sec in total. InferenceRunner: 226.751sec
[32m[0320 14:51:11 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11789/173481[03:00<41:08,65.49it/s]  7%|7         |12510/173481[03:10<40:57,65.49it/s] 14%|#4        |24623/173481[06:00<36:20,68.27it/s] 15%|#4        |25359/173481[06:10<36:09,68.27it/s] 21%|##        |36193/173481[09:00<34:33,66.21it/s] 21%|##1       |36846/173481[09:10<34:23,66.21it/s] 27%|##7       |47070/173481[12:00<33:20,63.18it/s] 27%|##7       |47706/173481[12:10<33:10,63.18it/s] 33%|###3      |58072/173481[15:00<30:57,62.14it/s] 34%|###3      |58762/173481[15:10<30:46,62.14it/s] 40%|####      |69689/173481[18:00<27:19,63.31it/s] 41%|####      |70374/173481[18:10<27:08,63.31it/s] 47%|####6     |80719/173481[21:00<24:49,62.27it/s] 47%|####6     |81234/173481[21:11<24:41,62.27it/s] 52%|#####1    |90097/173481[24:00<24:30,56.72it/s] 52%|#####2    |90738/173481[24:11<24:18,56.72it/s] 58%|#####7    |100465/173481[27:00<21:17,57.15it/s] 58%|#####8    |101148/173481[27:11<21:05,57.15it/s] 65%|######4   |112328/173481[30:00<16:38,61.22it/s] 65%|######5   |113098/173481[30:11<16:26,61.22it/s] 72%|#######1  |124237/173481[33:00<12:54,63.59it/s] 72%|#######2  |124980/173481[33:11<12:42,63.59it/s] 79%|#######8  |136189/173481[36:00<09:34,64.96it/s] 79%|#######8  |136992/173481[36:11<09:21,64.96it/s] 85%|########4 |147445/173481[39:00<06:48,63.72it/s] 85%|########5 |148083/173481[39:11<06:38,63.72it/s] 91%|#########1|158721/173481[42:00<03:53,63.18it/s] 92%|#########1|159492/173481[42:12<03:41,63.18it/s] 98%|#########8|170706/173481[45:00<00:42,64.84it/s] 99%|#########8|171480/173481[45:12<00:30,64.84it/s]100%|##########|173481/173481[45:42<00:00,63.25it/s]
[32m[0320 15:36:54 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2742.63 sec.
[32m[0320 15:36:54 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-867405.
[32m[0320 15:36:55 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:34<00:00,121.59it/s]
4
[32m[0320 15:39:30 @monitor.py:363][0m QueueInput/queue_size: 0.81141
[32m[0320 15:39:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.33
[32m[0320 15:39:30 @monitor.py:363][0m activation-summaries/output-rms: 0.039483
[32m[0320 15:39:30 @monitor.py:363][0m cross_entropy_loss: 1.7627
[32m[0320 15:39:30 @monitor.py:363][0m lr: 0.0005
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.19788
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0898
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12485
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13956
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.13205
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.13098
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 15:39:30 @monitor.py:363][0m train-error-top1: 0.4628
[32m[0320 15:39:30 @monitor.py:363][0m val-error-top1: 0.52254
[32m[0320 15:39:30 @monitor.py:363][0m val-utt-error: 0.14674
[32m[0320 15:39:30 @monitor.py:363][0m validation_cost: 2.0394
[32m[0320 15:39:30 @monitor.py:363][0m wd_cost: 0.53247
[32m[0320 15:39:30 @group.py:42][0m Callbacks took 156.601 sec in total. InferenceRunner: 154.807sec
[32m[0320 15:39:30 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10930/173481[03:00<44:37,60.71it/s]  7%|6         |11520/173481[03:10<44:27,60.71it/s] 12%|#2        |21358/173481[06:00<42:45,59.28it/s] 13%|#2        |21939/173481[06:10<42:36,59.28it/s] 18%|#8        |31431/173481[09:00<41:07,57.57it/s] 18%|#8        |31971/173481[09:10<40:57,57.57it/s] 24%|##3       |41544/173481[12:00<38:39,56.87it/s] 24%|##4       |42158/173481[12:10<38:29,56.87it/s] 30%|##9       |51537/173481[15:00<36:10,56.19it/s] 30%|###       |52129/173481[15:10<35:59,56.19it/s] 35%|###5      |61456/173481[18:00<33:33,55.63it/s] 36%|###5      |62050/173481[18:10<33:23,55.63it/s] 41%|####1     |71524/173481[21:00<30:27,55.78it/s] 42%|####1     |72123/173481[21:10<30:17,55.78it/s] 47%|####6     |81351/173481[24:00<27:49,55.18it/s] 47%|####7     |81975/173481[24:11<27:38,55.18it/s] 53%|#####2    |91318/173481[27:00<24:46,55.27it/s] 53%|#####2    |91942/173481[27:11<24:35,55.27it/s] 58%|#####8    |101319/173481[30:00<21:42,55.41it/s] 59%|#####8    |101957/173481[30:11<21:30,55.41it/s] 64%|######4   |111304/173481[33:00<18:41,55.44it/s] 65%|######4   |111914/173481[33:11<18:30,55.44it/s] 70%|#######   |122090/173481[36:00<14:52,57.59it/s] 71%|#######   |122829/173481[36:11<14:39,57.59it/s] 77%|#######7  |133869/173481[39:00<10:46,61.26it/s] 78%|#######7  |134593/173481[39:11<10:34,61.26it/s] 83%|########3 |144100/173481[42:00<08:18,58.97it/s] 83%|########3 |144771/173481[42:12<08:06,58.97it/s] 89%|########8 |154024/173481[45:00<05:41,56.98it/s] 89%|########9 |154679/173481[45:12<05:29,56.98it/s] 95%|#########4|164068/173481[48:00<02:46,56.38it/s] 95%|#########4|164751/173481[48:12<02:34,56.38it/s][32m[0320 16:30:25 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:3054.47 sec.
100%|##########|173481/173481[50:54<00:00,56.80it/s]
[32m[0320 16:30:25 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-1040886.
[32m[0320 16:30:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,199.47it/s]
5
[32m[0320 16:32:01 @monitor.py:363][0m QueueInput/queue_size: 0.49082
[32m[0320 16:32:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 18.517
[32m[0320 16:32:01 @monitor.py:363][0m activation-summaries/output-rms: 0.045638
[32m[0320 16:32:01 @monitor.py:363][0m cross_entropy_loss: 1.3527
[32m[0320 16:32:01 @monitor.py:363][0m lr: 0.00025
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.25923
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1137
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.16149
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.17085
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.16703
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16546
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 16:32:01 @monitor.py:363][0m train-error-top1: 0.368
[32m[0320 16:32:01 @monitor.py:363][0m val-error-top1: 0.41766
[32m[0320 16:32:01 @monitor.py:363][0m val-utt-error: 0.079322
[32m[0320 16:32:01 @monitor.py:363][0m validation_cost: 1.5715
[32m[0320 16:32:01 @monitor.py:363][0m wd_cost: 0.17294
[32m[0320 16:32:01 @group.py:42][0m Callbacks took 96.319 sec in total. InferenceRunner: 94.373sec
[32m[0320 16:32:01 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10771/173481[03:00<45:19,59.83it/s]  7%|6         |11375/173481[03:10<45:09,59.83it/s] 12%|#2        |20995/173481[06:00<43:36,58.27it/s] 12%|#2        |21611/173481[06:10<43:26,58.27it/s] 18%|#8        |31519/173481[09:00<40:32,58.36it/s] 19%|#8        |32115/173481[09:10<40:22,58.36it/s] 24%|##3       |41599/173481[12:00<38:27,57.14it/s] 24%|##4       |42192/173481[12:10<38:17,57.14it/s] 30%|##9       |51666/173481[15:00<35:54,56.53it/s] 30%|###       |52230/173481[15:10<35:44,56.53it/s] 36%|###5      |61609/173481[18:00<33:22,55.87it/s] 36%|###5      |62154/173481[18:10<33:12,55.87it/s] 41%|####1     |71620/173481[21:00<30:27,55.74it/s] 42%|####1     |72216/173481[21:11<30:16,55.74it/s] 47%|####7     |81727/173481[24:00<27:20,55.93it/s] 47%|####7     |82324/173481[24:11<27:09,55.93it/s] 53%|#####2    |91273/173481[27:00<25:10,54.43it/s] 53%|#####2    |91886/173481[27:11<24:59,54.43it/s] 58%|#####8    |100705/173481[30:00<22:43,53.39it/s] 58%|#####8    |101298/173481[30:11<22:31,53.39it/s] 64%|######3   |110335/173481[33:00<19:41,53.43it/s] 64%|######3   |110940/173481[33:11<19:30,53.43it/s] 69%|######9   |120124/173481[36:00<16:29,53.90it/s] 70%|######9   |120696/173481[36:11<16:19,53.90it/s] 75%|#######4  |129805/173481[39:00<13:31,53.84it/s] 75%|#######5  |130380/173481[39:11<13:20,53.84it/s] 80%|########  |139351/173481[42:00<10:38,53.43it/s] 81%|########  |139970/173481[42:12<10:27,53.43it/s] 86%|########5 |149011/173481[45:00<07:37,53.53it/s] 86%|########6 |149654/173481[45:12<07:25,53.53it/s] 92%|#########1|158863/173481[48:00<04:30,54.12it/s] 92%|#########1|159498/173481[48:12<04:18,54.12it/s] 97%|#########7|168691/173481[51:00<01:28,54.35it/s] 98%|#########7|169350/173481[51:12<01:16,54.35it/s]100%|##########|173481/173481[52:28<00:00,55.10it/s]
[32m[0320 17:24:29 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:3148.54 sec.
[32m[0320 17:24:31 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-1214367.
[32m[0320 17:24:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,183.11it/s]
6
[32m[0320 17:26:15 @monitor.py:363][0m QueueInput/queue_size: 0.61242
[32m[0320 17:26:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 26.938
[32m[0320 17:26:15 @monitor.py:363][0m activation-summaries/output-rms: 0.046001
[32m[0320 17:26:15 @monitor.py:363][0m cross_entropy_loss: 1.3069
[32m[0320 17:26:15 @monitor.py:363][0m lr: 0.00025
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.32751
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1236
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.18346
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.19902
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19759
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19505
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 17:26:15 @monitor.py:363][0m train-error-top1: 0.34971
[32m[0320 17:26:15 @monitor.py:363][0m val-error-top1: 0.39205
[32m[0320 17:26:15 @monitor.py:363][0m val-utt-error: 0.068059
[32m[0320 17:26:15 @monitor.py:363][0m validation_cost: 1.4689
[32m[0320 17:26:15 @monitor.py:363][0m wd_cost: 0.24157
[32m[0320 17:26:15 @group.py:42][0m Callbacks took 105.249 sec in total. InferenceRunner: 102.807sec
[32m[0320 17:26:15 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10139/173481[03:00<48:19,56.33it/s]  6%|6         |10695/173481[03:10<48:10,56.33it/s] 11%|#1        |19282/173481[06:00<48:06,53.41it/s] 11%|#1        |19833/173481[06:10<47:56,53.41it/s] 16%|#6        |28618/173481[09:00<45:52,52.62it/s] 17%|#6        |29169/173481[09:10<45:42,52.62it/s] 22%|##1       |37942/173481[12:00<43:16,52.20it/s] 22%|##2       |38435/173481[12:10<43:07,52.20it/s] 27%|##6       |46408/173481[15:00<42:48,49.48it/s] 27%|##7       |46963/173481[15:10<42:36,49.48it/s] 32%|###2      |55677/173481[18:00<38:54,50.47it/s] 32%|###2      |56233/173481[18:10<38:43,50.47it/s] 37%|###7      |64270/173481[21:00<37:06,49.05it/s] 37%|###7      |64797/173481[21:11<36:55,49.05it/s] 42%|####2     |73056/173481[24:00<34:12,48.93it/s] 42%|####2     |73581/173481[24:11<34:01,48.93it/s] 47%|####6     |81202/173481[27:00<32:42,47.01it/s] 47%|####7     |81711/173481[27:11<32:32,47.01it/s] 52%|#####1    |89458/173481[30:00<30:10,46.42it/s] 52%|#####1    |89931/173481[30:11<29:59,46.42it/s] 57%|#####6    |98026/173481[33:00<26:45,47.00it/s] 57%|#####6    |98577/173481[33:11<26:33,47.00it/s] 62%|######1   |107336/173481[36:00<22:23,49.25it/s] 62%|######2   |107907/173481[36:11<22:11,49.25it/s] 67%|######7   |116386/173481[39:00<19:07,49.75it/s] 67%|######7   |116987/173481[39:11<18:55,49.75it/s] 72%|#######2  |125752/173481[42:00<15:38,50.86it/s] 73%|#######2  |126225/173481[42:12<15:29,50.86it/s] 78%|#######7  |134770/173481[45:00<12:47,50.47it/s] 78%|#######8  |135381/173481[45:12<12:34,50.47it/s] 83%|########3 |144136/173481[48:00<09:32,51.24it/s] 83%|########3 |144709/173481[48:12<09:21,51.24it/s] 88%|########8 |153218/173481[51:00<06:38,50.84it/s] 89%|########8 |153831/173481[51:12<06:26,50.84it/s] 94%|#########3|162736/173481[54:00<03:27,51.83it/s] 94%|#########4|163383/173481[54:12<03:14,51.83it/s] 99%|#########9|172288/173481[57:00<00:22,52.43it/s]100%|#########9|172912/173481[57:12<00:10,52.43it/s]100%|##########|173481/173481[57:23<00:00,50.38it/s]
[32m[0320 18:23:38 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:3443.44 sec.
[32m[0320 18:23:39 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-1387848.
[32m[0320 18:23:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.31it/s]
7
[32m[0320 18:25:37 @monitor.py:363][0m QueueInput/queue_size: 0.67781
[32m[0320 18:25:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.56
[32m[0320 18:25:37 @monitor.py:363][0m activation-summaries/output-rms: 0.047051
[32m[0320 18:25:37 @monitor.py:363][0m cross_entropy_loss: 1.2068
[32m[0320 18:25:37 @monitor.py:363][0m lr: 0.00025
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.36399
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1363
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.18891
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20789
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20722
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20355
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 18:25:37 @monitor.py:363][0m train-error-top1: 0.32646
[32m[0320 18:25:37 @monitor.py:363][0m val-error-top1: 0.3824
[32m[0320 18:25:37 @monitor.py:363][0m val-utt-error: 0.061471
[32m[0320 18:25:37 @monitor.py:363][0m validation_cost: 1.4209
[32m[0320 18:25:37 @monitor.py:363][0m wd_cost: 0.26969
[32m[0320 18:25:37 @group.py:42][0m Callbacks took 118.991 sec in total. InferenceRunner: 117.428sec
[32m[0320 18:25:37 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10182/173481[03:00<48:06,56.57it/s]  6%|6         |10722/173481[03:10<47:57,56.57it/s] 11%|#1        |19348/173481[06:00<47:55,53.59it/s] 11%|#1        |19884/173481[06:10<47:45,53.59it/s] 16%|#6        |28189/173481[09:00<47:14,51.25it/s] 17%|#6        |28740/173481[09:10<47:04,51.25it/s] 22%|##1       |37567/173481[12:00<43:50,51.66it/s] 22%|##1       |38078/173481[12:10<43:40,51.66it/s] 27%|##7       |47056/173481[15:00<40:22,52.18it/s] 27%|##7       |47700/173481[15:10<40:10,52.18it/s] 33%|###2      |56680/173481[18:00<36:51,52.82it/s] 33%|###3      |57267/173481[18:10<36:40,52.82it/s] 38%|###8      |66265/173481[21:00<33:41,53.03it/s] 39%|###8      |66845/173481[21:11<33:31,53.03it/s] 44%|####3     |75545/173481[24:00<31:13,52.28it/s] 44%|####3     |76143/173481[24:11<31:01,52.28it/s] 49%|####9     |85398/173481[27:00<27:27,53.48it/s] 50%|####9     |86004/173481[27:11<27:15,53.48it/s] 55%|#####4    |94717/173481[30:00<24:57,52.61it/s] 55%|#####4    |95322/173481[30:11<24:45,52.61it/s] 60%|#####9    |103809/173481[33:00<22:31,51.54it/s] 60%|######    |104349/173481[33:11<22:21,51.54it/s] 64%|######4   |111895/173481[36:00<21:23,47.99it/s] 65%|######4   |112418/173481[36:11<21:12,47.99it/s] 70%|######9   |121309/173481[39:00<17:22,50.05it/s] 70%|#######   |121935/173481[39:11<17:09,50.05it/s] 76%|#######5  |131533/173481[42:00<13:08,53.20it/s] 76%|#######6  |132144/173481[42:12<12:56,53.20it/s] 81%|########1 |141193/173481[45:00<10:04,53.43it/s] 82%|########1 |141833/173481[45:12<09:52,53.43it/s] 87%|########7 |150937/173481[48:00<06:59,53.77it/s] 87%|########7 |151590/173481[48:12<06:47,53.77it/s] 93%|#########2|161011/173481[51:00<03:47,54.84it/s] 93%|#########3|161680/173481[51:12<03:35,54.84it/s] 99%|#########8|171330/173481[54:00<00:38,56.05it/s] 99%|#########9|172038/173481[54:12<00:25,56.05it/s]100%|##########|173481/173481[54:38<00:00,52.92it/s]
[32m[0320 19:20:15 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:3278.15 sec.
[32m[0320 19:20:16 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-1561329.
[32m[0320 19:20:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,184.30it/s]
8
[32m[0320 19:22:00 @monitor.py:363][0m QueueInput/queue_size: 0.52197
[32m[0320 19:22:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.97
[32m[0320 19:22:00 @monitor.py:363][0m activation-summaries/output-rms: 0.049198
[32m[0320 19:22:00 @monitor.py:363][0m cross_entropy_loss: 1.0898
[32m[0320 19:22:00 @monitor.py:363][0m lr: 0.000125
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.41649
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1423
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.20924
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.21966
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21876
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.21508
[32m[0320 19:22:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 19:22:00 @monitor.py:363][0m train-error-top1: 0.29939
[32m[0320 19:22:00 @monitor.py:363][0m val-error-top1: 0.33187
[32m[0320 19:22:00 @monitor.py:363][0m val-utt-error: 0.04261
[32m[0320 19:22:00 @monitor.py:363][0m validation_cost: 1.2113
[32m[0320 19:22:00 @monitor.py:363][0m wd_cost: 0.064416
[32m[0320 19:22:00 @group.py:42][0m Callbacks took 104.816 sec in total. InferenceRunner: 102.140sec
[32m[0320 19:22:00 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10932/173481[03:00<44:36,60.73it/s]  7%|6         |11505/173481[03:10<44:27,60.73it/s] 12%|#1        |20734/173481[06:00<44:20,57.42it/s] 12%|#2        |21238/173481[06:10<44:11,57.42it/s] 18%|#7        |30506/173481[09:00<42:41,55.81it/s] 18%|#7        |31125/173481[09:10<42:30,55.81it/s] 23%|##3       |40396/173481[12:00<40:03,55.37it/s] 24%|##3       |40966/173481[12:10<39:53,55.37it/s] 29%|##9       |50404/173481[15:00<36:58,55.48it/s] 29%|##9       |51057/173481[15:10<36:46,55.48it/s] 35%|###5      |60730/173481[18:00<33:18,56.40it/s] 35%|###5      |61359/173481[18:10<33:07,56.40it/s] 41%|####1     |71254/173481[21:00<29:40,57.41it/s] 41%|####1     |71913/173481[21:11<29:29,57.41it/s] 47%|####6     |81388/173481[24:00<27:00,56.84it/s] 47%|####7     |82027/173481[24:11<26:48,56.84it/s] 53%|#####2    |91757/173481[27:00<23:48,57.22it/s] 53%|#####3    |92391/173481[27:11<23:37,57.22it/s] 59%|#####8    |102181/173481[30:00<20:38,57.56it/s] 59%|#####9    |102807/173481[30:11<20:27,57.56it/s] 65%|######4   |112498/173481[33:00<17:41,57.43it/s] 65%|######5   |113143/173481[33:11<17:30,57.43it/s] 71%|#######   |122314/173481[36:00<15:14,55.94it/s] 71%|#######   |122925/173481[36:11<15:03,55.94it/s] 76%|#######5  |131458/173481[39:00<13:09,53.24it/s] 76%|#######6  |132063/173481[39:11<12:57,53.24it/s] 81%|########1 |141028/173481[42:00<10:09,53.20it/s] 82%|########1 |141646/173481[42:12<09:58,53.20it/s] 87%|########6 |150467/173481[45:00<07:15,52.82it/s] 87%|########7 |151149/173481[45:12<07:02,52.82it/s] 93%|#########2|160858/173481[48:00<03:48,55.16it/s] 93%|#########3|161592/173481[48:12<03:35,55.16it/s] 99%|#########8|170916/173481[51:00<00:46,55.52it/s] 99%|#########8|171561/173481[51:12<00:34,55.52it/s]100%|##########|173481/173481[51:46<00:00,55.84it/s]
[32m[0320 20:13:47 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:3106.82 sec.
[32m[0320 20:13:48 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-1734810.
[32m[0320 20:13:49 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:48<00:00,172.81it/s]
9
[32m[0320 20:15:38 @monitor.py:363][0m QueueInput/queue_size: 0.83143
[32m[0320 20:15:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 49.057
[32m[0320 20:15:38 @monitor.py:363][0m activation-summaries/output-rms: 0.047787
[32m[0320 20:15:38 @monitor.py:363][0m cross_entropy_loss: 1.0953
[32m[0320 20:15:38 @monitor.py:363][0m lr: 0.000125
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.47329
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1446
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.23144
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.23548
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.23506
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.23127
[32m[0320 20:15:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 20:15:38 @monitor.py:363][0m train-error-top1: 0.29603
[32m[0320 20:15:38 @monitor.py:363][0m val-error-top1: 0.32407
[32m[0320 20:15:38 @monitor.py:363][0m val-utt-error: 0.037297
[32m[0320 20:15:38 @monitor.py:363][0m validation_cost: 1.1809
[32m[0320 20:15:38 @monitor.py:363][0m wd_cost: 0.077992
[32m[0320 20:15:38 @group.py:42][0m Callbacks took 111.075 sec in total. InferenceRunner: 108.929sec
[32m[0320 20:15:38 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11929/173481[03:00<40:38,66.26it/s]  7%|7         |12474/173481[03:10<40:30,66.26it/s] 13%|#2        |22081/173481[06:00<41:24,60.93it/s] 13%|#3        |22716/173481[06:10<41:14,60.93it/s] 19%|#8        |32464/173481[09:00<39:39,59.26it/s] 19%|#9        |33060/173481[09:10<39:29,59.26it/s] 25%|##4       |42607/173481[12:00<37:45,57.76it/s] 25%|##4       |43218/173481[12:10<37:35,57.76it/s] 31%|###       |53092/173481[15:00<34:35,58.00it/s] 31%|###       |53682/173481[15:10<34:25,58.00it/s] 36%|###6      |63271/173481[18:00<32:04,57.26it/s] 37%|###6      |63894/173481[18:10<31:53,57.26it/s] 42%|####2     |73555/173481[21:00<29:07,57.19it/s] 43%|####2     |74155/173481[21:11<28:56,57.19it/s] 48%|####8     |83709/173481[24:00<26:20,56.80it/s] 49%|####8     |84330/173481[24:11<26:09,56.80it/s] 54%|#####4    |93955/173481[27:00<23:18,56.86it/s] 55%|#####4    |94620/173481[27:11<23:07,56.86it/s] 60%|######    |104377/173481[30:00<20:04,57.36it/s] 61%|######    |105018/173481[30:11<19:53,57.36it/s] 66%|######6   |114524/173481[33:00<17:16,56.86it/s] 66%|######6   |115091/173481[33:11<17:06,56.86it/s] 72%|#######2  |125595/173481[36:00<13:30,59.09it/s] 73%|#######2  |126385/173481[36:11<13:16,59.09it/s] 79%|#######9  |137822/173481[39:00<09:24,63.20it/s] 80%|#######9  |138673/173481[39:12<09:10,63.20it/s] 86%|########5 |148688/173481[42:00<06:41,61.75it/s] 86%|########6 |149406/173481[42:12<06:29,61.75it/s] 92%|#########2|160003/173481[45:00<03:36,62.30it/s] 93%|#########2|160788/173481[45:12<03:23,62.30it/s] 99%|#########8|171433/173481[48:00<00:32,62.88it/s] 99%|#########9|172195/173481[48:12<00:20,62.88it/s]100%|##########|173481/173481[48:30<00:00,59.62it/s]
[32m[0320 21:04:08 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:2910.01 sec.
[32m[0320 21:04:09 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-1908291.
[32m[0320 21:04:11 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:43<00:00,181.10it/s]
10
[32m[0320 21:05:54 @monitor.py:363][0m QueueInput/queue_size: 0.53727
[32m[0320 21:05:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 55.329
[32m[0320 21:05:54 @monitor.py:363][0m activation-summaries/output-rms: 0.049615
[32m[0320 21:05:54 @monitor.py:363][0m cross_entropy_loss: 0.99711
[32m[0320 21:05:54 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.52062
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1456
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.24435
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.24578
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2462
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.24231
[32m[0320 21:05:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 21:05:54 @monitor.py:363][0m train-error-top1: 0.27762
[32m[0320 21:05:54 @monitor.py:363][0m val-error-top1: 0.30439
[32m[0320 21:05:54 @monitor.py:363][0m val-utt-error: 0.031346
[32m[0320 21:05:54 @monitor.py:363][0m validation_cost: 1.0978
[32m[0320 21:05:54 @monitor.py:363][0m wd_cost: 0.088467
[32m[0320 21:05:54 @group.py:42][0m Callbacks took 106.428 sec in total. InferenceRunner: 103.944sec
[32m[0320 21:05:54 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13498/173481[03:00<35:33,74.98it/s]  8%|8         |14145/173481[03:10<35:24,74.98it/s] 19%|#8        |32420/173481[06:00<26:51,87.53it/s] 19%|#9        |33651/173481[06:10<26:37,87.53it/s] 29%|##9       |51152/173481[09:00<21:26,95.08it/s] 30%|###       |52283/173481[09:10<21:14,95.08it/s] 39%|###8      |66899/173481[12:00<19:29,91.12it/s] 39%|###9      |67695/173481[12:10<19:20,91.12it/s] 46%|####5     |79757/173481[15:00<19:30,80.08it/s] 47%|####6     |80679/173481[15:10<19:18,80.08it/s] 53%|#####3    |92728/173481[18:00<17:44,75.86it/s] 54%|#####3    |93333/173481[18:11<17:36,75.86it/s] 60%|######    |104416/173481[21:00<16:27,69.96it/s] 61%|######    |105063/173481[21:11<16:17,69.96it/s] 66%|######5   |113896/173481[24:00<16:31,60.09it/s] 66%|######5   |114459/173481[24:11<16:22,60.09it/s] 71%|#######1  |123412/173481[27:00<14:50,56.24it/s] 71%|#######1  |123993/173481[27:11<14:39,56.24it/s] 77%|#######6  |133338/173481[30:00<12:00,55.68it/s] 77%|#######7  |133953/173481[30:11<11:49,55.68it/s] 83%|########2 |143434/173481[33:00<08:57,55.88it/s] 83%|########3 |144056/173481[33:11<08:46,55.88it/s] 89%|########8 |153670/173481[36:00<05:51,56.37it/s] 89%|########8 |154330/173481[36:11<05:39,56.37it/s] 94%|#########4|163911/173481[39:00<02:48,56.63it/s] 95%|#########4|164565/173481[39:12<02:37,56.63it/s]100%|##########|173481/173481[41:55<00:00,68.97it/s]
[32m[0320 21:47:50 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:2515.21 sec.
[32m[0320 21:47:50 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-2081772.
[32m[0320 21:47:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.11it/s]
11
[32m[0320 21:49:45 @monitor.py:363][0m QueueInput/queue_size: 0.83312
[32m[0320 21:49:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 62.25
[32m[0320 21:49:45 @monitor.py:363][0m activation-summaries/output-rms: 0.050517
[32m[0320 21:49:45 @monitor.py:363][0m cross_entropy_loss: 0.93751
[32m[0320 21:49:45 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.55439
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1466
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.25496
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.25073
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2508
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.24704
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 21:49:45 @monitor.py:363][0m train-error-top1: 0.25855
[32m[0320 21:49:45 @monitor.py:363][0m val-error-top1: 0.29769
[32m[0320 21:49:45 @monitor.py:363][0m val-utt-error: 0.03039
[32m[0320 21:49:45 @monitor.py:363][0m validation_cost: 1.0749
[32m[0320 21:49:45 @monitor.py:363][0m wd_cost: 0.019153
[32m[0320 21:49:45 @group.py:42][0m Callbacks took 114.926 sec in total. InferenceRunner: 112.645sec
[32m[0320 21:49:45 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12721/173481[03:00<37:55,70.64it/s]  8%|7         |13230/173481[03:10<37:48,70.64it/s] 13%|#2        |22231/173481[06:00<41:42,60.45it/s] 13%|#3        |22794/173481[06:10<41:32,60.45it/s] 19%|#8        |32833/173481[09:00<39:17,59.66it/s] 19%|#9        |33450/173481[09:10<39:06,59.66it/s] 25%|##4       |43141/173481[12:00<37:10,58.42it/s] 25%|##5       |43708/173481[12:10<37:01,58.42it/s] 31%|###       |53077/173481[15:00<35:21,56.76it/s] 31%|###       |53694/173481[15:10<35:10,56.76it/s] 37%|###6      |63379/173481[18:00<32:11,56.99it/s] 37%|###6      |63966/173481[18:10<32:01,56.99it/s] 43%|####2     |73789/173481[21:00<28:56,57.41it/s] 43%|####2     |74395/173481[21:11<28:45,57.41it/s] 48%|####8     |83989/173481[24:00<26:09,57.03it/s] 49%|####8     |84540/173481[24:11<25:59,57.03it/s] 54%|#####4    |93741/173481[27:00<23:55,55.57it/s] 54%|#####4    |94368/173481[27:11<23:43,55.57it/s] 60%|#####9    |103723/173481[30:00<20:56,55.51it/s] 60%|######    |104287/173481[30:11<20:46,55.51it/s] 65%|######5   |113287/173481[33:00<18:28,54.28it/s] 66%|######5   |113871/173481[33:11<18:18,54.28it/s] 71%|#######   |122911/173481[36:00<15:38,53.86it/s] 71%|#######1  |123498/173481[36:11<15:27,53.86it/s] 76%|#######6  |132061/173481[39:00<13:12,52.29it/s] 76%|#######6  |132666/173481[39:11<13:00,52.29it/s] 81%|########1 |141084/173481[42:00<10:32,51.19it/s] 82%|########1 |141690/173481[42:12<10:21,51.19it/s] 87%|########6 |150553/173481[45:00<07:21,51.88it/s] 87%|########7 |151260/173481[45:12<07:08,51.88it/s] 91%|#########1|158596/173481[48:00<05:10,48.01it/s] 92%|#########1|159168/173481[48:12<04:58,48.01it/s] 96%|#########6|166795/173481[51:00<02:23,46.74it/s] 96%|#########6|167392/173481[51:12<02:10,46.74it/s]100%|##########|173481/173481[53:22<00:00,54.17it/s]
[32m[0320 22:43:07 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3202.56 sec.
[32m[0320 22:43:08 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-2255253.
[32m[0320 22:43:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,187.18it/s]
12
[32m[0320 22:44:50 @monitor.py:363][0m QueueInput/queue_size: 0.70949
[32m[0320 22:44:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 66.586
[32m[0320 22:44:50 @monitor.py:363][0m activation-summaries/output-rms: 0.049945
[32m[0320 22:44:50 @monitor.py:363][0m cross_entropy_loss: 1.0006
[32m[0320 22:44:50 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58824
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.147
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2652
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.25624
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25603
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25239
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 22:44:50 @monitor.py:363][0m train-error-top1: 0.27269
[32m[0320 22:44:50 @monitor.py:363][0m val-error-top1: 0.29328
[32m[0320 22:44:50 @monitor.py:363][0m val-utt-error: 0.028743
[32m[0320 22:44:50 @monitor.py:363][0m validation_cost: 1.0578
[32m[0320 22:44:50 @monitor.py:363][0m wd_cost: 0.020708
[32m[0320 22:44:50 @group.py:42][0m Callbacks took 102.880 sec in total. InferenceRunner: 100.563sec
[32m[0320 22:44:50 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9922/173481[03:00<49:28,55.10it/s]  6%|6         |10467/173481[03:10<49:18,55.10it/s] 11%|#1        |19246/173481[06:00<48:08,53.39it/s] 11%|#1        |19806/173481[06:10<47:58,53.39it/s] 17%|#6        |28782/173481[09:00<45:20,53.18it/s] 17%|#6        |29361/173481[09:10<45:09,53.18it/s] 22%|##1       |38163/173481[12:00<42:50,52.64it/s] 22%|##2       |38716/173481[12:10<42:39,52.64it/s] 28%|##7       |47731/173481[15:00<39:37,52.90it/s] 28%|##7       |48316/173481[15:10<39:26,52.90it/s] 33%|###2      |57125/173481[18:00<36:54,52.54it/s] 33%|###3      |57690/173481[18:10<36:43,52.54it/s] 39%|###8      |66820/173481[21:00<33:25,53.19it/s] 39%|###8      |67359/173481[21:11<33:15,53.19it/s] 44%|####3     |76210/173481[24:00<30:46,52.67it/s] 44%|####4     |76761/173481[24:11<30:36,52.67it/s] 49%|####9     |85431/173481[27:00<28:15,51.94it/s] 50%|####9     |86007/173481[27:11<28:04,51.94it/s] 55%|#####4    |94792/173481[30:00<25:14,51.96it/s] 55%|#####4    |95385/173481[30:11<25:02,51.96it/s] 60%|######    |104482/173481[33:00<21:45,52.87it/s] 61%|######    |105088/173481[33:11<21:33,52.87it/s] 65%|######5   |113584/173481[36:00<19:18,51.68it/s] 66%|######5   |114181/173481[36:11<19:07,51.68it/s] 71%|#######   |123148/173481[39:00<16:00,52.39it/s] 71%|#######1  |123747/173481[39:11<15:49,52.39it/s] 77%|#######6  |132787/173481[42:00<12:48,52.97it/s] 77%|#######6  |133395/173481[42:12<12:36,52.97it/s] 82%|########2 |142312/173481[45:00<09:48,52.94it/s] 82%|########2 |142932/173481[45:12<09:37,52.94it/s] 88%|########7 |151928/173481[48:00<06:45,53.18it/s] 88%|########7 |152564/173481[48:12<06:33,53.18it/s] 93%|#########3|161608/173481[51:00<03:42,53.47it/s] 94%|#########3|162279/173481[51:12<03:29,53.47it/s] 99%|#########8|171340/173481[54:00<00:39,53.76it/s] 99%|#########9|171957/173481[54:12<00:28,53.76it/s]100%|##########|173481/173481[54:42<00:00,52.86it/s]
[32m[0320 23:39:32 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:3282.11 sec.
[32m[0320 23:39:33 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-2428734.
[32m[0320 23:39:34 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:32<00:00,204.56it/s]
13
[32m[0320 23:41:06 @monitor.py:363][0m QueueInput/queue_size: 0.69511
[32m[0320 23:41:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.847
[32m[0320 23:41:06 @monitor.py:363][0m activation-summaries/output-rms: 0.051373
[32m[0320 23:41:06 @monitor.py:363][0m cross_entropy_loss: 0.89377
[32m[0320 23:41:06 @monitor.py:363][0m lr: 3.125e-05
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61534
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.148
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27238
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2599
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25952
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.256
[32m[0320 23:41:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0320 23:41:06 @monitor.py:363][0m train-error-top1: 0.2505
[32m[0320 23:41:06 @monitor.py:363][0m val-error-top1: 0.28486
[32m[0320 23:41:06 @monitor.py:363][0m val-utt-error: 0.028584
[32m[0320 23:41:06 @monitor.py:363][0m validation_cost: 1.024
[32m[0320 23:41:06 @monitor.py:363][0m wd_cost: 0.004383
[32m[0320 23:41:06 @group.py:42][0m Callbacks took 94.231 sec in total. InferenceRunner: 92.024sec
[32m[0320 23:41:06 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10320/173481[03:00<47:25,57.33it/s]  6%|6         |10863/173481[03:10<47:16,57.33it/s] 11%|#1        |19249/173481[06:00<48:20,53.18it/s] 11%|#1        |19773/173481[06:10<48:10,53.18it/s] 16%|#6        |28297/173481[09:00<46:49,51.67it/s] 17%|#6        |28880/173481[09:10<46:38,51.67it/s] 22%|##1       |37795/173481[12:00<43:19,52.20it/s] 22%|##2       |38335/173481[12:10<43:08,52.20it/s] 27%|##7       |47149/173481[15:00<40:25,52.08it/s] 27%|##7       |47685/173481[15:10<40:15,52.08it/s] 33%|###2      |56551/173481[18:00<37:22,52.15it/s] 33%|###2      |57132/173481[18:10<37:11,52.15it/s] 38%|###8      |66325/173481[21:00<33:34,53.20it/s] 39%|###8      |66942/173481[21:11<33:22,53.20it/s] 43%|####3     |75445/173481[24:00<31:29,51.89it/s] 44%|####3     |76038/173481[24:11<31:17,51.89it/s] 49%|####9     |85188/173481[27:00<27:46,52.99it/s] 49%|####9     |85662/173481[27:11<27:37,52.99it/s] 54%|#####4    |94232/173481[30:00<25:36,51.58it/s] 55%|#####4    |94794/173481[30:11<25:25,51.58it/s] 59%|#####9    |102817/173481[33:00<23:46,49.55it/s] 60%|#####9    |103368/173481[33:11<23:34,49.55it/s] 64%|######4   |111871/173481[36:00<20:34,49.92it/s] 65%|######4   |112464/173481[36:11<20:22,49.92it/s] 70%|######9   |120883/173481[39:00<17:32,49.98it/s] 70%|######9   |121415/173481[39:11<17:21,49.98it/s] 75%|#######4  |129556/173481[42:00<14:55,49.06it/s] 75%|#######5  |130118/173481[42:12<14:43,49.06it/s] 80%|#######9  |138121/173481[45:00<12:12,48.30it/s] 80%|#######9  |138696/173481[45:12<12:00,48.30it/s] 85%|########5 |147472/173481[48:00<08:39,50.06it/s] 85%|########5 |148087/173481[48:12<08:27,50.06it/s] 91%|######### |157153/173481[51:00<05:14,51.85it/s] 91%|######### |157782/173481[51:12<05:02,51.85it/s] 96%|#########5|166526/173481[54:00<02:13,51.96it/s] 96%|#########6|167235/173481[54:12<02:00,51.96it/s]100%|##########|173481/173481[55:55<00:00,51.71it/s]
[32m[0321 00:37:02 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3355.14 sec.
[32m[0321 00:37:02 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-2602215.
[32m[0321 00:37:04 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,195.44it/s]
14
[32m[0321 00:38:40 @monitor.py:363][0m QueueInput/queue_size: 0.52689
[32m[0321 00:38:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 74.425
[32m[0321 00:38:40 @monitor.py:363][0m activation-summaries/output-rms: 0.050773
[32m[0321 00:38:40 @monitor.py:363][0m cross_entropy_loss: 0.92853
[32m[0321 00:38:40 @monitor.py:363][0m lr: 3.125e-05
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63375
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1481
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27684
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26172
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26107
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25761
[32m[0321 00:38:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 00:38:40 @monitor.py:363][0m train-error-top1: 0.26031
[32m[0321 00:38:40 @monitor.py:363][0m val-error-top1: 0.28176
[32m[0321 00:38:40 @monitor.py:363][0m val-utt-error: 0.026671
[32m[0321 00:38:40 @monitor.py:363][0m validation_cost: 1.0139
[32m[0321 00:38:40 @monitor.py:363][0m wd_cost: 0.0045381
[32m[0321 00:38:40 @group.py:42][0m Callbacks took 98.642 sec in total. InferenceRunner: 96.319sec
[32m[0321 00:38:40 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10798/173481[03:00<45:12,59.98it/s]  7%|6         |11325/173481[03:10<45:03,59.98it/s] 11%|#1        |19924/173481[06:00<46:34,54.95it/s] 12%|#1        |20471/173481[06:10<46:24,54.95it/s] 17%|#6        |29326/173481[09:00<44:52,53.55it/s] 17%|#7        |29875/173481[09:10<44:41,53.55it/s] 22%|##2       |39016/173481[12:00<41:44,53.69it/s] 23%|##2       |39598/173481[12:10<41:33,53.69it/s] 28%|##7       |48232/173481[15:00<39:49,52.41it/s] 28%|##8       |48716/173481[15:10<39:40,52.41it/s] 33%|###2      |57082/173481[18:00<38:14,50.73it/s] 33%|###3      |57661/173481[18:10<38:03,50.73it/s] 38%|###7      |65710/173481[21:00<36:26,49.29it/s] 38%|###8      |66249/173481[21:11<36:15,49.29it/s] 43%|####3     |74932/173481[24:00<32:41,50.24it/s] 44%|####3     |75488/173481[24:11<32:30,50.24it/s] 49%|####8     |84323/173481[27:00<29:01,51.19it/s] 49%|####8     |84909/173481[27:11<28:50,51.19it/s] 54%|#####4    |93737/173481[30:00<25:41,51.74it/s] 54%|#####4    |94329/173481[30:11<25:29,51.74it/s] 60%|#####9    |103360/173481[33:00<22:13,52.58it/s] 60%|#####9    |103977/173481[33:11<22:01,52.58it/s] 65%|######5   |113119/173481[36:00<18:50,53.38it/s] 66%|######5   |113825/173481[36:11<18:37,53.38it/s] 71%|#######   |122562/173481[39:00<16:02,52.92it/s] 71%|#######   |123153/173481[39:11<15:51,52.92it/s] 76%|#######6  |131866/173481[42:00<13:15,52.29it/s] 76%|#######6  |132489/173481[42:12<13:03,52.29it/s] 82%|########1 |141634/173481[45:00<09:58,53.25it/s] 82%|########2 |142299/173481[45:12<09:45,53.25it/s] 87%|########7 |151198/173481[48:00<06:58,53.19it/s] 87%|########7 |151779/173481[48:12<06:48,53.19it/s] 93%|#########2|160492/173481[51:00<04:07,52.39it/s] 93%|#########2|161146/173481[51:12<03:55,52.39it/s] 98%|#########7|169744/173481[54:00<01:12,51.88it/s] 98%|#########8|170409/173481[54:12<00:59,51.88it/s]100%|##########|173481/173481[55:08<00:00,52.43it/s]
[32m[0321 01:33:49 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:3308.80 sec.
[32m[0321 01:33:50 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-2775696.
[32m[0321 01:33:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,195.87it/s]
15
[32m[0321 01:35:27 @monitor.py:363][0m QueueInput/queue_size: 0.73279
[32m[0321 01:35:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 77.405
[32m[0321 01:35:27 @monitor.py:363][0m activation-summaries/output-rms: 0.05014
[32m[0321 01:35:27 @monitor.py:363][0m cross_entropy_loss: 0.91839
[32m[0321 01:35:27 @monitor.py:363][0m lr: 3.125e-05
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.65192
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1486
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28102
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26353
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26259
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2592
[32m[0321 01:35:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 01:35:27 @monitor.py:363][0m train-error-top1: 0.2558
[32m[0321 01:35:27 @monitor.py:363][0m val-error-top1: 0.28084
[32m[0321 01:35:27 @monitor.py:363][0m val-utt-error: 0.024918
[32m[0321 01:35:27 @monitor.py:363][0m validation_cost: 1.0122
[32m[0321 01:35:27 @monitor.py:363][0m wd_cost: 0.0046926
[32m[0321 01:35:27 @group.py:42][0m Callbacks took 98.276 sec in total. InferenceRunner: 96.105sec
[32m[0321 01:35:27 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11023/173481[03:00<44:13,61.21it/s]  7%|6         |11527/173481[03:10<44:05,61.21it/s] 12%|#1        |20419/173481[06:00<45:16,56.35it/s] 12%|#2        |20993/173481[06:10<45:06,56.35it/s] 17%|#7        |29767/173481[09:00<44:19,54.05it/s] 17%|#7        |30276/173481[09:10<44:09,54.05it/s] 23%|##2       |39331/173481[12:00<41:43,53.58it/s] 23%|##3       |39924/173481[12:10<41:32,53.58it/s] 28%|##8       |49159/173481[15:00<38:18,54.08it/s] 29%|##8       |49767/173481[15:10<38:07,54.08it/s] 34%|###3      |58735/173481[18:00<35:39,53.63it/s] 34%|###4      |59289/173481[18:10<35:29,53.63it/s] 39%|###9      |68341/173481[21:00<32:45,53.49it/s] 40%|###9      |68922/173481[21:11<32:34,53.49it/s] 45%|####4     |77797/173481[24:00<30:05,53.01it/s] 45%|####5     |78392/173481[24:11<29:53,53.01it/s] 50%|#####     |86845/173481[27:00<27:59,51.59it/s] 50%|#####     |87404/173481[27:11<27:48,51.59it/s] 55%|#####5    |96145/173481[30:00<24:58,51.62it/s] 56%|#####5    |96704/173481[30:11<24:47,51.62it/s] 61%|######    |105487/173481[33:00<21:53,51.76it/s] 61%|######1   |106062/173481[33:11<21:42,51.76it/s] 66%|######6   |115006/173481[36:00<18:37,52.31it/s] 67%|######6   |115590/173481[36:11<18:26,52.31it/s] 72%|#######1  |124363/173481[39:00<15:42,52.14it/s] 72%|#######2  |125015/173481[39:11<15:29,52.14it/s] 77%|#######7  |133621/173481[42:00<12:49,51.78it/s] 77%|#######7  |134148/173481[42:12<12:39,51.78it/s] 82%|########2 |142645/173481[45:00<10:05,50.94it/s] 83%|########2 |143310/173481[45:12<09:52,50.94it/s] 87%|########7 |151573/173481[48:00<07:15,50.25it/s] 88%|########7 |152094/173481[48:12<07:05,50.25it/s] 92%|#########2|160207/173481[51:00<04:30,49.07it/s] 93%|#########2|160860/173481[51:12<04:17,49.07it/s] 98%|#########7|169723/173481[54:00<01:13,50.90it/s] 98%|#########8|170370/173481[54:12<01:01,50.90it/s]100%|##########|173481/173481[55:10<00:00,52.41it/s]
[32m[0321 02:30:38 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:3310.28 sec.
[32m[0321 02:30:38 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-2949177.
[32m[0321 02:30:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,199.62it/s]
16
[32m[0321 02:32:14 @monitor.py:363][0m QueueInput/queue_size: 0.58708
[32m[0321 02:32:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 80.176
[32m[0321 02:32:14 @monitor.py:363][0m activation-summaries/output-rms: 0.050863
[32m[0321 02:32:14 @monitor.py:363][0m cross_entropy_loss: 0.90272
[32m[0321 02:32:14 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.66419
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1487
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28349
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26447
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26336
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26002
[32m[0321 02:32:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 02:32:14 @monitor.py:363][0m train-error-top1: 0.25548
[32m[0321 02:32:14 @monitor.py:363][0m val-error-top1: 0.27607
[32m[0321 02:32:14 @monitor.py:363][0m val-utt-error: 0.023536
[32m[0321 02:32:14 @monitor.py:363][0m validation_cost: 0.99014
[32m[0321 02:32:14 @monitor.py:363][0m wd_cost: 0.00095846
[32m[0321 02:32:14 @group.py:42][0m Callbacks took 96.667 sec in total. InferenceRunner: 94.299sec
[32m[0321 02:32:14 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11176/173481[03:00<43:34,62.08it/s]  7%|6         |11739/173481[03:10<43:25,62.08it/s] 12%|#2        |21058/173481[06:00<43:35,58.27it/s] 12%|#2        |21599/173481[06:10<43:26,58.27it/s] 18%|#7        |30700/173481[09:00<42:38,55.82it/s] 18%|#8        |31282/173481[09:10<42:27,55.82it/s] 23%|##3       |40547/173481[12:00<40:05,55.25it/s] 24%|##3       |41121/173481[12:10<39:55,55.25it/s] 29%|##9       |50327/173481[15:00<37:27,54.79it/s] 29%|##9       |50907/173481[15:10<37:17,54.79it/s] 35%|###4      |59962/173481[18:00<34:56,54.14it/s] 35%|###4      |60570/173481[18:10<34:45,54.14it/s] 40%|####      |69730/173481[21:00<31:54,54.20it/s] 41%|####      |70281/173481[21:11<31:44,54.20it/s] 46%|####5     |79540/173481[24:00<28:48,54.35it/s] 46%|####6     |80133/173481[24:11<28:37,54.35it/s] 51%|#####1    |89266/173481[27:00<25:54,54.18it/s] 52%|#####1    |89825/173481[27:11<25:44,54.18it/s] 57%|#####6    |98827/173481[30:00<23:11,53.64it/s] 57%|#####7    |99429/173481[30:11<23:00,53.64it/s] 62%|######2   |108142/173481[33:00<20:40,52.68it/s] 63%|######2   |108747/173481[33:11<20:28,52.68it/s] 68%|######7   |117676/173481[36:00<17:36,52.81it/s] 68%|######8   |118296/173481[36:11<17:24,52.81it/s] 73%|#######3  |127258/173481[39:00<14:31,53.02it/s] 74%|#######3  |127843/173481[39:11<14:20,53.02it/s] 79%|#######8  |136841/173481[42:00<11:29,53.13it/s] 79%|#######9  |137493/173481[42:12<11:17,53.13it/s] 84%|########4 |146524/173481[45:00<08:24,53.46it/s] 85%|########4 |147141/173481[45:12<08:12,53.46it/s] 90%|######### |156238/173481[48:00<05:21,53.71it/s] 90%|######### |156915/173481[48:12<05:08,53.71it/s] 96%|#########5|165844/173481[51:00<02:22,53.53it/s] 96%|#########5|166497/173481[51:12<02:10,53.53it/s][32m[0321 03:25:36 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:3201.96 sec.
100%|##########|173481/173481[53:21<00:00,54.18it/s]
[32m[0321 03:25:37 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-3122658.
[32m[0321 03:25:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:32<00:00,202.77it/s]
17
[32m[0321 03:27:11 @monitor.py:363][0m QueueInput/queue_size: 0.72128
[32m[0321 03:27:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 82.143
[32m[0321 03:27:11 @monitor.py:363][0m activation-summaries/output-rms: 0.051747
[32m[0321 03:27:11 @monitor.py:363][0m cross_entropy_loss: 0.86004
[32m[0321 03:27:11 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6737
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1489
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28524
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26505
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26377
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26049
[32m[0321 03:27:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 03:27:11 @monitor.py:363][0m train-error-top1: 0.24215
[32m[0321 03:27:11 @monitor.py:363][0m val-error-top1: 0.27558
[32m[0321 03:27:11 @monitor.py:363][0m val-utt-error: 0.024865
[32m[0321 03:27:11 @monitor.py:363][0m validation_cost: 0.98796
[32m[0321 03:27:11 @monitor.py:363][0m wd_cost: 0.00097339
[32m[0321 03:27:11 @group.py:42][0m Callbacks took 95.047 sec in total. InferenceRunner: 92.836sec
[32m[0321 03:27:11 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10597/173481[03:00<46:07,58.85it/s]  6%|6         |11063/173481[03:10<46:00,58.85it/s] 11%|#1        |19615/173481[06:00<47:23,54.11it/s] 12%|#1        |20124/173481[06:10<47:13,54.11it/s] 17%|#6        |29090/173481[09:00<45:05,53.36it/s] 17%|#7        |29667/173481[09:10<44:54,53.36it/s] 23%|##2       |39253/173481[12:00<40:46,54.86it/s] 23%|##3       |39930/173481[12:10<40:34,54.86it/s] 29%|##9       |51117/173481[15:00<34:03,59.88it/s] 30%|##9       |51804/173481[15:10<33:52,59.88it/s] 35%|###5      |61081/173481[18:00<32:33,57.52it/s] 35%|###5      |61574/173481[18:10<32:25,57.52it/s] 40%|###9      |68809/173481[21:00<35:28,49.17it/s] 40%|###9      |69377/173481[21:11<35:17,49.17it/s] 45%|####5     |78524/173481[24:00<30:45,51.46it/s] 46%|####5     |79062/173481[24:11<30:34,51.46it/s] 50%|#####     |87487/173481[27:00<28:19,50.61it/s] 51%|#####     |88027/173481[27:11<28:08,50.61it/s] 56%|#####5    |96493/173481[30:00<25:30,50.32it/s] 56%|#####5    |97080/173481[30:11<25:18,50.32it/s] 61%|######    |105283/173481[33:00<22:56,49.56it/s] 61%|######1   |105828/173481[33:11<22:45,49.56it/s] 66%|######5   |113930/173481[36:00<20:20,48.79it/s] 66%|######5   |114474/173481[36:11<20:09,48.79it/s] 71%|#######   |122623/173481[39:00<17:27,48.53it/s] 71%|#######1  |123180/173481[39:11<17:16,48.53it/s] 76%|#######5  |131281/173481[42:00<14:33,48.31it/s] 76%|#######5  |131820/173481[42:12<14:22,48.31it/s] 81%|########  |140385/173481[45:00<11:09,49.42it/s] 81%|########1 |141018/173481[45:12<10:56,49.42it/s] 86%|########6 |149959/173481[48:00<07:39,51.23it/s] 87%|########6 |150552/173481[48:12<07:27,51.23it/s] 91%|#########1|158635/173481[51:00<04:58,49.66it/s] 92%|#########1|159209/173481[51:12<04:47,49.66it/s] 97%|#########6|167701/173481[54:00<01:55,50.00it/s] 97%|#########7|168294/173481[54:12<01:43,50.00it/s]100%|##########|173481/173481[55:50<00:00,51.78it/s]
[32m[0321 04:23:02 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:3350.30 sec.
[32m[0321 04:23:03 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-3296139.
[32m[0321 04:23:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.48it/s]
18
[32m[0321 04:24:44 @monitor.py:363][0m QueueInput/queue_size: 0.6414
[32m[0321 04:24:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 83.601
[32m[0321 04:24:44 @monitor.py:363][0m activation-summaries/output-rms: 0.050928
[32m[0321 04:24:44 @monitor.py:363][0m cross_entropy_loss: 0.92969
[32m[0321 04:24:44 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68323
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.149
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2869
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26564
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26421
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26095
[32m[0321 04:24:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 04:24:44 @monitor.py:363][0m train-error-top1: 0.25235
[32m[0321 04:24:44 @monitor.py:363][0m val-error-top1: 0.27347
[32m[0321 04:24:44 @monitor.py:363][0m val-utt-error: 0.022633
[32m[0321 04:24:44 @monitor.py:363][0m validation_cost: 0.97973
[32m[0321 04:24:44 @monitor.py:363][0m wd_cost: 0.00098836
[32m[0321 04:24:44 @group.py:42][0m Callbacks took 102.045 sec in total. InferenceRunner: 98.827sec
[32m[0321 04:24:44 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9556/173481[03:00<51:29,53.06it/s]  6%|5         |10011/173481[03:10<51:20,53.06it/s] 10%|#         |17740/173481[06:00<53:00,48.96it/s] 11%|#         |18218/173481[06:10<52:50,48.96it/s] 15%|#5        |26086/173481[09:00<51:35,47.62it/s] 15%|#5        |26571/173481[09:10<51:25,47.62it/s] 20%|#9        |34540/173481[12:00<48:58,47.29it/s] 20%|##        |35008/173481[12:10<48:48,47.29it/s] 25%|##4       |43048/173481[15:00<45:58,47.28it/s] 25%|##5       |43545/173481[15:10<45:48,47.28it/s] 30%|##9       |51808/173481[18:00<42:17,47.96it/s] 30%|###       |52317/173481[18:10<42:06,47.96it/s] 35%|###4      |60598/173481[21:00<38:53,48.38it/s] 35%|###5      |61143/173481[21:11<38:41,48.38it/s] 40%|###9      |69323/173481[24:00<35:50,48.43it/s] 40%|####      |69885/173481[24:11<35:39,48.43it/s] 45%|####5     |78327/173481[27:00<32:13,49.21it/s] 46%|####5     |79017/173481[27:11<31:59,49.21it/s] 51%|#####     |88120/173481[30:00<27:32,51.67it/s] 51%|#####1    |88701/173481[30:11<27:20,51.67it/s] 56%|#####6    |97156/173481[33:00<24:59,50.91it/s] 56%|#####6    |97683/173481[33:11<24:48,50.91it/s] 61%|######1   |106193/173481[36:00<22:10,50.56it/s] 62%|######1   |106743/173481[36:11<22:00,50.56it/s] 66%|######6   |114826/173481[39:00<19:51,49.21it/s] 67%|######6   |115395/173481[39:11<19:40,49.21it/s] 72%|#######1  |124138/173481[42:00<16:18,50.43it/s] 72%|#######1  |124785/173481[42:12<16:05,50.43it/s] 77%|#######7  |133810/173481[45:00<12:42,52.02it/s] 77%|#######7  |134421/173481[45:12<12:30,52.02it/s] 83%|########2 |143764/173481[48:00<09:14,53.60it/s] 83%|########3 |144459/173481[48:12<09:01,53.60it/s] 89%|########9 |154504/173481[51:00<05:36,56.47it/s] 89%|########9 |155193/173481[51:12<05:23,56.47it/s] 95%|#########4|164422/173481[54:00<02:42,55.77it/s] 95%|#########5|165069/173481[54:12<02:30,55.77it/s]100%|##########|173481/173481[56:50<00:00,50.87it/s]
[32m[0321 05:21:34 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:3410.48 sec.
[32m[0321 05:21:35 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-3469620.
[32m[0321 05:21:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.29it/s]
19
[32m[0321 05:23:14 @monitor.py:363][0m QueueInput/queue_size: 0.42024
[32m[0321 05:23:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 85.706
[32m[0321 05:23:14 @monitor.py:363][0m activation-summaries/output-rms: 0.052192
[32m[0321 05:23:14 @monitor.py:363][0m cross_entropy_loss: 0.85705
[32m[0321 05:23:14 @monitor.py:363][0m lr: 7.8125e-06
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68838
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1493
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28769
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26584
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26433
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26111
[32m[0321 05:23:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 05:23:14 @monitor.py:363][0m train-error-top1: 0.2383
[32m[0321 05:23:14 @monitor.py:363][0m val-error-top1: 0.27316
[32m[0321 05:23:14 @monitor.py:363][0m val-utt-error: 0.024227
[32m[0321 05:23:14 @monitor.py:363][0m validation_cost: 0.97953
[32m[0321 05:23:14 @monitor.py:363][0m wd_cost: 0.00019921
[32m[0321 05:23:14 @group.py:42][0m Callbacks took 99.470 sec in total. InferenceRunner: 97.387sec
[32m[0321 05:23:14 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11464/173481[03:00<42:24,63.69it/s]  7%|7         |12294/173481[03:10<42:10,63.69it/s] 13%|#3        |23101/173481[06:00<39:03,64.16it/s] 14%|#3        |23670/173481[06:10<38:54,64.16it/s] 19%|#8        |32917/173481[09:00<39:44,58.95it/s] 19%|#9        |33451/173481[09:10<39:35,58.95it/s] 24%|##4       |42440/173481[12:00<39:09,55.76it/s] 25%|##4       |43020/173481[12:10<38:59,55.76it/s] 30%|###       |52159/173481[15:00<36:51,54.85it/s] 30%|###       |52746/173481[15:10<36:41,54.85it/s] 36%|###5      |61975/173481[18:00<33:58,54.69it/s] 36%|###6      |62574/173481[18:10<33:47,54.69it/s] 41%|####1     |71930/173481[21:00<30:46,55.00it/s] 42%|####1     |72534/173481[21:11<30:35,55.00it/s] 47%|####7     |82183/173481[24:00<27:11,55.95it/s] 48%|####7     |82783/173481[24:11<27:00,55.95it/s] 53%|#####3    |92247/173481[27:00<24:12,55.93it/s] 54%|#####3    |92909/173481[27:11<24:00,55.93it/s] 59%|#####8    |101857/173481[30:00<21:51,54.63it/s] 59%|#####9    |102438/173481[30:11<21:40,54.63it/s] 64%|######4   |111277/173481[33:00<19:23,53.45it/s] 65%|######4   |111945/173481[33:11<19:11,53.45it/s] 70%|######9   |120775/173481[36:00<16:32,53.10it/s] 70%|######9   |121380/173481[36:11<16:21,53.10it/s] 75%|#######5  |130185/173481[39:00<13:41,52.69it/s] 75%|#######5  |130794/173481[39:11<13:30,52.69it/s] 81%|########  |139717/173481[42:00<10:39,52.81it/s] 81%|########  |140334/173481[42:12<10:27,52.81it/s] 86%|########6 |149363/173481[45:00<07:33,53.19it/s] 86%|########6 |150024/173481[45:12<07:20,53.19it/s] 92%|#########1|159073/173481[48:00<04:28,53.57it/s] 92%|#########2|159618/173481[48:12<04:18,53.57it/s] 97%|#########7|168871/173481[51:00<01:25,53.99it/s] 98%|#########7|169538/173481[51:12<01:13,53.99it/s]100%|##########|173481/173481[52:24<00:00,55.17it/s]
[32m[0321 06:15:38 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:3144.64 sec.
[32m[0321 06:15:39 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-3643101.
[32m[0321 06:15:41 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,197.51it/s]
20
[32m[0321 06:17:16 @monitor.py:363][0m QueueInput/queue_size: 0.55985
[32m[0321 06:17:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 85.554
[32m[0321 06:17:16 @monitor.py:363][0m activation-summaries/output-rms: 0.051005
[32m[0321 06:17:16 @monitor.py:363][0m cross_entropy_loss: 0.87724
[32m[0321 06:17:16 @monitor.py:363][0m lr: 7.8125e-06
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.69325
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1493
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28843
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26602
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26445
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26124
[32m[0321 06:17:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 06:17:16 @monitor.py:363][0m train-error-top1: 0.24622
[32m[0321 06:17:16 @monitor.py:363][0m val-error-top1: 0.2714
[32m[0321 06:17:16 @monitor.py:363][0m val-utt-error: 0.022899
[32m[0321 06:17:16 @monitor.py:363][0m validation_cost: 0.97368
[32m[0321 06:17:16 @monitor.py:363][0m wd_cost: 0.00020067
[32m[0321 06:17:16 @group.py:42][0m Callbacks took 97.724 sec in total. InferenceRunner: 95.308sec
[32m[0321 06:17:16 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10900/173481[03:00<44:45,60.53it/s]  7%|6         |11361/173481[03:10<44:38,60.53it/s] 11%|#1        |19864/173481[06:00<46:51,54.64it/s] 12%|#1        |20445/173481[06:10<46:40,54.64it/s] 17%|#7        |29848/173481[09:00<43:29,55.05it/s] 18%|#7        |30429/173481[09:10<43:18,55.05it/s] 23%|##3       |40072/173481[12:00<39:46,55.90it/s] 23%|##3       |40623/173481[12:10<39:36,55.90it/s] 29%|##8       |49870/173481[15:00<37:21,55.15it/s] 29%|##9       |50423/173481[15:10<37:11,55.15it/s] 35%|###4      |59986/173481[18:00<33:58,55.67it/s] 35%|###4      |60585/173481[18:10<33:48,55.67it/s] 40%|####      |70051/173481[21:00<30:53,55.79it/s] 41%|####      |70629/173481[21:11<30:43,55.79it/s] 46%|####6     |80065/173481[24:00<27:56,55.71it/s] 47%|####6     |80715/173481[24:11<27:45,55.71it/s] 52%|#####2    |90283/173481[27:00<24:39,56.23it/s] 52%|#####2    |90879/173481[27:11<24:28,56.23it/s] 58%|#####7    |100618/173481[30:00<21:22,56.81it/s] 58%|#####8    |101207/173481[30:11<21:12,56.81it/s] 64%|######3   |110789/173481[33:00<18:26,56.66it/s] 64%|######4   |111454/173481[33:11<18:14,56.66it/s] 70%|######9   |120862/173481[36:00<15:34,56.30it/s] 70%|#######   |121515/173481[36:11<15:22,56.30it/s] 75%|#######5  |130598/173481[39:00<12:57,55.17it/s] 76%|#######5  |131247/173481[39:12<12:45,55.17it/s] 81%|########  |140144/173481[42:00<10:16,54.08it/s] 81%|########1 |140792/173481[42:12<10:04,54.08it/s] 87%|########6 |150321/173481[45:00<06:58,55.28it/s] 87%|########7 |150987/173481[45:12<06:46,55.28it/s] 93%|#########2|160612/173481[48:00<03:48,56.21it/s] 93%|#########2|161317/173481[48:12<03:36,56.21it/s] 98%|#########8|170698/173481[51:00<00:49,56.11it/s] 99%|#########8|171360/173481[51:12<00:37,56.11it/s]100%|##########|173481/173481[51:50<00:00,55.77it/s]
[32m[0321 07:09:06 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:3110.49 sec.
[32m[0321 07:09:07 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-3816582.
[32m[0321 07:09:08 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,196.25it/s]
21
[32m[0321 07:10:44 @monitor.py:363][0m QueueInput/queue_size: 0.57817
[32m[0321 07:10:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 86.431
[32m[0321 07:10:44 @monitor.py:363][0m activation-summaries/output-rms: 0.050457
[32m[0321 07:10:44 @monitor.py:363][0m cross_entropy_loss: 0.87681
[32m[0321 07:10:44 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.69764
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1494
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28906
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2662
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26455
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26136
[32m[0321 07:10:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 07:10:44 @monitor.py:363][0m train-error-top1: 0.24467
[32m[0321 07:10:44 @monitor.py:363][0m val-error-top1: 0.27087
[32m[0321 07:10:44 @monitor.py:363][0m val-utt-error: 0.021996
[32m[0321 07:10:44 @monitor.py:363][0m validation_cost: 0.97152
[32m[0321 07:10:44 @monitor.py:363][0m wd_cost: 0.00020197
[32m[0321 07:10:44 @group.py:42][0m Callbacks took 97.866 sec in total. InferenceRunner: 95.920sec
[32m[0321 07:10:44 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11821/173481[03:00<41:02,65.64it/s]  7%|7         |12414/173481[03:10<40:53,65.64it/s] 13%|#2        |22100/173481[06:00<41:18,61.08it/s] 13%|#3        |22728/173481[06:10<41:08,61.08it/s] 19%|#8        |32335/173481[09:00<39:56,58.89it/s] 19%|#8        |32898/173481[09:10<39:47,58.89it/s] 25%|##4       |42595/173481[12:00<37:39,57.92it/s] 25%|##4       |43194/173481[12:10<37:29,57.92it/s] 30%|###       |52907/173481[15:00<34:53,57.60it/s] 31%|###       |53508/173481[15:10<34:42,57.60it/s] 36%|###6      |63247/173481[18:00<31:56,57.52it/s] 37%|###6      |63804/173481[18:10<31:46,57.52it/s] 42%|####2     |73321/173481[21:00<29:25,56.73it/s] 43%|####2     |73922/173481[21:11<29:15,56.73it/s] 48%|####8     |83467/173481[24:00<26:32,56.54it/s] 48%|####8     |84096/173481[24:11<26:20,56.54it/s] 54%|#####4    |93751/173481[27:00<23:22,56.83it/s] 54%|#####4    |94344/173481[27:11<23:12,56.83it/s] 60%|#####9    |103933/173481[30:00<20:26,56.70it/s] 60%|######    |104598/173481[30:11<20:14,56.70it/s] 66%|######5   |114193/173481[33:00<17:22,56.85it/s] 66%|######6   |114834/173481[33:11<17:11,56.85it/s] 72%|#######1  |124476/173481[36:00<14:19,56.99it/s] 72%|#######2  |125130/173481[36:11<14:08,56.99it/s] 77%|#######7  |134401/173481[39:00<11:37,56.04it/s] 78%|#######7  |135036/173481[39:12<11:25,56.04it/s] 83%|########3 |144157/173481[42:00<08:52,55.10it/s] 83%|########3 |144809/173481[42:12<08:40,55.10it/s] 89%|########8 |153847/173481[45:00<06:00,54.45it/s] 89%|########9 |154524/173481[45:12<05:48,54.45it/s] 95%|#########4|163951/173481[48:00<02:52,55.28it/s] 95%|#########4|164605/173481[48:12<02:40,55.28it/s]100%|##########|173481/173481[50:54<00:00,56.79it/s]
[32m[0321 08:01:39 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:3054.65 sec.
[32m[0321 08:01:39 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-3990063.
[32m[0321 08:01:41 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,196.45it/s]
22
[32m[0321 08:03:16 @monitor.py:363][0m QueueInput/queue_size: 0.99111
[32m[0321 08:03:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 87.496
[32m[0321 08:03:16 @monitor.py:363][0m activation-summaries/output-rms: 0.051093
[32m[0321 08:03:16 @monitor.py:363][0m cross_entropy_loss: 0.88176
[32m[0321 08:03:16 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.70012
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1495
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28938
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26627
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26459
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2614
[32m[0321 08:03:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 08:03:16 @monitor.py:363][0m train-error-top1: 0.24802
[32m[0321 08:03:16 @monitor.py:363][0m val-error-top1: 0.27113
[32m[0321 08:03:16 @monitor.py:363][0m val-utt-error: 0.02258
[32m[0321 08:03:16 @monitor.py:363][0m validation_cost: 0.97123
[32m[0321 08:03:16 @monitor.py:363][0m wd_cost: 4.0539e-05
[32m[0321 08:03:16 @group.py:42][0m Callbacks took 97.530 sec in total. InferenceRunner: 95.821sec
[32m[0321 08:03:16 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11876/173481[03:00<40:49,65.98it/s]  7%|7         |12464/173481[03:10<40:40,65.98it/s] 13%|#2        |22540/173481[06:00<40:18,62.42it/s] 13%|#3        |23119/173481[06:10<40:08,62.42it/s] 19%|#8        |32951/173481[09:00<39:00,60.04it/s] 19%|#9        |33585/173481[09:10<38:50,60.04it/s] 25%|##4       |43169/173481[12:00<37:12,58.36it/s] 25%|##5       |43773/173481[12:10<37:02,58.36it/s] 31%|###       |53308/173481[15:00<34:56,57.32it/s] 31%|###1      |53878/173481[15:10<34:46,57.32it/s] 37%|###6      |63406/173481[18:00<32:21,56.70it/s] 37%|###6      |64008/173481[18:10<32:10,56.70it/s] 42%|####2     |73487/173481[21:00<29:34,56.35it/s] 43%|####2     |74097/173481[21:11<29:23,56.35it/s] 48%|####8     |83506/173481[24:00<26:47,55.98it/s] 48%|####8     |83858/173481[24:11<26:40,55.98it/s] 53%|#####2    |91192/173481[27:00<28:18,48.44it/s] 53%|#####2    |91828/173481[27:11<28:05,48.44it/s] 59%|#####8    |101506/173481[30:00<22:51,52.50it/s] 59%|#####8    |102146/173481[30:11<22:38,52.50it/s] 64%|######4   |111634/173481[33:00<18:58,54.31it/s] 65%|######4   |112278/173481[33:11<18:46,54.31it/s] 70%|#######   |121701/173481[36:00<15:39,55.11it/s] 71%|#######   |122355/173481[36:11<15:27,55.11it/s] 76%|#######6  |131927/173481[39:00<12:22,55.95it/s] 76%|#######6  |132567/173481[39:11<12:11,55.95it/s] 82%|########2 |142264/173481[42:00<09:10,56.67it/s] 82%|########2 |142940/173481[42:12<08:58,56.67it/s] 88%|########7 |152603/173481[45:00<06:05,57.05it/s] 88%|########8 |153281/173481[45:12<05:54,57.05it/s] 94%|#########3|162809/173481[48:00<03:07,56.87it/s] 94%|#########4|163473/173481[48:12<02:55,56.87it/s]100%|#########9|172952/173481[51:00<00:09,56.61it/s]100%|##########|173481/173481[51:09<00:00,56.52it/s]
[32m[0321 08:54:26 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:3069.57 sec.
[32m[0321 08:54:27 @saver.py:84][0m Model saved to train_log/fcn2_w_8_a_32_quant_ends_False/model-4163544.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,168.43it/s]
23
[32m[0321 08:56:19 @monitor.py:363][0m QueueInput/queue_size: 0.52611
[32m[0321 08:56:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 88.091
[32m[0321 08:56:19 @monitor.py:363][0m activation-summaries/output-rms: 0.052063
[32m[0321 08:56:19 @monitor.py:363][0m cross_entropy_loss: 0.83612
[32m[0321 08:56:19 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.70262
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1496
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28972
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.064528
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26635
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.061402
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26462
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.061825
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26145
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.062156
[32m[0321 08:56:19 @monitor.py:363][0m train-error-top1: 0.23759
[32m[0321 08:56:19 @monitor.py:363][0m val-error-top1: 0.27093
[32m[0321 08:56:19 @monitor.py:363][0m val-utt-error: 0.022633
[32m[0321 08:56:19 @monitor.py:363][0m validation_cost: 0.96992
[32m[0321 08:56:19 @monitor.py:363][0m wd_cost: 4.0684e-05
[32m[0321 08:56:19 @group.py:42][0m Callbacks took 113.304 sec in total. InferenceRunner: 111.762sec
[32m[0321 08:56:19 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11245/173481[03:00<43:17,62.47it/s]  7%|6         |11850/173481[03:10<43:07,62.47it/s] 12%|#2        |21541/173481[06:00<42:24,59.72it/s] 13%|#2        |22128/173481[06:10<42:14,59.72it/s] 18%|#8        |32079/173481[09:00<39:51,59.12it/s] 19%|#8        |32718/173481[09:10<39:40,59.12it/s] 24%|##4       |42439/173481[12:00<37:26,58.33it/s] 25%|##4       |43050/173481[12:10<37:16,58.33it/s] 31%|###       |53169/173481[15:00<34:00,58.96it/s] 31%|###1      |53847/173481[15:10<33:49,58.96it/s] 38%|###7      |65509/173481[18:00<28:23,63.40it/s] 38%|###8      |66162/173481[18:10<28:12,63.40it/s] 45%|####4     |77671/173481[21:00<24:24,65.41it/s] 45%|####5     |78426/173481[21:11<24:13,65.41it/s] 52%|#####1    |89911/173481[24:00<20:53,66.68it/s] 52%|#####2    |90656/173481[24:11<20:42,66.68it/s] 59%|#####9    |102595/173481[27:00<17:14,68.52it/s] 60%|#####9    |103339/173481[27:11<17:03,68.52it/s] 66%|######6   |115309/173481[30:00<13:56,69.56it/s] 67%|######6   |116191/173481[30:11<13:43,69.56it/s]slurmstepd: *** JOB 70363 ON sls-sm-11 CANCELLED AT 2018-03-21T09:28:48 ***
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 70363.0 ON sls-sm-11 CANCELLED AT 2018-03-21T09:28:48 ***
