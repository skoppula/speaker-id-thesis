sls-titanx-1 1
SLURM_JOBID=82368
SLURM_TASKID=1
[32m[0322 11:10:00 @logger.py:74][0m Argv: drf_run.py --model_name=fcn2 --bitw=4 --bita=4 --quant_ends=True --load_ckpt=train_log/fcn2_w_4_a_32_quant_ends_True/checkpoint
[32m[0322 11:11:56 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0322 11:11:56 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0322 11:11:57 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0322 11:11:57 @drf_run.py:166][0m Using host: sls-titanx-1
[32m[0322 11:11:57 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0322 11:11:57 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0322 11:11:57 @drf_run.py:188][0m Using GPU: 1
[32m[0322 11:11:57 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0322 11:11:57 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0322 11:11:57 @training.py:108][0m Building graph for training tower 0 ...
[32m[0322 11:11:57 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear0 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear1 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear1 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear2 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear2 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear3 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear3 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m last_linear input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 11:11:57 @registry.py:130][0m last_linear output: [None, 255]
[32m[0322 11:11:57 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:11:57 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0322 11:11:57 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0322 11:11:57 @drf_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0322 11:11:58 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=1400871, size=5.34MB[0m
[32m[0322 11:11:58 @base.py:196][0m Setup callbacks graph ...
[32m[0322 11:11:59 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0322 11:11:59 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 11:11:59 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:11:59 @drf_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0322 11:11:59 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0322 11:11:59 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0322 11:12:00 @base.py:212][0m Creating the session ...
2018-03-22 11:12:00.557554: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-22 11:12:07.596142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:05:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-22 11:12:07.596206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:05:00.0, compute capability: 6.1)
[32m[0322 11:12:08 @base.py:220][0m Initializing the session ...
[32m[0322 11:12:08 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn2_w_4_a_32_quant_ends_True/model-3296139 ...
[32m[0322 11:12:09 @base.py:227][0m Graph Finalized.
[32m[0322 11:12:09 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0322 11:12:09 @steps.py:127][0m Start training with global_step=3296139
[32m[0322 11:12:12 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20354/173481[03:00<22:34,113.08it/s] 12%|#2        |21490/173481[03:10<22:24,113.08it/s] 23%|##3       |40355/173481[06:00<19:47,112.09it/s] 24%|##3       |41502/173481[06:10<19:37,112.09it/s] 35%|###4      |60224/173481[09:00<16:58,111.23it/s] 35%|###5      |61319/173481[09:10<16:48,111.23it/s] 46%|####6     |79828/173481[12:00<14:10,110.05it/s] 47%|####6     |80924/173481[12:10<14:01,110.05it/s] 53%|#####2    |91263/173481[15:00<17:00,80.56it/s]  53%|#####2    |91800/173481[15:10<16:53,80.56it/s] 58%|#####7    |99904/173481[18:00<20:23,60.16it/s] 58%|#####7    |100415/173481[18:10<20:14,60.16it/s] 63%|######2   |108771/173481[21:00<19:54,54.16it/s] 63%|######3   |109365/173481[21:11<19:43,54.16it/s] 68%|######8   |118026/173481[24:00<17:31,52.74it/s] 68%|######8   |118649/173481[24:11<17:19,52.74it/s] 74%|#######3  |127601/173481[27:00<14:26,52.96it/s] 74%|#######3  |128191/173481[27:11<14:15,52.96it/s] 79%|#######8  |136996/173481[30:00<11:34,52.57it/s] 79%|#######9  |137575/173481[30:11<11:23,52.57it/s] 84%|########4 |146160/173481[33:00<08:48,51.73it/s] 85%|########4 |146715/173481[33:11<08:37,51.73it/s] 89%|########9 |154581/173481[36:00<06:24,49.13it/s] 89%|########9 |155078/173481[36:11<06:14,49.13it/s] 94%|#########3|162656/173481[39:00<03:50,46.89it/s] 94%|#########4|163234/173481[39:12<03:38,46.89it/s] 99%|#########8|171116/173481[42:00<00:50,46.94it/s] 99%|#########8|171695/173481[42:12<00:38,46.94it/s]100%|##########|173481/173481[42:47<00:00,67.56it/s]
[32m[0322 11:54:59 @base.py:257][0m Epoch 1 (global_step 3469620) finished, time:2567.83 sec.
[32m[0322 11:55:00 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-3469620.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14808/18822[03:00<00:48,82.27it/s] 83%|########2 |15543/18822[03:10<00:39,82.27it/s]100%|##########|18822/18822[03:54<00:00,80.25it/s]
0
[32m[0322 11:58:55 @monitor.py:363][0m QueueInput/queue_size: 1.8299
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.518
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/output-rms: 0.013448
[32m[0322 11:58:55 @monitor.py:363][0m cross_entropy_loss: 4.0087
[32m[0322 11:58:55 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.69325
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0891
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32323
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30946
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29454
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2906
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 11:58:55 @monitor.py:363][0m train-error-top1: 0.87805
[32m[0322 11:58:55 @monitor.py:363][0m val-error-top1: 0.88274
[32m[0322 11:58:55 @monitor.py:363][0m val-utt-error: 0.56344
[32m[0322 11:58:55 @monitor.py:363][0m validation_cost: 4.0233
[32m[0322 11:58:55 @monitor.py:363][0m wd_cost: 0.00023326
[32m[0322 11:58:55 @group.py:42][0m Callbacks took 235.168 sec in total. InferenceRunner: 234.547sec
[32m[0322 11:58:55 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8900/173481[03:00<55:28,49.44it/s]  5%|5         |9399/173481[03:10<55:18,49.44it/s] 10%|#         |18125/173481[06:00<51:26,50.33it/s] 11%|#         |18659/173481[06:10<51:16,50.33it/s] 16%|#5        |27456/173481[09:00<47:39,51.07it/s] 16%|#6        |28003/173481[09:10<47:28,51.07it/s] 21%|##        |36305/173481[12:00<45:38,50.09it/s] 21%|##1       |36813/173481[12:10<45:28,50.09it/s] 26%|##5       |44645/173481[15:00<44:36,48.14it/s] 26%|##6       |45149/173481[15:10<44:25,48.14it/s] 31%|###       |53195/173481[18:00<41:55,47.82it/s] 31%|###       |53714/173481[18:10<41:44,47.82it/s] 36%|###5      |62205/173481[21:00<37:55,48.91it/s] 36%|###6      |62789/173481[21:11<37:43,48.91it/s] 41%|####      |70506/173481[24:00<36:09,47.47it/s] 41%|####      |71054/173481[24:11<35:57,47.47it/s] 46%|####6     |79975/173481[27:00<31:13,49.90it/s] 46%|####6     |80584/173481[27:11<31:01,49.90it/s] 51%|#####1    |89315/173481[30:00<27:34,50.87it/s] 52%|#####1    |89895/173481[30:11<27:23,50.87it/s] 57%|#####7    |99125/173481[33:00<23:33,52.62it/s] 57%|#####7    |99696/173481[33:11<23:22,52.62it/s] 63%|######2   |108575/173481[36:00<20:35,52.55it/s] 63%|######2   |109154/173481[36:11<20:24,52.55it/s] 68%|######7   |117190/173481[39:00<18:43,50.09it/s] 68%|######7   |117739/173481[39:11<18:32,50.09it/s] 73%|#######2  |126311/173481[42:00<15:36,50.38it/s] 73%|#######3  |126899/173481[42:12<15:24,50.38it/s] 78%|#######8  |135394/173481[45:00<12:35,50.42it/s] 78%|#######8  |136074/173481[45:12<12:21,50.42it/s] 84%|########3 |144929/173481[48:00<09:12,51.66it/s] 84%|########3 |145509/173481[48:12<09:01,51.66it/s] 89%|########8 |153685/173481[51:00<06:35,50.11it/s] 89%|########8 |154244/173481[51:12<06:23,50.11it/s] 94%|#########3|162855/173481[54:00<03:30,50.52it/s] 94%|#########4|163479/173481[54:12<03:17,50.52it/s]100%|#########9|172640/173481[57:00<00:16,52.36it/s]100%|#########9|173419/173481[57:12<00:01,52.36it/s]100%|##########|173481/173481[57:13<00:00,50.52it/s]
[32m[0322 12:56:09 @base.py:257][0m Epoch 2 (global_step 3643101) finished, time:3433.98 sec.
[32m[0322 12:56:09 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-3643101.
[32m[0322 12:56:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.20it/s]
1
[32m[0322 12:58:06 @monitor.py:363][0m QueueInput/queue_size: 0.24819
[32m[0322 12:58:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.542
[32m[0322 12:58:06 @monitor.py:363][0m activation-summaries/output-rms: 0.017033
[32m[0322 12:58:06 @monitor.py:363][0m cross_entropy_loss: 3.5342
[32m[0322 12:58:06 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.7005
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0866
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32458
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30994
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29491
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29217
[32m[0322 12:58:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 12:58:06 @monitor.py:363][0m train-error-top1: 0.81551
[32m[0322 12:58:06 @monitor.py:363][0m val-error-top1: 0.81765
[32m[0322 12:58:06 @monitor.py:363][0m val-utt-error: 0.41669
[32m[0322 12:58:06 @monitor.py:363][0m validation_cost: 3.5593
[32m[0322 12:58:06 @monitor.py:363][0m wd_cost: 0.00023596
[32m[0322 12:58:06 @group.py:42][0m Callbacks took 117.131 sec in total. InferenceRunner: 115.343sec
[32m[0322 12:58:06 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9804/173481[03:00<50:06,54.45it/s]  6%|5         |10359/173481[03:10<49:55,54.45it/s] 12%|#1        |19974/173481[06:00<46:08,55.45it/s] 12%|#1        |20588/173481[06:10<45:57,55.45it/s] 17%|#6        |28854/173481[09:00<46:10,52.21it/s] 17%|#6        |29343/173481[09:10<46:00,52.21it/s] 22%|##1       |37844/173481[12:00<44:17,51.05it/s] 22%|##2       |38401/173481[12:10<44:06,51.05it/s] 27%|##6       |46560/173481[15:00<42:33,49.70it/s] 27%|##7       |47063/173481[15:10<42:23,49.70it/s] 32%|###2      |55926/173481[18:00<38:32,50.84it/s] 33%|###2      |56509/173481[18:10<38:20,50.84it/s] 38%|###7      |65157/173481[21:00<35:21,51.06it/s] 38%|###7      |65728/173481[21:11<35:10,51.06it/s] 44%|####3     |75469/173481[24:00<30:15,53.99it/s] 44%|####3     |76137/173481[24:11<30:03,53.99it/s] 49%|####9     |85631/173481[27:00<26:31,55.19it/s] 50%|####9     |86225/173481[27:11<26:20,55.19it/s] 55%|#####4    |95189/173481[30:00<24:06,54.13it/s] 55%|#####5    |95768/173481[30:11<23:55,54.13it/s] 60%|######    |104556/173481[33:00<21:38,53.06it/s] 61%|######    |105153/173481[33:11<21:27,53.06it/s] 66%|######5   |114329/173481[36:00<18:22,53.66it/s] 66%|######6   |114948/173481[36:11<18:10,53.66it/s] 71%|#######1  |123985/173481[39:00<15:22,53.65it/s] 72%|#######1  |124658/173481[39:11<15:09,53.65it/s] 77%|#######7  |134394/173481[42:00<11:42,55.66it/s] 78%|#######7  |135136/173481[42:12<11:28,55.66it/s] 83%|########3 |144674/173481[45:00<08:30,56.37it/s] 84%|########3 |145333/173481[45:12<08:19,56.37it/s] 89%|########9 |154849/173481[48:00<05:30,56.45it/s] 90%|########9 |155519/173481[48:12<05:18,56.45it/s] 95%|#########4|164762/173481[51:00<02:36,55.75it/s] 95%|#########5|165243/173481[51:12<02:27,55.75it/s]100%|##########|173481/173481[53:39<00:00,53.88it/s]
[32m[0322 13:51:46 @base.py:257][0m Epoch 3 (global_step 3816582) finished, time:3219.93 sec.
[32m[0322 13:51:46 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-3816582.
[32m[0322 13:51:47 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,175.06it/s]
2
[32m[0322 13:53:35 @monitor.py:363][0m QueueInput/queue_size: 0.13631
[32m[0322 13:53:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.248
[32m[0322 13:53:35 @monitor.py:363][0m activation-summaries/output-rms: 0.019915
[32m[0322 13:53:35 @monitor.py:363][0m cross_entropy_loss: 3.2425
[32m[0322 13:53:35 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.70763
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0855
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32611
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31048
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29534
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29307
[32m[0322 13:53:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 13:53:35 @monitor.py:363][0m train-error-top1: 0.77632
[32m[0322 13:53:35 @monitor.py:363][0m val-error-top1: 0.77461
[32m[0322 13:53:35 @monitor.py:363][0m val-utt-error: 0.34295
[32m[0322 13:53:35 @monitor.py:363][0m validation_cost: 3.29
[32m[0322 13:53:35 @monitor.py:363][0m wd_cost: 0.00023861
[32m[0322 13:53:35 @group.py:42][0m Callbacks took 109.007 sec in total. InferenceRunner: 107.534sec
[32m[0322 13:53:35 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10076/173481[03:00<48:39,55.98it/s]  6%|6         |10537/173481[03:10<48:30,55.98it/s] 11%|#1        |19398/173481[06:00<47:44,53.79it/s] 11%|#1        |19938/173481[06:10<47:34,53.79it/s] 17%|#7        |30090/173481[09:00<42:19,56.46it/s] 18%|#7        |30712/173481[09:10<42:08,56.46it/s] 24%|##3       |40844/173481[12:00<38:04,58.05it/s] 24%|##3       |41482/173481[12:10<37:53,58.05it/s] 29%|##9       |51114/173481[15:00<35:26,57.55it/s] 30%|##9       |51703/173481[15:10<35:16,57.55it/s] 35%|###5      |61007/173481[18:00<33:20,56.22it/s] 36%|###5      |61597/173481[18:10<33:09,56.22it/s] 41%|####      |71095/173481[21:00<30:23,56.13it/s] 41%|####1     |71772/173481[21:11<30:11,56.13it/s] 47%|####7     |81799/173481[24:00<26:27,57.75it/s] 48%|####7     |82498/173481[24:11<26:15,57.75it/s] 53%|#####3    |92118/173481[27:00<23:34,57.54it/s] 53%|#####3    |92772/173481[27:11<23:22,57.54it/s] 59%|#####9    |102755/173481[30:00<20:13,58.30it/s] 60%|#####9    |103443/173481[30:11<20:01,58.30it/s] 65%|######5   |113048/173481[33:00<17:26,57.74it/s] 66%|######5   |113682/173481[33:11<17:15,57.74it/s] 71%|#######1  |123703/173481[36:00<14:11,58.44it/s] 72%|#######1  |124372/173481[36:11<14:00,58.44it/s] 78%|#######7  |134613/173481[39:00<10:53,59.50it/s] 78%|#######8  |135317/173481[39:12<10:41,59.50it/s] 84%|########3 |145328/173481[42:00<07:53,59.51it/s] 84%|########4 |145961/173481[42:12<07:42,59.51it/s] 89%|########9 |155107/173481[45:00<05:23,56.80it/s] 90%|########9 |155810/173481[45:12<05:11,56.80it/s] 96%|#########5|165853/173481[48:00<02:11,58.21it/s] 96%|#########5|166492/173481[48:12<02:00,58.21it/s]100%|##########|173481/173481[50:26<00:00,57.32it/s]
[32m[0322 14:44:01 @base.py:257][0m Epoch 4 (global_step 3990063) finished, time:3026.66 sec.
[32m[0322 14:44:02 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-3990063.
[32m[0322 14:44:03 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.69it/s]
3
[32m[0322 14:45:50 @monitor.py:363][0m QueueInput/queue_size: 0.52815
[32m[0322 14:45:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.769
[32m[0322 14:45:50 @monitor.py:363][0m activation-summaries/output-rms: 0.021008
[32m[0322 14:45:50 @monitor.py:363][0m cross_entropy_loss: 3.2077
[32m[0322 14:45:50 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.7118
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0851
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32698
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31082
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29561
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29347
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 14:45:50 @monitor.py:363][0m train-error-top1: 0.75492
[32m[0322 14:45:50 @monitor.py:363][0m val-error-top1: 0.7533
[32m[0322 14:45:50 @monitor.py:363][0m val-utt-error: 0.31298
[32m[0322 14:45:50 @monitor.py:363][0m validation_cost: 3.1679
[32m[0322 14:45:50 @monitor.py:363][0m wd_cost: 4.803e-05
[32m[0322 14:45:50 @group.py:42][0m Callbacks took 108.417 sec in total. InferenceRunner: 106.539sec
[32m[0322 14:45:50 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10542/173481[03:00<46:22,58.56it/s]  6%|6         |11056/173481[03:10<46:13,58.56it/s] 12%|#1        |20062/173481[06:00<46:01,55.56it/s] 12%|#1        |20576/173481[06:10<45:51,55.56it/s] 17%|#7        |29757/173481[09:00<43:47,54.70it/s] 17%|#7        |30334/173481[09:10<43:37,54.70it/s] 23%|##3       |40357/173481[12:00<39:07,56.71it/s] 24%|##3       |40996/173481[12:10<38:56,56.71it/s] 29%|##9       |51032/173481[15:00<35:12,57.97it/s] 30%|##9       |51632/173481[15:10<35:01,57.97it/s] 36%|###5      |61773/173481[18:00<31:39,58.81it/s] 36%|###5      |62426/173481[18:10<31:28,58.81it/s] 42%|####1     |72497/173481[21:00<28:26,59.18it/s] 42%|####2     |73146/173481[21:11<28:15,59.18it/s] 48%|####7     |82922/173481[24:00<25:46,58.54it/s] 48%|####8     |83595/173481[24:11<25:35,58.54it/s] 54%|#####3    |93131/173481[27:00<23:14,57.61it/s] 54%|#####4    |93747/173481[27:11<23:03,57.61it/s] 60%|#####9    |103427/173481[30:00<20:20,57.40it/s] 60%|######    |104103/173481[30:11<20:08,57.40it/s] 66%|######5   |113867/173481[33:00<17:13,57.70it/s] 66%|######6   |114511/173481[33:11<17:02,57.70it/s] 72%|#######1  |124122/173481[36:00<14:21,57.33it/s] 72%|#######1  |124771/173481[36:11<14:09,57.33it/s] 77%|#######7  |134118/173481[39:00<11:37,56.41it/s] 78%|#######7  |134806/173481[39:12<11:25,56.41it/s] 83%|########3 |144382/173481[42:00<08:33,56.71it/s] 84%|########3 |145077/173481[42:12<08:20,56.71it/s] 89%|########9 |154802/173481[45:00<05:26,57.29it/s] 90%|########9 |155386/173481[45:12<05:15,57.29it/s] 95%|#########4|164417/173481[48:00<02:44,55.27it/s] 95%|#########5|165036/173481[48:12<02:32,55.27it/s]100%|##########|173481/173481[50:46<00:00,56.94it/s]
[32m[0322 15:36:37 @base.py:257][0m Epoch 5 (global_step 4163544) finished, time:3046.94 sec.
[32m[0322 15:36:37 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-4163544.
[32m[0322 15:36:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.22it/s]
4
[32m[0322 15:38:33 @monitor.py:363][0m QueueInput/queue_size: 0.60052
[32m[0322 15:38:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.707
[32m[0322 15:38:33 @monitor.py:363][0m activation-summaries/output-rms: 0.022969
[32m[0322 15:38:33 @monitor.py:363][0m cross_entropy_loss: 3.0049
[32m[0322 15:38:33 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.71597
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0847
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32781
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31117
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29591
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29381
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 15:38:33 @monitor.py:363][0m train-error-top1: 0.72269
[32m[0322 15:38:33 @monitor.py:363][0m val-error-top1: 0.73636
[32m[0322 15:38:33 @monitor.py:363][0m val-utt-error: 0.28966
[32m[0322 15:38:33 @monitor.py:363][0m validation_cost: 3.0718
[32m[0322 15:38:33 @monitor.py:363][0m wd_cost: 4.8334e-05
[32m[0322 15:38:33 @group.py:42][0m Callbacks took 116.260 sec in total. InferenceRunner: 114.632sec
[32m[0322 15:38:33 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10433/173481[03:00<46:53,57.96it/s]  6%|6         |10980/173481[03:10<46:43,57.96it/s] 11%|#1        |19886/173481[06:00<46:27,55.10it/s] 12%|#1        |20477/173481[06:10<46:16,55.10it/s] 17%|#7        |29731/173481[09:00<43:38,54.90it/s] 17%|#7        |30290/173481[09:10<43:28,54.90it/s] 23%|##2       |39761/173481[12:00<40:17,55.30it/s] 23%|##3       |40366/173481[12:10<40:07,55.30it/s] 29%|##8       |49941/173481[15:00<36:49,55.92it/s] 29%|##9       |50530/173481[15:10<36:38,55.92it/s] 35%|###4      |60091/173481[18:00<33:39,56.15it/s] 35%|###4      |60689/173481[18:11<33:28,56.15it/s] 40%|####      |69907/173481[21:00<31:11,55.33it/s] 41%|####      |70510/173481[21:11<31:01,55.33it/s] 46%|####5     |79606/173481[24:00<28:39,54.59it/s] 46%|####6     |80250/173481[24:11<28:27,54.59it/s] 52%|#####1    |89536/173481[27:00<25:29,54.87it/s] 52%|#####1    |90150/173481[27:11<25:18,54.87it/s] 57%|#####7    |99086/173481[30:00<22:59,53.94it/s] 57%|#####7    |99735/173481[30:11<22:47,53.94it/s] 62%|######2   |108344/173481[33:00<20:37,52.66it/s] 63%|######2   |109006/173481[33:11<20:24,52.66it/s] 68%|######8   |118248/173481[36:00<17:06,53.81it/s] 68%|######8   |118806/173481[36:11<16:56,53.81it/s] 74%|#######3  |128311/173481[39:00<13:43,54.84it/s] 74%|#######4  |129015/173481[39:12<13:30,54.84it/s] 80%|#######9  |138281/173481[42:00<10:38,55.11it/s] 80%|########  |138960/173481[42:12<10:26,55.11it/s] 86%|########5 |148617/173481[45:00<07:22,56.24it/s] 86%|########6 |149291/173481[45:12<07:10,56.24it/s] 91%|#########1|158110/173481[48:00<04:42,54.43it/s] 91%|#########1|158735/173481[48:12<04:30,54.43it/s] 97%|#########6|167661/173481[51:00<01:48,53.74it/s] 97%|#########7|168344/173481[51:12<01:35,53.74it/s]100%|##########|173481/173481[52:48<00:00,54.76it/s]
[32m[0322 16:31:21 @base.py:257][0m Epoch 6 (global_step 4337025) finished, time:3168.22 sec.
[32m[0322 16:31:22 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-4337025.
[32m[0322 16:31:23 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,175.93it/s]
5
[32m[0322 16:33:10 @monitor.py:363][0m QueueInput/queue_size: 0.51297
[32m[0322 16:33:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.016
[32m[0322 16:33:10 @monitor.py:363][0m activation-summaries/output-rms: 0.023448
[32m[0322 16:33:10 @monitor.py:363][0m cross_entropy_loss: 2.946
[32m[0322 16:33:10 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.71907
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0845
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32841
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31146
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29615
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29402
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 16:33:10 @monitor.py:363][0m train-error-top1: 0.71178
[32m[0322 16:33:10 @monitor.py:363][0m val-error-top1: 0.72278
[32m[0322 16:33:10 @monitor.py:363][0m val-utt-error: 0.27048
[32m[0322 16:33:10 @monitor.py:363][0m validation_cost: 2.9952
[32m[0322 16:33:10 @monitor.py:363][0m wd_cost: 9.712e-06
[32m[0322 16:33:10 @group.py:42][0m Callbacks took 108.889 sec in total. InferenceRunner: 107.002sec
[32m[0322 16:33:10 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10001/173481[03:00<49:02,55.56it/s]  6%|6         |10554/173481[03:10<48:52,55.56it/s] 11%|#1        |19825/173481[06:00<46:30,55.06it/s] 12%|#1        |20359/173481[06:10<46:20,55.06it/s] 17%|#7        |30012/173481[09:00<42:50,55.82it/s] 18%|#7        |30596/173481[09:10<42:39,55.82it/s] 22%|##2       |38382/173481[12:00<44:23,50.73it/s] 22%|##2       |38839/173481[12:10<44:14,50.73it/s] 27%|##7       |47270/173481[15:00<42:01,50.04it/s] 28%|##7       |47854/173481[15:10<41:50,50.04it/s] 33%|###2      |57165/173481[18:00<37:00,52.39it/s] 33%|###3      |57719/173481[18:10<36:49,52.39it/s] 38%|###8      |66755/173481[21:00<33:40,52.83it/s] 39%|###8      |67304/173481[21:10<33:29,52.83it/s] 44%|####4     |76806/173481[24:00<29:40,54.29it/s] 45%|####4     |77384/173481[24:11<29:30,54.29it/s] 50%|####9     |86011/173481[27:00<27:40,52.67it/s] 50%|####9     |86624/173481[27:11<27:29,52.67it/s] 55%|#####5    |96085/173481[30:00<23:46,54.26it/s] 56%|#####5    |96719/173481[30:11<23:34,54.26it/s] 61%|######1   |106200/173481[33:00<20:18,55.20it/s] 62%|######1   |106829/173481[33:11<20:07,55.20it/s] 67%|######6   |115872/173481[36:00<17:37,54.46it/s] 67%|######7   |116484/173481[36:11<17:26,54.46it/s] 72%|#######2  |125427/173481[39:00<14:53,53.76it/s] 73%|#######2  |125970/173481[39:11<14:43,53.76it/s] 78%|#######7  |134520/173481[42:00<12:28,52.08it/s] 78%|#######7  |135089/173481[42:12<12:17,52.08it/s] 83%|########3 |144168/173481[45:00<09:14,52.83it/s] 83%|########3 |144802/173481[45:12<09:02,52.83it/s] 87%|########7 |151513/173481[48:00<07:57,46.04it/s] 87%|########7 |151709/173481[48:12<07:52,46.04it/s] 93%|#########2|160635/173481[51:00<04:26,48.25it/s] 93%|#########2|161274/173481[51:12<04:13,48.25it/s] 98%|#########8|170421/173481[54:00<00:59,51.12it/s] 99%|#########8|171157/173481[54:12<00:45,51.12it/s]100%|##########|173481/173481[54:53<00:00,52.68it/s]
[32m[0322 17:28:03 @base.py:257][0m Epoch 7 (global_step 4510506) finished, time:3293.33 sec.
[32m[0322 17:28:04 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-4510506.
[32m[0322 17:28:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.15it/s]
6
[32m[0322 17:29:49 @monitor.py:363][0m QueueInput/queue_size: 0.35062
[32m[0322 17:29:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.977
[32m[0322 17:29:49 @monitor.py:363][0m activation-summaries/output-rms: 0.024013
[32m[0322 17:29:49 @monitor.py:363][0m cross_entropy_loss: 2.9234
[32m[0322 17:29:49 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72113
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0844
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32881
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31165
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29631
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29414
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 17:29:49 @monitor.py:363][0m train-error-top1: 0.71742
[32m[0322 17:29:49 @monitor.py:363][0m val-error-top1: 0.71613
[32m[0322 17:29:49 @monitor.py:363][0m val-utt-error: 0.26304
[32m[0322 17:29:49 @monitor.py:363][0m validation_cost: 2.9588
[32m[0322 17:29:49 @monitor.py:363][0m wd_cost: 9.7421e-06
[32m[0322 17:29:49 @group.py:42][0m Callbacks took 105.907 sec in total. InferenceRunner: 104.494sec
[32m[0322 17:29:49 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10869/173481[03:00<44:53,60.37it/s]  7%|6         |11466/173481[03:10<44:43,60.37it/s] 12%|#2        |21506/173481[06:00<42:24,59.73it/s] 13%|#2        |22098/173481[06:10<42:14,59.73it/s] 18%|#8        |31449/173481[09:00<41:14,57.39it/s] 18%|#8        |32031/173481[09:10<41:04,57.39it/s] 24%|##3       |41629/173481[12:00<38:34,56.97it/s] 24%|##4       |42239/173481[12:10<38:23,56.97it/s] 30%|###       |52110/173481[15:00<35:07,57.59it/s] 30%|###       |52713/173481[15:10<34:57,57.59it/s] 36%|###5      |62222/173481[18:00<32:36,56.87it/s] 36%|###6      |62858/173481[18:10<32:25,56.87it/s] 42%|####1     |72424/173481[21:00<29:40,56.76it/s] 42%|####2     |72939/173481[21:11<29:31,56.76it/s] 47%|####7     |82359/173481[24:00<27:08,55.96it/s] 48%|####7     |82921/173481[24:11<26:58,55.96it/s] 53%|#####3    |92739/173481[27:00<23:41,56.80it/s] 54%|#####3    |93404/173481[27:11<23:29,56.80it/s] 60%|#####9    |103429/173481[30:00<20:06,58.06it/s] 60%|#####9    |104070/173481[30:11<19:55,58.06it/s] 66%|######5   |114474/173481[33:00<16:29,59.66it/s] 66%|######6   |115218/173481[33:11<16:16,59.66it/s] 72%|#######2  |125234/173481[36:00<13:27,59.71it/s] 73%|#######2  |125961/173481[36:11<13:15,59.71it/s] 78%|#######8  |135860/173481[39:00<10:33,59.37it/s] 79%|#######8  |136566/173481[39:11<10:21,59.37it/s] 85%|########4 |146613/173481[42:00<07:31,59.55it/s] 85%|########4 |147270/173481[42:12<07:20,59.55it/s] 91%|######### |157335/173481[45:00<04:31,59.56it/s] 91%|#########1|158060/173481[45:12<04:18,59.56it/s] 97%|#########6|168170/173481[48:00<01:28,59.87it/s] 97%|#########7|168948/173481[48:12<01:15,59.87it/s]100%|##########|173481/173481[49:28<00:00,58.44it/s]
[32m[0322 18:19:18 @base.py:257][0m Epoch 8 (global_step 4683987) finished, time:2968.67 sec.
[32m[0322 18:19:19 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-4683987.
[32m[0322 18:19:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.91it/s]
7
[32m[0322 18:21:04 @monitor.py:363][0m QueueInput/queue_size: 0.18601
[32m[0322 18:21:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.278
[32m[0322 18:21:04 @monitor.py:363][0m activation-summaries/output-rms: 0.02461
[32m[0322 18:21:04 @monitor.py:363][0m cross_entropy_loss: 2.8746
[32m[0322 18:21:04 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72318
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0843
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3292
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31185
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29648
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29425
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 18:21:04 @monitor.py:363][0m train-error-top1: 0.70464
[32m[0322 18:21:04 @monitor.py:363][0m val-error-top1: 0.70858
[32m[0322 18:21:04 @monitor.py:363][0m val-utt-error: 0.25555
[32m[0322 18:21:04 @monitor.py:363][0m validation_cost: 2.918
[32m[0322 18:21:04 @monitor.py:363][0m wd_cost: 9.772e-06
[32m[0322 18:21:04 @group.py:42][0m Callbacks took 106.173 sec in total. InferenceRunner: 104.056sec
[32m[0322 18:21:04 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11229/173481[03:00<43:21,62.37it/s]  7%|6         |11807/173481[03:10<43:12,62.37it/s] 12%|#2        |21231/173481[06:00<43:10,58.77it/s] 13%|#2        |21812/173481[06:10<43:00,58.77it/s] 18%|#7        |30701/173481[09:00<42:51,55.52it/s] 18%|#8        |31324/173481[09:10<42:40,55.52it/s] 24%|##3       |41263/173481[12:00<38:37,57.06it/s] 24%|##4       |41883/173481[12:10<38:26,57.06it/s] 30%|###       |52104/173481[15:00<34:31,58.60it/s] 30%|###       |52785/173481[15:10<34:19,58.60it/s] 36%|###5      |61924/173481[18:00<32:54,56.50it/s] 36%|###6      |62560/173481[18:10<32:43,56.50it/s] 42%|####1     |72641/173481[21:00<28:59,57.98it/s] 42%|####2     |73322/173481[21:11<28:47,57.98it/s] 48%|####8     |83479/173481[24:00<25:23,59.07it/s] 49%|####8     |84168/173481[24:11<25:11,59.07it/s] 55%|#####4    |94614/173481[27:00<21:45,60.43it/s] 55%|#####4    |95259/173481[27:11<21:34,60.43it/s] 61%|######    |105558/173481[30:00<18:40,60.61it/s] 61%|######1   |106290/173481[30:11<18:28,60.61it/s] 67%|######7   |116718/173481[33:00<15:26,61.30it/s] 68%|######7   |117470/173481[33:11<15:13,61.30it/s] 73%|#######3  |127438/173481[36:00<12:42,60.40it/s] 74%|#######3  |128170/173481[36:11<12:30,60.40it/s] 80%|#######9  |138248/173481[39:00<09:45,60.22it/s] 80%|########  |138952/173481[39:12<09:33,60.22it/s] 86%|########5 |148693/173481[42:00<06:59,59.10it/s] 86%|########6 |149365/173481[42:12<06:48,59.10it/s] 92%|#########1|159234/173481[45:00<04:02,58.83it/s] 92%|#########2|159952/173481[45:12<03:49,58.83it/s] 98%|#########7|169373/173481[48:00<01:11,57.55it/s] 98%|#########7|169983/173481[48:12<01:00,57.55it/s]100%|##########|173481/173481[49:18<00:00,58.64it/s]
[32m[0322 19:10:23 @base.py:257][0m Epoch 9 (global_step 4857468) finished, time:2958.52 sec.
[32m[0322 19:10:23 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-4857468.
[32m[0322 19:10:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.35it/s]
8
[32m[0322 19:12:09 @monitor.py:363][0m QueueInput/queue_size: 0.25538
[32m[0322 19:12:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.582
[32m[0322 19:12:09 @monitor.py:363][0m activation-summaries/output-rms: 0.023992
[32m[0322 19:12:09 @monitor.py:363][0m cross_entropy_loss: 2.9244
[32m[0322 19:12:09 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72439
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0842
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32943
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31197
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29659
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29432
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 19:12:09 @monitor.py:363][0m train-error-top1: 0.70946
[32m[0322 19:12:09 @monitor.py:363][0m val-error-top1: 0.70266
[32m[0322 19:12:09 @monitor.py:363][0m val-utt-error: 0.24891
[32m[0322 19:12:09 @monitor.py:363][0m validation_cost: 2.8861
[32m[0322 19:12:09 @monitor.py:363][0m wd_cost: 1.958e-06
[32m[0322 19:12:09 @group.py:42][0m Callbacks took 106.512 sec in total. InferenceRunner: 104.959sec
[32m[0322 19:12:09 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10197/173481[03:00<48:02,56.65it/s]  6%|6         |10721/173481[03:10<47:53,56.65it/s] 12%|#1        |20317/173481[06:00<45:14,56.43it/s] 12%|#2        |20821/173481[06:10<45:05,56.43it/s] 18%|#7        |30443/173481[09:00<42:18,56.34it/s] 18%|#7        |31066/173481[09:10<42:07,56.34it/s] 25%|##5       |43543/173481[12:00<34:06,63.51it/s] 26%|##5       |44472/173481[12:10<33:51,63.51it/s] 34%|###3      |58597/173481[15:00<26:31,72.19it/s] 34%|###4      |59581/173481[15:10<26:17,72.19it/s] 42%|####2     |73622/173481[18:00<21:29,77.42it/s] 43%|####2     |74458/173481[18:10<21:19,77.42it/s] 51%|#####     |88391/173481[21:00<17:48,79.67it/s] 51%|#####1    |89324/173481[21:11<17:36,79.67it/s] 60%|#####9    |103882/173481[24:00<14:01,82.74it/s] 60%|######    |104783/173481[24:11<13:50,82.74it/s] 68%|######8   |118148/173481[27:00<11:23,80.96it/s] 69%|######8   |119031/173481[27:11<11:12,80.96it/s] 76%|#######5  |131752/173481[30:00<08:53,78.17it/s] 76%|#######6  |132576/173481[30:11<08:43,78.17it/s] 83%|########3 |144462/173481[33:00<06:31,74.19it/s] 84%|########3 |145341/173481[33:11<06:19,74.19it/s] 91%|######### |157574/173481[36:00<03:36,73.51it/s] 91%|#########1|158449/173481[36:11<03:24,73.51it/s] 98%|#########7|169618/173481[39:00<00:55,70.05it/s] 98%|#########8|170351/173481[39:11<00:44,70.05it/s]100%|##########|173481/173481[40:07<00:00,72.07it/s]
[32m[0322 19:52:16 @base.py:257][0m Epoch 10 (global_step 5030949) finished, time:2407.10 sec.
[32m[0322 19:52:17 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-5030949.
[32m[0322 19:52:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.32it/s]
9
[32m[0322 19:54:20 @monitor.py:363][0m QueueInput/queue_size: 0.30221
[32m[0322 19:54:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.286
[32m[0322 19:54:20 @monitor.py:363][0m activation-summaries/output-rms: 0.025696
[32m[0322 19:54:20 @monitor.py:363][0m cross_entropy_loss: 2.7842
[32m[0322 19:54:20 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72537
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0841
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32962
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31207
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29667
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29437
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 19:54:20 @monitor.py:363][0m train-error-top1: 0.67777
[32m[0322 19:54:20 @monitor.py:363][0m val-error-top1: 0.70021
[32m[0322 19:54:20 @monitor.py:363][0m val-utt-error: 0.24535
[32m[0322 19:54:20 @monitor.py:363][0m validation_cost: 2.8736
[32m[0322 19:54:20 @monitor.py:363][0m wd_cost: 1.9608e-06
[32m[0322 19:54:20 @group.py:42][0m Callbacks took 123.510 sec in total. InferenceRunner: 121.979sec
[32m[0322 19:54:20 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10666/173481[03:00<45:47,59.25it/s]  6%|6         |11205/173481[03:10<45:38,59.25it/s] 12%|#1        |20534/173481[06:00<44:45,56.95it/s] 12%|#2        |21112/173481[06:10<44:35,56.95it/s] 17%|#7        |29963/173481[09:00<43:49,54.57it/s] 18%|#7        |30521/173481[09:10<43:39,54.57it/s] 23%|##3       |40322/173481[12:00<39:36,56.02it/s] 24%|##3       |40908/173481[12:10<39:26,56.02it/s] 29%|##9       |51031/173481[15:00<35:22,57.70it/s] 30%|##9       |51615/173481[15:10<35:11,57.70it/s] 36%|###5      |61799/173481[18:00<31:41,58.74it/s] 36%|###5      |62396/173481[18:10<31:31,58.74it/s] 42%|####1     |72152/173481[21:00<29:03,58.12it/s] 42%|####1     |72775/173481[21:11<28:52,58.12it/s] 48%|####7     |82556/173481[24:00<26:08,57.96it/s] 48%|####7     |83245/173481[24:11<25:56,57.96it/s] 53%|#####3    |92665/173481[27:00<23:36,57.04it/s] 54%|#####3    |93326/173481[27:11<23:25,57.04it/s] 59%|#####9    |102918/173481[30:00<20:37,57.00it/s] 60%|#####9    |103555/173481[30:11<20:26,57.00it/s] 65%|######5   |113297/173481[33:00<17:29,57.33it/s] 66%|######5   |114011/173481[33:11<17:17,57.33it/s] 71%|#######1  |123652/173481[36:00<14:27,57.43it/s] 72%|#######1  |124360/173481[36:11<14:15,57.43it/s] 77%|#######7  |133902/173481[39:00<11:32,57.18it/s] 78%|#######7  |134618/173481[39:11<11:19,57.18it/s] 83%|########3 |144721/173481[42:00<08:10,58.61it/s] 84%|########3 |145410/173481[42:12<07:58,58.61it/s] 89%|########9 |155097/173481[45:00<05:16,58.12it/s] 90%|########9 |155780/173481[45:12<05:04,58.12it/s] 95%|#########5|165341/173481[48:00<02:21,57.51it/s] 96%|#########5|165995/173481[48:12<02:10,57.51it/s]100%|##########|173481/173481[50:21<00:00,57.41it/s]
[32m[0322 20:44:41 @base.py:257][0m Epoch 11 (global_step 5204430) finished, time:3021.63 sec.
[32m[0322 20:44:42 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-5204430.
[32m[0322 20:44:44 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,178.96it/s]
10
[32m[0322 20:46:29 @monitor.py:363][0m QueueInput/queue_size: 0.20706
[32m[0322 20:46:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.518
[32m[0322 20:46:29 @monitor.py:363][0m activation-summaries/output-rms: 0.025796
[32m[0322 20:46:29 @monitor.py:363][0m cross_entropy_loss: 2.7898
[32m[0322 20:46:29 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72631
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32981
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31217
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29676
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29441
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 20:46:29 @monitor.py:363][0m train-error-top1: 0.68986
[32m[0322 20:46:29 @monitor.py:363][0m val-error-top1: 0.6955
[32m[0322 20:46:29 @monitor.py:363][0m val-utt-error: 0.24227
[32m[0322 20:46:29 @monitor.py:363][0m validation_cost: 2.8486
[32m[0322 20:46:29 @monitor.py:363][0m wd_cost: 1.9636e-06
[32m[0322 20:46:29 @group.py:42][0m Callbacks took 107.857 sec in total. InferenceRunner: 105.188sec
[32m[0322 20:46:29 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10781/173481[03:00<45:16,59.89it/s]  7%|6         |11319/173481[03:10<45:07,59.89it/s] 12%|#2        |21230/173481[06:00<43:02,58.95it/s] 13%|#2        |21859/173481[06:10<42:51,58.95it/s] 18%|#8        |31475/173481[09:00<40:52,57.91it/s] 18%|#8        |32058/173481[09:10<40:41,57.91it/s] 24%|##3       |41091/173481[12:00<39:42,55.58it/s] 24%|##3       |41617/173481[12:10<39:32,55.58it/s] 29%|##9       |50835/173481[15:00<37:16,54.84it/s] 30%|##9       |51409/173481[15:10<37:05,54.84it/s] 35%|###5      |61015/173481[18:00<33:39,55.69it/s] 36%|###5      |61615/173481[18:10<33:28,55.69it/s] 41%|####      |70784/173481[21:00<31:08,54.97it/s] 41%|####1     |71424/173481[21:10<30:56,54.97it/s] 47%|####6     |81145/173481[24:00<27:21,56.23it/s] 47%|####7     |81791/173481[24:11<27:10,56.23it/s] 53%|#####2    |91285/173481[27:00<24:20,56.28it/s] 53%|#####2    |91924/173481[27:11<24:09,56.28it/s] 59%|#####8    |101600/173481[30:00<21:05,56.79it/s] 59%|#####8    |102244/173481[30:11<20:54,56.79it/s] 64%|######4   |111870/173481[33:00<18:02,56.91it/s] 65%|######4   |112510/173481[33:11<17:51,56.91it/s] 70%|#######   |121818/173481[36:00<15:21,56.08it/s] 71%|#######   |122443/173481[36:11<15:10,56.08it/s] 76%|#######5  |131760/173481[39:00<12:29,55.65it/s] 76%|#######6  |132419/173481[39:11<12:17,55.65it/s] 82%|########1 |141840/173481[42:00<09:26,55.82it/s] 82%|########2 |142490/173481[42:11<09:15,55.82it/s] 88%|########7 |152228/173481[45:00<06:14,56.75it/s] 88%|########8 |152941/173481[45:12<06:01,56.75it/s] 94%|#########4|163135/173481[48:00<02:56,58.61it/s] 94%|#########4|163869/173481[48:12<02:44,58.61it/s]100%|##########|173481/173481[50:48<00:00,56.90it/s]
[32m[0322 21:37:18 @base.py:257][0m Epoch 12 (global_step 5377911) finished, time:3048.73 sec.
[32m[0322 21:37:19 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-5377911.
[32m[0322 21:37:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,175.56it/s]
11
[32m[0322 21:39:07 @monitor.py:363][0m QueueInput/queue_size: 0.16641
[32m[0322 21:39:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.364
[32m[0322 21:39:07 @monitor.py:363][0m activation-summaries/output-rms: 0.024696
[32m[0322 21:39:07 @monitor.py:363][0m cross_entropy_loss: 2.8044
[32m[0322 21:39:07 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72677
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0839
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3299
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31222
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2968
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29444
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 21:39:07 @monitor.py:363][0m train-error-top1: 0.69597
[32m[0322 21:39:07 @monitor.py:363][0m val-error-top1: 0.69486
[32m[0322 21:39:07 @monitor.py:363][0m val-utt-error: 0.23924
[32m[0322 21:39:07 @monitor.py:363][0m validation_cost: 2.8454
[32m[0322 21:39:07 @monitor.py:363][0m wd_cost: 3.93e-07
[32m[0322 21:39:07 @group.py:42][0m Callbacks took 109.382 sec in total. InferenceRunner: 107.224sec
[32m[0322 21:39:07 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11546/173481[03:00<42:04,64.14it/s]  7%|7         |12160/173481[03:10<41:55,64.14it/s] 13%|#3        |22764/173481[06:00<39:44,63.21it/s] 13%|#3        |23410/173481[06:10<39:33,63.21it/s] 19%|#8        |32729/173481[09:00<39:44,59.03it/s] 19%|#9        |33318/173481[09:10<39:34,59.03it/s] 25%|##4       |43131/173481[12:00<37:12,58.40it/s] 25%|##5       |43752/173481[12:10<37:01,58.40it/s] 31%|###       |53409/173481[15:00<34:39,57.74it/s] 31%|###1      |53993/173481[15:10<34:29,57.74it/s] 37%|###6      |63764/173481[18:00<31:43,57.63it/s] 37%|###7      |64454/173481[18:10<31:31,57.63it/s] 43%|####3     |75143/173481[21:00<27:11,60.29it/s] 44%|####3     |75847/173481[21:11<26:59,60.29it/s] 50%|####9     |86555/173481[24:00<23:26,61.81it/s] 50%|#####     |87248/173481[24:11<23:15,61.81it/s] 57%|#####6    |98062/173481[27:00<20:00,62.85it/s] 57%|#####6    |98723/173481[27:11<19:49,62.85it/s] 63%|######2   |108844/173481[30:00<17:33,61.34it/s] 63%|######3   |109562/173481[30:11<17:22,61.34it/s] 70%|######9   |121079/173481[33:00<13:32,64.48it/s] 70%|#######   |121878/173481[33:11<13:20,64.48it/s] 79%|#######8  |136229/173481[36:00<08:30,73.02it/s] 79%|#######9  |137232/173481[36:11<08:16,73.02it/s] 88%|########8 |153076/173481[39:00<04:08,82.03it/s] 89%|########8 |154196/173481[39:11<03:55,82.03it/s] 97%|#########6|168140/173481[42:00<01:04,82.85it/s] 97%|#########7|168943/173481[42:12<00:54,82.85it/s]100%|##########|173481/173481[43:23<00:00,66.64it/s]
[32m[0322 22:22:31 @base.py:257][0m Epoch 13 (global_step 5551392) finished, time:2603.29 sec.
[32m[0322 22:22:32 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-5551392.
[32m[0322 22:22:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.44it/s]
12
[32m[0322 22:24:19 @monitor.py:363][0m QueueInput/queue_size: 0.30291
[32m[0322 22:24:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.572
[32m[0322 22:24:19 @monitor.py:363][0m activation-summaries/output-rms: 0.02544
[32m[0322 22:24:19 @monitor.py:363][0m cross_entropy_loss: 2.7905
[32m[0322 22:24:19 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72721
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0839
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32999
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31227
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29685
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29446
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 22:24:19 @monitor.py:363][0m train-error-top1: 0.68573
[32m[0322 22:24:19 @monitor.py:363][0m val-error-top1: 0.69316
[32m[0322 22:24:19 @monitor.py:363][0m val-utt-error: 0.23765
[32m[0322 22:24:19 @monitor.py:363][0m validation_cost: 2.8341
[32m[0322 22:24:19 @monitor.py:363][0m wd_cost: 3.9327e-07
[32m[0322 22:24:19 @group.py:42][0m Callbacks took 108.449 sec in total. InferenceRunner: 106.691sec
[32m[0322 22:24:19 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11636/173481[03:00<41:43,64.64it/s]  7%|7         |12242/173481[03:10<41:34,64.64it/s] 13%|#2        |22078/173481[06:00<41:16,61.15it/s] 13%|#3        |22683/173481[06:10<41:06,61.15it/s] 19%|#9        |33218/173481[09:00<38:00,61.51it/s] 19%|#9        |33819/173481[09:10<37:50,61.51it/s] 26%|##5       |44727/173481[12:00<34:13,62.70it/s] 26%|##6       |45439/173481[12:10<34:02,62.70it/s] 32%|###2      |56028/173481[15:00<31:12,62.74it/s] 33%|###2      |56647/173481[15:10<31:02,62.74it/s] 39%|###8      |67251/173481[18:00<28:18,62.54it/s] 39%|###9      |67948/173481[18:10<28:07,62.54it/s] 45%|####5     |78133/173481[21:00<25:50,61.48it/s] 45%|####5     |78793/173481[21:11<25:40,61.48it/s] 52%|#####1    |89418/173481[24:00<22:34,62.07it/s] 52%|#####1    |90122/173481[24:11<22:23,62.07it/s] 58%|#####8    |100988/173481[27:00<19:07,63.15it/s] 59%|#####8    |101652/173481[27:11<18:57,63.15it/s] 65%|######4   |112278/173481[30:00<16:12,62.93it/s] 65%|######5   |112972/173481[30:11<16:01,62.93it/s] 71%|#######1  |123743/173481[33:00<13:05,63.30it/s] 72%|#######1  |124457/173481[33:11<12:54,63.30it/s] 78%|#######8  |135464/173481[36:00<09:52,64.20it/s] 79%|#######8  |136219/173481[36:11<09:40,64.20it/s] 85%|########4 |146996/173481[39:00<06:52,64.13it/s] 85%|########5 |147747/173481[39:11<06:41,64.13it/s] 91%|#########1|158461/173481[42:00<03:55,63.91it/s] 92%|#########1|159225/173481[42:12<03:43,63.91it/s] 98%|#########7|169593/173481[45:00<01:01,62.85it/s] 98%|#########8|170257/173481[45:12<00:51,62.85it/s]100%|##########|173481/173481[46:06<00:00,62.71it/s]
[32m[0322 23:10:25 @base.py:257][0m Epoch 14 (global_step 5724873) finished, time:2766.36 sec.
[32m[0322 23:10:26 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-5724873.
[32m[0322 23:10:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,178.62it/s]
13
[32m[0322 23:12:13 @monitor.py:363][0m QueueInput/queue_size: 0.27421
[32m[0322 23:12:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.839
[32m[0322 23:12:13 @monitor.py:363][0m activation-summaries/output-rms: 0.024829
[32m[0322 23:12:13 @monitor.py:363][0m cross_entropy_loss: 2.8648
[32m[0322 23:12:13 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72752
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0839
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33007
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31231
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29689
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29448
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 23:12:13 @monitor.py:363][0m train-error-top1: 0.69637
[32m[0322 23:12:13 @monitor.py:363][0m val-error-top1: 0.69044
[32m[0322 23:12:13 @monitor.py:363][0m val-utt-error: 0.23685
[32m[0322 23:12:13 @monitor.py:363][0m validation_cost: 2.8218
[32m[0322 23:12:13 @monitor.py:363][0m wd_cost: 3.9347e-07
[32m[0322 23:12:13 @group.py:42][0m Callbacks took 107.352 sec in total. InferenceRunner: 105.384sec
[32m[0322 23:12:13 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10882/173481[03:00<44:49,60.45it/s]  7%|6         |11439/173481[03:10<44:40,60.45it/s] 13%|#2        |21837/173481[06:00<41:40,60.65it/s] 13%|#2        |22348/173481[06:10<41:31,60.65it/s] 19%|#8        |32527/173481[09:00<39:08,60.01it/s] 19%|#9        |33196/173481[09:10<38:57,60.01it/s] 26%|##5       |44260/173481[12:00<34:27,62.49it/s] 26%|##5       |44984/173481[12:10<34:16,62.49it/s] 32%|###2      |56156/173481[15:00<30:26,64.24it/s] 33%|###2      |56894/173481[15:10<30:14,64.24it/s] 39%|###9      |67813/173481[18:00<27:18,64.50it/s] 39%|###9      |68504/173481[18:10<27:07,64.50it/s] 46%|####5     |79463/173481[21:00<24:15,64.61it/s] 46%|####6     |80196/173481[21:11<24:03,64.61it/s] 53%|#####2    |91268/173481[24:00<21:03,65.09it/s] 53%|#####3    |92006/173481[24:11<20:51,65.09it/s] 60%|#####9    |103857/173481[27:00<17:12,67.42it/s] 60%|######    |104711/173481[27:11<17:00,67.42it/s] 68%|######7   |117779/173481[30:00<12:53,72.04it/s] 68%|######8   |118765/173481[30:11<12:39,72.04it/s] 76%|#######6  |132693/173481[33:00<08:49,77.07it/s] 77%|#######7  |133651/173481[33:11<08:36,77.07it/s] 85%|########4 |146872/173481[36:00<05:41,77.91it/s] 85%|########5 |147776/173481[36:11<05:29,77.91it/s] 92%|#########1|159131/173481[39:00<03:17,72.68it/s] 92%|#########2|159912/173481[39:11<03:06,72.68it/s]100%|#########9|172752/173481[42:00<00:09,74.14it/s]100%|##########|173481/173481[42:09<00:00,68.59it/s]
[32m[0322 23:54:22 @base.py:257][0m Epoch 15 (global_step 5898354) finished, time:2529.32 sec.
[32m[0322 23:54:23 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-5898354.
[32m[0322 23:54:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:48<00:00,172.69it/s]
14
[32m[0322 23:56:13 @monitor.py:363][0m QueueInput/queue_size: 0.26675
[32m[0322 23:56:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.61
[32m[0322 23:56:13 @monitor.py:363][0m activation-summaries/output-rms: 0.026277
[32m[0322 23:56:13 @monitor.py:363][0m cross_entropy_loss: 2.7312
[32m[0322 23:56:13 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72757
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0839
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33011
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31234
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29691
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29449
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0322 23:56:13 @monitor.py:363][0m train-error-top1: 0.67149
[32m[0322 23:56:13 @monitor.py:363][0m val-error-top1: 0.69054
[32m[0322 23:56:13 @monitor.py:363][0m val-utt-error: 0.23701
[32m[0322 23:56:13 @monitor.py:363][0m validation_cost: 2.8233
[32m[0322 23:56:13 @monitor.py:363][0m wd_cost: 7.8708e-08
[32m[0322 23:56:13 @group.py:42][0m Callbacks took 110.838 sec in total. InferenceRunner: 109.007sec
[32m[0322 23:56:13 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15809/173481[03:00<29:55,87.83it/s] 10%|9         |16745/173481[03:10<29:44,87.83it/s] 18%|#8        |31940/173481[06:00<26:35,88.71it/s] 19%|#8        |32480/173481[06:10<26:29,88.71it/s] 24%|##3       |41094/173481[09:00<34:07,64.65it/s] 24%|##4       |41660/173481[09:10<33:59,64.65it/s] 29%|##9       |50506/173481[12:00<35:27,57.81it/s] 29%|##9       |51075/173481[12:10<35:17,57.81it/s] 35%|###4      |60146/173481[15:00<33:58,55.60it/s] 35%|###5      |60802/173481[15:10<33:46,55.60it/s] 41%|####      |70774/173481[18:00<29:53,57.27it/s] 41%|####1     |71330/173481[18:10<29:43,57.27it/s] 46%|####6     |80302/173481[21:00<28:13,55.02it/s] 47%|####6     |80926/173481[21:11<28:02,55.02it/s] 52%|#####1    |89868/173481[24:00<25:46,54.06it/s] 52%|#####2    |90515/173481[24:11<25:34,54.06it/s] 57%|#####7    |99355/173481[27:00<23:08,53.37it/s] 58%|#####7    |99972/173481[27:11<22:57,53.37it/s] 63%|######2   |108606/173481[30:00<20:39,52.36it/s] 63%|######2   |109230/173481[30:11<20:27,52.36it/s] 68%|######7   |117891/173481[33:00<17:49,51.96it/s] 68%|######8   |118425/173481[33:11<17:39,51.96it/s] 73%|#######3  |127386/173481[36:00<14:40,52.35it/s] 74%|#######3  |127977/173481[36:11<14:29,52.35it/s] 79%|#######8  |136776/173481[39:00<11:42,52.25it/s] 79%|#######9  |137378/173481[39:11<11:30,52.25it/s] 84%|########4 |146251/173481[42:00<08:39,52.44it/s] 85%|########4 |146855/173481[42:12<08:27,52.44it/s] 90%|########9 |156051/173481[45:00<05:26,53.42it/s] 90%|######### |156659/173481[45:12<05:14,53.42it/s] 95%|#########5|165335/173481[48:00<02:35,52.48it/s] 96%|#########5|165931/173481[48:12<02:23,52.48it/s]100%|##########|173481/173481[50:45<00:00,56.96it/s]
[32m[0323 00:46:59 @base.py:257][0m Epoch 16 (global_step 6071835) finished, time:3045.75 sec.
[32m[0323 00:46:59 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-6071835.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,170.29it/s]
15
[32m[0323 00:48:50 @monitor.py:363][0m QueueInput/queue_size: 0.22378
[32m[0323 00:48:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.63
[32m[0323 00:48:50 @monitor.py:363][0m activation-summaries/output-rms: 0.026027
[32m[0323 00:48:50 @monitor.py:363][0m cross_entropy_loss: 2.7549
[32m[0323 00:48:50 @monitor.py:363][0m lr: 2.4414e-07
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72762
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0839
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33015
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31236
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29693
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2945
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 00:48:50 @monitor.py:363][0m train-error-top1: 0.67777
[32m[0323 00:48:50 @monitor.py:363][0m val-error-top1: 0.68892
[32m[0323 00:48:50 @monitor.py:363][0m val-utt-error: 0.23388
[32m[0323 00:48:50 @monitor.py:363][0m validation_cost: 2.8145
[32m[0323 00:48:50 @monitor.py:363][0m wd_cost: 7.8721e-08
[32m[0323 00:48:50 @group.py:42][0m Callbacks took 111.395 sec in total. InferenceRunner: 110.544sec
[32m[0323 00:48:50 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9776/173481[03:00<50:14,54.31it/s]  6%|5         |10314/173481[03:10<50:04,54.31it/s] 11%|#1        |19250/173481[06:00<48:05,53.46it/s] 11%|#1        |19763/173481[06:10<47:55,53.46it/s] 17%|#6        |28690/173481[09:00<45:35,52.94it/s] 17%|#6        |29294/173481[09:10<45:23,52.94it/s] 22%|##1       |37500/173481[12:00<44:34,50.85it/s] 22%|##1       |37994/173481[12:10<44:24,50.85it/s] 26%|##6       |45944/173481[15:00<43:33,48.80it/s] 27%|##6       |46454/173481[15:10<43:22,48.80it/s] 32%|###1      |54668/173481[18:00<40:43,48.63it/s] 32%|###1      |55215/173481[18:10<40:31,48.63it/s] 37%|###6      |63730/173481[21:00<36:58,49.47it/s] 37%|###7      |64224/173481[21:11<36:48,49.47it/s] 42%|####1     |72819/173481[24:00<33:34,49.98it/s] 42%|####2     |73344/173481[24:11<33:23,49.98it/s] 47%|####7     |82205/173481[27:00<29:48,51.03it/s] 48%|####7     |82765/173481[27:11<29:37,51.03it/s] 53%|#####2    |91570/173481[30:00<26:30,51.52it/s] 53%|#####3    |92142/173481[30:11<26:18,51.52it/s] 58%|#####8    |100945/173481[33:00<23:20,51.79it/s] 59%|#####8    |101549/173481[33:11<23:08,51.79it/s] 64%|######3   |110630/173481[36:00<19:51,52.77it/s] 64%|######4   |111239/173481[36:11<19:39,52.77it/s] 69%|######8   |119675/173481[39:00<17:25,51.47it/s] 69%|######9   |120285/173481[39:12<17:13,51.47it/s] 74%|#######4  |128995/173481[42:00<14:21,51.62it/s] 75%|#######4  |129593/173481[42:12<14:10,51.62it/s] 80%|#######9  |138215/173481[45:00<11:25,51.42it/s] 80%|########  |138834/173481[45:12<11:13,51.42it/s] 85%|########5 |147715/173481[48:00<08:14,52.08it/s] 86%|########5 |148336/173481[48:12<08:02,52.08it/s] 91%|######### |157401/173481[51:00<05:03,52.93it/s] 91%|#########1|158020/173481[51:12<04:52,52.93it/s] 96%|#########6|166675/173481[54:00<02:10,52.21it/s] 96%|#########6|167260/173481[54:12<01:59,52.21it/s]100%|##########|173481/173481[56:12<00:00,51.44it/s]
[32m[0323 01:45:02 @base.py:257][0m Epoch 17 (global_step 6245316) finished, time:3372.34 sec.
[32m[0323 01:45:03 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-6245316.
[32m[0323 01:45:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,174.70it/s]
16
[32m[0323 01:46:53 @monitor.py:363][0m QueueInput/queue_size: 0.38465
[32m[0323 01:46:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.48
[32m[0323 01:46:53 @monitor.py:363][0m activation-summaries/output-rms: 0.025064
[32m[0323 01:46:53 @monitor.py:363][0m cross_entropy_loss: 2.7715
[32m[0323 01:46:53 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.7274
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0839
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33018
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31238
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29695
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29451
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 01:46:53 @monitor.py:363][0m train-error-top1: 0.68543
[32m[0323 01:46:53 @monitor.py:363][0m val-error-top1: 0.68946
[32m[0323 01:46:53 @monitor.py:363][0m val-utt-error: 0.23483
[32m[0323 01:46:53 @monitor.py:363][0m validation_cost: 2.8159
[32m[0323 01:46:53 @monitor.py:363][0m wd_cost: 1.5742e-08
[32m[0323 01:46:53 @group.py:42][0m Callbacks took 110.717 sec in total. InferenceRunner: 107.758sec
[32m[0323 01:46:53 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10730/173481[03:00<45:30,59.61it/s]  7%|6         |11283/173481[03:10<45:20,59.61it/s] 12%|#2        |21558/173481[06:00<42:17,59.88it/s] 13%|#2        |22113/173481[06:10<42:07,59.88it/s] 18%|#7        |30948/173481[09:00<42:36,55.76it/s] 18%|#8        |31505/173481[09:10<42:26,55.76it/s] 23%|##3       |40054/173481[12:00<41:55,53.04it/s] 23%|##3       |40610/173481[12:10<41:45,53.04it/s] 30%|###       |52753/173481[15:00<33:13,60.55it/s] 31%|###       |53608/173481[15:10<32:59,60.55it/s] 39%|###9      |68509/173481[18:00<24:26,71.58it/s] 40%|###9      |69132/173481[18:10<24:17,71.58it/s] 45%|####5     |78619/173481[21:00<25:07,62.94it/s] 46%|####5     |79193/173481[21:11<24:57,62.94it/s] 51%|#####     |87904/173481[24:00<25:09,56.69it/s] 51%|#####1    |88525/173481[24:11<24:58,56.69it/s] 56%|#####6    |97225/173481[27:00<23:28,54.13it/s] 56%|#####6    |97841/173481[27:11<23:17,54.13it/s] 61%|######1   |106644/173481[30:00<20:56,53.21it/s] 62%|######1   |107306/173481[30:11<20:43,53.21it/s] 67%|######7   |116615/173481[33:00<17:27,54.28it/s] 68%|######7   |117255/173481[33:11<17:15,54.28it/s] 73%|#######2  |126480/173481[36:00<14:21,54.54it/s] 73%|#######3  |127138/173481[36:11<14:09,54.54it/s] 79%|#######9  |137239/173481[39:00<10:35,57.04it/s] 80%|#######9  |137953/173481[39:12<10:22,57.04it/s] 85%|########5 |147859/173481[42:00<07:21,58.00it/s] 86%|########5 |148544/173481[42:12<07:09,58.00it/s] 91%|#########1|158574/173481[45:00<04:13,58.75it/s] 92%|#########1|159262/173481[45:12<04:02,58.75it/s] 98%|#########7|169193/173481[48:00<01:12,58.87it/s] 98%|#########7|169923/173481[48:12<01:00,58.87it/s]100%|##########|173481/173481[49:13<00:00,58.75it/s]
[32m[0323 02:36:06 @base.py:257][0m Epoch 18 (global_step 6418797) finished, time:2953.02 sec.
[32m[0323 02:36:07 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.57it/s]
17
[32m[0323 02:37:59 @monitor.py:363][0m QueueInput/queue_size: 0.21315
[32m[0323 02:37:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.728
[32m[0323 02:37:59 @monitor.py:363][0m activation-summaries/output-rms: 0.025674
[32m[0323 02:37:59 @monitor.py:363][0m cross_entropy_loss: 2.7655
[32m[0323 02:37:59 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72702
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0839
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3302
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31239
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29696
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29451
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 02:37:59 @monitor.py:363][0m train-error-top1: 0.67769
[32m[0323 02:37:59 @monitor.py:363][0m val-error-top1: 0.68843
[32m[0323 02:37:59 @monitor.py:363][0m val-utt-error: 0.23478
[32m[0323 02:37:59 @monitor.py:363][0m validation_cost: 2.812
[32m[0323 02:37:59 @monitor.py:363][0m wd_cost: 1.5737e-08
[32m[0323 02:37:59 @group.py:42][0m Callbacks took 113.021 sec in total. InferenceRunner: 112.340sec
[32m[0323 02:37:59 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17463/173481[03:00<26:48,97.01it/s] 10%|#         |18198/173481[03:10<26:40,97.01it/s] 17%|#7        |29508/173481[06:00<30:17,79.20it/s] 17%|#7        |30210/173481[06:10<30:08,79.20it/s] 24%|##4       |41776/173481[09:00<29:57,73.26it/s] 24%|##4       |42457/173481[09:10<29:48,73.26it/s] 31%|###       |53703/173481[12:00<28:41,69.58it/s] 31%|###1      |54376/173481[12:10<28:31,69.58it/s] 38%|###7      |65107/173481[15:00<27:14,66.32it/s] 38%|###7      |65822/173481[15:10<27:03,66.32it/s] 44%|####4     |76648/173481[18:00<24:45,65.19it/s] 45%|####4     |77262/173481[18:10<24:35,65.19it/s] 51%|#####     |87978/173481[21:00<22:14,64.05it/s] 51%|#####1    |88682/173481[21:11<22:03,64.05it/s] 57%|#####7    |99611/173481[24:00<19:08,64.34it/s] 58%|#####7    |100287/173481[24:11<18:57,64.34it/s] 64%|######3   |110780/173481[27:00<16:32,63.17it/s] 64%|######4   |111542/173481[27:11<16:20,63.17it/s] 71%|#######   |122378/173481[30:00<13:21,63.79it/s] 71%|#######   |123162/173481[30:11<13:08,63.79it/s] 77%|#######7  |134008/173481[33:00<10:14,64.20it/s] 78%|#######7  |134755/173481[33:11<10:03,64.20it/s] 84%|########3 |145288/173481[36:00<07:24,63.42it/s] 84%|########4 |146018/173481[36:11<07:13,63.42it/s] 90%|######### |156828/173481[39:00<04:21,63.76it/s] 91%|######### |157622/173481[39:12<04:08,63.76it/s] 96%|#########6|167173/173481[42:00<01:44,60.45it/s] 97%|#########6|167887/173481[42:12<01:32,60.45it/s]100%|##########|173481/173481[43:50<00:00,65.95it/s]
[32m[0323 03:21:50 @base.py:257][0m Epoch 19 (global_step 6592278) finished, time:2630.42 sec.
[32m[0323 03:21:50 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-6592278.
[32m[0323 03:21:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.80it/s]
18
[32m[0323 03:23:50 @monitor.py:363][0m QueueInput/queue_size: 0.53768
[32m[0323 03:23:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.964
[32m[0323 03:23:50 @monitor.py:363][0m activation-summaries/output-rms: 0.02504
[32m[0323 03:23:50 @monitor.py:363][0m cross_entropy_loss: 2.8358
[32m[0323 03:23:50 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72664
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.0839
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33021
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3124
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29697
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29452
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 03:23:50 @monitor.py:363][0m train-error-top1: 0.6937
[32m[0323 03:23:50 @monitor.py:363][0m val-error-top1: 0.68766
[32m[0323 03:23:50 @monitor.py:363][0m val-utt-error: 0.23441
[32m[0323 03:23:50 @monitor.py:363][0m validation_cost: 2.8076
[32m[0323 03:23:50 @monitor.py:363][0m wd_cost: 1.5732e-08
[32m[0323 03:23:50 @group.py:42][0m Callbacks took 120.605 sec in total. InferenceRunner: 118.543sec
[32m[0323 03:23:50 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17289/173481[03:00<27:06,96.05it/s] 11%|#         |18238/173481[03:10<26:56,96.05it/s] 16%|#6        |28227/173481[06:00<32:31,74.43it/s] 17%|#6        |28801/173481[06:10<32:23,74.43it/s] 23%|##2       |39062/173481[09:00<33:39,66.55it/s] 23%|##2       |39729/173481[09:10<33:29,66.55it/s] 29%|##9       |50431/173481[12:00<31:38,64.81it/s] 29%|##9       |51046/173481[12:10<31:29,64.81it/s] 35%|###5      |61231/173481[15:00<30:01,62.31it/s] 36%|###5      |61934/173481[15:10<29:50,62.31it/s] 42%|####1     |72427/173481[18:00<27:03,62.25it/s] 42%|####2     |73131/173481[18:10<26:52,62.25it/s] 48%|####8     |83931/173481[21:00<23:39,63.07it/s] 49%|####8     |84644/173481[21:11<23:28,63.07it/s] 55%|#####4    |94702/173481[24:00<21:22,61.40it/s] 55%|#####4    |95335/173481[24:11<21:12,61.40it/s] 62%|######1   |106847/173481[27:00<17:16,64.29it/s] 62%|######2   |107686/173481[27:11<17:03,64.29it/s] 69%|######9   |120326/173481[30:00<12:48,69.18it/s] 70%|######9   |121266/173481[30:11<12:34,69.18it/s] 78%|#######7  |134700/173481[33:00<08:43,74.14it/s] 78%|#######8  |135497/173481[33:11<08:32,74.14it/s] 85%|########4 |147357/173481[36:00<06:01,72.18it/s] 85%|########5 |148277/173481[36:11<05:49,72.18it/s] 92%|#########1|159554/173481[39:00<03:19,69.90it/s] 92%|#########2|160258/173481[39:12<03:09,69.90it/s] 99%|#########9|172123/173481[42:00<00:19,69.86it/s]100%|#########9|173087/173481[42:12<00:05,69.86it/s]100%|##########|173481/173481[42:17<00:00,68.37it/s]
[32m[0323 04:06:07 @base.py:257][0m Epoch 20 (global_step 6765759) finished, time:2537.20 sec.
[32m[0323 04:06:08 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-6765759.
[32m[0323 04:06:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.83it/s]
19
[32m[0323 04:07:54 @monitor.py:363][0m QueueInput/queue_size: 0.44326
[32m[0323 04:07:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.596
[32m[0323 04:07:54 @monitor.py:363][0m activation-summaries/output-rms: 0.026291
[32m[0323 04:07:54 @monitor.py:363][0m cross_entropy_loss: 2.726
[32m[0323 04:07:54 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72623
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3124
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29697
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29452
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 04:07:54 @monitor.py:363][0m train-error-top1: 0.67447
[32m[0323 04:07:54 @monitor.py:363][0m val-error-top1: 0.68752
[32m[0323 04:07:54 @monitor.py:363][0m val-utt-error: 0.23536
[32m[0323 04:07:54 @monitor.py:363][0m validation_cost: 2.8085
[32m[0323 04:07:54 @monitor.py:363][0m wd_cost: 3.1452e-09
[32m[0323 04:07:54 @group.py:42][0m Callbacks took 106.539 sec in total. InferenceRunner: 104.680sec
[32m[0323 04:07:54 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14849/173481[03:00<32:02,82.49it/s]  9%|9         |15722/173481[03:10<31:52,82.49it/s] 18%|#7        |31101/173481[06:00<27:31,86.21it/s] 18%|#8        |32059/173481[06:10<27:20,86.21it/s] 28%|##7       |47982/173481[09:00<23:16,89.84it/s] 28%|##8       |48966/173481[09:10<23:06,89.84it/s] 35%|###4      |60025/173481[12:00<24:39,76.69it/s] 35%|###4      |60661/173481[12:10<24:31,76.69it/s] 41%|####      |70816/173481[15:00<25:25,67.28it/s] 41%|####1     |71430/173481[15:10<25:16,67.28it/s] 47%|####6     |81345/173481[18:00<24:32,62.58it/s] 47%|####7     |82015/173481[18:10<24:21,62.58it/s] 53%|#####3    |92016/173481[21:00<22:18,60.89it/s] 53%|#####3    |92666/173481[21:11<22:07,60.89it/s] 59%|#####9    |102716/173481[24:00<19:36,60.15it/s] 60%|#####9    |103377/173481[24:11<19:25,60.15it/s] 65%|######5   |113405/173481[27:00<16:45,59.76it/s] 66%|######5   |114085/173481[27:11<16:33,59.76it/s] 71%|#######1  |124034/173481[30:00<13:52,59.40it/s] 72%|#######1  |124765/173481[30:11<13:40,59.40it/s] 78%|#######7  |135001/173481[33:00<10:39,60.15it/s] 78%|#######8  |135704/173481[33:11<10:28,60.15it/s] 84%|########4 |146140/173481[36:00<07:28,61.00it/s] 85%|########4 |146865/173481[36:11<07:16,61.00it/s] 90%|######### |156326/173481[39:00<04:52,58.70it/s] 90%|######### |156995/173481[39:12<04:40,58.70it/s] 96%|#########6|166632/173481[42:00<01:58,57.97it/s] 96%|#########6|167355/173481[42:12<01:45,57.97it/s]100%|##########|173481/173481[43:56<00:00,65.80it/s]
[32m[0323 04:51:51 @base.py:257][0m Epoch 21 (global_step 6939240) finished, time:2636.69 sec.
[32m[0323 04:51:51 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-6939240.
[32m[0323 04:51:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.48it/s]
20
[32m[0323 04:53:51 @monitor.py:363][0m QueueInput/queue_size: 0.31554
[32m[0323 04:53:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.627
[32m[0323 04:53:51 @monitor.py:363][0m activation-summaries/output-rms: 0.026327
[32m[0323 04:53:51 @monitor.py:363][0m cross_entropy_loss: 2.7485
[32m[0323 04:53:51 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72583
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3124
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29698
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29452
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 04:53:51 @monitor.py:363][0m train-error-top1: 0.67494
[32m[0323 04:53:51 @monitor.py:363][0m val-error-top1: 0.6866
[32m[0323 04:53:51 @monitor.py:363][0m val-utt-error: 0.23372
[32m[0323 04:53:51 @monitor.py:363][0m validation_cost: 2.8042
[32m[0323 04:53:51 @monitor.py:363][0m wd_cost: 3.144e-09
[32m[0323 04:53:51 @group.py:42][0m Callbacks took 120.606 sec in total. InferenceRunner: 118.779sec
[32m[0323 04:53:51 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17329/173481[03:00<27:02,96.27it/s] 11%|#         |18272/173481[03:10<26:52,96.27it/s] 17%|#6        |28855/173481[06:00<31:20,76.90it/s] 17%|#7        |29509/173481[06:10<31:12,76.90it/s] 23%|##2       |39131/173481[09:00<34:10,65.53it/s] 23%|##2       |39719/173481[09:10<34:01,65.53it/s] 28%|##8       |48705/173481[12:00<35:25,58.71it/s] 28%|##8       |49294/173481[12:10<35:15,58.71it/s] 34%|###4      |59200/173481[15:00<32:33,58.50it/s] 35%|###4      |59864/173481[15:10<32:22,58.50it/s] 40%|####      |69867/173481[18:00<29:19,58.88it/s] 41%|####      |70526/173481[18:10<29:08,58.88it/s] 47%|####6     |80735/173481[21:00<25:55,59.62it/s] 47%|####6     |81396/173481[21:11<25:44,59.62it/s] 53%|#####2    |91535/173481[24:00<22:50,59.80it/s] 53%|#####3    |92184/173481[24:11<22:39,59.80it/s] 59%|#####8    |102189/173481[27:00<19:58,59.49it/s] 59%|#####9    |102896/173481[27:11<19:46,59.49it/s] 65%|######5   |112990/173481[30:00<16:52,59.75it/s] 65%|######5   |113627/173481[30:11<16:41,59.75it/s] 71%|#######   |123123/173481[33:00<14:28,57.97it/s] 71%|#######1  |123729/173481[33:11<14:18,57.97it/s] 77%|#######6  |133121/173481[36:00<11:51,56.73it/s] 77%|#######7  |133744/173481[36:11<11:40,56.73it/s] 83%|########2 |143622/173481[39:00<08:39,57.52it/s] 83%|########3 |144352/173481[39:12<08:26,57.52it/s] 89%|########8 |154199/173481[42:00<05:31,58.13it/s] 89%|########9 |154849/173481[42:12<05:20,58.13it/s] 95%|#########4|164245/173481[45:00<02:42,56.94it/s] 95%|#########5|164891/173481[45:12<02:30,56.94it/s]100%|##########|173481/173481[47:42<00:00,60.61it/s]
[32m[0323 05:41:34 @base.py:257][0m Epoch 22 (global_step 7112721) finished, time:2862.30 sec.
[32m[0323 05:41:34 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-7112721.
[32m[0323 05:41:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.75it/s]
21
[32m[0323 05:43:33 @monitor.py:363][0m QueueInput/queue_size: 0.37442
[32m[0323 05:43:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.358
[32m[0323 05:43:33 @monitor.py:363][0m activation-summaries/output-rms: 0.02528
[32m[0323 05:43:33 @monitor.py:363][0m cross_entropy_loss: 2.7565
[32m[0323 05:43:33 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72547
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31241
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29698
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29451
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 05:43:33 @monitor.py:363][0m train-error-top1: 0.68151
[32m[0323 05:43:33 @monitor.py:363][0m val-error-top1: 0.68755
[32m[0323 05:43:33 @monitor.py:363][0m val-utt-error: 0.23398
[32m[0323 05:43:33 @monitor.py:363][0m validation_cost: 2.8073
[32m[0323 05:43:33 @monitor.py:363][0m wd_cost: 3.1429e-09
[32m[0323 05:43:33 @group.py:42][0m Callbacks took 119.830 sec in total. InferenceRunner: 117.838sec
[32m[0323 05:43:33 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17049/173481[03:00<27:31,94.72it/s] 10%|#         |17973/173481[03:10<27:21,94.72it/s] 17%|#6        |29474/173481[06:00<30:03,79.85it/s] 17%|#7        |30071/173481[06:10<29:55,79.85it/s] 23%|##2       |39576/173481[09:00<33:51,65.92it/s] 23%|##3       |40130/173481[09:10<33:43,65.92it/s] 30%|###       |52634/173481[12:00<29:09,69.07it/s] 31%|###       |53462/173481[12:10<28:57,69.07it/s] 39%|###9      |68358/173481[15:00<22:42,77.14it/s] 40%|###9      |69318/173481[15:10<22:30,77.14it/s] 46%|####5     |79429/173481[18:00<22:54,68.43it/s] 46%|####6     |80093/173481[18:10<22:44,68.43it/s] 52%|#####2    |90644/173481[21:00<21:10,65.22it/s] 53%|#####2    |91371/173481[21:11<20:58,65.22it/s] 59%|#####8    |101644/173481[24:00<18:58,63.09it/s] 59%|#####8    |102303/173481[24:11<18:48,63.09it/s] 65%|######4   |112749/173481[27:00<16:13,62.38it/s] 65%|######5   |113480/173481[27:11<16:01,62.38it/s] 71%|#######1  |123662/173481[30:00<13:30,61.49it/s] 72%|#######1  |124381/173481[30:11<13:18,61.49it/s] 78%|#######7  |134734/173481[33:00<10:30,61.50it/s] 78%|#######8  |135413/173481[33:11<10:19,61.50it/s] 84%|########4 |145729/173481[36:00<07:32,61.28it/s] 84%|########4 |146458/173481[36:11<07:20,61.28it/s] 90%|######### |156728/173481[39:00<04:33,61.19it/s] 91%|######### |157483/173481[39:12<04:21,61.19it/s] 97%|#########6|167889/173481[42:00<01:30,61.59it/s] 97%|#########7|168645/173481[42:12<01:18,61.59it/s]100%|##########|173481/173481[43:32<00:00,66.41it/s]
[32m[0323 06:27:06 @base.py:257][0m Epoch 23 (global_step 7286202) finished, time:2612.10 sec.
[32m[0323 06:27:06 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-7286202.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.58it/s]
22
[32m[0323 06:29:03 @monitor.py:363][0m QueueInput/queue_size: 0.64384
[32m[0323 06:29:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.531
[32m[0323 06:29:03 @monitor.py:363][0m activation-summaries/output-rms: 0.025858
[32m[0323 06:29:03 @monitor.py:363][0m cross_entropy_loss: 2.7581
[32m[0323 06:29:03 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.7253
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31241
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29698
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29451
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 06:29:03 @monitor.py:363][0m train-error-top1: 0.6837
[32m[0323 06:29:03 @monitor.py:363][0m val-error-top1: 0.68679
[32m[0323 06:29:03 @monitor.py:363][0m val-utt-error: 0.23148
[32m[0323 06:29:03 @monitor.py:363][0m validation_cost: 2.8026
[32m[0323 06:29:03 @monitor.py:363][0m wd_cost: 6.2848e-10
[32m[0323 06:29:03 @group.py:42][0m Callbacks took 117.871 sec in total. InferenceRunner: 117.226sec
[32m[0323 06:29:03 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |18180/173481[03:00<25:37,101.00it/s] 11%|#         |18887/173481[03:10<25:30,101.00it/s] 17%|#7        |30328/173481[06:00<29:29,80.91it/s]  18%|#7        |31053/173481[06:10<29:20,80.91it/s] 25%|##4       |43268/173481[09:00<28:30,76.13it/s] 25%|##5       |43987/173481[09:10<28:20,76.13it/s] 32%|###2      |56190/173481[12:00<26:27,73.90it/s] 33%|###2      |56847/173481[12:10<26:18,73.90it/s] 40%|###9      |69053/173481[15:00<23:57,72.65it/s] 40%|####      |69799/173481[15:10<23:47,72.65it/s] 47%|####7     |82098/173481[18:00<20:59,72.55it/s] 48%|####7     |82822/173481[18:10<20:49,72.55it/s] 55%|#####4    |95394/173481[21:00<17:46,73.20it/s] 55%|#####5    |96187/173481[21:11<17:35,73.20it/s] 63%|######2   |108797/173481[24:00<14:36,73.83it/s] 63%|######3   |109537/173481[24:11<14:26,73.83it/s] 69%|######9   |120347/173481[27:00<12:53,68.66it/s] 70%|######9   |121200/173481[27:11<12:41,68.66it/s] 76%|#######6  |131936/173481[30:00<10:25,66.45it/s] 76%|#######6  |132650/173481[30:11<10:14,66.45it/s] 82%|########2 |142958/173481[33:00<07:58,63.73it/s] 83%|########2 |143643/173481[33:11<07:48,63.73it/s] 89%|########8 |154173/173481[36:00<05:06,63.01it/s] 89%|########9 |154917/173481[36:11<04:54,63.01it/s] 95%|#########5|165508/173481[39:00<02:06,62.98it/s] 96%|#########5|166182/173481[39:12<01:55,62.98it/s]100%|##########|173481/173481[41:24<00:00,69.82it/s]
[32m[0323 07:10:28 @base.py:257][0m Epoch 24 (global_step 7459683) finished, time:2484.83 sec.
[32m[0323 07:10:29 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-7459683.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.59it/s]
23
[32m[0323 07:12:28 @monitor.py:363][0m QueueInput/queue_size: 0.4123
[32m[0323 07:12:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.694
[32m[0323 07:12:28 @monitor.py:363][0m activation-summaries/output-rms: 0.025142
[32m[0323 07:12:28 @monitor.py:363][0m cross_entropy_loss: 2.8431
[32m[0323 07:12:28 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72515
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31241
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29698
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.29451
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 07:12:28 @monitor.py:363][0m train-error-top1: 0.6899
[32m[0323 07:12:28 @monitor.py:363][0m val-error-top1: 0.68635
[32m[0323 07:12:28 @monitor.py:363][0m val-utt-error: 0.2318
[32m[0323 07:12:28 @monitor.py:363][0m validation_cost: 2.8013
[32m[0323 07:12:28 @monitor.py:363][0m wd_cost: 6.2838e-10
[32m[0323 07:12:28 @group.py:42][0m Callbacks took 120.092 sec in total. InferenceRunner: 119.449sec
[32m[0323 07:12:28 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17062/173481[03:00<27:30,94.78it/s] 10%|#         |18019/173481[03:10<27:20,94.78it/s] 17%|#7        |29512/173481[06:00<30:00,79.97it/s] 17%|#7        |30173/173481[06:10<29:52,79.97it/s] 24%|##3       |41105/173481[09:00<30:55,71.35it/s] 24%|##4       |41920/173481[09:10<30:43,71.35it/s] 30%|###       |52624/173481[12:00<29:51,67.47it/s] 31%|###       |53314/173481[12:10<29:41,67.47it/s] 37%|###6      |64187/173481[15:00<27:40,65.81it/s] 37%|###7      |64845/173481[15:10<27:30,65.81it/s] 43%|####3     |75207/173481[18:00<25:49,63.43it/s] 44%|####3     |75806/173481[18:10<25:39,63.43it/s] 50%|####9     |86122/173481[21:00<23:29,61.99it/s] 50%|#####     |86772/173481[21:11<23:18,61.99it/s] 57%|#####7    |98895/173481[24:00<18:47,66.17it/s] 58%|#####7    |99841/173481[24:11<18:32,66.17it/s] 66%|######6   |115171/173481[27:00<12:43,76.42it/s] 67%|######6   |116027/173481[27:11<12:31,76.42it/s] 74%|#######3  |127705/173481[30:00<10:28,72.87it/s] 74%|#######4  |128609/173481[30:11<10:15,72.87it/s] 80%|########  |139598/173481[33:00<08:08,69.30it/s] 81%|########  |140316/173481[33:11<07:58,69.30it/s] 87%|########6 |150912/173481[36:00<05:42,65.92it/s] 87%|########7 |151639/173481[36:11<05:31,65.92it/s] 93%|#########3|161775/173481[39:00<03:05,63.01it/s] 94%|#########3|162511/173481[39:12<02:54,63.01it/s]100%|#########9|172807/173481[42:00<00:10,62.13it/s]100%|##########|173481/173481[42:11<00:00,68.53it/s]
[32m[0323 07:54:40 @base.py:257][0m Epoch 25 (global_step 7633164) finished, time:2531.64 sec.
[32m[0323 07:54:41 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-7633164.
[32m[0323 07:54:42 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.48it/s]
24
[32m[0323 07:56:47 @monitor.py:363][0m QueueInput/queue_size: 0.54438
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.41
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/output-rms: 0.026183
[32m[0323 07:56:47 @monitor.py:363][0m cross_entropy_loss: 2.7226
[32m[0323 07:56:47 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72505
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31241
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29698
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2945
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 07:56:47 @monitor.py:363][0m train-error-top1: 0.66862
[32m[0323 07:56:47 @monitor.py:363][0m val-error-top1: 0.68663
[32m[0323 07:56:47 @monitor.py:363][0m val-utt-error: 0.23069
[32m[0323 07:56:47 @monitor.py:363][0m validation_cost: 2.8038
[32m[0323 07:56:47 @monitor.py:363][0m wd_cost: 6.2832e-10
[32m[0323 07:56:47 @group.py:42][0m Callbacks took 127.217 sec in total. InferenceRunner: 125.098sec
[32m[0323 07:56:47 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12876/173481[03:00<37:25,71.53it/s]  8%|7         |13523/173481[03:10<37:16,71.53it/s] 14%|#3        |24211/173481[06:00<37:08,66.97it/s] 14%|#4        |24860/173481[06:10<36:59,66.97it/s] 20%|##        |35411/173481[09:00<35:40,64.51it/s] 21%|##        |36048/173481[09:10<35:30,64.51it/s] 27%|##6       |46421/173481[12:00<33:43,62.78it/s] 27%|##7       |47045/173481[12:10<33:33,62.78it/s] 33%|###2      |57061/173481[15:00<31:52,60.89it/s] 33%|###3      |57708/173481[15:10<31:41,60.89it/s] 39%|###9      |68141/173481[18:00<28:40,61.22it/s] 40%|###9      |68790/173481[18:10<28:30,61.22it/s] 45%|####5     |78791/173481[21:00<26:13,60.17it/s] 46%|####5     |79435/173481[21:11<26:03,60.17it/s] 52%|#####1    |89371/173481[24:00<23:34,59.46it/s] 52%|#####1    |90020/173481[24:11<23:23,59.46it/s] 58%|#####7    |99801/173481[27:00<20:55,58.69it/s] 58%|#####7    |100471/173481[27:11<20:43,58.69it/s] 64%|######3   |110441/173481[30:00<17:50,58.90it/s] 64%|######4   |111085/173481[30:11<17:39,58.90it/s] 70%|######9   |120813/173481[33:00<15:04,58.25it/s] 70%|#######   |121490/173481[33:11<14:52,58.25it/s] 76%|#######5  |131517/173481[36:00<11:53,58.85it/s] 76%|#######6  |132180/173481[36:11<11:41,58.85it/s] 82%|########1 |142211/173481[39:00<08:48,59.13it/s] 82%|########2 |142926/173481[39:12<08:36,59.13it/s] 88%|########8 |152767/173481[42:00<05:51,58.89it/s] 88%|########8 |153491/173481[42:12<05:39,58.89it/s] 94%|#########4|163271/173481[45:00<02:54,58.61it/s] 95%|#########4|163970/173481[45:12<02:42,58.61it/s]100%|##########|173481/173481[47:55<00:00,60.34it/s]
[32m[0323 08:44:42 @base.py:257][0m Epoch 26 (global_step 7806645) finished, time:2875.00 sec.
[32m[0323 08:44:43 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-7806645.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.64it/s]
25
[32m[0323 08:46:47 @monitor.py:363][0m QueueInput/queue_size: 0.40735
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.465
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/output-rms: 0.026243
[32m[0323 08:46:47 @monitor.py:363][0m cross_entropy_loss: 2.7514
[32m[0323 08:46:47 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72502
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31241
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29698
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2945
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 08:46:47 @monitor.py:363][0m train-error-top1: 0.67809
[32m[0323 08:46:47 @monitor.py:363][0m val-error-top1: 0.68602
[32m[0323 08:46:47 @monitor.py:363][0m val-utt-error: 0.23026
[32m[0323 08:46:47 @monitor.py:363][0m validation_cost: 2.8004
[32m[0323 08:46:47 @monitor.py:363][0m wd_cost: 1.2566e-10
[32m[0323 08:46:47 @group.py:42][0m Callbacks took 124.792 sec in total. InferenceRunner: 124.139sec
[32m[0323 08:46:47 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16846/173481[03:00<27:53,93.59it/s] 10%|#         |17805/173481[03:10<27:43,93.59it/s] 16%|#6        |27790/173481[06:00<32:56,73.70it/s] 16%|#6        |28354/173481[06:10<32:49,73.70it/s] 21%|##1       |37104/173481[09:00<37:23,60.80it/s] 22%|##1       |37640/173481[09:10<37:14,60.80it/s] 27%|##6       |46754/173481[12:00<37:04,56.98it/s] 27%|##7       |47330/173481[12:10<36:54,56.98it/s] 33%|###2      |57100/173481[15:00<33:53,57.23it/s] 33%|###3      |57769/173481[15:10<33:42,57.23it/s] 39%|###9      |68105/173481[18:00<29:42,59.12it/s] 40%|###9      |68764/173481[18:10<29:31,59.12it/s] 46%|####5     |79201/173481[21:00<26:02,60.35it/s] 46%|####6     |79874/173481[21:11<25:51,60.35it/s] 52%|#####2    |90515/173481[24:00<22:27,61.57it/s] 53%|#####2    |91204/173481[24:11<22:16,61.57it/s] 58%|#####8    |101420/173481[27:00<19:40,61.07it/s] 59%|#####8    |102092/173481[27:11<19:29,61.07it/s] 65%|######4   |112544/173481[30:00<16:31,61.43it/s] 65%|######5   |113249/173481[30:11<16:20,61.43it/s] 71%|#######1  |123427/173481[33:00<13:41,60.94it/s] 72%|#######1  |124129/173481[33:11<13:29,60.94it/s] 77%|#######7  |134307/173481[36:00<10:45,60.69it/s] 78%|#######7  |134979/173481[36:11<10:34,60.69it/s] 84%|########3 |145273/173481[39:00<07:43,60.81it/s] 84%|########4 |145929/173481[39:12<07:33,60.81it/s] 90%|######### |156140/173481[42:00<04:46,60.59it/s] 90%|######### |156925/173481[42:12<04:33,60.59it/s] 96%|#########6|167265/173481[45:00<01:41,61.19it/s] 97%|#########6|168014/173481[45:12<01:29,61.19it/s]100%|##########|173481/173481[46:39<00:00,61.96it/s]
[32m[0323 09:33:27 @base.py:257][0m Epoch 27 (global_step 7980126) finished, time:2799.75 sec.
[32m[0323 09:33:27 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-7980126.
[32m[0323 09:33:28 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.48it/s]
26
[32m[0323 09:35:26 @monitor.py:363][0m QueueInput/queue_size: 0.84476
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.275
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/output-rms: 0.025022
[32m[0323 09:35:26 @monitor.py:363][0m cross_entropy_loss: 2.7623
[32m[0323 09:35:26 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72499
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31241
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29698
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2945
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 09:35:26 @monitor.py:363][0m train-error-top1: 0.68687
[32m[0323 09:35:26 @monitor.py:363][0m val-error-top1: 0.68725
[32m[0323 09:35:26 @monitor.py:363][0m val-utt-error: 0.23095
[32m[0323 09:35:26 @monitor.py:363][0m validation_cost: 2.8059
[32m[0323 09:35:26 @monitor.py:363][0m wd_cost: 1.2566e-10
[32m[0323 09:35:26 @group.py:42][0m Callbacks took 118.864 sec in total. InferenceRunner: 117.297sec
[32m[0323 09:35:26 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17096/173481[03:00<27:26,94.97it/s] 10%|#         |18048/173481[03:10<27:16,94.97it/s] 17%|#7        |30119/173481[06:00<29:05,82.13it/s] 18%|#7        |30753/173481[06:10<28:57,82.13it/s] 24%|##3       |41362/173481[09:00<31:01,70.96it/s] 24%|##4       |42026/173481[09:10<30:52,70.96it/s] 35%|###4      |59864/173481[12:00<22:33,83.96it/s] 35%|###5      |61097/173481[12:10<22:18,83.96it/s] 45%|####5     |78578/173481[15:00<17:01,92.89it/s] 46%|####5     |79604/173481[15:10<16:50,92.89it/s] 55%|#####5    |96067/173481[18:00<13:35,94.98it/s] 56%|#####5    |97128/173481[18:10<13:23,94.98it/s] 65%|######5   |113296/173481[21:00<10:31,95.34it/s] 66%|######5   |114346/173481[21:11<10:20,95.34it/s] 74%|#######4  |129099/173481[24:00<08:05,91.41it/s] 75%|#######4  |129817/173481[24:11<07:57,91.41it/s] 81%|########1 |140637/173481[27:00<07:15,75.36it/s] 81%|########1 |141369/173481[27:11<07:06,75.36it/s] 88%|########7 |152049/173481[30:00<05:11,68.86it/s] 88%|########8 |152793/173481[30:11<05:00,68.86it/s] 94%|#########4|163621/173481[33:00<02:28,66.50it/s] 95%|#########4|164375/173481[33:11<02:16,66.50it/s]100%|##########|173481/173481[35:22<00:00,81.74it/s]
[32m[0323 10:10:48 @base.py:257][0m Epoch 28 (global_step 8153607) finished, time:2122.47 sec.
[32m[0323 10:10:49 @saver.py:84][0m Model saved to train_log/fcn2_w_4_a_4_quant_ends_True_preload/model-8153607.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.67it/s]
27
[32m[0323 10:12:42 @monitor.py:363][0m QueueInput/queue_size: 0.6445
[32m[0323 10:12:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 21.406
[32m[0323 10:12:42 @monitor.py:363][0m activation-summaries/output-rms: 0.026175
[32m[0323 10:12:42 @monitor.py:363][0m cross_entropy_loss: 2.752
[32m[0323 10:12:42 @monitor.py:363][0m lr: 7.6294e-09
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.72498
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.084
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33022
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.060369
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31241
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.065467
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29698
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.066457
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2945
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.06414
[32m[0323 10:12:42 @monitor.py:363][0m train-error-top1: 0.68018
[32m[0323 10:12:42 @monitor.py:363][0m val-error-top1: 0.68635
[32m[0323 10:12:42 @monitor.py:363][0m val-utt-error: 0.22984
[32m[0323 10:12:42 @monitor.py:363][0m validation_cost: 2.7996
[32m[0323 10:12:42 @monitor.py:363][0m wd_cost: 1.2566e-10
[32m[0323 10:12:42 @group.py:42][0m Callbacks took 113.515 sec in total. InferenceRunner: 112.947sec
[32m[0323 10:12:42 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19366/173481[03:00<23:52,107.59it/s] 12%|#1        |20431/173481[03:10<23:42,107.59it/s] 22%|##2       |38692/173481[06:00<20:54,107.47it/s] 23%|##2       |39848/173481[06:10<20:43,107.47it/s] 34%|###3      |58257/173481[09:00<17:46,108.08it/s] 34%|###4      |59398/173481[09:10<17:35,108.08it/s] 43%|####2     |73967/173481[12:00<17:10,96.57it/s]  43%|####3     |74857/173481[12:10<17:01,96.57it/s] 51%|#####     |88107/173481[15:00<16:25,86.64it/s] 51%|#####1    |88986/173481[15:10<16:15,86.64it/s] 59%|#####8    |102183/173481[18:00<14:27,82.20it/s] 59%|#####9    |103066/173481[18:11<14:16,82.20it/s] 66%|######6   |114878/173481[21:00<12:51,75.92it/s] 67%|######6   |115612/173481[21:11<12:42,75.92it/s] 73%|#######2  |126539/173481[24:00<11:11,69.91it/s] 73%|#######3  |127273/173481[24:11<11:00,69.91it/s] 80%|#######9  |138565/173481[27:00<08:31,68.32it/s] 80%|########  |139352/173481[27:11<08:19,68.32it/s]srun: got SIGCONT
slurmstepd: *** JOB 82368 ON sls-titanx-1 CANCELLED AT 2018-03-23T10:41:19 ***
srun: forcing job termination
slurmstepd: *** STEP 82368.0 ON sls-titanx-1 CANCELLED AT 2018-03-23T10:41:19 ***
