sls-sm-16 0
SLURM_JOBID=82583
SLURM_TASKID=2
[32m[0323 10:45:59 @logger.py:67][0m Existing log file 'train_log/lcn_w_4_a_32_quant_ends_False/log.log' backuped to 'train_log/lcn_w_4_a_32_quant_ends_False/log.log.0323-104559'
[32m[0323 10:45:59 @logger.py:74][0m Argv: drf_run.py --model_name=lcn --bitw=4 --bita=32 --quant_ends=False
[32m[0323 10:46:18 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 10:46:18 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 10:46:18 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 10:46:18 @drf_run.py:166][0m Using host: sls-sm-16
[32m[0323 10:46:18 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 10:46:18 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 10:46:18 @drf_run.py:188][0m Using GPU: 0
[32m[0323 10:46:18 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 10:46:18 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 10:46:18 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 10:46:18 @registry.py:122][0m conv0a input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0a output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0b input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0b output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0c input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:18 @registry.py:130][0m conv0c output: [None, 1, 1, 25]
[32m[0323 10:46:18 @registry.py:122][0m conv0d input: [None, 10, 10, 1]
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:18 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:18 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0d output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0e input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0e output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0f input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0f output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0g input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0g output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0h input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0h output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0i input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0i output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m conv0j input: [None, 10, 10, 1]
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:19 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m conv0j output: [None, 1, 1, 25]
[32m[0323 10:46:19 @registry.py:122][0m linear1 input: [None, 10, 1, 25]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:19 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:19 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:19 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 10:46:19 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 10:46:19 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:19 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:19 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 10:46:19 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:19 @regularize.py:81][0m regularize_cost() found 14 tensors.
[32m[0323 10:46:19 @regularize.py:18][0m Applying regularizer for conv0a/W:0, conv0b/W:0, conv0c/W:0, conv0d/W:0, conv0e/W:0, conv0f/W:0, conv0g/W:0, conv0h/W:0, conv0i/W:0, conv0j/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 10:46:19 @drf_run.py:123][0m Parameter count: {'mults': 2762388, 'weights': 287643}
[32m[0323 10:46:20 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape              dim
------------------  ---------------  -----
conv0a/W:0          [10, 10, 1, 25]   2500
conv0a/b:0          [25]                25
conv0a/bn/beta:0    [25]                25
conv0a/bn/gamma:0   [25]                25
conv0b/W:0          [10, 10, 1, 25]   2500
conv0b/b:0          [25]                25
conv0b/bn/beta:0    [25]                25
conv0b/bn/gamma:0   [25]                25
conv0c/W:0          [10, 10, 1, 25]   2500
conv0c/b:0          [25]                25
conv0c/bn/beta:0    [25]                25
conv0c/bn/gamma:0   [25]                25
conv0d/W:0          [10, 10, 1, 25]   2500
conv0d/b:0          [25]                25
conv0d/bn/beta:0    [25]                25
conv0d/bn/gamma:0   [25]                25
conv0e/W:0          [10, 10, 1, 25]   2500
conv0e/b:0          [25]                25
conv0e/bn/beta:0    [25]                25
conv0e/bn/gamma:0   [25]                25
conv0f/W:0          [10, 10, 1, 25]   2500
conv0f/b:0          [25]                25
conv0f/bn/beta:0    [25]                25
conv0f/bn/gamma:0   [25]                25
conv0g/W:0          [10, 10, 1, 25]   2500
conv0g/b:0          [25]                25
conv0g/bn/beta:0    [25]                25
conv0g/bn/gamma:0   [25]                25
conv0h/W:0          [10, 10, 1, 25]   2500
conv0h/b:0          [25]                25
conv0h/bn/beta:0    [25]                25
conv0h/bn/gamma:0   [25]                25
conv0i/W:0          [10, 10, 1, 25]   2500
conv0i/b:0          [25]                25
conv0i/bn/beta:0    [25]                25
conv0i/bn/gamma:0   [25]                25
conv0j/W:0          [10, 10, 1, 25]   2500
conv0j/b:0          [25]                25
conv0j/bn/beta:0    [25]                25
conv0j/bn/gamma:0   [25]                25
linear1/W:0         [250, 256]       64000
linear1/b:0         [256]              256
linear1/bn/beta:0   [256]              256
linear1/bn/gamma:0  [256]              256
linear2/W:0         [256, 256]       65536
linear2/b:0         [256]              256
linear2/bn/beta:0   [256]              256
linear2/bn/gamma:0  [256]              256
linear3/W:0         [256, 256]       65536
linear3/b:0         [256]              256
linear3/bn/beta:0   [256]              256
linear3/bn/gamma:0  [256]              256
last_linear/W:0     [256, 255]       65280
last_linear/b:0     [255]              255[36m
Total #vars=54, #params=288661, size=1.10MB[0m
[32m[0323 10:46:20 @base.py:196][0m Setup callbacks graph ...
[32m[0323 10:46:21 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0a/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0a/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0a/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0b/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0b/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0b/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0c/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0c/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0c/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0d/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0d/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0d/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0e/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0e/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0e/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0f/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0f/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0f/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0g/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0g/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0g/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0h/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0h/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0h/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0i/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0i/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0i/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0j/W
[32m[0323 10:46:21 @drf_run.py:61][0m Not quantizing conv0j/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing conv0j/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:46:21 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:46:21 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:46:21 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:46:21 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:46:21 @drf_run.py:123][0m Parameter count: {'mults': 5524776, 'weights': 575286}
[32m[0323 10:46:21 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 10:46:21 @graph.py:90][0m Applying collection UPDATE_OPS of 26 ops.
[32m[0323 10:46:22 @base.py:212][0m Creating the session ...
2018-03-23 10:46:22.816850: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-23 10:46:26.197819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:02:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-03-23 10:46:26.197866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
[32m[0323 10:46:31 @base.py:220][0m Initializing the session ...
[32m[0323 10:46:31 @base.py:227][0m Graph Finalized.
[32m[0323 10:46:31 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 10:46:34 @monitor.py:251][0m Found existing JSON at train_log/lcn_w_4_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 10:46:34 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 10:46:34 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11798/173481[03:00<41:06,65.54it/s]  7%|7         |12478/173481[03:10<40:56,65.54it/s] 14%|#3        |23526/173481[06:00<38:14,65.35it/s] 14%|#3        |24155/173481[06:10<38:05,65.35it/s] 20%|#9        |34461/173481[09:00<36:48,62.96it/s] 20%|##        |35096/173481[09:10<36:37,62.96it/s] 26%|##6       |45382/173481[12:00<34:32,61.79it/s] 26%|##6       |45894/173481[12:10<34:24,61.79it/s] 32%|###2      |55851/173481[15:00<32:43,59.92it/s] 33%|###2      |56482/173481[15:10<32:32,59.92it/s] 38%|###7      |65178/173481[18:00<32:28,55.57it/s] 38%|###7      |65790/173481[18:10<32:17,55.57it/s] 43%|####3     |75216/173481[21:00<29:25,55.66it/s] 44%|####3     |75841/173481[21:11<29:14,55.66it/s] 49%|####9     |85452/173481[24:00<26:04,56.25it/s] 50%|####9     |86075/173481[24:11<25:53,56.25it/s] 55%|#####4    |94606/173481[27:00<24:36,53.42it/s] 55%|#####4    |95230/173481[27:11<24:24,53.42it/s] 61%|######    |105298/173481[30:00<20:12,56.25it/s] 61%|######1   |105995/173481[30:11<19:59,56.25it/s] 67%|######7   |116702/173481[33:00<15:52,59.59it/s] 68%|######7   |117422/173481[33:11<15:40,59.59it/s] 73%|#######3  |127249/173481[36:00<13:02,59.08it/s] 74%|#######3  |128123/173481[36:11<12:47,59.08it/s] 81%|########  |139774/173481[39:00<08:47,63.90it/s] 81%|########  |140492/173481[39:12<08:36,63.90it/s] 87%|########6 |150877/173481[42:00<06:00,62.77it/s] 87%|########7 |151597/173481[42:12<05:48,62.77it/s] 93%|#########2|161286/173481[45:00<03:22,60.19it/s] 93%|#########3|161890/173481[45:12<03:12,60.19it/s] 99%|#########8|171327/173481[48:00<00:37,57.90it/s] 99%|#########9|172249/173481[48:12<00:21,57.90it/s]100%|##########|173481/173481[48:29<00:00,59.63it/s]
[32m[0323 11:35:04 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2909.34 sec.
[32m[0323 11:35:04 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:22<00:00,131.86it/s]
0
[32m[0323 11:37:27 @monitor.py:363][0m QueueInput/queue_size: 0.96746
[32m[0323 11:37:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9074
[32m[0323 11:37:27 @monitor.py:363][0m activation-summaries/output-rms: 0.028785
[32m[0323 11:37:27 @monitor.py:363][0m cross_entropy_loss: 2.5838
[32m[0323 11:37:27 @monitor.py:363][0m lr: 0.001
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.18565
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 3.5369e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.15311
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.4878e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.17743
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 2.6325e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.14788
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 2.8885e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.17078
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 3.0081e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14739
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 2.6654e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.17895
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 3.2381e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14762
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.1567e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.18539
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 3.4627e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.15219
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 2.5928e-06
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13528
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.70755
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14508
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090673
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12291
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11651
[32m[0323 11:37:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 11:37:27 @monitor.py:363][0m train-error-top1: 0.63723
[32m[0323 11:37:27 @monitor.py:363][0m val-error-top1: 0.70076
[32m[0323 11:37:27 @monitor.py:363][0m val-utt-error: 0.39061
[32m[0323 11:37:27 @monitor.py:363][0m validation_cost: 2.916
[32m[0323 11:37:27 @monitor.py:363][0m wd_cost: 0.51058
[32m[0323 11:37:27 @group.py:42][0m Callbacks took 143.198 sec in total. InferenceRunner: 142.772sec
[32m[0323 11:37:27 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14180/173481[03:00<33:42,78.78it/s]  9%|8         |14984/173481[03:10<33:31,78.78it/s] 16%|#5        |27390/173481[06:00<32:04,75.91it/s] 16%|#6        |28217/173481[06:20<31:53,75.91it/s] 22%|##1       |38164/173481[09:00<33:41,66.93it/s] 22%|##2       |38779/173481[09:10<33:32,66.93it/s] 28%|##8       |49105/173481[12:00<32:32,63.70it/s] 29%|##8       |49729/173481[12:10<32:22,63.70it/s] 35%|###4      |60484/173481[15:00<29:40,63.46it/s] 35%|###5      |61139/173481[15:10<29:30,63.46it/s] 41%|####1     |71377/173481[18:00<27:28,61.95it/s] 42%|####1     |72043/173481[18:10<27:17,61.95it/s] 48%|####7     |82502/173481[21:00<24:30,61.88it/s] 48%|####7     |83179/173481[21:11<24:19,61.88it/s] 54%|#####4    |93755/173481[24:00<21:21,62.19it/s] 54%|#####4    |94451/173481[24:11<21:10,62.19it/s] 60%|######    |104645/173481[27:00<18:42,61.33it/s] 61%|######    |105506/173481[27:11<18:28,61.33it/s] 67%|######6   |116090/173481[30:00<15:19,62.43it/s] 67%|######7   |116774/173481[30:11<15:08,62.43it/s] 73%|#######3  |126945/173481[33:00<12:38,61.35it/s] 74%|#######3  |127636/173481[33:11<12:27,61.35it/s] 79%|#######8  |136469/173481[36:00<10:51,56.82it/s] 79%|#######9  |137386/173481[36:11<10:35,56.82it/s] 85%|########5 |147806/173481[39:00<07:09,59.74it/s] 86%|########5 |148485/173481[39:12<06:58,59.74it/s] 91%|#########1|158620/173481[42:00<04:08,59.90it/s] 92%|#########1|159357/173481[42:12<03:55,59.90it/s] 98%|#########7|169895/173481[45:00<00:58,61.23it/s] 98%|#########8|170659/173481[45:12<00:46,61.23it/s]100%|##########|173481/173481[46:06<00:00,62.70it/s]
[32m[0323 12:23:34 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2766.96 sec.
[32m[0323 12:23:34 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-346962.
[32m[0323 12:23:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:22<00:00,132.03it/s]
1
[32m[0323 12:25:57 @monitor.py:363][0m QueueInput/queue_size: 1.7456
[32m[0323 12:25:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 4.1156
[32m[0323 12:25:57 @monitor.py:363][0m activation-summaries/output-rms: 0.02947
[32m[0323 12:25:57 @monitor.py:363][0m cross_entropy_loss: 2.5706
[32m[0323 12:25:57 @monitor.py:363][0m lr: 0.001
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.18297
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.2407e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.15412
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 3.8172e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.17695
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.4223e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.14886
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.5122e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.17096
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.7815e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.14902
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 4.1768e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.17997
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 4.2662e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.14887
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 3.6492e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.18503
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.0241e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.15217
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.2188e-06
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13711
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.97891
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14613
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.12231
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089257
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11642
[32m[0323 12:25:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 12:25:57 @monitor.py:363][0m train-error-top1: 0.63985
[32m[0323 12:25:57 @monitor.py:363][0m val-error-top1: 0.69256
[32m[0323 12:25:57 @monitor.py:363][0m val-utt-error: 0.3743
[32m[0323 12:25:57 @monitor.py:363][0m validation_cost: 2.8589
[32m[0323 12:25:57 @monitor.py:363][0m wd_cost: 0.51478
[32m[0323 12:25:57 @group.py:42][0m Callbacks took 143.524 sec in total. InferenceRunner: 142.582sec
[32m[0323 12:25:57 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15203/173481[03:00<31:14,84.46it/s]  9%|9         |16042/173481[03:10<31:04,84.46it/s] 17%|#6        |29323/173481[06:00<29:32,81.34it/s] 17%|#7        |29918/173481[06:10<29:24,81.34it/s] 23%|##2       |39522/173481[09:00<33:25,66.79it/s] 23%|##3       |40140/173481[09:10<33:16,66.79it/s] 29%|##8       |49869/173481[12:00<33:20,61.78it/s] 29%|##9       |50497/173481[12:10<33:10,61.78it/s] 35%|###4      |60356/173481[15:00<31:26,59.97it/s] 35%|###5      |60988/173481[15:10<31:15,59.97it/s] 41%|####1     |71532/173481[18:00<27:51,61.01it/s] 42%|####1     |72223/173481[18:10<27:39,61.01it/s] 48%|####7     |83148/173481[21:00<24:00,62.72it/s] 48%|####8     |83840/173481[21:11<23:49,62.72it/s] 55%|#####4    |94679/173481[24:00<20:43,63.38it/s] 55%|#####4    |95388/173481[24:11<20:32,63.38it/s] 61%|######    |105488/173481[27:00<18:22,61.67it/s] 61%|######1   |106397/173481[27:11<18:07,61.67it/s] 68%|######7   |117561/173481[30:00<14:30,64.26it/s] 68%|######8   |118299/173481[30:11<14:18,64.26it/s] 74%|#######4  |128968/173481[33:00<11:37,63.81it/s] 75%|#######4  |129739/173481[33:11<11:25,63.81it/s] 81%|########1 |140858/173481[36:00<08:22,64.91it/s] 81%|########1 |141323/173481[36:11<08:15,64.91it/s] 88%|########8 |152750/173481[39:00<05:16,65.48it/s] 89%|########8 |153564/173481[39:12<05:04,65.48it/s] 95%|#########5|164811/173481[42:00<02:10,66.24it/s] 95%|#########5|165604/173481[42:12<01:58,66.24it/s]100%|##########|173481/173481[44:12<00:00,65.41it/s]
[32m[0323 13:10:10 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2652.11 sec.
[32m[0323 13:10:10 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-520443.
[32m[0323 13:10:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:41<00:00,116.63it/s]
2
[32m[0323 13:12:51 @monitor.py:363][0m QueueInput/queue_size: 0.75849
[32m[0323 13:12:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.7839
[32m[0323 13:12:51 @monitor.py:363][0m activation-summaries/output-rms: 0.034538
[32m[0323 13:12:51 @monitor.py:363][0m cross_entropy_loss: 2.1195
[32m[0323 13:12:51 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.24573
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.9987e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.20277
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.161e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.2426
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.2825e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.19869
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1992e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.23426
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.7043e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.19761
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.3139e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.24476
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.0728e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.19688
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.2255e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.25529
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6139e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.19998
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.1771e-06
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.18668
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.117
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.1942
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.17039
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16648
[32m[0323 13:12:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 13:12:51 @monitor.py:363][0m train-error-top1: 0.55071
[32m[0323 13:12:51 @monitor.py:363][0m val-error-top1: 0.59288
[32m[0323 13:12:51 @monitor.py:363][0m val-utt-error: 0.23021
[32m[0323 13:12:51 @monitor.py:363][0m validation_cost: 2.3429
[32m[0323 13:12:51 @monitor.py:363][0m wd_cost: 0.19299
[32m[0323 13:12:51 @group.py:42][0m Callbacks took 161.879 sec in total. InferenceRunner: 161.402sec
[32m[0323 13:12:51 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14502/173481[03:00<32:53,80.57it/s]  9%|8         |15297/173481[03:10<32:43,80.57it/s] 16%|#5        |27426/173481[06:00<32:03,75.93it/s] 16%|#6        |28090/173481[06:10<31:54,75.93it/s] 23%|##2       |39063/173481[09:00<32:06,69.79it/s] 23%|##2       |39172/173481[09:10<32:04,69.79it/s] 30%|##9       |51375/173481[12:00<29:27,69.09it/s] 30%|##9       |52034/173481[12:10<29:17,69.09it/s] 36%|###6      |63278/173481[15:00<27:10,67.57it/s] 37%|###6      |64002/173481[15:10<27:00,67.57it/s] 44%|####3     |75509/173481[18:00<24:05,67.76it/s] 44%|####3     |76214/173481[18:10<23:55,67.76it/s] 50%|#####     |87369/173481[21:00<21:28,66.81it/s] 51%|#####     |88072/173481[21:11<21:18,66.81it/s] 57%|#####7    |99286/173481[24:00<18:35,66.51it/s] 58%|#####7    |99996/173481[24:11<18:24,66.51it/s] 64%|######4   |111398/173481[27:00<15:28,66.88it/s] 65%|######4   |112148/173481[27:11<15:17,66.88it/s] 71%|#######   |122775/173481[30:00<13:00,64.99it/s] 71%|#######1  |123587/173481[30:11<12:47,64.99it/s] 78%|#######7  |135198/173481[33:00<09:31,66.94it/s] 78%|#######8  |135983/173481[33:11<09:20,66.94it/s] 85%|########4 |147145/173481[36:00<06:35,66.65it/s] 85%|########5 |147897/173481[36:11<06:23,66.65it/s] 91%|######### |157609/173481[39:00<04:15,62.10it/s] 91%|#########1|158504/173481[39:12<04:01,62.10it/s] 98%|#########7|169743/173481[42:00<00:57,64.64it/s] 98%|#########8|170442/173481[42:12<00:47,64.64it/s]100%|##########|173481/173481[43:01<00:00,67.21it/s]
[32m[0323 13:55:53 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2581.31 sec.
[32m[0323 13:55:53 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-693924.
[32m[0323 13:55:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,139.50it/s]
3
[32m[0323 13:58:08 @monitor.py:363][0m QueueInput/queue_size: 0.49136
[32m[0323 13:58:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.2702
[32m[0323 13:58:08 @monitor.py:363][0m activation-summaries/output-rms: 0.034624
[32m[0323 13:58:08 @monitor.py:363][0m cross_entropy_loss: 2.0772
[32m[0323 13:58:08 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.27115
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.5762e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.22153
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.5362e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.26286
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.7814e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.21686
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3876e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.25733
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 4.8892e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.21762
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.5471e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.26645
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 5.8541e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21654
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.2858e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.28039
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.3766e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.22031
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.1767e-06
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21702
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.186
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2204
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19668
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18714
[32m[0323 13:58:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 13:58:08 @monitor.py:363][0m train-error-top1: 0.54021
[32m[0323 13:58:08 @monitor.py:363][0m val-error-top1: 0.57101
[32m[0323 13:58:08 @monitor.py:363][0m val-utt-error: 0.2071
[32m[0323 13:58:08 @monitor.py:363][0m validation_cost: 2.2456
[32m[0323 13:58:08 @monitor.py:363][0m wd_cost: 0.25013
[32m[0323 13:58:08 @group.py:42][0m Callbacks took 135.521 sec in total. InferenceRunner: 134.935sec
[32m[0323 13:58:08 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13938/173481[03:00<34:20,77.43it/s]  8%|8         |14581/173481[03:10<34:12,77.43it/s] 15%|#4        |25424/173481[06:00<35:16,69.96it/s] 15%|#5        |26086/173481[06:10<35:06,69.96it/s] 22%|##1       |37367/173481[09:00<33:18,68.11it/s] 22%|##1       |38013/173481[09:10<33:09,68.11it/s] 28%|##8       |49129/173481[12:00<31:04,66.70it/s] 29%|##8       |49819/173481[12:10<30:54,66.70it/s] 35%|###5      |60890/173481[15:00<28:25,66.01it/s] 36%|###5      |61651/173481[15:10<28:14,66.01it/s] 42%|####1     |72083/173481[18:00<26:23,64.04it/s] 42%|####1     |72806/173481[18:10<26:12,64.04it/s] 48%|####8     |83882/173481[21:00<23:03,64.78it/s] 49%|####8     |84553/173481[21:11<22:52,64.78it/s] 55%|#####4    |94873/173481[24:00<20:50,62.86it/s] 55%|#####5    |95721/173481[24:11<20:36,62.86it/s] 62%|######1   |107012/173481[27:00<17:01,65.07it/s] 62%|######2   |107732/173481[27:11<16:50,65.07it/s] 68%|######8   |118622/173481[30:00<14:06,64.78it/s] 69%|######8   |119301/173481[30:11<13:56,64.78it/s] 74%|#######4  |129207/173481[33:00<11:58,61.62it/s] 75%|#######4  |129853/173481[33:11<11:48,61.62it/s] 82%|########1 |141802/173481[36:00<08:03,65.52it/s] 82%|########2 |142543/173481[36:11<07:52,65.52it/s] 89%|########8 |153649/173481[39:00<05:01,65.67it/s] 89%|########8 |154381/173481[39:11<04:50,65.67it/s] 95%|#########5|164987/173481[42:00<02:12,64.30it/s] 96%|#########5|165710/173481[42:12<02:00,64.30it/s]100%|##########|173481/173481[44:21<00:00,65.17it/s]
[32m[0323 14:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2661.93 sec.
[32m[0323 14:42:30 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-867405.
[32m[0323 14:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:16<00:00,137.46it/s]
4
[32m[0323 14:44:48 @monitor.py:363][0m QueueInput/queue_size: 0.56757
[32m[0323 14:44:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.2171
[32m[0323 14:44:48 @monitor.py:363][0m activation-summaries/output-rms: 0.036405
[32m[0323 14:44:48 @monitor.py:363][0m cross_entropy_loss: 2.0198
[32m[0323 14:44:48 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.27344
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.9452e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.22357
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.1897e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.26514
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.9971e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.21878
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1928e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.25815
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0193e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.2175
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.4037e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.26568
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.0441e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.21749
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.5818e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.28129
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.4167e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.22218
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 4.0369e-06
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.22051
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2301
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.22155
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19922
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18936
[32m[0323 14:44:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 14:44:48 @monitor.py:363][0m train-error-top1: 0.52921
[32m[0323 14:44:48 @monitor.py:363][0m val-error-top1: 0.57568
[32m[0323 14:44:48 @monitor.py:363][0m val-utt-error: 0.21921
[32m[0323 14:44:48 @monitor.py:363][0m validation_cost: 2.2662
[32m[0323 14:44:48 @monitor.py:363][0m wd_cost: 0.2555
[32m[0323 14:44:48 @group.py:42][0m Callbacks took 137.492 sec in total. InferenceRunner: 136.942sec
[32m[0323 14:44:48 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14442/173481[03:00<33:02,80.23it/s]  9%|8         |15238/173481[03:10<32:52,80.23it/s] 15%|#4        |25986/173481[06:00<34:29,71.28it/s] 15%|#5        |26780/173481[06:10<34:18,71.28it/s] 20%|#9        |33931/173481[09:00<42:39,54.52it/s] 20%|##        |34751/173481[09:10<42:24,54.52it/s] 28%|##7       |48051/173481[12:00<32:29,64.32it/s] 28%|##8       |48816/173481[12:10<32:18,64.32it/s] 36%|###5      |62109/173481[15:00<26:18,70.55it/s] 36%|###6      |62968/173481[15:10<26:06,70.55it/s] 43%|####3     |75431/173481[18:00<22:37,72.22it/s] 44%|####3     |76100/173481[18:10<22:28,72.22it/s] 52%|#####1    |89981/173481[21:00<18:14,76.28it/s] 52%|#####2    |90886/173481[21:11<18:02,76.28it/s] 60%|######    |104705/173481[24:00<14:31,78.94it/s] 61%|######    |105617/173481[24:11<14:19,78.94it/s] 67%|######6   |116186/173481[27:00<13:32,70.56it/s] 67%|######7   |116860/173481[27:11<13:22,70.56it/s] 73%|#######3  |127026/173481[30:00<11:54,64.98it/s] 74%|#######3  |127722/173481[30:11<11:44,64.98it/s] 80%|#######9  |137981/173481[33:00<09:24,62.85it/s] 80%|#######9  |138690/173481[33:11<09:13,62.85it/s] 86%|########5 |148970/173481[36:00<06:35,61.94it/s] 86%|########6 |149665/173481[36:11<06:24,61.94it/s] 92%|#########2|159607/173481[39:00<03:49,60.48it/s] 92%|#########2|160336/173481[39:12<03:37,60.48it/s] 98%|#########8|170576/173481[42:00<00:47,60.70it/s] 99%|#########8|171286/173481[42:12<00:36,60.70it/s]100%|##########|173481/173481[42:48<00:00,67.54it/s]
[32m[0323 15:27:36 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:2568.76 sec.
[32m[0323 15:27:37 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-1040886.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:16<00:00,137.45it/s]
5
[32m[0323 15:29:54 @monitor.py:363][0m QueueInput/queue_size: 0.51298
[32m[0323 15:29:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.091
[32m[0323 15:29:54 @monitor.py:363][0m activation-summaries/output-rms: 0.036814
[32m[0323 15:29:54 @monitor.py:363][0m cross_entropy_loss: 1.8896
[32m[0323 15:29:54 @monitor.py:363][0m lr: 0.00025
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.31855
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.6781e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.24932
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2604e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3079
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.2098e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.24496
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1409e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.30636
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.1561e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.24378
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9356e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.31221
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.2161e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.24343
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.5894e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.32742
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 4.9932e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.24791
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.5481e-06
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26289
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2583
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2524
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090673
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.22656
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.21828
[32m[0323 15:29:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 15:29:54 @monitor.py:363][0m train-error-top1: 0.48924
[32m[0323 15:29:54 @monitor.py:363][0m val-error-top1: 0.52877
[32m[0323 15:29:54 @monitor.py:363][0m val-utt-error: 0.16911
[32m[0323 15:29:54 @monitor.py:363][0m validation_cost: 2.0417
[32m[0323 15:29:54 @monitor.py:363][0m wd_cost: 0.06827
[32m[0323 15:29:54 @group.py:42][0m Callbacks took 137.201 sec in total. InferenceRunner: 136.949sec
[32m[0323 15:29:54 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13205/173481[03:00<36:24,73.36it/s]  8%|8         |14024/173481[03:10<36:13,73.36it/s] 14%|#4        |24576/173481[06:00<36:33,67.88it/s] 15%|#4        |25180/173481[06:10<36:24,67.88it/s] 20%|##        |34951/173481[09:00<37:02,62.34it/s] 20%|##        |35519/173481[09:10<36:52,62.34it/s] 26%|##5       |44945/173481[12:00<36:28,58.73it/s] 26%|##6       |45559/173481[12:10<36:18,58.73it/s] 32%|###2      |55809/173481[15:00<32:56,59.53it/s] 33%|###2      |56513/173481[15:10<32:44,59.53it/s] 38%|###8      |66740/173481[18:00<29:35,60.12it/s] 39%|###8      |67399/173481[18:10<29:24,60.12it/s] 44%|####4     |77154/173481[21:00<27:13,58.96it/s] 45%|####4     |78048/173481[21:11<26:58,58.96it/s] 51%|#####1    |89257/173481[24:00<22:20,62.83it/s] 52%|#####1    |89954/173481[24:11<22:09,62.83it/s] 58%|#####7    |100475/173481[27:00<19:26,62.57it/s] 58%|#####8    |101204/173481[27:11<19:15,62.57it/s] 64%|######4   |111530/173481[30:00<16:40,61.92it/s] 64%|######4   |111644/173481[30:11<16:38,61.92it/s] 71%|#######   |122545/173481[33:00<13:47,61.55it/s] 71%|#######1  |123236/173481[33:11<13:36,61.55it/s] 77%|#######6  |133527/173481[36:00<10:51,61.28it/s] 77%|#######7  |134226/173481[36:11<10:40,61.28it/s] 84%|########3 |145505/173481[39:00<07:18,63.80it/s] 84%|########4 |146370/173481[39:12<07:04,63.80it/s] 91%|######### |157595/173481[42:00<04:02,65.44it/s] 91%|#########1|158354/173481[42:12<03:51,65.44it/s] 99%|#########9|171807/173481[45:00<00:23,71.56it/s]100%|#########9|172752/173481[45:12<00:10,71.56it/s]100%|##########|173481/173481[45:21<00:00,63.74it/s]
[32m[0323 16:15:15 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:2721.57 sec.
[32m[0323 16:15:16 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-1214367.
[32m[0323 16:15:16 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.50it/s]
6
[32m[0323 16:17:19 @monitor.py:363][0m QueueInput/queue_size: 0.57402
[32m[0323 16:17:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 16.553
[32m[0323 16:17:19 @monitor.py:363][0m activation-summaries/output-rms: 0.038216
[32m[0323 16:17:19 @monitor.py:363][0m cross_entropy_loss: 1.8361
[32m[0323 16:17:19 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.36717
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.466e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.28713
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.3944e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.3536
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.2364e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.28182
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.1816e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.35275
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0758e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.28041
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0632e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.35843
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.4745e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.28057
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.6651e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.37789
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.2196e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.28456
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.4207e-06
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31983
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2718
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29629
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26544
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25716
[32m[0323 16:17:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 16:17:19 @monitor.py:363][0m train-error-top1: 0.475
[32m[0323 16:17:19 @monitor.py:363][0m val-error-top1: 0.5185
[32m[0323 16:17:19 @monitor.py:363][0m val-utt-error: 0.157
[32m[0323 16:17:19 @monitor.py:363][0m validation_cost: 1.9941
[32m[0323 16:17:19 @monitor.py:363][0m wd_cost: 0.095547
[32m[0323 16:17:19 @group.py:42][0m Callbacks took 123.628 sec in total. InferenceRunner: 122.636sec
[32m[0323 16:17:19 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12944/173481[03:00<37:12,71.91it/s]  8%|7         |13731/173481[03:10<37:01,71.91it/s] 16%|#5        |27015/173481[06:00<32:35,74.91it/s] 16%|#6        |27834/173481[06:10<32:24,74.91it/s] 24%|##3       |41031/173481[09:00<28:54,76.36it/s] 24%|##4       |41848/173481[09:10<28:43,76.36it/s] 30%|##9       |51274/173481[12:00<31:14,65.21it/s] 30%|###       |52098/173481[12:10<31:01,65.21it/s] 36%|###6      |62666/173481[15:00<28:45,64.23it/s] 36%|###6      |63303/173481[15:10<28:35,64.23it/s] 43%|####2     |74107/173481[18:00<25:55,63.89it/s] 43%|####3     |74788/173481[18:10<25:44,63.89it/s] 49%|####9     |85404/173481[21:00<23:10,63.32it/s] 49%|####9     |85828/173481[21:11<23:04,63.32it/s] 56%|#####5    |96574/173481[24:00<20:26,62.68it/s] 56%|#####6    |97226/173481[24:11<20:16,62.68it/s] 62%|######2   |108174/173481[27:00<17:07,63.54it/s] 63%|######2   |108917/173481[27:11<16:56,63.54it/s] 69%|######9   |119726/173481[30:00<14:01,63.86it/s] 69%|######9   |120458/173481[30:11<13:50,63.86it/s] 75%|#######5  |130928/173481[33:00<11:15,63.03it/s] 76%|#######5  |131683/173481[33:11<11:03,63.03it/s] 82%|########2 |142719/173481[36:00<07:58,64.24it/s] 83%|########2 |143483/173481[36:11<07:46,64.24it/s] 89%|########9 |154524/173481[39:00<04:52,64.90it/s] 89%|########9 |155263/173481[39:12<04:40,64.90it/s] 96%|#########5|165810/173481[42:00<02:00,63.78it/s] 96%|#########6|166610/173481[42:12<01:47,63.78it/s]100%|##########|173481/173481[43:58<00:00,65.74it/s]
[32m[0323 17:01:18 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:2638.97 sec.
[32m[0323 17:01:18 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-1387848.
[32m[0323 17:01:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,154.25it/s]
7
[32m[0323 17:03:20 @monitor.py:363][0m QueueInput/queue_size: 0.62657
[32m[0323 17:03:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.102
[32m[0323 17:03:20 @monitor.py:363][0m activation-summaries/output-rms: 0.037474
[32m[0323 17:03:20 @monitor.py:363][0m cross_entropy_loss: 1.8428
[32m[0323 17:03:20 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.38602
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.5299e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.30289
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.3353e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.37354
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.6356e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.29658
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2511e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.37083
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0673e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.29567
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0259e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.3746
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3773e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.2949
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.5871e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.39833
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.5259e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.29975
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.479e-06
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.35676
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2867
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31566
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28346
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27383
[32m[0323 17:03:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 17:03:20 @monitor.py:363][0m train-error-top1: 0.4908
[32m[0323 17:03:20 @monitor.py:363][0m val-error-top1: 0.52024
[32m[0323 17:03:20 @monitor.py:363][0m val-utt-error: 0.16242
[32m[0323 17:03:20 @monitor.py:363][0m validation_cost: 2.0053
[32m[0323 17:03:20 @monitor.py:363][0m wd_cost: 0.11115
[32m[0323 17:03:20 @group.py:42][0m Callbacks took 122.563 sec in total. InferenceRunner: 122.034sec
[32m[0323 17:03:20 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13448/173481[03:00<35:42,74.69it/s]  8%|8         |14077/173481[03:10<35:34,74.69it/s] 14%|#4        |24288/173481[06:00<37:17,66.68it/s] 14%|#4        |24897/173481[06:10<37:08,66.68it/s] 21%|##        |35703/173481[09:00<35:19,65.00it/s] 21%|##        |36374/173481[09:10<35:09,65.00it/s] 27%|##7       |47422/173481[12:00<32:17,65.05it/s] 28%|##7       |48102/173481[12:10<32:07,65.05it/s] 34%|###3      |58711/173481[15:00<29:57,63.86it/s] 34%|###4      |59392/173481[15:10<29:46,63.86it/s] 41%|####      |70402/173481[18:00<26:40,64.40it/s] 41%|####      |71104/173481[18:10<26:29,64.40it/s] 47%|####7     |81955/173481[21:00<23:43,64.29it/s] 48%|####7     |82647/173481[21:11<23:32,64.29it/s] 53%|#####3    |92127/173481[24:00<22:32,60.15it/s] 54%|#####3    |92883/173481[24:11<22:19,60.15it/s] 60%|######    |104262/173481[27:00<18:08,63.57it/s] 61%|######    |105022/173481[27:11<17:56,63.57it/s] 67%|######6   |116054/173481[30:00<14:49,64.53it/s] 67%|######7   |116737/173481[30:11<14:39,64.53it/s] 73%|#######3  |127415/173481[33:00<12:01,63.81it/s] 74%|#######3  |127702/173481[33:11<11:57,63.81it/s] 80%|#######9  |138564/173481[36:00<09:15,62.86it/s] 80%|########  |139382/173481[36:11<09:02,62.86it/s] 87%|########6 |150202/173481[39:00<06:05,63.74it/s] 87%|########7 |151021/173481[39:11<05:52,63.74it/s] 93%|#########3|162153/173481[42:00<02:54,65.04it/s] 94%|#########3|162837/173481[42:12<02:43,65.04it/s] 99%|#########9|172198/173481[45:00<00:21,60.07it/s]100%|#########9|172927/173481[45:12<00:09,60.07it/s]100%|##########|173481/173481[45:22<00:00,63.73it/s]
[32m[0323 17:48:43 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:2722.11 sec.
[32m[0323 17:48:43 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-1561329.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.55it/s]
8
[32m[0323 17:50:46 @monitor.py:363][0m QueueInput/queue_size: 0.50006
[32m[0323 17:50:46 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 23.043
[32m[0323 17:50:46 @monitor.py:363][0m activation-summaries/output-rms: 0.038046
[32m[0323 17:50:46 @monitor.py:363][0m cross_entropy_loss: 1.8138
[32m[0323 17:50:46 @monitor.py:363][0m lr: 0.000125
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.40872
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.5479e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.31333
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.3243e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.39572
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.6918e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.30753
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2982e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.39596
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0535e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.30607
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0676e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.39824
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3132e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.30564
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.6267e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.42168
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.5597e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.31126
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3398e-06
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.3955
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.295
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33485
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090673
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29761
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28809
[32m[0323 17:50:46 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 17:50:46 @monitor.py:363][0m train-error-top1: 0.47943
[32m[0323 17:50:46 @monitor.py:363][0m val-error-top1: 0.50091
[32m[0323 17:50:46 @monitor.py:363][0m val-utt-error: 0.14823
[32m[0323 17:50:46 @monitor.py:363][0m validation_cost: 1.9252
[32m[0323 17:50:46 @monitor.py:363][0m wd_cost: 0.025491
[32m[0323 17:50:46 @group.py:42][0m Callbacks took 123.606 sec in total. InferenceRunner: 123.392sec
[32m[0323 17:50:46 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13722/173481[03:00<34:55,76.23it/s]  8%|8         |14311/173481[03:10<34:48,76.23it/s] 14%|#3        |24095/173481[06:00<37:56,65.63it/s] 14%|#4        |24878/173481[06:10<37:44,65.63it/s] 21%|##        |35922/173481[09:00<34:54,65.67it/s] 21%|##1       |36549/173481[09:10<34:45,65.67it/s] 27%|##7       |47197/173481[12:00<32:49,64.12it/s] 28%|##7       |47874/173481[12:10<32:39,64.12it/s] 34%|###3      |58158/173481[15:00<30:46,62.46it/s] 34%|###3      |58266/173481[15:10<30:44,62.46it/s] 37%|###6      |64109/173481[18:00<42:09,43.24it/s] 37%|###7      |64754/173481[18:10<41:54,43.24it/s] 44%|####4     |76361/173481[21:00<30:36,52.88it/s] 44%|####4     |77129/173481[21:11<30:22,52.88it/s] 51%|#####     |88437/173481[24:00<23:57,59.14it/s] 51%|#####1    |89203/173481[24:11<23:45,59.14it/s] 58%|#####7    |100603/173481[27:00<19:15,63.08it/s] 58%|#####8    |101401/173481[27:11<19:02,63.08it/s] 64%|######4   |111890/173481[30:00<16:19,62.89it/s] 65%|######4   |112706/173481[30:11<16:06,62.89it/s] 72%|#######1  |124425/173481[33:00<12:22,66.09it/s] 72%|#######2  |125236/173481[33:11<12:09,66.09it/s] 79%|#######8  |136837/173481[36:00<09:02,67.49it/s] 79%|#######9  |137651/173481[36:11<08:50,67.49it/s] 86%|########5 |148757/173481[39:00<06:09,66.85it/s] 86%|########6 |149762/173481[39:12<05:54,66.85it/s] 94%|#########4|163806/173481[42:00<02:10,74.29it/s] 95%|#########5|164819/173481[42:12<01:56,74.29it/s]100%|##########|173481/173481[43:55<00:00,65.81it/s]
[32m[0323 18:34:42 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:2635.90 sec.
[32m[0323 18:34:42 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-1734810.
[32m[0323 18:34:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,139.72it/s]
9
[32m[0323 18:36:57 @monitor.py:363][0m QueueInput/queue_size: 0.64076
[32m[0323 18:36:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 26.101
[32m[0323 18:36:57 @monitor.py:363][0m activation-summaries/output-rms: 0.039597
[32m[0323 18:36:57 @monitor.py:363][0m cross_entropy_loss: 1.7862
[32m[0323 18:36:57 @monitor.py:363][0m lr: 0.000125
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.43283
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.5176e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.3276
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2219e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.41905
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0c/b-rms: 8.022e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.32202
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.2726e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.41902
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0604e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.32028
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0426e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.42238
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3628e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.31973
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.6883e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.44783
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.5967e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.32567
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3573e-06
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4374
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.35968
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090673
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31622
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30735
[32m[0323 18:36:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0323 18:36:57 @monitor.py:363][0m train-error-top1: 0.48554
[32m[0323 18:36:57 @monitor.py:363][0m val-error-top1: 0.49981
[32m[0323 18:36:57 @monitor.py:363][0m val-utt-error: 0.14409
[32m[0323 18:36:57 @monitor.py:363][0m validation_cost: 1.9137
[32m[0323 18:36:57 @monitor.py:363][0m wd_cost: 0.029689
[32m[0323 18:36:57 @group.py:42][0m Callbacks took 135.266 sec in total. InferenceRunner: 134.729sec
[32m[0323 18:36:57 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13493/173481[03:00<35:34,74.96it/s]  8%|8         |14317/173481[03:10<35:23,74.96it/s] 16%|#6        |28117/173481[06:00<31:04,77.97it/s] 17%|#6        |28720/173481[06:10<30:56,77.97it/s] 21%|##1       |37102/173481[09:00<37:20,60.87it/s] 22%|##1       |37615/173481[09:10<37:12,60.87it/s] 26%|##6       |45684/173481[12:00<39:50,53.47it/s] 27%|##6       |46175/173481[12:10<39:40,53.47it/s] 31%|###1      |54146/173481[15:00<39:45,50.03it/s] 32%|###1      |54710/173481[15:10<39:33,50.03it/s] 37%|###6      |63816/173481[18:00<35:16,51.81it/s] 37%|###7      |64512/173481[18:10<35:03,51.81it/s] 42%|####2     |72977/173481[21:00<32:37,51.34it/s] 42%|####2     |73513/173481[21:11<32:27,51.34it/s] 47%|####7     |82301/173481[24:00<29:28,51.57it/s] 48%|####7     |82873/173481[24:11<29:17,51.57it/s] 53%|#####2    |91686/173481[27:00<26:17,51.85it/s] 53%|#####3    |92275/173481[27:11<26:06,51.85it/s] 58%|#####7    |100191/173481[30:00<24:42,49.44it/s] 58%|#####8    |101069/173481[30:11<24:24,49.44it/s] 64%|######3   |110258/173481[33:00<20:04,52.48it/s] 64%|######4   |111055/173481[33:11<19:49,52.48it/s] 70%|#######   |121681/173481[36:00<15:01,57.45it/s] 71%|#######   |122347/173481[36:11<14:50,57.45it/s] 76%|#######6  |132619/173481[39:00<11:31,59.06it/s] 77%|#######6  |132880/173481[39:11<11:27,59.06it/s] 82%|########2 |142431/173481[42:00<09:07,56.69it/s] 83%|########2 |143127/173481[42:12<08:55,56.69it/s] 88%|########7 |152139/173481[45:00<06:26,55.28it/s] 88%|########8 |152794/173481[45:12<06:14,55.28it/s] 93%|#########3|161946/173481[48:00<03:30,54.87it/s] 94%|#########3|162536/173481[48:12<03:19,54.87it/s] 98%|#########8|170861/173481[51:00<00:50,52.05it/s] 99%|#########8|171465/173481[51:12<00:38,52.05it/s]100%|##########|173481/173481[51:52<00:00,55.73it/s]
[32m[0323 19:28:50 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3112.77 sec.
[32m[0323 19:28:50 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-1908291.
[32m[0323 19:28:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:06<00:00,148.84it/s]
10
[32m[0323 19:30:58 @monitor.py:363][0m QueueInput/queue_size: 0.6708
[32m[0323 19:30:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.914
[32m[0323 19:30:58 @monitor.py:363][0m activation-summaries/output-rms: 0.038308
[32m[0323 19:30:58 @monitor.py:363][0m cross_entropy_loss: 1.77
[32m[0323 19:30:58 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.45122
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.5014e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.33849
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2467e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.43537
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.7262e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.33303
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3088e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.43727
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.1195e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3308
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9871e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.43957
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.2865e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33021
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.74e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.46704
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.655e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3365
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3634e-06
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.47461
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3053
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.37956
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.33127
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.32284
[32m[0323 19:30:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 19:30:58 @monitor.py:363][0m train-error-top1: 0.46513
[32m[0323 19:30:58 @monitor.py:363][0m val-error-top1: 0.48967
[32m[0323 19:30:58 @monitor.py:363][0m val-utt-error: 0.13638
[32m[0323 19:30:58 @monitor.py:363][0m validation_cost: 1.8688
[32m[0323 19:30:58 @monitor.py:363][0m wd_cost: 0.033464
[32m[0323 19:30:58 @group.py:42][0m Callbacks took 127.693 sec in total. InferenceRunner: 126.467sec
[32m[0323 19:30:58 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12488/173481[03:00<38:40,69.38it/s]  7%|7         |13005/173481[03:10<38:33,69.38it/s] 13%|#2        |21741/173481[06:00<42:49,59.05it/s] 13%|#2        |22322/173481[06:10<42:39,59.05it/s] 18%|#7        |31057/173481[09:00<43:01,55.16it/s] 18%|#8        |31584/173481[09:10<42:52,55.16it/s] 23%|##2       |39791/173481[12:00<43:09,51.63it/s] 23%|##3       |40294/173481[12:10<42:59,51.63it/s] 28%|##7       |48381/173481[15:00<42:02,49.60it/s] 28%|##8       |48904/173481[15:10<41:51,49.60it/s] 33%|###2      |57198/173481[18:00<39:19,49.29it/s] 33%|###3      |57741/173481[18:10<39:08,49.29it/s] 38%|###8      |66290/173481[21:00<35:48,49.89it/s] 39%|###8      |66859/173481[21:11<35:37,49.89it/s] 44%|####3     |75585/173481[24:00<32:09,50.75it/s] 44%|####3     |76307/173481[24:11<31:54,50.75it/s] 49%|####9     |85210/173481[27:00<28:15,52.07it/s] 49%|####9     |85751/173481[27:11<28:04,52.07it/s] 55%|#####4    |94621/173481[30:00<25:11,52.18it/s] 55%|#####4    |95224/173481[30:11<24:59,52.18it/s] 60%|#####9    |103765/173481[33:00<22:35,51.44it/s] 60%|#####9    |103989/173481[33:11<22:31,51.44it/s] 66%|######5   |113796/173481[36:00<18:35,53.49it/s] 66%|######5   |114402/173481[36:11<18:24,53.49it/s] 71%|#######1  |123265/173481[39:00<15:46,53.04it/s] 71%|#######1  |123870/173481[39:12<15:35,53.04it/s] 76%|#######6  |132570/173481[42:00<13:01,52.35it/s] 77%|#######6  |133164/173481[42:12<12:50,52.35it/s] 83%|########2 |143400/173481[45:00<08:57,55.98it/s] 83%|########3 |144185/173481[45:12<08:43,55.98it/s] 89%|########9 |154715/173481[48:00<05:16,59.22it/s] 90%|########9 |155379/173481[48:12<05:05,59.22it/s] 95%|#########5|165156/173481[51:00<02:22,58.61it/s] 96%|#########5|166012/173481[51:12<02:07,58.61it/s]100%|##########|173481/173481[53:19<00:00,54.22it/s]
[32m[0323 20:24:17 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3199.66 sec.
[32m[0323 20:24:18 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-2081772.
[32m[0323 20:24:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.51it/s]
11
[32m[0323 20:26:21 @monitor.py:363][0m QueueInput/queue_size: 0.61231
[32m[0323 20:26:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.459
[32m[0323 20:26:21 @monitor.py:363][0m activation-summaries/output-rms: 0.038313
[32m[0323 20:26:21 @monitor.py:363][0m cross_entropy_loss: 1.7981
[32m[0323 20:26:21 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.46175
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.5485e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34333
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2708e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.44487
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8223e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.33777
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3261e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4476
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0994e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.33543
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9842e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45031
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.2632e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.33512
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7136e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.47832
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.5614e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34125
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3739e-06
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.49909
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3083
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.39173
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.33916
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33099
[32m[0323 20:26:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0323 20:26:21 @monitor.py:363][0m train-error-top1: 0.4749
[32m[0323 20:26:21 @monitor.py:363][0m val-error-top1: 0.49048
[32m[0323 20:26:21 @monitor.py:363][0m val-utt-error: 0.13309
[32m[0323 20:26:21 @monitor.py:363][0m validation_cost: 1.8724
[32m[0323 20:26:21 @monitor.py:363][0m wd_cost: 0.0071744
[32m[0323 20:26:21 @group.py:42][0m Callbacks took 123.929 sec in total. InferenceRunner: 123.431sec
[32m[0323 20:26:21 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13263/173481[03:00<36:14,73.68it/s]  8%|8         |13974/173481[03:10<36:04,73.68it/s] 15%|#5        |26604/173481[06:00<33:07,73.89it/s] 16%|#5        |27319/173481[06:10<32:57,73.89it/s] 21%|##        |36225/173481[09:00<36:52,62.03it/s] 21%|##1       |36745/173481[09:10<36:44,62.03it/s] 26%|##6       |45543/173481[12:00<37:46,56.43it/s] 27%|##6       |46098/173481[12:10<37:37,56.43it/s] 32%|###1      |54879/173481[15:00<36:34,54.05it/s] 32%|###1      |55460/173481[15:10<36:23,54.05it/s] 37%|###7      |64663/173481[18:00<33:27,54.20it/s] 38%|###7      |65288/173481[18:10<33:16,54.20it/s] 43%|####3     |75455/173481[21:00<28:41,56.93it/s] 44%|####3     |76113/173481[21:10<28:30,56.93it/s] 49%|####9     |85585/173481[24:00<25:52,56.60it/s] 50%|####9     |86203/173481[24:11<25:41,56.60it/s] 55%|#####5    |95534/173481[27:00<23:13,55.93it/s] 55%|#####5    |96163/173481[27:11<23:02,55.93it/s] 61%|######    |105364/173481[30:00<20:32,55.25it/s] 61%|######1   |105993/173481[30:11<20:21,55.25it/s] 67%|######6   |115599/173481[33:00<17:12,56.04it/s] 67%|######6   |116214/173481[33:11<17:01,56.04it/s] 72%|#######2  |125039/173481[36:00<14:54,54.18it/s] 73%|#######2  |125982/173481[36:11<14:36,54.18it/s] 79%|#######8  |136599/173481[39:00<10:27,58.77it/s] 79%|#######9  |137213/173481[39:11<10:17,58.77it/s] 85%|########5 |147776/173481[42:00<07:05,60.38it/s] 86%|########5 |148447/173481[42:11<06:54,60.38it/s] 91%|#########1|158529/173481[45:00<04:08,60.06it/s] 92%|#########1|159238/173481[45:12<03:57,60.06it/s] 97%|#########7|169101/173481[48:00<01:13,59.39it/s] 98%|#########7|169823/173481[48:12<01:01,59.39it/s]100%|##########|173481/173481[49:14<00:00,58.72it/s]
[32m[0323 21:15:35 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:2954.15 sec.
[32m[0323 21:15:36 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-2255253.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.36it/s]
12
[32m[0323 21:17:38 @monitor.py:363][0m QueueInput/queue_size: 0.78305
[32m[0323 21:17:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 33.195
[32m[0323 21:17:38 @monitor.py:363][0m activation-summaries/output-rms: 0.038741
[32m[0323 21:17:38 @monitor.py:363][0m cross_entropy_loss: 1.7494
[32m[0323 21:17:38 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47046
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.547e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.34774
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2431e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45357
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.7824e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34218
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3459e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.45755
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0991e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34007
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0144e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.45982
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3143e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.3396
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7511e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.48884
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6174e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34568
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3649e-06
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.52361
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3109
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.40442
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.34743
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.33968
[32m[0323 21:17:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0323 21:17:38 @monitor.py:363][0m train-error-top1: 0.46817
[32m[0323 21:17:38 @monitor.py:363][0m val-error-top1: 0.49067
[32m[0323 21:17:38 @monitor.py:363][0m val-utt-error: 0.1358
[32m[0323 21:17:38 @monitor.py:363][0m validation_cost: 1.8702
[32m[0323 21:17:38 @monitor.py:363][0m wd_cost: 0.007684
[32m[0323 21:17:38 @group.py:42][0m Callbacks took 122.207 sec in total. InferenceRunner: 121.949sec
[32m[0323 21:17:38 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13251/173481[03:00<36:16,73.62it/s]  8%|7         |13830/173481[03:10<36:08,73.62it/s] 11%|#         |18759/173481[06:00<59:39,43.23it/s] 11%|#1        |19452/173481[06:10<59:23,43.23it/s] 19%|#8        |32316/173481[09:00<42:49,54.93it/s] 19%|#9        |33012/173481[09:10<42:37,54.93it/s] 26%|##5       |44418/173481[12:00<35:34,60.46it/s] 26%|##5       |45092/173481[12:10<35:23,60.46it/s] 32%|###1      |55328/173481[15:00<32:31,60.53it/s] 32%|###2      |55976/173481[15:10<32:21,60.53it/s] 39%|###8      |66858/173481[18:00<28:32,62.24it/s] 39%|###8      |67607/173481[18:10<28:20,62.24it/s] 45%|####5     |78843/173481[21:00<24:30,64.34it/s] 46%|####5     |79552/173481[21:11<24:19,64.34it/s] 52%|#####2    |90982/173481[24:00<20:52,65.85it/s] 53%|#####2    |91762/173481[24:11<20:40,65.85it/s] 59%|#####9    |102356/173481[27:00<18:22,64.49it/s] 59%|#####9    |103172/173481[27:11<18:10,64.49it/s] 66%|######5   |114403/173481[30:00<14:59,65.68it/s] 66%|######6   |115160/173481[30:11<14:47,65.68it/s] 73%|#######2  |126012/173481[33:00<12:09,65.08it/s] 73%|#######3  |126807/173481[33:11<11:57,65.08it/s] 79%|#######8  |136625/173481[36:00<09:55,61.87it/s] 79%|#######9  |137449/173481[36:11<09:42,61.87it/s] 86%|########5 |148384/173481[39:00<06:34,63.55it/s] 86%|########5 |149167/173481[39:11<06:22,63.55it/s] 92%|#########2|160129/173481[42:00<03:27,64.39it/s] 93%|#########2|160825/173481[42:12<03:16,64.39it/s] 98%|#########8|170568/173481[45:00<00:47,60.99it/s] 98%|#########8|170697/173481[45:12<00:45,60.99it/s]100%|##########|173481/173481[45:55<00:00,62.96it/s]
[32m[0323 22:03:33 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:2755.38 sec.
[32m[0323 22:03:33 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-2428734.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,166.93it/s]
13
[32m[0323 22:05:26 @monitor.py:363][0m QueueInput/queue_size: 0.61778
[32m[0323 22:05:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 34.732
[32m[0323 22:05:26 @monitor.py:363][0m activation-summaries/output-rms: 0.038504
[32m[0323 22:05:26 @monitor.py:363][0m cross_entropy_loss: 1.7548
[32m[0323 22:05:26 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.47712
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4549e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35074
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2284e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.45965
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8269e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34561
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3461e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46432
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0623e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34311
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.007e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.46695
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3374e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34286
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.6967e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49581
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.681e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.34875
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.372e-06
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.54329
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3133
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41395
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.35352
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.34604
[32m[0323 22:05:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0323 22:05:26 @monitor.py:363][0m train-error-top1: 0.46052
[32m[0323 22:05:26 @monitor.py:363][0m val-error-top1: 0.48792
[32m[0323 22:05:26 @monitor.py:363][0m val-utt-error: 0.13527
[32m[0323 22:05:26 @monitor.py:363][0m validation_cost: 1.8645
[32m[0323 22:05:26 @monitor.py:363][0m wd_cost: 0.0016182
[32m[0323 22:05:26 @group.py:42][0m Callbacks took 112.966 sec in total. InferenceRunner: 112.765sec
[32m[0323 22:05:26 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14188/173481[03:00<33:41,78.82it/s]  9%|8         |14861/173481[03:10<33:32,78.82it/s] 14%|#4        |24667/173481[06:00<37:02,66.95it/s] 15%|#4        |25181/173481[06:10<36:55,66.95it/s] 20%|#9        |34072/173481[09:00<39:35,58.69it/s] 20%|#9        |34676/173481[09:10<39:25,58.69it/s] 26%|##5       |44665/173481[12:00<36:31,58.77it/s] 26%|##6       |45302/173481[12:10<36:21,58.77it/s] 32%|###1      |54770/173481[15:00<34:27,57.42it/s] 32%|###1      |55221/173481[15:10<34:19,57.42it/s] 37%|###6      |63407/173481[18:00<35:05,52.27it/s] 37%|###6      |64042/173481[18:10<34:53,52.27it/s] 43%|####2     |74270/173481[21:00<29:31,56.02it/s] 43%|####3     |74851/173481[21:11<29:20,56.02it/s] 49%|####8     |84806/173481[24:00<25:48,57.25it/s] 49%|####9     |85450/173481[24:11<25:37,57.25it/s] 54%|#####4    |94092/173481[27:00<24:22,54.27it/s] 55%|#####4    |94561/173481[27:11<24:14,54.27it/s] 59%|#####9    |102847/173481[30:00<22:57,51.29it/s] 60%|#####9    |103418/173481[30:11<22:45,51.29it/s] 66%|######5   |114122/173481[33:00<17:32,56.40it/s] 66%|######6   |114798/173481[33:11<17:20,56.40it/s] 72%|#######2  |125311/173481[36:00<13:34,59.14it/s] 73%|#######2  |125926/173481[36:11<13:24,59.14it/s] 78%|#######7  |135081/173481[39:00<11:18,56.60it/s] 78%|#######8  |135729/173481[39:11<11:06,56.60it/s] 84%|########3 |144889/173481[42:00<08:34,55.53it/s] 84%|########3 |145601/173481[42:12<08:22,55.53it/s] 89%|########9 |154569/173481[45:00<05:46,54.64it/s] 90%|########9 |155406/173481[45:12<05:30,54.64it/s] 95%|#########5|165597/173481[48:00<02:16,57.76it/s] 96%|#########5|166198/173481[48:12<02:06,57.76it/s]100%|##########|173481/173481[49:57<00:00,57.88it/s]
[32m[0323 22:55:23 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:2997.00 sec.
[32m[0323 22:55:23 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-2602215.
[32m[0323 22:55:25 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.97it/s]
14
[32m[0323 22:57:26 @monitor.py:363][0m QueueInput/queue_size: 49.948
[32m[0323 22:57:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.248
[32m[0323 22:57:26 @monitor.py:363][0m activation-summaries/output-rms: 0.039037
[32m[0323 22:57:26 @monitor.py:363][0m cross_entropy_loss: 1.765
[32m[0323 22:57:26 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48094
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4528e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35231
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.246e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46311
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.7683e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34691
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3414e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.46707
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0611e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34456
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0197e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47048
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.327e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34409
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7023e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.49968
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6718e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3502
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3546e-06
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.55635
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3145
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.41995
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.35702
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.34968
[32m[0323 22:57:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0323 22:57:26 @monitor.py:363][0m train-error-top1: 0.47676
[32m[0323 22:57:26 @monitor.py:363][0m val-error-top1: 0.48564
[32m[0323 22:57:26 @monitor.py:363][0m val-utt-error: 0.13351
[32m[0323 22:57:26 @monitor.py:363][0m validation_cost: 1.8502
[32m[0323 22:57:26 @monitor.py:363][0m wd_cost: 0.0016706
[32m[0323 22:57:26 @group.py:42][0m Callbacks took 123.023 sec in total. InferenceRunner: 121.473sec
[32m[0323 22:57:26 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13106/173481[03:00<36:42,72.80it/s]  8%|7         |13850/173481[03:10<36:32,72.80it/s] 15%|#4        |25920/173481[06:00<34:09,71.98it/s] 15%|#5        |26755/173481[06:10<33:58,71.98it/s] 21%|##1       |36756/173481[09:00<34:45,65.56it/s] 22%|##1       |37337/173481[09:10<34:36,65.56it/s] 27%|##7       |47520/173481[12:00<33:33,62.55it/s] 28%|##7       |48085/173481[12:10<33:24,62.55it/s] 33%|###3      |58023/173481[15:00<31:52,60.38it/s] 34%|###3      |58705/173481[15:10<31:41,60.38it/s] 40%|###9      |68571/173481[18:00<29:23,59.47it/s] 40%|###9      |69216/173481[18:10<29:13,59.47it/s] 46%|####5     |79681/173481[21:00<25:48,60.57it/s] 46%|####6     |80489/173481[21:11<25:35,60.57it/s] 53%|#####2    |91887/173481[24:00<21:15,63.99it/s] 53%|#####3    |92765/173481[24:11<21:01,63.99it/s] 60%|######    |104167/173481[27:00<17:29,66.04it/s] 60%|######    |104934/173481[27:11<17:18,66.04it/s] 67%|######7   |116971/173481[30:00<13:45,68.49it/s] 68%|######7   |117789/173481[30:11<13:33,68.49it/s] 74%|#######4  |128555/173481[33:00<11:17,66.36it/s] 75%|#######4  |129422/173481[33:11<11:03,66.36it/s] 81%|########  |139886/173481[36:00<08:40,64.60it/s] 81%|########1 |140615/173481[36:11<08:28,64.60it/s] 87%|########6 |150606/173481[39:00<06:09,61.97it/s] 87%|########7 |151270/173481[39:11<05:58,61.97it/s] 92%|#########2|160166/173481[42:00<03:52,57.20it/s] 93%|#########2|161084/173481[42:12<03:36,57.20it/s]100%|##########|173481/173481[44:53<00:00,64.40it/s]
[32m[0323 23:42:20 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:2693.63 sec.
[32m[0323 23:42:20 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-2775696.
[32m[0323 23:42:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,155.61it/s]
15
[32m[0323 23:44:21 @monitor.py:363][0m QueueInput/queue_size: 0.58731
[32m[0323 23:44:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.087
[32m[0323 23:44:21 @monitor.py:363][0m activation-summaries/output-rms: 0.038789
[32m[0323 23:44:21 @monitor.py:363][0m cross_entropy_loss: 1.7574
[32m[0323 23:44:21 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48423
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4636e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35361
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2371e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46594
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.7878e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.3483
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3393e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47028
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0804e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34596
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0014e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.4735
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3348e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34534
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7011e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50301
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6464e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35156
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3548e-06
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56918
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3158
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.42609
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36064
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35354
[32m[0323 23:44:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083137
[32m[0323 23:44:21 @monitor.py:363][0m train-error-top1: 0.46285
[32m[0323 23:44:21 @monitor.py:363][0m val-error-top1: 0.48566
[32m[0323 23:44:21 @monitor.py:363][0m val-utt-error: 0.13054
[32m[0323 23:44:21 @monitor.py:363][0m validation_cost: 1.8504
[32m[0323 23:44:21 @monitor.py:363][0m wd_cost: 0.0017241
[32m[0323 23:44:21 @group.py:42][0m Callbacks took 121.693 sec in total. InferenceRunner: 120.972sec
[32m[0323 23:44:21 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14621/173481[03:00<32:35,81.22it/s]  9%|8         |15426/173481[03:10<32:25,81.22it/s] 15%|#5        |26251/173481[06:00<34:05,71.97it/s] 16%|#5        |27066/173481[06:10<33:54,71.97it/s] 23%|##2       |39205/173481[09:00<31:05,71.97it/s] 23%|##3       |39909/173481[09:10<30:55,71.97it/s] 29%|##9       |50845/173481[12:00<30:00,68.12it/s] 30%|##9       |51538/173481[12:10<29:50,68.12it/s] 36%|###6      |62770/173481[15:00<27:28,67.16it/s] 37%|###6      |63574/173481[15:10<27:16,67.16it/s] 44%|####3     |76302/173481[18:00<22:49,70.95it/s] 44%|####4     |77112/173481[18:10<22:38,70.95it/s] 52%|#####1    |89875/173481[21:00<19:03,73.10it/s] 52%|#####2    |90690/173481[21:10<18:52,73.10it/s] 60%|#####9    |103325/173481[24:00<15:49,73.89it/s] 60%|######    |104131/173481[24:11<15:38,73.89it/s] 66%|######6   |115185/173481[27:00<13:56,69.66it/s] 67%|######6   |116002/173481[27:11<13:45,69.66it/s] 74%|#######3  |128245/173481[30:00<10:36,71.07it/s] 74%|#######4  |129066/173481[30:11<10:24,71.07it/s] 81%|########1 |141185/173481[33:00<07:31,71.48it/s] 82%|########1 |142020/173481[33:11<07:20,71.48it/s] 89%|########9 |154538/173481[36:00<04:20,72.80it/s] 90%|########9 |155530/173481[36:11<04:06,72.80it/s] 97%|#########7|169070/173481[39:00<00:57,76.56it/s] 98%|#########7|169759/173481[39:11<00:48,76.56it/s]100%|##########|173481/173481[40:15<00:00,71.82it/s]
[32m[0324 00:24:37 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:2415.47 sec.
[32m[0324 00:24:37 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-2949177.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.51it/s]
16
[32m[0324 00:26:30 @monitor.py:363][0m QueueInput/queue_size: 0.54459
[32m[0324 00:26:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.173
[32m[0324 00:26:30 @monitor.py:363][0m activation-summaries/output-rms: 0.039082
[32m[0324 00:26:30 @monitor.py:363][0m cross_entropy_loss: 1.7763
[32m[0324 00:26:30 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4864
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4754e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35435
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2367e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46742
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8566e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34905
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3496e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47199
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0666e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3465
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0099e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47582
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3107e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34597
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.6972e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50502
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6473e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35226
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3635e-06
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57795
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3165
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.42992
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36283
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35584
[32m[0324 00:26:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 00:26:30 @monitor.py:363][0m train-error-top1: 0.47411
[32m[0324 00:26:30 @monitor.py:363][0m val-error-top1: 0.48532
[32m[0324 00:26:30 @monitor.py:363][0m val-utt-error: 0.13054
[32m[0324 00:26:30 @monitor.py:363][0m validation_cost: 1.8497
[32m[0324 00:26:30 @monitor.py:363][0m wd_cost: 0.00035191
[32m[0324 00:26:30 @group.py:42][0m Callbacks took 112.646 sec in total. InferenceRunner: 112.377sec
[32m[0324 00:26:30 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13246/173481[03:00<36:17,73.59it/s]  8%|8         |14073/173481[03:10<36:06,73.59it/s] 15%|#4        |25224/173481[06:00<35:21,69.89it/s] 15%|#4        |25808/173481[06:10<35:12,69.89it/s] 20%|##        |35094/173481[09:00<37:32,61.45it/s] 21%|##        |35711/173481[09:10<37:21,61.45it/s] 26%|##5       |44954/173481[12:00<36:58,57.92it/s] 26%|##6       |45797/173481[12:10<36:44,57.92it/s] 32%|###1      |54994/173481[15:00<34:45,56.83it/s] 32%|###2      |55583/173481[15:10<34:34,56.83it/s] 38%|###7      |65094/173481[18:00<31:59,56.47it/s] 38%|###7      |65750/173481[18:10<31:47,56.47it/s] 44%|####3     |76229/173481[21:00<27:27,59.04it/s] 44%|####4     |76893/173481[21:11<27:15,59.04it/s] 50%|#####     |87190/173481[24:00<23:59,59.95it/s] 51%|#####     |87906/173481[24:11<23:47,59.95it/s] 57%|#####6    |98094/173481[27:00<20:51,60.26it/s] 57%|#####6    |98771/173481[27:11<20:39,60.26it/s] 63%|######2   |108959/173481[30:00<17:49,60.31it/s] 63%|######3   |109691/173481[30:11<17:37,60.31it/s] 69%|######9   |120470/173481[33:00<14:13,62.07it/s] 70%|######9   |121113/173481[33:11<14:03,62.07it/s] 76%|#######5  |131227/173481[36:00<11:33,60.90it/s] 76%|#######6  |131961/173481[36:11<11:21,60.90it/s] 82%|########1 |142078/173481[39:00<08:38,60.59it/s] 82%|########2 |142838/173481[39:11<08:25,60.59it/s] 88%|########8 |153188/173481[42:00<05:31,61.15it/s] 89%|########8 |153940/173481[42:12<05:19,61.15it/s] 95%|#########4|164580/173481[45:00<02:23,62.20it/s] 95%|#########5|165327/173481[45:12<02:11,62.20it/s]100%|##########|173481/173481[47:49<00:00,60.47it/s]
[32m[0324 01:14:19 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:2869.11 sec.
[32m[0324 01:14:19 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-3122658.
[32m[0324 01:14:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.55it/s]
17
[32m[0324 01:16:20 @monitor.py:363][0m QueueInput/queue_size: 0.82375
[32m[0324 01:16:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.736
[32m[0324 01:16:20 @monitor.py:363][0m activation-summaries/output-rms: 0.039187
[32m[0324 01:16:20 @monitor.py:363][0m cross_entropy_loss: 1.7386
[32m[0324 01:16:20 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4875
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.473e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35475
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2298e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46839
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8504e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34933
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3387e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47354
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0778e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34687
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0097e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47704
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.328e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34632
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.707e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50645
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6373e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35261
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3699e-06
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58464
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.317
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.43286
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36442
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35752
[32m[0324 01:16:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 01:16:20 @monitor.py:363][0m train-error-top1: 0.46009
[32m[0324 01:16:20 @monitor.py:363][0m val-error-top1: 0.48514
[32m[0324 01:16:20 @monitor.py:363][0m val-utt-error: 0.1307
[32m[0324 01:16:20 @monitor.py:363][0m validation_cost: 1.846
[32m[0324 01:16:20 @monitor.py:363][0m wd_cost: 0.00035731
[32m[0324 01:16:20 @group.py:42][0m Callbacks took 121.842 sec in total. InferenceRunner: 120.245sec
[32m[0324 01:16:20 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13264/173481[03:00<36:14,73.69it/s]  8%|8         |13999/173481[03:10<36:04,73.69it/s] 15%|#4        |25418/173481[06:00<35:01,70.47it/s] 15%|#4        |25953/173481[06:10<34:53,70.47it/s] 21%|##        |35943/173481[09:00<35:52,63.91it/s] 21%|##1       |36586/173481[09:10<35:42,63.91it/s] 27%|##6       |46228/173481[12:00<35:10,60.30it/s] 27%|##6       |46597/173481[12:10<35:04,60.30it/s] 33%|###2      |57019/173481[15:00<32:16,60.13it/s] 33%|###3      |57581/173481[15:10<32:07,60.13it/s] 39%|###9      |68048/173481[18:00<28:57,60.69it/s] 40%|###9      |68679/173481[18:10<28:46,60.69it/s] 45%|####5     |78649/173481[21:00<26:26,59.78it/s] 46%|####5     |79262/173481[21:11<26:16,59.78it/s] 51%|#####1    |88723/173481[24:00<24:26,57.81it/s] 51%|#####1    |89328/173481[24:11<24:15,57.81it/s] 57%|#####6    |98534/173481[27:00<22:15,56.10it/s] 57%|#####7    |99174/173481[27:11<22:04,56.10it/s] 63%|######2   |109007/173481[30:00<18:48,57.12it/s] 63%|######3   |109687/173481[30:11<18:36,57.12it/s] 69%|######9   |119798/173481[33:00<15:17,58.50it/s] 69%|######9   |120467/173481[33:11<15:06,58.50it/s] 75%|#######4  |129963/173481[36:00<12:37,57.46it/s] 75%|#######5  |130628/173481[36:11<12:25,57.46it/s] 81%|########1 |140588/173481[39:00<09:24,58.23it/s] 81%|########1 |141367/173481[39:12<09:11,58.23it/s] 87%|########7 |151742/173481[42:00<06:02,60.04it/s] 88%|########7 |152512/173481[42:12<05:49,60.04it/s] 94%|#########4|163208/173481[45:00<02:46,61.81it/s] 95%|#########4|163974/173481[45:12<02:33,61.81it/s]100%|##########|173481/173481[47:53<00:00,60.38it/s]
[32m[0324 02:04:14 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:2873.22 sec.
[32m[0324 02:04:14 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-3296139.
[32m[0324 02:04:14 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:24<00:00,130.24it/s]
18
[32m[0324 02:06:39 @monitor.py:363][0m QueueInput/queue_size: 0.70596
[32m[0324 02:06:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.056
[32m[0324 02:06:39 @monitor.py:363][0m activation-summaries/output-rms: 0.038496
[32m[0324 02:06:39 @monitor.py:363][0m cross_entropy_loss: 1.7496
[32m[0324 02:06:39 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48875
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4858e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.355
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2215e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46951
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8316e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34977
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3322e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47503
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0817e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34735
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0033e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47846
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.31e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34682
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7127e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50783
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6524e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35296
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3641e-06
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59136
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3177
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.43585
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36611
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.35931
[32m[0324 02:06:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 02:06:39 @monitor.py:363][0m train-error-top1: 0.46218
[32m[0324 02:06:39 @monitor.py:363][0m val-error-top1: 0.48945
[32m[0324 02:06:39 @monitor.py:363][0m val-utt-error: 0.13495
[32m[0324 02:06:39 @monitor.py:363][0m validation_cost: 1.8635
[32m[0324 02:06:39 @monitor.py:363][0m wd_cost: 0.00036285
[32m[0324 02:06:39 @group.py:42][0m Callbacks took 145.337 sec in total. InferenceRunner: 144.538sec
[32m[0324 02:06:39 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13930/173481[03:00<34:21,77.38it/s]  8%|8         |14675/173481[03:10<34:12,77.38it/s] 14%|#4        |24857/173481[06:00<36:24,68.03it/s] 15%|#4        |25451/173481[06:10<36:15,68.03it/s] 21%|##        |36420/173481[09:00<34:34,66.08it/s] 21%|##1       |37034/173481[09:10<34:24,66.08it/s] 27%|##7       |47153/173481[12:00<33:35,62.69it/s] 28%|##7       |47821/173481[12:10<33:24,62.69it/s] 34%|###4      |59373/173481[15:00<29:10,65.18it/s] 35%|###4      |60121/173481[15:10<28:59,65.18it/s] 42%|####1     |72057/173481[18:00<24:58,67.69it/s] 42%|####1     |72251/173481[18:10<24:55,67.69it/s] 49%|####8     |84277/173481[21:00<21:56,67.78it/s] 49%|####9     |85066/173481[21:11<21:44,67.78it/s] 56%|#####6    |97287/173481[24:00<18:09,69.96it/s] 57%|#####6    |98062/173481[24:11<17:58,69.96it/s] 64%|######3   |110172/173481[27:00<14:54,70.76it/s] 64%|######3   |110972/173481[27:11<14:43,70.76it/s] 71%|#######   |122902/173481[30:00<11:55,70.74it/s] 71%|#######1  |123712/173481[30:11<11:43,70.74it/s] 77%|#######7  |134401/173481[33:00<09:42,67.13it/s] 78%|#######7  |135186/173481[33:11<09:30,67.13it/s] 86%|########5 |148400/173481[36:00<05:48,72.06it/s] 86%|########6 |149382/173481[36:11<05:34,72.06it/s] 94%|#########3|162718/173481[39:00<02:22,75.62it/s] 94%|#########4|163650/173481[39:12<02:10,75.62it/s]100%|##########|173481/173481[41:15<00:00,70.08it/s]
[32m[0324 02:47:54 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:2475.46 sec.
[32m[0324 02:47:55 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-3469620.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.66it/s]
19
[32m[0324 02:49:53 @monitor.py:363][0m QueueInput/queue_size: 0.93383
[32m[0324 02:49:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.657
[32m[0324 02:49:53 @monitor.py:363][0m activation-summaries/output-rms: 0.04046
[32m[0324 02:49:53 @monitor.py:363][0m cross_entropy_loss: 1.7148
[32m[0324 02:49:53 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48933
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4951e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35519
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.22e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.46997
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8256e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.34992
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3243e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47541
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0724e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3475
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0115e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47903
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3147e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34696
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7042e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50848
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6492e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35317
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3625e-06
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59501
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.318
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.43725
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36685
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36008
[32m[0324 02:49:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 02:49:53 @monitor.py:363][0m train-error-top1: 0.46401
[32m[0324 02:49:53 @monitor.py:363][0m val-error-top1: 0.48278
[32m[0324 02:49:53 @monitor.py:363][0m val-utt-error: 0.13006
[32m[0324 02:49:53 @monitor.py:363][0m validation_cost: 1.8351
[32m[0324 02:49:53 @monitor.py:363][0m wd_cost: 7.3135e-05
[32m[0324 02:49:53 @group.py:42][0m Callbacks took 118.867 sec in total. InferenceRunner: 118.645sec
[32m[0324 02:49:53 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13730/173481[03:00<34:54,76.28it/s]  8%|8         |14384/173481[03:10<34:45,76.28it/s] 15%|#5        |26311/173481[06:00<33:37,72.94it/s] 16%|#5        |27162/173481[06:10<33:25,72.94it/s] 24%|##3       |40966/173481[09:00<28:42,76.94it/s] 24%|##4       |41809/173481[09:10<28:31,76.94it/s] 32%|###1      |55456/173481[12:00<25:00,78.68it/s] 32%|###2      |56304/173481[12:10<24:49,78.68it/s] 40%|####      |70015/173481[15:00<21:37,79.77it/s] 41%|####      |70885/173481[15:10<21:26,79.77it/s] 47%|####7     |82187/173481[18:00<20:47,73.19it/s] 48%|####7     |83072/173481[18:10<20:35,73.19it/s] 54%|#####4    |93801/173481[21:00<19:21,68.58it/s] 54%|#####4    |94517/173481[21:11<19:11,68.58it/s] 60%|######    |104854/173481[24:00<17:39,64.80it/s] 61%|######    |105529/173481[24:11<17:28,64.80it/s] 67%|######6   |115946/173481[27:00<15:10,63.17it/s] 67%|######7   |116635/173481[27:11<14:59,63.17it/s] 73%|#######3  |127172/173481[30:00<12:17,62.76it/s] 74%|#######3  |127865/173481[30:11<12:06,62.76it/s] 80%|#######9  |138133/173481[33:00<09:31,61.81it/s] 80%|########  |138852/173481[33:11<09:20,61.81it/s] 86%|########5 |149182/173481[36:00<06:34,61.60it/s] 86%|########6 |149851/173481[36:11<06:23,61.60it/s] 92%|#########2|159866/173481[39:00<03:45,60.45it/s] 93%|#########2|160653/173481[39:11<03:32,60.45it/s] 99%|#########9|172539/173481[42:00<00:14,65.05it/s]100%|#########9|173361/173481[42:12<00:01,65.05it/s]100%|##########|173481/173481[42:13<00:00,68.46it/s]
[32m[0324 03:32:07 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:2534.00 sec.
[32m[0324 03:32:08 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-3643101.
[32m[0324 03:32:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.36it/s]
20
[32m[0324 03:34:08 @monitor.py:363][0m QueueInput/queue_size: 0.54787
[32m[0324 03:34:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.006
[32m[0324 03:34:08 @monitor.py:363][0m activation-summaries/output-rms: 0.038893
[32m[0324 03:34:08 @monitor.py:363][0m cross_entropy_loss: 1.7507
[32m[0324 03:34:08 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.48985
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4864e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35535
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2242e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47043
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8172e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35007
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3233e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47596
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0737e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34764
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0111e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47926
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3069e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34697
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.6996e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50908
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6563e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35333
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3685e-06
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59844
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3183
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.43866
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3676
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36087
[32m[0324 03:34:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 03:34:08 @monitor.py:363][0m train-error-top1: 0.46274
[32m[0324 03:34:08 @monitor.py:363][0m val-error-top1: 0.48554
[32m[0324 03:34:08 @monitor.py:363][0m val-utt-error: 0.13479
[32m[0324 03:34:08 @monitor.py:363][0m validation_cost: 1.8592
[32m[0324 03:34:08 @monitor.py:363][0m wd_cost: 7.3681e-05
[32m[0324 03:34:08 @group.py:42][0m Callbacks took 120.173 sec in total. InferenceRunner: 118.871sec
[32m[0324 03:34:08 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12556/173481[03:00<38:27,69.75it/s]  8%|7         |13306/173481[03:10<38:16,69.75it/s] 15%|#4        |25695/173481[06:00<34:31,71.33it/s] 15%|#5        |26430/173481[06:10<34:21,71.33it/s] 21%|##1       |36531/173481[09:00<34:57,65.29it/s] 21%|##1       |37159/173481[09:10<34:47,65.29it/s] 27%|##6       |46821/173481[12:00<34:37,60.96it/s] 27%|##7       |47454/173481[12:10<34:27,60.96it/s] 34%|###3      |58376/173481[15:00<30:40,62.53it/s] 34%|###4      |59134/173481[15:10<30:28,62.53it/s] 41%|####      |70315/173481[18:00<26:42,64.37it/s] 41%|####      |70974/173481[18:10<26:32,64.37it/s] 47%|####6     |81296/173481[21:00<24:31,62.64it/s] 47%|####7     |81973/173481[21:11<24:20,62.64it/s] 53%|#####3    |92421/173481[24:00<21:42,62.22it/s] 54%|#####3    |93105/173481[24:11<21:31,62.22it/s] 60%|#####9    |103755/173481[27:00<18:34,62.58it/s] 60%|######    |104470/173481[27:11<18:22,62.58it/s] 66%|######6   |114914/173481[30:00<15:40,62.29it/s] 67%|######6   |115834/173481[30:11<15:25,62.29it/s] 73%|#######3  |126919/173481[33:00<12:02,64.41it/s] 74%|#######3  |127642/173481[33:11<11:51,64.41it/s] 80%|#######9  |138095/173481[36:00<09:19,63.23it/s] 80%|########  |138809/173481[36:11<09:08,63.23it/s] 86%|########6 |149415/173481[39:00<06:21,63.06it/s] 87%|########6 |150175/173481[39:12<06:09,63.06it/s] 93%|#########2|160818/173481[42:00<03:20,63.20it/s] 93%|#########3|161547/173481[42:12<03:08,63.20it/s] 99%|#########9|171898/173481[45:00<00:25,62.37it/s]100%|#########9|172852/173481[45:12<00:10,62.37it/s]100%|##########|173481/173481[45:21<00:00,63.74it/s]
[32m[0324 04:19:29 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:2721.87 sec.
[32m[0324 04:19:30 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-3816582.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.31it/s]
21
[32m[0324 04:21:29 @monitor.py:363][0m QueueInput/queue_size: 0.76914
[32m[0324 04:21:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.488
[32m[0324 04:21:29 @monitor.py:363][0m activation-summaries/output-rms: 0.038904
[32m[0324 04:21:29 @monitor.py:363][0m cross_entropy_loss: 1.774
[32m[0324 04:21:29 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49028
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4973e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35547
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2261e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47079
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8189e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35013
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3231e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47636
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0739e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34768
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0006e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47967
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3123e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34706
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50945
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6628e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3534
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3673e-06
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60148
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3186
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4399
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36827
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36157
[32m[0324 04:21:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 04:21:29 @monitor.py:363][0m train-error-top1: 0.47277
[32m[0324 04:21:29 @monitor.py:363][0m val-error-top1: 0.48353
[32m[0324 04:21:29 @monitor.py:363][0m val-utt-error: 0.12948
[32m[0324 04:21:29 @monitor.py:363][0m validation_cost: 1.8427
[32m[0324 04:21:29 @monitor.py:363][0m wd_cost: 7.4166e-05
[32m[0324 04:21:29 @group.py:42][0m Callbacks took 119.882 sec in total. InferenceRunner: 119.663sec
[32m[0324 04:21:29 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14207/173481[03:00<33:38,78.93it/s]  9%|8         |14996/173481[03:10<33:28,78.93it/s] 16%|#6        |27890/173481[06:00<31:19,77.44it/s] 16%|#6        |28470/173481[06:10<31:12,77.44it/s] 22%|##2       |38884/173481[09:00<32:50,68.29it/s] 23%|##2       |39556/173481[09:10<32:41,68.29it/s] 29%|##8       |49575/173481[12:00<32:30,63.53it/s] 29%|##8       |50193/173481[12:10<32:20,63.53it/s] 35%|###4      |60343/173481[15:00<30:36,61.62it/s] 35%|###5      |60972/173481[15:10<30:25,61.62it/s] 42%|####1     |72095/173481[18:00<26:39,63.40it/s] 42%|####1     |72857/173481[18:10<26:27,63.40it/s] 48%|####8     |83817/173481[21:00<23:15,64.25it/s] 49%|####8     |84505/173481[21:11<23:04,64.25it/s] 55%|#####5    |95451/173481[24:00<20:10,64.44it/s] 55%|#####5    |96189/173481[24:11<19:59,64.44it/s] 62%|######1   |106949/173481[27:00<17:17,64.16it/s] 62%|######2   |107761/173481[27:11<17:04,64.16it/s] 69%|######8   |119564/173481[30:00<13:24,66.99it/s] 69%|######9   |120378/173481[30:11<13:12,66.99it/s] 76%|#######6  |132109/173481[33:00<10:05,68.31it/s] 77%|#######6  |132904/173481[33:11<09:54,68.31it/s] 83%|########3 |144624/173481[36:00<06:58,68.91it/s] 84%|########3 |145617/173481[36:11<06:44,68.91it/s] 90%|######### |156899/173481[39:00<04:01,68.54it/s] 91%|######### |157023/173481[39:12<04:00,68.54it/s] 97%|#########7|169032/173481[42:00<01:05,67.97it/s] 98%|#########7|169825/173481[42:12<00:53,67.97it/s]100%|##########|173481/173481[43:08<00:00,67.01it/s]
[32m[0324 05:04:38 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:2588.78 sec.
[32m[0324 05:04:38 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-3990063.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.57it/s]
22
[32m[0324 05:06:36 @monitor.py:363][0m QueueInput/queue_size: 0.53378
[32m[0324 05:06:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.598
[32m[0324 05:06:36 @monitor.py:363][0m activation-summaries/output-rms: 0.039169
[32m[0324 05:06:36 @monitor.py:363][0m cross_entropy_loss: 1.736
[32m[0324 05:06:36 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49055
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4969e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35554
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2263e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47091
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8185e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35014
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3225e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47668
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0743e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34771
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 6.0003e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.47991
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.313e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34711
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7017e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50973
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.656e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35345
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3685e-06
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60324
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3187
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44056
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3686
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36193
[32m[0324 05:06:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 05:06:36 @monitor.py:363][0m train-error-top1: 0.46044
[32m[0324 05:06:36 @monitor.py:363][0m val-error-top1: 0.48498
[32m[0324 05:06:36 @monitor.py:363][0m val-utt-error: 0.12964
[32m[0324 05:06:36 @monitor.py:363][0m validation_cost: 1.846
[32m[0324 05:06:36 @monitor.py:363][0m wd_cost: 1.4887e-05
[32m[0324 05:06:36 @group.py:42][0m Callbacks took 118.322 sec in total. InferenceRunner: 117.967sec
[32m[0324 05:06:36 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14735/173481[03:00<32:19,81.86it/s]  9%|8         |15562/173481[03:10<32:09,81.86it/s] 15%|#5        |26145/173481[06:00<34:22,71.45it/s] 15%|#5        |26869/173481[06:10<34:11,71.45it/s] 22%|##1       |38038/173481[09:00<32:52,68.66it/s] 22%|##2       |38899/173481[09:10<32:40,68.66it/s] 29%|##9       |50566/173481[12:00<29:38,69.12it/s] 30%|##9       |51287/173481[12:10<29:27,69.12it/s] 36%|###6      |62795/173481[15:00<26:55,68.53it/s] 37%|###6      |63563/173481[15:10<26:44,68.53it/s] 44%|####3     |76311/173481[18:00<22:36,71.66it/s] 44%|####4     |77188/173481[18:10<22:23,71.66it/s] 51%|#####1    |88907/173481[21:00<19:54,70.81it/s] 52%|#####1    |89778/173481[21:11<19:42,70.81it/s] 59%|#####8    |101769/173481[24:00<16:48,71.13it/s] 59%|#####9    |102640/173481[24:11<16:35,71.13it/s] 67%|######6   |115615/173481[27:00<13:02,73.91it/s] 67%|######7   |116484/173481[27:11<12:51,73.91it/s] 74%|#######3  |128026/173481[30:00<10:37,71.34it/s] 74%|#######4  |128823/173481[30:11<10:25,71.34it/s] 81%|########  |140353/173481[33:00<07:54,69.88it/s] 81%|########1 |141170/173481[33:11<07:42,69.88it/s] 89%|########8 |153684/173481[36:00<04:35,71.91it/s] 89%|########9 |154668/173481[36:11<04:21,71.91it/s] 97%|#########7|168447/173481[39:00<01:05,76.63it/s] 98%|#########7|169476/173481[39:12<00:52,76.63it/s]100%|##########|173481/173481[39:58<00:00,72.33it/s]
[32m[0324 05:46:35 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:2398.34 sec.
[32m[0324 05:46:35 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-4163544.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,155.62it/s]
23
[32m[0324 05:48:36 @monitor.py:363][0m QueueInput/queue_size: 49.938
[32m[0324 05:48:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.123
[32m[0324 05:48:36 @monitor.py:363][0m activation-summaries/output-rms: 0.040087
[32m[0324 05:48:36 @monitor.py:363][0m cross_entropy_loss: 1.654
[32m[0324 05:48:36 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.4908
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4922e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35556
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2258e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47115
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8254e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35018
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3235e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47702
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0747e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34776
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.999e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48025
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3129e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34721
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7009e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.50996
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6532e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3535
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3709e-06
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60502
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.319
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4412
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36895
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36229
[32m[0324 05:48:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 05:48:36 @monitor.py:363][0m train-error-top1: 0.4388
[32m[0324 05:48:36 @monitor.py:363][0m val-error-top1: 0.47875
[32m[0324 05:48:36 @monitor.py:363][0m val-utt-error: 0.12501
[32m[0324 05:48:36 @monitor.py:363][0m validation_cost: 1.8175
[32m[0324 05:48:36 @monitor.py:363][0m wd_cost: 1.4942e-05
[32m[0324 05:48:36 @group.py:42][0m Callbacks took 121.129 sec in total. InferenceRunner: 120.968sec
[32m[0324 05:48:36 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16073/173481[03:00<29:22,89.29it/s] 10%|9         |16944/173481[03:10<29:13,89.29it/s] 18%|#8        |31826/173481[06:00<26:42,88.39it/s] 19%|#8        |32612/173481[06:10<26:33,88.39it/s] 27%|##6       |46497/173481[09:00<24:58,84.73it/s] 27%|##6       |46606/173481[09:10<24:57,84.73it/s] 33%|###3      |57667/173481[12:00<26:56,71.64it/s] 34%|###3      |58429/173481[12:10<26:46,71.64it/s] 42%|####2     |73641/173481[15:00<20:59,79.28it/s] 43%|####2     |74571/173481[15:10<20:47,79.28it/s] 52%|#####1    |89974/173481[18:00<16:26,84.62it/s] 52%|#####2    |90956/173481[18:10<16:15,84.62it/s] 61%|######1   |106121/173481[21:00<12:53,87.09it/s] 62%|######1   |107091/173481[21:11<12:42,87.09it/s] 70%|#######   |121999/173481[24:00<09:47,87.64it/s] 71%|#######   |122721/173481[24:11<09:39,87.64it/s] 79%|#######8  |136657/173481[27:00<07:16,84.42it/s] 79%|#######9  |137660/173481[27:11<07:04,84.42it/s] 88%|########8 |152812/173481[30:00<03:57,87.00it/s] 89%|########8 |153852/173481[30:11<03:45,87.00it/s] 97%|#########6|168116/173481[33:00<01:02,86.00it/s] 97%|#########7|169066/173481[33:11<00:51,86.00it/s]100%|##########|173481/173481[34:05<00:00,84.81it/s]
[32m[0324 06:22:41 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:2045.48 sec.
[32m[0324 06:22:42 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-4337025.
[32m[0324 06:22:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.19it/s]
24
[32m[0324 06:24:37 @monitor.py:363][0m QueueInput/queue_size: 0.99494
[32m[0324 06:24:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.173
[32m[0324 06:24:37 @monitor.py:363][0m activation-summaries/output-rms: 0.040662
[32m[0324 06:24:37 @monitor.py:363][0m cross_entropy_loss: 1.7128
[32m[0324 06:24:37 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49097
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4938e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35558
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2267e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4713
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8248e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35022
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3245e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47713
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0757e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.3478
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48045
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.316e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34723
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7013e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51015
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6545e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35353
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3708e-06
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60632
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3191
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44158
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36914
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36248
[32m[0324 06:24:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 06:24:37 @monitor.py:363][0m train-error-top1: 0.46241
[32m[0324 06:24:37 @monitor.py:363][0m val-error-top1: 0.48276
[32m[0324 06:24:37 @monitor.py:363][0m val-utt-error: 0.1273
[32m[0324 06:24:37 @monitor.py:363][0m validation_cost: 1.8396
[32m[0324 06:24:37 @monitor.py:363][0m wd_cost: 2.9959e-06
[32m[0324 06:24:37 @group.py:42][0m Callbacks took 115.851 sec in total. InferenceRunner: 114.647sec
[32m[0324 06:24:37 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14027/173481[03:00<34:06,77.93it/s]  9%|8         |14848/173481[03:10<33:55,77.93it/s] 17%|#6        |28954/173481[06:00<29:58,80.35it/s] 17%|#7        |29785/173481[06:10<29:48,80.35it/s] 26%|##5       |44345/173481[09:00<25:58,82.84it/s] 26%|##6       |45246/173481[09:10<25:47,82.84it/s] 35%|###5      |60745/173481[12:00<21:39,86.78it/s] 36%|###5      |61616/173481[12:10<21:29,86.78it/s] 43%|####3     |75255/173481[15:00<19:35,83.58it/s] 44%|####3     |76109/173481[15:10<19:25,83.58it/s] 51%|#####     |88446/173481[18:00<18:08,78.09it/s] 51%|#####1    |89315/173481[18:10<17:57,78.09it/s] 58%|#####8    |100699/173481[21:00<16:40,72.74it/s] 58%|#####8    |101416/173481[21:11<16:30,72.74it/s] 65%|######4   |112506/173481[24:00<14:43,68.98it/s] 65%|######5   |113260/173481[24:11<14:33,68.98it/s] 72%|#######1  |124484/173481[27:00<12:03,67.74it/s] 72%|#######2  |125245/173481[27:11<11:52,67.74it/s] 78%|#######8  |136109/173481[30:00<09:25,66.12it/s] 79%|#######8  |136640/173481[30:11<09:17,66.12it/s] 85%|########5 |147670/173481[33:00<06:36,65.16it/s] 86%|########5 |148422/173481[33:11<06:24,65.16it/s] 92%|#########1|158966/173481[36:00<03:47,63.93it/s] 92%|#########2|159722/173481[36:11<03:35,63.93it/s] 99%|#########9|171871/173481[39:00<00:23,67.58it/s]100%|#########9|172680/173481[39:12<00:11,67.58it/s]100%|##########|173481/173481[39:24<00:00,73.38it/s]
[32m[0324 07:04:01 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:2364.02 sec.
[32m[0324 07:04:01 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.40it/s]
25
[32m[0324 07:06:03 @monitor.py:363][0m QueueInput/queue_size: 0.77901
[32m[0324 07:06:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.118
[32m[0324 07:06:03 @monitor.py:363][0m activation-summaries/output-rms: 0.03894
[32m[0324 07:06:03 @monitor.py:363][0m cross_entropy_loss: 1.7391
[32m[0324 07:06:03 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49106
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4917e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.3556
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2262e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4714
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8274e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35024
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3257e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4772
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0742e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34783
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9989e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48051
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3134e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34722
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51025
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6558e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35356
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3715e-06
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6071
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3192
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44189
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36929
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36265
[32m[0324 07:06:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 07:06:03 @monitor.py:363][0m train-error-top1: 0.45832
[32m[0324 07:06:03 @monitor.py:363][0m val-error-top1: 0.48469
[32m[0324 07:06:03 @monitor.py:363][0m val-utt-error: 0.13442
[32m[0324 07:06:03 @monitor.py:363][0m validation_cost: 1.8527
[32m[0324 07:06:03 @monitor.py:363][0m wd_cost: 3.0008e-06
[32m[0324 07:06:03 @group.py:42][0m Callbacks took 121.349 sec in total. InferenceRunner: 121.130sec
[32m[0324 07:06:03 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12474/173481[03:00<38:43,69.30it/s]  8%|7         |13218/173481[03:10<38:32,69.30it/s] 15%|#4        |25575/173481[06:00<34:43,70.99it/s] 15%|#5        |26309/173481[06:10<34:33,70.99it/s] 22%|##1       |37524/173481[09:00<33:01,68.61it/s] 22%|##1       |38124/173481[09:10<32:52,68.61it/s] 28%|##7       |48145/173481[12:00<32:55,63.44it/s] 28%|##8       |48791/173481[12:10<32:45,63.44it/s] 34%|###4      |59371/173481[15:00<30:14,62.90it/s] 35%|###4      |60048/173481[15:10<30:03,62.90it/s] 41%|####      |70360/173481[18:00<27:44,61.96it/s] 41%|####      |71055/173481[18:10<27:33,61.96it/s] 47%|####7     |81849/173481[21:00<24:17,62.88it/s] 48%|####7     |82545/173481[21:11<24:06,62.88it/s] 54%|#####3    |93572/173481[24:00<20:48,63.98it/s] 54%|#####4    |94311/173481[24:11<20:37,63.98it/s] 61%|######    |105059/173481[27:00<17:50,63.90it/s] 61%|######    |105810/173481[27:11<17:39,63.90it/s] 67%|######7   |116802/173481[30:00<14:37,64.56it/s] 68%|######7   |117529/173481[30:11<14:26,64.56it/s] 74%|#######3  |127859/173481[33:00<12:04,62.95it/s] 74%|#######4  |128580/173481[33:11<11:53,62.95it/s] 80%|#######9  |138614/173481[36:00<09:28,61.31it/s] 80%|########  |139335/173481[36:11<09:16,61.31it/s] 86%|########6 |149450/173481[39:00<06:35,60.74it/s] 87%|########6 |150194/173481[39:12<06:23,60.74it/s] 93%|#########2|160819/173481[42:00<03:24,61.93it/s] 93%|#########3|161594/173481[42:12<03:11,61.93it/s] 99%|#########8|171482/173481[45:00<00:33,60.55it/s] 99%|#########9|172372/173481[45:12<00:18,60.55it/s]100%|##########|173481/173481[45:27<00:00,63.61it/s]
[32m[0324 07:51:30 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:2727.38 sec.
[32m[0324 07:51:30 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:23<00:00,130.74it/s]
26
[32m[0324 07:53:54 @monitor.py:363][0m QueueInput/queue_size: 0.69204
[32m[0324 07:53:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.316
[32m[0324 07:53:54 @monitor.py:363][0m activation-summaries/output-rms: 0.039187
[32m[0324 07:53:54 @monitor.py:363][0m cross_entropy_loss: 1.7711
[32m[0324 07:53:54 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49116
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4907e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35562
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2269e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47148
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8224e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35026
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3255e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47729
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0723e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34781
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9979e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.4806
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3168e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34722
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.701e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51034
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.658e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35357
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3715e-06
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60791
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3192
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44221
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36946
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36283
[32m[0324 07:53:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 07:53:54 @monitor.py:363][0m train-error-top1: 0.46844
[32m[0324 07:53:54 @monitor.py:363][0m val-error-top1: 0.48542
[32m[0324 07:53:54 @monitor.py:363][0m val-utt-error: 0.13139
[32m[0324 07:53:54 @monitor.py:363][0m validation_cost: 1.8484
[32m[0324 07:53:54 @monitor.py:363][0m wd_cost: 3.0059e-06
[32m[0324 07:53:54 @group.py:42][0m Callbacks took 144.266 sec in total. InferenceRunner: 143.978sec
[32m[0324 07:53:54 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13714/173481[03:00<34:57,76.18it/s]  8%|8         |14453/173481[03:10<34:47,76.18it/s] 15%|#5        |26798/173481[06:00<32:51,74.39it/s] 16%|#5        |27529/173481[06:10<32:41,74.39it/s] 23%|##2       |39657/173481[09:00<30:36,72.89it/s] 23%|##3       |40399/173481[09:10<30:25,72.89it/s] 29%|##9       |51090/173481[12:00<30:03,67.88it/s] 30%|##9       |51753/173481[12:10<29:53,67.88it/s] 36%|###5      |61902/173481[15:00<29:10,63.73it/s] 36%|###6      |62598/173481[15:10<28:59,63.73it/s] 43%|####2     |73754/173481[18:00<25:39,64.77it/s] 43%|####2     |74487/173481[18:10<25:28,64.77it/s] 49%|####9     |85712/173481[21:00<22:18,65.59it/s] 50%|####9     |86461/173481[21:11<22:06,65.59it/s] 56%|#####6    |97351/173481[24:00<19:29,65.12it/s] 57%|#####6    |98044/173481[24:11<19:18,65.12it/s] 63%|######2   |108598/173481[27:00<16:57,63.77it/s] 63%|######3   |109295/173481[27:11<16:46,63.77it/s] 70%|######9   |120741/173481[30:00<13:24,65.56it/s] 70%|######9   |121435/173481[30:11<13:13,65.56it/s] 76%|#######6  |132045/173481[33:00<10:45,64.15it/s] 77%|#######6  |132793/173481[33:11<10:34,64.15it/s] 83%|########2 |143687/173481[36:00<07:42,64.41it/s] 83%|########3 |144485/173481[36:11<07:30,64.41it/s] 89%|########9 |154559/173481[39:00<05:03,62.34it/s] 90%|########9 |155564/173481[39:12<04:47,62.34it/s] 96%|#########6|167294/173481[42:00<01:33,66.27it/s] 97%|#########6|168086/173481[42:12<01:21,66.27it/s]100%|##########|173481/173481[43:34<00:00,66.36it/s]
[32m[0324 08:37:28 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:2614.15 sec.
[32m[0324 08:37:29 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-4857468.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.06it/s]
27
[32m[0324 08:39:37 @monitor.py:363][0m QueueInput/queue_size: 0.72378
[32m[0324 08:39:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.301
[32m[0324 08:39:37 @monitor.py:363][0m activation-summaries/output-rms: 0.039395
[32m[0324 08:39:37 @monitor.py:363][0m cross_entropy_loss: 1.7298
[32m[0324 08:39:37 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49124
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4933e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35562
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2262e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47152
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8222e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35025
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3254e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47736
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0728e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34782
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9979e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48066
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3169e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34722
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7009e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51042
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6576e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35358
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3718e-06
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60841
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44239
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36955
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36293
[32m[0324 08:39:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 08:39:37 @monitor.py:363][0m train-error-top1: 0.46595
[32m[0324 08:39:37 @monitor.py:363][0m val-error-top1: 0.48372
[32m[0324 08:39:37 @monitor.py:363][0m val-utt-error: 0.12836
[32m[0324 08:39:37 @monitor.py:363][0m validation_cost: 1.84
[32m[0324 08:39:37 @monitor.py:363][0m wd_cost: 6.0179e-07
[32m[0324 08:39:37 @group.py:42][0m Callbacks took 128.219 sec in total. InferenceRunner: 127.997sec
[32m[0324 08:39:37 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14518/173481[03:00<32:51,80.65it/s]  9%|8         |15139/173481[03:10<32:43,80.65it/s] 15%|#4        |25383/173481[06:00<35:45,69.04it/s] 15%|#4        |26008/173481[06:10<35:35,69.04it/s] 21%|##1       |36931/173481[09:00<34:13,66.51it/s] 22%|##1       |37647/173481[09:10<34:02,66.51it/s] 28%|##8       |48859/173481[12:00<31:17,66.39it/s] 29%|##8       |49612/173481[12:10<31:05,66.39it/s] 35%|###4      |60453/173481[15:00<28:48,65.38it/s] 35%|###5      |61149/173481[15:10<28:38,65.38it/s] 42%|####1     |72384/173481[18:00<25:35,65.83it/s] 42%|####2     |73123/173481[18:10<25:24,65.83it/s] 48%|####8     |83428/173481[21:00<23:37,63.51it/s] 49%|####8     |84335/173481[21:11<23:23,63.51it/s] 55%|#####5    |96063/173481[24:00<19:20,66.69it/s] 56%|#####5    |96815/173481[24:11<19:09,66.69it/s] 62%|######2   |108103/173481[27:00<16:18,66.78it/s] 63%|######2   |108852/173481[27:11<16:07,66.78it/s] 69%|######9   |120118/173481[30:00<13:19,66.76it/s] 70%|######9   |120913/173481[30:11<13:07,66.76it/s] 76%|#######6  |132139/173481[33:00<10:19,66.77it/s] 77%|#######6  |132887/173481[33:11<10:07,66.77it/s] 83%|########3 |144112/173481[36:00<07:20,66.64it/s] 84%|########3 |145048/173481[36:11<07:06,66.64it/s] 90%|######### |156373/173481[39:00<04:13,67.37it/s] 91%|######### |157142/173481[39:12<04:02,67.37it/s] 97%|#########7|168388/173481[42:00<01:15,67.06it/s] 98%|#########7|169217/173481[42:12<01:03,67.06it/s]100%|##########|173481/173481[43:19<00:00,66.74it/s]
[32m[0324 09:22:56 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:2599.27 sec.
[32m[0324 09:22:56 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-5030949.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:10<00:00,144.58it/s]
28
[32m[0324 09:25:06 @monitor.py:363][0m QueueInput/queue_size: 1.3667
[32m[0324 09:25:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.122
[32m[0324 09:25:06 @monitor.py:363][0m activation-summaries/output-rms: 0.038689
[32m[0324 09:25:06 @monitor.py:363][0m cross_entropy_loss: 1.6866
[32m[0324 09:25:06 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49129
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.494e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35562
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2263e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47157
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8217e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35026
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3256e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47745
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34783
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9975e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48072
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3162e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34724
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7001e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51046
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6579e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35359
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3722e-06
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60881
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44254
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36963
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36301
[32m[0324 09:25:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 09:25:06 @monitor.py:363][0m train-error-top1: 0.44591
[32m[0324 09:25:06 @monitor.py:363][0m val-error-top1: 0.48325
[32m[0324 09:25:06 @monitor.py:363][0m val-utt-error: 0.13298
[32m[0324 09:25:06 @monitor.py:363][0m validation_cost: 1.85
[32m[0324 09:25:06 @monitor.py:363][0m wd_cost: 6.0229e-07
[32m[0324 09:25:06 @group.py:42][0m Callbacks took 130.348 sec in total. InferenceRunner: 130.199sec
[32m[0324 09:25:06 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12946/173481[03:00<37:12,71.92it/s]  8%|7         |13631/173481[03:10<37:02,71.92it/s] 15%|#5        |26256/173481[06:00<33:39,72.92it/s] 16%|#5        |27013/173481[06:10<33:28,72.92it/s] 23%|##2       |39357/173481[09:00<30:41,72.85it/s] 23%|##3       |40123/173481[09:10<30:30,72.85it/s] 30%|###       |52540/173481[12:00<27:35,73.04it/s] 31%|###       |53298/173481[12:10<27:25,73.04it/s] 38%|###7      |65477/173481[15:00<24:50,72.45it/s] 38%|###8      |66251/173481[15:10<24:40,72.45it/s] 45%|####4     |77793/173481[18:00<22:39,70.38it/s] 45%|####5     |78733/173481[18:10<22:26,70.38it/s] 54%|#####3    |93083/173481[21:00<17:24,76.98it/s] 54%|#####4    |94020/173481[21:11<17:12,76.98it/s] 62%|######2   |108343/173481[24:00<13:27,80.69it/s] 63%|######3   |109294/173481[24:11<13:15,80.69it/s] 71%|#######1  |123584/173481[27:00<10:03,82.63it/s] 72%|#######1  |124556/173481[27:11<09:52,82.63it/s] 80%|#######9  |138117/173481[30:00<07:13,81.63it/s] 80%|#######9  |138485/173481[30:11<07:08,81.63it/s] 87%|########6 |150537/173481[33:00<05:06,74.79it/s] 87%|########7 |151264/173481[33:11<04:57,74.79it/s] 93%|#########3|161795/173481[36:00<02:51,68.12it/s] 94%|#########3|162531/173481[36:11<02:40,68.12it/s]100%|#########9|172765/173481[39:00<00:11,64.33it/s]100%|#########9|173441/173481[39:12<00:00,64.33it/s]100%|##########|173481/173481[39:12<00:00,73.73it/s]
[32m[0324 10:04:19 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:2352.79 sec.
[32m[0324 10:04:19 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-5204430.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,140.16it/s]
29
[32m[0324 10:06:34 @monitor.py:363][0m QueueInput/queue_size: 0.70554
[32m[0324 10:06:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.31
[32m[0324 10:06:34 @monitor.py:363][0m activation-summaries/output-rms: 0.040563
[32m[0324 10:06:34 @monitor.py:363][0m cross_entropy_loss: 1.7043
[32m[0324 10:06:34 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49134
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.495e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35564
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.226e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4716
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8208e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35027
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3254e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47747
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0726e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9979e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48075
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3164e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.6998e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51052
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6578e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3536
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3717e-06
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60919
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44268
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36971
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.3631
[32m[0324 10:06:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 10:06:34 @monitor.py:363][0m train-error-top1: 0.46246
[32m[0324 10:06:34 @monitor.py:363][0m val-error-top1: 0.48057
[32m[0324 10:06:34 @monitor.py:363][0m val-utt-error: 0.12942
[32m[0324 10:06:34 @monitor.py:363][0m validation_cost: 1.8277
[32m[0324 10:06:34 @monitor.py:363][0m wd_cost: 6.0277e-07
[32m[0324 10:06:34 @group.py:42][0m Callbacks took 134.543 sec in total. InferenceRunner: 134.304sec
[32m[0324 10:06:34 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13503/173481[03:00<35:32,75.02it/s]  8%|8         |14292/173481[03:10<35:22,75.02it/s] 16%|#5        |27370/173481[06:00<32:02,76.01it/s] 16%|#6        |28040/173481[06:10<31:53,76.01it/s] 22%|##2       |38291/173481[09:00<33:23,67.47it/s] 22%|##2       |38914/173481[09:10<33:14,67.47it/s] 28%|##8       |49394/173481[12:00<32:05,64.45it/s] 29%|##8       |50025/173481[12:10<31:55,64.45it/s] 35%|###4      |60504/173481[15:00<29:51,63.06it/s] 35%|###5      |61120/173481[15:10<29:41,63.06it/s] 41%|####1     |71407/173481[18:00<27:32,61.79it/s] 42%|####1     |72032/173481[18:10<27:21,61.79it/s] 48%|####7     |82933/173481[21:00<23:59,62.89it/s] 48%|####8     |83621/173481[21:11<23:48,62.89it/s] 54%|#####4    |94274/173481[24:00<20:58,62.95it/s] 55%|#####4    |95005/173481[24:11<20:46,62.95it/s] 61%|######    |105566/173481[27:00<18:00,62.84it/s] 61%|######1   |106280/173481[27:11<17:49,62.84it/s] 67%|######7   |116289/173481[30:00<15:35,61.16it/s] 67%|######7   |117041/173481[30:11<15:22,61.16it/s] 74%|#######3  |128080/173481[33:00<11:57,63.26it/s] 74%|#######4  |128850/173481[33:11<11:45,63.26it/s] 80%|########  |139370/173481[36:00<09:01,62.99it/s] 81%|########  |140079/173481[36:11<08:50,62.99it/s] 87%|########6 |150281/173481[39:00<06:15,61.75it/s] 87%|########7 |150999/173481[39:12<06:04,61.75it/s] 93%|#########2|161222/173481[42:00<03:20,61.26it/s] 93%|#########3|161968/173481[42:12<03:07,61.26it/s]100%|#########9|173004/173481[45:00<00:07,63.29it/s]100%|##########|173481/173481[45:06<00:00,64.09it/s]
[32m[0324 10:51:41 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:2706.95 sec.
[32m[0324 10:51:41 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-5377911.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,129.04it/s]
30
[32m[0324 10:54:07 @monitor.py:363][0m QueueInput/queue_size: 0.62934
[32m[0324 10:54:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.228
[32m[0324 10:54:07 @monitor.py:363][0m activation-summaries/output-rms: 0.03873
[32m[0324 10:54:07 @monitor.py:363][0m cross_entropy_loss: 1.7294
[32m[0324 10:54:07 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49137
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2258e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47163
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8213e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3255e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47749
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0726e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9979e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48078
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3149e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.6999e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51055
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3536
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.371e-06
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60936
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44273
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36974
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36313
[32m[0324 10:54:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 10:54:07 @monitor.py:363][0m train-error-top1: 0.46092
[32m[0324 10:54:07 @monitor.py:363][0m val-error-top1: 0.48366
[32m[0324 10:54:07 @monitor.py:363][0m val-utt-error: 0.12756
[32m[0324 10:54:07 @monitor.py:363][0m validation_cost: 1.8402
[32m[0324 10:54:07 @monitor.py:363][0m wd_cost: 1.2059e-07
[32m[0324 10:54:07 @group.py:42][0m Callbacks took 146.067 sec in total. InferenceRunner: 145.884sec
[32m[0324 10:54:07 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11889/173481[03:00<40:46,66.05it/s]  7%|7         |12519/173481[03:10<40:37,66.05it/s] 13%|#3        |22801/173481[06:00<39:43,63.22it/s] 13%|#3        |23387/173481[06:10<39:34,63.22it/s] 20%|##        |35030/173481[09:00<35:14,65.49it/s] 21%|##        |35687/173481[09:10<35:04,65.49it/s] 27%|##7       |47060/173481[12:00<31:51,66.15it/s] 28%|##7       |47774/173481[12:10<31:40,66.15it/s] 34%|###4      |59107/173481[15:00<28:39,66.54it/s] 35%|###4      |59852/173481[15:10<28:27,66.54it/s] 41%|####1     |71216/173481[18:00<25:28,66.90it/s] 41%|####1     |71909/173481[18:10<25:18,66.90it/s] 48%|####7     |82673/173481[21:00<23:12,65.23it/s] 48%|####8     |83384/173481[21:11<23:01,65.23it/s] 54%|#####4    |94142/173481[24:00<20:30,64.46it/s] 55%|#####4    |94844/173481[24:11<20:19,64.46it/s] 61%|######1   |106445/173481[27:00<16:50,66.35it/s] 62%|######1   |107426/173481[27:11<16:35,66.35it/s] 70%|#######   |121752/173481[30:00<11:33,74.54it/s] 71%|#######   |122736/173481[30:11<11:20,74.54it/s] 78%|#######8  |135351/173481[33:00<08:28,75.04it/s] 78%|#######8  |135954/173481[33:11<08:20,75.04it/s] 84%|########3 |145662/173481[36:00<07:08,64.97it/s] 84%|########4 |146379/173481[36:11<06:57,64.97it/s] 91%|######### |157147/173481[39:00<04:13,64.38it/s] 91%|#########1|158162/173481[39:11<03:57,64.38it/s] 97%|#########7|168785/173481[42:00<01:12,64.51it/s] 98%|#########7|169588/173481[42:12<01:00,64.51it/s]100%|##########|173481/173481[43:15<00:00,66.85it/s]
[32m[0324 11:37:22 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:2595.13 sec.
[32m[0324 11:37:22 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,128.99it/s]
31
[32m[0324 11:39:48 @monitor.py:363][0m QueueInput/queue_size: 1.0528
[32m[0324 11:39:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.518
[32m[0324 11:39:48 @monitor.py:363][0m activation-summaries/output-rms: 0.039112
[32m[0324 11:39:48 @monitor.py:363][0m cross_entropy_loss: 1.7738
[32m[0324 11:39:48 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49139
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4951e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2259e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47166
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3251e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47752
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0723e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34784
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9982e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48082
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7003e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51058
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6586e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3536
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60954
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3194
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44279
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36977
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36316
[32m[0324 11:39:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 11:39:48 @monitor.py:363][0m train-error-top1: 0.46871
[32m[0324 11:39:48 @monitor.py:363][0m val-error-top1: 0.48158
[32m[0324 11:39:48 @monitor.py:363][0m val-utt-error: 0.12879
[32m[0324 11:39:48 @monitor.py:363][0m validation_cost: 1.8323
[32m[0324 11:39:48 @monitor.py:363][0m wd_cost: 1.2064e-07
[32m[0324 11:39:48 @group.py:42][0m Callbacks took 146.120 sec in total. InferenceRunner: 145.937sec
[32m[0324 11:39:48 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13946/173481[03:00<34:19,77.48it/s]  8%|8         |14743/173481[03:10<34:08,77.48it/s] 16%|#5        |27404/173481[06:00<31:59,76.09it/s] 16%|#6        |28158/173481[06:10<31:49,76.09it/s] 22%|##2       |38368/173481[09:00<33:16,67.66it/s] 22%|##2       |39003/173481[09:10<33:07,67.66it/s] 28%|##8       |48974/173481[12:00<32:56,62.99it/s] 29%|##8       |49595/173481[12:10<32:46,62.99it/s] 34%|###4      |59427/173481[15:00<31:27,60.43it/s] 35%|###4      |60073/173481[15:10<31:16,60.43it/s] 41%|####      |70629/173481[18:00<27:57,61.31it/s] 41%|####1     |71258/173481[18:10<27:47,61.31it/s] 47%|####7     |82190/173481[21:00<24:15,62.74it/s] 48%|####7     |82993/173481[21:11<24:02,62.74it/s] 54%|#####4    |94249/173481[24:00<20:22,64.79it/s] 55%|#####4    |95048/173481[24:11<20:10,64.79it/s] 61%|######    |105537/173481[27:00<17:46,63.73it/s] 61%|######1   |106234/173481[27:11<17:35,63.73it/s] 68%|######7   |117269/173481[30:00<14:32,64.44it/s] 68%|######8   |117983/173481[30:11<14:21,64.44it/s] 74%|#######4  |128404/173481[33:00<11:54,63.12it/s] 74%|#######4  |129038/173481[33:11<11:44,63.12it/s] 80%|#######9  |138206/173481[36:00<10:03,58.47it/s] 80%|########  |138958/173481[36:11<09:50,58.47it/s] 85%|########5 |148014/173481[39:00<07:31,56.40it/s] 86%|########5 |148676/173481[39:12<07:19,56.40it/s] 91%|#########1|157868/173481[42:00<04:41,55.56it/s] 91%|#########1|158447/173481[42:12<04:30,55.56it/s] 95%|#########5|165305/173481[45:00<02:52,47.39it/s] 96%|#########5|165753/173481[45:12<02:43,47.39it/s] 99%|#########9|172609/173481[48:00<00:19,43.71it/s]100%|#########9|173062/173481[48:12<00:09,43.71it/s]100%|##########|173481/173481[48:23<00:00,59.75it/s]
[32m[0324 12:28:11 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:2903.51 sec.
[32m[0324 12:28:12 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-5724873.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:55<00:00,107.15it/s]
32
[32m[0324 12:31:07 @monitor.py:363][0m QueueInput/queue_size: 0.7342
[32m[0324 12:31:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.457
[32m[0324 12:31:07 @monitor.py:363][0m activation-summaries/output-rms: 0.039399
[32m[0324 12:31:07 @monitor.py:363][0m cross_entropy_loss: 1.7244
[32m[0324 12:31:07 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49142
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4949e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2257e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47167
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8209e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.325e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47754
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0721e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34784
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9982e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48084
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3147e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7002e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.5106
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.3536
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3713e-06
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60963
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3194
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44283
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.3698
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36319
[32m[0324 12:31:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 12:31:07 @monitor.py:363][0m train-error-top1: 0.45695
[32m[0324 12:31:07 @monitor.py:363][0m val-error-top1: 0.48086
[32m[0324 12:31:07 @monitor.py:363][0m val-utt-error: 0.129
[32m[0324 12:31:07 @monitor.py:363][0m validation_cost: 1.8285
[32m[0324 12:31:07 @monitor.py:363][0m wd_cost: 1.2066e-07
[32m[0324 12:31:07 @group.py:42][0m Callbacks took 175.888 sec in total. InferenceRunner: 175.679sec
[32m[0324 12:31:07 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7766/173481[03:00<1:04:01,43.14it/s]  5%|4         |8152/173481[03:10<1:03:52,43.14it/s]  9%|8         |15268/173481[06:00<1:02:11,42.40it/s]  9%|9         |15657/173481[06:10<1:02:02,42.40it/s] 13%|#3        |22638/173481[09:00<1:00:21,41.66it/s] 13%|#3        |23095/173481[09:10<1:00:10,41.66it/s] 17%|#7        |30268/173481[12:00<56:48,42.02it/s]   18%|#7        |30706/173481[12:10<56:38,42.02it/s] 22%|##1       |37532/173481[15:00<55:02,41.17it/s] 22%|##1       |37917/173481[15:10<54:52,41.17it/s] 25%|##5       |43673/173481[18:00<57:59,37.30it/s] 25%|##5       |44049/173481[18:10<57:49,37.30it/s] 29%|##8       |49544/173481[21:00<59:21,34.80it/s] 29%|##8       |49866/173481[21:11<59:11,34.80it/s] 32%|###1      |55218/173481[24:00<59:35,33.08it/s] 32%|###2      |55577/173481[24:11<59:24,33.08it/s] 35%|###5      |61329/173481[27:00<55:47,33.51it/s] 36%|###5      |61697/173481[27:11<55:36,33.51it/s] 39%|###9      |67707/173481[30:00<51:11,34.44it/s] 39%|###9      |68117/173481[30:11<50:59,34.44it/s] 43%|####3     |75093/173481[33:00<43:47,37.44it/s] 44%|####3     |75572/173481[33:11<43:34,37.44it/s] 48%|####7     |82978/173481[36:00<37:21,40.37it/s] 48%|####8     |83501/173481[36:11<37:08,40.37it/s] 52%|#####2    |91072/173481[39:00<32:17,42.54it/s] 53%|#####2    |91602/173481[39:12<32:04,42.54it/s] 57%|#####7    |99461/173481[42:00<27:44,44.48it/s] 58%|#####7    |100032/173481[42:12<27:31,44.48it/s] 63%|######2   |108528/173481[45:00<22:55,47.24it/s] 63%|######2   |109108/173481[45:12<22:42,47.24it/s] 68%|######7   |117896/173481[48:00<18:42,49.52it/s] 68%|######8   |118461/173481[48:12<18:30,49.52it/s] 73%|#######3  |127344/173481[51:00<15:05,50.96it/s] 74%|#######3  |128012/173481[51:12<14:52,50.96it/s] 79%|#######8  |136899/173481[54:00<11:43,52.00it/s] 79%|#######9  |137574/173481[54:12<11:30,52.00it/s] 84%|########4 |146428/173481[57:00<08:35,52.46it/s] 85%|########4 |147087/173481[57:13<08:23,52.46it/s] 90%|########9 |155838/173481[1:00:00<05:36,52.37it/s] 90%|######### |156510/173481[1:00:13<05:24,52.37it/s] 95%|#########5|165093/173481[1:03:00<02:41,51.89it/s] 96%|#########5|165753/173481[1:03:13<02:28,51.89it/s]100%|##########|173481/173481[1:05:45<00:00,43.97it/s]
[32m[0324 13:36:53 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:3945.36 sec.
[32m[0324 13:36:53 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:26<00:00,128.40it/s]
33
[32m[0324 13:39:19 @monitor.py:363][0m QueueInput/queue_size: 0.83592
[32m[0324 13:39:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.219
[32m[0324 13:39:19 @monitor.py:363][0m activation-summaries/output-rms: 0.038732
[32m[0324 13:39:19 @monitor.py:363][0m cross_entropy_loss: 1.7476
[32m[0324 13:39:19 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49144
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4949e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2256e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47168
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8209e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.325e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47757
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9982e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48086
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3148e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7002e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51061
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6583e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6096
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44285
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36981
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36321
[32m[0324 13:39:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 13:39:19 @monitor.py:363][0m train-error-top1: 0.46533
[32m[0324 13:39:19 @monitor.py:363][0m val-error-top1: 0.48279
[32m[0324 13:39:19 @monitor.py:363][0m val-utt-error: 0.13011
[32m[0324 13:39:19 @monitor.py:363][0m validation_cost: 1.8453
[32m[0324 13:39:19 @monitor.py:363][0m wd_cost: 2.4133e-08
[32m[0324 13:39:19 @group.py:42][0m Callbacks took 146.767 sec in total. InferenceRunner: 146.600sec
[32m[0324 13:39:19 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9912/173481[03:00<49:30,55.06it/s]  6%|6         |10459/173481[03:10<49:20,55.06it/s] 11%|#1        |19552/173481[06:00<47:14,54.30it/s] 12%|#1        |20108/173481[06:10<47:04,54.30it/s] 17%|#6        |29174/173481[09:00<44:38,53.87it/s] 17%|#7        |29756/173481[09:10<44:27,53.87it/s] 23%|##2       |39062/173481[12:00<41:11,54.39it/s] 23%|##2       |39630/173481[12:10<41:00,54.39it/s] 28%|##8       |48949/173481[15:00<37:58,54.66it/s] 29%|##8       |49526/173481[15:10<37:47,54.66it/s] 34%|###3      |58721/173481[18:00<35:06,54.47it/s] 34%|###4      |59306/173481[18:10<34:56,54.47it/s] 39%|###9      |68273/173481[21:00<32:37,53.76it/s] 40%|###9      |68862/173481[21:11<32:26,53.76it/s] 44%|####4     |76842/173481[24:00<31:53,50.49it/s] 45%|####4     |77406/173481[24:11<31:42,50.49it/s] 49%|####9     |85797/173481[27:00<29:09,50.11it/s] 50%|####9     |86174/173481[27:11<29:02,50.11it/s] 55%|#####4    |94782/173481[30:00<26:13,50.01it/s] 55%|#####4    |95342/173481[30:11<26:02,50.01it/s] 60%|#####9    |103661/173481[33:00<23:25,49.67it/s] 60%|######    |104251/173481[33:11<23:13,49.67it/s] 65%|######4   |112133/173481[36:00<21:09,48.33it/s] 65%|######4   |112726/173481[36:11<20:57,48.33it/s] 70%|#######   |122104/173481[39:00<16:35,51.62it/s] 71%|#######   |122802/173481[39:11<16:21,51.62it/s] 76%|#######6  |132282/173481[42:00<12:43,53.97it/s] 77%|#######6  |132934/173481[42:12<12:31,53.97it/s] 82%|########2 |142481/173481[45:00<09:20,55.28it/s] 83%|########2 |143158/173481[45:12<09:08,55.28it/s] 88%|########8 |152723/173481[48:00<06:10,56.08it/s] 88%|########8 |153431/173481[48:12<05:57,56.08it/s] 94%|#########3|162980/173481[51:00<03:05,56.53it/s] 94%|#########4|163557/173481[51:12<02:55,56.53it/s]100%|#########9|173082/173481[54:00<00:07,56.32it/s]100%|##########|173481/173481[54:07<00:00,53.41it/s]
[32m[0324 14:33:27 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:3247.93 sec.
[32m[0324 14:33:27 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-6071835.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:23<00:00,130.94it/s]
34
[32m[0324 14:35:51 @monitor.py:363][0m QueueInput/queue_size: 0.67984
[32m[0324 14:35:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.377
[32m[0324 14:35:51 @monitor.py:363][0m activation-summaries/output-rms: 0.040576
[32m[0324 14:35:51 @monitor.py:363][0m cross_entropy_loss: 1.7124
[32m[0324 14:35:51 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49145
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4948e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2256e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47169
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8209e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47757
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0719e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.998e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48087
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3148e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7004e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51062
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6581e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60957
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44288
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36983
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36322
[32m[0324 14:35:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 14:35:51 @monitor.py:363][0m train-error-top1: 0.45692
[32m[0324 14:35:51 @monitor.py:363][0m val-error-top1: 0.48225
[32m[0324 14:35:51 @monitor.py:363][0m val-utt-error: 0.12709
[32m[0324 14:35:51 @monitor.py:363][0m validation_cost: 1.8326
[32m[0324 14:35:51 @monitor.py:363][0m wd_cost: 2.4133e-08
[32m[0324 14:35:51 @group.py:42][0m Callbacks took 143.898 sec in total. InferenceRunner: 143.761sec
[32m[0324 14:35:51 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9980/173481[03:00<49:09,55.44it/s]  6%|6         |10528/173481[03:10<48:59,55.44it/s] 11%|#1        |19488/173481[06:00<47:26,54.10it/s] 12%|#1        |20022/173481[06:10<47:16,54.10it/s] 17%|#6        |28920/173481[09:00<45:15,53.24it/s] 17%|#6        |29442/173481[09:10<45:05,53.24it/s] 22%|##1       |37947/173481[12:00<43:44,51.65it/s] 22%|##2       |38473/173481[12:10<43:34,51.65it/s] 27%|##6       |46206/173481[15:00<43:39,48.59it/s] 27%|##6       |46690/173481[15:10<43:29,48.59it/s] 31%|###1      |54276/173481[18:00<42:36,46.63it/s] 32%|###1      |54790/173481[18:10<42:25,46.63it/s] 36%|###6      |62495/173481[21:00<40:05,46.14it/s] 36%|###6      |63015/173481[21:11<39:54,46.14it/s] 41%|####      |70678/173481[24:00<37:24,45.80it/s] 41%|####1     |71155/173481[24:11<37:14,45.80it/s] 45%|####5     |78366/173481[27:00<35:52,44.19it/s] 45%|####5     |78860/173481[27:11<35:41,44.19it/s] 50%|####9     |86396/173481[30:00<32:41,44.40it/s] 50%|#####     |86910/173481[30:11<32:29,44.40it/s] 55%|#####4    |94735/173481[33:00<28:56,45.34it/s] 55%|#####4    |95239/173481[33:11<28:45,45.34it/s] 59%|#####9    |102660/173481[36:00<26:25,44.67it/s] 59%|#####9    |103171/173481[36:11<26:13,44.67it/s] 64%|######3   |110581/173481[39:00<23:38,44.33it/s] 64%|######4   |111123/173481[39:12<23:26,44.33it/s] 69%|######8   |118994/173481[42:00<19:57,45.50it/s] 69%|######8   |119560/173481[42:12<19:44,45.50it/s] 74%|#######3  |127668/173481[45:00<16:18,46.81it/s] 74%|#######3  |128245/173481[45:12<16:06,46.81it/s] 78%|#######8  |135991/173481[48:00<13:26,46.51it/s] 79%|#######8  |136520/173481[48:12<13:14,46.51it/s] 83%|########3 |144326/173481[51:00<10:28,46.38it/s] 83%|########3 |144470/173481[51:12<10:25,46.38it/s] 88%|########8 |152695/173481[54:00<07:27,46.44it/s] 88%|########8 |153355/173481[54:12<07:13,46.44it/s] 93%|#########3|162199/173481[57:00<03:48,49.41it/s] 94%|#########3|162855/173481[57:13<03:35,49.41it/s] 99%|#########8|171418/173481[1:00:00<00:41,50.30it/s] 99%|#########9|172030/173481[1:00:13<00:28,50.30it/s]100%|##########|173481/173481[1:00:42<00:00,47.62it/s]
[32m[0324 15:36:34 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:3642.71 sec.
[32m[0324 15:36:34 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:08<00:00,146.12it/s]
35
[32m[0324 15:38:43 @monitor.py:363][0m QueueInput/queue_size: 0.73045
[32m[0324 15:38:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.317
[32m[0324 15:38:43 @monitor.py:363][0m activation-summaries/output-rms: 0.039133
[32m[0324 15:38:43 @monitor.py:363][0m cross_entropy_loss: 1.7269
[32m[0324 15:38:43 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49145
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2256e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.4717
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8209e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47758
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.072e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48088
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3147e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51063
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6582e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60944
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3192
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44289
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36984
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36323
[32m[0324 15:38:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 15:38:43 @monitor.py:363][0m train-error-top1: 0.45586
[32m[0324 15:38:43 @monitor.py:363][0m val-error-top1: 0.48023
[32m[0324 15:38:43 @monitor.py:363][0m val-utt-error: 0.12985
[32m[0324 15:38:43 @monitor.py:363][0m validation_cost: 1.8297
[32m[0324 15:38:43 @monitor.py:363][0m wd_cost: 4.8259e-09
[32m[0324 15:38:43 @group.py:42][0m Callbacks took 129.042 sec in total. InferenceRunner: 128.828sec
[32m[0324 15:38:43 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8098/173481[03:00<1:01:16,44.99it/s]  5%|4         |8583/173481[03:10<1:01:05,44.99it/s] 10%|9         |16680/173481[06:00<56:27,46.29it/s]  10%|9         |17179/173481[06:10<56:16,46.29it/s] 15%|#4        |25245/173481[09:00<52:39,46.92it/s] 15%|#4        |25749/173481[09:10<52:28,46.92it/s] 19%|#9        |33650/173481[12:00<49:47,46.80it/s] 20%|#9        |34139/173481[12:10<49:37,46.80it/s] 24%|##4       |41695/173481[15:00<48:02,45.72it/s] 24%|##4       |42187/173481[15:10<47:51,45.72it/s] 28%|##8       |49055/173481[18:00<48:07,43.08it/s] 29%|##8       |49519/173481[18:10<47:57,43.08it/s] 33%|###3      |57346/173481[21:00<43:28,44.52it/s] 33%|###3      |57829/173481[21:11<43:17,44.52it/s] 38%|###7      |65096/173481[24:00<41:15,43.78it/s] 38%|###7      |65564/173481[24:11<41:05,43.78it/s] 42%|####2     |73225/173481[27:00<37:35,44.45it/s] 42%|####2     |73709/173481[27:11<37:24,44.45it/s] 46%|####6     |80510/173481[30:00<36:34,42.37it/s] 47%|####6     |80994/173481[30:11<36:22,42.37it/s] 51%|#####     |88275/173481[33:00<33:13,42.74it/s] 51%|#####1    |88534/173481[33:11<33:07,42.74it/s] 55%|#####5    |95668/173481[36:00<30:57,41.89it/s] 55%|#####5    |96159/173481[36:11<30:45,41.89it/s] 59%|#####9    |103074/173481[39:00<28:16,41.51it/s] 60%|#####9    |103534/173481[39:12<28:04,41.51it/s] 63%|######3   |109950/173481[42:01<26:36,39.78it/s] 64%|######3   |110381/173481[42:12<26:26,39.78it/s] 67%|######7   |116336/173481[45:01<25:23,37.51it/s] 67%|######7   |116800/173481[45:12<25:11,37.51it/s] 71%|#######   |122383/173481[48:01<24:01,35.44it/s] 71%|#######   |122829/173481[48:12<23:49,35.44it/s] 74%|#######4  |128965/173481[51:01<20:36,35.99it/s] 75%|#######4  |129347/173481[51:12<20:26,35.99it/s] 78%|#######8  |135542/173481[54:01<17:26,36.26it/s] 78%|#######8  |135999/173481[54:12<17:13,36.26it/s] 82%|########1 |142110/173481[57:01<14:22,36.37it/s] 82%|########2 |142612/173481[57:13<14:08,36.37it/s] 86%|########6 |149322/173481[1:00:01<10:33,38.13it/s] 86%|########6 |149779/173481[1:00:13<10:21,38.13it/s] 90%|######### |156644/173481[1:03:01<07:07,39.36it/s] 91%|######### |157148/173481[1:03:13<06:54,39.36it/s] 95%|#########4|164090/173481[1:06:01<03:52,40.33it/s] 95%|#########4|164604/173481[1:06:13<03:40,40.33it/s] 98%|#########8|170780/173481[1:09:01<01:09,38.68it/s] 99%|#########8|171304/173481[1:09:13<00:56,38.68it/s]100%|##########|173481/173481[1:10:07<00:00,41.23it/s]
[32m[0324 16:48:51 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:4207.72 sec.
[32m[0324 16:48:51 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s] 73%|#######2  |13727/18822[03:00<01:06,76.26it/s] 77%|#######7  |14501/18822[03:10<00:56,76.26it/s]100%|##########|18822/18822[04:07<00:00,75.98it/s]
36
[32m[0324 16:52:59 @monitor.py:363][0m QueueInput/queue_size: 0.60714
[32m[0324 16:52:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.527
[32m[0324 16:52:59 @monitor.py:363][0m activation-summaries/output-rms: 0.038763
[32m[0324 16:52:59 @monitor.py:363][0m cross_entropy_loss: 1.7684
[32m[0324 16:52:59 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49146
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2256e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47171
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.8209e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47759
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0721e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48088
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3147e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7004e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51063
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6582e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60924
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3192
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.44289
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36984
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36324
[32m[0324 16:52:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 16:52:59 @monitor.py:363][0m train-error-top1: 0.47159
[32m[0324 16:52:59 @monitor.py:363][0m val-error-top1: 0.48504
[32m[0324 16:52:59 @monitor.py:363][0m val-utt-error: 0.12926
[32m[0324 16:52:59 @monitor.py:363][0m validation_cost: 1.8465
[32m[0324 16:52:59 @monitor.py:363][0m wd_cost: 4.8247e-09
[32m[0324 16:52:59 @group.py:42][0m Callbacks took 248.413 sec in total. InferenceRunner: 247.807sec
[32m[0324 16:52:59 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |7837/173481[03:00<1:03:24,43.54it/s]  5%|4         |8244/173481[03:10<1:03:15,43.54it/s]  9%|8         |15290/173481[06:00<1:02:07,42.44it/s]  9%|9         |15748/173481[06:10<1:01:56,42.44it/s] 13%|#3        |22854/173481[09:00<59:26,42.23it/s]   13%|#3        |23213/173481[09:10<59:18,42.23it/s] 17%|#7        |29509/173481[12:00<1:00:52,39.42it/s] 17%|#7        |29948/173481[12:10<1:00:40,39.42it/s] 21%|##        |35969/173481[15:00<1:01:01,37.55it/s] 21%|##        |36328/173481[15:10<1:00:52,37.55it/s] 25%|##4       |42884/173481[18:00<57:18,37.98it/s]   25%|##4       |43285/173481[18:10<57:08,37.98it/s] 29%|##8       |49661/173481[21:00<54:34,37.81it/s] 29%|##8       |50086/173481[21:11<54:23,37.81it/s] 33%|###2      |56798/173481[24:00<50:14,38.71it/s] 33%|###2      |57238/173481[24:11<50:03,38.71it/s] 37%|###6      |63939/173481[27:00<46:35,39.18it/s] 37%|###7      |64358/173481[27:11<46:24,39.18it/s] 41%|####      |71070/173481[30:00<43:19,39.40it/s] 41%|####1     |71541/173481[30:11<43:07,39.40it/s] 45%|####5     |78199/173481[33:00<40:12,39.50it/s] 45%|####5     |78672/173481[33:11<40:00,39.50it/s] 49%|####8     |84679/173481[36:00<39:18,37.66it/s] 49%|####9     |85128/173481[36:11<39:06,37.66it/s] 53%|#####2    |91609/173481[39:00<35:50,38.07it/s] 53%|#####3    |92028/173481[39:12<35:39,38.07it/s] 57%|#####6    |98359/173481[42:00<33:08,37.78it/s] 57%|#####6    |98824/173481[42:12<32:56,37.78it/s] 60%|######    |104919/173481[45:00<30:48,37.10it/s] 61%|######    |105398/173481[45:12<30:35,37.10it/s] 65%|######5   |112799/173481[48:00<25:11,40.16it/s] 65%|######5   |113343/173481[48:12<24:57,40.16it/s] 70%|######9   |120914/173481[51:00<20:37,42.48it/s] 70%|######9   |121426/173481[51:12<20:25,42.48it/s] 74%|#######3  |128339/173481[54:00<17:58,41.85it/s] 74%|#######4  |128885/173481[54:12<17:45,41.85it/s] 79%|#######8  |136504/173481[57:00<14:09,43.52it/s] 79%|#######9  |137078/173481[57:13<13:56,43.52it/s] 83%|########3 |144349/173481[1:00:00<11:08,43.55it/s] 84%|########3 |144913/173481[1:00:13<10:55,43.55it/s] 88%|########7 |152247/173481[1:03:00<08:05,43.71it/s] 88%|########8 |152763/173481[1:03:13<07:53,43.71it/s] 92%|#########2|160229/173481[1:06:00<05:01,44.03it/s] 93%|#########2|160803/173481[1:06:13<04:47,44.03it/s] 97%|#########7|169096/173481[1:09:00<01:34,46.50it/s] 98%|#########7|169724/173481[1:09:13<01:20,46.50it/s]100%|##########|173481/173481[1:10:49<00:00,40.83it/s]
[32m[0324 18:03:48 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:4249.01 sec.
[32m[0324 18:03:48 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-6592278.
  0%|          |0/18822[00:00<?,?it/s] 90%|######### |17000/18822[03:00<00:19,94.44it/s] 96%|#########6|18094/18822[03:10<00:07,94.44it/s]100%|##########|18822/18822[03:17<00:00,95.11it/s]
37
[32m[0324 18:07:06 @monitor.py:363][0m QueueInput/queue_size: 0.92465
[32m[0324 18:07:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.462
[32m[0324 18:07:06 @monitor.py:363][0m activation-summaries/output-rms: 0.03928
[32m[0324 18:07:06 @monitor.py:363][0m cross_entropy_loss: 1.7235
[32m[0324 18:07:06 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49146
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47171
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47759
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0721e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.998e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3147e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3715e-06
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60905
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3192
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0324 18:07:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 18:07:06 @monitor.py:363][0m train-error-top1: 0.46534
[32m[0324 18:07:06 @monitor.py:363][0m val-error-top1: 0.48201
[32m[0324 18:07:06 @monitor.py:363][0m val-utt-error: 0.12496
[32m[0324 18:07:06 @monitor.py:363][0m validation_cost: 1.835
[32m[0324 18:07:06 @monitor.py:363][0m wd_cost: 4.8236e-09
[32m[0324 18:07:06 @group.py:42][0m Callbacks took 198.204 sec in total. InferenceRunner: 197.926sec
[32m[0324 18:07:06 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9158/173481[03:00<53:49,50.88it/s]  6%|5         |9634/173481[03:10<53:40,50.88it/s] 10%|#         |17553/173481[06:00<53:24,48.66it/s] 10%|#         |18032/173481[06:10<53:14,48.66it/s] 15%|#4        |25782/173481[09:00<52:13,47.14it/s] 15%|#5        |26302/173481[09:10<52:01,47.14it/s] 20%|#9        |34272/173481[12:00<49:12,47.15it/s] 20%|##        |34817/173481[12:10<49:00,47.15it/s] 24%|##4       |41650/173481[15:00<50:06,43.85it/s] 24%|##4       |42158/173481[15:10<49:54,43.85it/s] 29%|##8       |49907/173481[18:00<45:55,44.84it/s] 29%|##9       |50440/173481[18:10<45:44,44.84it/s] 34%|###3      |58143/173481[21:00<42:26,45.29it/s] 34%|###3      |58674/173481[21:11<42:15,45.29it/s] 38%|###8      |66413/173481[24:00<39:07,45.61it/s] 39%|###8      |66881/173481[24:11<38:57,45.61it/s] 42%|####2     |73567/173481[27:00<39:12,42.48it/s] 43%|####2     |74000/173481[27:11<39:02,42.48it/s] 47%|####6     |80843/173481[30:00<37:16,41.42it/s] 47%|####6     |81304/173481[30:11<37:05,41.42it/s] 50%|#####     |87403/173481[33:00<37:00,38.77it/s] 51%|#####     |87861/173481[33:11<36:48,38.77it/s] 55%|#####4    |94884/173481[36:00<32:39,40.12it/s] 55%|#####5    |95450/173481[36:11<32:25,40.12it/s] 60%|#####9    |103612/173481[39:00<26:31,43.91it/s] 60%|######    |104202/173481[39:12<26:17,43.91it/s] 65%|######4   |112313/173481[42:00<22:09,46.01it/s] 65%|######5   |112883/173481[42:12<21:57,46.01it/s] 70%|######9   |120973/173481[45:00<18:37,46.98it/s] 70%|#######   |121550/173481[45:12<18:25,46.98it/s] 74%|#######4  |129218/173481[48:00<15:54,46.38it/s] 75%|#######4  |129764/173481[48:12<15:42,46.38it/s] 79%|#######8  |136698/173481[51:00<13:59,43.83it/s] 79%|#######9  |137304/173481[51:12<13:45,43.83it/s] 84%|########3 |145015/173481[54:00<10:32,44.99it/s] 84%|########3 |145592/173481[54:12<10:19,44.99it/s] 89%|########8 |153823/173481[57:00<06:59,46.88it/s] 89%|########9 |154412/173481[57:13<06:46,46.88it/s] 94%|#########3|162688/173481[1:00:00<03:44,48.03it/s] 94%|#########4|163292/173481[1:00:13<03:32,48.03it/s] 99%|#########8|171087/173481[1:03:00<00:50,47.33it/s] 99%|#########8|171657/173481[1:03:13<00:38,47.33it/s]100%|##########|173481/173481[1:03:56<00:00,45.22it/s]
[32m[0324 19:11:02 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:3836.03 sec.
[32m[0324 19:11:03 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14794/18822[03:00<00:49,82.16it/s] 79%|#######8  |14855/18822[03:10<00:48,82.16it/s]100%|##########|18822/18822[04:05<00:00,76.66it/s]
38
[32m[0324 19:15:09 @monitor.py:363][0m QueueInput/queue_size: 0.59088
[32m[0324 19:15:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.216
[32m[0324 19:15:09 @monitor.py:363][0m activation-summaries/output-rms: 0.038701
[32m[0324 19:15:09 @monitor.py:363][0m cross_entropy_loss: 1.742
[32m[0324 19:15:09 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49146
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47171
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.47759
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0721e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60877
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3192
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0324 19:15:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 19:15:09 @monitor.py:363][0m train-error-top1: 0.46207
[32m[0324 19:15:09 @monitor.py:363][0m val-error-top1: 0.48064
[32m[0324 19:15:09 @monitor.py:363][0m val-utt-error: 0.12698
[32m[0324 19:15:09 @monitor.py:363][0m validation_cost: 1.8251
[32m[0324 19:15:09 @monitor.py:363][0m wd_cost: 9.6435e-10
[32m[0324 19:15:09 @group.py:42][0m Callbacks took 246.368 sec in total. InferenceRunner: 245.550sec
[32m[0324 19:15:09 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8999/173481[03:00<54:50,49.99it/s]  5%|5         |9443/173481[03:10<54:41,49.99it/s] 10%|#         |17505/173481[06:00<53:30,48.58it/s] 10%|#         |18014/173481[06:10<53:20,48.58it/s] 15%|#4        |25987/173481[09:00<51:23,47.84it/s] 15%|#5        |26503/173481[09:10<51:12,47.84it/s] 20%|##        |34720/173481[12:00<48:00,48.17it/s] 20%|##        |35237/173481[12:10<47:49,48.17it/s] 25%|##4       |43335/173481[15:00<45:10,48.02it/s] 25%|##5       |43815/173481[15:10<45:00,48.02it/s] 29%|##9       |50572/173481[18:00<46:48,43.76it/s] 29%|##9       |50996/173481[18:10<46:39,43.76it/s] 34%|###3      |58387/173481[21:00<44:01,43.58it/s] 34%|###3      |58856/173481[21:11<43:50,43.58it/s] 38%|###8      |66103/173481[24:00<41:24,43.22it/s] 38%|###8      |66551/173481[24:11<41:14,43.22it/s] 42%|####2     |73632/173481[27:00<39:08,42.51it/s] 43%|####2     |74111/173481[27:11<38:57,42.51it/s] 47%|####6     |81139/173481[30:00<36:33,42.10it/s] 47%|####7     |81616/173481[30:11<36:21,42.10it/s] 51%|#####     |88217/173481[33:00<34:57,40.66it/s] 51%|#####1    |88711/173481[33:11<34:44,40.66it/s] 55%|#####4    |95018/173481[36:00<33:23,39.17it/s] 55%|#####5    |95511/173481[36:11<33:10,39.17it/s] 59%|#####9    |102577/173481[39:00<29:09,40.52it/s] 59%|#####9    |103112/173481[39:12<28:56,40.52it/s] 64%|######3   |110577/173481[42:00<24:43,42.39it/s] 64%|######4   |111124/173481[42:12<24:31,42.39it/s] 69%|######8   |119596/173481[45:00<19:33,45.92it/s] 69%|######9   |120261/173481[45:12<19:18,45.92it/s] 74%|#######4  |128437/173481[48:00<15:48,47.47it/s] 74%|#######4  |129042/173481[48:12<15:36,47.47it/s] 79%|#######9  |137387/173481[51:00<12:23,48.57it/s] 80%|#######9  |137963/173481[51:12<12:11,48.57it/s] 84%|########3 |145487/173481[54:00<09:59,46.71it/s] 84%|########4 |146114/173481[54:12<09:45,46.71it/s] 89%|########9 |154557/173481[57:00<06:30,48.48it/s] 89%|########9 |155232/173481[57:13<06:16,48.48it/s] 94%|#########4|163369/173481[1:00:00<03:27,48.71it/s] 95%|#########4|163946/173481[1:00:13<03:15,48.71it/s] 99%|#########8|171606/173481[1:03:00<00:39,47.19it/s] 99%|#########9|172252/173481[1:03:13<00:26,47.19it/s][32m[0324 20:18:49 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:3819.91 sec.
100%|##########|173481/173481[1:03:39<00:00,45.41it/s]
[32m[0324 20:18:50 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-6939240.
  0%|          |0/18822[00:00<?,?it/s] 83%|########3 |15675/18822[03:00<00:36,87.08it/s] 88%|########7 |16488/18822[03:10<00:26,87.08it/s]100%|##########|18822/18822[03:37<00:00,86.47it/s]
39
[32m[0324 20:22:27 @monitor.py:363][0m QueueInput/queue_size: 0.95349
[32m[0324 20:22:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.344
[32m[0324 20:22:27 @monitor.py:363][0m activation-summaries/output-rms: 0.040674
[32m[0324 20:22:27 @monitor.py:363][0m cross_entropy_loss: 1.7023
[32m[0324 20:22:27 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4948e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35565
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60848
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3192
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0324 20:22:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 20:22:27 @monitor.py:363][0m train-error-top1: 0.46095
[32m[0324 20:22:27 @monitor.py:363][0m val-error-top1: 0.47991
[32m[0324 20:22:27 @monitor.py:363][0m val-utt-error: 0.12454
[32m[0324 20:22:27 @monitor.py:363][0m validation_cost: 1.8223
[32m[0324 20:22:27 @monitor.py:363][0m wd_cost: 9.6398e-10
[32m[0324 20:22:27 @group.py:42][0m Callbacks took 218.751 sec in total. InferenceRunner: 217.677sec
[32m[0324 20:22:27 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8199/173481[03:00<1:00:28,45.55it/s]  5%|4         |8619/173481[03:10<1:00:19,45.55it/s] 10%|9         |16481/173481[06:00<57:09,45.78it/s]  10%|9         |16948/173481[06:10<56:59,45.78it/s] 14%|#3        |23912/173481[09:00<57:25,43.41it/s] 14%|#4        |24382/173481[09:10<57:14,43.41it/s] 18%|#8        |31451/173481[12:00<55:31,42.63it/s] 18%|#8        |31881/173481[12:10<55:21,42.63it/s] 22%|##2       |38679/173481[15:00<54:19,41.36it/s] 23%|##2       |39125/173481[15:10<54:08,41.36it/s] 26%|##6       |45906/173481[18:00<52:11,40.74it/s] 27%|##6       |46360/173481[18:10<52:00,40.74it/s] 30%|###       |52556/173481[21:00<52:00,38.75it/s] 31%|###       |52999/173481[21:11<51:49,38.75it/s] 34%|###4      |59747/173481[24:00<48:11,39.34it/s] 35%|###4      |60206/173481[24:11<47:59,39.34it/s] 39%|###8      |66945/173481[27:00<44:46,39.66it/s] 39%|###8      |67394/173481[27:11<44:34,39.66it/s] 43%|####2     |73856/173481[30:00<42:33,39.01it/s] 43%|####2     |74322/173481[30:11<42:21,39.01it/s] 47%|####6     |80951/173481[33:00<39:19,39.21it/s] 47%|####6     |81455/173481[33:11<39:06,39.21it/s] 51%|#####     |88362/173481[36:00<35:19,40.17it/s] 51%|#####1    |88873/173481[36:11<35:06,40.17it/s] 55%|#####5    |96001/173481[39:00<31:17,41.27it/s] 56%|#####5    |96598/173481[39:12<31:02,41.27it/s] 60%|######    |104276/173481[42:00<26:31,43.49it/s] 60%|######    |104865/173481[42:12<26:17,43.49it/s] 65%|######5   |112949/173481[45:00<22:04,45.72it/s] 65%|######5   |113545/173481[45:12<21:51,45.72it/s] 70%|#######   |121652/173481[48:00<18:22,46.99it/s] 70%|#######   |122235/173481[48:12<18:10,46.99it/s] 75%|#######4  |129729/173481[51:00<15:53,45.90it/s] 75%|#######5  |130350/173481[51:12<15:39,45.90it/s] 80%|#######9  |138022/173481[54:00<12:51,45.99it/s] 80%|#######9  |138617/173481[54:12<12:38,45.99it/s] 84%|########3 |145056/173481[57:00<11:12,42.24it/s] 84%|########3 |145190/173481[57:13<11:09,42.24it/s] 88%|########8 |152744/173481[1:00:00<08:08,42.47it/s] 88%|########8 |153365/173481[1:00:13<07:53,42.47it/s] 93%|#########2|161016/173481[1:03:00<04:42,44.15it/s] 93%|#########3|161602/173481[1:03:13<04:29,44.15it/s] 98%|#########7|169150/173481[1:06:00<01:36,44.66it/s] 98%|#########7|169770/173481[1:06:13<01:23,44.66it/s]100%|##########|173481/173481[1:07:42<00:00,42.70it/s]
[32m[0324 21:30:10 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:4062.74 sec.
[32m[0324 21:30:10 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######8  |14697/18822[03:00<00:50,81.65it/s] 83%|########2 |15615/18822[03:10<00:39,81.65it/s]100%|##########|18822/18822[03:48<00:00,82.25it/s]
40
[32m[0324 21:33:59 @monitor.py:363][0m QueueInput/queue_size: 0.79715
[32m[0324 21:33:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.29
[32m[0324 21:33:59 @monitor.py:363][0m activation-summaries/output-rms: 0.038841
[32m[0324 21:33:59 @monitor.py:363][0m cross_entropy_loss: 1.7184
[32m[0324 21:33:59 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60822
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3192
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0324 21:33:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 21:33:59 @monitor.py:363][0m train-error-top1: 0.4557
[32m[0324 21:33:59 @monitor.py:363][0m val-error-top1: 0.47474
[32m[0324 21:33:59 @monitor.py:363][0m val-utt-error: 0.12299
[32m[0324 21:33:59 @monitor.py:363][0m validation_cost: 1.8039
[32m[0324 21:33:59 @monitor.py:363][0m wd_cost: 9.6363e-10
[32m[0324 21:33:59 @group.py:42][0m Callbacks took 229.220 sec in total. InferenceRunner: 228.849sec
[32m[0324 21:33:59 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7485/173481[03:00<1:06:39,41.50it/s]  5%|4         |8084/173481[03:20<1:06:25,41.50it/s]  9%|8         |14761/173481[06:00<1:04:35,40.95it/s]  9%|8         |15533/173481[06:20<1:04:16,40.95it/s] 13%|#2        |22195/173481[09:00<1:01:19,41.12it/s] 13%|#3        |22642/173481[09:10<1:01:08,41.12it/s] 17%|#7        |29877/173481[12:00<57:08,41.88it/s]   17%|#7        |30304/173481[12:10<56:58,41.88it/s] 22%|##1       |37456/173481[15:00<53:59,41.99it/s] 22%|##1       |37879/173481[15:10<53:49,41.99it/s] 26%|##5       |44779/173481[18:00<51:54,41.33it/s] 26%|##6       |45200/173481[18:10<51:44,41.33it/s] 30%|##9       |51375/173481[21:00<52:23,38.84it/s] 30%|##9       |51810/173481[21:11<52:12,38.84it/s] 34%|###3      |58755/173481[24:00<47:56,39.88it/s] 34%|###4      |59189/173481[24:11<47:45,39.88it/s] 38%|###8      |66690/173481[27:00<42:30,41.87it/s] 39%|###8      |67194/173481[27:11<42:18,41.87it/s] 44%|####3     |75830/173481[30:00<35:27,45.90it/s] 44%|####4     |76414/173481[30:11<35:14,45.90it/s] 49%|####9     |85471/173481[33:00<29:40,49.43it/s] 50%|####9     |86094/173481[33:11<29:27,49.43it/s] 55%|#####4    |95154/173481[36:00<25:20,51.52it/s] 55%|#####5    |95792/173481[36:11<25:07,51.52it/s] 60%|#####9    |104045/173481[39:01<23:00,50.28it/s] 60%|######    |104211/173481[39:12<22:57,50.28it/s] 66%|######6   |114927/173481[42:01<17:46,54.90it/s] 67%|######6   |115515/173481[42:12<17:35,54.90it/s] 72%|#######1  |124621/173481[45:01<14:58,54.37it/s] 72%|#######2  |125219/173481[45:12<14:47,54.37it/s] 77%|#######7  |134248/173481[48:01<12:07,53.92it/s] 78%|#######7  |134848/173481[48:12<11:56,53.92it/s] 83%|########3 |144052/173481[51:01<09:03,54.19it/s] 83%|########3 |144649/173481[51:12<08:52,54.19it/s] 89%|########8 |153791/173481[54:01<06:03,54.15it/s] 89%|########8 |154383/173481[54:12<05:52,54.15it/s] 94%|#########3|162772/173481[57:01<03:26,51.93it/s] 94%|#########4|163246/173481[57:13<03:17,51.93it/s] 99%|#########9|171789/173481[1:00:01<00:33,50.99it/s] 99%|#########9|172389/173481[1:00:13<00:21,50.99it/s]100%|##########|173481/173481[1:00:33<00:00,47.74it/s]
[32m[0324 22:34:33 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3633.90 sec.
[32m[0324 22:34:34 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-7286202.
[32m[0324 22:34:34 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 84%|########4 |15852/18822[03:00<00:33,88.06it/s] 89%|########9 |16818/18822[03:10<00:22,88.06it/s]100%|##########|18822/18822[03:33<00:00,88.18it/s]
41
[32m[0324 22:38:07 @monitor.py:363][0m QueueInput/queue_size: 0.82747
[32m[0324 22:38:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.536
[32m[0324 22:38:07 @monitor.py:363][0m activation-summaries/output-rms: 0.039047
[32m[0324 22:38:07 @monitor.py:363][0m cross_entropy_loss: 1.759
[32m[0324 22:38:07 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60805
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0324 22:38:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 22:38:07 @monitor.py:363][0m train-error-top1: 0.47142
[32m[0324 22:38:07 @monitor.py:363][0m val-error-top1: 0.47739
[32m[0324 22:38:07 @monitor.py:363][0m val-utt-error: 0.1222
[32m[0324 22:38:07 @monitor.py:363][0m validation_cost: 1.8104
[32m[0324 22:38:07 @monitor.py:363][0m wd_cost: 1.9268e-10
[32m[0324 22:38:07 @group.py:42][0m Callbacks took 214.082 sec in total. InferenceRunner: 213.473sec
[32m[0324 22:38:07 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9401/173481[03:00<52:21,52.23it/s]  6%|5         |9929/173481[03:10<52:11,52.23it/s] 11%|#         |18712/173481[06:00<49:37,51.98it/s] 11%|#1        |19247/173481[06:10<49:27,51.98it/s] 16%|#6        |27929/173481[09:00<47:01,51.59it/s] 16%|#6        |28469/173481[09:10<46:51,51.59it/s] 21%|##        |36234/173481[12:00<46:57,48.71it/s] 21%|##1       |36771/173481[12:10<46:46,48.71it/s] 26%|##6       |45544/173481[15:00<42:30,50.17it/s] 27%|##6       |46139/173481[15:10<42:18,50.17it/s] 32%|###1      |54932/173481[18:00<38:38,51.14it/s] 32%|###1      |55507/173481[18:11<38:26,51.14it/s] 37%|###7      |64567/173481[21:00<34:42,52.31it/s] 38%|###7      |65135/173481[21:11<34:31,52.31it/s] 43%|####3     |74706/173481[24:00<30:21,54.24it/s] 43%|####3     |75292/173481[24:11<30:10,54.24it/s] 49%|####8     |84437/173481[27:00<27:24,54.15it/s] 49%|####9     |85049/173481[27:11<27:13,54.15it/s] 54%|#####4    |94515/173481[30:00<23:54,55.05it/s] 55%|#####4    |94648/173481[30:11<23:51,55.05it/s] 60%|#####9    |103894/173481[33:00<21:39,53.54it/s] 60%|######    |104570/173481[33:11<21:27,53.54it/s] 65%|######5   |113374/173481[36:00<18:52,53.08it/s] 66%|######5   |114013/173481[36:12<18:40,53.08it/s] 71%|#######   |123101/173481[39:00<15:40,53.55it/s] 71%|#######1  |123784/173481[39:12<15:28,53.55it/s] 77%|#######6  |133109/173481[42:00<12:20,54.56it/s] 77%|#######7  |133829/173481[42:12<12:06,54.56it/s] 82%|########2 |143056/173481[45:00<09:14,54.91it/s] 83%|########2 |143913/173481[45:12<08:58,54.91it/s] 89%|########8 |153991/173481[48:00<05:37,57.68it/s] 89%|########9 |154648/173481[48:12<05:26,57.68it/s] 94%|#########4|163244/173481[51:00<03:08,54.36it/s] 95%|#########4|163996/173481[51:12<02:54,54.36it/s] 98%|#########8|170776/173481[54:00<00:57,47.29it/s] 99%|#########8|171126/173481[54:13<00:49,47.29it/s]100%|##########|173481/173481[55:21<00:00,52.22it/s]
[32m[0324 23:33:29 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3321.98 sec.
[32m[0324 23:33:30 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######4  |13992/18822[03:00<01:02,77.73it/s] 79%|#######8  |14798/18822[03:10<00:51,77.73it/s]100%|##########|18822/18822[03:56<00:00,79.47it/s]
42
[32m[0324 23:37:27 @monitor.py:363][0m QueueInput/queue_size: 0.85097
[32m[0324 23:37:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.391
[32m[0324 23:37:27 @monitor.py:363][0m activation-summaries/output-rms: 0.039284
[32m[0324 23:37:27 @monitor.py:363][0m cross_entropy_loss: 1.7199
[32m[0324 23:37:27 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60788
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0324 23:37:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0324 23:37:27 @monitor.py:363][0m train-error-top1: 0.46133
[32m[0324 23:37:27 @monitor.py:363][0m val-error-top1: 0.4798
[32m[0324 23:37:27 @monitor.py:363][0m val-utt-error: 0.12671
[32m[0324 23:37:27 @monitor.py:363][0m validation_cost: 1.8241
[32m[0324 23:37:27 @monitor.py:363][0m wd_cost: 1.9264e-10
[32m[0324 23:37:27 @group.py:42][0m Callbacks took 237.400 sec in total. InferenceRunner: 236.878sec
[32m[0324 23:37:27 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |6966/173481[03:00<1:11:42,38.70it/s]  4%|4         |7322/173481[03:10<1:11:33,38.70it/s]  8%|7         |13283/173481[06:00<1:12:32,36.81it/s]  8%|7         |13662/173481[06:10<1:12:22,36.81it/s] 11%|#1        |19213/173481[09:00<1:13:57,34.76it/s] 11%|#1        |19594/173481[09:10<1:13:46,34.76it/s] 15%|#4        |25403/173481[12:00<1:11:23,34.57it/s] 15%|#4        |25762/173481[12:10<1:11:13,34.57it/s] 18%|#8        |32046/173481[15:00<1:06:01,35.70it/s] 19%|#8        |32364/173481[15:10<1:05:52,35.70it/s] 23%|##2       |39378/173481[18:00<58:44,38.05it/s]   23%|##3       |39907/173481[18:10<58:30,38.05it/s] 27%|##7       |47664/173481[21:00<50:19,41.66it/s] 28%|##7       |48167/173481[21:11<50:07,41.66it/s] 32%|###2      |55888/173481[24:00<44:59,43.56it/s] 33%|###2      |56412/173481[24:11<44:47,43.56it/s] 37%|###6      |63568/173481[27:00<42:29,43.11it/s] 37%|###6      |64047/173481[27:11<42:18,43.11it/s] 41%|####1     |71598/173481[30:00<38:43,43.84it/s] 42%|####1     |72064/173481[30:11<38:33,43.84it/s] 46%|####5     |79535/173481[33:00<35:36,43.97it/s] 46%|####6     |80152/173481[33:11<35:22,43.97it/s] 51%|#####     |88319/173481[36:00<30:40,46.26it/s] 51%|#####1    |88907/173481[36:11<30:28,46.26it/s] 56%|#####5    |97118/173481[39:00<26:46,47.53it/s] 56%|#####6    |97658/173481[39:12<26:35,47.53it/s] 61%|######1   |106100/173481[42:00<23:04,48.68it/s] 61%|######1   |106690/173481[42:12<22:51,48.68it/s] 66%|######5   |114417/173481[45:00<20:45,47.41it/s] 66%|######6   |115066/173481[45:12<20:32,47.41it/s] 71%|#######1  |123854/173481[48:00<16:36,49.79it/s] 72%|#######1  |124507/173481[48:12<16:23,49.79it/s] 77%|#######6  |133154/173481[51:00<13:15,50.71it/s] 77%|#######7  |133667/173481[51:12<13:05,50.71it/s] 81%|########  |140171/173481[54:00<12:35,44.08it/s] 81%|########1 |140644/173481[54:12<12:24,44.08it/s] 85%|########4 |147051/173481[57:00<10:45,40.94it/s] 85%|########5 |147838/173481[57:12<10:26,40.94it/s] 91%|#########1|157945/173481[1:00:00<05:18,48.84it/s] 91%|#########1|158734/173481[1:00:13<05:01,48.84it/s] 97%|#########7|169098/173481[1:03:00<01:20,54.62it/s] 98%|#########7|169873/173481[1:03:13<01:06,54.62it/s]100%|##########|173481/173481[1:04:21<00:00,44.93it/s]
[32m[0325 00:41:48 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3861.27 sec.
[32m[0325 00:41:48 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-7633164.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:27<00:00,127.66it/s]
43
[32m[0325 00:44:16 @monitor.py:363][0m QueueInput/queue_size: 1.0757
[32m[0325 00:44:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.229
[32m[0325 00:44:16 @monitor.py:363][0m activation-summaries/output-rms: 0.038623
[32m[0325 00:44:16 @monitor.py:363][0m cross_entropy_loss: 1.7315
[32m[0325 00:44:16 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60778
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 00:44:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 00:44:16 @monitor.py:363][0m train-error-top1: 0.46222
[32m[0325 00:44:16 @monitor.py:363][0m val-error-top1: 0.47278
[32m[0325 00:44:16 @monitor.py:363][0m val-utt-error: 0.12071
[32m[0325 00:44:16 @monitor.py:363][0m validation_cost: 1.7948
[32m[0325 00:44:16 @monitor.py:363][0m wd_cost: 1.9261e-10
[32m[0325 00:44:16 @group.py:42][0m Callbacks took 147.922 sec in total. InferenceRunner: 147.458sec
[32m[0325 00:44:16 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10132/173481[03:00<48:22,56.28it/s]  6%|5         |10286/173481[03:10<48:19,56.28it/s] 12%|#1        |19962/173481[06:00<46:09,55.43it/s] 12%|#1        |20547/173481[06:10<45:58,55.43it/s] 18%|#7        |31032/173481[09:00<40:43,58.31it/s] 18%|#8        |31729/173481[09:10<40:31,58.31it/s] 25%|##4       |42632/173481[12:00<35:37,61.22it/s] 25%|##4       |43251/173481[12:10<35:27,61.22it/s] 31%|###1      |54182/173481[15:00<31:44,62.66it/s] 32%|###1      |54906/173481[15:10<31:32,62.66it/s] 37%|###7      |64366/173481[18:00<30:35,59.46it/s] 37%|###7      |65035/173481[18:10<30:23,59.46it/s] 44%|####3     |75488/173481[21:00<26:56,60.60it/s] 44%|####3     |76158/173481[21:11<26:45,60.60it/s] 50%|####9     |86147/173481[24:00<24:18,59.90it/s] 50%|#####     |86821/173481[24:11<24:06,59.90it/s] 55%|#####4    |94551/173481[27:00<25:04,52.47it/s] 55%|#####4    |95109/173481[27:11<24:53,52.47it/s] 59%|#####9    |103152/173481[30:00<23:26,50.02it/s] 60%|#####9    |103705/173481[30:11<23:15,50.02it/s] 64%|######4   |111152/173481[33:00<22:04,47.06it/s] 64%|######4   |111699/173481[33:11<21:52,47.06it/s] 69%|######9   |120055/173481[36:00<18:27,48.23it/s] 70%|######9   |120607/173481[36:11<18:16,48.23it/s] 74%|#######4  |128768/173481[39:00<15:25,48.32it/s] 75%|#######4  |129304/173481[39:12<15:14,48.32it/s] 79%|#######9  |137244/173481[42:00<12:39,47.69it/s] 79%|#######9  |137797/173481[42:12<12:28,47.69it/s] 84%|########3 |145065/173481[45:00<10:24,45.47it/s] 84%|########3 |145634/173481[45:12<10:12,45.47it/s] 89%|########8 |153597/173481[48:00<07:08,46.41it/s] 89%|########8 |154097/173481[48:12<06:57,46.41it/s] 93%|#########3|161396/173481[51:00<04:29,44.81it/s] 93%|#########3|161576/173481[51:12<04:25,44.81it/s] 97%|#########6|167677/173481[54:00<02:27,39.24it/s] 97%|#########6|168176/173481[54:12<02:15,39.24it/s][32m[0325 01:40:37 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:3381.40 sec.
100%|##########|173481/173481[56:21<00:00,51.30it/s]
[32m[0325 01:40:38 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-7806645.
[32m[0325 01:40:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 75%|#######4  |14104/18822[03:00<01:00,78.35it/s] 79%|#######8  |14860/18822[03:10<00:50,78.35it/s]100%|##########|18822/18822[03:57<00:00,79.10it/s]
44
[32m[0325 01:44:37 @monitor.py:363][0m QueueInput/queue_size: 1.5831
[32m[0325 01:44:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.303
[32m[0325 01:44:37 @monitor.py:363][0m activation-summaries/output-rms: 0.040492
[32m[0325 01:44:37 @monitor.py:363][0m cross_entropy_loss: 1.6945
[32m[0325 01:44:37 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60775
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 01:44:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 01:44:37 @monitor.py:363][0m train-error-top1: 0.46133
[32m[0325 01:44:37 @monitor.py:363][0m val-error-top1: 0.47288
[32m[0325 01:44:37 @monitor.py:363][0m val-utt-error: 0.12076
[32m[0325 01:44:37 @monitor.py:363][0m validation_cost: 1.792
[32m[0325 01:44:37 @monitor.py:363][0m wd_cost: 3.8521e-11
[32m[0325 01:44:37 @group.py:42][0m Callbacks took 239.325 sec in total. InferenceRunner: 237.987sec
[32m[0325 01:44:37 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9494/173481[03:00<51:49,52.74it/s]  6%|5         |10003/173481[03:10<51:39,52.74it/s] 11%|#         |18597/173481[06:00<49:59,51.63it/s] 11%|#1        |19142/173481[06:10<49:49,51.63it/s] 15%|#5        |26726/173481[09:00<50:45,48.18it/s] 16%|#5        |27211/173481[09:10<50:35,48.18it/s] 20%|##        |35122/173481[12:00<48:39,47.40it/s] 21%|##        |35642/173481[12:10<48:28,47.40it/s] 25%|##4       |42561/173481[15:00<49:25,44.15it/s] 25%|##4       |43029/173481[15:10<49:14,44.15it/s] 29%|##9       |50618/173481[18:00<46:03,44.45it/s] 29%|##9       |51125/173481[18:11<45:52,44.45it/s] 34%|###3      |58935/173481[21:00<42:07,45.31it/s] 34%|###4      |59459/173481[21:11<41:56,45.31it/s] 39%|###8      |67197/173481[24:00<38:50,45.60it/s] 39%|###8      |67581/173481[24:11<38:42,45.60it/s] 43%|####3     |75173/173481[27:00<36:27,44.94it/s] 44%|####3     |75669/173481[27:11<36:16,44.94it/s] 48%|####7     |83110/173481[30:00<33:50,44.51it/s] 48%|####8     |83603/173481[30:11<33:39,44.51it/s] 53%|#####2    |91087/173481[33:00<30:55,44.41it/s] 53%|#####2    |91607/173481[33:11<30:43,44.41it/s] 57%|#####6    |98334/173481[36:00<29:39,42.23it/s] 57%|#####6    |98833/173481[36:11<29:27,42.23it/s] 61%|######1   |106131/173481[39:00<26:15,42.76it/s] 61%|######1   |106675/173481[39:12<26:02,42.76it/s] 66%|######5   |113633/173481[42:00<23:37,42.21it/s] 66%|######5   |114047/173481[42:12<23:28,42.21it/s] 69%|######9   |120427/173481[45:00<22:11,39.85it/s] 70%|######9   |120910/173481[45:12<21:59,39.85it/s] 73%|#######3  |127360/173481[48:00<19:37,39.17it/s] 74%|#######3  |127855/173481[48:12<19:24,39.17it/s] 78%|#######7  |134476/173481[51:00<16:31,39.35it/s] 78%|#######7  |134986/173481[51:13<16:18,39.35it/s] 82%|########1 |141460/173481[54:00<13:39,39.07it/s] 82%|########1 |141990/173481[54:13<13:25,39.07it/s] 85%|########5 |147731/173481[57:00<11:39,36.79it/s] 85%|########5 |148229/173481[57:13<11:26,36.79it/s] 89%|########9 |154429/173481[1:00:00<08:34,37.00it/s] 89%|########9 |154925/173481[1:00:13<08:21,37.00it/s] 93%|#########2|161171/173481[1:03:00<05:30,37.22it/s] 93%|#########3|161667/173481[1:03:13<05:17,37.22it/s] 97%|#########6|168230/173481[1:06:00<02:17,38.19it/s] 97%|#########7|168776/173481[1:06:13<02:03,38.19it/s]100%|##########|173481/173481[1:08:06<00:00,42.45it/s]
[32m[0325 02:52:44 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:4086.93 sec.
[32m[0325 02:52:46 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-7980126.
  0%|          |0/18822[00:00<?,?it/s] 72%|#######2  |13595/18822[03:00<01:09,75.52it/s] 76%|#######6  |14366/18822[03:10<00:59,75.52it/s]100%|##########|18822/18822[04:06<00:00,76.23it/s]
45
[32m[0325 02:56:53 @monitor.py:363][0m QueueInput/queue_size: 0.59916
[32m[0325 02:56:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.263
[32m[0325 02:56:53 @monitor.py:363][0m activation-summaries/output-rms: 0.038946
[32m[0325 02:56:53 @monitor.py:363][0m cross_entropy_loss: 1.7183
[32m[0325 02:56:53 @monitor.py:363][0m lr: 1.5259e-08
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60772
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 02:56:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 02:56:53 @monitor.py:363][0m train-error-top1: 0.45446
[32m[0325 02:56:53 @monitor.py:363][0m val-error-top1: 0.47358
[32m[0325 02:56:53 @monitor.py:363][0m val-utt-error: 0.12363
[32m[0325 02:56:53 @monitor.py:363][0m validation_cost: 1.7973
[32m[0325 02:56:53 @monitor.py:363][0m wd_cost: 3.8519e-11
[32m[0325 02:56:53 @group.py:42][0m Callbacks took 248.937 sec in total. InferenceRunner: 246.981sec
[32m[0325 02:56:53 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |7880/173481[03:00<1:03:02,43.78it/s]  5%|4         |8319/173481[03:10<1:02:52,43.78it/s]  9%|8         |15345/173481[06:00<1:01:52,42.59it/s]  9%|9         |15802/173481[06:10<1:01:42,42.59it/s] 14%|#3        |23539/173481[09:00<56:47,44.01it/s]   14%|#3        |24041/173481[09:10<56:35,44.01it/s] 18%|#8        |31833/173481[12:00<52:26,45.02it/s] 19%|#8        |32314/173481[12:10<52:15,45.02it/s] 23%|##2       |39768/173481[15:00<50:02,44.54it/s] 23%|##3       |40234/173481[15:10<49:51,44.54it/s] 28%|##7       |47727/173481[18:00<47:13,44.38it/s] 28%|##7       |48212/173481[18:10<47:02,44.38it/s] 32%|###2      |55990/173481[21:00<43:23,45.13it/s] 33%|###2      |56525/173481[21:11<43:11,45.13it/s] 37%|###6      |63866/173481[24:00<41:07,44.43it/s] 37%|###7      |64319/173481[24:11<40:56,44.43it/s] 41%|####1     |71905/173481[27:00<38:00,44.54it/s] 42%|####1     |72375/173481[27:11<37:49,44.54it/s] 45%|####4     |77876/173481[30:00<41:54,38.02it/s] 45%|####5     |78409/173481[30:11<41:40,38.02it/s] 50%|####9     |85927/173481[33:00<35:30,41.10it/s] 50%|####9     |86488/173481[33:11<35:16,41.10it/s] 54%|#####4    |94075/173481[36:00<30:43,43.08it/s] 55%|#####4    |94606/173481[36:11<30:30,43.08it/s] 59%|#####8    |101999/173481[39:00<27:21,43.54it/s] 59%|#####9    |102517/173481[39:12<27:09,43.54it/s] 63%|######3   |109322/173481[42:00<25:25,42.06it/s] 63%|######3   |109813/173481[42:12<25:13,42.06it/s] 67%|######7   |116732/173481[45:00<22:43,41.61it/s] 68%|######7   |117223/173481[45:12<22:32,41.61it/s] 72%|#######1  |124069/173481[48:00<19:59,41.18it/s] 72%|#######1  |124521/173481[48:12<19:48,41.18it/s] 76%|#######5  |131266/173481[51:00<17:20,40.57it/s] 76%|#######5  |131820/173481[51:12<17:06,40.57it/s] 80%|#######9  |138431/173481[54:00<14:32,40.18it/s] 80%|########  |138977/173481[54:12<14:18,40.18it/s] 84%|########4 |146360/173481[57:00<10:45,42.02it/s] 85%|########4 |146927/173481[57:13<10:31,42.02it/s] 89%|########8 |154210/173481[1:00:00<07:30,42.80it/s] 89%|########9 |154745/173481[1:00:13<07:17,42.80it/s] 93%|#########3|161795/173481[1:03:00<04:35,42.46it/s] 94%|#########3|162311/173481[1:03:13<04:23,42.46it/s] 98%|#########7|169505/173481[1:06:00<01:33,42.64it/s] 98%|#########8|170053/173481[1:06:13<01:20,42.64it/s]100%|##########|173481/173481[1:07:36<00:00,42.77it/s]
[32m[0325 04:04:29 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:4056.59 sec.
[32m[0325 04:04:30 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-8153607.
  0%|          |0/18822[00:00<?,?it/s] 74%|#######3  |13905/18822[03:00<01:03,77.25it/s] 78%|#######8  |14758/18822[03:10<00:52,77.25it/s]100%|##########|18822/18822[04:01<00:00,78.09it/s]
46
[32m[0325 04:08:31 @monitor.py:363][0m QueueInput/queue_size: 0.74992
[32m[0325 04:08:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.425
[32m[0325 04:08:31 @monitor.py:363][0m activation-summaries/output-rms: 0.039262
[32m[0325 04:08:31 @monitor.py:363][0m cross_entropy_loss: 1.7311
[32m[0325 04:08:31 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60771
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 04:08:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 04:08:31 @monitor.py:363][0m train-error-top1: 0.46124
[32m[0325 04:08:31 @monitor.py:363][0m val-error-top1: 0.46952
[32m[0325 04:08:31 @monitor.py:363][0m val-utt-error: 0.11906
[32m[0325 04:08:31 @monitor.py:363][0m validation_cost: 1.7797
[32m[0325 04:08:31 @monitor.py:363][0m wd_cost: 3.8519e-11
[32m[0325 04:08:31 @group.py:42][0m Callbacks took 241.497 sec in total. InferenceRunner: 241.064sec
[32m[0325 04:08:31 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7240/173481[03:00<1:08:53,40.22it/s]  4%|4         |7683/173481[03:10<1:08:42,40.22it/s]  9%|8         |14794/173481[06:00<1:04:23,41.07it/s]  9%|8         |15263/173481[06:10<1:04:12,41.07it/s] 13%|#2        |22290/173481[09:00<1:00:55,41.36it/s] 13%|#3        |22797/173481[09:10<1:00:43,41.36it/s] 17%|#6        |29367/173481[12:00<59:35,40.31it/s]   17%|#7        |29851/173481[12:10<59:23,40.31it/s] 21%|##1       |37198/173481[15:00<54:16,41.84it/s] 22%|##1       |37688/173481[15:10<54:05,41.84it/s] 26%|##5       |44867/173481[18:00<50:46,42.22it/s] 26%|##6       |45357/173481[18:10<50:34,42.22it/s] 30%|###       |52831/173481[21:00<46:32,43.21it/s] 31%|###       |53340/173481[21:11<46:20,43.21it/s] 35%|###4      |60519/173481[24:00<43:51,42.93it/s] 35%|###4      |60623/173481[24:11<43:48,42.93it/s] 39%|###9      |67731/173481[27:00<42:31,41.45it/s] 39%|###9      |68244/173481[27:11<42:18,41.45it/s] 44%|####3     |75566/173481[30:00<38:25,42.46it/s] 44%|####3     |76072/173481[30:11<38:14,42.46it/s] 48%|####8     |83604/173481[33:00<34:24,43.53it/s] 48%|####8     |84107/173481[33:11<34:13,43.53it/s] 53%|#####2    |91609/173481[36:00<31:01,43.99it/s] 53%|#####3    |92043/173481[36:12<30:51,43.99it/s] 57%|#####7    |99516/173481[39:00<28:02,43.96it/s] 58%|#####7    |100049/173481[39:12<27:50,43.96it/s] 62%|######1   |107459/173481[42:00<24:59,44.04it/s] 62%|######2   |108033/173481[42:12<24:46,44.04it/s] 67%|######6   |115436/173481[45:00<21:53,44.18it/s] 67%|######6   |115989/173481[45:12<21:41,44.18it/s] 71%|#######   |122361/173481[48:00<20:42,41.13it/s] 71%|#######   |122905/173481[48:12<20:29,41.13it/s] 75%|#######5  |130710/173481[51:00<16:21,43.60it/s] 76%|#######5  |131260/173481[51:12<16:08,43.60it/s] 80%|########  |139135/173481[54:00<12:40,45.14it/s] 81%|########  |139679/173481[54:12<12:28,45.14it/s] 85%|########4 |147165/173481[57:00<09:46,44.87it/s] 85%|########5 |147711/173481[57:13<09:34,44.87it/s] 90%|########9 |155544/173481[1:00:00<06:32,45.69it/s] 90%|########9 |156085/173481[1:00:13<06:20,45.69it/s] 94%|#########4|163804/173481[1:03:00<03:31,45.79it/s] 95%|#########4|164422/173481[1:03:13<03:17,45.79it/s] 99%|#########8|171657/173481[1:06:00<00:40,44.68it/s] 99%|#########9|172277/173481[1:06:13<00:26,44.68it/s]100%|##########|173481/173481[1:06:41<00:00,43.35it/s]
[32m[0325 05:15:13 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:4001.82 sec.
[32m[0325 05:15:13 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-8327088.
[32m[0325 05:15:13 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 65%|######5   |12278/18822[03:00<01:35,68.21it/s] 70%|######9   |13097/18822[03:10<01:23,68.21it/s]100%|##########|18822/18822[04:22<00:00,71.70it/s]
47
[32m[0325 05:19:36 @monitor.py:363][0m QueueInput/queue_size: 5.5634
[32m[0325 05:19:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.409
[32m[0325 05:19:36 @monitor.py:363][0m activation-summaries/output-rms: 0.039491
[32m[0325 05:19:36 @monitor.py:363][0m cross_entropy_loss: 1.6976
[32m[0325 05:19:36 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 05:19:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 05:19:36 @monitor.py:363][0m train-error-top1: 0.45991
[32m[0325 05:19:36 @monitor.py:363][0m val-error-top1: 0.46977
[32m[0325 05:19:36 @monitor.py:363][0m val-utt-error: 0.11959
[32m[0325 05:19:36 @monitor.py:363][0m validation_cost: 1.7756
[32m[0325 05:19:36 @monitor.py:363][0m wd_cost: 7.7037e-12
[32m[0325 05:19:36 @group.py:42][0m Callbacks took 263.315 sec in total. InferenceRunner: 262.538sec
[32m[0325 05:19:36 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8666/173481[03:00<57:03,48.14it/s]  5%|5         |9153/173481[03:10<56:53,48.14it/s]  9%|9         |16426/173481[06:00<57:32,45.49it/s] 10%|9         |16872/173481[06:10<57:23,45.49it/s] 14%|#3        |24128/173481[09:00<56:27,44.09it/s] 14%|#4        |24614/173481[09:10<56:16,44.09it/s] 18%|#7        |30926/173481[12:00<58:24,40.68it/s] 18%|#8        |31405/173481[12:10<58:12,40.68it/s] 23%|##2       |39054/173481[15:00<52:20,42.80it/s] 23%|##2       |39579/173481[15:10<52:08,42.80it/s] 27%|##7       |47432/173481[18:00<47:06,44.59it/s] 28%|##7       |47986/173481[18:10<46:54,44.59it/s] 32%|###1      |54986/173481[21:00<45:40,43.24it/s] 32%|###1      |55509/173481[21:11<45:28,43.24it/s] 37%|###7      |64445/173481[24:00<38:18,47.44it/s] 38%|###7      |65065/173481[24:11<38:05,47.44it/s] 42%|####2     |73595/173481[27:00<33:55,49.08it/s] 43%|####2     |74017/173481[27:11<33:46,49.08it/s] 48%|####7     |82765/173481[30:00<30:14,49.99it/s] 48%|####8     |83319/173481[30:11<30:03,49.99it/s] 53%|#####2    |91777/173481[33:00<27:13,50.03it/s] 53%|#####3    |92351/173481[33:11<27:01,50.03it/s] 58%|#####7    |100584/173481[36:00<24:33,49.47it/s] 58%|#####8    |101227/173481[36:12<24:20,49.47it/s] 63%|######3   |110078/173481[39:00<20:41,51.05it/s] 64%|######3   |110675/173481[39:12<20:30,51.05it/s] 68%|######8   |118560/173481[42:00<18:40,49.01it/s] 69%|######8   |119144/173481[42:12<18:28,49.01it/s] 73%|#######3  |126939/173481[45:00<16:14,47.75it/s] 74%|#######3  |127587/173481[45:12<16:01,47.75it/s] 78%|#######8  |136078/173481[48:00<12:40,49.21it/s] 79%|#######8  |136707/173481[48:12<12:27,49.21it/s] 84%|########3 |145114/173481[51:00<09:30,49.70it/s] 84%|########4 |145727/173481[51:12<09:18,49.70it/s] 89%|########8 |154053/173481[54:00<06:31,49.68it/s] 89%|########9 |154688/173481[54:12<06:18,49.68it/s] 94%|#########3|163069/173481[57:00<03:28,49.88it/s] 94%|#########4|163725/173481[57:13<03:15,49.88it/s] 99%|#########9|171908/173481[1:00:00<00:31,49.49it/s] 99%|#########9|172482/173481[1:00:13<00:20,49.49it/s]100%|##########|173481/173481[1:00:54<00:00,47.47it/s]
[32m[0325 06:20:31 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:3654.89 sec.
[32m[0325 06:20:32 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-8500569.
  0%|          |0/18822[00:00<?,?it/s] 82%|########1 |15356/18822[03:00<00:40,85.31it/s] 86%|########6 |16189/18822[03:10<00:30,85.31it/s]100%|##########|18822/18822[03:38<00:00,86.10it/s]
48
[32m[0325 06:24:11 @monitor.py:363][0m QueueInput/queue_size: 0.84558
[32m[0325 06:24:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.202
[32m[0325 06:24:11 @monitor.py:363][0m activation-summaries/output-rms: 0.038826
[32m[0325 06:24:11 @monitor.py:363][0m cross_entropy_loss: 1.7223
[32m[0325 06:24:11 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 06:24:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 06:24:11 @monitor.py:363][0m train-error-top1: 0.45974
[32m[0325 06:24:11 @monitor.py:363][0m val-error-top1: 0.46544
[32m[0325 06:24:11 @monitor.py:363][0m val-utt-error: 0.11816
[32m[0325 06:24:11 @monitor.py:363][0m validation_cost: 1.7646
[32m[0325 06:24:11 @monitor.py:363][0m wd_cost: 7.7037e-12
[32m[0325 06:24:11 @group.py:42][0m Callbacks took 220.007 sec in total. InferenceRunner: 218.633sec
[32m[0325 06:24:11 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10035/173481[03:00<48:51,55.75it/s]  6%|6         |10545/173481[03:10<48:42,55.75it/s] 11%|#1        |19184/173481[06:00<48:21,53.17it/s] 11%|#1        |19771/173481[06:10<48:10,53.17it/s] 17%|#6        |29147/173481[09:00<44:21,54.24it/s] 17%|#7        |29716/173481[09:10<44:10,54.24it/s] 22%|##2       |38836/173481[12:00<41:31,54.03it/s] 23%|##2       |39422/173481[12:10<41:21,54.03it/s] 27%|##7       |47473/173481[15:00<41:19,50.83it/s] 28%|##7       |48013/173481[15:10<41:08,50.83it/s] 33%|###2      |56960/173481[18:00<37:31,51.75it/s] 33%|###3      |57580/173481[18:10<37:19,51.75it/s] 39%|###9      |68469/173481[21:00<30:35,57.20it/s] 40%|###9      |69091/173481[21:11<30:24,57.20it/s] 46%|####5     |79768/173481[24:00<26:05,59.86it/s] 46%|####6     |80500/173481[24:11<25:53,59.86it/s] 53%|#####2    |91707/173481[27:00<21:39,62.92it/s] 53%|#####3    |92471/173481[27:11<21:27,62.92it/s] 59%|#####8    |101864/173481[30:00<20:03,59.50it/s] 59%|#####9    |102460/173481[30:11<19:53,59.50it/s] 64%|######3   |110326/173481[33:00<20:02,52.52it/s] 64%|######3   |110997/173481[33:11<19:49,52.52it/s] 69%|######9   |120262/173481[36:00<16:28,53.83it/s] 70%|######9   |120951/173481[36:11<16:15,53.83it/s] 75%|#######4  |129749/173481[39:00<13:41,53.26it/s] 75%|#######5  |130358/173481[39:12<13:29,53.26it/s] 80%|########  |139046/173481[42:00<10:56,52.44it/s] 81%|########  |139736/173481[42:12<10:43,52.44it/s] 86%|########5 |148391/173481[45:00<08:00,52.18it/s] 86%|########5 |149042/173481[45:12<07:48,52.18it/s] 91%|######### |157733/173481[48:00<05:02,52.04it/s] 91%|#########1|158408/173481[48:12<04:49,52.04it/s] 96%|#########5|166057/173481[51:00<02:31,48.97it/s] 96%|#########6|166677/173481[51:12<02:18,48.97it/s]100%|##########|173481/173481[53:33<00:00,53.99it/s]
[32m[0325 07:17:44 @base.py:257][0m Epoch 51 (global_step 8674050) finished, time:3213.51 sec.
[32m[0325 07:17:44 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-8674050.
[32m[0325 07:17:45 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 85%|########4 |15926/18822[03:00<00:32,88.47it/s] 90%|######### |16945/18822[03:10<00:21,88.47it/s]100%|##########|18822/18822[03:30<00:00,89.53it/s]
49
[32m[0325 07:21:15 @monitor.py:363][0m QueueInput/queue_size: 0.71616
[32m[0325 07:21:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.396
[32m[0325 07:21:15 @monitor.py:363][0m activation-summaries/output-rms: 0.040438
[32m[0325 07:21:15 @monitor.py:363][0m cross_entropy_loss: 1.689
[32m[0325 07:21:15 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 07:21:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 07:21:15 @monitor.py:363][0m train-error-top1: 0.45652
[32m[0325 07:21:15 @monitor.py:363][0m val-error-top1: 0.46614
[32m[0325 07:21:15 @monitor.py:363][0m val-utt-error: 0.11864
[32m[0325 07:21:15 @monitor.py:363][0m validation_cost: 1.7651
[32m[0325 07:21:15 @monitor.py:363][0m wd_cost: 1.5407e-12
[32m[0325 07:21:15 @group.py:42][0m Callbacks took 210.701 sec in total. InferenceRunner: 210.252sec
[32m[0325 07:21:15 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9778/173481[03:00<50:13,54.32it/s]  6%|5         |10302/173481[03:10<50:03,54.32it/s] 11%|#         |18956/173481[06:00<48:58,52.59it/s] 11%|#1        |19470/173481[06:10<48:48,52.59it/s] 16%|#6        |27881/173481[09:00<47:32,51.04it/s] 16%|#6        |28408/173481[09:10<47:22,51.04it/s] 21%|##        |36131/173481[12:00<47:24,48.29it/s] 21%|##1       |36635/173481[12:10<47:13,48.29it/s] 26%|##6       |45277/173481[15:00<43:08,49.52it/s] 26%|##6       |45905/173481[15:10<42:56,49.52it/s] 32%|###1      |54912/173481[18:00<38:24,51.44it/s] 32%|###2      |55630/173481[18:10<38:10,51.44it/s] 38%|###7      |65111/173481[21:00<33:29,53.92it/s] 38%|###7      |65703/173481[21:11<33:18,53.92it/s] 43%|####3     |74993/173481[24:00<30:10,54.41it/s] 44%|####3     |75624/173481[24:11<29:58,54.41it/s] 49%|####8     |84938/173481[27:00<26:55,54.82it/s] 49%|####9     |85578/173481[27:11<26:43,54.82it/s] 54%|#####4    |93727/173481[30:00<25:44,51.65it/s] 54%|#####4    |94331/173481[30:11<25:32,51.65it/s] 60%|#####9    |103470/173481[33:00<22:04,52.86it/s] 60%|#####9    |104069/173481[33:11<21:53,52.86it/s] 65%|######5   |112771/173481[36:00<19:21,52.26it/s] 65%|######5   |113395/173481[36:11<19:09,52.26it/s] 71%|#######   |122415/173481[39:00<16:05,52.91it/s] 71%|#######   |123040/173481[39:12<15:53,52.91it/s] 76%|#######6  |132027/173481[42:00<12:59,53.15it/s] 76%|#######6  |132659/173481[42:12<12:48,53.15it/s] 82%|########1 |141575/173481[45:00<10:00,53.10it/s] 82%|########1 |142230/173481[45:12<09:48,53.10it/s] 87%|########6 |150426/173481[48:00<07:31,51.06it/s] 87%|########7 |151100/173481[48:12<07:18,51.06it/s] 92%|#########2|160099/173481[51:00<04:15,52.36it/s] 93%|#########2|160780/173481[51:12<04:02,52.36it/s] 98%|#########7|169348/173481[54:00<01:19,51.87it/s] 98%|#########8|170030/173481[54:13<01:06,51.87it/s]100%|##########|173481/173481[55:19<00:00,52.26it/s]
[32m[0325 08:16:34 @base.py:257][0m Epoch 52 (global_step 8847531) finished, time:3319.30 sec.
[32m[0325 08:16:35 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-8847531.
  0%|          |0/18822[00:00<?,?it/s] 87%|########7 |16385/18822[03:00<00:26,91.02it/s] 93%|#########3|17546/18822[03:10<00:14,91.02it/s]100%|##########|18822/18822[03:24<00:00,92.25it/s]
50
[32m[0325 08:20:00 @monitor.py:363][0m QueueInput/queue_size: 0.62509
[32m[0325 08:20:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.336
[32m[0325 08:20:00 @monitor.py:363][0m activation-summaries/output-rms: 0.038642
[32m[0325 08:20:00 @monitor.py:363][0m cross_entropy_loss: 1.6999
[32m[0325 08:20:00 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 08:20:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 08:20:00 @monitor.py:363][0m train-error-top1: 0.44957
[32m[0325 08:20:00 @monitor.py:363][0m val-error-top1: 0.46489
[32m[0325 08:20:00 @monitor.py:363][0m val-utt-error: 0.118
[32m[0325 08:20:00 @monitor.py:363][0m validation_cost: 1.7606
[32m[0325 08:20:00 @monitor.py:363][0m wd_cost: 1.5407e-12
[32m[0325 08:20:00 @group.py:42][0m Callbacks took 205.200 sec in total. InferenceRunner: 204.056sec
[32m[0325 08:20:00 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9672/173481[03:00<50:48,53.73it/s]  6%|5         |10166/173481[03:10<50:39,53.73it/s] 11%|#         |18803/173481[06:00<49:24,52.18it/s] 11%|#1        |19343/173481[06:10<49:13,52.18it/s] 16%|#5        |27029/173481[09:00<50:05,48.73it/s] 16%|#5        |27523/173481[09:10<49:55,48.73it/s] 21%|##        |36047/173481[12:00<46:21,49.40it/s] 21%|##1       |36574/173481[12:10<46:11,49.40it/s] 26%|##5       |45001/173481[15:00<43:11,49.57it/s] 26%|##6       |45542/173481[15:10<43:00,49.57it/s] 31%|###1      |53954/173481[18:00<40:07,49.65it/s] 31%|###1      |54494/173481[18:11<39:56,49.65it/s] 36%|###6      |63015/173481[21:00<36:49,49.99it/s] 37%|###6      |63569/173481[21:11<36:38,49.99it/s] 41%|####1     |71849/173481[24:00<34:11,49.53it/s] 42%|####1     |72299/173481[24:11<34:02,49.53it/s] 46%|####5     |79677/173481[27:00<33:45,46.31it/s] 46%|####6     |80229/173481[27:11<33:33,46.31it/s] 51%|#####     |88000/173481[30:00<30:47,46.27it/s] 51%|#####1    |88569/173481[30:11<30:35,46.27it/s] 55%|#####5    |96110/173481[33:00<28:14,45.65it/s] 56%|#####5    |96565/173481[33:11<28:04,45.65it/s] 61%|######    |105147/173481[36:00<23:48,47.82it/s] 61%|######    |105733/173481[36:12<23:36,47.82it/s] 66%|######5   |114461/173481[39:00<19:47,49.70it/s] 66%|######6   |115075/173481[39:12<19:35,49.70it/s] 71%|#######1  |123260/173481[42:00<17:00,49.24it/s] 71%|#######1  |123364/173481[42:12<16:57,49.24it/s] 76%|#######5  |131465/173481[45:00<14:47,47.34it/s] 76%|#######6  |132064/173481[45:12<14:34,47.34it/s] 81%|########  |140299/173481[48:00<11:28,48.19it/s] 81%|########1 |140848/173481[48:12<11:17,48.19it/s] 86%|########5 |148880/173481[51:00<08:33,47.92it/s] 86%|########6 |149479/173481[51:12<08:20,47.92it/s] 91%|######### |157851/173481[54:00<05:19,48.86it/s] 91%|#########1|158503/173481[54:13<05:06,48.86it/s] 97%|#########6|167707/173481[57:00<01:51,51.64it/s] 97%|#########7|168486/173481[57:13<01:36,51.64it/s]100%|##########|173481/173481[58:44<00:00,49.22it/s]
[32m[0325 09:18:44 @base.py:257][0m Epoch 53 (global_step 9021012) finished, time:3524.63 sec.
[32m[0325 09:18:45 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-9021012.
[32m[0325 09:18:45 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 81%|########  |15171/18822[03:00<00:43,84.28it/s] 86%|########5 |16124/18822[03:10<00:32,84.28it/s]100%|##########|18822/18822[03:37<00:00,86.55it/s]
51
[32m[0325 09:22:22 @monitor.py:363][0m QueueInput/queue_size: 0.63601
[32m[0325 09:22:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.495
[32m[0325 09:22:22 @monitor.py:363][0m activation-summaries/output-rms: 0.039226
[32m[0325 09:22:22 @monitor.py:363][0m cross_entropy_loss: 1.721
[32m[0325 09:22:22 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 09:22:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 09:22:22 @monitor.py:363][0m train-error-top1: 0.45972
[32m[0325 09:22:22 @monitor.py:363][0m val-error-top1: 0.46298
[32m[0325 09:22:22 @monitor.py:363][0m val-utt-error: 0.11433
[32m[0325 09:22:22 @monitor.py:363][0m validation_cost: 1.7503
[32m[0325 09:22:22 @monitor.py:363][0m wd_cost: 1.5407e-12
[32m[0325 09:22:22 @group.py:42][0m Callbacks took 218.113 sec in total. InferenceRunner: 217.475sec
[32m[0325 09:22:22 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10492/173481[03:00<46:36,58.29it/s]  6%|6         |10883/173481[03:10<46:29,58.29it/s] 11%|#         |18797/173481[06:00<50:03,51.51it/s] 11%|#1        |19323/173481[06:10<49:53,51.51it/s] 16%|#5        |27633/173481[09:00<48:21,50.27it/s] 16%|#6        |28140/173481[09:10<48:11,50.27it/s] 21%|##        |36024/173481[12:00<47:21,48.37it/s] 21%|##1       |36599/173481[12:10<47:10,48.37it/s] 26%|##5       |44574/173481[15:00<44:49,47.93it/s] 26%|##5       |45029/173481[15:10<44:40,47.93it/s] 30%|##9       |51945/173481[18:00<45:51,44.16it/s] 30%|###       |52448/173481[18:10<45:40,44.16it/s] 35%|###4      |60229/173481[21:00<41:52,45.07it/s] 35%|###5      |60753/173481[21:11<41:41,45.07it/s] 40%|###9      |68704/173481[24:00<37:55,46.05it/s] 40%|###9      |69239/173481[24:11<37:43,46.05it/s] 44%|####4     |76965/173481[27:00<34:59,45.97it/s] 45%|####4     |77518/173481[27:11<34:47,45.97it/s] 49%|####9     |85627/173481[30:00<31:08,47.02it/s] 50%|####9     |86167/173481[30:11<30:56,47.02it/s] 54%|#####4    |93745/173481[33:00<28:51,46.04it/s] 54%|#####4    |94103/173481[33:11<28:44,46.04it/s] 58%|#####8    |101289/173481[36:00<27:25,43.88it/s] 59%|#####8    |101833/173481[36:11<27:12,43.88it/s] 63%|######3   |109580/173481[39:00<23:41,44.94it/s] 63%|######3   |110139/173481[39:12<23:29,44.94it/s] 68%|######7   |117840/173481[42:00<20:25,45.41it/s] 68%|######8   |118414/173481[42:12<20:12,45.41it/s] 73%|#######2  |126146/173481[45:00<17:14,45.77it/s] 73%|#######3  |126713/173481[45:12<17:01,45.77it/s] 77%|#######7  |133909/173481[48:00<14:51,44.41it/s] 78%|#######7  |134546/173481[48:12<14:36,44.41it/s] 83%|########2 |143264/173481[51:00<10:30,47.89it/s] 83%|########2 |143925/173481[51:12<10:17,47.89it/s] 88%|########7 |152440/173481[54:00<07:06,49.38it/s] 88%|########8 |153103/173481[54:12<06:52,49.38it/s] 93%|#########3|161839/173481[57:00<03:49,50.76it/s] 94%|#########3|162523/173481[57:13<03:35,50.76it/s] 99%|#########8|171172/173481[1:00:00<00:45,51.29it/s] 99%|#########9|171878/173481[1:00:13<00:31,51.29it/s]100%|##########|173481/173481[1:00:44<00:00,47.60it/s]
[32m[0325 10:23:07 @base.py:257][0m Epoch 54 (global_step 9194493) finished, time:3644.52 sec.
[32m[0325 10:23:07 @saver.py:84][0m Model saved to train_log/lcn_w_4_a_32_quant_ends_False/model-9194493.
[32m[0325 10:23:07 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 87%|########6 |16299/18822[03:00<00:27,90.55it/s] 93%|#########2|17443/18822[03:10<00:15,90.55it/s]100%|##########|18822/18822[03:24<00:00,91.95it/s]
52
[32m[0325 10:26:32 @monitor.py:363][0m QueueInput/queue_size: 0.98524
[32m[0325 10:26:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.39
[32m[0325 10:26:32 @monitor.py:363][0m activation-summaries/output-rms: 0.039443
[32m[0325 10:26:32 @monitor.py:363][0m cross_entropy_loss: 1.6815
[32m[0325 10:26:32 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0a/W-rms: 0.49147
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0a/b-rms: 5.4947e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0b/W-rms: 0.35566
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0b/b-rms: 5.2255e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0c/W-rms: 0.47172
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0c/b-rms: 7.821e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0d/W-rms: 0.35028
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0d/b-rms: 4.3249e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0e/W-rms: 0.4776
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0e/b-rms: 5.0722e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0f/W-rms: 0.34785
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0f/b-rms: 5.9981e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0g/W-rms: 0.48089
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0g/b-rms: 6.3146e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0h/W-rms: 0.34725
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0h/b-rms: 4.7005e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0i/W-rms: 0.51064
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0i/b-rms: 5.6584e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0j/W-rms: 0.35361
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/conv0j/b-rms: 3.3714e-06
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6077
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.3193
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.4429
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.090672
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.36985
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.089258
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.36325
[32m[0325 10:26:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.083136
[32m[0325 10:26:32 @monitor.py:363][0m train-error-top1: 0.45535
[32m[0325 10:26:32 @monitor.py:363][0m val-error-top1: 0.46353
[32m[0325 10:26:32 @monitor.py:363][0m val-utt-error: 0.11556
[32m[0325 10:26:32 @monitor.py:363][0m validation_cost: 1.7505
[32m[0325 10:26:32 @monitor.py:363][0m wd_cost: 3.0815e-13
[32m[0325 10:26:32 @group.py:42][0m Callbacks took 205.476 sec in total. InferenceRunner: 204.867sec
[32m[0325 10:26:32 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11493/173481[03:00<42:17,63.85it/s]  7%|7         |12221/173481[03:10<42:05,63.85it/s] 13%|#3        |22948/173481[06:00<39:21,63.74it/s] 14%|#3        |23540/173481[06:10<39:12,63.74it/s] 20%|#9        |34359/173481[09:00<36:28,63.57it/s] 20%|##        |35012/173481[09:10<36:18,63.57it/s] 26%|##6       |45486/173481[12:00<34:02,62.68it/s] 27%|##6       |46205/173481[12:10<33:50,62.68it/s] 33%|###2      |56707/173481[15:00<31:08,62.50it/s] 33%|###3      |57320/173481[15:10<30:58,62.50it/s] 38%|###8      |66143/173481[18:00<31:22,57.02it/s] 38%|###8      |66744/173481[18:11<31:12,57.02it/s]slurmstepd: *** STEP 82583.0 ON sls-sm-16 CANCELLED AT 2018-03-25T10:45:36 DUE TO TIME LIMIT ***
srun: error: sls-sm-16: task 0: Terminated
srun: Force Terminated job step 82583.0
