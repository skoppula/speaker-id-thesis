sls-sm-3 3
SLURM_JOBID=85140
SLURM_TASKID=1
[32m[0328 11:37:01 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=2 --bita=32 --quant_ends=True --load_ckpt=train_log/fcn1_w_2_a_32_quant_ends_False/checkpoint
[32m[0328 11:49:11 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 11:49:11 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 11:49:11 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 11:49:11 @drf_run.py:166][0m Using host: sls-sm-3
[32m[0328 11:49:11 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 11:49:11 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 11:49:11 @drf_run.py:188][0m Using GPU: 3
[32m[0328 11:49:11 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 11:49:11 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 11:49:11 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 11:49:11 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0328 11:49:11 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:49:11 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:49:11 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:49:11 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:49:11 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:49:12 @registry.py:130][0m linear0 output: [None, 256]
[32m[0328 11:49:12 @registry.py:122][0m linear1 input: [None, 256]
[32m[0328 11:49:12 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:49:12 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:49:12 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 11:49:12 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 11:49:12 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:49:12 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:49:12 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 11:49:12 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 11:49:12 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:49:12 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:49:12 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:49:12 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 11:49:12 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 11:49:12 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:49:12 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:49:12 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 11:49:12 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:49:12 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0328 11:49:12 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 11:49:12 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0328 11:49:13 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0328 11:49:13 @base.py:196][0m Setup callbacks graph ...
[32m[0328 11:49:13 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:49:13 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:49:13 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:49:13 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:49:13 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0328 11:49:13 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 11:49:13 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0328 11:49:14 @base.py:212][0m Creating the session ...
2018-03-28 11:49:14.991160: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-28 11:49:16.272472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:82:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-28 11:49:16.272512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:82:00.0, compute capability: 6.1)
[32m[0328 11:49:17 @base.py:220][0m Initializing the session ...
[32m[0328 11:49:17 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn1_w_2_a_32_quant_ends_False/model-10061898 ...
[32m[0328 11:49:17 @base.py:227][0m Graph Finalized.
[32m[0328 11:49:17 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 11:49:17 @steps.py:127][0m Start training with global_step=10061898
[32m[0328 11:49:20 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20504/173481[03:00<22:22,113.91it/s] 13%|#2        |21724/173481[03:10<22:12,113.91it/s] 24%|##3       |41242/173481[06:00<19:14,114.56it/s] 24%|##4       |42433/173481[06:10<19:03,114.56it/s] 36%|###6      |63171/173481[09:00<15:34,118.08it/s] 37%|###7      |64473/173481[09:10<15:23,118.08it/s] 49%|####9     |85448/173481[12:00<12:08,120.85it/s] 50%|####9     |86734/173481[12:10<11:57,120.85it/s] 61%|######    |105150/173481[15:00<09:54,114.87it/s] 61%|######1   |106131/173481[15:10<09:46,114.87it/s] 69%|######9   |120416/173481[18:00<09:03,97.58it/s]  70%|######9   |121030/173481[18:10<08:57,97.58it/s] 75%|#######5  |130755/173481[21:00<09:50,72.31it/s] 76%|#######5  |131360/173481[21:11<09:42,72.31it/s] 82%|########1 |141616/173481[24:00<08:04,65.77it/s] 82%|########2 |142300/173481[24:11<07:54,65.77it/s] 87%|########7 |151721/173481[27:00<05:59,60.57it/s] 88%|########7 |152308/173481[27:11<05:49,60.57it/s] 93%|#########2|161155/173481[30:00<03:39,56.19it/s] 93%|#########3|161782/173481[30:11<03:28,56.19it/s] 99%|#########8|171101/173481[33:00<00:42,55.71it/s] 99%|#########9|171771/173481[33:11<00:30,55.71it/s]100%|##########|173481/173481[33:44<00:00,85.67it/s]
[32m[0328 12:23:04 @base.py:257][0m Epoch 1 (global_step 10235379) finished, time:2024.89 sec.
[32m[0328 12:23:05 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-10235379.
  0%|          |0/18822[00:00<?,?it/s] 51%|#####     |9541/18822[03:00<02:55,53.00it/s] 54%|#####3    |10133/18822[03:10<02:43,53.00it/s]100%|##########|18822/18822[05:18<00:00,59.15it/s]
0
[32m[0328 12:28:23 @monitor.py:363][0m QueueInput/queue_size: 1.9436
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.241
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/output-rms: 0.029803
[32m[0328 12:28:23 @monitor.py:363][0m cross_entropy_loss: 6.313
[32m[0328 12:28:23 @monitor.py:363][0m lr: 4.7684e-10
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 12:28:23 @monitor.py:363][0m train-error-top1: 0.94191
[32m[0328 12:28:23 @monitor.py:363][0m val-error-top1: 0.94423
[32m[0328 12:28:23 @monitor.py:363][0m val-utt-error: 0.84061
[32m[0328 12:28:23 @monitor.py:363][0m validation_cost: 6.489
[32m[0328 12:28:23 @monitor.py:363][0m wd_cost: 4.2313e-14
[32m[0328 12:28:23 @group.py:42][0m Callbacks took 318.944 sec in total. InferenceRunner: 318.245sec
[32m[0328 12:28:23 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10590/173481[03:00<46:09,58.82it/s]  6%|6         |11124/173481[03:10<46:00,58.82it/s] 12%|#1        |20815/173481[06:00<44:01,57.80it/s] 12%|#2        |21414/173481[06:10<43:51,57.80it/s] 18%|#7        |30835/173481[09:00<41:55,56.71it/s] 18%|#8        |31389/173481[09:10<41:45,56.71it/s] 23%|##2       |39875/173481[12:00<41:48,53.27it/s] 23%|##3       |40409/173481[12:10<41:38,53.27it/s] 28%|##8       |49146/173481[15:00<39:34,52.37it/s] 29%|##8       |49709/173481[15:10<39:23,52.37it/s] 34%|###4      |59140/173481[18:00<35:21,53.89it/s] 34%|###4      |59738/173481[18:10<35:10,53.89it/s] 40%|###9      |68971/173481[21:00<32:06,54.25it/s] 40%|####      |69569/173481[21:10<31:55,54.25it/s] 45%|####5     |78772/173481[24:00<29:02,54.35it/s] 46%|####5     |79452/173481[24:11<28:50,54.35it/s] 52%|#####1    |89605/173481[27:00<24:28,57.11it/s] 52%|#####2    |90222/173481[27:11<24:17,57.11it/s] 57%|#####7    |99600/173481[30:00<21:52,56.31it/s] 58%|#####7    |100229/173481[30:11<21:40,56.31it/s] 63%|######3   |109530/173481[33:00<19:07,55.73it/s] 63%|######3   |110153/173481[33:11<18:56,55.73it/s] 69%|######9   |119772/173481[36:00<15:53,56.31it/s] 69%|######9   |120434/173481[36:11<15:42,56.31it/s] 75%|#######4  |129610/173481[39:00<13:10,55.47it/s] 75%|#######5  |130205/173481[39:11<13:00,55.47it/s] 80%|########  |139395/173481[42:00<10:20,54.90it/s] 81%|########  |140077/173481[42:11<10:08,54.90it/s] 86%|########6 |149450/173481[45:00<07:13,55.37it/s] 87%|########6 |150114/173481[45:12<07:01,55.37it/s] 92%|#########2|159622/173481[48:00<04:07,55.94it/s] 92%|#########2|160275/173481[48:12<03:56,55.94it/s] 98%|#########7|169705/173481[51:00<01:07,55.97it/s] 98%|#########8|170404/173481[51:12<00:54,55.97it/s]100%|##########|173481/173481[52:07<00:00,55.47it/s]
[32m[0328 13:20:31 @base.py:257][0m Epoch 2 (global_step 10408860) finished, time:3127.56 sec.
[32m[0328 13:20:31 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-10408860.
[32m[0328 13:20:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:36<00:00,120.64it/s]
1
[32m[0328 13:23:08 @monitor.py:363][0m QueueInput/queue_size: 0.5915
[32m[0328 13:23:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.115
[32m[0328 13:23:08 @monitor.py:363][0m activation-summaries/output-rms: 0.029154
[32m[0328 13:23:08 @monitor.py:363][0m cross_entropy_loss: 6.2815
[32m[0328 13:23:08 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 13:23:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 13:23:08 @monitor.py:363][0m train-error-top1: 0.93991
[32m[0328 13:23:08 @monitor.py:363][0m val-error-top1: 0.94366
[32m[0328 13:23:08 @monitor.py:363][0m val-utt-error: 0.83764
[32m[0328 13:23:08 @monitor.py:363][0m validation_cost: 6.489
[32m[0328 13:23:08 @monitor.py:363][0m wd_cost: 4.2313e-14
[32m[0328 13:23:08 @group.py:42][0m Callbacks took 156.529 sec in total. InferenceRunner: 156.030sec
[32m[0328 13:23:08 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14649/173481[03:00<32:32,81.36it/s]  9%|8         |15258/173481[03:10<32:24,81.36it/s] 14%|#4        |25133/173481[06:00<36:25,67.89it/s] 15%|#4        |25656/173481[06:10<36:17,67.89it/s] 20%|#9        |34539/173481[09:00<39:12,59.05it/s] 20%|##        |35083/173481[09:10<39:03,59.05it/s] 25%|##5       |44030/173481[12:00<38:43,55.71it/s] 26%|##5       |44588/173481[12:10<38:33,55.71it/s] 31%|###       |53274/173481[15:00<37:29,53.44it/s] 31%|###1      |53818/173481[15:10<37:19,53.44it/s] 36%|###6      |62804/173481[18:00<34:40,53.19it/s] 37%|###6      |63365/173481[18:10<34:30,53.19it/s] 42%|####1     |72579/173481[21:00<31:17,53.74it/s] 42%|####2     |73161/173481[21:10<31:06,53.74it/s] 47%|####6     |80894/173481[24:00<31:04,49.67it/s] 47%|####6     |81333/173481[24:11<30:55,49.67it/s] 51%|#####     |88034/173481[27:00<32:17,44.10it/s] 51%|#####     |88468/173481[27:11<32:07,44.10it/s] 55%|#####4    |95131/173481[30:00<31:21,41.63it/s] 55%|#####5    |95559/173481[30:11<31:11,41.63it/s] 59%|#####9    |102469/173481[33:00<28:44,41.18it/s] 59%|#####9    |102913/173481[33:11<28:33,41.18it/s] 63%|######3   |110018/173481[36:00<25:27,41.56it/s] 64%|######3   |110493/173481[36:11<25:15,41.56it/s] 68%|######7   |117524/173481[39:00<22:24,41.62it/s] 68%|######8   |117972/173481[39:11<22:13,41.62it/s] 72%|#######1  |124849/173481[42:00<19:42,41.14it/s] 72%|#######2  |125263/173481[42:11<19:31,41.14it/s] 76%|#######6  |132402/173481[45:00<16:28,41.55it/s] 77%|#######6  |133100/173481[45:11<16:11,41.55it/s] 83%|########2 |143684/173481[48:00<09:56,49.97it/s] 83%|########3 |144433/173481[48:12<09:41,49.97it/s] 90%|########9 |155284/173481[51:00<05:23,56.28it/s] 90%|########9 |156038/173481[51:12<05:09,56.28it/s] 96%|#########6|166574/173481[54:00<01:56,59.32it/s] 96%|#########6|167326/173481[54:12<01:43,59.32it/s]100%|##########|173481/173481[55:48<00:00,51.81it/s]
[32m[0328 14:18:56 @base.py:257][0m Epoch 3 (global_step 10582341) finished, time:3348.33 sec.
[32m[0328 14:18:56 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-10582341.
[32m[0328 14:18:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 84%|########3 |15809/18822[03:00<00:34,87.82it/s] 89%|########9 |16773/18822[03:10<00:23,87.82it/s]100%|##########|18822/18822[03:31<00:00,88.86it/s]
2
[32m[0328 14:22:29 @monitor.py:363][0m QueueInput/queue_size: 0.43982
[32m[0328 14:22:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.946
[32m[0328 14:22:29 @monitor.py:363][0m activation-summaries/output-rms: 0.028799
[32m[0328 14:22:29 @monitor.py:363][0m cross_entropy_loss: 6.2263
[32m[0328 14:22:29 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 14:22:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 14:22:29 @monitor.py:363][0m train-error-top1: 0.93814
[32m[0328 14:22:29 @monitor.py:363][0m val-error-top1: 0.9421
[32m[0328 14:22:29 @monitor.py:363][0m val-utt-error: 0.8327
[32m[0328 14:22:29 @monitor.py:363][0m validation_cost: 6.3896
[32m[0328 14:22:29 @monitor.py:363][0m wd_cost: 8.4627e-15
[32m[0328 14:22:29 @group.py:42][0m Callbacks took 212.703 sec in total. InferenceRunner: 211.841sec
[32m[0328 14:22:29 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11853/173481[03:00<40:54,65.84it/s]  7%|7         |12504/173481[03:10<40:44,65.84it/s] 14%|#3        |23423/173481[06:00<38:27,65.04it/s] 14%|#3        |24067/173481[06:10<38:17,65.04it/s] 20%|##        |35136/173481[09:00<35:26,65.06it/s] 21%|##        |35827/173481[09:10<35:15,65.06it/s] 27%|##7       |46924/173481[12:00<32:18,65.27it/s] 27%|##7       |47607/173481[12:10<32:08,65.27it/s] 34%|###3      |58789/173481[15:00<29:08,65.59it/s] 34%|###4      |59513/173481[15:10<28:57,65.59it/s] 41%|####      |70455/173481[18:00<26:20,65.20it/s] 41%|####1     |71142/173481[18:10<26:09,65.20it/s] 47%|####7     |81968/173481[21:00<23:37,64.57it/s] 48%|####7     |82974/173481[21:11<23:21,64.57it/s] 57%|#####6    |98089/173481[24:00<16:44,75.04it/s] 57%|#####7    |99124/173481[24:11<16:30,75.04it/s] 66%|######6   |114758/173481[27:00<11:48,82.90it/s] 67%|######6   |115802/173481[27:11<11:35,82.90it/s] 73%|#######3  |126864/173481[30:00<10:27,74.26it/s] 74%|#######3  |127614/173481[30:11<10:17,74.26it/s] 80%|########  |138818/173481[33:00<08:14,70.11it/s] 80%|########  |139559/173481[33:11<08:03,70.11it/s] 86%|########5 |149183/173481[36:00<06:24,63.23it/s] 86%|########6 |149820/173481[36:11<06:14,63.23it/s] 92%|#########2|159613/173481[39:00<03:49,60.47it/s] 92%|#########2|160312/173481[39:11<03:37,60.47it/s] 98%|#########7|169449/173481[42:00<01:10,57.41it/s] 98%|#########7|169972/173481[42:11<01:01,57.41it/s]100%|##########|173481/173481[43:20<00:00,66.71it/s]
[32m[0328 15:05:49 @base.py:257][0m Epoch 4 (global_step 10755822) finished, time:2600.54 sec.
[32m[0328 15:05:49 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-10755822.
[32m[0328 15:05:50 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 97%|#########6|18250/18822[03:00<00:05,101.39it/s]100%|##########|18822/18822[03:05<00:00,101.52it/s]
3
[32m[0328 15:08:55 @monitor.py:363][0m QueueInput/queue_size: 0.70855
[32m[0328 15:08:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.115
[32m[0328 15:08:55 @monitor.py:363][0m activation-summaries/output-rms: 0.028027
[32m[0328 15:08:55 @monitor.py:363][0m cross_entropy_loss: 6.2587
[32m[0328 15:08:55 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 15:08:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 15:08:55 @monitor.py:363][0m train-error-top1: 0.94576
[32m[0328 15:08:55 @monitor.py:363][0m val-error-top1: 0.94186
[32m[0328 15:08:55 @monitor.py:363][0m val-utt-error: 0.82919
[32m[0328 15:08:55 @monitor.py:363][0m validation_cost: 6.3822
[32m[0328 15:08:55 @monitor.py:363][0m wd_cost: 8.4627e-15
[32m[0328 15:08:55 @group.py:42][0m Callbacks took 185.993 sec in total. InferenceRunner: 185.412sec
[32m[0328 15:08:55 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12367/173481[03:00<39:05,68.69it/s]  8%|7         |13043/173481[03:10<38:55,68.69it/s] 14%|#3        |23962/173481[06:00<37:29,66.48it/s] 14%|#4        |24551/173481[06:10<37:20,66.48it/s] 20%|##        |34744/173481[09:00<36:41,63.02it/s] 20%|##        |35316/173481[09:10<36:32,63.02it/s] 26%|##5       |44566/173481[12:00<36:44,58.49it/s] 26%|##6       |45141/173481[12:10<36:34,58.49it/s] 32%|###1      |54703/173481[15:00<34:29,57.38it/s] 32%|###1      |55341/173481[15:10<34:18,57.38it/s] 38%|###7      |65097/173481[18:00<31:23,57.56it/s] 38%|###7      |65726/173481[18:10<31:12,57.56it/s] 43%|####3     |75033/173481[21:00<29:06,56.35it/s] 44%|####3     |75601/173481[21:10<28:56,56.35it/s] 49%|####8     |84313/173481[24:00<27:35,53.85it/s] 49%|####8     |84856/173481[24:11<27:25,53.85it/s] 54%|#####4    |94032/173481[27:00<24:33,53.91it/s] 55%|#####4    |94614/173481[27:11<24:22,53.91it/s] 60%|#####9    |103442/173481[30:00<21:59,53.08it/s] 60%|#####9    |104051/173481[30:11<21:47,53.08it/s] 65%|######5   |113022/173481[33:00<18:57,53.15it/s] 66%|######5   |113666/173481[33:11<18:45,53.15it/s] 71%|#######   |122871/173481[36:00<15:38,53.92it/s] 71%|#######1  |123451/173481[36:11<15:27,53.92it/s] 76%|#######6  |132667/173481[39:00<12:33,54.16it/s] 77%|#######6  |133271/173481[39:11<12:22,54.16it/s] 82%|########1 |142177/173481[42:00<09:45,53.49it/s] 82%|########2 |142828/173481[42:11<09:33,53.49it/s] 88%|########7 |152385/173481[45:00<06:23,55.05it/s] 88%|########8 |153041/173481[45:11<06:11,55.05it/s] 94%|#########3|162380/173481[48:00<03:20,55.29it/s] 94%|#########3|163023/173481[48:12<03:09,55.29it/s] 99%|#########8|171674/173481[51:00<00:33,53.40it/s] 99%|#########9|172306/173481[51:12<00:22,53.40it/s]100%|##########|173481/173481[51:34<00:00,56.05it/s]
[32m[0328 16:00:30 @base.py:257][0m Epoch 5 (global_step 10929303) finished, time:3094.97 sec.
[32m[0328 16:00:30 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-10929303.
[32m[0328 16:00:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.03it/s]
4
[32m[0328 16:02:15 @monitor.py:363][0m QueueInput/queue_size: 0.45814
[32m[0328 16:02:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.888
[32m[0328 16:02:15 @monitor.py:363][0m activation-summaries/output-rms: 0.027989
[32m[0328 16:02:15 @monitor.py:363][0m cross_entropy_loss: 6.2326
[32m[0328 16:02:15 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 16:02:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 16:02:15 @monitor.py:363][0m train-error-top1: 0.94352
[32m[0328 16:02:15 @monitor.py:363][0m val-error-top1: 0.94123
[32m[0328 16:02:15 @monitor.py:363][0m val-utt-error: 0.82228
[32m[0328 16:02:15 @monitor.py:363][0m validation_cost: 6.3182
[32m[0328 16:02:15 @monitor.py:363][0m wd_cost: 8.4627e-15
[32m[0328 16:02:15 @group.py:42][0m Callbacks took 105.060 sec in total. InferenceRunner: 104.565sec
[32m[0328 16:02:15 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10999/173481[03:00<44:19,61.10it/s]  7%|6         |11606/173481[03:10<44:09,61.10it/s] 12%|#2        |21575/173481[06:00<42:15,59.91it/s] 13%|#2        |22165/173481[06:10<42:05,59.91it/s] 18%|#8        |31826/173481[09:00<40:26,58.38it/s] 19%|#8        |32355/173481[09:10<40:17,58.38it/s] 24%|##3       |40796/173481[12:00<41:08,53.76it/s] 24%|##3       |41321/173481[12:10<40:58,53.76it/s] 29%|##8       |49826/173481[15:00<39:42,51.89it/s] 29%|##9       |50355/173481[15:10<39:32,51.89it/s] 34%|###4      |59129/173481[18:00<36:48,51.79it/s] 34%|###4      |59740/173481[18:10<36:36,51.79it/s] 40%|###9      |69101/173481[21:00<32:30,53.53it/s] 40%|####      |69631/173481[21:11<32:20,53.53it/s] 45%|####5     |78325/173481[24:00<30:17,52.36it/s] 45%|####5     |78905/173481[24:11<30:06,52.36it/s] 50%|#####     |87321/173481[27:00<28:04,51.14it/s] 51%|#####     |87873/173481[27:11<27:54,51.14it/s] 56%|#####5    |96321/173481[30:00<25:26,50.56it/s] 56%|#####5    |96860/173481[30:11<25:15,50.56it/s] 61%|######    |105021/173481[33:00<23:05,49.42it/s] 61%|######    |105575/173481[33:11<22:54,49.42it/s] 66%|######5   |113870/173481[36:00<20:09,49.29it/s] 66%|######5   |114445/173481[36:11<19:57,49.29it/s] 71%|#######   |123162/173481[39:00<16:37,50.43it/s] 71%|#######1  |123766/173481[39:11<16:25,50.43it/s] 76%|#######6  |132256/173481[42:00<13:36,50.47it/s] 77%|#######6  |132824/173481[42:12<13:25,50.47it/s] 82%|########1 |141401/173481[45:00<10:33,50.63it/s] 82%|########1 |142024/173481[45:12<10:21,50.63it/s] 87%|########6 |150491/173481[48:00<07:34,50.56it/s] 87%|########7 |151150/173481[48:12<07:21,50.56it/s] 92%|#########2|160068/173481[51:00<04:18,51.85it/s] 93%|#########2|160682/173481[51:12<04:06,51.85it/s] 97%|#########7|168751/173481[54:00<01:34,49.98it/s] 98%|#########7|169335/173481[54:12<01:22,49.98it/s]100%|##########|173481/173481[55:39<00:00,51.94it/s]
[32m[0328 16:57:55 @base.py:257][0m Epoch 6 (global_step 11102784) finished, time:3339.77 sec.
[32m[0328 16:57:55 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-11102784.
[32m[0328 16:57:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 93%|#########2|17493/18822[03:00<00:13,97.18it/s] 99%|#########8|18588/18822[03:10<00:02,97.18it/s]100%|##########|18822/18822[03:12<00:00,97.84it/s]
5
[32m[0328 17:01:08 @monitor.py:363][0m QueueInput/queue_size: 0.74579
[32m[0328 17:01:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.175
[32m[0328 17:01:08 @monitor.py:363][0m activation-summaries/output-rms: 0.029069
[32m[0328 17:01:08 @monitor.py:363][0m cross_entropy_loss: 6.1581
[32m[0328 17:01:08 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 17:01:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 17:01:08 @monitor.py:363][0m train-error-top1: 0.93902
[32m[0328 17:01:08 @monitor.py:363][0m val-error-top1: 0.94161
[32m[0328 17:01:08 @monitor.py:363][0m val-utt-error: 0.82871
[32m[0328 17:01:08 @monitor.py:363][0m validation_cost: 6.324
[32m[0328 17:01:08 @monitor.py:363][0m wd_cost: 1.6925e-15
[32m[0328 17:01:08 @group.py:42][0m Callbacks took 193.165 sec in total. InferenceRunner: 192.386sec
[32m[0328 17:01:08 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12011/173481[03:00<40:19,66.73it/s]  7%|7         |12570/173481[03:10<40:11,66.73it/s] 13%|#2        |21829/173481[06:00<42:06,60.02it/s] 13%|#2        |22409/173481[06:10<41:56,60.02it/s] 19%|#8        |32939/173481[09:00<38:29,60.86it/s] 19%|#9        |33429/173481[09:10<38:21,60.86it/s] 24%|##3       |41200/173481[12:00<42:08,52.32it/s] 24%|##4       |41669/173481[12:10<41:59,52.32it/s] 29%|##8       |49605/173481[15:00<41:50,49.35it/s] 29%|##8       |50114/173481[15:10<41:40,49.35it/s] 34%|###3      |58571/173481[18:00<38:37,49.58it/s] 34%|###4      |59119/173481[18:10<38:26,49.58it/s] 39%|###8      |67490/173481[21:00<35:38,49.56it/s] 39%|###9      |68034/173481[21:10<35:27,49.56it/s] 44%|####4     |76830/173481[24:00<31:46,50.70it/s] 45%|####4     |77379/173481[24:11<31:35,50.70it/s] 50%|####9     |86045/173481[27:00<28:36,50.94it/s] 50%|####9     |86632/173481[27:11<28:24,50.94it/s] 55%|#####5    |95726/173481[30:00<24:46,52.32it/s] 56%|#####5    |96321/173481[30:11<24:34,52.32it/s] 61%|######    |105046/173481[33:00<21:54,52.05it/s] 61%|######    |105654/173481[33:11<21:43,52.05it/s] 66%|######5   |114244/173481[36:00<19:08,51.57it/s] 66%|######6   |114836/173481[36:11<18:57,51.57it/s] 71%|#######1  |123245/173481[39:00<16:29,50.77it/s] 71%|#######1  |123809/173481[39:11<16:18,50.77it/s] 76%|#######6  |132059/173481[42:00<13:50,49.85it/s] 76%|#######6  |132639/173481[42:11<13:39,49.85it/s] 81%|########1 |140820/173481[45:00<11:03,49.25it/s] 82%|########1 |141394/173481[45:12<10:51,49.25it/s] 86%|########6 |149855/173481[48:00<07:55,49.71it/s] 87%|########6 |150457/173481[48:12<07:43,49.71it/s] 92%|#########1|159100/173481[51:00<04:44,50.52it/s] 92%|#########2|159724/173481[51:12<04:32,50.52it/s] 97%|#########7|168580/173481[54:00<01:35,51.57it/s] 98%|#########7|169263/173481[54:12<01:21,51.57it/s]100%|##########|173481/173481[55:28<00:00,52.12it/s]
[32m[0328 17:56:36 @base.py:257][0m Epoch 7 (global_step 11276265) finished, time:3328.22 sec.
[32m[0328 17:56:37 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-11276265.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:51<00:00,110.05it/s]
6
[32m[0328 17:59:28 @monitor.py:363][0m QueueInput/queue_size: 0.71183
[32m[0328 17:59:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.056
[32m[0328 17:59:28 @monitor.py:363][0m activation-summaries/output-rms: 0.02863
[32m[0328 17:59:28 @monitor.py:363][0m cross_entropy_loss: 6.1951
[32m[0328 17:59:28 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 17:59:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 17:59:28 @monitor.py:363][0m train-error-top1: 0.94034
[32m[0328 17:59:28 @monitor.py:363][0m val-error-top1: 0.94257
[32m[0328 17:59:28 @monitor.py:363][0m val-utt-error: 0.82967
[32m[0328 17:59:28 @monitor.py:363][0m validation_cost: 6.3943
[32m[0328 17:59:28 @monitor.py:363][0m wd_cost: 1.6925e-15
[32m[0328 17:59:28 @group.py:42][0m Callbacks took 171.328 sec in total. InferenceRunner: 171.039sec
[32m[0328 17:59:28 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11449/173481[03:00<42:27,63.59it/s]  7%|6         |12033/173481[03:10<42:18,63.59it/s] 12%|#2        |21367/173481[06:00<42:56,59.04it/s] 13%|#2        |21955/173481[06:10<42:46,59.04it/s] 20%|#9        |34629/173481[09:00<35:18,65.55it/s] 20%|##        |35140/173481[09:10<35:10,65.55it/s] 25%|##5       |44224/173481[12:00<36:38,58.79it/s] 26%|##5       |44778/173481[12:10<36:29,58.79it/s] 31%|###1      |53824/173481[15:00<35:39,55.93it/s] 31%|###1      |54380/173481[15:10<35:29,55.93it/s] 36%|###6      |63054/173481[18:00<34:24,53.49it/s] 37%|###6      |63620/173481[18:10<34:13,53.49it/s] 42%|####1     |72824/173481[21:00<31:08,53.88it/s] 42%|####2     |73418/173481[21:10<30:57,53.88it/s] 48%|####7     |82430/173481[24:00<28:18,53.62it/s] 48%|####7     |82991/173481[24:11<28:07,53.62it/s] 53%|#####3    |92114/173481[27:00<25:15,53.70it/s] 53%|#####3    |92717/173481[27:11<25:03,53.70it/s] 59%|#####8    |101829/173481[30:00<22:11,53.83it/s] 59%|#####9    |102438/173481[30:11<21:59,53.83it/s] 64%|######4   |111664/173481[33:00<18:59,54.23it/s] 65%|######4   |112266/173481[33:11<18:48,54.23it/s] 71%|#######   |122574/173481[36:00<14:49,57.23it/s] 71%|#######1  |123208/173481[36:11<14:38,57.23it/s] 76%|#######6  |132669/173481[39:00<12:00,56.65it/s] 77%|#######6  |133333/173481[39:11<11:48,56.65it/s] 82%|########2 |143014/173481[42:00<08:53,57.06it/s] 83%|########2 |143628/173481[42:11<08:43,57.06it/s] 88%|########8 |152968/173481[45:00<06:05,56.16it/s] 89%|########8 |153618/173481[45:12<05:53,56.16it/s] 94%|#########3|162893/173481[48:00<03:10,55.65it/s] 94%|#########4|163544/173481[48:12<02:58,55.65it/s]100%|#########9|172919/173481[51:00<00:10,55.66it/s]100%|##########|173481/173481[51:10<00:00,56.49it/s]
[32m[0328 18:50:38 @base.py:257][0m Epoch 8 (global_step 11449746) finished, time:3070.83 sec.
[32m[0328 18:50:39 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:57<00:00,106.04it/s]
7
[32m[0328 18:53:36 @monitor.py:363][0m QueueInput/queue_size: 0.47585
[32m[0328 18:53:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.928
[32m[0328 18:53:36 @monitor.py:363][0m activation-summaries/output-rms: 0.028643
[32m[0328 18:53:36 @monitor.py:363][0m cross_entropy_loss: 6.1646
[32m[0328 18:53:36 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 18:53:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 18:53:36 @monitor.py:363][0m train-error-top1: 0.93818
[32m[0328 18:53:36 @monitor.py:363][0m val-error-top1: 0.94115
[32m[0328 18:53:36 @monitor.py:363][0m val-utt-error: 0.82356
[32m[0328 18:53:36 @monitor.py:363][0m validation_cost: 6.3233
[32m[0328 18:53:36 @monitor.py:363][0m wd_cost: 1.6925e-15
[32m[0328 18:53:36 @group.py:42][0m Callbacks took 177.834 sec in total. InferenceRunner: 177.519sec
[32m[0328 18:53:36 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11823/173481[03:00<41:01,65.67it/s]  7%|7         |12352/173481[03:10<40:53,65.67it/s] 12%|#2        |21612/173481[06:00<42:32,59.49it/s] 13%|#2        |22172/173481[06:10<42:23,59.49it/s] 18%|#8        |31703/173481[09:00<40:56,57.72it/s] 19%|#8        |32272/173481[09:10<40:46,57.72it/s] 26%|##6       |45471/173481[12:00<32:25,65.79it/s] 27%|##6       |46383/173481[12:10<32:11,65.79it/s] 33%|###2      |57094/173481[15:00<29:45,65.18it/s] 33%|###3      |57697/173481[15:10<29:36,65.18it/s] 39%|###8      |67255/173481[18:00<29:15,60.50it/s] 39%|###9      |67867/173481[18:10<29:05,60.50it/s] 45%|####4     |77461/173481[21:00<27:20,58.54it/s] 45%|####5     |78072/173481[21:10<27:09,58.54it/s] 50%|#####     |87516/173481[24:00<25:03,57.17it/s] 51%|#####     |88141/173481[24:11<24:52,57.17it/s] 56%|#####6    |97893/173481[27:00<21:56,57.40it/s] 57%|#####6    |98512/173481[27:11<21:46,57.40it/s] 62%|######2   |108073/173481[30:00<19:08,56.97it/s] 63%|######2   |108827/173481[30:11<18:54,56.97it/s] 69%|######8   |119380/173481[33:00<15:05,59.75it/s] 69%|######9   |120032/173481[33:11<14:54,59.75it/s] 75%|#######4  |130089/173481[36:00<12:07,59.62it/s] 75%|#######5  |130883/173481[36:11<11:54,59.62it/s] 81%|########1 |140949/173481[39:00<09:02,59.97it/s] 82%|########1 |141589/173481[39:11<08:51,59.97it/s] 87%|########7 |151753/173481[42:00<06:02,59.99it/s] 88%|########7 |152482/173481[42:11<05:50,59.99it/s] 94%|#########3|162658/173481[45:00<02:59,60.29it/s] 94%|#########4|163302/173481[45:12<02:48,60.29it/s]100%|#########9|172648/173481[48:00<00:14,57.79it/s]100%|#########9|173317/173481[48:12<00:02,57.79it/s]100%|##########|173481/173481[48:15<00:00,59.92it/s]
[32m[0328 19:41:51 @base.py:257][0m Epoch 9 (global_step 11623227) finished, time:2895.00 sec.
[32m[0328 19:41:52 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-11623227.
[32m[0328 19:41:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########8|18521/18822[03:00<00:02,102.89it/s]100%|##########|18822/18822[03:02<00:00,103.12it/s]
8
[32m[0328 19:44:54 @monitor.py:363][0m QueueInput/queue_size: 0.57308
[32m[0328 19:44:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.085
[32m[0328 19:44:54 @monitor.py:363][0m activation-summaries/output-rms: 0.028032
[32m[0328 19:44:54 @monitor.py:363][0m cross_entropy_loss: 6.2122
[32m[0328 19:44:54 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 19:44:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 19:44:54 @monitor.py:363][0m train-error-top1: 0.94592
[32m[0328 19:44:54 @monitor.py:363][0m val-error-top1: 0.94124
[32m[0328 19:44:54 @monitor.py:363][0m val-utt-error: 0.82547
[32m[0328 19:44:54 @monitor.py:363][0m validation_cost: 6.3282
[32m[0328 19:44:54 @monitor.py:363][0m wd_cost: 3.3851e-16
[32m[0328 19:44:54 @group.py:42][0m Callbacks took 183.203 sec in total. InferenceRunner: 182.556sec
[32m[0328 19:44:54 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13058/173481[03:00<36:51,72.54it/s]  8%|7         |13761/173481[03:10<36:41,72.54it/s] 14%|#4        |24297/173481[06:00<37:03,67.11it/s] 14%|#4        |24916/173481[06:10<36:53,67.11it/s] 20%|##        |34831/173481[09:00<36:57,62.52it/s] 20%|##        |35451/173481[09:10<36:47,62.52it/s] 26%|##6       |45189/173481[12:00<35:40,59.93it/s] 26%|##6       |45774/173481[12:10<35:30,59.93it/s] 32%|###1      |55382/173481[15:00<33:48,58.23it/s] 32%|###2      |55966/173481[15:10<33:38,58.23it/s] 38%|###7      |65352/173481[18:00<31:44,56.77it/s] 38%|###8      |65955/173481[18:10<31:34,56.77it/s] 47%|####6     |80985/173481[21:00<22:27,68.66it/s] 47%|####7     |82025/173481[21:10<22:12,68.66it/s] 57%|#####6    |98302/173481[24:00<15:38,80.13it/s] 57%|#####7    |98931/173481[24:11<15:30,80.13it/s] 63%|######2   |108427/173481[27:00<16:24,66.10it/s] 63%|######2   |109056/173481[27:11<16:14,66.10it/s] 68%|######8   |118525/173481[30:00<15:05,60.69it/s] 69%|######8   |119166/173481[30:11<14:54,60.69it/s] 74%|#######4  |128667/173481[33:00<12:46,58.43it/s] 75%|#######4  |129291/173481[33:11<12:36,58.43it/s] 80%|#######9  |138697/173481[36:00<10:09,57.04it/s] 80%|########  |139332/173481[36:11<09:58,57.04it/s] 86%|########5 |148637/173481[39:00<07:22,56.11it/s] 86%|########6 |149266/173481[39:11<07:11,56.11it/s] 92%|#########2|160082/173481[42:00<03:44,59.60it/s] 93%|#########2|160726/173481[42:11<03:33,59.60it/s] 98%|#########8|170073/173481[45:00<00:59,57.48it/s] 98%|#########8|170734/173481[45:12<00:47,57.48it/s]100%|##########|173481/173481[46:00<00:00,62.84it/s]
[32m[0328 20:30:55 @base.py:257][0m Epoch 10 (global_step 11796708) finished, time:2760.81 sec.
[32m[0328 20:30:55 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s] 92%|#########1|17315/18822[03:00<00:15,96.19it/s] 98%|#########7|18421/18822[03:10<00:04,96.19it/s]100%|##########|18822/18822[03:14<00:00,96.98it/s]
9
[32m[0328 20:34:10 @monitor.py:363][0m QueueInput/queue_size: 0.62906
[32m[0328 20:34:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.862
[32m[0328 20:34:10 @monitor.py:363][0m activation-summaries/output-rms: 0.027897
[32m[0328 20:34:10 @monitor.py:363][0m cross_entropy_loss: 6.1982
[32m[0328 20:34:10 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 20:34:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 20:34:10 @monitor.py:363][0m train-error-top1: 0.94042
[32m[0328 20:34:10 @monitor.py:363][0m val-error-top1: 0.94092
[32m[0328 20:34:10 @monitor.py:363][0m val-utt-error: 0.82329
[32m[0328 20:34:10 @monitor.py:363][0m validation_cost: 6.2936
[32m[0328 20:34:10 @monitor.py:363][0m wd_cost: 3.3851e-16
[32m[0328 20:34:10 @group.py:42][0m Callbacks took 194.364 sec in total. InferenceRunner: 194.107sec
[32m[0328 20:34:10 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10766/173481[03:00<45:20,59.80it/s]  7%|6         |11330/173481[03:10<45:11,59.80it/s] 13%|#2        |22457/173481[06:00<40:25,62.27it/s] 13%|#3        |23172/173481[06:10<40:13,62.27it/s] 19%|#8        |32865/173481[09:00<39:05,59.96it/s] 19%|#9        |33450/173481[09:10<38:55,59.96it/s] 25%|##4       |43306/173481[12:00<36:47,58.96it/s] 25%|##5       |43926/173481[12:10<36:37,58.96it/s] 31%|###       |53487/173481[15:00<34:38,57.74it/s] 31%|###1      |54060/173481[15:10<34:28,57.74it/s] 37%|###6      |63358/173481[18:00<32:37,56.25it/s] 37%|###6      |63946/173481[18:10<32:27,56.25it/s] 42%|####2     |73276/173481[21:00<30:00,55.67it/s] 43%|####2     |73860/173481[21:10<29:49,55.67it/s] 48%|####7     |83264/173481[24:00<27:03,55.58it/s] 48%|####8     |83871/173481[24:11<26:52,55.58it/s] 54%|#####3    |93432/173481[27:00<23:48,56.03it/s] 54%|#####4    |94099/173481[27:11<23:36,56.03it/s] 63%|######3   |109892/173481[30:00<15:15,69.48it/s] 64%|######4   |111062/173481[30:11<14:58,69.48it/s] 73%|#######2  |126111/173481[33:00<10:03,78.45it/s] 73%|#######3  |126788/173481[33:11<09:55,78.45it/s] 79%|#######8  |136526/173481[36:00<09:14,66.60it/s] 79%|#######9  |137206/173481[36:11<09:04,66.60it/s] 85%|########4 |146971/173481[39:00<07:07,62.01it/s] 85%|########5 |147625/173481[39:11<06:56,62.01it/s] 91%|######### |157206/173481[42:00<04:34,59.31it/s] 91%|######### |157845/173481[42:11<04:23,59.31it/s] 96%|#########6|167332/173481[45:00<01:46,57.74it/s] 97%|#########6|168000/173481[45:12<01:34,57.74it/s]100%|##########|173481/173481[46:49<00:00,61.74it/s]
[32m[0328 21:21:00 @base.py:257][0m Epoch 11 (global_step 11970189) finished, time:2809.98 sec.
[32m[0328 21:21:00 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-11970189.
[32m[0328 21:21:00 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 93%|#########2|17450/18822[03:00<00:14,96.94it/s] 98%|#########8|18519/18822[03:10<00:03,96.94it/s]100%|##########|18822/18822[03:13<00:00,97.27it/s]
10
[32m[0328 21:24:14 @monitor.py:363][0m QueueInput/queue_size: 0.4934
[32m[0328 21:24:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.161
[32m[0328 21:24:14 @monitor.py:363][0m activation-summaries/output-rms: 0.029032
[32m[0328 21:24:14 @monitor.py:363][0m cross_entropy_loss: 6.1281
[32m[0328 21:24:14 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 21:24:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 21:24:14 @monitor.py:363][0m train-error-top1: 0.93817
[32m[0328 21:24:14 @monitor.py:363][0m val-error-top1: 0.94152
[32m[0328 21:24:14 @monitor.py:363][0m val-utt-error: 0.82775
[32m[0328 21:24:14 @monitor.py:363][0m validation_cost: 6.3011
[32m[0328 21:24:14 @monitor.py:363][0m wd_cost: 3.3851e-16
[32m[0328 21:24:14 @group.py:42][0m Callbacks took 194.054 sec in total. InferenceRunner: 193.523sec
[32m[0328 21:24:14 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10918/173481[03:00<44:40,60.65it/s]  7%|6         |11624/173481[03:10<44:28,60.65it/s] 12%|#2        |21085/173481[06:00<43:25,58.49it/s] 12%|#2        |21639/173481[06:10<43:16,58.49it/s] 18%|#7        |31054/173481[09:00<41:43,56.89it/s] 18%|#8        |31648/173481[09:10<41:33,56.89it/s] 24%|##3       |41063/173481[12:00<39:14,56.24it/s] 24%|##4       |41644/173481[12:10<39:04,56.24it/s] 29%|##9       |51108/173481[15:00<36:24,56.02it/s] 30%|##9       |51694/173481[15:10<36:13,56.02it/s] 35%|###5      |61280/173481[18:00<33:14,56.26it/s] 36%|###5      |61890/173481[18:10<33:03,56.26it/s] 41%|####1     |71190/173481[21:00<30:38,55.65it/s] 41%|####1     |71776/173481[21:10<30:27,55.65it/s] 47%|####6     |81280/173481[24:00<27:30,55.85it/s] 47%|####7     |81921/173481[24:11<27:19,55.85it/s] 53%|#####2    |91256/173481[27:00<24:37,55.64it/s] 53%|#####2    |91894/173481[27:11<24:26,55.64it/s] 59%|#####8    |102313/173481[30:00<20:18,58.39it/s] 59%|#####9    |103079/173481[30:11<20:05,58.39it/s] 65%|######5   |113020/173481[33:00<17:05,58.93it/s] 66%|######5   |113648/173481[33:11<16:55,58.93it/s] 71%|#######   |122915/173481[36:00<14:49,56.88it/s] 71%|#######1  |123804/173481[36:11<14:33,56.88it/s] 81%|########  |139740/173481[39:00<07:57,70.72it/s] 81%|########1 |140845/173481[39:11<07:41,70.72it/s] 88%|########8 |153045/173481[42:00<04:42,72.28it/s] 89%|########8 |153709/173481[42:11<04:33,72.28it/s] 94%|#########3|162930/173481[45:00<02:49,62.41it/s] 94%|#########4|163584/173481[45:12<02:38,62.41it/s]100%|##########|173481/173481[47:52<00:00,60.39it/s]
[32m[0328 22:12:06 @base.py:257][0m Epoch 12 (global_step 12143670) finished, time:2872.63 sec.
[32m[0328 22:12:07 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-12143670.
  0%|          |0/18822[00:00<?,?it/s] 97%|#########6|18241/18822[03:00<00:05,101.34it/s]100%|##########|18822/18822[03:05<00:00,101.40it/s]
11
[32m[0328 22:15:12 @monitor.py:363][0m QueueInput/queue_size: 0.5187
[32m[0328 22:15:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.046
[32m[0328 22:15:12 @monitor.py:363][0m activation-summaries/output-rms: 0.028369
[32m[0328 22:15:12 @monitor.py:363][0m cross_entropy_loss: 6.1731
[32m[0328 22:15:12 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 22:15:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 22:15:12 @monitor.py:363][0m train-error-top1: 0.93951
[32m[0328 22:15:12 @monitor.py:363][0m val-error-top1: 0.94177
[32m[0328 22:15:12 @monitor.py:363][0m val-utt-error: 0.82749
[32m[0328 22:15:12 @monitor.py:363][0m validation_cost: 6.3599
[32m[0328 22:15:12 @monitor.py:363][0m wd_cost: 6.7701e-17
[32m[0328 22:15:12 @group.py:42][0m Callbacks took 185.916 sec in total. InferenceRunner: 185.631sec
[32m[0328 22:15:12 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10659/173481[03:00<45:50,59.21it/s]  6%|6         |11218/173481[03:10<45:40,59.21it/s] 12%|#1        |20654/173481[06:00<44:27,57.30it/s] 12%|#2        |21228/173481[06:10<44:17,57.30it/s] 18%|#7        |30464/173481[09:00<42:40,55.86it/s] 18%|#7        |31028/173481[09:10<42:30,55.86it/s] 23%|##3       |40329/173481[12:00<40:07,55.32it/s] 24%|##3       |40907/173481[12:10<39:56,55.32it/s] 29%|##8       |50177/173481[15:00<37:21,55.01it/s] 29%|##9       |50750/173481[15:10<37:11,55.01it/s] 35%|###4      |60562/173481[18:00<33:24,56.32it/s] 35%|###5      |61188/173481[18:10<33:13,56.32it/s] 41%|####      |70729/173481[21:00<30:21,56.40it/s] 41%|####1     |71358/173481[21:10<30:10,56.40it/s] 47%|####6     |80974/173481[24:00<27:12,56.65it/s] 47%|####7     |81584/173481[24:11<27:02,56.65it/s] 53%|#####2    |91414/173481[27:00<23:51,57.32it/s] 53%|#####3    |92038/173481[27:11<23:40,57.32it/s] 59%|#####8    |101654/173481[30:00<20:58,57.10it/s] 59%|#####8    |102305/173481[30:11<20:46,57.10it/s] 65%|######4   |112024/173481[33:00<17:51,57.35it/s] 65%|######4   |112686/173481[33:11<17:40,57.35it/s] 70%|#######   |122249/173481[36:00<14:57,57.07it/s] 71%|#######   |122880/173481[36:11<14:46,57.07it/s] 76%|#######6  |132503/173481[39:00<11:58,57.02it/s] 77%|#######6  |133113/173481[39:11<11:47,57.02it/s] 82%|########2 |142624/173481[42:00<09:05,56.61it/s] 83%|########2 |143283/173481[42:11<08:53,56.61it/s] 90%|######### |156376/173481[45:00<04:23,65.03it/s] 91%|######### |157473/173481[45:12<04:06,65.03it/s]100%|##########|173481/173481[47:59<00:00,60.24it/s]
[32m[0328 23:03:12 @base.py:257][0m Epoch 13 (global_step 12317151) finished, time:2879.99 sec.
[32m[0328 23:03:12 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,109.39it/s]
12
[32m[0328 23:06:05 @monitor.py:363][0m QueueInput/queue_size: 0.34344
[32m[0328 23:06:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.906
[32m[0328 23:06:05 @monitor.py:363][0m activation-summaries/output-rms: 0.028656
[32m[0328 23:06:05 @monitor.py:363][0m cross_entropy_loss: 6.1488
[32m[0328 23:06:05 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0328 23:06:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0328 23:06:05 @monitor.py:363][0m train-error-top1: 0.93394
[32m[0328 23:06:05 @monitor.py:363][0m val-error-top1: 0.94049
[32m[0328 23:06:05 @monitor.py:363][0m val-utt-error: 0.82085
[32m[0328 23:06:05 @monitor.py:363][0m validation_cost: 6.2979
[32m[0328 23:06:05 @monitor.py:363][0m wd_cost: 6.7701e-17
[32m[0328 23:06:05 @group.py:42][0m Callbacks took 172.381 sec in total. InferenceRunner: 172.093sec
[32m[0328 23:06:05 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10418/173481[03:00<46:57,57.87it/s]  6%|6         |10972/173481[03:10<46:47,57.87it/s] 12%|#1        |20196/173481[06:00<45:35,56.04it/s] 12%|#1        |20752/173481[06:10<45:25,56.04it/s] 17%|#7        |30028/173481[09:00<43:13,55.32it/s] 18%|#7        |30609/173481[09:10<43:02,55.32it/s] 23%|##3       |40737/173481[12:00<38:35,57.33it/s] 24%|##3       |41422/173481[12:10<38:23,57.33it/s] 29%|##9       |50618/173481[15:00<36:30,56.09it/s] 30%|##9       |51212/173481[15:10<36:20,56.09it/s] 35%|###4      |60678/173481[18:00<33:34,55.98it/s] 35%|###5      |61282/173481[18:10<33:24,55.98it/s] 41%|####      |70792/173481[21:00<30:30,56.09it/s] 41%|####1     |71407/173481[21:10<30:19,56.09it/s] 47%|####7     |82088/173481[24:00<25:42,59.23it/s] 48%|####7     |82810/173481[24:11<25:30,59.23it/s] 53%|#####3    |92662/173481[27:00<22:50,58.99it/s] 54%|#####3    |93269/173481[27:11<22:39,58.99it/s] 59%|#####9    |102737/173481[30:00<20:31,57.44it/s] 60%|#####9    |103361/173481[30:11<20:20,57.44it/s] 65%|######4   |112088/173481[33:00<18:45,54.55it/s] 65%|######4   |112709/173481[33:11<18:34,54.55it/s] 70%|######9   |121278/173481[36:00<16:29,52.74it/s] 70%|#######   |121817/173481[36:11<16:19,52.74it/s] 75%|#######4  |129413/173481[39:00<15:05,48.67it/s] 75%|#######4  |129976/173481[39:11<14:53,48.67it/s] 79%|#######9  |137193/173481[42:00<13:12,45.78it/s] 79%|#######9  |137687/173481[42:11<13:01,45.78it/s] 84%|########3 |145163/173481[45:00<10:29,45.01it/s] 84%|########3 |145694/173481[45:11<10:17,45.01it/s] 88%|########8 |153343/173481[48:00<07:25,45.22it/s] 89%|########8 |153910/173481[48:12<07:12,45.22it/s] 93%|#########3|161670/173481[51:00<04:18,45.73it/s] 94%|#########3|162256/173481[51:12<04:05,45.73it/s] 99%|#########8|170923/173481[54:00<00:52,48.40it/s] 99%|#########8|171638/173481[54:12<00:38,48.40it/s]100%|##########|173481/173481[54:41<00:00,52.87it/s]
[32m[0329 00:00:46 @base.py:257][0m Epoch 14 (global_step 12490632) finished, time:3281.12 sec.
[32m[0329 00:00:46 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-12490632.
[32m[0329 00:00:47 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.86it/s]
13
[32m[0329 00:02:40 @monitor.py:363][0m QueueInput/queue_size: 0.41678
[32m[0329 00:02:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.071
[32m[0329 00:02:40 @monitor.py:363][0m activation-summaries/output-rms: 0.027976
[32m[0329 00:02:40 @monitor.py:363][0m cross_entropy_loss: 6.2011
[32m[0329 00:02:40 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 00:02:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 00:02:40 @monitor.py:363][0m train-error-top1: 0.94597
[32m[0329 00:02:40 @monitor.py:363][0m val-error-top1: 0.94117
[32m[0329 00:02:40 @monitor.py:363][0m val-utt-error: 0.82547
[32m[0329 00:02:40 @monitor.py:363][0m validation_cost: 6.316
[32m[0329 00:02:40 @monitor.py:363][0m wd_cost: 1.354e-17
[32m[0329 00:02:40 @group.py:42][0m Callbacks took 114.348 sec in total. InferenceRunner: 113.491sec
[32m[0329 00:02:40 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8841/173481[03:00<55:52,49.12it/s]  5%|5         |9297/173481[03:10<55:42,49.12it/s] 10%|9         |17033/173481[06:00<55:11,47.24it/s] 10%|#         |17499/173481[06:10<55:01,47.24it/s] 14%|#4        |24828/173481[09:00<54:49,45.19it/s] 15%|#4        |25304/173481[09:10<54:39,45.19it/s] 19%|#8        |32883/173481[12:00<52:06,44.97it/s] 19%|#9        |33335/173481[12:10<51:56,44.97it/s] 24%|##4       |41667/173481[15:00<46:56,46.80it/s] 24%|##4       |42206/173481[15:10<46:45,46.80it/s] 29%|##9       |50492/173481[18:00<42:48,47.89it/s] 29%|##9       |51013/173481[18:10<42:37,47.89it/s] 34%|###4      |58998/173481[21:00<40:06,47.57it/s] 34%|###4      |59511/173481[21:11<39:55,47.57it/s] 39%|###8      |66925/173481[24:00<38:49,45.73it/s] 39%|###8      |67481/173481[24:11<38:37,45.73it/s] 44%|####3     |75672/173481[27:00<34:35,47.12it/s] 44%|####3     |76195/173481[27:11<34:24,47.12it/s] 48%|####8     |83882/173481[30:00<32:13,46.35it/s] 49%|####8     |84411/173481[30:11<32:01,46.35it/s] 53%|#####2    |91942/173481[33:00<29:50,45.54it/s] 53%|#####3    |92434/173481[33:11<29:39,45.54it/s] 58%|#####7    |99807/173481[36:00<27:32,44.60it/s] 58%|#####7    |100296/173481[36:11<27:21,44.60it/s] 62%|######2   |107925/173481[39:00<24:21,44.85it/s] 63%|######2   |108471/173481[39:11<24:09,44.85it/s] 67%|######6   |116177/173481[42:00<21:04,45.33it/s] 67%|######7   |116701/173481[42:11<20:52,45.33it/s] 72%|#######1  |124172/173481[45:00<18:19,44.87it/s] 72%|#######1  |124716/173481[45:12<18:06,44.87it/s] 76%|#######6  |132267/173481[48:00<15:17,44.91it/s] 77%|#######6  |132801/173481[48:12<15:05,44.91it/s] 81%|########  |140332/173481[51:00<12:18,44.86it/s] 81%|########1 |140873/173481[51:12<12:06,44.86it/s] 86%|########5 |148388/173481[54:00<09:20,44.81it/s] 86%|########5 |148941/173481[54:12<09:07,44.81it/s] 90%|######### |156572/173481[57:00<06:14,45.13it/s] 91%|######### |157081/173481[57:12<06:03,45.13it/s] 97%|#########6|167657/173481[1:00:00<01:51,52.09it/s] 97%|#########7|168451/173481[1:00:12<01:36,52.09it/s]100%|##########|173481/173481[1:01:44<00:00,46.83it/s]
[32m[0329 01:04:25 @base.py:257][0m Epoch 15 (global_step 12664113) finished, time:3704.63 sec.
[32m[0329 01:04:25 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:53<00:00,108.62it/s]
14
[32m[0329 01:07:18 @monitor.py:363][0m QueueInput/queue_size: 0.42111
[32m[0329 01:07:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.867
[32m[0329 01:07:18 @monitor.py:363][0m activation-summaries/output-rms: 0.02793
[32m[0329 01:07:18 @monitor.py:363][0m cross_entropy_loss: 6.1908
[32m[0329 01:07:18 @monitor.py:363][0m lr: 1.4901e-11
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 01:07:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 01:07:18 @monitor.py:363][0m train-error-top1: 0.94245
[32m[0329 01:07:18 @monitor.py:363][0m val-error-top1: 0.94092
[32m[0329 01:07:18 @monitor.py:363][0m val-utt-error: 0.82425
[32m[0329 01:07:18 @monitor.py:363][0m validation_cost: 6.2871
[32m[0329 01:07:18 @monitor.py:363][0m wd_cost: 1.354e-17
[32m[0329 01:07:18 @group.py:42][0m Callbacks took 173.560 sec in total. InferenceRunner: 173.299sec
[32m[0329 01:07:18 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9186/173481[03:00<53:40,51.02it/s]  6%|5         |9675/173481[03:10<53:30,51.02it/s] 10%|#         |18096/173481[06:00<51:32,50.24it/s] 11%|#         |18590/173481[06:10<51:22,50.24it/s] 16%|#5        |27201/173481[09:00<48:21,50.41it/s] 16%|#5        |27705/173481[09:10<48:11,50.41it/s] 21%|##        |35822/173481[12:00<46:42,49.12it/s] 21%|##        |36310/173481[12:10<46:32,49.12it/s] 26%|##5       |44325/173481[15:00<44:41,48.16it/s] 26%|##5       |44855/173481[15:10<44:30,48.16it/s] 30%|###       |52743/173481[18:00<42:24,47.45it/s] 31%|###       |53245/173481[18:10<42:13,47.45it/s] 35%|###5      |61134/173481[21:00<39:48,47.03it/s] 36%|###5      |61641/173481[21:10<39:38,47.03it/s] 40%|####      |69436/173481[24:00<37:14,46.56it/s] 40%|####      |69924/173481[24:11<37:04,46.56it/s] 45%|####4     |77536/173481[27:00<34:57,45.75it/s] 45%|####4     |78035/173481[27:11<34:46,45.75it/s] 49%|####9     |85836/173481[30:00<31:48,45.92it/s] 50%|####9     |86341/173481[30:11<31:37,45.92it/s] 54%|#####4    |94081/173481[33:00<28:51,45.86it/s] 55%|#####4    |94593/173481[33:11<28:40,45.86it/s] 59%|#####8    |102071/173481[36:00<26:23,45.10it/s] 59%|#####9    |102580/173481[36:11<26:11,45.10it/s] 63%|######3   |110117/173481[39:00<23:31,44.90it/s] 64%|######3   |110630/173481[39:11<23:19,44.90it/s] 68%|######8   |118101/173481[42:00<20:41,44.62it/s] 68%|######8   |118605/173481[42:11<20:29,44.62it/s] 73%|#######2  |126171/173481[45:00<17:37,44.72it/s] 73%|#######3  |126690/173481[45:12<17:26,44.72it/s] 77%|#######7  |134191/173481[48:00<14:40,44.63it/s] 78%|#######7  |134641/173481[48:12<14:30,44.63it/s] 82%|########1 |141916/173481[51:00<12:01,43.76it/s] 82%|########2 |142417/173481[51:12<11:49,43.76it/s] 86%|########6 |149812/173481[54:00<09:00,43.81it/s] 87%|########6 |150340/173481[54:12<08:48,43.81it/s] 92%|#########2|160376/173481[57:00<04:21,50.17it/s] 93%|#########2|161093/173481[57:12<04:06,50.17it/s] 97%|#########7|168661/173481[1:00:00<01:40,48.00it/s] 98%|#########7|169160/173481[1:00:12<01:30,48.00it/s]100%|##########|173481/173481[1:01:56<00:00,46.68it/s]
[32m[0329 02:09:15 @base.py:257][0m Epoch 16 (global_step 12837594) finished, time:3716.43 sec.
[32m[0329 02:09:15 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:51<00:00,109.59it/s]
15
[32m[0329 02:12:07 @monitor.py:363][0m QueueInput/queue_size: 0.46273
[32m[0329 02:12:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.158
[32m[0329 02:12:07 @monitor.py:363][0m activation-summaries/output-rms: 0.028978
[32m[0329 02:12:07 @monitor.py:363][0m cross_entropy_loss: 6.1187
[32m[0329 02:12:07 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 02:12:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 02:12:07 @monitor.py:363][0m train-error-top1: 0.93875
[32m[0329 02:12:07 @monitor.py:363][0m val-error-top1: 0.94109
[32m[0329 02:12:07 @monitor.py:363][0m val-utt-error: 0.82531
[32m[0329 02:12:07 @monitor.py:363][0m validation_cost: 6.2865
[32m[0329 02:12:07 @monitor.py:363][0m wd_cost: 1.354e-17
[32m[0329 02:12:07 @group.py:42][0m Callbacks took 172.097 sec in total. InferenceRunner: 171.761sec
[32m[0329 02:12:07 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9350/173481[03:00<52:40,51.93it/s]  6%|5         |9814/173481[03:10<52:31,51.93it/s] 10%|#         |17845/173481[06:00<52:27,49.44it/s] 11%|#         |18304/173481[06:10<52:18,49.44it/s] 15%|#5        |26244/173481[09:00<51:06,48.01it/s] 15%|#5        |26724/173481[09:10<50:56,48.01it/s] 20%|#9        |34580/173481[12:00<49:06,47.14it/s] 20%|##        |35034/173481[12:10<48:56,47.14it/s] 25%|##4       |42747/173481[15:00<47:07,46.24it/s] 25%|##4       |43239/173481[15:10<46:56,46.24it/s] 29%|##9       |51027/173481[18:00<44:15,46.12it/s] 30%|##9       |51514/173481[18:10<44:04,46.12it/s] 34%|###4      |59190/173481[21:00<41:39,45.73it/s] 34%|###4      |59694/173481[21:10<41:28,45.73it/s] 39%|###8      |67257/173481[24:00<39:06,45.27it/s] 39%|###9      |67764/173481[24:11<38:55,45.27it/s] 44%|####3     |75470/173481[27:00<35:56,45.45it/s] 44%|####3     |75994/173481[27:11<35:45,45.45it/s] 48%|####8     |84005/173481[30:00<32:08,46.41it/s] 49%|####8     |84629/173481[30:11<31:54,46.41it/s] 54%|#####4    |94106/173481[33:00<26:02,50.80it/s] 55%|#####4    |94759/173481[33:11<25:49,50.80it/s] 60%|######    |104130/173481[36:00<21:45,53.13it/s] 60%|######    |104754/173481[36:11<21:33,53.13it/s] 66%|######5   |114150/173481[39:00<18:11,54.37it/s] 66%|######6   |114799/173481[39:11<17:59,54.37it/s] 72%|#######1  |124086/173481[42:00<15:01,54.78it/s] 72%|#######1  |124724/173481[42:11<14:50,54.78it/s] 77%|#######7  |133731/173481[45:00<12:13,54.17it/s] 77%|#######7  |134265/173481[45:11<12:03,54.17it/s] 82%|########1 |141525/173481[48:00<11:04,48.12it/s] 82%|########1 |142041/173481[48:12<10:53,48.12it/s] 87%|########6 |150135/173481[51:00<08:06,47.97it/s] 87%|########6 |150881/173481[51:12<07:51,47.97it/s] 93%|#########2|161295/173481[54:00<03:45,54.09it/s] 93%|#########3|161774/173481[54:12<03:36,54.09it/s] 98%|#########7|169380/173481[57:00<01:23,49.07it/s] 98%|#########7|169954/173481[57:12<01:11,49.07it/s]100%|##########|173481/173481[58:27<00:00,49.45it/s]
[32m[0329 03:10:35 @base.py:257][0m Epoch 17 (global_step 13011075) finished, time:3507.98 sec.
[32m[0329 03:10:35 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-13011075.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:40<00:00,117.34it/s]
16
[32m[0329 03:13:15 @monitor.py:363][0m QueueInput/queue_size: 1.1171
[32m[0329 03:13:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.037
[32m[0329 03:13:15 @monitor.py:363][0m activation-summaries/output-rms: 0.028307
[32m[0329 03:13:15 @monitor.py:363][0m cross_entropy_loss: 6.1644
[32m[0329 03:13:15 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 03:13:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 03:13:15 @monitor.py:363][0m train-error-top1: 0.93952
[32m[0329 03:13:15 @monitor.py:363][0m val-error-top1: 0.94195
[32m[0329 03:13:15 @monitor.py:363][0m val-utt-error: 0.8285
[32m[0329 03:13:15 @monitor.py:363][0m validation_cost: 6.3551
[32m[0329 03:13:15 @monitor.py:363][0m wd_cost: 2.7081e-18
[32m[0329 03:13:15 @group.py:42][0m Callbacks took 160.663 sec in total. InferenceRunner: 160.422sec
[32m[0329 03:13:15 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8895/173481[03:00<55:30,49.42it/s]  5%|5         |9383/173481[03:10<55:20,49.42it/s] 10%|#         |17634/173481[06:00<53:01,48.98it/s] 10%|#         |18140/173481[06:10<52:51,48.98it/s] 15%|#5        |26324/173481[09:00<50:26,48.62it/s] 15%|#5        |26798/173481[09:10<50:16,48.62it/s] 20%|#9        |34449/173481[12:00<49:31,46.79it/s] 20%|##        |34908/173481[12:10<49:21,46.79it/s] 25%|##4       |43019/173481[15:00<46:04,47.20it/s] 25%|##5       |43606/173481[15:10<45:51,47.20it/s] 30%|###       |52761/173481[18:00<39:54,50.42it/s] 31%|###       |53213/173481[18:10<39:45,50.42it/s] 35%|###4      |60628/173481[21:00<40:10,46.82it/s] 35%|###5      |61098/173481[21:11<40:00,46.82it/s] 40%|###9      |68659/173481[24:00<38:14,45.69it/s] 40%|###9      |69163/173481[24:11<38:03,45.69it/s] 44%|####4     |76689/173481[27:00<35:44,45.14it/s] 44%|####4     |77178/173481[27:11<35:33,45.14it/s] 49%|####8     |84704/173481[30:00<33:00,44.83it/s] 49%|####9     |85184/173481[30:11<32:49,44.83it/s] 53%|#####3    |92664/173481[33:00<30:15,44.52it/s] 54%|#####3    |93173/173481[33:11<30:03,44.52it/s] 58%|#####7    |100569/173481[36:00<27:29,44.22it/s] 58%|#####8    |101078/173481[36:11<27:17,44.22it/s] 63%|######2   |108523/173481[39:00<24:29,44.20it/s] 63%|######2   |109004/173481[39:11<24:18,44.20it/s] 67%|######7   |116429/173481[42:00<21:35,44.06it/s] 67%|######7   |116938/173481[42:11<21:23,44.06it/s] 72%|#######1  |124684/173481[45:00<18:05,44.94it/s] 72%|#######2  |125193/173481[45:12<17:54,44.94it/s] 77%|#######6  |133114/173481[48:00<14:40,45.86it/s] 77%|#######7  |133633/173481[48:12<14:28,45.86it/s] 81%|########1 |141089/173481[51:00<11:58,45.07it/s] 82%|########1 |141626/173481[51:12<11:46,45.07it/s] 87%|########7 |150974/173481[54:00<07:34,49.51it/s] 87%|########7 |151720/173481[54:12<07:19,49.51it/s] 93%|#########2|161049/173481[57:00<03:56,52.54it/s] 93%|#########3|161553/173481[57:12<03:47,52.54it/s] 98%|#########7|169196/173481[1:00:00<01:28,48.63it/s] 98%|#########7|169728/173481[1:00:12<01:17,48.63it/s]100%|##########|173481/173481[1:01:38<00:00,46.91it/s]
[32m[0329 04:14:54 @base.py:257][0m Epoch 18 (global_step 13184556) finished, time:3698.11 sec.
[32m[0329 04:14:54 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:41<00:00,116.86it/s]
17
[32m[0329 04:17:35 @monitor.py:363][0m QueueInput/queue_size: 0.81437
[32m[0329 04:17:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.917
[32m[0329 04:17:35 @monitor.py:363][0m activation-summaries/output-rms: 0.028756
[32m[0329 04:17:35 @monitor.py:363][0m cross_entropy_loss: 6.145
[32m[0329 04:17:35 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 04:17:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 04:17:35 @monitor.py:363][0m train-error-top1: 0.93551
[32m[0329 04:17:35 @monitor.py:363][0m val-error-top1: 0.94067
[32m[0329 04:17:35 @monitor.py:363][0m val-utt-error: 0.82329
[32m[0329 04:17:35 @monitor.py:363][0m validation_cost: 6.3023
[32m[0329 04:17:35 @monitor.py:363][0m wd_cost: 2.7081e-18
[32m[0329 04:17:35 @group.py:42][0m Callbacks took 161.324 sec in total. InferenceRunner: 161.072sec
[32m[0329 04:17:35 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8715/173481[03:00<56:43,48.42it/s]  5%|5         |9169/173481[03:10<56:33,48.42it/s] 10%|9         |16521/173481[06:00<57:10,45.75it/s] 10%|9         |16957/173481[06:10<57:01,45.75it/s] 14%|#4        |24363/173481[09:00<55:41,44.63it/s] 14%|#4        |24822/173481[09:10<55:31,44.63it/s] 19%|#8        |32403/173481[12:00<52:40,44.64it/s] 19%|#8        |32858/173481[12:10<52:30,44.64it/s] 23%|##3       |40461/173481[15:00<49:35,44.70it/s] 24%|##3       |40942/173481[15:10<49:24,44.70it/s] 28%|##8       |48588/173481[18:00<46:20,44.93it/s] 28%|##8       |49057/173481[18:10<46:09,44.93it/s] 33%|###2      |56491/173481[21:00<43:54,44.41it/s] 33%|###2      |56972/173481[21:10<43:43,44.41it/s] 37%|###7      |64493/173481[24:00<40:53,44.43it/s] 37%|###7      |64972/173481[24:11<40:42,44.43it/s] 42%|####1     |72598/173481[27:00<37:35,44.72it/s] 42%|####2     |73107/173481[27:11<37:24,44.72it/s] 47%|####6     |80723/173481[30:00<34:24,44.92it/s] 47%|####6     |81239/173481[30:11<34:13,44.92it/s] 51%|#####1    |88858/173481[33:00<31:18,45.05it/s] 52%|#####1    |89362/173481[33:11<31:07,45.05it/s] 56%|#####5    |97036/173481[36:00<28:09,45.24it/s] 56%|#####6    |97537/173481[36:11<27:58,45.24it/s] 61%|######    |105130/173481[39:00<25:15,45.10it/s] 61%|######    |105637/173481[39:11<25:04,45.10it/s] 65%|######5   |113243/173481[42:00<22:16,45.08it/s] 66%|######5   |113777/173481[42:11<22:04,45.08it/s] 70%|#######   |121638/173481[45:00<18:50,45.84it/s] 70%|#######   |122147/173481[45:12<18:39,45.84it/s] 75%|#######4  |129758/173481[48:00<16:01,45.46it/s] 75%|#######5  |130296/173481[48:12<15:49,45.46it/s] 80%|#######9  |138498/173481[51:00<12:25,46.95it/s] 80%|########  |139242/173481[51:12<12:09,46.95it/s] 86%|########6 |149789/173481[54:00<07:21,53.70it/s] 87%|########6 |150517/173481[54:12<07:07,53.70it/s] 91%|#########1|158483/173481[57:00<04:54,50.86it/s] 92%|#########1|159049/173481[57:12<04:43,50.86it/s] 96%|#########6|166888/173481[1:00:00<02:15,48.68it/s] 96%|#########6|167397/173481[1:00:12<02:04,48.68it/s]100%|##########|173481/173481[1:02:28<00:00,46.28it/s]
[32m[0329 05:20:04 @base.py:257][0m Epoch 19 (global_step 13358037) finished, time:3748.65 sec.
[32m[0329 05:20:04 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:39<00:00,118.19it/s]
18
[32m[0329 05:22:43 @monitor.py:363][0m QueueInput/queue_size: 0.45186
[32m[0329 05:22:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.065
[32m[0329 05:22:43 @monitor.py:363][0m activation-summaries/output-rms: 0.027937
[32m[0329 05:22:43 @monitor.py:363][0m cross_entropy_loss: 6.1992
[32m[0329 05:22:43 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 05:22:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 05:22:43 @monitor.py:363][0m train-error-top1: 0.94455
[32m[0329 05:22:43 @monitor.py:363][0m val-error-top1: 0.94102
[32m[0329 05:22:43 @monitor.py:363][0m val-utt-error: 0.82483
[32m[0329 05:22:43 @monitor.py:363][0m validation_cost: 6.3122
[32m[0329 05:22:43 @monitor.py:363][0m wd_cost: 2.7081e-18
[32m[0329 05:22:43 @group.py:42][0m Callbacks took 159.469 sec in total. InferenceRunner: 159.262sec
[32m[0329 05:22:43 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8357/173481[03:00<59:17,46.41it/s]  5%|5         |8796/173481[03:10<59:08,46.41it/s]  9%|9         |16217/173481[06:00<58:15,44.99it/s] 10%|9         |16642/173481[06:10<58:06,44.99it/s] 14%|#3        |23877/173481[09:00<57:00,43.74it/s] 14%|#4        |24328/173481[09:10<56:50,43.74it/s] 18%|#8        |32047/173481[12:00<52:55,44.54it/s] 19%|#8        |32518/173481[12:10<52:44,44.54it/s] 23%|##3       |40327/173481[15:00<49:02,45.25it/s] 24%|##3       |40811/173481[15:10<48:51,45.25it/s] 28%|##7       |48380/173481[18:00<46:20,44.99it/s] 28%|##8       |48852/173481[18:10<46:09,44.99it/s] 33%|###2      |56984/173481[21:00<41:53,46.35it/s] 33%|###3      |57492/173481[21:11<41:42,46.35it/s] 38%|###7      |65662/173481[24:00<38:01,47.26it/s] 38%|###8      |66176/173481[24:11<37:50,47.26it/s] 43%|####2     |73942/173481[27:00<35:35,46.62it/s] 43%|####2     |74476/173481[27:11<35:23,46.62it/s] 47%|####7     |82337/173481[30:00<32:34,46.62it/s] 48%|####7     |82857/173481[30:11<32:23,46.62it/s] 52%|#####2    |90792/173481[33:00<29:27,46.79it/s] 53%|#####2    |91291/173481[33:11<29:16,46.79it/s] 57%|#####6    |98553/173481[36:00<27:49,44.88it/s] 57%|#####7    |98996/173481[36:11<27:39,44.88it/s] 61%|######1   |106417/173481[39:00<25:14,44.27it/s] 62%|######1   |106926/173481[39:11<25:03,44.27it/s] 66%|######5   |114087/173481[42:00<22:47,43.42it/s] 66%|######6   |114591/173481[42:12<22:36,43.42it/s] 70%|#######   |121467/173481[45:00<20:33,42.17it/s] 70%|#######   |121991/173481[45:12<20:21,42.17it/s] 75%|#######4  |129692/173481[48:00<16:38,43.86it/s] 75%|#######5  |130391/173481[48:12<16:22,43.86it/s] 81%|########  |140372/173481[51:00<10:56,50.43it/s] 81%|########1 |141118/173481[51:12<10:41,50.43it/s] 86%|########5 |148834/173481[54:00<08:26,48.66it/s] 86%|########6 |149336/173481[54:12<08:16,48.66it/s] 91%|######### |157177/173481[57:00<05:43,47.47it/s] 91%|######### |157738/173481[57:12<05:31,47.47it/s] 95%|#########5|165167/173481[1:00:00<03:01,45.88it/s] 96%|#########5|165690/173481[1:00:12<02:49,45.88it/s]100%|#########9|173023/173481[1:03:00<00:10,44.73it/s]100%|##########|173481/173481[1:03:11<00:00,45.76it/s]
[32m[0329 06:25:54 @base.py:257][0m Epoch 20 (global_step 13531518) finished, time:3791.09 sec.
[32m[0329 06:25:55 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-13531518.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,108.85it/s]
19
[32m[0329 06:28:48 @monitor.py:363][0m QueueInput/queue_size: 0.58193
[32m[0329 06:28:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.864
[32m[0329 06:28:48 @monitor.py:363][0m activation-summaries/output-rms: 0.027936
[32m[0329 06:28:48 @monitor.py:363][0m cross_entropy_loss: 6.1895
[32m[0329 06:28:48 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 06:28:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 06:28:48 @monitor.py:363][0m train-error-top1: 0.94304
[32m[0329 06:28:48 @monitor.py:363][0m val-error-top1: 0.94064
[32m[0329 06:28:48 @monitor.py:363][0m val-utt-error: 0.82335
[32m[0329 06:28:48 @monitor.py:363][0m validation_cost: 6.2856
[32m[0329 06:28:48 @monitor.py:363][0m wd_cost: 5.4161e-19
[32m[0329 06:28:48 @group.py:42][0m Callbacks took 173.767 sec in total. InferenceRunner: 172.932sec
[32m[0329 06:28:48 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8636/173481[03:00<57:15,47.98it/s]  5%|5         |9100/173481[03:10<57:06,47.98it/s] 10%|9         |16552/173481[06:00<56:59,45.89it/s] 10%|9         |17015/173481[06:10<56:49,45.89it/s] 15%|#4        |25976/173481[09:00<50:16,48.90it/s] 15%|#5        |26498/173481[09:10<50:05,48.90it/s] 20%|##        |34816/173481[12:00<47:09,49.00it/s] 20%|##        |35280/173481[12:10<47:00,49.00it/s] 25%|##4       |42941/173481[15:00<46:18,46.99it/s] 25%|##5       |43414/173481[15:10<46:07,46.99it/s] 30%|##9       |51511/173481[18:00<42:59,47.29it/s] 30%|##9       |51995/173481[18:10<42:49,47.29it/s] 34%|###4      |59621/173481[21:00<41:07,46.14it/s] 35%|###4      |60020/173481[21:10<40:58,46.14it/s] 39%|###8      |67081/173481[24:00<40:37,43.66it/s] 39%|###8      |67540/173481[24:11<40:26,43.66it/s] 43%|####3     |74776/173481[27:00<38:04,43.20it/s] 43%|####3     |75280/173481[27:11<37:53,43.20it/s] 48%|####7     |82929/173481[30:00<34:07,44.22it/s] 48%|####8     |83427/173481[30:11<33:56,44.22it/s] 52%|#####2    |90776/173481[33:00<31:23,43.90it/s] 53%|#####2    |91255/173481[33:11<31:12,43.90it/s] 57%|#####6    |98567/173481[36:00<28:38,43.59it/s] 57%|#####7    |99075/173481[36:11<28:26,43.59it/s] 61%|######1   |106316/173481[39:00<25:50,43.32it/s] 62%|######1   |106816/173481[39:11<25:39,43.32it/s] 66%|######5   |114259/173481[42:00<22:34,43.72it/s] 66%|######6   |114780/173481[42:11<22:22,43.72it/s] 71%|#######1  |123858/173481[45:00<17:12,48.05it/s] 72%|#######1  |124580/173481[45:12<16:57,48.05it/s] 77%|#######6  |133491/173481[48:00<13:09,50.63it/s] 77%|#######7  |134031/173481[48:12<12:59,50.63it/s] 82%|########1 |141975/173481[51:00<10:45,48.82it/s] 82%|########2 |142525/173481[51:12<10:34,48.82it/s] 86%|########6 |149751/173481[54:00<08:37,45.83it/s] 87%|########6 |150275/173481[54:12<08:26,45.83it/s] 91%|######### |157531/173481[57:00<05:58,44.48it/s] 91%|#########1|158105/173481[57:12<05:45,44.48it/s] 95%|#########5|165419/173481[1:00:00<03:02,44.15it/s] 96%|#########5|165952/173481[1:00:12<02:50,44.15it/s]100%|#########9|173157/173481[1:03:00<00:07,43.56it/s]100%|##########|173481/173481[1:03:08<00:00,45.79it/s]
[32m[0329 07:31:56 @base.py:257][0m Epoch 21 (global_step 13704999) finished, time:3788.48 sec.
[32m[0329 07:31:57 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-13704999.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:46<00:00,112.89it/s]
20
[32m[0329 07:34:43 @monitor.py:363][0m QueueInput/queue_size: 0.42983
[32m[0329 07:34:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.157
[32m[0329 07:34:43 @monitor.py:363][0m activation-summaries/output-rms: 0.028931
[32m[0329 07:34:43 @monitor.py:363][0m cross_entropy_loss: 6.1198
[32m[0329 07:34:43 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 07:34:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 07:34:43 @monitor.py:363][0m train-error-top1: 0.93872
[32m[0329 07:34:43 @monitor.py:363][0m val-error-top1: 0.94103
[32m[0329 07:34:43 @monitor.py:363][0m val-utt-error: 0.82414
[32m[0329 07:34:43 @monitor.py:363][0m validation_cost: 6.2815
[32m[0329 07:34:43 @monitor.py:363][0m wd_cost: 5.4161e-19
[32m[0329 07:34:43 @group.py:42][0m Callbacks took 167.050 sec in total. InferenceRunner: 166.751sec
[32m[0329 07:34:43 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|4         |8615/173481[03:00<57:25,47.84it/s]  5%|5         |9076/173481[03:10<57:16,47.84it/s] 10%|9         |16795/173481[06:00<56:01,46.61it/s] 10%|9         |17264/173481[06:10<55:51,46.61it/s] 14%|#4        |25045/173481[09:00<53:32,46.21it/s] 15%|#4        |25509/173481[09:10<53:22,46.21it/s] 19%|#9        |33145/173481[12:00<51:18,45.59it/s] 19%|#9        |33589/173481[12:10<51:08,45.59it/s] 23%|##3       |40612/173481[15:00<50:58,43.44it/s] 24%|##3       |41041/173481[15:10<50:48,43.44it/s] 28%|##7       |48145/173481[18:00<49:00,42.63it/s] 28%|##8       |48590/173481[18:10<48:49,42.63it/s] 32%|###2      |55535/173481[21:00<47:00,41.82it/s] 32%|###2      |55994/173481[21:10<46:49,41.82it/s] 37%|###6      |63325/173481[24:00<43:10,42.53it/s] 37%|###6      |63769/173481[24:11<42:59,42.53it/s] 41%|####      |70980/173481[27:00<40:10,42.52it/s] 41%|####1     |71464/173481[27:11<39:59,42.52it/s] 46%|####5     |79065/173481[30:00<36:01,43.67it/s] 46%|####5     |79532/173481[30:11<35:51,43.67it/s] 50%|#####     |87180/173481[33:00<32:25,44.35it/s] 51%|#####     |87684/173481[33:11<32:14,44.35it/s] 55%|#####4    |95212/173481[36:00<29:19,44.49it/s] 55%|#####5    |95684/173481[36:11<29:08,44.49it/s] 59%|#####9    |103046/173481[39:00<26:40,44.00it/s] 60%|#####9    |103706/173481[39:11<26:25,44.00it/s] 65%|######5   |113630/173481[42:00<19:49,50.33it/s] 66%|######5   |114289/173481[42:11<19:36,50.33it/s] 71%|#######   |122345/173481[45:00<17:16,49.35it/s] 71%|#######   |122848/173481[45:11<17:05,49.35it/s] 75%|#######5  |130520/173481[48:00<15:08,47.30it/s] 76%|#######5  |131019/173481[48:12<14:57,47.30it/s] 80%|#######9  |138740/173481[51:00<12:27,46.46it/s] 80%|########  |139259/173481[51:12<12:16,46.46it/s] 85%|########4 |146740/173481[54:00<09:48,45.43it/s] 85%|########4 |147246/173481[54:12<09:37,45.43it/s] 89%|########9 |154565/173481[57:00<07:05,44.42it/s] 89%|########9 |155108/173481[57:12<06:53,44.42it/s] 94%|#########3|162998/173481[1:00:00<03:49,45.60it/s] 94%|#########4|163550/173481[1:00:12<03:37,45.60it/s] 99%|#########8|171363/173481[1:03:00<00:46,46.03it/s] 99%|#########9|171917/173481[1:03:12<00:33,46.03it/s]100%|##########|173481/173481[1:03:46<00:00,45.34it/s]
[32m[0329 08:38:30 @base.py:257][0m Epoch 22 (global_step 13878480) finished, time:3826.49 sec.
[32m[0329 08:38:30 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-13878480.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:47<00:00,112.23it/s]
21
[32m[0329 08:41:18 @monitor.py:363][0m QueueInput/queue_size: 0.51218
[32m[0329 08:41:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.037
[32m[0329 08:41:18 @monitor.py:363][0m activation-summaries/output-rms: 0.02835
[32m[0329 08:41:18 @monitor.py:363][0m cross_entropy_loss: 6.1637
[32m[0329 08:41:18 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 08:41:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 08:41:18 @monitor.py:363][0m train-error-top1: 0.9391
[32m[0329 08:41:18 @monitor.py:363][0m val-error-top1: 0.94186
[32m[0329 08:41:18 @monitor.py:363][0m val-utt-error: 0.82775
[32m[0329 08:41:18 @monitor.py:363][0m validation_cost: 6.3529
[32m[0329 08:41:18 @monitor.py:363][0m wd_cost: 5.4161e-19
[32m[0329 08:41:18 @group.py:42][0m Callbacks took 168.036 sec in total. InferenceRunner: 167.716sec
[32m[0329 08:41:18 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8845/173481[03:00<55:50,49.14it/s]  5%|5         |9338/173481[03:10<55:40,49.14it/s] 10%|#         |17404/173481[06:00<53:49,48.33it/s] 10%|#         |17889/173481[06:10<53:39,48.33it/s] 15%|#4        |25889/173481[09:00<51:32,47.72it/s] 15%|#5        |26366/173481[09:10<51:22,47.72it/s] 20%|#9        |34014/173481[12:00<50:06,46.38it/s] 20%|#9        |34479/173481[12:10<49:56,46.38it/s] 24%|##4       |42115/173481[15:00<47:55,45.68it/s] 25%|##4       |42588/173481[15:10<47:45,45.68it/s] 29%|##8       |49859/173481[18:00<46:30,44.30it/s] 29%|##9       |50316/173481[18:10<46:20,44.30it/s] 33%|###3      |57550/173481[21:00<44:25,43.50it/s] 33%|###3      |58008/173481[21:10<44:14,43.50it/s] 38%|###7      |65512/173481[24:00<41:01,43.86it/s] 38%|###8      |66003/173481[24:11<40:50,43.86it/s] 42%|####2     |73409/173481[27:00<38:01,43.86it/s] 43%|####2     |73889/173481[27:11<37:50,43.86it/s] 47%|####6     |81384/173481[30:00<34:49,44.08it/s] 47%|####7     |81853/173481[30:11<34:38,44.08it/s] 51%|#####1    |89197/173481[33:00<32:07,43.74it/s] 52%|#####1    |89653/173481[33:11<31:56,43.74it/s] 57%|#####6    |98731/173481[36:00<26:00,47.91it/s] 57%|#####7    |99374/173481[36:11<25:46,47.91it/s] 62%|######2   |108209/173481[39:00<21:41,50.16it/s] 63%|######2   |108728/173481[39:11<21:30,50.16it/s] 67%|######7   |116448/173481[42:00<19:51,47.87it/s] 67%|######7   |116973/173481[42:11<19:40,47.87it/s] 72%|#######1  |124527/173481[45:00<17:36,46.33it/s] 72%|#######2  |125018/173481[45:12<17:26,46.33it/s] 76%|#######6  |132389/173481[48:00<15:14,44.96it/s] 77%|#######6  |132893/173481[48:12<15:02,44.96it/s] 81%|########  |140394/173481[51:00<12:20,44.71it/s] 81%|########1 |140903/173481[51:12<12:08,44.71it/s] 86%|########5 |148394/173481[54:00<09:22,44.57it/s] 86%|########5 |148933/173481[54:12<09:10,44.57it/s] 90%|######### |156404/173481[57:00<06:23,44.53it/s] 90%|######### |156919/173481[57:12<06:11,44.53it/s] 95%|#########4|164318/173481[1:00:00<03:27,44.25it/s] 95%|#########5|164853/173481[1:00:12<03:15,44.25it/s] 99%|#########9|172188/173481[1:03:00<00:29,43.98it/s]100%|#########9|172709/173481[1:03:12<00:17,43.98it/s]100%|##########|173481/173481[1:03:31<00:00,45.51it/s]
[32m[0329 09:44:50 @base.py:257][0m Epoch 23 (global_step 14051961) finished, time:3811.84 sec.
[32m[0329 09:44:50 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-14051961.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:47<00:00,112.37it/s]
22
[32m[0329 09:47:38 @monitor.py:363][0m QueueInput/queue_size: 0.4983
[32m[0329 09:47:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.916
[32m[0329 09:47:38 @monitor.py:363][0m activation-summaries/output-rms: 0.028732
[32m[0329 09:47:38 @monitor.py:363][0m cross_entropy_loss: 6.1435
[32m[0329 09:47:38 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 09:47:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 09:47:38 @monitor.py:363][0m train-error-top1: 0.93512
[32m[0329 09:47:38 @monitor.py:363][0m val-error-top1: 0.94069
[32m[0329 09:47:38 @monitor.py:363][0m val-utt-error: 0.82005
[32m[0329 09:47:38 @monitor.py:363][0m validation_cost: 6.2998
[32m[0329 09:47:38 @monitor.py:363][0m wd_cost: 1.0832e-19
[32m[0329 09:47:38 @group.py:42][0m Callbacks took 167.776 sec in total. InferenceRunner: 167.518sec
[32m[0329 09:47:38 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8762/173481[03:00<56:23,48.68it/s]  5%|5         |9224/173481[03:10<56:14,48.68it/s] 10%|9         |16655/173481[06:00<56:39,46.14it/s] 10%|9         |17103/173481[06:10<56:29,46.14it/s] 14%|#4        |24552/173481[09:00<55:11,44.98it/s] 14%|#4        |25000/173481[09:10<55:01,44.98it/s] 19%|#8        |32518/173481[12:00<52:39,44.61it/s] 19%|#9        |32985/173481[12:10<52:29,44.61it/s] 23%|##3       |40503/173481[15:00<49:49,44.48it/s] 24%|##3       |40990/173481[15:10<49:38,44.48it/s] 28%|##7       |48205/173481[18:00<47:52,43.62it/s] 28%|##8       |48660/173481[18:10<47:41,43.62it/s] 32%|###2      |55673/173481[21:00<46:10,42.53it/s] 32%|###2      |56111/173481[21:10<45:59,42.53it/s] 37%|###6      |63440/173481[24:00<42:48,42.84it/s] 37%|###6      |63962/173481[24:10<42:36,42.84it/s] 42%|####1     |71996/173481[27:00<37:32,45.06it/s] 42%|####1     |72532/173481[27:11<37:20,45.06it/s] 46%|####6     |80343/173481[30:00<33:57,45.70it/s] 47%|####6     |80852/173481[30:11<33:46,45.70it/s] 52%|#####2    |90719/173481[33:00<27:03,50.98it/s] 53%|#####2    |91402/173481[33:11<26:49,50.98it/s] 57%|#####7    |99610/173481[36:00<24:32,50.17it/s] 58%|#####7    |100092/173481[36:11<24:22,50.17it/s] 62%|######1   |107153/173481[39:00<24:12,45.67it/s] 62%|######2   |107642/173481[39:11<24:01,45.67it/s] 66%|######6   |114741/173481[42:00<22:19,43.84it/s] 66%|######6   |115236/173481[42:11<22:08,43.84it/s] 71%|#######   |122341/173481[45:00<19:48,43.02it/s] 71%|#######   |122827/173481[45:11<19:37,43.02it/s] 75%|#######4  |129923/173481[48:00<17:03,42.56it/s] 75%|#######5  |130422/173481[48:12<16:51,42.56it/s] 79%|#######9  |137548/173481[51:00<14:06,42.46it/s] 80%|#######9  |138072/173481[51:12<13:53,42.46it/s] 84%|########3 |145121/173481[54:00<11:11,42.26it/s] 84%|########3 |145632/173481[54:12<10:58,42.26it/s] 88%|########8 |152753/173481[57:00<08:09,42.33it/s] 88%|########8 |153261/173481[57:12<07:57,42.33it/s] 92%|#########2|160348/173481[1:00:00<05:10,42.26it/s] 93%|#########2|160847/173481[1:00:12<04:58,42.26it/s] 97%|#########6|167783/173481[1:03:00<02:16,41.77it/s] 97%|#########6|168272/173481[1:03:12<02:04,41.77it/s]100%|##########|173481/173481[1:05:20<00:00,44.25it/s]
[32m[0329 10:52:58 @base.py:257][0m Epoch 24 (global_step 14225442) finished, time:3920.36 sec.
[32m[0329 10:52:58 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-14225442.
  0%|          |0/18822[00:00<?,?it/s] 90%|########9 |16933/18822[03:00<00:20,94.07it/s] 95%|#########5|17947/18822[03:10<00:09,94.07it/s]100%|##########|18822/18822[03:18<00:00,94.72it/s]
23
[32m[0329 10:56:17 @monitor.py:363][0m QueueInput/queue_size: 0.66215
[32m[0329 10:56:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.067
[32m[0329 10:56:17 @monitor.py:363][0m activation-summaries/output-rms: 0.028024
[32m[0329 10:56:17 @monitor.py:363][0m cross_entropy_loss: 6.1994
[32m[0329 10:56:17 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 10:56:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 10:56:17 @monitor.py:363][0m train-error-top1: 0.94652
[32m[0329 10:56:17 @monitor.py:363][0m val-error-top1: 0.94097
[32m[0329 10:56:17 @monitor.py:363][0m val-utt-error: 0.82404
[32m[0329 10:56:17 @monitor.py:363][0m validation_cost: 6.3107
[32m[0329 10:56:17 @monitor.py:363][0m wd_cost: 1.0832e-19
[32m[0329 10:56:17 @group.py:42][0m Callbacks took 198.999 sec in total. InferenceRunner: 198.727sec
[32m[0329 10:56:17 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  4%|4         |7747/173481[03:00<1:04:11,43.03it/s]  5%|4         |8166/173481[03:10<1:04:01,43.03it/s]  9%|8         |15057/173481[06:00<1:03:11,41.78it/s]  9%|8         |15468/173481[06:10<1:03:02,41.78it/s] 13%|#2        |22352/173481[09:00<1:01:13,41.14it/s] 13%|#3        |22741/173481[09:10<1:01:03,41.14it/s] 17%|#7        |29842/173481[12:00<57:51,41.37it/s]   17%|#7        |30294/173481[12:10<57:40,41.37it/s] 22%|##1       |37482/173481[15:00<54:06,41.90it/s] 22%|##1       |37915/173481[15:10<53:55,41.90it/s] 27%|##7       |47292/173481[18:00<44:23,47.37it/s] 28%|##7       |47971/173481[18:10<44:09,47.37it/s] 33%|###3      |57752/173481[21:00<36:57,52.19it/s] 34%|###3      |58261/173481[21:10<36:47,52.19it/s] 38%|###8      |66267/173481[24:00<36:00,49.62it/s] 38%|###8      |66776/173481[24:11<35:50,49.62it/s] 43%|####2     |74532/173481[27:00<34:34,47.69it/s] 43%|####3     |75016/173481[27:11<34:24,47.69it/s] 48%|####7     |82713/173481[30:00<32:30,46.54it/s] 48%|####7     |83226/173481[30:11<32:19,46.54it/s] 52%|#####2    |90907/173481[33:00<29:54,46.02it/s] 53%|#####2    |91381/173481[33:11<29:43,46.02it/s] 57%|#####7    |98998/173481[36:00<27:17,45.48it/s] 57%|#####7    |99521/173481[36:11<27:06,45.48it/s] 62%|######1   |107122/173481[39:00<24:24,45.30it/s] 62%|######2   |107661/173481[39:11<24:13,45.30it/s] 66%|######6   |115207/173481[42:00<21:32,45.07it/s] 67%|######6   |115698/173481[42:11<21:21,45.07it/s] 71%|#######1  |123292/173481[45:00<18:35,44.99it/s] 71%|#######1  |123811/173481[45:12<18:24,44.99it/s] 76%|#######5  |131421/173481[48:00<15:33,45.07it/s] 76%|#######6  |131945/173481[48:12<15:21,45.07it/s] 80%|########  |139517/173481[51:00<12:34,45.02it/s] 81%|########  |140026/173481[51:12<12:23,45.02it/s] 85%|########5 |147722/173481[54:00<09:28,45.29it/s] 85%|########5 |148249/173481[54:12<09:17,45.29it/s] 90%|########9 |155832/173481[57:00<06:30,45.17it/s] 90%|######### |156381/173481[57:12<06:18,45.17it/s] 95%|#########4|164017/173481[1:00:00<03:28,45.32it/s] 95%|#########4|164565/173481[1:00:12<03:16,45.32it/s] 99%|#########9|172307/173481[1:03:00<00:25,45.68it/s]100%|#########9|172836/173481[1:03:12<00:14,45.68it/s]100%|##########|173481/173481[1:03:27<00:00,45.56it/s]
[32m[0329 11:59:45 @base.py:257][0m Epoch 25 (global_step 14398923) finished, time:3807.87 sec.
[32m[0329 11:59:45 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_True_preload/model-14398923.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:50<00:00,110.19it/s]
24
[32m[0329 12:02:36 @monitor.py:363][0m QueueInput/queue_size: 0.57037
[32m[0329 12:02:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.861
[32m[0329 12:02:36 @monitor.py:363][0m activation-summaries/output-rms: 0.027875
[32m[0329 12:02:36 @monitor.py:363][0m cross_entropy_loss: 6.1867
[32m[0329 12:02:36 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0329 12:02:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0329 12:02:36 @monitor.py:363][0m train-error-top1: 0.94155
[32m[0329 12:02:36 @monitor.py:363][0m val-error-top1: 0.94102
[32m[0329 12:02:36 @monitor.py:363][0m val-utt-error: 0.82526
[32m[0329 12:02:36 @monitor.py:363][0m validation_cost: 6.2839
[32m[0329 12:02:36 @monitor.py:363][0m wd_cost: 1.0832e-19
[32m[0329 12:02:36 @group.py:42][0m Callbacks took 171.065 sec in total. InferenceRunner: 170.823sec
[32m[0329 12:02:36 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8683/173481[03:00<56:56,48.24it/s]  5%|5         |9155/173481[03:10<56:46,48.24it/s] 10%|9         |16962/173481[06:00<55:23,47.09it/s] 10%|#         |17440/173481[06:10<55:13,47.09it/s] 15%|#4        |25186/173481[09:00<53:17,46.37it/s] 15%|#4        |25657/173481[09:10<53:07,46.37it/s] 19%|#9        |33376/173481[12:00<50:50,45.93it/s] 19%|#9        |33820/173481[12:10<50:40,45.93it/s] 24%|##3       |41604/173481[15:00<47:58,45.82it/s] 24%|##4       |42250/173481[15:10<47:44,45.82it/s] 30%|###       |52282/173481[18:00<39:04,51.70it/s] 31%|###       |52925/173481[18:10<38:51,51.70it/s] 35%|###5      |60776/173481[21:00<38:04,49.34it/s] 35%|###5      |61272/173481[21:10<37:54,49.34it/s] 40%|###9      |68866/173481[24:00<37:04,47.03it/s] 40%|###9      |69341/173481[24:11<36:54,47.03it/s] 44%|####4     |76726/173481[27:00<35:36,45.28it/s] 45%|####4     |77230/173481[27:11<35:25,45.28it/s] 49%|####8     |84606/173481[30:00<33:16,44.51it/s] 49%|####9     |85091/173481[30:11<33:05,44.51it/s] 53%|#####3    |92601/173481[33:00<30:19,44.46it/s] 54%|#####3    |93115/173481[33:11<30:07,44.46it/s] 58%|#####8    |100702/173481[36:00<27:07,44.73it/s] 58%|#####8    |101206/173481[36:11<26:55,44.73it/s]slurmstepd: *** JOB 85140 ON sls-sm-3 CANCELLED AT 2018-03-29T12:39:05 ***
