sls-sm-11 2
SLURM_JOBID=70360
SLURM_TASKID=5
[32m[0320 11:46:09 @logger.py:67][0m Existing log file 'train_log/fcn2_w_32_a_32_quant_ends_False/log.log' backuped to 'train_log/fcn2_w_32_a_32_quant_ends_False/log.log.0320-114609'
[32m[0320 11:46:09 @logger.py:74][0m Argv: drf_run.py --model_name=fcn2 --bitw=32 --bita=32 --quant_ends=False
[32m[0320 11:46:19 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0320 11:46:19 @drf_run.py:140][0m Using 6 threads
('whole utterance size', 75290)
[32m[0320 11:46:20 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0320 11:46:20 @drf_run.py:166][0m Using host: sls-sm-11
[32m[0320 11:46:20 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0320 11:46:20 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0320 11:46:20 @drf_run.py:188][0m Using GPU: 2
[32m[0320 11:46:20 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0320 11:46:20 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0320 11:46:20 @training.py:108][0m Building graph for training tower 0 ...
[32m[0320 11:46:20 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0320 11:46:20 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0320 11:46:20 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear0 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m linear1 input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear1 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m linear2 input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear2 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m linear3 input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0320 11:46:20 @registry.py:130][0m linear3 output: [None, 504]
[32m[0320 11:46:20 @registry.py:122][0m last_linear input: [None, 504]
[32m[0320 11:46:20 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0320 11:46:20 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0320 11:46:20 @registry.py:130][0m last_linear output: [None, 255]
[32m[0320 11:46:20 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0320 11:46:20 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0320 11:46:20 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0320 11:46:20 @drf_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0320 11:46:20 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=1400871, size=5.34MB[0m
[32m[0320 11:46:20 @base.py:196][0m Setup callbacks graph ...
[32m[0320 11:46:20 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0320 11:46:20 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0320 11:46:20 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0320 11:46:20 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0320 11:46:20 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0320 11:46:21 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0320 11:46:21 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0320 11:46:21 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0320 11:46:21 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0320 11:46:21 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0320 11:46:21 @drf_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0320 11:46:21 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0320 11:46:21 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0320 11:46:21 @base.py:212][0m Creating the session ...
2018-03-20 11:46:21.519464: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-20 11:46:21.989044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:81:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-03-20 11:46:21.989138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:81:00.0, compute capability: 6.1)
[32m[0320 11:46:29 @base.py:220][0m Initializing the session ...
[32m[0320 11:46:29 @base.py:227][0m Graph Finalized.
[32m[0320 11:46:29 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0320 11:46:38 @monitor.py:251][0m Found existing JSON at train_log/fcn2_w_32_a_32_quant_ends_False/stat.json, will append to it.
[32m[0320 11:46:38 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0320 11:46:38 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11462/173481[03:00<42:24,63.68it/s]  7%|6         |12126/173481[03:10<42:13,63.68it/s] 13%|#3        |23161/173481[06:00<38:56,64.33it/s] 14%|#3        |23850/173481[06:10<38:46,64.33it/s] 20%|##        |34795/173481[09:00<35:51,64.47it/s] 20%|##        |35473/173481[09:10<35:40,64.47it/s] 27%|##6       |46327/173481[12:00<32:58,64.27it/s] 27%|##7       |47022/173481[12:10<32:47,64.27it/s] 34%|###3      |58355/173481[15:00<29:17,65.52it/s] 34%|###4      |59082/173481[15:10<29:06,65.52it/s] 41%|####      |70489/173481[18:00<25:49,66.45it/s] 41%|####1     |71298/173481[18:10<25:37,66.45it/s] 48%|####7     |82591/173481[21:00<22:40,66.83it/s] 48%|####8     |83310/173481[21:11<22:29,66.83it/s] 54%|#####4    |94339/173481[24:00<19:58,66.03it/s] 55%|#####4    |95112/173481[24:11<19:46,66.03it/s] 61%|######    |105265/173481[27:00<17:58,63.25it/s] 61%|######1   |105972/173481[27:11<17:47,63.25it/s] 66%|######6   |115321/173481[30:00<16:20,59.33it/s] 67%|######6   |115968/173481[30:11<16:09,59.33it/s] 73%|#######2  |126032/173481[33:00<13:18,59.41it/s] 73%|#######3  |126774/173481[33:11<13:06,59.41it/s] 79%|#######9  |137895/173481[36:00<09:29,62.49it/s] 80%|########  |139110/173481[36:11<09:10,62.49it/s] 90%|######### |156757/173481[39:00<03:33,78.29it/s] 91%|#########1|157979/173481[39:11<03:18,78.29it/s] 98%|#########7|169319/173481[42:00<00:56,73.79it/s] 98%|#########8|170076/173481[42:12<00:46,73.79it/s]100%|##########|173481/173481[43:04<00:00,67.11it/s]
[32m[0320 12:29:43 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2585.01 sec.
[32m[0320 12:29:43 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########7|18424/18822[03:00<00:03,102.35it/s]100%|##########|18822/18822[03:04<00:00,102.17it/s]
0
[32m[0320 12:32:47 @monitor.py:363][0m QueueInput/queue_size: 0.88302
[32m[0320 12:32:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.7765
[32m[0320 12:32:47 @monitor.py:363][0m activation-summaries/output-rms: 0.029569
[32m[0320 12:32:47 @monitor.py:363][0m cross_entropy_loss: 2.625
[32m[0320 12:32:47 @monitor.py:363][0m lr: 0.001
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.11049
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.62075
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.081009
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.08754
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064693
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.071792
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065454
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.071182
[32m[0320 12:32:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064027
[32m[0320 12:32:47 @monitor.py:363][0m train-error-top1: 0.63623
[32m[0320 12:32:47 @monitor.py:363][0m val-error-top1: 0.72996
[32m[0320 12:32:47 @monitor.py:363][0m val-utt-error: 0.39948
[32m[0320 12:32:47 @monitor.py:363][0m validation_cost: 3.1293
[32m[0320 12:32:47 @monitor.py:363][0m wd_cost: 0.94204
[32m[0320 12:32:47 @group.py:42][0m Callbacks took 184.920 sec in total. InferenceRunner: 184.228sec
[32m[0320 12:32:47 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12126/173481[03:00<39:55,67.37it/s]  7%|7         |12731/173481[03:10<39:46,67.37it/s] 12%|#2        |21520/173481[06:00<43:04,58.81it/s] 13%|#2        |22095/173481[06:10<42:54,58.81it/s] 19%|#8        |32218/173481[09:00<39:49,59.11it/s] 19%|#8        |32901/173481[09:10<39:38,59.11it/s] 25%|##5       |43798/173481[12:00<35:04,61.61it/s] 26%|##5       |44511/173481[12:10<34:53,61.61it/s] 32%|###2      |55738/173481[15:00<30:43,63.88it/s] 33%|###2      |56511/173481[15:10<30:31,63.88it/s] 39%|###8      |67614/173481[18:00<27:10,64.91it/s] 39%|###9      |68343/173481[18:10<26:59,64.91it/s] 46%|####5     |79726/173481[21:00<23:39,66.07it/s] 46%|####6     |80481/173481[21:11<23:27,66.07it/s] 53%|#####2    |91600/173481[24:00<20:40,66.01it/s] 53%|#####3    |92373/173481[24:11<20:28,66.01it/s] 60%|#####9    |103546/173481[27:00<17:36,66.18it/s] 60%|######    |104349/173481[27:11<17:24,66.18it/s] 67%|######6   |115486/173481[30:00<14:35,66.26it/s] 67%|######7   |116325/173481[30:11<14:22,66.26it/s] 74%|#######3  |127606/173481[33:00<11:26,66.78it/s] 74%|#######4  |128385/173481[33:11<11:15,66.78it/s] 80%|########  |139276/173481[36:00<08:39,65.79it/s] 81%|########  |140067/173481[36:11<08:27,65.79it/s] 91%|######### |157115/173481[39:00<03:26,79.08it/s] 91%|#########1|158352/173481[39:12<03:11,79.08it/s] 98%|#########8|170297/173481[42:00<00:41,76.04it/s] 99%|#########8|171087/173481[42:12<00:31,76.04it/s]100%|##########|173481/173481[42:49<00:00,67.50it/s]
[32m[0320 13:15:37 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2569.98 sec.
[32m[0320 13:15:38 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-346962.
[32m[0320 13:15:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|#########9|18755/18822[03:00<00:00,104.19it/s]100%|##########|18822/18822[03:01<00:00,103.87it/s]
1
[32m[0320 13:18:41 @monitor.py:363][0m QueueInput/queue_size: 0.25621
[32m[0320 13:18:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.777
[32m[0320 13:18:41 @monitor.py:363][0m activation-summaries/output-rms: 0.029967
[32m[0320 13:18:41 @monitor.py:363][0m cross_entropy_loss: 2.5546
[32m[0320 13:18:41 @monitor.py:363][0m lr: 0.001
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.11075
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.86824
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.080814
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.087905
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064693
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.068234
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065454
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.067747
[32m[0320 13:18:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064026
[32m[0320 13:18:41 @monitor.py:363][0m train-error-top1: 0.62261
[32m[0320 13:18:41 @monitor.py:363][0m val-error-top1: 0.73069
[32m[0320 13:18:41 @monitor.py:363][0m val-utt-error: 0.40415
[32m[0320 13:18:41 @monitor.py:363][0m validation_cost: 3.1316
[32m[0320 13:18:41 @monitor.py:363][0m wd_cost: 0.91777
[32m[0320 13:18:41 @group.py:42][0m Callbacks took 183.483 sec in total. InferenceRunner: 181.223sec
[32m[0320 13:18:41 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11479/173481[03:00<42:20,63.76it/s]  7%|6         |12120/173481[03:10<42:10,63.76it/s] 13%|#2        |22513/173481[06:00<40:15,62.50it/s] 13%|#3        |23142/173481[06:10<40:05,62.50it/s] 20%|#9        |34190/173481[09:00<36:28,63.66it/s] 20%|##        |34920/173481[09:10<36:16,63.66it/s] 26%|##6       |45589/173481[12:00<33:34,63.49it/s] 27%|##6       |46188/173481[12:10<33:24,63.49it/s] 33%|###2      |56983/173481[15:00<30:37,63.39it/s] 33%|###3      |57702/173481[15:10<30:26,63.39it/s] 40%|###9      |68933/173481[18:00<26:51,64.86it/s] 40%|####      |69663/173481[18:10<26:40,64.86it/s] 47%|####6     |80773/173481[21:00<23:39,65.31it/s] 47%|####6     |81532/173481[21:11<23:27,65.31it/s] 54%|#####3    |92944/173481[24:00<20:12,66.44it/s] 54%|#####3    |93660/173481[24:11<20:01,66.44it/s] 60%|#####9    |103639/173481[27:00<18:33,62.72it/s] 60%|######    |104243/173481[27:11<18:23,62.72it/s] 65%|######5   |113521/173481[30:00<17:04,58.55it/s] 66%|######5   |114204/173481[30:11<16:52,58.55it/s] 71%|#######1  |123607/173481[33:00<14:30,57.26it/s] 72%|#######1  |124344/173481[33:11<14:18,57.26it/s] 78%|#######8  |135511/173481[36:00<10:18,61.38it/s] 79%|#######8  |136326/173481[36:11<10:05,61.38it/s] 86%|########6 |149971/173481[39:00<05:37,69.59it/s] 87%|########7 |151214/173481[39:11<05:19,69.59it/s] 96%|#########6|167065/173481[42:00<01:19,80.32it/s] 97%|#########6|167844/173481[42:12<01:10,80.32it/s]100%|##########|173481/173481[43:36<00:00,66.30it/s]
[32m[0320 14:02:18 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2616.79 sec.
[32m[0320 14:02:18 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-520443.
  0%|          |0/18822[00:00<?,?it/s] 98%|#########8|18488/18822[03:00<00:03,102.63it/s]100%|##########|18822/18822[03:03<00:00,102.84it/s]
2
[32m[0320 14:05:21 @monitor.py:363][0m QueueInput/queue_size: 0.24287
[32m[0320 14:05:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.0023
[32m[0320 14:05:21 @monitor.py:363][0m activation-summaries/output-rms: 0.037194
[32m[0320 14:05:21 @monitor.py:363][0m cross_entropy_loss: 2.0619
[32m[0320 14:05:21 @monitor.py:363][0m lr: 0.0005
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.17225
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0126
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear0/W-rms: 0.11583
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.1227
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064693
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.094371
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065455
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.097045
[32m[0320 14:05:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 14:05:21 @monitor.py:363][0m train-error-top1: 0.52974
[32m[0320 14:05:21 @monitor.py:363][0m val-error-top1: 0.58104
[32m[0320 14:05:21 @monitor.py:363][0m val-utt-error: 0.20954
[32m[0320 14:05:21 @monitor.py:363][0m validation_cost: 2.3139
[32m[0320 14:05:21 @monitor.py:363][0m wd_cost: 0.38104
[32m[0320 14:05:21 @group.py:42][0m Callbacks took 183.676 sec in total. InferenceRunner: 183.027sec
[32m[0320 14:05:21 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12196/173481[03:00<39:40,67.75it/s]  7%|7         |12878/173481[03:10<39:30,67.75it/s] 14%|#3        |24221/173481[06:00<36:58,67.27it/s] 14%|#4        |24879/173481[06:10<36:48,67.27it/s] 21%|##        |35951/173481[09:00<34:37,66.20it/s] 21%|##1       |36501/173481[09:10<34:29,66.20it/s] 27%|##7       |47584/173481[12:00<32:05,65.40it/s] 28%|##7       |48329/173481[12:10<31:53,65.40it/s] 34%|###4      |59128/173481[15:00<29:26,64.75it/s] 35%|###4      |59924/173481[15:10<29:13,64.75it/s] 41%|####1     |71380/173481[18:00<25:38,66.36it/s] 42%|####1     |72263/173481[18:10<25:25,66.36it/s] 48%|####8     |83345/173481[21:00<22:37,66.42it/s] 48%|####8     |84069/173481[21:11<22:26,66.42it/s] 55%|#####4    |95314/173481[24:00<19:36,66.45it/s] 55%|#####5    |96063/173481[24:11<19:25,66.45it/s] 62%|######1   |107158/173481[27:00<16:43,66.12it/s] 62%|######2   |107853/173481[27:11<16:32,66.12it/s] 69%|######8   |119086/173481[30:00<13:41,66.19it/s] 69%|######9   |119841/173481[30:11<13:30,66.19it/s] 76%|#######5  |131230/173481[33:00<10:32,66.81it/s] 76%|#######6  |132008/173481[33:11<10:20,66.81it/s] 83%|########2 |143920/173481[36:00<07:10,68.60it/s] 83%|########3 |144735/173481[36:11<06:59,68.60it/s] 90%|######### |156748/173481[39:00<03:59,69.91it/s] 91%|######### |157611/173481[39:12<03:47,69.91it/s]100%|#########9|173408/173481[42:00<00:00,79.65it/s]100%|##########|173481/173481[42:01<00:00,68.81it/s]
[32m[0320 14:47:22 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2521.04 sec.
[32m[0320 14:47:23 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-693924.
[32m[0320 14:47:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 83%|########2 |15591/18822[03:00<00:37,86.61it/s] 86%|########5 |16123/18822[03:10<00:31,86.61it/s]100%|##########|18822/18822[03:46<00:00,83.08it/s]
3
[32m[0320 14:51:11 @monitor.py:363][0m QueueInput/queue_size: 0.031006
[32m[0320 14:51:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.388
[32m[0320 14:51:11 @monitor.py:363][0m activation-summaries/output-rms: 0.0387
[32m[0320 14:51:11 @monitor.py:363][0m cross_entropy_loss: 1.8633
[32m[0320 14:51:11 @monitor.py:363][0m lr: 0.0005
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.19599
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0813
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12308
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14213
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11538
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11433
[32m[0320 14:51:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 14:51:11 @monitor.py:363][0m train-error-top1: 0.47904
[32m[0320 14:51:11 @monitor.py:363][0m val-error-top1: 0.53506
[32m[0320 14:51:11 @monitor.py:363][0m val-utt-error: 0.15732
[32m[0320 14:51:11 @monitor.py:363][0m validation_cost: 2.092
[32m[0320 14:51:11 @monitor.py:363][0m wd_cost: 0.48809
[32m[0320 14:51:11 @group.py:42][0m Callbacks took 228.454 sec in total. InferenceRunner: 226.573sec
[32m[0320 14:51:11 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11788/173481[03:00<41:09,65.49it/s]  7%|7         |12510/173481[03:10<40:58,65.49it/s] 14%|#4        |24620/173481[06:00<36:20,68.26it/s] 15%|#4        |25356/173481[06:10<36:09,68.26it/s] 21%|##        |36190/173481[09:00<34:33,66.21it/s] 21%|##1       |36822/173481[09:10<34:23,66.21it/s] 27%|##7       |47065/173481[12:00<33:21,63.18it/s] 27%|##7       |47706/173481[12:10<33:10,63.18it/s] 33%|###3      |58069/173481[15:00<30:57,62.14it/s] 34%|###3      |58760/173481[15:10<30:46,62.14it/s] 40%|####      |69686/173481[18:00<27:19,63.31it/s] 41%|####      |70374/173481[18:10<27:08,63.31it/s] 47%|####6     |80719/173481[21:00<24:49,62.28it/s] 47%|####6     |81234/173481[21:11<24:41,62.28it/s] 52%|#####1    |90097/173481[24:00<24:29,56.73it/s] 52%|#####2    |90738/173481[24:11<24:18,56.73it/s] 58%|#####7    |100465/173481[27:00<21:17,57.15it/s] 58%|#####8    |101149/173481[27:11<21:05,57.15it/s] 65%|######4   |112328/173481[30:00<16:38,61.22it/s] 65%|######5   |113100/173481[30:11<16:26,61.22it/s] 72%|#######1  |124237/173481[33:00<12:54,63.59it/s] 72%|#######2  |124980/173481[33:11<12:42,63.59it/s] 79%|#######8  |136189/173481[36:00<09:34,64.96it/s] 79%|#######8  |136992/173481[36:11<09:21,64.96it/s] 85%|########4 |147447/173481[39:00<06:48,63.73it/s] 85%|########5 |148086/173481[39:12<06:38,63.73it/s] 91%|#########1|158721/173481[42:00<03:53,63.18it/s] 92%|#########1|159498/173481[42:12<03:41,63.18it/s] 98%|#########8|170707/173481[45:00<00:42,64.83it/s] 99%|#########8|171486/173481[45:12<00:30,64.83it/s]100%|##########|173481/173481[45:42<00:00,63.25it/s]
[32m[0320 15:36:54 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2742.64 sec.
[32m[0320 15:36:54 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-867405.
[32m[0320 15:36:55 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:34<00:00,121.61it/s]
4
[32m[0320 15:39:30 @monitor.py:363][0m QueueInput/queue_size: 0.34258
[32m[0320 15:39:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 10.187
[32m[0320 15:39:30 @monitor.py:363][0m activation-summaries/output-rms: 0.039601
[32m[0320 15:39:30 @monitor.py:363][0m cross_entropy_loss: 1.7755
[32m[0320 15:39:30 @monitor.py:363][0m lr: 0.0005
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.19785
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1343
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.12429
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14469
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11923
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11715
[32m[0320 15:39:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 15:39:30 @monitor.py:363][0m train-error-top1: 0.46335
[32m[0320 15:39:30 @monitor.py:363][0m val-error-top1: 0.51858
[32m[0320 15:39:30 @monitor.py:363][0m val-utt-error: 0.14743
[32m[0320 15:39:30 @monitor.py:363][0m validation_cost: 2.0132
[32m[0320 15:39:30 @monitor.py:363][0m wd_cost: 0.50465
[32m[0320 15:39:30 @group.py:42][0m Callbacks took 156.604 sec in total. InferenceRunner: 154.787sec
[32m[0320 15:39:30 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10930/173481[03:00<44:37,60.71it/s]  7%|6         |11523/173481[03:10<44:27,60.71it/s] 12%|#2        |21358/173481[06:00<42:46,59.28it/s] 13%|#2        |21939/173481[06:10<42:36,59.28it/s] 18%|#8        |31432/173481[09:00<41:07,57.57it/s] 18%|#8        |31975/173481[09:10<40:58,57.57it/s] 24%|##3       |41548/173481[12:00<38:39,56.87it/s] 24%|##4       |42161/173481[12:10<38:29,56.87it/s] 30%|##9       |51543/173481[15:00<36:10,56.19it/s] 30%|###       |52137/173481[15:10<35:59,56.19it/s] 35%|###5      |61462/173481[18:00<33:33,55.63it/s] 36%|###5      |62055/173481[18:10<33:22,55.63it/s] 41%|####1     |71531/173481[21:00<30:27,55.78it/s] 42%|####1     |72129/173481[21:11<30:16,55.78it/s] 47%|####6     |81358/173481[24:00<27:49,55.18it/s] 47%|####7     |81981/173481[24:11<27:38,55.18it/s] 53%|#####2    |91327/173481[27:00<24:46,55.28it/s] 53%|#####3    |91953/173481[27:11<24:34,55.28it/s] 58%|#####8    |101326/173481[30:00<21:42,55.41it/s] 59%|#####8    |101967/173481[30:11<21:30,55.41it/s] 64%|######4   |111316/173481[33:00<18:41,55.44it/s] 65%|######4   |111921/173481[33:11<18:30,55.44it/s] 70%|#######   |122104/173481[36:00<14:52,57.59it/s] 71%|#######   |122841/173481[36:11<14:39,57.59it/s] 77%|#######7  |133888/173481[39:00<10:46,61.27it/s] 78%|#######7  |134601/173481[39:12<10:34,61.27it/s] 83%|########3 |144118/173481[42:00<08:17,58.96it/s] 83%|########3 |144777/173481[42:12<08:06,58.96it/s] 89%|########8 |154039/173481[45:00<05:41,56.97it/s] 89%|########9 |154689/173481[45:12<05:29,56.97it/s] 95%|#########4|164080/173481[48:00<02:46,56.37it/s] 95%|#########4|164763/173481[48:12<02:34,56.37it/s]100%|##########|173481/173481[50:54<00:00,56.80it/s]
[32m[0320 16:30:25 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:3054.47 sec.
[32m[0320 16:30:25 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-1040886.
[32m[0320 16:30:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,199.38it/s]
5
[32m[0320 16:32:01 @monitor.py:363][0m QueueInput/queue_size: 0.3103
[32m[0320 16:32:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 18.265
[32m[0320 16:32:01 @monitor.py:363][0m activation-summaries/output-rms: 0.045155
[32m[0320 16:32:01 @monitor.py:363][0m cross_entropy_loss: 1.3989
[32m[0320 16:32:01 @monitor.py:363][0m lr: 0.00025
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.2591
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1633
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.16144
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.17525
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.1405
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.13794
[32m[0320 16:32:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 16:32:01 @monitor.py:363][0m train-error-top1: 0.37639
[32m[0320 16:32:01 @monitor.py:363][0m val-error-top1: 0.42171
[32m[0320 16:32:01 @monitor.py:363][0m val-utt-error: 0.08336
[32m[0320 16:32:01 @monitor.py:363][0m validation_cost: 1.5817
[32m[0320 16:32:01 @monitor.py:363][0m wd_cost: 0.15764
[32m[0320 16:32:01 @group.py:42][0m Callbacks took 96.298 sec in total. InferenceRunner: 94.410sec
[32m[0320 16:32:01 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10771/173481[03:00<45:19,59.82it/s]  7%|6         |11376/173481[03:10<45:09,59.82it/s] 12%|#2        |20995/173481[06:00<43:37,58.26it/s] 12%|#2        |21612/173481[06:10<43:26,58.26it/s] 18%|#8        |31519/173481[09:00<40:32,58.35it/s] 19%|#8        |32118/173481[09:10<40:22,58.35it/s] 24%|##3       |41599/173481[12:00<38:27,57.14it/s] 24%|##4       |42192/173481[12:10<38:17,57.14it/s] 30%|##9       |51667/173481[15:00<35:55,56.52it/s] 30%|###       |52236/173481[15:10<35:45,56.52it/s] 36%|###5      |61615/173481[18:00<33:22,55.88it/s] 36%|###5      |62157/173481[18:10<33:12,55.88it/s] 41%|####1     |71629/173481[21:00<30:27,55.75it/s] 42%|####1     |72216/173481[21:11<30:16,55.75it/s] 47%|####7     |81733/173481[24:00<27:20,55.93it/s] 47%|####7     |82326/173481[24:11<27:09,55.93it/s] 53%|#####2    |91279/173481[27:00<25:10,54.43it/s] 53%|#####2    |91887/173481[27:11<24:59,54.43it/s] 58%|#####8    |100711/173481[30:00<22:42,53.39it/s] 58%|#####8    |101298/173481[30:11<22:31,53.39it/s] 64%|######3   |110341/173481[33:00<19:41,53.44it/s] 64%|######3   |110940/173481[33:11<19:30,53.44it/s] 69%|######9   |120127/173481[36:00<16:30,53.89it/s] 70%|######9   |120696/173481[36:11<16:19,53.89it/s] 75%|#######4  |129811/173481[39:00<13:31,53.84it/s] 75%|#######5  |130380/173481[39:11<13:20,53.84it/s] 80%|########  |139357/173481[42:00<10:38,53.43it/s] 81%|########  |139969/173481[42:12<10:27,53.43it/s] 86%|########5 |149017/173481[45:00<07:36,53.54it/s] 86%|########6 |149652/173481[45:12<07:25,53.54it/s] 92%|#########1|158867/173481[48:00<04:30,54.13it/s] 92%|#########1|159498/173481[48:12<04:18,54.13it/s] 97%|#########7|168691/173481[51:00<01:28,54.35it/s] 98%|#########7|169350/173481[51:12<01:16,54.35it/s]100%|##########|173481/173481[52:28<00:00,55.10it/s]
[32m[0320 17:24:30 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:3148.57 sec.
[32m[0320 17:24:31 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-1214367.
[32m[0320 17:24:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,183.13it/s]
6
[32m[0320 17:26:15 @monitor.py:363][0m QueueInput/queue_size: 0.46095
[32m[0320 17:26:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 26.335
[32m[0320 17:26:15 @monitor.py:363][0m activation-summaries/output-rms: 0.045659
[32m[0320 17:26:15 @monitor.py:363][0m cross_entropy_loss: 1.3774
[32m[0320 17:26:15 @monitor.py:363][0m lr: 0.00025
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.32782
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1767
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.184
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20816
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.16526
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16251
[32m[0320 17:26:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 17:26:15 @monitor.py:363][0m train-error-top1: 0.36691
[32m[0320 17:26:15 @monitor.py:363][0m val-error-top1: 0.40013
[32m[0320 17:26:15 @monitor.py:363][0m val-utt-error: 0.07029
[32m[0320 17:26:15 @monitor.py:363][0m validation_cost: 1.4887
[32m[0320 17:26:15 @monitor.py:363][0m wd_cost: 0.22211
[32m[0320 17:26:15 @group.py:42][0m Callbacks took 105.235 sec in total. InferenceRunner: 102.788sec
[32m[0320 17:26:15 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10138/173481[03:00<48:20,56.32it/s]  6%|6         |10695/173481[03:10<48:10,56.32it/s] 11%|#1        |19282/173481[06:00<48:06,53.41it/s] 11%|#1        |19833/173481[06:10<47:56,53.41it/s] 16%|#6        |28618/173481[09:00<45:52,52.62it/s] 17%|#6        |29169/173481[09:10<45:42,52.62it/s] 22%|##1       |37942/173481[12:00<43:16,52.20it/s] 22%|##2       |38433/173481[12:10<43:06,52.20it/s] 27%|##6       |46408/173481[15:00<42:48,49.48it/s] 27%|##7       |46965/173481[15:10<42:36,49.48it/s] 32%|###2      |55677/173481[18:00<38:54,50.47it/s] 32%|###2      |56235/173481[18:10<38:43,50.47it/s] 37%|###7      |64270/173481[21:00<37:06,49.05it/s] 37%|###7      |64798/173481[21:11<36:55,49.05it/s] 42%|####2     |73056/173481[24:00<34:12,48.93it/s] 42%|####2     |73581/173481[24:11<34:01,48.93it/s] 47%|####6     |81202/173481[27:00<32:42,47.01it/s] 47%|####7     |81711/173481[27:11<32:32,47.01it/s] 52%|#####1    |89458/173481[30:00<30:10,46.42it/s] 52%|#####1    |89933/173481[30:11<29:59,46.42it/s] 57%|#####6    |98028/173481[33:00<26:45,47.01it/s] 57%|#####6    |98578/173481[33:11<26:33,47.01it/s] 62%|######1   |107338/173481[36:00<22:23,49.24it/s] 62%|######2   |107913/173481[36:11<22:11,49.24it/s] 67%|######7   |116390/173481[39:00<19:07,49.76it/s] 67%|######7   |116991/173481[39:11<18:55,49.76it/s] 72%|#######2  |125752/173481[42:00<15:38,50.85it/s] 73%|#######2  |126231/173481[42:12<15:29,50.85it/s] 78%|#######7  |134770/173481[45:00<12:47,50.47it/s] 78%|#######8  |135387/173481[45:12<12:34,50.47it/s] 83%|########3 |144136/173481[48:00<09:32,51.24it/s] 83%|########3 |144711/173481[48:12<09:21,51.24it/s] 88%|########8 |153218/173481[51:00<06:38,50.84it/s] 89%|########8 |153838/173481[51:12<06:26,50.84it/s] 94%|#########3|162736/173481[54:00<03:27,51.83it/s] 94%|#########4|163389/173481[54:12<03:14,51.83it/s] 99%|#########9|172288/173481[57:00<00:22,52.43it/s]100%|#########9|172925/173481[57:12<00:10,52.43it/s]100%|##########|173481/173481[57:23<00:00,50.38it/s]
[32m[0320 18:23:38 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:3443.44 sec.
[32m[0320 18:23:39 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-1387848.
[32m[0320 18:23:40 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.78it/s]
7
[32m[0320 18:25:37 @monitor.py:363][0m QueueInput/queue_size: 0.43405
[32m[0320 18:25:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.634
[32m[0320 18:25:37 @monitor.py:363][0m activation-summaries/output-rms: 0.045793
[32m[0320 18:25:37 @monitor.py:363][0m cross_entropy_loss: 1.2601
[32m[0320 18:25:37 @monitor.py:363][0m lr: 0.00025
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.36584
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1914
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.18955
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.22107
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.17535
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.17201
[32m[0320 18:25:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 18:25:37 @monitor.py:363][0m train-error-top1: 0.3482
[32m[0320 18:25:37 @monitor.py:363][0m val-error-top1: 0.39138
[32m[0320 18:25:37 @monitor.py:363][0m val-utt-error: 0.067793
[32m[0320 18:25:37 @monitor.py:363][0m validation_cost: 1.4493
[32m[0320 18:25:37 @monitor.py:363][0m wd_cost: 0.2522
[32m[0320 18:25:37 @group.py:42][0m Callbacks took 118.990 sec in total. InferenceRunner: 117.079sec
[32m[0320 18:25:37 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10181/173481[03:00<48:07,56.56it/s]  6%|6         |10722/173481[03:10<47:57,56.56it/s] 11%|#1        |19346/173481[06:00<47:56,53.59it/s] 11%|#1        |19884/173481[06:10<47:46,53.59it/s] 16%|#6        |28189/173481[09:00<47:14,51.25it/s] 17%|#6        |28740/173481[09:10<47:04,51.25it/s] 22%|##1       |37567/173481[12:00<43:50,51.66it/s] 22%|##1       |38078/173481[12:10<43:40,51.66it/s] 27%|##7       |47057/173481[15:00<40:22,52.19it/s] 27%|##7       |47701/173481[15:10<40:10,52.19it/s] 33%|###2      |56682/173481[18:00<36:51,52.82it/s] 33%|###3      |57269/173481[18:10<36:40,52.82it/s] 38%|###8      |66265/173481[21:00<33:42,53.02it/s] 39%|###8      |66845/173481[21:11<33:31,53.02it/s] 44%|####3     |75543/173481[24:00<31:13,52.27it/s] 44%|####3     |76145/173481[24:11<31:02,52.27it/s] 49%|####9     |85399/173481[27:00<27:27,53.47it/s] 50%|####9     |86004/173481[27:11<27:15,53.47it/s] 55%|#####4    |94723/173481[30:00<24:56,52.62it/s] 55%|#####4    |95322/173481[30:11<24:45,52.62it/s] 60%|#####9    |103813/173481[33:00<22:31,51.54it/s] 60%|######    |104348/173481[33:11<22:21,51.54it/s] 65%|######4   |111896/173481[36:00<21:23,47.99it/s] 65%|######4   |112419/173481[36:11<21:12,47.99it/s] 70%|######9   |121309/173481[39:00<17:22,50.05it/s] 70%|#######   |121936/173481[39:11<17:09,50.05it/s] 76%|#######5  |131533/173481[42:00<13:08,53.20it/s] 76%|#######6  |132145/173481[42:12<12:56,53.20it/s] 81%|########1 |141193/173481[45:00<10:04,53.43it/s] 82%|########1 |141834/173481[45:12<09:52,53.43it/s] 87%|########7 |150937/173481[48:00<06:59,53.77it/s] 87%|########7 |151590/173481[48:12<06:47,53.77it/s] 93%|#########2|161011/173481[51:00<03:47,54.84it/s] 93%|#########3|161677/173481[51:12<03:35,54.84it/s] 99%|#########8|171331/173481[54:00<00:38,56.05it/s] 99%|#########9|172038/173481[54:12<00:25,56.05it/s]100%|##########|173481/173481[54:38<00:00,52.92it/s]
[32m[0320 19:20:15 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:3278.17 sec.
[32m[0320 19:20:16 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-1561329.
[32m[0320 19:20:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.37it/s]
8
[32m[0320 19:21:55 @monitor.py:363][0m QueueInput/queue_size: 0.18498
[32m[0320 19:21:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.776
[32m[0320 19:21:55 @monitor.py:363][0m activation-summaries/output-rms: 0.047576
[32m[0320 19:21:55 @monitor.py:363][0m cross_entropy_loss: 1.1885
[32m[0320 19:21:55 @monitor.py:363][0m lr: 0.000125
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.41895
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1983
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.20993
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.23228
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.18274
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.17931
[32m[0320 19:21:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 19:21:55 @monitor.py:363][0m train-error-top1: 0.33036
[32m[0320 19:21:55 @monitor.py:363][0m val-error-top1: 0.34762
[32m[0320 19:21:55 @monitor.py:363][0m val-utt-error: 0.049729
[32m[0320 19:21:55 @monitor.py:363][0m validation_cost: 1.2696
[32m[0320 19:21:55 @monitor.py:363][0m wd_cost: 0.060098
[32m[0320 19:21:55 @group.py:42][0m Callbacks took 100.005 sec in total. InferenceRunner: 97.349sec
[32m[0320 19:21:55 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10654/173481[03:00<45:52,59.17it/s]  6%|6         |11236/173481[03:10<45:42,59.17it/s] 12%|#1        |20506/173481[06:00<44:50,56.86it/s] 12%|#2        |20997/173481[06:10<44:41,56.86it/s] 17%|#7        |30232/173481[09:00<43:05,55.41it/s] 18%|#7        |30831/173481[09:10<42:54,55.41it/s] 23%|##3       |40128/173481[12:00<40:16,55.19it/s] 23%|##3       |40713/173481[12:10<40:05,55.19it/s] 29%|##8       |50152/173481[15:00<37:05,55.43it/s] 29%|##9       |50763/173481[15:10<36:54,55.43it/s] 35%|###4      |60460/173481[18:00<33:26,56.33it/s] 35%|###5      |61077/173481[18:10<33:15,56.33it/s] 41%|####      |70960/173481[21:00<29:48,57.31it/s] 41%|####1     |71625/173481[21:11<29:37,57.31it/s] 47%|####6     |81124/173481[24:00<27:03,56.88it/s] 47%|####7     |81753/173481[24:11<26:52,56.88it/s] 53%|#####2    |91481/173481[27:00<23:53,57.20it/s] 53%|#####3    |92117/173481[27:11<23:42,57.20it/s] 59%|#####8    |101896/173481[30:00<20:44,57.53it/s] 59%|#####9    |102549/173481[30:11<20:32,57.53it/s] 65%|######4   |112228/173481[33:00<17:46,57.46it/s] 65%|######5   |112881/173481[33:11<17:34,57.46it/s] 70%|#######   |122078/173481[36:00<15:16,56.06it/s] 71%|#######   |122667/173481[36:11<15:06,56.06it/s] 76%|#######5  |131284/173481[39:00<13:08,53.48it/s] 76%|#######5  |131822/173481[39:12<12:58,53.48it/s] 81%|########1 |140765/173481[42:00<10:16,53.07it/s] 82%|########1 |141399/173481[42:12<10:04,53.07it/s] 87%|########6 |150202/173481[45:00<07:21,52.74it/s] 87%|########6 |150885/173481[45:12<07:08,52.74it/s] 93%|#########2|160610/173481[48:00<03:53,55.17it/s] 93%|#########2|161316/173481[48:12<03:40,55.17it/s] 98%|#########8|170644/173481[51:00<00:51,55.44it/s] 99%|#########8|171309/173481[51:12<00:39,55.44it/s][32m[0320 20:13:47 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:3111.62 sec.
100%|##########|173481/173481[51:51<00:00,55.75it/s]
[32m[0320 20:13:48 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-1734810.
[32m[0320 20:13:50 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.81it/s]
9
[32m[0320 20:15:27 @monitor.py:363][0m QueueInput/queue_size: 0.35089
[32m[0320 20:15:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.505
[32m[0320 20:15:27 @monitor.py:363][0m activation-summaries/output-rms: 0.047125
[32m[0320 20:15:27 @monitor.py:363][0m cross_entropy_loss: 1.1811
[32m[0320 20:15:27 @monitor.py:363][0m lr: 0.000125
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.47691
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2026
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.23255
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2477
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19299
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18957
[32m[0320 20:15:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 20:15:27 @monitor.py:363][0m train-error-top1: 0.32726
[32m[0320 20:15:27 @monitor.py:363][0m val-error-top1: 0.34205
[32m[0320 20:15:27 @monitor.py:363][0m val-utt-error: 0.046807
[32m[0320 20:15:27 @monitor.py:363][0m validation_cost: 1.2479
[32m[0320 20:15:27 @monitor.py:363][0m wd_cost: 0.072527
[32m[0320 20:15:27 @group.py:42][0m Callbacks took 99.870 sec in total. InferenceRunner: 97.128sec
[32m[0320 20:15:27 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11287/173481[03:00<43:07,62.69it/s]  7%|6         |11874/173481[03:10<42:57,62.69it/s] 12%|#2        |21469/173481[06:00<42:36,59.46it/s] 13%|#2        |22028/173481[06:10<42:27,59.46it/s] 18%|#8        |31831/173481[09:00<40:21,58.50it/s] 19%|#8        |32418/173481[09:10<40:11,58.50it/s] 24%|##4       |41947/173481[12:00<38:15,57.31it/s] 25%|##4       |42564/173481[12:10<38:04,57.31it/s] 30%|###       |52447/173481[15:00<34:53,57.81it/s] 31%|###       |53058/173481[15:10<34:43,57.81it/s] 36%|###6      |62641/173481[18:00<32:17,57.21it/s] 36%|###6      |63250/173481[18:10<32:06,57.21it/s] 42%|####2     |72931/173481[21:00<29:18,57.19it/s] 42%|####2     |73542/173481[21:11<29:07,57.19it/s] 48%|####7     |83089/173481[24:00<26:31,56.80it/s] 48%|####8     |83700/173481[24:11<26:20,56.80it/s] 54%|#####3    |93305/173481[27:00<23:32,56.78it/s] 54%|#####4    |93954/173481[27:11<23:20,56.78it/s] 60%|#####9    |103711/173481[30:00<20:18,57.28it/s] 60%|######    |104382/173481[30:11<20:06,57.28it/s] 66%|######5   |114007/173481[33:00<17:19,57.24it/s] 66%|######6   |114534/173481[33:11<17:09,57.24it/s] 72%|#######1  |124861/173481[36:00<13:47,58.72it/s] 72%|#######2  |125611/173481[36:11<13:35,58.72it/s] 79%|#######8  |137032/173481[39:00<09:39,62.86it/s] 79%|#######9  |137862/173481[39:12<09:26,62.86it/s] 85%|########5 |148009/173481[42:00<06:51,61.90it/s] 86%|########5 |148728/173481[42:12<06:39,61.90it/s] 92%|#########1|159349/173481[45:00<03:46,62.44it/s] 92%|#########2|160056/173481[45:12<03:35,62.44it/s] 98%|#########8|170785/173481[48:00<00:42,62.98it/s] 99%|#########8|171474/173481[48:12<00:31,62.98it/s]100%|##########|173481/173481[48:41<00:00,59.39it/s]
[32m[0320 21:04:08 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:2921.23 sec.
[32m[0320 21:04:09 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-1908291.
[32m[0320 21:04:11 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:21<00:00,231.33it/s]
10
[32m[0320 21:05:32 @monitor.py:363][0m QueueInput/queue_size: 0.08039
[32m[0320 21:05:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 53.486
[32m[0320 21:05:32 @monitor.py:363][0m activation-summaries/output-rms: 0.04819
[32m[0320 21:05:32 @monitor.py:363][0m cross_entropy_loss: 1.1403
[32m[0320 21:05:32 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.52571
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.205
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.24569
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.25911
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20073
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19732
[32m[0320 21:05:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 21:05:32 @monitor.py:363][0m train-error-top1: 0.318
[32m[0320 21:05:32 @monitor.py:363][0m val-error-top1: 0.32407
[32m[0320 21:05:32 @monitor.py:363][0m val-utt-error: 0.039528
[32m[0320 21:05:32 @monitor.py:363][0m validation_cost: 1.1737
[32m[0320 21:05:32 @monitor.py:363][0m wd_cost: 0.082497
[32m[0320 21:05:32 @group.py:42][0m Callbacks took 83.877 sec in total. InferenceRunner: 81.379sec
[32m[0320 21:05:32 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12070/173481[03:00<40:07,67.04it/s]  7%|7         |12771/173481[03:10<39:57,67.04it/s] 17%|#7        |29918/173481[06:00<29:54,79.99it/s] 18%|#7        |31023/173481[06:10<29:40,79.99it/s] 28%|##8       |48836/173481[09:00<22:52,90.84it/s] 29%|##8       |49891/173481[09:10<22:40,90.84it/s] 38%|###7      |65057/173481[12:00<19:58,90.48it/s] 38%|###7      |65829/173481[12:10<19:49,90.48it/s] 45%|####5     |78070/173481[15:00<19:47,80.37it/s] 45%|####5     |78795/173481[15:10<19:38,80.37it/s] 53%|#####2    |91468/173481[18:00<17:41,77.28it/s] 53%|#####3    |92038/173481[18:10<17:33,77.28it/s] 59%|#####9    |103080/173481[21:00<16:41,70.32it/s] 60%|#####9    |103743/173481[21:11<16:31,70.32it/s] 65%|######4   |112731/173481[24:00<16:38,60.84it/s] 65%|######5   |113337/173481[24:11<16:28,60.84it/s] 70%|#######   |122284/173481[27:00<15:03,56.68it/s] 71%|#######   |122841/173481[27:11<14:53,56.68it/s] 76%|#######6  |132058/173481[30:00<12:26,55.46it/s] 77%|#######6  |132722/173481[30:11<12:14,55.46it/s] 82%|########1 |142147/173481[33:00<09:21,55.76it/s] 82%|########2 |142815/173481[33:11<09:10,55.76it/s] 88%|########7 |152410/173481[36:00<06:13,56.37it/s] 88%|########8 |153050/173481[36:11<06:02,56.37it/s] 94%|#########3|162662/173481[39:00<03:10,56.66it/s] 94%|#########4|163311/173481[39:12<02:59,56.66it/s] 99%|#########9|172540/173481[42:00<00:16,55.76it/s]100%|#########9|173157/173481[42:12<00:05,55.76it/s][32m[0320 21:47:50 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:2537.75 sec.
100%|##########|173481/173481[42:17<00:00,68.36it/s]
[32m[0320 21:47:50 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-2081772.
[32m[0320 21:47:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.12it/s]
11
[32m[0320 21:49:45 @monitor.py:363][0m QueueInput/queue_size: 0.36491
[32m[0320 21:49:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 59.953
[32m[0320 21:49:45 @monitor.py:363][0m activation-summaries/output-rms: 0.049864
[32m[0320 21:49:45 @monitor.py:363][0m cross_entropy_loss: 1.0305
[32m[0320 21:49:45 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56066
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2072
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.25652
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26349
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20358
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20022
[32m[0320 21:49:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 21:49:45 @monitor.py:363][0m train-error-top1: 0.28833
[32m[0320 21:49:45 @monitor.py:363][0m val-error-top1: 0.31748
[32m[0320 21:49:45 @monitor.py:363][0m val-utt-error: 0.039847
[32m[0320 21:49:45 @monitor.py:363][0m validation_cost: 1.1494
[32m[0320 21:49:45 @monitor.py:363][0m wd_cost: 0.017906
[32m[0320 21:49:45 @group.py:42][0m Callbacks took 114.930 sec in total. InferenceRunner: 112.642sec
[32m[0320 21:49:45 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12721/173481[03:00<37:55,70.64it/s]  8%|7         |13233/173481[03:10<37:48,70.64it/s] 13%|#2        |22231/173481[06:00<41:42,60.45it/s] 13%|#3        |22798/173481[06:10<41:32,60.45it/s] 19%|#8        |32835/173481[09:00<39:17,59.67it/s] 19%|#9        |33450/173481[09:10<39:06,59.67it/s] 25%|##4       |43141/173481[12:00<37:11,58.42it/s] 25%|##5       |43710/173481[12:10<37:01,58.42it/s] 31%|###       |53077/173481[15:00<35:21,56.76it/s] 31%|###       |53695/173481[15:10<35:10,56.76it/s] 37%|###6      |63379/173481[18:00<32:11,56.99it/s] 37%|###6      |63967/173481[18:10<32:01,56.99it/s] 43%|####2     |73789/173481[21:00<28:56,57.41it/s] 43%|####2     |74397/173481[21:11<28:45,57.41it/s] 48%|####8     |83989/173481[24:00<26:09,57.03it/s] 49%|####8     |84540/173481[24:11<25:59,57.03it/s] 54%|#####4    |93743/173481[27:00<23:54,55.57it/s] 54%|#####4    |94368/173481[27:11<23:43,55.57it/s] 60%|#####9    |103724/173481[30:00<20:56,55.51it/s] 60%|######    |104292/173481[30:11<20:46,55.51it/s] 65%|######5   |113287/173481[33:00<18:28,54.28it/s] 66%|######5   |113874/173481[33:11<18:18,54.28it/s] 71%|#######   |122911/173481[36:00<15:38,53.86it/s] 71%|#######1  |123498/173481[36:11<15:27,53.86it/s] 76%|#######6  |132061/173481[39:00<13:12,52.29it/s] 76%|#######6  |132666/173481[39:11<13:00,52.29it/s] 81%|########1 |141085/173481[42:00<10:32,51.18it/s] 82%|########1 |141689/173481[42:12<10:21,51.18it/s] 87%|########6 |150555/173481[45:00<07:21,51.89it/s] 87%|########7 |151260/173481[45:12<07:08,51.89it/s] 91%|#########1|158599/173481[48:00<05:09,48.01it/s] 92%|#########1|159168/173481[48:12<04:58,48.01it/s] 96%|#########6|166796/173481[51:00<02:23,46.74it/s] 96%|#########6|167394/173481[51:12<02:10,46.74it/s]100%|##########|173481/173481[53:22<00:00,54.17it/s]
[32m[0320 22:43:07 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3202.56 sec.
[32m[0320 22:43:08 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-2255253.
[32m[0320 22:43:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,187.35it/s]
12
[32m[0320 22:44:50 @monitor.py:363][0m QueueInput/queue_size: 0.21757
[32m[0320 22:44:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 63.905
[32m[0320 22:44:50 @monitor.py:363][0m activation-summaries/output-rms: 0.04889
[32m[0320 22:44:50 @monitor.py:363][0m cross_entropy_loss: 1.1105
[32m[0320 22:44:50 @monitor.py:363][0m lr: 6.25e-05
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59541
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2093
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.26684
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26825
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20668
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20338
[32m[0320 22:44:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 22:44:50 @monitor.py:363][0m train-error-top1: 0.3052
[32m[0320 22:44:50 @monitor.py:363][0m val-error-top1: 0.31367
[32m[0320 22:44:50 @monitor.py:363][0m val-utt-error: 0.037881
[32m[0320 22:44:50 @monitor.py:363][0m validation_cost: 1.1349
[32m[0320 22:44:50 @monitor.py:363][0m wd_cost: 0.019373
[32m[0320 22:44:50 @group.py:42][0m Callbacks took 102.881 sec in total. InferenceRunner: 100.473sec
[32m[0320 22:44:50 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9922/173481[03:00<49:28,55.10it/s]  6%|6         |10467/173481[03:10<49:18,55.10it/s] 11%|#1        |19246/173481[06:00<48:08,53.39it/s] 11%|#1        |19806/173481[06:10<47:58,53.39it/s] 17%|#6        |28780/173481[09:00<45:21,53.18it/s] 17%|#6        |29361/173481[09:10<45:10,53.18it/s] 22%|##1       |38161/173481[12:00<42:50,52.64it/s] 22%|##2       |38716/173481[12:10<42:40,52.64it/s] 28%|##7       |47729/173481[15:00<39:37,52.90it/s] 28%|##7       |48317/173481[15:10<39:26,52.90it/s] 33%|###2      |57124/173481[18:00<36:54,52.54it/s] 33%|###3      |57693/173481[18:10<36:43,52.54it/s] 39%|###8      |66820/173481[21:00<33:25,53.19it/s] 39%|###8      |67359/173481[21:11<33:15,53.19it/s] 44%|####3     |76210/173481[24:00<30:46,52.67it/s] 44%|####4     |76761/173481[24:11<30:36,52.67it/s] 49%|####9     |85432/173481[27:00<28:15,51.93it/s] 50%|####9     |86007/173481[27:11<28:04,51.93it/s] 55%|#####4    |94792/173481[30:00<25:14,51.96it/s] 55%|#####4    |95387/173481[30:11<25:02,51.96it/s] 60%|######    |104482/173481[33:00<21:45,52.87it/s] 61%|######    |105087/173481[33:11<21:33,52.87it/s] 65%|######5   |113584/173481[36:00<19:18,51.68it/s] 66%|######5   |114178/173481[36:11<19:07,51.68it/s] 71%|#######   |123148/173481[39:00<16:00,52.39it/s] 71%|#######1  |123747/173481[39:11<15:49,52.39it/s] 77%|#######6  |132788/173481[42:00<12:48,52.97it/s] 77%|#######6  |133390/173481[42:12<12:36,52.97it/s] 82%|########2 |142312/173481[45:00<09:48,52.94it/s] 82%|########2 |142929/173481[45:12<09:37,52.94it/s] 88%|########7 |151930/173481[48:00<06:45,53.18it/s] 88%|########7 |152559/173481[48:12<06:33,53.18it/s] 93%|#########3|161610/173481[51:00<03:41,53.47it/s] 94%|#########3|162273/173481[51:12<03:29,53.47it/s] 99%|#########8|171340/173481[54:00<00:39,53.76it/s] 99%|#########9|171951/173481[54:12<00:28,53.76it/s]100%|##########|173481/173481[54:42<00:00,52.86it/s]
[32m[0320 23:39:32 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:3282.10 sec.
[32m[0320 23:39:33 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-2428734.
[32m[0320 23:39:34 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:27<00:00,214.70it/s]
13
[32m[0320 23:41:02 @monitor.py:363][0m QueueInput/queue_size: 0.20421
[32m[0320 23:41:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 68.502
[32m[0320 23:41:02 @monitor.py:363][0m activation-summaries/output-rms: 0.048977
[32m[0320 23:41:02 @monitor.py:363][0m cross_entropy_loss: 0.99421
[32m[0320 23:41:02 @monitor.py:363][0m lr: 3.125e-05
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62345
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2101
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27399
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27154
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20881
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20557
[32m[0320 23:41:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0320 23:41:02 @monitor.py:363][0m train-error-top1: 0.28418
[32m[0320 23:41:02 @monitor.py:363][0m val-error-top1: 0.30689
[32m[0320 23:41:02 @monitor.py:363][0m val-utt-error: 0.036287
[32m[0320 23:41:02 @monitor.py:363][0m validation_cost: 1.1079
[32m[0320 23:41:02 @monitor.py:363][0m wd_cost: 0.0041065
[32m[0320 23:41:02 @group.py:42][0m Callbacks took 89.903 sec in total. InferenceRunner: 87.678sec
[32m[0320 23:41:02 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10064/173481[03:00<48:42,55.91it/s]  6%|6         |10632/173481[03:10<48:32,55.91it/s] 11%|#         |19036/173481[06:00<48:50,52.70it/s] 11%|#1        |19566/173481[06:10<48:40,52.70it/s] 16%|#6        |28051/173481[09:00<47:11,51.36it/s] 17%|#6        |28638/173481[09:10<47:00,51.36it/s] 22%|##1       |37575/173481[12:00<43:27,52.12it/s] 22%|##1       |38106/173481[12:10<43:17,52.12it/s] 27%|##7       |46921/173481[15:00<40:33,52.01it/s] 27%|##7       |47448/173481[15:10<40:23,52.01it/s] 32%|###2      |56317/173481[18:00<37:28,52.10it/s] 33%|###2      |56893/173481[18:10<37:17,52.10it/s] 38%|###8      |66085/173481[21:00<33:40,53.15it/s] 38%|###8      |66684/173481[21:11<33:29,53.15it/s] 43%|####3     |75187/173481[24:00<31:36,51.82it/s] 44%|####3     |75779/173481[24:11<31:25,51.82it/s] 49%|####8     |84985/173481[27:00<27:46,53.09it/s] 49%|####9     |85482/173481[27:11<27:37,53.09it/s] 54%|#####4    |93984/173481[30:00<25:43,51.50it/s] 55%|#####4    |94566/173481[30:11<25:32,51.50it/s] 59%|#####9    |102591/173481[33:00<23:49,49.59it/s] 59%|#####9    |103146/173481[33:11<23:38,49.59it/s] 64%|######4   |111631/173481[36:00<20:39,49.89it/s] 65%|######4   |112232/173481[36:11<20:27,49.89it/s] 70%|######9   |120656/173481[39:00<17:36,50.01it/s] 70%|######9   |121204/173481[39:11<17:25,50.01it/s] 75%|#######4  |129325/173481[42:00<14:59,49.06it/s] 75%|#######4  |129902/173481[42:12<14:48,49.06it/s] 79%|#######9  |137887/173481[45:00<12:17,48.29it/s] 80%|#######9  |138480/173481[45:12<12:04,48.29it/s] 85%|########4 |147223/173481[48:00<08:45,50.01it/s] 85%|########5 |147864/173481[48:12<08:32,50.01it/s] 90%|######### |156913/173481[51:00<05:19,51.85it/s] 91%|######### |157554/173481[51:12<05:07,51.85it/s] 96%|#########5|166368/173481[54:00<02:16,52.19it/s] 96%|#########6|166944/173481[54:12<02:05,52.19it/s]100%|##########|173481/173481[55:59<00:00,51.64it/s]
[32m[0321 00:37:02 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3359.48 sec.
[32m[0321 00:37:02 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-2602215.
[32m[0321 00:37:04 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:18<00:00,240.42it/s]
14
[32m[0321 00:38:22 @monitor.py:363][0m QueueInput/queue_size: 0.21096
[32m[0321 00:38:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 71.39
[32m[0321 00:38:22 @monitor.py:363][0m activation-summaries/output-rms: 0.049266
[32m[0321 00:38:22 @monitor.py:363][0m cross_entropy_loss: 1.045
[32m[0321 00:38:22 @monitor.py:363][0m lr: 3.125e-05
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.64238
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2102
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27843
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27287
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20966
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20648
[32m[0321 00:38:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 00:38:22 @monitor.py:363][0m train-error-top1: 0.29489
[32m[0321 00:38:22 @monitor.py:363][0m val-error-top1: 0.30382
[32m[0321 00:38:22 @monitor.py:363][0m val-utt-error: 0.034003
[32m[0321 00:38:22 @monitor.py:363][0m validation_cost: 1.0954
[32m[0321 00:38:22 @monitor.py:363][0m wd_cost: 0.0042565
[32m[0321 00:38:22 @group.py:42][0m Callbacks took 80.566 sec in total. InferenceRunner: 78.297sec
[32m[0321 00:38:22 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9898/173481[03:00<49:35,54.98it/s]  6%|5         |10396/173481[03:10<49:26,54.98it/s] 11%|#         |18978/173481[06:00<48:56,52.61it/s] 11%|#1        |19515/173481[06:10<48:46,52.61it/s] 16%|#6        |28342/173481[09:00<46:14,52.31it/s] 17%|#6        |28923/173481[09:10<46:03,52.31it/s] 22%|##1       |38086/173481[12:00<42:24,53.20it/s] 22%|##2       |38632/173481[12:10<42:14,53.20it/s] 27%|##7       |47471/173481[15:00<39:52,52.66it/s] 28%|##7       |47901/173481[15:10<39:44,52.66it/s] 32%|###2      |56140/173481[18:00<38:52,50.31it/s] 33%|###2      |56679/173481[18:10<38:41,50.31it/s] 37%|###7      |64780/173481[21:00<36:53,49.12it/s] 38%|###7      |65337/173481[21:11<36:41,49.12it/s] 43%|####2     |74020/173481[24:00<33:01,50.19it/s] 43%|####2     |74565/173481[24:11<32:50,50.19it/s] 48%|####8     |83357/173481[27:00<29:26,51.02it/s] 48%|####8     |83953/173481[27:11<29:14,51.02it/s] 53%|#####3    |92784/173481[30:00<26:01,51.69it/s] 54%|#####3    |93375/173481[30:11<25:49,51.69it/s] 59%|#####9    |102412/173481[33:00<22:32,52.56it/s] 59%|#####9    |103011/173481[33:11<22:20,52.56it/s] 65%|######4   |112132/173481[36:00<19:11,53.27it/s] 65%|######4   |112762/173481[36:11<18:59,53.27it/s] 70%|#######   |121644/173481[39:00<16:17,53.05it/s] 70%|#######   |122247/173481[39:12<16:05,53.05it/s] 75%|#######5  |130894/173481[42:00<13:35,52.20it/s] 76%|#######5  |131524/173481[42:12<13:23,52.20it/s] 81%|########1 |140662/173481[45:00<10:17,53.18it/s] 81%|########1 |141303/173481[45:12<10:05,53.18it/s] 87%|########6 |150304/173481[48:00<07:14,53.37it/s] 87%|########6 |150879/173481[48:12<07:03,53.37it/s] 92%|#########1|159544/173481[51:00<04:26,52.33it/s] 92%|#########2|160199/173481[51:12<04:13,52.33it/s] 97%|#########7|168844/173481[54:00<01:29,51.99it/s] 98%|#########7|169440/173481[54:12<01:17,51.99it/s]100%|##########|173481/173481[55:26<00:00,52.15it/s]
[32m[0321 01:33:49 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:3326.88 sec.
[32m[0321 01:33:50 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-2775696.
[32m[0321 01:33:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:19<00:00,238.06it/s]
15
[32m[0321 01:35:10 @monitor.py:363][0m QueueInput/queue_size: 0.22084
[32m[0321 01:35:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 74.019
[32m[0321 01:35:10 @monitor.py:363][0m activation-summaries/output-rms: 0.049006
[32m[0321 01:35:10 @monitor.py:363][0m cross_entropy_loss: 1.0395
[32m[0321 01:35:10 @monitor.py:363][0m lr: 3.125e-05
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.66116
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2111
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2827
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27421
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21052
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20737
[32m[0321 01:35:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 01:35:10 @monitor.py:363][0m train-error-top1: 0.29394
[32m[0321 01:35:10 @monitor.py:363][0m val-error-top1: 0.30394
[32m[0321 01:35:10 @monitor.py:363][0m val-utt-error: 0.034587
[32m[0321 01:35:10 @monitor.py:363][0m validation_cost: 1.0958
[32m[0321 01:35:10 @monitor.py:363][0m wd_cost: 0.0044077
[32m[0321 01:35:10 @group.py:42][0m Callbacks took 81.241 sec in total. InferenceRunner: 79.075sec
[32m[0321 01:35:10 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10166/173481[03:00<48:11,56.48it/s]  6%|6         |10674/173481[03:10<48:02,56.48it/s] 11%|#1        |19483/173481[06:00<47:31,54.00it/s] 12%|#1        |20040/173481[06:10<47:21,54.00it/s] 17%|#6        |28921/173481[09:00<45:17,53.20it/s] 17%|#6        |29436/173481[09:10<45:07,53.20it/s] 22%|##2       |38405/173481[12:00<42:31,52.94it/s] 22%|##2       |38970/173481[12:10<42:20,52.94it/s] 28%|##7       |48222/173481[15:00<38:51,53.73it/s] 28%|##8       |48799/173481[15:10<38:40,53.73it/s] 33%|###3      |57823/173481[18:00<36:00,53.53it/s] 34%|###3      |58397/173481[18:10<35:49,53.53it/s] 39%|###8      |67447/173481[21:00<33:01,53.50it/s] 39%|###9      |68004/173481[21:11<32:51,53.50it/s] 44%|####4     |76921/173481[24:00<30:19,53.06it/s] 45%|####4     |77495/173481[24:11<30:09,53.06it/s] 50%|####9     |85981/173481[27:00<28:14,51.65it/s] 50%|####9     |86538/173481[27:11<28:03,51.65it/s] 55%|#####4    |95269/173481[30:00<25:15,51.62it/s] 55%|#####5    |95862/173481[30:11<25:03,51.62it/s] 60%|######    |104605/173481[33:00<22:11,51.74it/s] 61%|######    |105198/173481[33:11<21:59,51.74it/s] 66%|######5   |114138/173481[36:00<18:53,52.34it/s] 66%|######6   |114714/173481[36:11<18:42,52.34it/s] 71%|#######1  |123391/173481[39:00<16:05,51.86it/s] 72%|#######1  |124056/173481[39:12<15:52,51.86it/s] 77%|#######6  |132727/173481[42:00<13:05,51.86it/s] 77%|#######6  |133338/173481[42:12<12:54,51.86it/s] 82%|########1 |141721/173481[45:00<10:24,50.89it/s] 82%|########2 |142356/173481[45:12<10:11,50.89it/s] 87%|########6 |150811/173481[48:00<07:27,50.69it/s] 87%|########7 |151326/173481[48:12<07:17,50.69it/s] 92%|#########1|159349/173481[51:00<04:48,49.01it/s] 92%|#########2|159942/173481[51:12<04:36,49.01it/s] 97%|#########7|168781/173481[54:00<01:32,50.65it/s] 98%|#########7|169446/173481[54:12<01:19,50.65it/s]100%|##########|173481/173481[55:27<00:00,52.14it/s]
[32m[0321 02:30:38 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:3327.32 sec.
[32m[0321 02:30:38 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-2949177.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:18<00:00,240.35it/s]
16
[32m[0321 02:31:57 @monitor.py:363][0m QueueInput/queue_size: 0.25762
[32m[0321 02:31:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 76.369
[32m[0321 02:31:57 @monitor.py:363][0m activation-summaries/output-rms: 0.049332
[32m[0321 02:31:57 @monitor.py:363][0m cross_entropy_loss: 1.0464
[32m[0321 02:31:57 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67383
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2114
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28519
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2749
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21094
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20782
[32m[0321 02:31:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 02:31:57 @monitor.py:363][0m train-error-top1: 0.29199
[32m[0321 02:31:57 @monitor.py:363][0m val-error-top1: 0.29986
[32m[0321 02:31:57 @monitor.py:363][0m val-utt-error: 0.0331
[32m[0321 02:31:57 @monitor.py:363][0m validation_cost: 1.0791
[32m[0321 02:31:57 @monitor.py:363][0m wd_cost: 0.00090121
[32m[0321 02:31:57 @group.py:42][0m Callbacks took 79.018 sec in total. InferenceRunner: 78.327sec
[32m[0321 02:31:57 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10288/173481[03:00<47:36,57.14it/s]  6%|6         |10773/173481[03:10<47:27,57.14it/s] 12%|#1        |20110/173481[06:00<45:47,55.82it/s] 12%|#1        |20671/173481[06:10<45:37,55.82it/s] 17%|#7        |29740/173481[09:00<43:51,54.63it/s] 17%|#7        |30315/173481[09:10<43:40,54.63it/s] 23%|##2       |39592/173481[12:00<40:48,54.67it/s] 23%|##3       |40155/173481[12:10<40:38,54.67it/s] 28%|##8       |49414/173481[15:00<37:51,54.62it/s] 29%|##8       |49976/173481[15:10<37:41,54.62it/s] 34%|###4      |59038/173481[18:00<35:18,54.03it/s] 34%|###4      |59591/173481[18:10<35:07,54.03it/s] 40%|###9      |68818/173481[21:00<32:11,54.18it/s] 40%|####      |69399/173481[21:11<32:01,54.18it/s] 45%|####5     |78574/173481[24:00<29:11,54.19it/s] 46%|####5     |79187/173481[24:11<29:00,54.19it/s] 51%|#####     |88300/173481[27:00<26:14,54.10it/s] 51%|#####1    |88917/173481[27:11<26:02,54.10it/s] 56%|#####6    |97859/173481[30:00<23:30,53.60it/s] 57%|#####6    |98470/173481[30:11<23:19,53.60it/s] 62%|######1   |107290/173481[33:00<20:49,52.99it/s] 62%|######2   |107816/173481[33:11<20:39,52.99it/s] 67%|######7   |116728/173481[36:00<17:56,52.70it/s] 68%|######7   |117340/173481[36:11<17:45,52.70it/s] 73%|#######2  |126364/173481[39:00<14:47,53.11it/s] 73%|#######3  |126963/173481[39:12<14:35,53.11it/s] 78%|#######8  |135897/173481[42:00<11:48,53.03it/s] 79%|#######8  |136534/173481[42:12<11:36,53.03it/s] 84%|########3 |145588/173481[45:00<08:42,53.43it/s] 84%|########4 |146223/173481[45:12<08:30,53.43it/s] 90%|########9 |155302/173481[48:00<05:38,53.69it/s] 90%|########9 |155930/173481[48:12<05:26,53.69it/s] 95%|#########5|164890/173481[51:00<02:40,53.47it/s] 95%|#########5|165555/173481[51:12<02:28,53.47it/s][32m[0321 03:25:36 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:3219.60 sec.
100%|##########|173481/173481[53:39<00:00,53.88it/s]
[32m[0321 03:25:37 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-3122658.
[32m[0321 03:25:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:15<00:00,248.59it/s]
17
[32m[0321 03:26:54 @monitor.py:363][0m QueueInput/queue_size: 0.26856
[32m[0321 03:26:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 78.47
[32m[0321 03:26:54 @monitor.py:363][0m activation-summaries/output-rms: 0.050549
[32m[0321 03:26:54 @monitor.py:363][0m cross_entropy_loss: 0.96897
[32m[0321 03:26:54 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.68367
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2118
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28693
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27524
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21115
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20805
[32m[0321 03:26:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 03:26:54 @monitor.py:363][0m train-error-top1: 0.27755
[32m[0321 03:26:54 @monitor.py:363][0m val-error-top1: 0.29884
[32m[0321 03:26:54 @monitor.py:363][0m val-utt-error: 0.03464
[32m[0321 03:26:54 @monitor.py:363][0m validation_cost: 1.075
[32m[0321 03:26:54 @monitor.py:363][0m wd_cost: 0.00091602
[32m[0321 03:26:54 @group.py:42][0m Callbacks took 77.948 sec in total. InferenceRunner: 75.726sec
[32m[0321 03:26:54 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9751/173481[03:00<50:23,54.15it/s]  6%|5         |10254/173481[03:10<50:14,54.15it/s] 11%|#         |18703/173481[06:00<49:45,51.85it/s] 11%|#1        |19242/173481[06:10<49:34,51.85it/s] 16%|#6        |28219/173481[09:00<46:15,52.34it/s] 17%|#6        |28752/173481[09:10<46:05,52.34it/s] 22%|##2       |38203/173481[12:00<41:52,53.85it/s] 22%|##2       |38838/173481[12:10<41:40,53.85it/s] 29%|##8       |49884/173481[15:00<34:59,58.86it/s] 29%|##9       |50658/173481[15:10<34:46,58.86it/s] 35%|###4      |60253/173481[18:00<32:24,58.22it/s] 35%|###5      |60767/173481[18:10<32:16,58.22it/s] 39%|###9      |67909/173481[21:00<35:48,49.14it/s] 39%|###9      |68471/173481[21:11<35:36,49.14it/s] 45%|####4     |77604/173481[24:00<31:05,51.39it/s] 45%|####5     |78197/173481[24:11<30:54,51.39it/s] 50%|####9     |86647/173481[27:00<28:29,50.81it/s] 50%|#####     |87198/173481[27:11<28:18,50.81it/s] 55%|#####5    |95620/173481[30:00<25:47,50.32it/s] 55%|#####5    |96186/173481[30:11<25:35,50.32it/s] 60%|######    |104467/173481[33:00<23:08,49.72it/s] 61%|######    |105012/173481[33:11<22:57,49.72it/s] 65%|######5   |113138/173481[36:00<20:33,48.93it/s] 66%|######5   |113670/173481[36:11<20:22,48.93it/s] 70%|#######   |121765/173481[39:00<17:48,48.41it/s] 71%|#######   |122349/173481[39:12<17:36,48.41it/s] 75%|#######5  |130502/173481[42:00<14:46,48.47it/s] 76%|#######5  |131028/173481[42:12<14:35,48.47it/s] 80%|########  |139465/173481[45:00<11:32,49.12it/s] 81%|########  |140106/173481[45:12<11:19,49.12it/s] 86%|########5 |149035/173481[48:00<07:58,51.06it/s] 86%|########6 |149695/173481[48:12<07:45,51.06it/s] 91%|######### |157801/173481[51:00<05:14,49.84it/s] 91%|#########1|158388/173481[51:12<05:02,49.84it/s] 96%|#########6|166833/173481[54:00<02:12,50.01it/s] 97%|#########6|167472/173481[54:12<02:00,50.01it/s]100%|##########|173481/173481[56:07<00:00,51.52it/s]
[32m[0321 04:23:02 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:3367.40 sec.
[32m[0321 04:23:03 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-3296139.
[32m[0321 04:23:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:31<00:00,206.11it/s]
18
[32m[0321 04:24:36 @monitor.py:363][0m QueueInput/queue_size: 0.38985
[32m[0321 04:24:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 79.521
[32m[0321 04:24:36 @monitor.py:363][0m activation-summaries/output-rms: 0.049454
[32m[0321 04:24:36 @monitor.py:363][0m cross_entropy_loss: 1.0445
[32m[0321 04:24:36 @monitor.py:363][0m lr: 1.5625e-05
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6935
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2123
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28862
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27561
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21136
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20828
[32m[0321 04:24:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 04:24:36 @monitor.py:363][0m train-error-top1: 0.29256
[32m[0321 04:24:36 @monitor.py:363][0m val-error-top1: 0.29692
[32m[0321 04:24:36 @monitor.py:363][0m val-utt-error: 0.032887
[32m[0321 04:24:36 @monitor.py:363][0m validation_cost: 1.0688
[32m[0321 04:24:36 @monitor.py:363][0m wd_cost: 0.00093091
[32m[0321 04:24:36 @group.py:42][0m Callbacks took 94.681 sec in total. InferenceRunner: 91.331sec
[32m[0321 04:24:36 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9215/173481[03:00<53:28,51.19it/s]  6%|5         |9681/173481[03:10<53:19,51.19it/s] 10%|#         |17397/173481[06:00<54:01,48.15it/s] 10%|#         |17865/173481[06:10<53:51,48.15it/s] 15%|#4        |25728/173481[09:00<52:10,47.20it/s] 15%|#5        |26220/173481[09:10<51:59,47.20it/s] 20%|#9        |34180/173481[12:00<49:19,47.07it/s] 20%|#9        |34677/173481[12:10<49:08,47.07it/s] 25%|##4       |42688/173481[15:00<46:13,47.16it/s] 25%|##4       |43203/173481[15:10<46:02,47.16it/s] 30%|##9       |51407/173481[18:00<42:34,47.79it/s] 30%|##9       |51975/173481[18:10<42:22,47.79it/s] 35%|###4      |60220/173481[21:00<39:01,48.37it/s] 35%|###5      |60771/173481[21:11<38:50,48.37it/s] 40%|###9      |68954/173481[24:00<35:57,48.44it/s] 40%|####      |69501/173481[24:11<35:46,48.44it/s] 45%|####4     |77908/173481[27:00<32:27,49.08it/s] 45%|####5     |78561/173481[27:11<32:13,49.08it/s] 51%|#####     |87694/173481[30:00<27:43,51.58it/s] 51%|#####     |88317/173481[30:11<27:31,51.58it/s] 56%|#####5    |96760/173481[33:00<25:05,50.97it/s] 56%|#####6    |97341/173481[33:11<24:53,50.97it/s] 61%|######    |105799/173481[36:00<22:17,50.59it/s] 61%|######1   |106390/173481[36:11<22:06,50.59it/s] 66%|######5   |114457/173481[39:00<19:56,49.31it/s] 66%|######6   |115041/173481[39:12<19:45,49.31it/s] 71%|#######1  |123736/173481[42:00<16:27,50.39it/s] 72%|#######1  |124379/173481[42:12<16:14,50.39it/s] 77%|#######6  |133390/173481[45:00<12:51,51.96it/s] 77%|#######7  |134037/173481[45:12<12:39,51.96it/s] 83%|########2 |143302/173481[48:00<09:24,53.47it/s] 83%|########3 |144030/173481[48:12<09:10,53.47it/s] 89%|########8 |154054/173481[51:00<05:44,56.41it/s] 89%|########9 |154773/173481[51:12<05:31,56.41it/s] 95%|#########4|164008/173481[54:00<02:49,55.85it/s] 95%|#########4|164673/173481[54:12<02:37,55.85it/s]100%|##########|173481/173481[56:57<00:00,50.76it/s]
[32m[0321 05:21:34 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:3417.84 sec.
[32m[0321 05:21:35 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-3469620.
[32m[0321 05:21:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,198.68it/s]
19
[32m[0321 05:23:11 @monitor.py:363][0m QueueInput/queue_size: 0.22748
[32m[0321 05:23:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 81.211
[32m[0321 05:23:11 @monitor.py:363][0m activation-summaries/output-rms: 0.049578
[32m[0321 05:23:11 @monitor.py:363][0m cross_entropy_loss: 0.9635
[32m[0321 05:23:11 @monitor.py:363][0m lr: 7.8125e-06
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.69882
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2126
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2894
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27572
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21142
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20834
[32m[0321 05:23:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 05:23:11 @monitor.py:363][0m train-error-top1: 0.27477
[32m[0321 05:23:11 @monitor.py:363][0m val-error-top1: 0.29673
[32m[0321 05:23:11 @monitor.py:363][0m val-utt-error: 0.033471
[32m[0321 05:23:11 @monitor.py:363][0m validation_cost: 1.07
[32m[0321 05:23:11 @monitor.py:363][0m wd_cost: 0.00018773
[32m[0321 05:23:11 @group.py:42][0m Callbacks took 97.090 sec in total. InferenceRunner: 94.747sec
[32m[0321 05:23:11 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11293/173481[03:00<43:05,62.73it/s]  7%|6         |12118/173481[03:10<42:52,62.73it/s] 13%|#3        |22973/173481[06:00<39:19,63.79it/s] 14%|#3        |23544/173481[06:10<39:10,63.79it/s] 19%|#8        |32797/173481[09:00<39:51,58.82it/s] 19%|#9        |33338/173481[09:10<39:42,58.82it/s] 24%|##4       |42313/173481[12:00<39:16,55.67it/s] 25%|##4       |42894/173481[12:10<39:05,55.67it/s] 30%|##9       |52039/173481[15:00<36:55,54.83it/s] 30%|###       |52624/173481[15:10<36:44,54.83it/s] 36%|###5      |61873/173481[18:00<33:59,54.72it/s] 36%|###5      |62442/173481[18:10<33:49,54.72it/s] 41%|####1     |71815/173481[21:00<30:49,54.97it/s] 42%|####1     |72408/173481[21:11<30:38,54.97it/s] 47%|####7     |82057/173481[24:00<27:15,55.91it/s] 48%|####7     |82656/173481[24:11<27:04,55.91it/s] 53%|#####3    |92125/173481[27:00<24:14,55.92it/s] 53%|#####3    |92754/173481[27:11<24:03,55.92it/s] 59%|#####8    |101749/173481[30:00<21:52,54.65it/s] 59%|#####8    |102312/173481[30:11<21:42,54.65it/s] 64%|######4   |111163/173481[33:00<19:26,53.44it/s] 64%|######4   |111816/173481[33:11<19:13,53.44it/s] 70%|######9   |120667/173481[36:00<16:34,53.12it/s] 70%|######9   |121242/173481[36:11<16:23,53.12it/s] 75%|#######4  |130081/173481[39:00<13:43,52.70it/s] 75%|#######5  |130677/173481[39:12<13:32,52.70it/s] 80%|########  |139621/173481[42:00<10:40,52.84it/s] 81%|########  |140220/173481[42:12<10:29,52.84it/s] 86%|########6 |149245/173481[45:00<07:36,53.14it/s] 86%|########6 |149891/173481[45:12<07:23,53.14it/s] 92%|#########1|158983/173481[48:00<04:30,53.61it/s] 92%|#########1|159516/173481[48:12<04:20,53.61it/s] 97%|#########7|168751/173481[51:00<01:27,53.93it/s] 98%|#########7|169416/173481[51:12<01:15,53.93it/s]100%|##########|173481/173481[52:27<00:00,55.13it/s]
[32m[0321 06:15:38 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:3147.03 sec.
[32m[0321 06:15:39 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-3643101.
[32m[0321 06:15:41 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:24<00:00,222.25it/s]
20
[32m[0321 06:17:05 @monitor.py:363][0m QueueInput/queue_size: 0.20921
[32m[0321 06:17:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 81.732
[32m[0321 06:17:05 @monitor.py:363][0m activation-summaries/output-rms: 0.049779
[32m[0321 06:17:05 @monitor.py:363][0m cross_entropy_loss: 1.0116
[32m[0321 06:17:05 @monitor.py:363][0m lr: 7.8125e-06
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.70385
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2126
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29013
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2758
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21146
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20841
[32m[0321 06:17:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 06:17:05 @monitor.py:363][0m train-error-top1: 0.28367
[32m[0321 06:17:05 @monitor.py:363][0m val-error-top1: 0.29513
[32m[0321 06:17:05 @monitor.py:363][0m val-utt-error: 0.032568
[32m[0321 06:17:05 @monitor.py:363][0m validation_cost: 1.062
[32m[0321 06:17:05 @monitor.py:363][0m wd_cost: 0.00018919
[32m[0321 06:17:05 @group.py:42][0m Callbacks took 87.133 sec in total. InferenceRunner: 84.697sec
[32m[0321 06:17:05 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10342/173481[03:00<47:19,57.45it/s]  6%|6         |10875/173481[03:10<47:10,57.45it/s] 11%|#1        |19282/173481[06:00<48:14,53.26it/s] 11%|#1        |19845/173481[06:10<48:04,53.26it/s] 17%|#6        |29273/173481[09:00<44:12,54.36it/s] 17%|#7        |29835/173481[09:10<44:02,54.36it/s] 23%|##2       |39465/173481[12:00<40:16,55.47it/s] 23%|##3       |40065/173481[12:10<40:05,55.47it/s] 28%|##8       |49258/173481[15:00<37:41,54.93it/s] 29%|##8       |49869/173481[15:10<37:30,54.93it/s] 34%|###4      |59368/173481[18:00<34:14,55.54it/s] 35%|###4      |59992/173481[18:10<34:03,55.54it/s] 40%|####      |69440/173481[21:00<31:06,55.74it/s] 40%|####      |70065/173481[21:11<30:55,55.74it/s] 46%|####5     |79451/173481[24:00<28:08,55.68it/s] 46%|####6     |80085/173481[24:11<27:57,55.68it/s] 52%|#####1    |89698/173481[27:00<24:48,56.29it/s] 52%|#####2    |90309/173481[27:11<24:37,56.29it/s] 58%|#####7    |100000/173481[30:00<21:34,56.75it/s] 58%|#####8    |100658/173481[30:11<21:23,56.75it/s] 64%|######3   |110169/173481[33:00<18:38,56.62it/s] 64%|######3   |110829/173481[33:11<18:26,56.62it/s] 69%|######9   |120240/173481[36:00<15:45,56.28it/s] 70%|######9   |120909/173481[36:11<15:34,56.28it/s] 75%|#######4  |129991/173481[39:00<13:07,55.21it/s] 75%|#######5  |130653/173481[39:11<12:55,55.21it/s] 80%|########  |139558/173481[42:00<10:26,54.15it/s] 81%|########  |140211/173481[42:12<10:14,54.15it/s] 86%|########6 |149704/173481[45:00<07:10,55.23it/s] 87%|########6 |150395/173481[45:12<06:57,55.23it/s] 92%|#########2|159988/173481[48:00<04:00,56.16it/s] 93%|#########2|160696/173481[48:12<03:47,56.16it/s] 98%|#########8|170122/173481[51:00<00:59,56.22it/s] 98%|#########8|170787/173481[51:12<00:47,56.22it/s]100%|##########|173481/173481[52:01<00:00,55.58it/s]
[32m[0321 07:09:06 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:3121.08 sec.
[32m[0321 07:09:07 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-3816582.
[32m[0321 07:09:08 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:20<00:00,233.30it/s]
21
[32m[0321 07:10:29 @monitor.py:363][0m QueueInput/queue_size: 0.28902
[32m[0321 07:10:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 82.255
[32m[0321 07:10:29 @monitor.py:363][0m activation-summaries/output-rms: 0.049252
[32m[0321 07:10:29 @monitor.py:363][0m cross_entropy_loss: 0.99753
[32m[0321 07:10:29 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.70837
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2129
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29078
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27589
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2115
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20846
[32m[0321 07:10:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 07:10:29 @monitor.py:363][0m train-error-top1: 0.28082
[32m[0321 07:10:29 @monitor.py:363][0m val-error-top1: 0.29479
[32m[0321 07:10:29 @monitor.py:363][0m val-utt-error: 0.032356
[32m[0321 07:10:29 @monitor.py:363][0m validation_cost: 1.0619
[32m[0321 07:10:29 @monitor.py:363][0m wd_cost: 0.00019051
[32m[0321 07:10:29 @group.py:42][0m Callbacks took 82.783 sec in total. InferenceRunner: 80.688sec
[32m[0321 07:10:29 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10969/173481[03:00<44:27,60.92it/s]  7%|6         |11538/173481[03:10<44:18,60.92it/s] 12%|#2        |21241/173481[06:00<43:03,58.92it/s] 13%|#2        |21812/173481[06:10<42:53,58.92it/s] 18%|#8        |31441/173481[09:00<40:58,57.77it/s] 18%|#8        |32058/173481[09:10<40:47,57.77it/s] 24%|##4       |41713/173481[12:00<38:15,57.41it/s] 24%|##4       |42330/173481[12:10<38:04,57.41it/s] 30%|###       |52045/173481[15:00<35:15,57.40it/s] 30%|###       |52644/173481[15:10<35:05,57.40it/s] 36%|###5      |62419/173481[18:00<32:11,57.51it/s] 36%|###6      |63007/173481[18:10<32:00,57.51it/s] 42%|####1     |72457/173481[21:00<29:44,56.62it/s] 42%|####2     |73068/173481[21:11<29:33,56.62it/s] 48%|####7     |82645/173481[24:00<26:44,56.60it/s] 48%|####7     |83238/173481[24:11<26:34,56.60it/s] 54%|#####3    |92915/173481[27:00<23:37,56.83it/s] 54%|#####3    |93522/173481[27:11<23:27,56.83it/s] 59%|#####9    |103105/173481[30:00<20:40,56.71it/s] 60%|#####9    |103722/173481[30:11<20:30,56.71it/s] 65%|######5   |113305/173481[33:00<17:41,56.68it/s] 66%|######5   |113983/173481[33:11<17:29,56.68it/s] 71%|#######1  |123625/173481[36:00<14:34,56.99it/s] 72%|#######1  |124266/173481[36:11<14:23,56.99it/s] 77%|#######7  |133645/173481[39:00<11:47,56.32it/s] 77%|#######7  |134224/173481[39:11<11:37,56.32it/s] 83%|########2 |143353/173481[42:00<09:06,55.10it/s] 83%|########2 |143984/173481[42:12<08:55,55.10it/s] 88%|########8 |152979/173481[45:00<06:17,54.27it/s] 89%|########8 |153666/173481[45:12<06:05,54.27it/s] 94%|#########4|163165/173481[48:00<03:06,55.40it/s] 94%|#########4|163775/173481[48:12<02:55,55.40it/s]100%|#########9|172954/173481[51:00<00:09,54.89it/s][32m[0321 08:01:39 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:3069.73 sec.
100%|##########|173481/173481[51:09<00:00,56.51it/s]
[32m[0321 08:01:39 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-3990063.
[32m[0321 08:01:41 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:19<00:00,237.07it/s]
22
[32m[0321 08:03:00 @monitor.py:363][0m QueueInput/queue_size: 0.30912
[32m[0321 08:03:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 83.117
[32m[0321 08:03:00 @monitor.py:363][0m activation-summaries/output-rms: 0.049496
[32m[0321 08:03:00 @monitor.py:363][0m cross_entropy_loss: 1.0258
[32m[0321 08:03:00 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.71092
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.213
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29111
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27592
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21151
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20848
[32m[0321 08:03:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 08:03:00 @monitor.py:363][0m train-error-top1: 0.28907
[32m[0321 08:03:00 @monitor.py:363][0m val-error-top1: 0.29509
[32m[0321 08:03:00 @monitor.py:363][0m val-utt-error: 0.032196
[32m[0321 08:03:00 @monitor.py:363][0m validation_cost: 1.0618
[32m[0321 08:03:00 @monitor.py:363][0m wd_cost: 3.8249e-05
[32m[0321 08:03:00 @group.py:42][0m Callbacks took 81.106 sec in total. InferenceRunner: 79.406sec
[32m[0321 08:03:00 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10906/173481[03:00<44:43,60.58it/s]  7%|6         |11499/173481[03:10<44:33,60.58it/s] 12%|#2        |21574/173481[06:00<42:15,59.90it/s] 13%|#2        |22148/173481[06:10<42:06,59.90it/s] 18%|#8        |32042/173481[09:00<39:56,59.02it/s] 19%|#8        |32613/173481[09:10<39:46,59.02it/s] 24%|##4       |42262/173481[12:00<37:47,57.87it/s] 25%|##4       |42849/173481[12:10<37:37,57.87it/s] 30%|###       |52402/173481[15:00<35:20,57.09it/s] 31%|###       |53000/173481[15:10<35:10,57.09it/s] 36%|###6      |62494/173481[18:00<32:42,56.56it/s] 36%|###6      |63081/173481[18:10<32:31,56.56it/s] 42%|####1     |72562/173481[21:00<29:54,56.24it/s] 42%|####2     |73173/173481[21:11<29:43,56.24it/s] 48%|####7     |82576/173481[24:00<27:05,55.93it/s] 48%|####7     |83199/173481[24:11<26:54,55.93it/s] 52%|#####2    |90268/173481[27:00<28:37,48.44it/s] 52%|#####2    |90891/173481[27:11<28:24,48.44it/s] 58%|#####7    |100582/173481[30:00<23:08,52.50it/s] 58%|#####8    |101211/173481[30:11<22:56,52.50it/s] 64%|######3   |110712/173481[33:00<19:15,54.32it/s] 64%|######4   |111345/173481[33:11<19:03,54.32it/s] 70%|######9   |120763/173481[36:00<15:57,55.07it/s] 70%|######9   |121431/173481[36:11<15:45,55.07it/s] 76%|#######5  |130990/173481[39:00<12:39,55.93it/s] 76%|#######5  |131667/173481[39:11<12:27,55.93it/s] 81%|########1 |141310/173481[42:00<09:28,56.62it/s] 82%|########1 |141999/173481[42:12<09:16,56.62it/s] 87%|########7 |151662/173481[45:00<06:22,57.06it/s] 88%|########7 |152332/173481[45:12<06:10,57.06it/s] 93%|#########3|161873/173481[48:00<03:24,56.89it/s] 94%|#########3|162555/173481[48:12<03:12,56.89it/s] 99%|#########9|172030/173481[51:00<00:25,56.65it/s]100%|#########9|172719/173481[51:12<00:13,56.65it/s]100%|##########|173481/173481[51:25<00:00,56.22it/s]
[32m[0321 08:54:26 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:3085.99 sec.
[32m[0321 08:54:27 @saver.py:84][0m Model saved to train_log/fcn2_w_32_a_32_quant_ends_False/model-4163544.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,168.51it/s]
23
[32m[0321 08:56:19 @monitor.py:363][0m QueueInput/queue_size: 0.3473
[32m[0321 08:56:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 83.916
[32m[0321 08:56:19 @monitor.py:363][0m activation-summaries/output-rms: 0.050777
[32m[0321 08:56:19 @monitor.py:363][0m cross_entropy_loss: 0.95159
[32m[0321 08:56:19 @monitor.py:363][0m lr: 3.9063e-06
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.71349
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2131
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29144
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.063661
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27594
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.064692
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.21152
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.065456
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20849
[32m[0321 08:56:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.064025
[32m[0321 08:56:19 @monitor.py:363][0m train-error-top1: 0.27306
[32m[0321 08:56:19 @monitor.py:363][0m val-error-top1: 0.29494
[32m[0321 08:56:19 @monitor.py:363][0m val-utt-error: 0.033684
[32m[0321 08:56:19 @monitor.py:363][0m validation_cost: 1.0599
[32m[0321 08:56:19 @monitor.py:363][0m wd_cost: 3.8395e-05
[32m[0321 08:56:19 @group.py:42][0m Callbacks took 113.293 sec in total. InferenceRunner: 111.708sec
[32m[0321 08:56:19 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11245/173481[03:00<43:17,62.47it/s]  7%|6         |11846/173481[03:10<43:07,62.47it/s] 12%|#2        |21541/173481[06:00<42:24,59.72it/s] 13%|#2        |22124/173481[06:10<42:14,59.72it/s] 18%|#8        |32078/173481[09:00<39:51,59.12it/s] 19%|#8        |32712/173481[09:10<39:41,59.12it/s] 24%|##4       |42439/173481[12:00<37:26,58.33it/s] 25%|##4       |43046/173481[12:10<37:16,58.33it/s] 31%|###       |53168/173481[15:00<34:00,58.96it/s] 31%|###1      |53844/173481[15:10<33:49,58.96it/s] 38%|###7      |65509/173481[18:00<28:23,63.40it/s] 38%|###8      |66157/173481[18:10<28:12,63.40it/s] 45%|####4     |77671/173481[21:00<24:24,65.41it/s] 45%|####5     |78426/173481[21:11<24:13,65.41it/s] 52%|#####1    |89912/173481[24:00<20:53,66.68it/s] 52%|#####2    |90654/173481[24:11<20:42,66.68it/s] 59%|#####9    |102595/173481[27:00<17:14,68.52it/s] 60%|#####9    |103334/173481[27:11<17:03,68.52it/s] 66%|######6   |115310/173481[30:00<13:56,69.56it/s] 67%|######6   |116185/173481[30:11<13:43,69.56it/s]slurmstepd: *** JOB 70360 ON sls-sm-11 CANCELLED AT 2018-03-21T09:28:48 ***
