sls-titan-10 1
SLURM_JOBID=85142
SLURM_TASKID=3
[32m[0328 11:37:17 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=8 --bita=32 --quant_ends=True --load_ckpt=train_log/fcn1_w_8_a_32_quant_ends_False/checkpoint
[32m[0328 11:37:26 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 11:37:26 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 11:37:26 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 11:37:26 @drf_run.py:166][0m Using host: sls-titan-10
[32m[0328 11:37:26 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 11:37:26 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 11:37:26 @drf_run.py:188][0m Using GPU: 1
[32m[0328 11:37:26 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 11:37:26 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 11:37:26 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 11:37:26 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear0 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear1 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:37:26 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:37:26 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 11:37:26 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:37:26 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:37:26 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 11:37:26 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:37:26 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0328 11:37:26 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 11:37:26 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0328 11:37:27 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0328 11:37:27 @base.py:196][0m Setup callbacks graph ...
[32m[0328 11:37:27 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:37:27 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:37:27 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:37:28 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:37:28 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:37:28 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:37:28 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0328 11:37:28 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 11:37:28 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0328 11:37:28 @base.py:212][0m Creating the session ...
2018-03-28 11:37:28.850929: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-28 11:37:31.735697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:03:00.0
totalMemory: 11.92GiB freeMemory: 11.81GiB
2018-03-28 11:37:31.735740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
[32m[0328 11:37:36 @base.py:220][0m Initializing the session ...
[32m[0328 11:37:36 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn1_w_8_a_32_quant_ends_False/model-10408860 ...
[32m[0328 11:37:36 @base.py:227][0m Graph Finalized.
[32m[0328 11:37:36 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 11:37:36 @steps.py:127][0m Start training with global_step=10408860
[32m[0328 11:37:39 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14277/173481[03:00<33:27,79.31it/s]  9%|8         |15167/173481[03:10<33:16,79.31it/s] 16%|#6        |28231/173481[06:00<30:52,78.41it/s] 17%|#6        |28950/173481[06:10<30:43,78.41it/s] 24%|##4       |42396/173481[09:00<27:48,78.55it/s] 25%|##4       |43230/173481[09:10<27:38,78.55it/s] 32%|###2      |56137/173481[12:00<25:15,77.43it/s] 33%|###2      |56925/173481[12:10<25:05,77.43it/s] 40%|###9      |69195/173481[15:00<23:12,74.91it/s] 40%|####      |69831/173481[15:10<23:03,74.91it/s] 46%|####5     |79498/173481[18:00<24:08,64.89it/s] 46%|####6     |80155/173481[18:11<23:58,64.89it/s] 52%|#####1    |90055/173481[21:00<22:34,61.61it/s] 52%|#####2    |90696/173481[21:11<22:23,61.61it/s] 58%|#####7    |100556/173481[24:00<20:16,59.93it/s] 58%|#####8    |101253/173481[24:11<20:05,59.93it/s] 64%|######4   |111187/173481[27:00<17:27,59.49it/s] 64%|######4   |111881/173481[27:11<17:15,59.49it/s] 70%|#######   |121566/173481[30:00<14:46,58.55it/s] 70%|#######   |122245/173481[30:11<14:35,58.55it/s] 76%|#######6  |132116/173481[33:00<11:46,58.58it/s] 77%|#######6  |132840/173481[33:12<11:33,58.58it/s] 82%|########2 |142826/173481[36:00<08:39,59.03it/s] 83%|########2 |143551/173481[36:12<08:26,59.03it/s] 88%|########8 |152752/173481[39:00<06:03,57.02it/s] 88%|########8 |153390/173481[39:12<05:52,57.02it/s] 94%|#########3|162228/173481[42:00<03:25,54.75it/s] 94%|#########3|162921/173481[42:12<03:12,54.75it/s] 99%|#########9|172422/173481[45:00<00:19,55.67it/s]100%|#########9|173125/173481[45:12<00:06,55.67it/s]100%|##########|173481/173481[45:19<00:00,63.79it/s]
[32m[0328 12:22:59 @base.py:257][0m Epoch 1 (global_step 10582341) finished, time:2719.49 sec.
[32m[0328 12:22:59 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 49%|####8     |9202/18822[03:00<03:08,51.12it/s] 52%|#####2    |9788/18822[03:10<02:56,51.12it/s]100%|##########|18822/18822[05:24<00:00,58.06it/s]
0
[32m[0328 12:28:23 @monitor.py:363][0m QueueInput/queue_size: 1.3998
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.083
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/output-rms: 0.036241
[32m[0328 12:28:23 @monitor.py:363][0m cross_entropy_loss: 2.4613
[32m[0328 12:28:23 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 12:28:23 @monitor.py:363][0m train-error-top1: 0.6107
[32m[0328 12:28:23 @monitor.py:363][0m val-error-top1: 0.60901
[32m[0328 12:28:23 @monitor.py:363][0m val-utt-error: 0.22973
[32m[0328 12:28:23 @monitor.py:363][0m validation_cost: 2.4786
[32m[0328 12:28:23 @monitor.py:363][0m wd_cost: 2.9766e-15
[32m[0328 12:28:23 @group.py:42][0m Callbacks took 324.545 sec in total. InferenceRunner: 324.204sec
[32m[0328 12:28:23 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10589/173481[03:00<46:09,58.83it/s]  6%|6         |11125/173481[03:10<45:59,58.83it/s] 12%|#1        |20810/173481[06:00<44:02,57.79it/s] 12%|#2        |21419/173481[06:10<43:51,57.79it/s] 18%|#7        |30832/173481[09:00<41:55,56.71it/s] 18%|#8        |31394/173481[09:10<41:45,56.71it/s] 23%|##2       |39872/173481[12:00<41:48,53.27it/s] 23%|##3       |40419/173481[12:10<41:37,53.27it/s] 28%|##8       |49145/173481[15:00<39:34,52.37it/s] 29%|##8       |49720/173481[15:10<39:23,52.37it/s] 34%|###4      |59160/173481[18:00<35:18,53.95it/s] 34%|###4      |59789/173481[18:11<35:07,53.95it/s] 40%|###9      |69120/173481[21:00<31:50,54.63it/s] 40%|####      |69738/173481[21:11<31:38,54.63it/s] 46%|####5     |79366/173481[24:00<28:08,55.75it/s] 46%|####6     |80019/173481[24:11<27:56,55.75it/s] 52%|#####1    |89616/173481[27:00<24:48,56.34it/s] 52%|#####2    |90244/173481[27:11<24:37,56.34it/s] 58%|#####7    |99760/173481[30:00<21:48,56.35it/s] 58%|#####7    |100399/173481[30:11<21:37,56.35it/s] 63%|######3   |109860/173481[33:00<18:51,56.22it/s] 64%|######3   |110504/173481[33:11<18:40,56.22it/s] 69%|######9   |119775/173481[36:00<16:05,55.64it/s] 69%|######9   |120426/173481[36:12<15:53,55.64it/s] 75%|#######4  |129615/173481[39:00<13:15,55.13it/s] 75%|#######5  |130230/173481[39:12<13:04,55.13it/s] 80%|########  |139423/173481[42:00<10:21,54.81it/s] 81%|########  |140123/173481[42:12<10:08,54.81it/s] 86%|########6 |149455/173481[45:00<07:14,55.26it/s] 87%|########6 |150144/173481[45:12<07:02,55.26it/s] 92%|#########2|159610/173481[48:00<04:08,55.83it/s] 92%|#########2|160302/173481[48:12<03:56,55.83it/s] 98%|#########7|169776/173481[51:00<01:05,56.15it/s] 98%|#########8|170489/173481[51:12<00:53,56.15it/s]100%|##########|173481/173481[52:04<00:00,55.52it/s]
[32m[0328 13:20:28 @base.py:257][0m Epoch 2 (global_step 10755822) finished, time:3124.80 sec.
[32m[0328 13:20:28 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-10755822.
[32m[0328 13:20:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,140.98it/s]
1
[32m[0328 13:22:42 @monitor.py:363][0m QueueInput/queue_size: 0.46429
[32m[0328 13:22:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.445
[32m[0328 13:22:42 @monitor.py:363][0m activation-summaries/output-rms: 0.035594
[32m[0328 13:22:42 @monitor.py:363][0m cross_entropy_loss: 2.5258
[32m[0328 13:22:42 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 13:22:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 13:22:42 @monitor.py:363][0m train-error-top1: 0.62259
[32m[0328 13:22:42 @monitor.py:363][0m val-error-top1: 0.61227
[32m[0328 13:22:42 @monitor.py:363][0m val-utt-error: 0.23483
[32m[0328 13:22:42 @monitor.py:363][0m validation_cost: 2.5005
[32m[0328 13:22:42 @monitor.py:363][0m wd_cost: 2.9766e-15
[32m[0328 13:22:42 @group.py:42][0m Callbacks took 134.088 sec in total. InferenceRunner: 133.514sec
[32m[0328 13:22:42 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13174/173481[03:00<36:30,73.17it/s]  8%|7         |13748/173481[03:10<36:23,73.17it/s] 14%|#3        |23831/173481[06:00<38:06,65.45it/s] 14%|#4        |24368/173481[06:10<37:58,65.45it/s] 19%|#9        |33194/173481[09:00<40:20,57.96it/s] 19%|#9        |33753/173481[09:10<40:10,57.96it/s] 25%|##4       |42699/173481[12:00<39:26,55.26it/s] 25%|##4       |43253/173481[12:10<39:16,55.26it/s] 30%|###       |52050/173481[15:00<37:47,53.55it/s] 30%|###       |52563/173481[15:10<37:37,53.55it/s] 35%|###5      |61424/173481[18:00<35:22,52.79it/s] 36%|###5      |62027/173481[18:11<35:11,52.79it/s] 41%|####1     |71719/173481[21:00<30:53,54.90it/s] 42%|####1     |72330/173481[21:11<30:42,54.90it/s] 47%|####7     |81942/173481[24:00<27:19,55.83it/s] 48%|####7     |82558/173481[24:11<27:08,55.83it/s] 53%|#####3    |92369/173481[27:00<23:46,56.86it/s] 54%|#####3    |93028/173481[27:11<23:34,56.86it/s] 59%|#####9    |102672/173481[30:00<20:41,57.05it/s] 60%|#####9    |103365/173481[30:11<20:29,57.05it/s] 65%|######5   |113174/173481[33:00<17:25,57.68it/s] 66%|######5   |113823/173481[33:11<17:14,57.68it/s] 71%|#######1  |123519/173481[36:00<14:27,57.56it/s] 72%|#######1  |124179/173481[36:12<14:16,57.56it/s] 77%|#######7  |133869/173481[39:00<11:28,57.53it/s] 78%|#######7  |134518/173481[39:12<11:17,57.53it/s] 83%|########3 |144430/173481[42:00<08:20,58.09it/s] 84%|########3 |145165/173481[42:12<08:07,58.09it/s] 89%|########9 |155030/173481[45:00<05:15,58.48it/s] 90%|########9 |155743/173481[45:12<05:03,58.48it/s] 96%|#########5|165804/173481[48:00<02:09,59.15it/s] 96%|#########6|166550/173481[48:12<01:57,59.15it/s]100%|##########|173481/173481[50:06<00:00,57.71it/s]
[32m[0328 14:12:49 @base.py:257][0m Epoch 3 (global_step 10929303) finished, time:3006.28 sec.
[32m[0328 14:12:49 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,140.40it/s]
2
[32m[0328 14:15:03 @monitor.py:363][0m QueueInput/queue_size: 0.35854
[32m[0328 14:15:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.084
[32m[0328 14:15:03 @monitor.py:363][0m activation-summaries/output-rms: 0.035314
[32m[0328 14:15:03 @monitor.py:363][0m cross_entropy_loss: 2.4917
[32m[0328 14:15:03 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 14:15:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 14:15:03 @monitor.py:363][0m train-error-top1: 0.61109
[32m[0328 14:15:03 @monitor.py:363][0m val-error-top1: 0.61115
[32m[0328 14:15:03 @monitor.py:363][0m val-utt-error: 0.23069
[32m[0328 14:15:03 @monitor.py:363][0m validation_cost: 2.4941
[32m[0328 14:15:03 @monitor.py:363][0m wd_cost: 2.9766e-15
[32m[0328 14:15:03 @group.py:42][0m Callbacks took 134.306 sec in total. InferenceRunner: 134.072sec
[32m[0328 14:15:03 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13013/173481[03:00<37:00,72.28it/s]  8%|7         |13581/173481[03:10<36:52,72.28it/s] 13%|#2        |22468/173481[06:00<41:22,60.84it/s] 13%|#3        |23034/173481[06:10<41:12,60.84it/s] 18%|#8        |31903/173481[09:00<41:54,56.31it/s] 19%|#8        |32512/173481[09:10<41:43,56.31it/s] 24%|##4       |42033/173481[12:00<38:55,56.29it/s] 25%|##4       |42588/173481[12:10<38:45,56.29it/s] 30%|###       |52343/173481[15:00<35:33,56.78it/s] 31%|###       |53017/173481[15:10<35:21,56.78it/s] 36%|###5      |61833/173481[18:00<34:02,54.67it/s] 36%|###5      |62442/173481[18:10<33:50,54.67it/s] 41%|####1     |71988/173481[21:00<30:27,55.53it/s] 42%|####1     |72618/173481[21:11<30:16,55.53it/s] 47%|####7     |82163/173481[24:00<27:10,56.00it/s] 48%|####7     |82792/173481[24:11<26:59,56.00it/s] 53%|#####2    |91844/173481[27:00<24:47,54.87it/s] 53%|#####3    |92404/173481[27:11<24:37,54.87it/s] 59%|#####8    |101848/173481[30:00<21:37,55.22it/s] 59%|#####9    |102548/173481[30:11<21:24,55.22it/s] 65%|######4   |112743/173481[33:00<17:31,57.75it/s] 65%|######5   |113472/173481[33:11<17:19,57.75it/s] 71%|#######1  |123582/173481[36:00<14:06,58.96it/s] 72%|#######1  |124277/173481[36:11<13:54,58.96it/s] 77%|#######7  |134216/173481[39:00<11:05,59.02it/s] 78%|#######7  |134892/173481[39:12<10:53,59.02it/s] 83%|########3 |144448/173481[42:00<08:21,57.91it/s] 84%|########3 |145112/173481[42:12<08:09,57.91it/s] 89%|########9 |154698/173481[45:00<05:27,57.41it/s] 90%|########9 |155357/173481[45:12<05:15,57.41it/s] 95%|#########5|165088/173481[48:00<02:25,57.56it/s] 96%|#########5|165783/173481[48:12<02:13,57.56it/s]100%|##########|173481/173481[50:46<00:00,56.95it/s]
[32m[0328 15:05:49 @base.py:257][0m Epoch 4 (global_step 11102784) finished, time:3046.16 sec.
[32m[0328 15:05:49 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:08<00:00,147.02it/s]
3
[32m[0328 15:07:58 @monitor.py:363][0m QueueInput/queue_size: 0.5134
[32m[0328 15:07:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.187
[32m[0328 15:07:58 @monitor.py:363][0m activation-summaries/output-rms: 0.035067
[32m[0328 15:07:58 @monitor.py:363][0m cross_entropy_loss: 2.4702
[32m[0328 15:07:58 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 15:07:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 15:07:58 @monitor.py:363][0m train-error-top1: 0.60533
[32m[0328 15:07:58 @monitor.py:363][0m val-error-top1: 0.61012
[32m[0328 15:07:58 @monitor.py:363][0m val-utt-error: 0.23154
[32m[0328 15:07:58 @monitor.py:363][0m validation_cost: 2.4877
[32m[0328 15:07:58 @monitor.py:363][0m wd_cost: 5.9531e-16
[32m[0328 15:07:58 @group.py:42][0m Callbacks took 128.506 sec in total. InferenceRunner: 128.038sec
[32m[0328 15:07:58 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10984/173481[03:00<44:23,61.02it/s]  7%|6         |11507/173481[03:10<44:14,61.02it/s] 12%|#2        |21045/173481[06:00<43:32,58.34it/s] 12%|#2        |21557/173481[06:10<43:23,58.34it/s] 18%|#8        |31307/173481[09:00<41:05,57.67it/s] 18%|#8        |31951/173481[09:10<40:54,57.67it/s] 24%|##3       |41498/173481[12:00<38:30,57.13it/s] 24%|##4       |42083/173481[12:10<38:19,57.13it/s] 30%|##9       |51268/173481[15:00<36:35,55.67it/s] 30%|##9       |51936/173481[15:10<36:23,55.67it/s] 36%|###5      |61822/173481[18:00<32:35,57.11it/s] 36%|###5      |62448/173481[18:10<32:24,57.11it/s] 41%|####1     |71946/173481[21:00<29:51,56.67it/s] 42%|####1     |72557/173481[21:11<29:40,56.67it/s] 47%|####6     |81407/173481[24:00<28:08,54.53it/s] 47%|####7     |81971/173481[24:11<27:58,54.53it/s] 52%|#####2    |90796/173481[27:00<25:50,53.32it/s] 53%|#####2    |91417/173481[27:11<25:39,53.32it/s] 58%|#####7    |100352/173481[30:00<22:54,53.20it/s] 58%|#####8    |100944/173481[30:11<22:43,53.20it/s] 63%|######3   |109952/173481[33:00<19:52,53.26it/s] 64%|######3   |110586/173481[33:11<19:40,53.26it/s] 69%|######9   |119843/173481[36:00<16:31,54.09it/s] 69%|######9   |120476/173481[36:11<16:19,54.09it/s] 75%|#######4  |129567/173481[39:00<13:32,54.05it/s] 75%|#######5  |130251/173481[39:12<13:19,54.05it/s] 80%|########  |139008/173481[42:00<10:47,53.24it/s] 81%|########  |139662/173481[42:12<10:35,53.24it/s] 86%|########5 |149128/173481[45:00<07:25,54.69it/s] 86%|########6 |149822/173481[45:12<07:12,54.69it/s] 92%|#########1|159228/173481[48:00<04:17,55.39it/s] 92%|#########2|159851/173481[48:12<04:06,55.39it/s] 97%|#########7|168635/173481[51:00<01:30,53.78it/s] 98%|#########7|169286/173481[51:12<01:18,53.78it/s]100%|##########|173481/173481[52:32<00:00,55.03it/s]
[32m[0328 16:00:30 @base.py:257][0m Epoch 5 (global_step 11276265) finished, time:3152.49 sec.
[32m[0328 16:00:30 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-11276265.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:06<00:00,149.25it/s]
4
[32m[0328 16:02:36 @monitor.py:363][0m QueueInput/queue_size: 0.76677
[32m[0328 16:02:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.374
[32m[0328 16:02:36 @monitor.py:363][0m activation-summaries/output-rms: 0.037196
[32m[0328 16:02:36 @monitor.py:363][0m cross_entropy_loss: 2.4603
[32m[0328 16:02:36 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 16:02:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 16:02:36 @monitor.py:363][0m train-error-top1: 0.60354
[32m[0328 16:02:36 @monitor.py:363][0m val-error-top1: 0.61028
[32m[0328 16:02:36 @monitor.py:363][0m val-utt-error: 0.23186
[32m[0328 16:02:36 @monitor.py:363][0m validation_cost: 2.4858
[32m[0328 16:02:36 @monitor.py:363][0m wd_cost: 5.9531e-16
[32m[0328 16:02:36 @group.py:42][0m Callbacks took 126.395 sec in total. InferenceRunner: 126.125sec
[32m[0328 16:02:36 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12229/173481[03:00<39:33,67.94it/s]  7%|7         |12835/173481[03:10<39:24,67.94it/s] 13%|#3        |22808/173481[06:00<39:50,63.02it/s] 14%|#3        |23437/173481[06:10<39:40,63.02it/s] 19%|#8        |32910/173481[09:00<39:27,59.37it/s] 19%|#9        |33449/173481[09:10<39:18,59.37it/s] 24%|##4       |41876/173481[12:00<40:29,54.16it/s] 24%|##4       |42404/173481[12:10<40:20,54.16it/s] 29%|##9       |50881/173481[15:00<39:17,52.01it/s] 30%|##9       |51393/173481[15:10<39:07,52.01it/s] 35%|###4      |60230/173481[18:00<36:19,51.97it/s] 35%|###5      |60844/173481[18:10<36:07,51.97it/s] 40%|####      |70140/173481[21:00<32:12,53.47it/s] 41%|####      |70680/173481[21:11<32:02,53.47it/s] 46%|####5     |79436/173481[24:00<29:50,52.53it/s] 46%|####6     |80026/173481[24:11<29:39,52.53it/s] 51%|#####     |88356/173481[27:00<27:49,51.00it/s] 51%|#####1    |88890/173481[27:11<27:38,51.00it/s] 56%|#####6    |97351/173481[30:00<25:08,50.47it/s] 56%|#####6    |97880/173481[30:11<24:57,50.47it/s] 61%|######1   |106071/173481[33:00<22:43,49.43it/s] 61%|######1   |106625/173481[33:11<22:32,49.43it/s] 66%|######6   |114940/173481[36:00<19:46,49.35it/s] 67%|######6   |115532/173481[36:11<19:34,49.35it/s] 72%|#######1  |124296/173481[39:00<16:11,50.63it/s] 72%|#######1  |124898/173481[39:12<15:59,50.63it/s] 77%|#######6  |133316/173481[42:00<13:17,50.36it/s] 77%|#######7  |133889/173481[42:12<13:06,50.36it/s] 82%|########2 |142491/173481[45:00<10:11,50.66it/s] 83%|########2 |143135/173481[45:12<09:59,50.66it/s] 87%|########7 |151651/173481[48:00<07:09,50.77it/s] 88%|########7 |152316/173481[48:12<06:56,50.77it/s] 93%|#########2|161151/173481[51:00<03:58,51.75it/s] 93%|#########3|161745/173481[51:12<03:46,51.75it/s] 98%|#########7|169772/173481[54:00<01:14,49.75it/s] 98%|#########8|170334/173481[54:12<01:03,49.75it/s]100%|##########|173481/173481[55:18<00:00,52.28it/s]
[32m[0328 16:57:55 @base.py:257][0m Epoch 6 (global_step 11449746) finished, time:3318.31 sec.
[32m[0328 16:57:55 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.43it/s]
5
[32m[0328 17:00:00 @monitor.py:363][0m QueueInput/queue_size: 0.52308
[32m[0328 17:00:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.082
[32m[0328 17:00:00 @monitor.py:363][0m activation-summaries/output-rms: 0.036244
[32m[0328 17:00:00 @monitor.py:363][0m cross_entropy_loss: 2.4605
[32m[0328 17:00:00 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 17:00:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 17:00:00 @monitor.py:363][0m train-error-top1: 0.61014
[32m[0328 17:00:00 @monitor.py:363][0m val-error-top1: 0.60888
[32m[0328 17:00:00 @monitor.py:363][0m val-utt-error: 0.22989
[32m[0328 17:00:00 @monitor.py:363][0m validation_cost: 2.4777
[32m[0328 17:00:00 @monitor.py:363][0m wd_cost: 5.9531e-16
[32m[0328 17:00:00 @group.py:42][0m Callbacks took 124.719 sec in total. InferenceRunner: 124.308sec
[32m[0328 17:00:00 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11160/173481[03:00<43:38,61.99it/s]  7%|6         |11704/173481[03:10<43:29,61.99it/s] 12%|#1        |20312/173481[06:00<45:41,55.87it/s] 12%|#2        |20832/173481[06:10<45:32,55.87it/s] 17%|#6        |29485/173481[09:00<45:02,53.29it/s] 17%|#7        |30040/173481[09:10<44:51,53.29it/s] 22%|##1       |38068/173481[12:00<44:50,50.33it/s] 22%|##2       |38549/173481[12:10<44:40,50.33it/s] 27%|##6       |46410/173481[15:00<43:53,48.25it/s] 27%|##7       |46915/173481[15:10<43:42,48.25it/s] 32%|###1      |55090/173481[18:00<40:54,48.23it/s] 32%|###2      |55637/173481[18:11<40:43,48.23it/s] 37%|###6      |64093/173481[21:00<37:07,49.11it/s] 37%|###7      |64584/173481[21:11<36:57,49.11it/s] 42%|####2     |73265/173481[24:00<33:23,50.01it/s] 43%|####2     |73851/173481[24:11<33:12,50.01it/s] 48%|####7     |82550/173481[27:00<29:50,50.78it/s] 48%|####7     |83156/173481[27:11<29:38,50.78it/s] 53%|#####3    |92042/173481[30:00<26:14,51.74it/s] 53%|#####3    |92644/173481[30:11<26:02,51.74it/s] 58%|#####8    |101472/173481[33:00<23:03,52.06it/s] 59%|#####8    |102069/173481[33:11<22:51,52.06it/s] 64%|######3   |110815/173481[36:00<20:05,51.98it/s] 64%|######4   |111415/173481[36:12<19:53,51.98it/s] 69%|######9   |119759/173481[39:00<17:37,50.81it/s] 69%|######9   |120339/173481[39:12<17:25,50.81it/s] 74%|#######4  |128754/173481[42:00<14:47,50.39it/s] 75%|#######4  |129349/173481[42:12<14:35,50.39it/s] 79%|#######9  |137504/173481[45:00<12:07,49.48it/s] 80%|#######9  |138099/173481[45:12<11:55,49.48it/s] 84%|########4 |146390/173481[48:00<09:08,49.42it/s] 85%|########4 |147024/173481[48:12<08:55,49.42it/s] 90%|########9 |155518/173481[51:00<05:58,50.06it/s] 90%|######### |156184/173481[51:12<05:45,50.06it/s] 95%|#########5|164980/173481[54:00<02:45,51.27it/s] 95%|#########5|165671/173481[54:13<02:32,51.27it/s]100%|##########|173481/173481[56:32<00:00,51.14it/s]
[32m[0328 17:56:32 @base.py:257][0m Epoch 7 (global_step 11623227) finished, time:3392.56 sec.
[32m[0328 17:56:32 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-11623227.
[32m[0328 17:56:33 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.72it/s]
6
[32m[0328 17:58:37 @monitor.py:363][0m QueueInput/queue_size: 0.36919
[32m[0328 17:58:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.445
[32m[0328 17:58:37 @monitor.py:363][0m activation-summaries/output-rms: 0.035601
[32m[0328 17:58:37 @monitor.py:363][0m cross_entropy_loss: 2.5253
[32m[0328 17:58:37 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 17:58:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 17:58:37 @monitor.py:363][0m train-error-top1: 0.62233
[32m[0328 17:58:37 @monitor.py:363][0m val-error-top1: 0.61219
[32m[0328 17:58:37 @monitor.py:363][0m val-utt-error: 0.23483
[32m[0328 17:58:37 @monitor.py:363][0m validation_cost: 2.5
[32m[0328 17:58:37 @monitor.py:363][0m wd_cost: 1.1906e-16
[32m[0328 17:58:37 @group.py:42][0m Callbacks took 124.797 sec in total. InferenceRunner: 124.071sec
[32m[0328 17:58:37 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13184/173481[03:00<36:29,73.22it/s]  8%|7         |13749/173481[03:10<36:21,73.22it/s] 13%|#3        |23250/173481[06:00<39:29,63.41it/s] 14%|#3        |23763/173481[06:10<39:21,63.41it/s] 19%|#8        |32104/173481[09:00<42:32,55.40it/s] 19%|#8        |32635/173481[09:10<42:22,55.40it/s] 24%|##3       |41545/173481[12:00<40:48,53.88it/s] 24%|##4       |42099/173481[12:10<40:38,53.88it/s] 29%|##9       |51168/173481[15:00<37:58,53.67it/s] 30%|##9       |51713/173481[15:10<37:48,53.67it/s] 35%|###4      |60396/173481[18:00<35:56,52.44it/s] 35%|###5      |60963/173481[18:11<35:45,52.44it/s] 41%|####      |70363/173481[21:00<31:54,53.87it/s] 41%|####      |71127/173481[21:11<31:40,53.87it/s] 47%|####6     |81199/173481[24:00<27:03,56.85it/s] 47%|####7     |81803/173481[24:11<26:52,56.85it/s] 52%|#####2    |90743/173481[27:00<25:07,54.87it/s] 53%|#####2    |91368/173481[27:11<24:56,54.87it/s] 58%|#####7    |100254/173481[30:00<22:40,53.83it/s] 58%|#####8    |100871/173481[30:11<22:28,53.83it/s] 63%|######3   |109783/173481[33:00<19:53,53.38it/s] 64%|######3   |110415/173481[33:11<19:41,53.38it/s] 69%|######9   |119759/173481[36:00<16:28,54.37it/s] 69%|######9   |120404/173481[36:12<16:16,54.37it/s] 75%|#######4  |129822/173481[39:00<13:11,55.13it/s] 75%|#######5  |130498/173481[39:12<12:59,55.13it/s] 81%|########  |140159/173481[42:00<09:52,56.25it/s] 81%|########1 |140818/173481[42:12<09:40,56.25it/s] 87%|########6 |150170/173481[45:00<06:56,55.93it/s] 87%|########6 |150833/173481[45:12<06:44,55.93it/s] 92%|#########2|160104/173481[48:00<04:00,55.55it/s] 93%|#########2|160813/173481[48:12<03:48,55.55it/s] 98%|#########8|170084/173481[51:00<01:01,55.50it/s] 98%|#########8|170793/173481[51:12<00:48,55.50it/s]100%|##########|173481/173481[52:01<00:00,55.58it/s]
[32m[0328 18:50:38 @base.py:257][0m Epoch 8 (global_step 11796708) finished, time:3121.42 sec.
[32m[0328 18:50:39 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,162.20it/s]
7
[32m[0328 18:52:35 @monitor.py:363][0m QueueInput/queue_size: 0.4304
[32m[0328 18:52:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.084
[32m[0328 18:52:35 @monitor.py:363][0m activation-summaries/output-rms: 0.035313
[32m[0328 18:52:35 @monitor.py:363][0m cross_entropy_loss: 2.4912
[32m[0328 18:52:35 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 18:52:35 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 18:52:35 @monitor.py:363][0m train-error-top1: 0.6107
[32m[0328 18:52:35 @monitor.py:363][0m val-error-top1: 0.61109
[32m[0328 18:52:35 @monitor.py:363][0m val-utt-error: 0.23016
[32m[0328 18:52:35 @monitor.py:363][0m validation_cost: 2.4936
[32m[0328 18:52:35 @monitor.py:363][0m wd_cost: 1.1906e-16
[32m[0328 18:52:35 @group.py:42][0m Callbacks took 116.371 sec in total. InferenceRunner: 116.058sec
[32m[0328 18:52:35 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11916/173481[03:00<40:40,66.20it/s]  7%|7         |12456/173481[03:10<40:32,66.20it/s] 12%|#2        |21024/173481[06:00<44:18,57.36it/s] 12%|#2        |21584/173481[06:10<44:08,57.36it/s] 18%|#7        |31148/173481[09:00<41:46,56.79it/s] 18%|#8        |31724/173481[09:10<41:36,56.79it/s] 24%|##4       |41767/173481[12:00<37:56,57.87it/s] 24%|##4       |42457/173481[12:10<37:44,57.87it/s] 31%|###       |53469/173481[15:00<32:39,61.23it/s] 31%|###1      |54125/173481[15:10<32:29,61.23it/s] 37%|###7      |64637/173481[18:00<29:25,61.64it/s] 38%|###7      |65340/173481[18:11<29:14,61.64it/s] 44%|####3     |75903/173481[21:00<26:11,62.10it/s] 44%|####4     |76620/173481[21:11<25:59,62.10it/s] 50%|####9     |86698/173481[24:00<23:42,61.01it/s] 50%|#####     |87362/173481[24:11<23:31,61.01it/s] 56%|#####6    |97778/173481[27:00<20:35,61.28it/s] 57%|#####6    |98477/173481[27:11<20:23,61.28it/s] 63%|######2   |108840/173481[30:00<17:33,61.37it/s] 63%|######3   |109543/173481[30:11<17:21,61.37it/s] 69%|######9   |119888/173481[33:00<14:33,61.37it/s] 70%|######9   |120617/173481[33:11<14:21,61.37it/s] 75%|#######5  |130923/173481[36:00<11:33,61.33it/s] 76%|#######5  |131676/173481[36:12<11:21,61.33it/s] 82%|########1 |142230/173481[39:00<08:23,62.07it/s] 82%|########2 |142996/173481[39:12<08:11,62.07it/s] 88%|########8 |153516/173481[42:00<05:20,62.38it/s] 89%|########8 |154310/173481[42:12<05:07,62.38it/s] 95%|#########4|164765/173481[45:00<02:19,62.44it/s] 95%|#########5|165482/173481[45:12<02:08,62.44it/s]100%|##########|173481/173481[47:30<00:00,60.86it/s]
[32m[0328 19:40:05 @base.py:257][0m Epoch 9 (global_step 11970189) finished, time:2850.41 sec.
[32m[0328 19:40:06 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.67it/s]
8
[32m[0328 19:42:09 @monitor.py:363][0m QueueInput/queue_size: 1.0918
[32m[0328 19:42:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.188
[32m[0328 19:42:09 @monitor.py:363][0m activation-summaries/output-rms: 0.035068
[32m[0328 19:42:09 @monitor.py:363][0m cross_entropy_loss: 2.4713
[32m[0328 19:42:09 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 19:42:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 19:42:09 @monitor.py:363][0m train-error-top1: 0.6062
[32m[0328 19:42:09 @monitor.py:363][0m val-error-top1: 0.61008
[32m[0328 19:42:09 @monitor.py:363][0m val-utt-error: 0.23133
[32m[0328 19:42:09 @monitor.py:363][0m validation_cost: 2.4877
[32m[0328 19:42:09 @monitor.py:363][0m wd_cost: 1.1906e-16
[32m[0328 19:42:09 @group.py:42][0m Callbacks took 124.171 sec in total. InferenceRunner: 123.292sec
[32m[0328 19:42:09 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13077/173481[03:00<36:48,72.64it/s]  8%|7         |13701/173481[03:10<36:39,72.64it/s] 14%|#3        |23783/173481[06:00<38:08,65.40it/s] 14%|#4        |24428/173481[06:10<37:59,65.40it/s] 20%|##        |35047/173481[09:00<36:04,63.96it/s] 21%|##        |35709/173481[09:10<35:54,63.96it/s] 27%|##6       |46229/173481[12:00<33:39,63.02it/s] 27%|##7       |46868/173481[12:10<33:28,63.02it/s] 33%|###2      |57032/173481[15:00<31:34,61.48it/s] 33%|###3      |57659/173481[15:10<31:23,61.48it/s] 39%|###9      |67777/173481[18:00<29:05,60.57it/s] 39%|###9      |68445/173481[18:11<28:54,60.57it/s] 45%|####5     |78755/173481[21:00<25:58,60.78it/s] 46%|####5     |79461/173481[21:11<25:46,60.78it/s] 52%|#####1    |90005/173481[24:00<22:34,61.63it/s] 52%|#####2    |90657/173481[24:11<22:23,61.63it/s] 58%|#####7    |100267/173481[27:00<20:36,59.22it/s] 58%|#####8    |100931/173481[27:11<20:25,59.22it/s] 64%|######3   |110529/173481[30:00<18:03,58.10it/s] 64%|######4   |111163/173481[30:11<17:52,58.10it/s] 69%|######9   |120405/173481[33:00<15:40,56.43it/s] 70%|######9   |121071/173481[33:11<15:28,56.43it/s] 75%|#######5  |130467/173481[36:00<12:45,56.16it/s] 76%|#######5  |131151/173481[36:12<12:33,56.16it/s] 81%|########1 |141147/173481[39:00<09:20,57.70it/s] 82%|########1 |141845/173481[39:12<09:08,57.70it/s] 88%|########7 |152192/173481[42:00<05:57,59.47it/s] 88%|########8 |152921/173481[42:12<05:45,59.47it/s] 94%|#########3|162848/173481[45:00<02:59,59.33it/s] 94%|#########4|163521/173481[45:12<02:47,59.33it/s]100%|#########9|172982/173481[48:00<00:08,57.77it/s][32m[0328 20:30:19 @base.py:257][0m Epoch 10 (global_step 12143670) finished, time:2889.72 sec.
100%|##########|173481/173481[48:09<00:00,60.03it/s]
[32m[0328 20:30:19 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-12143670.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.64it/s]
9
[32m[0328 20:32:23 @monitor.py:363][0m QueueInput/queue_size: 0.54061
[32m[0328 20:32:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.374
[32m[0328 20:32:23 @monitor.py:363][0m activation-summaries/output-rms: 0.037196
[32m[0328 20:32:23 @monitor.py:363][0m cross_entropy_loss: 2.4601
[32m[0328 20:32:23 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 20:32:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 20:32:23 @monitor.py:363][0m train-error-top1: 0.60329
[32m[0328 20:32:23 @monitor.py:363][0m val-error-top1: 0.61024
[32m[0328 20:32:23 @monitor.py:363][0m val-utt-error: 0.23191
[32m[0328 20:32:23 @monitor.py:363][0m validation_cost: 2.4856
[32m[0328 20:32:23 @monitor.py:363][0m wd_cost: 2.3812e-17
[32m[0328 20:32:23 @group.py:42][0m Callbacks took 123.575 sec in total. InferenceRunner: 123.321sec
[32m[0328 20:32:23 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13192/173481[03:00<36:27,73.28it/s]  8%|7         |13825/173481[03:10<36:18,73.28it/s] 14%|#4        |24320/173481[06:00<37:04,67.07it/s] 14%|#4        |24960/173481[06:10<36:54,67.07it/s] 20%|##        |35259/173481[09:00<36:07,63.76it/s] 21%|##        |35878/173481[09:10<35:58,63.76it/s] 26%|##6       |45916/173481[12:00<34:37,61.39it/s] 27%|##6       |46562/173481[12:10<34:27,61.39it/s] 33%|###2      |56578/173481[15:00<32:18,60.29it/s] 33%|###3      |57255/173481[15:10<32:07,60.29it/s] 39%|###8      |67563/173481[18:00<29:06,60.66it/s] 39%|###9      |68195/173481[18:11<28:55,60.66it/s] 45%|####4     |77886/173481[21:00<27:01,58.95it/s] 45%|####5     |78550/173481[21:11<26:50,58.95it/s] 51%|#####     |88356/173481[24:00<24:13,58.55it/s] 51%|#####1    |88993/173481[24:11<24:02,58.55it/s] 57%|#####6    |98735/173481[27:00<21:26,58.10it/s] 57%|#####7    |99350/173481[27:11<21:15,58.10it/s] 63%|######2   |109011/173481[30:00<18:39,57.59it/s] 63%|######3   |109706/173481[30:11<18:27,57.59it/s] 69%|######9   |119702/173481[33:00<15:19,58.48it/s] 69%|######9   |120385/173481[33:11<15:07,58.48it/s] 75%|#######5  |130381/173481[36:00<12:11,58.89it/s] 76%|#######5  |131056/173481[36:12<12:00,58.89it/s] 81%|########1 |141111/173481[39:00<09:06,59.24it/s] 82%|########1 |141841/173481[39:12<08:54,59.24it/s] 87%|########7 |151540/173481[42:00<06:14,58.58it/s] 88%|########7 |152258/173481[42:12<06:02,58.58it/s] 93%|#########3|161918/173481[45:00<03:18,58.11it/s] 94%|#########3|162605/173481[45:12<03:07,58.11it/s] 99%|#########9|171999/173481[48:00<00:25,57.04it/s]100%|#########9|172685/173481[48:12<00:13,57.04it/s]100%|##########|173481/173481[48:27<00:00,59.67it/s]
[32m[0328 21:20:50 @base.py:257][0m Epoch 11 (global_step 12317151) finished, time:2907.27 sec.
[32m[0328 21:20:50 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.68it/s]
10
[32m[0328 21:22:47 @monitor.py:363][0m QueueInput/queue_size: 0.70526
[32m[0328 21:22:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.082
[32m[0328 21:22:47 @monitor.py:363][0m activation-summaries/output-rms: 0.036245
[32m[0328 21:22:47 @monitor.py:363][0m cross_entropy_loss: 2.4604
[32m[0328 21:22:47 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 21:22:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 21:22:47 @monitor.py:363][0m train-error-top1: 0.6102
[32m[0328 21:22:47 @monitor.py:363][0m val-error-top1: 0.60886
[32m[0328 21:22:47 @monitor.py:363][0m val-utt-error: 0.22973
[32m[0328 21:22:47 @monitor.py:363][0m validation_cost: 2.4776
[32m[0328 21:22:47 @monitor.py:363][0m wd_cost: 2.3812e-17
[32m[0328 21:22:47 @group.py:42][0m Callbacks took 116.743 sec in total. InferenceRunner: 116.430sec
[32m[0328 21:22:47 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12470/173481[03:00<38:45,69.25it/s]  8%|7         |13063/173481[03:10<38:36,69.25it/s] 13%|#3        |23085/173481[06:00<39:21,63.70it/s] 14%|#3        |23717/173481[06:10<39:11,63.70it/s] 19%|#9        |33658/173481[09:00<38:07,61.12it/s] 20%|#9        |34244/173481[09:10<37:58,61.12it/s] 25%|##4       |43275/173481[12:00<38:03,57.01it/s] 25%|##5       |43874/173481[12:10<37:53,57.01it/s] 31%|###       |53450/173481[15:00<35:14,56.76it/s] 31%|###1      |54099/173481[15:10<35:03,56.76it/s] 37%|###6      |64120/173481[18:00<31:25,57.99it/s] 37%|###7      |64694/173481[18:10<31:16,57.99it/s] 43%|####3     |75062/173481[21:00<27:38,59.36it/s] 44%|####3     |75710/173481[21:11<27:27,59.36it/s] 49%|####9     |85619/173481[24:00<24:49,59.00it/s] 50%|####9     |86266/173481[24:11<24:38,59.00it/s] 55%|#####5    |96170/173481[27:00<21:54,58.81it/s] 56%|#####5    |96794/173481[27:11<21:44,58.81it/s] 61%|######1   |106442/173481[30:00<19:17,57.92it/s] 62%|######1   |107089/173481[30:11<19:06,57.92it/s] 67%|######7   |116715/173481[33:00<16:27,57.49it/s] 68%|######7   |117354/173481[33:11<16:16,57.49it/s] 73%|#######3  |126814/173481[36:00<13:41,56.79it/s] 73%|#######3  |127469/173481[36:11<13:30,56.79it/s] 79%|#######9  |137331/173481[39:00<10:27,57.60it/s] 80%|#######9  |138047/173481[39:11<10:15,57.60it/s] 85%|########5 |148128/173481[42:00<07:11,58.77it/s] 86%|########5 |148817/173481[42:12<06:59,58.77it/s] 92%|#########1|158835/173481[45:00<04:07,59.12it/s] 92%|#########1|159574/173481[45:12<03:55,59.12it/s] 98%|#########7|169425/173481[48:00<01:08,58.97it/s] 98%|#########8|170130/173481[48:12<00:56,58.97it/s]100%|##########|173481/173481[49:09<00:00,58.81it/s]
[32m[0328 22:11:57 @base.py:257][0m Epoch 12 (global_step 12490632) finished, time:2949.99 sec.
[32m[0328 22:11:57 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-12490632.
[32m[0328 22:11:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,154.44it/s]
11
[32m[0328 22:13:59 @monitor.py:363][0m QueueInput/queue_size: 1.2806
[32m[0328 22:13:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.445
[32m[0328 22:13:59 @monitor.py:363][0m activation-summaries/output-rms: 0.035603
[32m[0328 22:13:59 @monitor.py:363][0m cross_entropy_loss: 2.5341
[32m[0328 22:13:59 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 22:13:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 22:13:59 @monitor.py:363][0m train-error-top1: 0.62165
[32m[0328 22:13:59 @monitor.py:363][0m val-error-top1: 0.61224
[32m[0328 22:13:59 @monitor.py:363][0m val-utt-error: 0.23515
[32m[0328 22:13:59 @monitor.py:363][0m validation_cost: 2.4989
[32m[0328 22:13:59 @monitor.py:363][0m wd_cost: 4.7625e-18
[32m[0328 22:13:59 @group.py:42][0m Callbacks took 122.523 sec in total. InferenceRunner: 121.891sec
[32m[0328 22:13:59 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14034/173481[03:00<34:05,77.93it/s]  8%|8         |14669/173481[03:10<33:57,77.93it/s] 14%|#4        |24687/173481[06:00<36:51,67.27it/s] 15%|#4        |25212/173481[06:10<36:43,67.27it/s] 20%|#9        |34391/173481[09:00<38:43,59.85it/s] 20%|##        |35013/173481[09:10<38:33,59.85it/s] 26%|##5       |44642/173481[12:00<36:47,58.37it/s] 26%|##6       |45274/173481[12:10<36:36,58.37it/s] 32%|###1      |55209/173481[15:00<33:40,58.53it/s] 32%|###2      |55828/173481[15:10<33:30,58.53it/s] 38%|###7      |65835/173481[18:00<30:31,58.78it/s] 38%|###8      |66563/173481[18:11<30:18,58.78it/s] 45%|####4     |77694/173481[21:00<25:41,62.13it/s] 45%|####5     |78428/173481[21:11<25:29,62.13it/s] 51%|#####1    |88721/173481[24:00<22:53,61.69it/s] 52%|#####1    |89388/173481[24:11<22:43,61.69it/s] 57%|#####7    |99245/173481[27:00<20:36,60.03it/s] 58%|#####7    |99923/173481[27:11<20:25,60.03it/s] 63%|######3   |109882/173481[30:00<17:47,59.56it/s] 64%|######3   |110563/173481[30:11<17:36,59.56it/s] 70%|######9   |120748/173481[33:00<14:39,59.96it/s] 70%|######9   |121436/173481[33:11<14:27,59.96it/s] 76%|#######5  |131504/173481[36:00<11:41,59.86it/s] 76%|#######6  |132233/173481[36:11<11:29,59.86it/s] 82%|########2 |142520/173481[39:00<08:31,60.52it/s] 83%|########2 |143244/173481[39:12<08:19,60.52it/s] 89%|########8 |153615/173481[42:00<05:25,61.07it/s] 89%|########8 |154380/173481[42:12<05:12,61.07it/s] 95%|#########5|164959/173481[45:00<02:17,62.03it/s] 96%|#########5|165728/173481[45:12<02:04,62.03it/s]100%|##########|173481/173481[47:11<00:00,61.27it/s]
[32m[0328 23:01:10 @base.py:257][0m Epoch 13 (global_step 12664113) finished, time:2831.21 sec.
[32m[0328 23:01:11 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.00it/s]
12
[32m[0328 23:03:14 @monitor.py:363][0m QueueInput/queue_size: 0.54411
[32m[0328 23:03:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.084
[32m[0328 23:03:14 @monitor.py:363][0m activation-summaries/output-rms: 0.035314
[32m[0328 23:03:14 @monitor.py:363][0m cross_entropy_loss: 2.4912
[32m[0328 23:03:14 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 23:03:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 23:03:14 @monitor.py:363][0m train-error-top1: 0.6107
[32m[0328 23:03:14 @monitor.py:363][0m val-error-top1: 0.61108
[32m[0328 23:03:14 @monitor.py:363][0m val-utt-error: 0.22994
[32m[0328 23:03:14 @monitor.py:363][0m validation_cost: 2.4936
[32m[0328 23:03:14 @monitor.py:363][0m wd_cost: 4.7625e-18
[32m[0328 23:03:14 @group.py:42][0m Callbacks took 124.084 sec in total. InferenceRunner: 123.843sec
[32m[0328 23:03:14 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13559/173481[03:00<35:23,75.33it/s]  8%|8         |14212/173481[03:10<35:14,75.33it/s] 14%|#3        |24283/173481[06:00<37:23,66.51it/s] 14%|#4        |24883/173481[06:10<37:14,66.51it/s] 20%|##        |35283/173481[09:00<36:09,63.70it/s] 21%|##        |35922/173481[09:10<35:59,63.70it/s] 27%|##6       |46562/173481[12:00<33:29,63.17it/s] 27%|##7       |47252/173481[12:10<33:18,63.17it/s] 33%|###3      |57784/173481[15:00<30:43,62.75it/s] 34%|###3      |58452/173481[15:10<30:33,62.75it/s] 40%|###9      |69148/173481[18:00<27:37,62.94it/s] 40%|####      |69847/173481[18:11<27:26,62.94it/s] 46%|####6     |80532/173481[21:00<24:33,63.09it/s] 47%|####6     |81223/173481[21:11<24:22,63.09it/s] 53%|#####2    |91785/173481[24:00<21:40,62.80it/s] 53%|#####3    |92463/173481[24:11<21:30,62.80it/s] 59%|#####9    |103024/173481[27:00<18:45,62.62it/s] 60%|#####9    |103682/173481[27:11<18:34,62.62it/s] 66%|######5   |114162/173481[30:00<15:52,62.25it/s] 66%|######6   |114857/173481[30:11<15:41,62.25it/s] 72%|#######2  |125044/173481[33:00<13:09,61.34it/s] 72%|#######2  |125759/173481[33:11<12:58,61.34it/s] 78%|#######8  |136175/173481[36:00<10:05,61.59it/s] 79%|#######8  |136891/173481[36:11<09:54,61.59it/s] 85%|########5 |147489/173481[39:00<06:57,62.21it/s] 85%|########5 |148222/173481[39:12<06:46,62.21it/s] 92%|#########1|158835/173481[42:00<03:53,62.62it/s] 92%|#########1|159600/173481[42:12<03:41,62.62it/s] 98%|#########7|169688/173481[45:00<01:01,61.43it/s] 98%|#########8|170377/173481[45:12<00:50,61.43it/s]100%|##########|173481/173481[46:05<00:00,62.72it/s]
[32m[0328 23:49:20 @base.py:257][0m Epoch 14 (global_step 12837594) finished, time:2765.75 sec.
[32m[0328 23:49:20 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.69it/s]
13
[32m[0328 23:51:24 @monitor.py:363][0m QueueInput/queue_size: 0.40562
[32m[0328 23:51:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.188
[32m[0328 23:51:24 @monitor.py:363][0m activation-summaries/output-rms: 0.035068
[32m[0328 23:51:24 @monitor.py:363][0m cross_entropy_loss: 2.4699
[32m[0328 23:51:24 @monitor.py:363][0m lr: 7.4506e-12
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0328 23:51:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0328 23:51:24 @monitor.py:363][0m train-error-top1: 0.60546
[32m[0328 23:51:24 @monitor.py:363][0m val-error-top1: 0.61008
[32m[0328 23:51:24 @monitor.py:363][0m val-utt-error: 0.23117
[32m[0328 23:51:24 @monitor.py:363][0m validation_cost: 2.4874
[32m[0328 23:51:24 @monitor.py:363][0m wd_cost: 4.7625e-18
[32m[0328 23:51:24 @group.py:42][0m Callbacks took 123.711 sec in total. InferenceRunner: 123.280sec
[32m[0328 23:51:24 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13262/173481[03:00<36:15,73.66it/s]  8%|7         |13872/173481[03:10<36:06,73.66it/s] 14%|#3        |24137/173481[06:00<37:29,66.38it/s] 14%|#4        |24786/173481[06:10<37:19,66.38it/s] 21%|##        |35755/173481[09:00<35:04,65.45it/s] 21%|##1       |36440/173481[09:10<34:53,65.45it/s] 27%|##7       |46872/173481[12:00<33:12,63.55it/s] 27%|##7       |47491/173481[12:10<33:02,63.55it/s] 33%|###3      |58022/173481[15:00<30:40,62.72it/s] 34%|###3      |58679/173481[15:10<30:30,62.72it/s] 40%|###9      |69272/173481[18:00<27:44,62.61it/s] 40%|####      |69931/173481[18:11<27:33,62.61it/s] 46%|####6     |80204/173481[21:00<25:12,61.66it/s] 47%|####6     |80862/173481[21:11<25:02,61.66it/s] 53%|#####2    |91142/173481[24:00<22:25,61.20it/s] 53%|#####2    |91791/173481[24:11<22:14,61.20it/s] 59%|#####8    |101954/173481[27:00<19:39,60.63it/s] 59%|#####9    |102647/173481[27:11<19:28,60.63it/s] 65%|######4   |112608/173481[30:00<16:56,59.90it/s] 65%|######5   |113291/173481[30:11<16:44,59.90it/s] 71%|#######1  |123272/173481[33:00<14:02,59.57it/s] 71%|#######1  |124000/173481[33:11<13:50,59.57it/s] 77%|#######7  |134147/173481[36:00<10:55,59.98it/s] 78%|#######7  |134889/173481[36:12<10:43,59.98it/s] 84%|########3 |145050/173481[39:00<07:51,60.28it/s] 84%|########4 |145781/173481[39:12<07:39,60.28it/s] 90%|########9 |156038/173481[42:00<04:47,60.66it/s] 90%|######### |156796/173481[42:12<04:35,60.66it/s] 96%|#########6|166940/173481[45:00<01:47,60.61it/s] 97%|#########6|167693/173481[45:12<01:35,60.61it/s]100%|##########|173481/173481[46:50<00:00,61.72it/s]
[32m[0329 00:38:15 @base.py:257][0m Epoch 15 (global_step 13011075) finished, time:2811.00 sec.
[32m[0329 00:38:15 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-13011075.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.29it/s]
14
[32m[0329 00:40:20 @monitor.py:363][0m QueueInput/queue_size: 5.8206
[32m[0329 00:40:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.374
[32m[0329 00:40:20 @monitor.py:363][0m activation-summaries/output-rms: 0.037196
[32m[0329 00:40:20 @monitor.py:363][0m cross_entropy_loss: 2.4617
[32m[0329 00:40:20 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 00:40:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 00:40:20 @monitor.py:363][0m train-error-top1: 0.6039
[32m[0329 00:40:20 @monitor.py:363][0m val-error-top1: 0.61025
[32m[0329 00:40:20 @monitor.py:363][0m val-utt-error: 0.23196
[32m[0329 00:40:20 @monitor.py:363][0m validation_cost: 2.4857
[32m[0329 00:40:20 @monitor.py:363][0m wd_cost: 9.525e-19
[32m[0329 00:40:20 @group.py:42][0m Callbacks took 124.818 sec in total. InferenceRunner: 124.421sec
[32m[0329 00:40:20 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13471/173481[03:00<35:38,74.83it/s]  8%|8         |14075/173481[03:10<35:30,74.83it/s] 14%|#3        |24277/173481[06:00<37:19,66.62it/s] 14%|#4        |24901/173481[06:10<37:10,66.62it/s] 20%|##        |34873/173481[09:00<36:57,62.50it/s] 20%|##        |35489/173481[09:10<36:47,62.50it/s] 26%|##6       |45287/173481[12:00<35:33,60.09it/s] 26%|##6       |45883/173481[12:10<35:23,60.09it/s] 32%|###2      |55536/173481[15:00<33:37,58.46it/s] 32%|###2      |56180/173481[15:10<33:26,58.46it/s] 38%|###8      |66236/173481[18:00<30:19,58.94it/s] 39%|###8      |66915/173481[18:11<30:07,58.94it/s] 44%|####4     |76496/173481[21:00<27:53,57.95it/s] 44%|####4     |77135/173481[21:11<27:42,57.95it/s] 50%|#####     |87080/173481[24:00<24:40,58.37it/s] 51%|#####     |87756/173481[24:11<24:28,58.37it/s] 56%|#####6    |97621/173481[27:00<21:37,58.46it/s] 57%|#####6    |98281/173481[27:11<21:26,58.46it/s] 62%|######2   |108108/173481[30:00<18:40,58.36it/s] 63%|######2   |108765/173481[30:11<18:28,58.36it/s] 69%|######8   |118863/173481[33:00<15:25,59.05it/s] 69%|######8   |119571/173481[33:11<15:13,59.05it/s] 75%|#######4  |129668/173481[36:00<12:15,59.53it/s] 75%|#######5  |130359/173481[36:11<12:04,59.53it/s] 81%|########1 |140556/173481[39:00<09:08,60.00it/s] 81%|########1 |141315/173481[39:12<08:56,60.00it/s] 87%|########7 |151311/173481[42:00<06:10,59.87it/s] 88%|########7 |152016/173481[42:12<05:58,59.87it/s] 93%|#########3|161581/173481[45:00<03:23,58.42it/s] 94%|#########3|162272/173481[45:12<03:11,58.42it/s] 99%|#########9|171922/173481[48:00<00:26,57.93it/s]100%|#########9|172621/173481[48:12<00:14,57.93it/s]100%|##########|173481/173481[48:27<00:00,59.67it/s]
[32m[0329 01:28:47 @base.py:257][0m Epoch 16 (global_step 13184556) finished, time:2907.13 sec.
[32m[0329 01:28:47 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.21it/s]
15
[32m[0329 01:30:52 @monitor.py:363][0m QueueInput/queue_size: 0.59587
[32m[0329 01:30:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.082
[32m[0329 01:30:52 @monitor.py:363][0m activation-summaries/output-rms: 0.036246
[32m[0329 01:30:52 @monitor.py:363][0m cross_entropy_loss: 2.4605
[32m[0329 01:30:52 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 01:30:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 01:30:52 @monitor.py:363][0m train-error-top1: 0.61026
[32m[0329 01:30:52 @monitor.py:363][0m val-error-top1: 0.60887
[32m[0329 01:30:52 @monitor.py:363][0m val-utt-error: 0.22957
[32m[0329 01:30:52 @monitor.py:363][0m validation_cost: 2.4776
[32m[0329 01:30:52 @monitor.py:363][0m wd_cost: 9.525e-19
[32m[0329 01:30:52 @group.py:42][0m Callbacks took 125.658 sec in total. InferenceRunner: 125.313sec
[32m[0329 01:30:52 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |13010/173481[03:00<37:00,72.26it/s]  8%|7         |13614/173481[03:10<36:52,72.26it/s] 14%|#3        |23545/173481[06:00<38:38,64.67it/s] 14%|#3        |24137/173481[06:10<38:29,64.67it/s] 19%|#9        |33675/173481[09:00<38:43,60.18it/s] 20%|#9        |34248/173481[09:10<38:33,60.18it/s] 25%|##4       |43239/173481[12:00<38:27,56.44it/s] 25%|##5       |43815/173481[12:10<38:17,56.44it/s] 31%|###       |53202/173481[15:00<35:52,55.89it/s] 31%|###1      |53824/173481[15:10<35:41,55.89it/s] 37%|###6      |63527/173481[18:00<32:22,56.61it/s] 37%|###6      |64099/173481[18:11<32:12,56.61it/s] 43%|####2     |74019/173481[21:00<28:51,57.44it/s] 43%|####3     |74689/173481[21:11<28:39,57.44it/s] 49%|####8     |84580/173481[24:00<25:31,58.05it/s] 49%|####9     |85214/173481[24:11<25:20,58.05it/s] 55%|#####4    |95160/173481[27:00<22:20,58.41it/s] 55%|#####5    |95834/173481[27:11<22:09,58.41it/s] 61%|######    |105583/173481[30:00<19:27,58.15it/s] 61%|######1   |106279/173481[30:11<19:15,58.15it/s] 67%|######6   |116092/173481[33:00<16:24,58.27it/s] 67%|######7   |116758/173481[33:11<16:13,58.27it/s] 73%|#######2  |126620/173481[36:00<13:22,58.37it/s] 73%|#######3  |127319/173481[36:12<13:10,58.37it/s] 79%|#######9  |137230/173481[39:00<10:18,58.65it/s] 80%|#######9  |137944/173481[39:12<10:05,58.65it/s] 85%|########5 |147817/173481[42:00<07:16,58.73it/s] 86%|########5 |148571/173481[42:12<07:04,58.73it/s] 92%|#########1|158790/173481[45:00<04:05,59.81it/s] 92%|#########1|159574/173481[45:12<03:52,59.81it/s] 98%|#########7|169893/173481[48:00<00:59,60.73it/s] 98%|#########8|170656/173481[48:12<00:46,60.73it/s]100%|##########|173481/173481[48:57<00:00,59.05it/s]
[32m[0329 02:19:50 @base.py:257][0m Epoch 17 (global_step 13358037) finished, time:2937.72 sec.
[32m[0329 02:19:50 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,159.48it/s]
16
[32m[0329 02:21:49 @monitor.py:363][0m QueueInput/queue_size: 0.82051
[32m[0329 02:21:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.445
[32m[0329 02:21:49 @monitor.py:363][0m activation-summaries/output-rms: 0.035604
[32m[0329 02:21:49 @monitor.py:363][0m cross_entropy_loss: 2.5247
[32m[0329 02:21:49 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 02:21:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 02:21:49 @monitor.py:363][0m train-error-top1: 0.62212
[32m[0329 02:21:49 @monitor.py:363][0m val-error-top1: 0.61217
[32m[0329 02:21:49 @monitor.py:363][0m val-utt-error: 0.23473
[32m[0329 02:21:49 @monitor.py:363][0m validation_cost: 2.4999
[32m[0329 02:21:49 @monitor.py:363][0m wd_cost: 9.525e-19
[32m[0329 02:21:49 @group.py:42][0m Callbacks took 118.378 sec in total. InferenceRunner: 118.035sec
[32m[0329 02:21:49 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14999/173481[03:00<31:42,83.32it/s]  9%|9         |15648/173481[03:10<31:34,83.32it/s] 15%|#4        |25993/173481[06:00<34:52,70.48it/s] 15%|#5        |26614/173481[06:10<34:43,70.48it/s] 21%|##        |36352/173481[09:00<36:04,63.36it/s] 21%|##1       |36971/173481[09:10<35:54,63.36it/s] 27%|##7       |47437/173481[12:00<33:37,62.46it/s] 28%|##7       |48113/173481[12:10<33:27,62.46it/s] 33%|###3      |58084/173481[15:00<31:39,60.75it/s] 34%|###3      |58758/173481[15:10<31:28,60.75it/s] 40%|###9      |69254/173481[18:00<28:17,61.39it/s] 40%|####      |69968/173481[18:11<28:06,61.39it/s] 47%|####6     |81184/173481[21:00<24:08,63.74it/s] 47%|####7     |81839/173481[21:11<23:57,63.74it/s] 53%|#####3    |92004/173481[24:00<21:56,61.87it/s] 53%|#####3    |92659/173481[24:11<21:46,61.87it/s] 59%|#####9    |102549/173481[27:00<19:38,60.18it/s] 60%|#####9    |103246/173481[27:11<19:27,60.18it/s] 65%|######5   |113452/173481[30:00<16:34,60.37it/s] 66%|######5   |114129/173481[30:11<16:23,60.37it/s] 72%|#######1  |124359/173481[33:00<13:32,60.48it/s] 72%|#######2  |125061/173481[33:11<13:20,60.48it/s] 78%|#######8  |135335/173481[36:00<10:28,60.72it/s] 78%|#######8  |136088/173481[36:12<10:15,60.72it/s] 84%|########4 |146459/173481[39:00<07:21,61.25it/s] 85%|########4 |147200/173481[39:12<07:09,61.25it/s] 91%|######### |157583/173481[42:00<04:18,61.52it/s] 91%|#########1|158333/173481[42:12<04:06,61.52it/s] 97%|#########7|168865/173481[45:00<01:14,62.09it/s] 98%|#########7|169617/173481[45:12<01:02,62.09it/s]100%|##########|173481/173481[46:16<00:00,62.49it/s]
[32m[0329 03:08:05 @base.py:257][0m Epoch 18 (global_step 13531518) finished, time:2776.33 sec.
[32m[0329 03:08:05 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-13531518.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.51it/s]
17
[32m[0329 03:10:09 @monitor.py:363][0m QueueInput/queue_size: 0.75849
[32m[0329 03:10:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.084
[32m[0329 03:10:09 @monitor.py:363][0m activation-summaries/output-rms: 0.035314
[32m[0329 03:10:09 @monitor.py:363][0m cross_entropy_loss: 2.4911
[32m[0329 03:10:09 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 03:10:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 03:10:09 @monitor.py:363][0m train-error-top1: 0.61084
[32m[0329 03:10:09 @monitor.py:363][0m val-error-top1: 0.61108
[32m[0329 03:10:09 @monitor.py:363][0m val-utt-error: 0.2301
[32m[0329 03:10:09 @monitor.py:363][0m validation_cost: 2.4936
[32m[0329 03:10:09 @monitor.py:363][0m wd_cost: 1.905e-19
[32m[0329 03:10:09 @group.py:42][0m Callbacks took 124.484 sec in total. InferenceRunner: 124.243sec
[32m[0329 03:10:09 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13853/173481[03:00<34:34,76.94it/s]  8%|8         |14495/173481[03:10<34:26,76.94it/s] 14%|#4        |24294/173481[06:00<37:35,66.14it/s] 14%|#4        |24863/173481[06:10<37:26,66.14it/s] 20%|##        |35138/173481[09:00<36:34,63.05it/s] 21%|##        |35777/173481[09:10<36:24,63.05it/s] 27%|##6       |46383/173481[12:00<33:45,62.76it/s] 27%|##7       |47057/173481[12:10<33:34,62.76it/s] 33%|###3      |57405/173481[15:00<31:12,61.99it/s] 33%|###3      |58052/173481[15:10<31:02,61.99it/s] 39%|###9      |68448/173481[18:00<28:23,61.66it/s] 40%|###9      |69143/173481[18:11<28:12,61.66it/s] 46%|####5     |79409/173481[21:00<25:35,61.27it/s] 46%|####6     |80055/173481[21:11<25:24,61.27it/s] 52%|#####1    |90183/173481[24:00<22:55,60.56it/s] 52%|#####2    |90839/173481[24:11<22:44,60.56it/s] 58%|#####8    |101304/173481[27:00<19:40,61.16it/s] 59%|#####8    |101979/173481[27:11<19:29,61.16it/s] 65%|######4   |112137/173481[30:00<16:51,60.67it/s] 65%|######5   |112822/173481[30:11<16:39,60.67it/s] 71%|#######   |122864/173481[33:00<14:01,60.13it/s] 71%|#######1  |123531/173481[33:11<13:50,60.13it/s] 77%|#######6  |133465/173481[36:00<11:12,59.50it/s] 77%|#######7  |134194/173481[36:12<11:00,59.50it/s] 83%|########3 |144388/173481[39:00<08:04,60.08it/s] 84%|########3 |145157/173481[39:12<07:51,60.08it/s] 90%|########9 |155442/173481[42:00<04:56,60.74it/s] 90%|######### |156155/173481[42:12<04:45,60.74it/s] 96%|#########5|166308/173481[45:00<01:58,60.54it/s] 96%|#########6|167000/173481[45:12<01:47,60.54it/s]100%|##########|173481/173481[47:05<00:00,61.40it/s]
[32m[0329 03:57:15 @base.py:257][0m Epoch 19 (global_step 13704999) finished, time:2825.24 sec.
[32m[0329 03:57:15 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-13704999.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.38it/s]
18
[32m[0329 03:59:20 @monitor.py:363][0m QueueInput/queue_size: 0.36041
[32m[0329 03:59:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.188
[32m[0329 03:59:20 @monitor.py:363][0m activation-summaries/output-rms: 0.035068
[32m[0329 03:59:20 @monitor.py:363][0m cross_entropy_loss: 2.4699
[32m[0329 03:59:20 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 03:59:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 03:59:20 @monitor.py:363][0m train-error-top1: 0.60567
[32m[0329 03:59:20 @monitor.py:363][0m val-error-top1: 0.61008
[32m[0329 03:59:20 @monitor.py:363][0m val-utt-error: 0.23122
[32m[0329 03:59:20 @monitor.py:363][0m validation_cost: 2.4874
[32m[0329 03:59:20 @monitor.py:363][0m wd_cost: 1.905e-19
[32m[0329 03:59:20 @group.py:42][0m Callbacks took 125.537 sec in total. InferenceRunner: 125.182sec
[32m[0329 03:59:20 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13172/173481[03:00<36:31,73.16it/s]  8%|7         |13776/173481[03:10<36:22,73.16it/s] 14%|#3        |23757/173481[06:00<38:16,65.20it/s] 14%|#4        |24388/173481[06:10<38:06,65.20it/s] 20%|##        |35157/173481[09:00<35:52,64.25it/s] 21%|##        |35818/173481[09:10<35:42,64.25it/s] 27%|##6       |46412/173481[12:00<33:25,63.37it/s] 27%|##7       |47018/173481[12:10<33:15,63.37it/s] 33%|###3      |57530/173481[15:00<30:53,62.56it/s] 34%|###3      |58176/173481[15:10<30:43,62.56it/s] 40%|###9      |68586/173481[18:00<28:12,61.98it/s] 40%|###9      |69248/173481[18:11<28:01,61.98it/s] 46%|####5     |79570/173481[21:00<25:27,61.50it/s] 46%|####6     |80275/173481[21:11<25:15,61.50it/s] 52%|#####2    |90614/173481[24:00<22:29,61.43it/s] 53%|#####2    |91286/173481[24:11<22:18,61.43it/s] 59%|#####8    |101577/173481[27:00<19:35,61.16it/s] 59%|#####8    |102276/173481[27:11<19:24,61.16it/s] 65%|######4   |112532/173481[30:00<16:39,61.01it/s] 65%|######5   |113222/173481[30:11<16:27,61.01it/s] 71%|#######1  |123349/173481[33:00<13:47,60.55it/s] 72%|#######1  |124060/173481[33:11<13:36,60.55it/s] 77%|#######7  |134188/173481[36:00<10:50,60.38it/s] 78%|#######7  |134891/173481[36:12<10:39,60.38it/s] 84%|########3 |144861/173481[39:00<07:58,59.83it/s] 84%|########3 |145581/173481[39:12<07:46,59.83it/s] 90%|########9 |156048/173481[42:00<04:45,60.97it/s] 90%|######### |156846/173481[42:12<04:32,60.97it/s] 97%|#########6|168017/173481[45:00<01:25,63.61it/s] 97%|#########7|168904/173481[45:12<01:11,63.61it/s]100%|##########|173481/173481[46:15<00:00,62.51it/s]
[32m[0329 04:45:35 @base.py:257][0m Epoch 20 (global_step 13878480) finished, time:2775.04 sec.
[32m[0329 04:45:35 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-13878480.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.85it/s]
19
[32m[0329 04:47:40 @monitor.py:363][0m QueueInput/queue_size: 0.97949
[32m[0329 04:47:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.374
[32m[0329 04:47:40 @monitor.py:363][0m activation-summaries/output-rms: 0.037197
[32m[0329 04:47:40 @monitor.py:363][0m cross_entropy_loss: 2.4601
[32m[0329 04:47:40 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 04:47:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 04:47:40 @monitor.py:363][0m train-error-top1: 0.60353
[32m[0329 04:47:40 @monitor.py:363][0m val-error-top1: 0.61024
[32m[0329 04:47:40 @monitor.py:363][0m val-utt-error: 0.23202
[32m[0329 04:47:40 @monitor.py:363][0m validation_cost: 2.4856
[32m[0329 04:47:40 @monitor.py:363][0m wd_cost: 1.905e-19
[32m[0329 04:47:40 @group.py:42][0m Callbacks took 125.130 sec in total. InferenceRunner: 124.802sec
[32m[0329 04:47:40 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15842/173481[03:00<29:51,88.01it/s] 10%|9         |16719/173481[03:10<29:41,88.01it/s] 17%|#6        |28993/173481[06:00<30:09,79.84it/s] 17%|#7        |29580/173481[06:10<30:02,79.84it/s] 23%|##2       |39383/173481[09:00<33:21,67.00it/s] 23%|##3       |39989/173481[09:10<33:12,67.00it/s] 29%|##8       |49996/173481[12:00<32:48,62.72it/s] 29%|##9       |50610/173481[12:10<32:39,62.72it/s] 35%|###5      |60771/173481[15:00<30:40,61.25it/s] 35%|###5      |61410/173481[15:10<30:29,61.25it/s] 41%|####1     |71258/173481[18:00<28:31,59.72it/s] 41%|####1     |71879/173481[18:11<28:21,59.72it/s] 47%|####7     |81682/173481[21:00<26:01,58.80it/s] 47%|####7     |82340/173481[21:11<25:49,58.80it/s] 53%|#####3    |92226/173481[24:00<23:04,58.69it/s] 54%|#####3    |92886/173481[24:11<22:53,58.69it/s] 59%|#####9    |102676/173481[27:00<20:13,58.37it/s] 60%|#####9    |103328/173481[27:11<20:01,58.37it/s] 65%|######5   |113229/173481[30:00<17:09,58.50it/s] 66%|######5   |113910/173481[30:11<16:58,58.50it/s] 71%|#######1  |123903/173481[33:00<14:01,58.90it/s] 72%|#######1  |124660/173481[33:11<13:48,58.90it/s] 78%|#######7  |134855/173481[36:00<10:45,59.85it/s] 78%|#######8  |135625/173481[36:12<10:32,59.85it/s] 86%|########5 |148367/173481[39:00<06:17,66.60it/s] 86%|########6 |149428/173481[39:12<06:01,66.60it/s] 95%|#########4|164512/173481[42:00<01:57,76.44it/s] 95%|#########5|165584/173481[42:12<01:43,76.44it/s]100%|##########|173481/173481[43:37<00:00,66.27it/s]
[32m[0329 05:31:18 @base.py:257][0m Epoch 21 (global_step 14051961) finished, time:2617.65 sec.
[32m[0329 05:31:18 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-14051961.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,149.70it/s]
20
[32m[0329 05:33:24 @monitor.py:363][0m QueueInput/queue_size: 49.76
[32m[0329 05:33:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.339
[32m[0329 05:33:24 @monitor.py:363][0m activation-summaries/output-rms: 0.035145
[32m[0329 05:33:24 @monitor.py:363][0m cross_entropy_loss: 2.4717
[32m[0329 05:33:24 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 05:33:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 05:33:24 @monitor.py:363][0m train-error-top1: 0.61123
[32m[0329 05:33:24 @monitor.py:363][0m val-error-top1: 0.60892
[32m[0329 05:33:24 @monitor.py:363][0m val-utt-error: 0.22782
[32m[0329 05:33:24 @monitor.py:363][0m validation_cost: 2.4828
[32m[0329 05:33:24 @monitor.py:363][0m wd_cost: 3.81e-20
[32m[0329 05:33:24 @group.py:42][0m Callbacks took 126.010 sec in total. InferenceRunner: 125.749sec
[32m[0329 05:33:24 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13915/173481[03:00<34:24,77.30it/s]  8%|8         |14531/173481[03:10<34:16,77.30it/s] 14%|#4        |24752/173481[06:00<36:37,67.69it/s] 15%|#4        |25342/173481[06:10<36:28,67.69it/s] 20%|##        |34876/173481[09:00<37:36,61.44it/s] 20%|##        |35439/173481[09:10<37:26,61.44it/s] 26%|##5       |44604/173481[12:00<37:21,57.50it/s] 26%|##6       |45183/173481[12:10<37:11,57.50it/s] 32%|###1      |54711/173481[15:00<34:50,56.82it/s] 32%|###1      |55334/173481[15:10<34:39,56.82it/s] 38%|###7      |65120/173481[18:00<31:30,57.31it/s] 38%|###7      |65761/173481[18:11<31:19,57.31it/s] 44%|####3     |75819/173481[21:00<27:53,58.36it/s] 44%|####4     |76479/173481[21:11<27:42,58.36it/s] 50%|####9     |86410/173481[24:00<24:46,58.59it/s] 50%|#####     |87079/173481[24:11<24:34,58.59it/s] 56%|#####5    |97100/173481[27:00<21:34,58.99it/s] 56%|#####6    |97751/173481[27:11<21:23,58.99it/s] 62%|######2   |107670/173481[30:00<18:38,58.85it/s] 62%|######2   |108375/173481[30:11<18:26,58.85it/s] 68%|######8   |118080/173481[33:00<15:49,58.34it/s] 68%|######8   |118754/173481[33:11<15:38,58.34it/s] 74%|#######4  |128430/173481[36:00<12:57,57.91it/s] 74%|#######4  |129110/173481[36:12<12:46,57.91it/s] 80%|########  |138930/173481[39:00<09:54,58.12it/s] 80%|########  |139644/173481[39:12<09:42,58.12it/s] 86%|########6 |149610/173481[42:00<06:46,58.72it/s] 87%|########6 |150354/173481[42:12<06:33,58.72it/s] 92%|#########2|160285/173481[45:00<03:43,59.01it/s] 93%|#########2|161014/173481[45:12<03:31,59.01it/s] 99%|#########8|170903/173481[48:00<00:43,59.00it/s] 99%|#########8|171661/173481[48:12<00:30,59.00it/s]100%|##########|173481/173481[48:42<00:00,59.37it/s]
[32m[0329 06:22:06 @base.py:257][0m Epoch 22 (global_step 14225442) finished, time:2922.09 sec.
[32m[0329 06:22:06 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-14225442.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.78it/s]
21
[32m[0329 06:24:11 @monitor.py:363][0m QueueInput/queue_size: 1.3223
[32m[0329 06:24:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.445
[32m[0329 06:24:11 @monitor.py:363][0m activation-summaries/output-rms: 0.035604
[32m[0329 06:24:11 @monitor.py:363][0m cross_entropy_loss: 2.5249
[32m[0329 06:24:11 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 06:24:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 06:24:11 @monitor.py:363][0m train-error-top1: 0.62213
[32m[0329 06:24:11 @monitor.py:363][0m val-error-top1: 0.61216
[32m[0329 06:24:11 @monitor.py:363][0m val-utt-error: 0.23478
[32m[0329 06:24:11 @monitor.py:363][0m validation_cost: 2.4999
[32m[0329 06:24:11 @monitor.py:363][0m wd_cost: 3.81e-20
[32m[0329 06:24:11 @group.py:42][0m Callbacks took 125.135 sec in total. InferenceRunner: 124.842sec
[32m[0329 06:24:11 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15325/173481[03:00<30:57,85.14it/s]  9%|9         |15958/173481[03:10<30:50,85.14it/s] 15%|#5        |26228/173481[06:00<34:40,70.78it/s] 15%|#5        |26814/173481[06:10<34:32,70.78it/s] 21%|##1       |36682/173481[09:00<35:44,63.80it/s] 21%|##1       |37260/173481[09:10<35:35,63.80it/s] 28%|##7       |47923/173481[12:00<33:09,63.12it/s] 28%|##8       |48663/173481[12:10<32:57,63.12it/s] 34%|###3      |58880/173481[15:00<30:49,61.98it/s] 34%|###4      |59550/173481[15:10<30:38,61.98it/s] 40%|####      |70061/173481[18:00<27:46,62.05it/s] 41%|####      |70856/173481[18:11<27:34,62.05it/s] 47%|####7     |81901/173481[21:00<23:54,63.86it/s] 48%|####7     |82523/173481[21:11<23:44,63.86it/s] 53%|#####3    |92677/173481[24:00<21:47,61.80it/s] 54%|#####3    |93358/173481[24:11<21:36,61.80it/s] 60%|#####9    |103315/173481[27:00<19:21,60.42it/s] 60%|#####9    |103968/173481[27:11<19:10,60.42it/s] 66%|######5   |114358/173481[30:00<16:11,60.88it/s] 66%|######6   |115093/173481[30:11<15:59,60.88it/s] 72%|#######2  |125366/173481[33:00<13:08,61.02it/s] 73%|#######2  |126059/173481[33:11<12:57,61.02it/s] 79%|#######8  |136524/173481[36:00<10:00,61.49it/s] 79%|#######9  |137258/173481[36:12<09:49,61.49it/s] 85%|########5 |147729/173481[39:00<06:56,61.87it/s] 86%|########5 |148460/173481[39:12<06:44,61.87it/s] 92%|#########1|158869/173481[42:00<03:56,61.88it/s] 92%|#########2|159644/173481[42:12<03:43,61.88it/s] 98%|#########7|170002/173481[45:00<00:56,61.86it/s] 98%|#########8|170773/173481[45:12<00:43,61.86it/s]100%|##########|173481/173481[45:57<00:00,62.92it/s]
[32m[0329 07:10:08 @base.py:257][0m Epoch 23 (global_step 14398923) finished, time:2757.14 sec.
[32m[0329 07:10:09 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-14398923.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.40it/s]
22
[32m[0329 07:12:14 @monitor.py:363][0m QueueInput/queue_size: 0.79056
[32m[0329 07:12:14 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.084
[32m[0329 07:12:14 @monitor.py:363][0m activation-summaries/output-rms: 0.035314
[32m[0329 07:12:14 @monitor.py:363][0m cross_entropy_loss: 2.4911
[32m[0329 07:12:14 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 07:12:14 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 07:12:14 @monitor.py:363][0m train-error-top1: 0.61084
[32m[0329 07:12:14 @monitor.py:363][0m val-error-top1: 0.61108
[32m[0329 07:12:14 @monitor.py:363][0m val-utt-error: 0.2301
[32m[0329 07:12:14 @monitor.py:363][0m validation_cost: 2.4936
[32m[0329 07:12:14 @monitor.py:363][0m wd_cost: 3.81e-20
[32m[0329 07:12:14 @group.py:42][0m Callbacks took 125.432 sec in total. InferenceRunner: 125.159sec
[32m[0329 07:12:14 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13638/173481[03:00<35:10,75.75it/s]  8%|8         |14254/173481[03:10<35:01,75.75it/s] 14%|#3        |24028/173481[06:00<38:01,65.52it/s] 14%|#4        |24627/173481[06:10<37:51,65.52it/s] 20%|##        |34803/173481[09:00<36:56,62.56it/s] 20%|##        |35417/173481[09:10<36:46,62.56it/s] 26%|##6       |45940/173481[12:00<34:10,62.21it/s] 27%|##6       |46575/173481[12:10<33:59,62.21it/s] 33%|###2      |56898/173481[15:00<31:34,61.53it/s] 33%|###3      |57545/173481[15:10<31:24,61.53it/s] 39%|###9      |67709/173481[18:00<29:00,60.79it/s] 39%|###9      |68357/173481[18:11<28:49,60.79it/s] 45%|####5     |78587/173481[21:00<26:05,60.61it/s] 46%|####5     |79276/173481[21:11<25:54,60.61it/s] 52%|#####1    |89473/173481[24:00<23:07,60.54it/s] 52%|#####1    |90164/173481[24:11<22:56,60.54it/s] 58%|#####7    |100423/173481[27:00<20:03,60.68it/s] 58%|#####8    |101126/173481[27:11<19:52,60.68it/s] 64%|######4   |111398/173481[30:00<17:00,60.82it/s] 65%|######4   |112152/173481[30:11<16:48,60.82it/s] 71%|#######   |122408/173481[33:00<13:57,60.99it/s] 71%|#######   |123116/173481[33:12<13:45,60.99it/s] 77%|#######6  |133208/173481[36:00<11:05,60.49it/s] 77%|#######7  |133942/173481[36:12<10:53,60.49it/s] 83%|########3 |144143/173481[39:00<08:04,60.61it/s] 84%|########3 |144874/173481[39:12<07:51,60.61it/s] 90%|########9 |155283/173481[42:00<04:57,61.24it/s] 90%|########9 |156037/173481[42:12<04:44,61.24it/s] 96%|#########5|166492/173481[45:00<01:53,61.75it/s] 96%|#########6|167201/173481[45:12<01:41,61.75it/s]100%|##########|173481/173481[46:58<00:00,61.55it/s]
[32m[0329 07:59:12 @base.py:257][0m Epoch 24 (global_step 14572404) finished, time:2818.50 sec.
[32m[0329 07:59:13 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-14572404.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.65it/s]
23
[32m[0329 08:01:17 @monitor.py:363][0m QueueInput/queue_size: 0.4671
[32m[0329 08:01:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.187
[32m[0329 08:01:17 @monitor.py:363][0m activation-summaries/output-rms: 0.035068
[32m[0329 08:01:17 @monitor.py:363][0m cross_entropy_loss: 2.4699
[32m[0329 08:01:17 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 08:01:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 08:01:17 @monitor.py:363][0m train-error-top1: 0.60546
[32m[0329 08:01:17 @monitor.py:363][0m val-error-top1: 0.61008
[32m[0329 08:01:17 @monitor.py:363][0m val-utt-error: 0.23122
[32m[0329 08:01:17 @monitor.py:363][0m validation_cost: 2.4874
[32m[0329 08:01:17 @monitor.py:363][0m wd_cost: 7.62e-21
[32m[0329 08:01:17 @group.py:42][0m Callbacks took 124.457 sec in total. InferenceRunner: 124.137sec
[32m[0329 08:01:17 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13196/173481[03:00<36:26,73.31it/s]  8%|7         |13799/173481[03:10<36:18,73.31it/s] 14%|#3        |23706/173481[06:00<38:24,65.00it/s] 14%|#4        |24329/173481[06:10<38:14,65.00it/s] 20%|##        |34910/173481[09:00<36:19,63.59it/s] 20%|##        |35560/173481[09:10<36:08,63.59it/s] 26%|##6       |45912/173481[12:00<34:06,62.33it/s] 27%|##6       |46559/173481[12:10<33:56,62.33it/s] 33%|###2      |57116/173481[15:00<31:08,62.28it/s] 33%|###3      |57766/173481[15:10<30:57,62.28it/s] 39%|###9      |68118/173481[18:00<28:27,61.70it/s] 40%|###9      |68777/173481[18:11<28:17,61.70it/s] 45%|####5     |78834/173481[21:00<26:02,60.59it/s] 46%|####5     |79526/173481[21:11<25:50,60.59it/s] 53%|#####2    |91372/173481[24:00<21:06,64.81it/s] 53%|#####3    |92363/173481[24:11<20:51,64.81it/s] 60%|######    |104194/173481[27:00<17:00,67.87it/s] 60%|######    |104848/173481[27:11<16:51,67.87it/s] 66%|######6   |114905/173481[30:00<15:23,63.41it/s] 67%|######6   |115581/173481[30:11<15:13,63.41it/s] 72%|#######2  |125542/173481[33:00<13:03,61.18it/s] 73%|#######2  |126237/173481[33:11<12:52,61.18it/s] 79%|#######9  |137494/173481[36:00<09:25,63.68it/s] 80%|#######9  |138421/173481[36:12<09:10,63.68it/s] 88%|########8 |152797/173481[39:00<04:44,72.81it/s] 89%|########8 |153862/173481[39:12<04:29,72.81it/s] 97%|#########7|168611/173481[42:00<01:01,79.63it/s] 98%|#########7|169673/173481[42:12<00:47,79.63it/s]100%|##########|173481/173481[43:09<00:00,66.98it/s]
[32m[0329 08:44:27 @base.py:257][0m Epoch 25 (global_step 14745885) finished, time:2589.87 sec.
[32m[0329 08:44:27 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-14745885.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.37it/s]
24
[32m[0329 08:46:31 @monitor.py:363][0m QueueInput/queue_size: 0.33097
[32m[0329 08:46:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.374
[32m[0329 08:46:31 @monitor.py:363][0m activation-summaries/output-rms: 0.037197
[32m[0329 08:46:31 @monitor.py:363][0m cross_entropy_loss: 2.4601
[32m[0329 08:46:31 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 08:46:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 08:46:31 @monitor.py:363][0m train-error-top1: 0.60353
[32m[0329 08:46:31 @monitor.py:363][0m val-error-top1: 0.61024
[32m[0329 08:46:31 @monitor.py:363][0m val-utt-error: 0.23202
[32m[0329 08:46:31 @monitor.py:363][0m validation_cost: 2.4856
[32m[0329 08:46:31 @monitor.py:363][0m wd_cost: 7.62e-21
[32m[0329 08:46:31 @group.py:42][0m Callbacks took 124.631 sec in total. InferenceRunner: 124.351sec
[32m[0329 08:46:31 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13922/173481[03:00<34:23,77.34it/s]  8%|8         |14513/173481[03:10<34:15,77.34it/s] 14%|#4        |24888/173481[06:00<36:20,68.16it/s] 15%|#4        |25524/173481[06:10<36:10,68.16it/s] 21%|##        |35576/173481[09:00<36:13,63.46it/s] 21%|##        |36205/173481[09:10<36:03,63.46it/s] 27%|##6       |46200/173481[12:00<34:41,61.16it/s] 27%|##6       |46825/173481[12:10<34:30,61.16it/s] 33%|###2      |56680/173481[15:00<32:38,59.65it/s] 33%|###3      |57344/173481[15:10<32:26,59.65it/s] 39%|###9      |67666/173481[18:00<29:13,60.33it/s] 39%|###9      |68310/173481[18:11<29:03,60.33it/s] 45%|####4     |77982/173481[21:00<27:04,58.78it/s] 45%|####5     |78641/173481[21:11<26:53,58.78it/s] 51%|#####1    |88507/173481[24:00<24:09,58.63it/s] 51%|#####1    |89155/173481[24:11<23:58,58.63it/s] 57%|#####7    |98897/173481[27:00<21:22,58.17it/s] 57%|#####7    |99578/173481[27:11<21:10,58.17it/s] 63%|######2   |109265/173481[30:00<18:29,57.88it/s] 63%|######3   |109950/173481[30:11<18:17,57.88it/s] 69%|######9   |119832/173481[33:00<15:20,58.29it/s] 69%|######9   |120514/173481[33:11<15:08,58.29it/s] 75%|#######5  |130469/173481[36:00<12:12,58.69it/s] 76%|#######5  |131165/173481[36:12<12:01,58.69it/s] 81%|########1 |141161/173481[39:00<09:07,59.03it/s] 82%|########1 |141890/173481[39:12<08:55,59.03it/s] 87%|########7 |151531/173481[42:00<06:16,58.31it/s] 88%|########7 |152207/173481[42:12<06:04,58.31it/s] 93%|#########3|161871/173481[45:00<03:20,57.87it/s] 94%|#########3|162560/173481[45:12<03:08,57.87it/s] 99%|#########9|172162/173481[48:00<00:22,57.52it/s]100%|#########9|172883/173481[48:12<00:10,57.52it/s]100%|##########|173481/173481[48:23<00:00,59.74it/s]
[32m[0329 09:34:55 @base.py:257][0m Epoch 26 (global_step 14919366) finished, time:2903.81 sec.
[32m[0329 09:34:55 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-14919366.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.10it/s]
25
[32m[0329 09:37:00 @monitor.py:363][0m QueueInput/queue_size: 0.48438
[32m[0329 09:37:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.082
[32m[0329 09:37:00 @monitor.py:363][0m activation-summaries/output-rms: 0.036246
[32m[0329 09:37:00 @monitor.py:363][0m cross_entropy_loss: 2.4604
[32m[0329 09:37:00 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 09:37:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 09:37:00 @monitor.py:363][0m train-error-top1: 0.61026
[32m[0329 09:37:00 @monitor.py:363][0m val-error-top1: 0.60887
[32m[0329 09:37:00 @monitor.py:363][0m val-utt-error: 0.22957
[32m[0329 09:37:00 @monitor.py:363][0m validation_cost: 2.4776
[32m[0329 09:37:00 @monitor.py:363][0m wd_cost: 1.524e-21
[32m[0329 09:37:00 @group.py:42][0m Callbacks took 124.853 sec in total. InferenceRunner: 124.586sec
[32m[0329 09:37:00 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13150/173481[03:00<36:35,73.04it/s]  8%|7         |13795/173481[03:10<36:26,73.04it/s] 14%|#4        |24669/173481[06:00<36:21,68.22it/s] 15%|#4        |25267/173481[06:10<36:12,68.22it/s] 20%|##        |34856/173481[09:00<37:20,61.86it/s] 20%|##        |35409/173481[09:10<37:11,61.86it/s] 28%|##8       |48840/173481[12:00<30:09,68.88it/s] 29%|##8       |49823/173481[12:10<29:55,68.88it/s] 36%|###5      |61915/173481[15:00<26:18,70.69it/s] 36%|###6      |62549/173481[15:10<26:09,70.69it/s] 42%|####1     |72607/173481[18:00<26:02,64.56it/s] 42%|####2     |73270/173481[18:11<25:52,64.56it/s] 48%|####8     |83495/173481[21:00<24:00,62.45it/s] 49%|####8     |84176/173481[21:11<23:49,62.45it/s] 54%|#####4    |94145/173481[24:00<21:45,60.76it/s] 55%|#####4    |94778/173481[24:11<21:35,60.76it/s] 60%|######    |104667/173481[27:00<19:14,59.59it/s] 61%|######    |105341/173481[27:11<19:03,59.59it/s] 66%|######6   |115296/173481[30:00<16:20,59.32it/s] 67%|######6   |115958/173481[30:11<16:09,59.32it/s] 73%|#######2  |126160/173481[33:00<13:10,59.83it/s] 73%|#######3  |126952/173481[33:11<12:57,59.83it/s] 81%|########1 |141082/173481[36:00<07:46,69.50it/s] 82%|########1 |142106/173481[36:12<07:31,69.50it/s] 90%|######### |156955/173481[39:00<03:32,77.73it/s] 91%|#########1|158024/173481[39:12<03:18,77.73it/s]100%|#########9|172690/173481[42:00<00:09,82.29it/s]100%|##########|173481/173481[42:08<00:00,68.61it/s]
[32m[0329 10:19:09 @base.py:257][0m Epoch 27 (global_step 15092847) finished, time:2528.68 sec.
[32m[0329 10:19:09 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-15092847.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.26it/s]
26
[32m[0329 10:21:13 @monitor.py:363][0m QueueInput/queue_size: 49.592
[32m[0329 10:21:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.126
[32m[0329 10:21:13 @monitor.py:363][0m activation-summaries/output-rms: 0.036036
[32m[0329 10:21:13 @monitor.py:363][0m cross_entropy_loss: 2.5278
[32m[0329 10:21:13 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 10:21:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 10:21:13 @monitor.py:363][0m train-error-top1: 0.62154
[32m[0329 10:21:13 @monitor.py:363][0m val-error-top1: 0.61274
[32m[0329 10:21:13 @monitor.py:363][0m val-utt-error: 0.23531
[32m[0329 10:21:13 @monitor.py:363][0m validation_cost: 2.503
[32m[0329 10:21:13 @monitor.py:363][0m wd_cost: 1.524e-21
[32m[0329 10:21:13 @group.py:42][0m Callbacks took 124.697 sec in total. InferenceRunner: 124.448sec
[32m[0329 10:21:13 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15026/173481[03:00<31:38,83.47it/s]  9%|9         |15900/173481[03:10<31:27,83.47it/s] 16%|#6        |27927/173481[06:00<31:27,77.12it/s] 16%|#6        |28505/173481[06:10<31:19,77.12it/s] 22%|##2       |38624/173481[09:00<33:28,67.13it/s] 23%|##2       |39223/173481[09:10<33:20,67.13it/s] 29%|##8       |50105/173481[12:00<31:26,65.41it/s] 29%|##9       |50753/173481[12:10<31:16,65.41it/s] 35%|###5      |60850/173481[15:00<30:04,62.42it/s] 35%|###5      |61478/173481[15:10<29:54,62.42it/s] 42%|####1     |72563/173481[18:00<26:23,63.71it/s] 42%|####2     |73218/173481[18:10<26:13,63.71it/s] 48%|####8     |84084/173481[21:00<23:20,63.85it/s] 49%|####8     |84747/173481[21:11<23:09,63.85it/s] 55%|#####4    |95055/173481[24:00<20:57,62.36it/s] 55%|#####5    |95714/173481[24:11<20:46,62.36it/s] 61%|######    |105769/173481[27:00<18:31,60.91it/s] 61%|######1   |106477/173481[27:11<18:20,60.91it/s] 67%|######7   |116899/173481[30:00<15:22,61.36it/s] 68%|######7   |117600/173481[30:11<15:10,61.36it/s] 74%|#######3  |127966/173481[33:00<12:21,61.42it/s] 74%|#######4  |128764/173481[33:11<12:08,61.42it/s] 80%|########  |139095/173481[36:00<09:18,61.62it/s] 81%|########  |139814/173481[36:12<09:06,61.62it/s] 86%|########6 |149932/173481[39:00<06:26,60.90it/s] 87%|########6 |150630/173481[39:12<06:15,60.90it/s] 93%|#########2|160857/173481[42:00<03:27,60.80it/s] 93%|#########3|161593/173481[42:12<03:15,60.80it/s] 99%|#########9|171945/173481[45:00<00:25,61.20it/s]100%|#########9|172718/173481[45:12<00:12,61.20it/s]100%|##########|173481/173481[45:25<00:00,63.65it/s]
[32m[0329 11:06:39 @base.py:257][0m Epoch 28 (global_step 15266328) finished, time:2725.58 sec.
[32m[0329 11:06:39 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-15266328.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.49it/s]
27
[32m[0329 11:08:38 @monitor.py:363][0m QueueInput/queue_size: 0.52422
[32m[0329 11:08:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.084
[32m[0329 11:08:38 @monitor.py:363][0m activation-summaries/output-rms: 0.035314
[32m[0329 11:08:38 @monitor.py:363][0m cross_entropy_loss: 2.4911
[32m[0329 11:08:38 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 11:08:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 11:08:38 @monitor.py:363][0m train-error-top1: 0.61084
[32m[0329 11:08:38 @monitor.py:363][0m val-error-top1: 0.61108
[32m[0329 11:08:38 @monitor.py:363][0m val-utt-error: 0.23021
[32m[0329 11:08:38 @monitor.py:363][0m validation_cost: 2.4936
[32m[0329 11:08:38 @monitor.py:363][0m wd_cost: 1.524e-21
[32m[0329 11:08:38 @group.py:42][0m Callbacks took 119.167 sec in total. InferenceRunner: 118.772sec
[32m[0329 11:08:38 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13748/173481[03:00<34:51,76.37it/s]  8%|8         |14377/173481[03:10<34:43,76.37it/s] 14%|#3        |24107/173481[06:00<37:55,65.64it/s] 14%|#4        |24684/173481[06:10<37:46,65.64it/s] 20%|##        |34933/173481[09:00<36:47,62.76it/s] 20%|##        |35536/173481[09:10<36:37,62.76it/s] 26%|##6       |45805/173481[12:00<34:34,61.56it/s] 27%|##6       |46447/173481[12:10<34:23,61.56it/s] 33%|###2      |56463/173481[15:00<32:18,60.36it/s] 33%|###2      |57102/173481[15:10<32:08,60.36it/s] 39%|###8      |67307/173481[18:00<29:20,60.30it/s] 39%|###9      |67971/173481[18:11<29:09,60.30it/s] 45%|####4     |78038/173481[21:00<26:31,59.96it/s] 45%|####5     |78721/173481[21:11<26:20,59.96it/s] 51%|#####1    |88691/173481[24:00<23:43,59.56it/s] 52%|#####1    |89371/173481[24:11<23:32,59.56it/s] 57%|#####7    |99615/173481[27:00<20:28,60.12it/s] 58%|#####7    |100278/173481[27:11<20:17,60.12it/s] 64%|######3   |110501/173481[30:00<17:24,60.30it/s] 64%|######4   |111162/173481[30:11<17:13,60.30it/s] 70%|######9   |121269/173481[33:00<14:29,60.06it/s] 70%|#######   |121972/173481[33:11<14:17,60.06it/s] 76%|#######6  |132123/173481[36:00<11:27,60.18it/s] 77%|#######6  |132845/173481[36:11<11:15,60.18it/s] 82%|########2 |143089/173481[39:00<08:21,60.55it/s] 83%|########2 |143812/173481[39:12<08:10,60.55it/s] 89%|########8 |154173/173481[42:00<05:16,61.06it/s] 89%|########9 |154907/173481[42:12<05:04,61.06it/s] 95%|#########5|165272/173481[45:00<02:13,61.36it/s] 96%|#########5|165998/173481[45:12<02:01,61.36it/s]100%|##########|173481/173481[47:21<00:00,61.05it/s]
[32m[0329 11:56:00 @base.py:257][0m Epoch 29 (global_step 15439809) finished, time:2841.55 sec.
[32m[0329 11:56:00 @saver.py:84][0m Model saved to train_log/fcn1_w_8_a_32_quant_ends_True_preload/model-15439809.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.65it/s]
28
[32m[0329 11:58:05 @monitor.py:363][0m QueueInput/queue_size: 0.61047
[32m[0329 11:58:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.188
[32m[0329 11:58:05 @monitor.py:363][0m activation-summaries/output-rms: 0.035068
[32m[0329 11:58:05 @monitor.py:363][0m cross_entropy_loss: 2.4699
[32m[0329 11:58:05 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59468
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2049
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33363
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.088481
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32404
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.089551
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.31459
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.081382
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.30302
[32m[0329 11:58:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.086386
[32m[0329 11:58:05 @monitor.py:363][0m train-error-top1: 0.60567
[32m[0329 11:58:05 @monitor.py:363][0m val-error-top1: 0.61008
[32m[0329 11:58:05 @monitor.py:363][0m val-utt-error: 0.23122
[32m[0329 11:58:05 @monitor.py:363][0m validation_cost: 2.4874
[32m[0329 11:58:05 @monitor.py:363][0m wd_cost: 3.048e-22
[32m[0329 11:58:05 @group.py:42][0m Callbacks took 125.201 sec in total. InferenceRunner: 124.949sec
[32m[0329 11:58:05 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13317/173481[03:00<36:04,73.98it/s]  8%|8         |13920/173481[03:10<35:56,73.98it/s] 14%|#3        |23818/173481[06:00<38:14,65.23it/s] 14%|#4        |24437/173481[06:10<38:04,65.23it/s] 20%|##        |34865/173481[09:00<36:31,63.24it/s] 20%|##        |35499/173481[09:10<36:21,63.24it/s] 26%|##6       |45777/173481[12:00<34:23,61.90it/s] 27%|##6       |46433/173481[12:10<34:12,61.90it/s] 33%|###2      |56771/173481[15:00<31:38,61.49it/s] 33%|###3      |57429/173481[15:10<31:27,61.49it/s] 39%|###9      |67707/173481[18:00<28:50,61.11it/s] 39%|###9      |68372/173481[18:11<28:39,61.11it/s] 45%|####5     |78565/173481[21:00<26:03,60.71it/s] 46%|####5     |79256/173481[21:11<25:51,60.71it/s] 52%|#####1    |89667/173481[24:00<22:49,61.19it/s] 52%|#####2    |90381/173481[24:11<22:38,61.19it/s] 58%|#####7    |100472/173481[27:00<20:04,60.59it/s] 58%|#####8    |101161/173481[27:11<19:53,60.59it/s] 64%|######4   |111060/173481[30:00<17:25,59.69it/s] 64%|######4   |111737/173481[30:11<17:14,59.69it/s] 70%|#######   |121682/173481[33:00<14:32,59.35it/s] 71%|#######   |122356/173481[33:11<14:21,59.35it/s] 76%|#######6  |132320/173481[36:00<11:35,59.22it/s] 77%|#######6  |132996/173481[36:11<11:23,59.22it/s] 82%|########2 |142958/173481[39:00<08:35,59.16it/s] 83%|########2 |143677/173481[39:12<08:23,59.16it/s]slurmstepd: *** JOB 85142 ON sls-titan-10 CANCELLED AT 2018-03-29T12:39:05 ***
srun: got SIGCONT
srun: forcing job termination
slurmstepd: *** STEP 85142.0 ON sls-titan-10 CANCELLED AT 2018-03-29T12:39:05 ***
