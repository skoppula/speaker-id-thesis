sls-titan-10 1
SLURM_JOBID=82593
SLURM_TASKID=1
[32m[0323 10:57:38 @logger.py:67][0m Existing log file 'train_log/fcn1_w_2_a_32_quant_ends_False/log.log' backuped to 'train_log/fcn1_w_2_a_32_quant_ends_False/log.log.0323-105738'
[32m[0323 10:57:38 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=2 --bita=32 --quant_ends=False
[32m[0323 11:04:23 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 11:04:23 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 11:04:23 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 11:04:23 @drf_run.py:166][0m Using host: sls-titan-10
[32m[0323 11:04:23 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 11:04:23 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 11:04:23 @drf_run.py:188][0m Using GPU: 1
[32m[0323 11:04:23 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 11:04:23 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 11:04:23 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 11:04:23 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0323 11:04:23 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0323 11:04:23 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0323 11:04:23 @registry.py:130][0m linear0 output: [None, 256]
[32m[0323 11:04:23 @registry.py:122][0m linear1 input: [None, 256]
[32m[0323 11:04:23 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 11:04:23 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 11:04:23 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 11:04:23 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 11:04:23 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 11:04:23 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 11:04:23 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 11:04:24 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 11:04:24 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 11:04:24 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 11:04:24 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 11:04:24 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 11:04:24 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 11:04:24 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 11:04:24 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 11:04:24 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 11:04:24 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 11:04:24 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0323 11:04:24 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 11:04:24 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0323 11:04:24 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0323 11:04:24 @base.py:196][0m Setup callbacks graph ...
[32m[0323 11:04:24 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 11:04:24 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0323 11:04:24 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0323 11:04:24 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 11:04:24 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 11:04:24 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 11:04:24 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 11:04:24 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 11:04:25 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 11:04:25 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 11:04:25 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 11:04:25 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 11:04:25 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 11:04:25 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 11:04:25 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 11:04:25 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 11:04:25 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 11:04:25 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0323 11:04:25 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 11:04:25 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0323 11:04:25 @base.py:212][0m Creating the session ...
2018-03-23 11:04:25.701511: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-23 11:04:27.697625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:03:00.0
totalMemory: 11.92GiB freeMemory: 11.81GiB
2018-03-23 11:04:27.697665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
[32m[0323 11:04:28 @base.py:220][0m Initializing the session ...
[32m[0323 11:04:28 @base.py:227][0m Graph Finalized.
[32m[0323 11:04:28 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 11:04:30 @monitor.py:251][0m Found existing JSON at train_log/fcn1_w_2_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 11:04:30 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 11:04:30 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20311/173481[03:00<22:37,112.80it/s] 12%|#2        |20890/173481[03:10<22:32,112.80it/s] 18%|#8        |31666/173481[06:00<29:12,80.91it/s]  19%|#8        |32335/173481[06:10<29:04,80.91it/s] 24%|##4       |41816/173481[09:00<33:01,66.45it/s] 24%|##4       |42452/173481[09:10<32:51,66.45it/s] 36%|###5      |62153/173481[12:00<22:10,83.69it/s] 36%|###6      |63275/173481[12:10<21:56,83.69it/s] 47%|####7     |81751/173481[15:00<16:09,94.62it/s] 48%|####7     |82800/173481[15:10<15:58,94.62it/s] 58%|#####8    |101288/173481[18:00<11:54,101.10it/s] 59%|#####9    |102380/173481[18:11<11:43,101.10it/s] 70%|#######   |121602/173481[21:00<08:06,106.66it/s] 71%|#######   |122810/173481[21:11<07:55,106.66it/s] 83%|########3 |144589/173481[24:00<04:08,116.23it/s] 84%|########4 |146101/173481[24:11<03:55,116.23it/s] 93%|#########2|161013/173481[27:00<02:01,102.23it/s] 93%|#########3|161725/173481[27:11<01:54,102.23it/s] 99%|#########9|172263/173481[30:00<00:15,77.57it/s] 100%|#########9|172973/173481[30:11<00:06,77.57it/s]100%|##########|173481/173481[30:20<00:00,95.29it/s]
[32m[0323 11:34:51 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:1820.59 sec.
[32m[0323 11:34:51 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.38it/s]
0
[32m[0323 11:36:59 @monitor.py:363][0m QueueInput/queue_size: 1.4067
[32m[0323 11:36:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.7758
[32m[0323 11:36:59 @monitor.py:363][0m activation-summaries/output-rms: 0.024465
[32m[0323 11:36:59 @monitor.py:363][0m cross_entropy_loss: 2.93
[32m[0323 11:36:59 @monitor.py:363][0m lr: 0.001
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.12947
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.65266
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.097368
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14094
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11927
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092134
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.12012
[32m[0323 11:36:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 11:36:59 @monitor.py:363][0m train-error-top1: 0.70155
[32m[0323 11:36:59 @monitor.py:363][0m val-error-top1: 0.80266
[32m[0323 11:36:59 @monitor.py:363][0m val-utt-error: 0.56694
[32m[0323 11:36:59 @monitor.py:363][0m validation_cost: 3.5515
[32m[0323 11:36:59 @monitor.py:363][0m wd_cost: 0.67016
[32m[0323 11:36:59 @group.py:42][0m Callbacks took 128.038 sec in total. InferenceRunner: 127.728sec
[32m[0323 11:36:59 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14421/173481[03:00<33:05,80.12it/s]  9%|8         |15144/173481[03:10<32:56,80.12it/s] 15%|#5        |26235/173481[06:00<34:00,72.15it/s] 15%|#5        |26854/173481[06:10<33:52,72.15it/s] 21%|##1       |36560/173481[09:00<35:42,63.91it/s] 21%|##1       |37124/173481[09:10<35:33,63.91it/s] 27%|##7       |47426/173481[12:00<33:50,62.09it/s] 28%|##7       |48044/173481[12:10<33:40,62.09it/s] 34%|###3      |58645/173481[15:00<30:46,62.21it/s] 34%|###4      |59339/173481[15:10<30:34,62.21it/s] 40%|####      |69560/173481[18:00<28:12,61.41it/s] 40%|####      |70254/173481[18:11<28:00,61.41it/s] 47%|####6     |80775/173481[21:00<24:58,61.85it/s] 47%|####6     |81439/173481[21:11<24:48,61.85it/s] 53%|#####2    |91942/173481[24:00<21:56,61.94it/s] 53%|#####3    |92630/173481[24:11<21:45,61.94it/s] 59%|#####9    |103062/173481[27:00<18:58,61.86it/s] 60%|#####9    |103794/173481[27:11<18:46,61.86it/s] 66%|######5   |114443/173481[30:00<15:44,62.54it/s] 66%|######6   |115100/173481[30:11<15:33,62.54it/s] 72%|#######2  |125261/173481[33:00<13:06,61.29it/s] 73%|#######2  |125909/173481[33:11<12:56,61.29it/s] 78%|#######8  |135690/173481[36:00<10:34,59.53it/s] 79%|#######8  |136332/173481[36:12<10:24,59.53it/s] 84%|########4 |146113/173481[39:00<07:46,58.70it/s] 85%|########4 |146858/173481[39:12<07:33,58.70it/s] 90%|######### |156900/173481[42:00<04:39,59.31it/s] 91%|######### |157626/173481[42:12<04:27,59.31it/s] 97%|#########6|168135/173481[45:00<01:27,60.81it/s] 97%|#########7|168882/173481[45:12<01:15,60.81it/s]100%|##########|173481/173481[46:27<00:00,62.25it/s]
[32m[0323 12:23:26 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2787.04 sec.
[32m[0323 12:23:26 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-346962.
[32m[0323 12:23:26 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.24it/s]
1
[32m[0323 12:25:22 @monitor.py:363][0m QueueInput/queue_size: 0.86083
[32m[0323 12:25:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.876
[32m[0323 12:25:22 @monitor.py:363][0m activation-summaries/output-rms: 0.025791
[32m[0323 12:25:22 @monitor.py:363][0m cross_entropy_loss: 2.8705
[32m[0323 12:25:22 @monitor.py:363][0m lr: 0.001
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13183
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.86751
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.096676
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.14011
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11538
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092134
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11777
[32m[0323 12:25:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.08885
[32m[0323 12:25:22 @monitor.py:363][0m train-error-top1: 0.68887
[32m[0323 12:25:22 @monitor.py:363][0m val-error-top1: 0.80859
[32m[0323 12:25:22 @monitor.py:363][0m val-utt-error: 0.58506
[32m[0323 12:25:22 @monitor.py:363][0m validation_cost: 3.6683
[32m[0323 12:25:22 @monitor.py:363][0m wd_cost: 0.65967
[32m[0323 12:25:22 @group.py:42][0m Callbacks took 116.038 sec in total. InferenceRunner: 115.323sec
[32m[0323 12:25:22 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15369/173481[03:00<30:51,85.38it/s]  9%|9         |16288/173481[03:10<30:41,85.38it/s] 16%|#5        |27284/173481[06:00<32:40,74.56it/s] 16%|#6        |27873/173481[06:10<32:32,74.56it/s] 22%|##1       |37479/173481[09:00<35:12,64.37it/s] 22%|##1       |38066/173481[09:10<35:03,64.37it/s] 28%|##7       |47809/173481[12:00<34:31,60.68it/s] 28%|##7       |48428/173481[12:10<34:20,60.68it/s] 34%|###3      |58229/173481[15:00<32:25,59.25it/s] 34%|###3      |58896/173481[15:10<32:13,59.25it/s] 40%|###9      |69322/173481[18:00<28:44,60.41it/s] 40%|####      |70044/173481[18:11<28:32,60.41it/s] 47%|####6     |80849/173481[21:00<24:49,62.17it/s] 47%|####7     |81584/173481[21:11<24:38,62.17it/s] 53%|#####3    |92402/173481[24:00<21:23,63.16it/s] 54%|#####3    |93163/173481[24:11<21:11,63.16it/s] 60%|#####9    |103879/173481[27:00<18:16,63.46it/s] 60%|######    |104496/173481[27:11<18:07,63.46it/s] 66%|######6   |115284/173481[30:00<15:17,63.41it/s] 67%|######6   |116035/173481[30:11<15:05,63.41it/s] 73%|#######2  |126604/173481[33:00<12:22,63.14it/s] 73%|#######3  |127418/173481[33:12<12:09,63.14it/s] 80%|#######9  |138514/173481[36:00<09:01,64.61it/s] 80%|########  |139302/173481[36:12<08:48,64.61it/s] 87%|########6 |150359/173481[39:00<05:54,65.20it/s] 87%|########7 |151148/173481[39:12<05:42,65.20it/s] 94%|#########3|162414/173481[42:00<02:47,66.07it/s] 94%|#########4|163221/173481[42:12<02:35,66.07it/s]100%|##########|173481/173481[44:47<00:00,64.54it/s]
[32m[0323 13:10:10 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2687.88 sec.
[32m[0323 13:10:10 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-520443.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.44it/s]
2
[32m[0323 13:12:05 @monitor.py:363][0m QueueInput/queue_size: 0.31801
[32m[0323 13:12:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.4119
[32m[0323 13:12:05 @monitor.py:363][0m activation-summaries/output-rms: 0.030691
[32m[0323 13:12:05 @monitor.py:363][0m cross_entropy_loss: 2.4539
[32m[0323 13:12:05 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.18491
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.95442
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.14127
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.22919
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.18703
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092134
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19628
[32m[0323 13:12:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.08885
[32m[0323 13:12:05 @monitor.py:363][0m train-error-top1: 0.61951
[32m[0323 13:12:05 @monitor.py:363][0m val-error-top1: 0.70585
[32m[0323 13:12:05 @monitor.py:363][0m val-utt-error: 0.37918
[32m[0323 13:12:05 @monitor.py:363][0m validation_cost: 2.916
[32m[0323 13:12:05 @monitor.py:363][0m wd_cost: 0.31198
[32m[0323 13:12:05 @group.py:42][0m Callbacks took 115.378 sec in total. InferenceRunner: 115.172sec
[32m[0323 13:12:05 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13188/173481[03:00<36:27,73.26it/s]  8%|7         |13849/173481[03:10<36:18,73.26it/s] 14%|#4        |24413/173481[06:00<36:52,67.37it/s] 14%|#4        |25018/173481[06:10<36:43,67.37it/s] 21%|##        |36195/173481[09:00<34:27,66.40it/s] 21%|##1       |36919/173481[09:10<34:16,66.40it/s] 28%|##7       |48193/173481[12:00<31:23,66.52it/s] 28%|##8       |48929/173481[12:10<31:12,66.52it/s] 35%|###4      |60142/173481[15:00<28:25,66.45it/s] 35%|###5      |60862/173481[15:10<28:14,66.45it/s] 42%|####1     |72308/173481[18:00<25:09,67.01it/s] 42%|####2     |73058/173481[18:10<24:58,67.01it/s] 49%|####8     |84273/173481[21:00<22:16,66.74it/s] 49%|####8     |84999/173481[21:11<22:05,66.74it/s] 55%|#####5    |96140/173481[24:00<19:26,66.33it/s] 56%|#####5    |96907/173481[24:11<19:14,66.33it/s] 62%|######2   |108234/173481[27:00<16:17,66.76it/s] 63%|######2   |108992/173481[27:11<16:06,66.76it/s] 69%|######9   |120048/173481[30:00<13:27,66.18it/s] 70%|######9   |120829/173481[30:11<13:15,66.18it/s] 76%|#######6  |131998/173481[33:00<10:25,66.28it/s] 77%|#######6  |132777/173481[33:11<10:14,66.28it/s] 83%|########3 |144043/173481[36:00<07:22,66.60it/s] 83%|########3 |144802/173481[36:11<07:10,66.60it/s] 90%|########9 |155623/173481[39:00<04:32,65.44it/s] 90%|######### |156397/173481[39:12<04:21,65.44it/s] 96%|#########6|167053/173481[42:00<01:39,64.45it/s] 97%|#########6|167753/173481[42:12<01:28,64.45it/s]100%|##########|173481/173481[43:47<00:00,66.02it/s]
[32m[0323 13:55:53 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2627.82 sec.
[32m[0323 13:55:53 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-693924.
[32m[0323 13:55:53 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,189.48it/s]
3
[32m[0323 13:57:33 @monitor.py:363][0m QueueInput/queue_size: 0.56216
[32m[0323 13:57:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.552
[32m[0323 13:57:33 @monitor.py:363][0m activation-summaries/output-rms: 0.030538
[32m[0323 13:57:33 @monitor.py:363][0m cross_entropy_loss: 2.4132
[32m[0323 13:57:33 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21356
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0254
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.14655
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27113
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.22042
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092134
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.23133
[32m[0323 13:57:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.08885
[32m[0323 13:57:33 @monitor.py:363][0m train-error-top1: 0.60351
[32m[0323 13:57:33 @monitor.py:363][0m val-error-top1: 0.69161
[32m[0323 13:57:33 @monitor.py:363][0m val-utt-error: 0.3811
[32m[0323 13:57:33 @monitor.py:363][0m validation_cost: 2.8862
[32m[0323 13:57:33 @monitor.py:363][0m wd_cost: 0.39968
[32m[0323 13:57:33 @group.py:42][0m Callbacks took 99.924 sec in total. InferenceRunner: 99.341sec
[32m[0323 13:57:33 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11947/173481[03:00<40:33,66.37it/s]  7%|7         |12581/173481[03:10<40:24,66.37it/s] 13%|#3        |23094/173481[06:00<39:07,64.07it/s] 14%|#3        |23736/173481[06:10<38:57,64.07it/s] 20%|##        |35047/173481[09:00<35:22,65.22it/s] 21%|##        |35726/173481[09:10<35:12,65.22it/s] 27%|##6       |46827/173481[12:00<32:18,65.32it/s] 27%|##7       |47483/173481[12:10<32:08,65.32it/s] 34%|###3      |58620/173481[15:00<29:15,65.42it/s] 34%|###4      |59316/173481[15:10<29:05,65.42it/s] 40%|####      |70082/173481[18:00<26:42,64.53it/s] 41%|####      |70696/173481[18:10<26:32,64.53it/s] 47%|####7     |81582/173481[21:00<23:51,64.21it/s] 47%|####7     |82276/173481[21:11<23:40,64.21it/s] 54%|#####3    |93147/173481[24:00<20:50,64.22it/s] 54%|#####4    |93866/173481[24:11<20:39,64.22it/s] 60%|######    |104723/173481[27:00<17:49,64.27it/s] 61%|######    |105442/173481[27:11<17:38,64.27it/s] 67%|######7   |116297/173481[30:00<14:49,64.27it/s] 67%|######7   |117019/173481[30:11<14:38,64.27it/s] 74%|#######3  |127832/173481[33:00<11:51,64.16it/s] 74%|#######4  |128603/173481[33:11<11:39,64.16it/s] 80%|########  |139447/173481[36:00<08:48,64.34it/s] 81%|########  |140205/173481[36:11<08:37,64.34it/s] 87%|########7 |151330/173481[39:00<05:39,65.17it/s] 88%|########7 |152100/173481[39:12<05:28,65.17it/s] 94%|#########3|162827/173481[42:00<02:45,64.51it/s] 94%|#########4|163535/173481[42:12<02:34,64.51it/s]100%|##########|173481/173481[44:57<00:00,64.31it/s]
[32m[0323 14:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2697.53 sec.
[32m[0323 14:42:30 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-867405.
[32m[0323 14:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.80it/s]
4
[32m[0323 14:44:36 @monitor.py:363][0m QueueInput/queue_size: 0.65338
[32m[0323 14:44:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 7.5335
[32m[0323 14:44:36 @monitor.py:363][0m activation-summaries/output-rms: 0.032358
[32m[0323 14:44:36 @monitor.py:363][0m cross_entropy_loss: 2.3351
[32m[0323 14:44:36 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21626
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0764
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.14741
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.27336
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.22378
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.23396
[32m[0323 14:44:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.08885
[32m[0323 14:44:36 @monitor.py:363][0m train-error-top1: 0.59744
[32m[0323 14:44:36 @monitor.py:363][0m val-error-top1: 0.69419
[32m[0323 14:44:36 @monitor.py:363][0m val-utt-error: 0.36064
[32m[0323 14:44:36 @monitor.py:363][0m validation_cost: 2.8892
[32m[0323 14:44:36 @monitor.py:363][0m wd_cost: 0.40763
[32m[0323 14:44:36 @group.py:42][0m Callbacks took 125.791 sec in total. InferenceRunner: 124.822sec
[32m[0323 14:44:36 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14476/173481[03:00<32:57,80.41it/s]  9%|8         |15160/173481[03:10<32:48,80.41it/s] 15%|#5        |26361/173481[06:00<33:48,72.51it/s] 16%|#5        |27000/173481[06:10<33:40,72.51it/s] 21%|##1       |37296/173481[09:00<34:20,66.10it/s] 22%|##1       |37939/173481[09:10<34:10,66.10it/s] 30%|##9       |51269/173481[12:00<28:31,71.40it/s] 30%|###       |52090/173481[12:10<28:20,71.40it/s] 38%|###7      |65321/173481[15:00<24:10,74.58it/s] 38%|###8      |66137/173481[15:10<23:59,74.58it/s] 46%|####5     |79076/173481[18:00<20:50,75.47it/s] 46%|####6     |79825/173481[18:10<20:40,75.47it/s] 54%|#####3    |93576/173481[21:00<17:05,77.92it/s] 54%|#####4    |94445/173481[21:11<16:54,77.92it/s] 60%|######    |104710/173481[24:00<16:37,68.97it/s] 61%|######    |105370/173481[24:11<16:27,68.97it/s] 67%|######6   |115497/173481[27:00<15:04,64.13it/s] 67%|######6   |116155/173481[27:11<14:53,64.13it/s] 73%|#######2  |126291/173481[30:00<12:41,61.97it/s] 73%|#######3  |127008/173481[30:11<12:29,61.97it/s] 79%|#######9  |137301/173481[33:00<09:47,61.56it/s] 80%|#######9  |137970/173481[33:11<09:36,61.56it/s] 85%|########5 |148261/173481[36:00<06:51,61.21it/s] 86%|########5 |148967/173481[36:11<06:40,61.21it/s] 92%|#########1|158891/173481[39:00<04:02,60.11it/s] 92%|#########2|159615/173481[39:12<03:50,60.11it/s] 98%|#########7|169868/173481[42:00<00:59,60.55it/s] 98%|#########8|170590/173481[42:12<00:47,60.55it/s]100%|##########|173481/173481[43:00<00:00,67.23it/s]
[32m[0323 15:27:36 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:2580.45 sec.
[32m[0323 15:27:37 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-1040886.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:26<00:00,128.33it/s]
5
[32m[0323 15:30:03 @monitor.py:363][0m QueueInput/queue_size: 0.58577
[32m[0323 15:30:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 11.293
[32m[0323 15:30:03 @monitor.py:363][0m activation-summaries/output-rms: 0.033018
[32m[0323 15:30:03 @monitor.py:363][0m cross_entropy_loss: 2.155
[32m[0323 15:30:03 @monitor.py:363][0m lr: 0.00025
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26392
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1069
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.18951
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.37123
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.30242
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.32162
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 15:30:03 @monitor.py:363][0m train-error-top1: 0.54487
[32m[0323 15:30:03 @monitor.py:363][0m val-error-top1: 0.63833
[32m[0323 15:30:03 @monitor.py:363][0m val-utt-error: 0.30146
[32m[0323 15:30:03 @monitor.py:363][0m validation_cost: 2.5841
[32m[0323 15:30:03 @monitor.py:363][0m wd_cost: 0.14217
[32m[0323 15:30:03 @group.py:42][0m Callbacks took 146.913 sec in total. InferenceRunner: 146.687sec
[32m[0323 15:30:03 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14045/173481[03:00<34:03,78.02it/s]  8%|8         |14660/173481[03:10<33:55,78.02it/s] 14%|#4        |25150/173481[06:00<35:53,68.89it/s] 15%|#4        |25754/173481[06:10<35:44,68.89it/s] 20%|##        |35483/173481[09:00<36:43,62.62it/s] 21%|##        |36054/173481[09:10<36:34,62.62it/s] 26%|##6       |45510/173481[12:00<36:10,58.96it/s] 27%|##6       |46114/173481[12:10<36:00,58.96it/s] 33%|###2      |56446/173481[15:00<32:35,59.84it/s] 33%|###2      |57134/173481[15:10<32:24,59.84it/s] 39%|###8      |67330/173481[18:00<29:24,60.15it/s] 39%|###9      |68003/173481[18:11<29:13,60.15it/s] 45%|####5     |78543/173481[21:00<25:51,61.20it/s] 46%|####5     |79196/173481[21:11<25:40,61.20it/s] 52%|#####1    |89867/173481[24:00<22:27,62.04it/s] 52%|#####2    |90604/173481[24:11<22:15,62.04it/s] 58%|#####8    |101107/173481[27:00<19:22,62.24it/s] 59%|#####8    |101794/173481[27:11<19:11,62.24it/s] 65%|######4   |112190/173481[30:00<16:30,61.90it/s] 65%|######5   |112834/173481[30:11<16:19,61.90it/s] 71%|#######   |123121/173481[33:00<13:41,61.31it/s] 71%|#######1  |123829/173481[33:11<13:29,61.31it/s] 77%|#######7  |134101/173481[36:00<10:43,61.15it/s] 78%|#######7  |134806/173481[36:11<10:32,61.15it/s] 90%|######### |156889/173481[39:00<03:21,82.47it/s] 91%|#########1|158629/173481[39:12<03:00,82.47it/s] 97%|#########7|168929/173481[42:00<01:01,73.87it/s] 98%|#########7|169679/173481[42:12<00:51,73.87it/s]100%|##########|173481/173481[43:14<00:00,66.87it/s]
[32m[0323 16:13:18 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:2594.37 sec.
[32m[0323 16:13:18 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-1214367.
[32m[0323 16:13:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:28<00:00,211.70it/s]
6
[32m[0323 16:14:47 @monitor.py:363][0m QueueInput/queue_size: 0.74154
[32m[0323 16:14:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 15.163
[32m[0323 16:14:47 @monitor.py:363][0m activation-summaries/output-rms: 0.034952
[32m[0323 16:14:47 @monitor.py:363][0m cross_entropy_loss: 2.1151
[32m[0323 16:14:47 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31927
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1242
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.20908
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.45925
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.37572
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.40082
[32m[0323 16:14:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 16:14:47 @monitor.py:363][0m train-error-top1: 0.53921
[32m[0323 16:14:47 @monitor.py:363][0m val-error-top1: 0.64748
[32m[0323 16:14:47 @monitor.py:363][0m val-utt-error: 0.32882
[32m[0323 16:14:47 @monitor.py:363][0m validation_cost: 2.6525
[32m[0323 16:14:47 @monitor.py:363][0m wd_cost: 0.20579
[32m[0323 16:14:47 @group.py:42][0m Callbacks took 89.298 sec in total. InferenceRunner: 88.917sec
[32m[0323 16:14:47 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11589/173481[03:00<41:55,64.37it/s]  7%|7         |12258/173481[03:10<41:44,64.37it/s] 13%|#3        |22610/173481[06:00<40:04,62.76it/s] 13%|#3        |23228/173481[06:10<39:54,62.76it/s] 19%|#8        |32709/173481[09:00<39:36,59.23it/s] 19%|#9        |33288/173481[09:10<39:26,59.23it/s] 25%|##4       |43274/173481[12:00<36:48,58.96it/s] 25%|##5       |43896/173481[12:10<36:37,58.96it/s] 31%|###       |53709/173481[15:00<34:08,58.45it/s] 31%|###1      |54343/173481[15:10<33:58,58.45it/s] 37%|###7      |64410/173481[18:00<30:50,58.95it/s] 38%|###7      |65088/173481[18:10<30:38,58.95it/s] 44%|####3     |75865/173481[21:00<26:35,61.20it/s] 44%|####4     |76588/173481[21:11<26:23,61.20it/s] 50%|#####     |87098/173481[24:00<23:17,61.80it/s] 51%|#####     |87773/173481[24:11<23:06,61.80it/s] 57%|#####6    |98334/173481[27:00<20:10,62.10it/s] 57%|#####7    |99068/173481[27:11<19:58,62.10it/s] 63%|######3   |110003/173481[30:00<16:40,63.44it/s] 64%|######3   |110761/173481[30:11<16:28,63.44it/s] 70%|#######   |121479/173481[33:00<13:37,63.59it/s] 70%|#######   |122178/173481[33:11<13:26,63.59it/s] 77%|#######6  |132759/173481[36:00<10:45,63.12it/s] 77%|#######6  |133463/173481[36:11<10:33,63.12it/s] 83%|########3 |144570/173481[39:00<07:29,64.34it/s] 84%|########3 |145392/173481[39:12<07:16,64.34it/s] 90%|######### |156324/173481[42:00<04:24,64.81it/s] 91%|######### |157118/173481[42:12<04:12,64.81it/s] 97%|#########6|167654/173481[45:00<01:31,63.86it/s] 97%|#########7|168452/173481[45:12<01:18,63.86it/s]100%|##########|173481/173481[46:30<00:00,62.16it/s]
[32m[0323 17:01:18 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:2790.86 sec.
[32m[0323 17:01:18 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-1387848.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.43it/s]
7
[32m[0323 17:03:17 @monitor.py:363][0m QueueInput/queue_size: 0.087532
[32m[0323 17:03:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 17.256
[32m[0323 17:03:17 @monitor.py:363][0m activation-summaries/output-rms: 0.034878
[32m[0323 17:03:17 @monitor.py:363][0m cross_entropy_loss: 2.1309
[32m[0323 17:03:17 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.35904
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1354
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.21799
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.48841
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.40333
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.42909
[32m[0323 17:03:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 17:03:17 @monitor.py:363][0m train-error-top1: 0.54579
[32m[0323 17:03:17 @monitor.py:363][0m val-error-top1: 0.65441
[32m[0323 17:03:17 @monitor.py:363][0m val-utt-error: 0.35044
[32m[0323 17:03:17 @monitor.py:363][0m validation_cost: 2.692
[32m[0323 17:03:17 @monitor.py:363][0m wd_cost: 0.23576
[32m[0323 17:03:17 @group.py:42][0m Callbacks took 119.096 sec in total. InferenceRunner: 118.814sec
[32m[0323 17:03:17 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13231/173481[03:00<36:20,73.50it/s]  8%|7         |13857/173481[03:10<36:11,73.50it/s] 14%|#3        |24075/173481[06:00<37:36,66.22it/s] 14%|#4        |24697/173481[06:10<37:26,66.22it/s] 20%|##        |35468/173481[09:00<35:32,64.71it/s] 21%|##        |36156/173481[09:10<35:22,64.71it/s] 27%|##7       |47198/173481[12:00<32:24,64.94it/s] 28%|##7       |47903/173481[12:10<32:13,64.94it/s] 34%|###3      |58486/173481[15:00<30:02,63.80it/s] 34%|###4      |59176/173481[15:10<29:51,63.80it/s] 40%|####      |70183/173481[18:00<26:44,64.38it/s] 41%|####      |70871/173481[18:10<26:33,64.38it/s] 47%|####7     |81734/173481[21:00<23:47,64.28it/s] 48%|####7     |82435/173481[21:11<23:36,64.28it/s] 53%|#####3    |92795/173481[24:00<21:24,62.83it/s] 54%|#####3    |93527/173481[24:11<21:12,62.83it/s] 60%|######    |104313/173481[27:00<18:10,63.40it/s] 61%|######    |105046/173481[27:11<17:59,63.40it/s] 67%|######6   |115841/173481[30:00<15:04,63.72it/s] 67%|######7   |116537/173481[30:11<14:53,63.72it/s] 73%|#######3  |127203/173481[33:00<12:09,63.42it/s] 74%|#######3  |127922/173481[33:11<11:58,63.42it/s] 80%|#######9  |138448/173481[36:00<09:16,62.94it/s] 80%|########  |139212/173481[36:11<09:04,62.94it/s] 86%|########6 |150002/173481[39:00<06:09,63.56it/s] 87%|########6 |150842/173481[39:12<05:56,63.56it/s] 93%|#########3|161953/173481[42:00<02:57,64.94it/s] 94%|#########3|162650/173481[42:12<02:46,64.94it/s] 99%|#########9|171987/173481[45:00<00:24,59.99it/s]100%|#########9|172727/173481[45:12<00:12,59.99it/s]100%|##########|173481/173481[45:25<00:00,63.65it/s]
[32m[0323 17:48:42 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:2725.48 sec.
[32m[0323 17:48:43 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-1561329.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:21<00:00,231.94it/s]
8
[32m[0323 17:50:04 @monitor.py:363][0m QueueInput/queue_size: 0.34271
[32m[0323 17:50:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.862
[32m[0323 17:50:04 @monitor.py:363][0m activation-summaries/output-rms: 0.03497
[32m[0323 17:50:04 @monitor.py:363][0m cross_entropy_loss: 2.0665
[32m[0323 17:50:04 @monitor.py:363][0m lr: 0.000125
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.40235
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1446
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.24203
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.56211
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.46185
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.49446
[32m[0323 17:50:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 17:50:04 @monitor.py:363][0m train-error-top1: 0.53245
[32m[0323 17:50:04 @monitor.py:363][0m val-error-top1: 0.59311
[32m[0323 17:50:04 @monitor.py:363][0m val-utt-error: 0.2419
[32m[0323 17:50:04 @monitor.py:363][0m validation_cost: 2.3536
[32m[0323 17:50:04 @monitor.py:363][0m wd_cost: 0.061017
[32m[0323 17:50:04 @group.py:42][0m Callbacks took 81.395 sec in total. InferenceRunner: 81.160sec
[32m[0323 17:50:04 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11115/173481[03:00<43:49,61.75it/s]  7%|6         |11726/173481[03:10<43:39,61.75it/s] 13%|#2        |22097/173481[06:00<41:06,61.38it/s] 13%|#3        |22596/173481[06:10<40:58,61.38it/s] 19%|#9        |33289/173481[09:00<37:49,61.77it/s] 20%|#9        |33974/173481[09:10<37:38,61.77it/s] 26%|##5       |44602/173481[12:00<34:28,62.30it/s] 26%|##6       |45277/173481[12:10<34:17,62.30it/s] 32%|###2      |55992/173481[15:00<31:11,62.78it/s] 33%|###2      |56661/173481[15:10<31:00,62.78it/s] 39%|###8      |67002/173481[18:00<28:38,61.95it/s] 39%|###8      |67631/173481[18:11<28:28,61.95it/s] 45%|####4     |78036/173481[21:00<25:48,61.62it/s] 45%|####5     |78712/173481[21:11<25:37,61.62it/s] 52%|#####1    |89347/173481[24:00<22:32,62.22it/s] 52%|#####1    |90028/173481[24:11<22:21,62.22it/s] 58%|#####7    |100217/173481[27:00<19:55,61.28it/s] 58%|#####8    |100936/173481[27:11<19:43,61.28it/s] 64%|######3   |110847/173481[30:00<17:21,60.15it/s] 64%|######4   |111556/173481[30:11<17:09,60.15it/s] 71%|#######   |122797/173481[33:00<13:23,63.11it/s] 71%|#######1  |123521/173481[33:11<13:11,63.11it/s] 78%|#######8  |135559/173481[36:00<09:27,66.78it/s] 79%|#######8  |136446/173481[36:12<09:14,66.78it/s] 86%|########6 |149727/173481[39:00<05:28,72.25it/s] 87%|########6 |150681/173481[39:12<05:15,72.25it/s] 94%|#########4|163801/173481[42:00<02:08,75.10it/s] 95%|#########4|164800/173481[42:12<01:55,75.10it/s][32m[0323 18:34:18 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:2653.81 sec.
100%|##########|173481/173481[44:13<00:00,65.37it/s]
[32m[0323 18:34:18 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-1734810.
[32m[0323 18:34:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:26<00:00,216.62it/s]
9
[32m[0323 18:35:45 @monitor.py:363][0m QueueInput/queue_size: 0.6222
[32m[0323 18:35:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 23.527
[32m[0323 18:35:45 @monitor.py:363][0m activation-summaries/output-rms: 0.036664
[32m[0323 18:35:45 @monitor.py:363][0m cross_entropy_loss: 1.9766
[32m[0323 18:35:45 @monitor.py:363][0m lr: 0.000125
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.44833
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1497
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2654
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.6416
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.52926
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.56979
[32m[0323 18:35:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 18:35:45 @monitor.py:363][0m train-error-top1: 0.51998
[32m[0323 18:35:45 @monitor.py:363][0m val-error-top1: 0.60892
[32m[0323 18:35:45 @monitor.py:363][0m val-utt-error: 0.26246
[32m[0323 18:35:45 @monitor.py:363][0m validation_cost: 2.4435
[32m[0323 18:35:45 @monitor.py:363][0m wd_cost: 0.078211
[32m[0323 18:35:45 @group.py:42][0m Callbacks took 87.575 sec in total. InferenceRunner: 86.899sec
[32m[0323 18:35:45 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11127/173481[03:00<43:46,61.82it/s]  7%|6         |11930/173481[03:10<43:33,61.82it/s] 14%|#3        |23907/173481[06:00<37:43,66.09it/s] 14%|#4        |24495/173481[06:10<37:34,66.09it/s] 19%|#9        |33661/173481[09:00<39:08,59.55it/s] 20%|#9        |34161/173481[09:10<38:59,59.55it/s] 24%|##4       |42221/173481[12:00<41:22,52.87it/s] 25%|##4       |42715/173481[12:10<41:13,52.87it/s] 29%|##9       |50826/173481[15:00<40:42,50.21it/s] 30%|##9       |51330/173481[15:10<40:32,50.21it/s] 34%|###4      |59754/173481[18:00<37:59,49.90it/s] 35%|###4      |60290/173481[18:10<37:48,49.90it/s] 40%|####      |69593/173481[21:00<33:11,52.17it/s] 40%|####      |70115/173481[21:11<33:01,52.17it/s] 45%|####5     |78609/173481[24:00<30:56,51.11it/s] 46%|####5     |79190/173481[24:11<30:44,51.11it/s] 51%|#####     |87808/173481[27:00<27:56,51.11it/s] 51%|#####     |88400/173481[27:11<27:44,51.11it/s] 56%|#####5    |97126/173481[30:00<24:44,51.42it/s] 56%|#####6    |97710/173481[30:11<24:33,51.42it/s] 61%|######1   |106136/173481[33:00<22:07,50.73it/s] 62%|######1   |106730/173481[33:11<21:55,50.73it/s] 68%|######7   |117428/173481[36:00<16:39,56.09it/s] 68%|######8   |118075/173481[36:11<16:27,56.09it/s] 74%|#######3  |128086/173481[39:00<13:08,57.61it/s] 74%|#######4  |128856/173481[39:12<12:54,57.61it/s] 80%|#######9  |138441/173481[42:00<10:08,57.55it/s] 80%|########  |139105/173481[42:12<09:57,57.55it/s] 85%|########5 |148211/173481[45:00<07:32,55.86it/s] 86%|########5 |148870/173481[45:12<07:20,55.86it/s] 91%|#########1|158006/173481[48:00<04:40,55.12it/s] 91%|#########1|158711/173481[48:12<04:27,55.12it/s] 96%|#########6|167261/173481[51:00<01:56,53.19it/s] 97%|#########6|167889/173481[51:12<01:45,53.19it/s]100%|##########|173481/173481[53:04<00:00,54.47it/s]
[32m[0323 19:28:50 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3184.79 sec.
[32m[0323 19:28:50 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-1908291.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:16<00:00,247.27it/s]
10
[32m[0323 19:30:06 @monitor.py:363][0m QueueInput/queue_size: 0.34279
[32m[0323 19:30:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 26.074
[32m[0323 19:30:06 @monitor.py:363][0m activation-summaries/output-rms: 0.035328
[32m[0323 19:30:06 @monitor.py:363][0m cross_entropy_loss: 1.9563
[32m[0323 19:30:06 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.48843
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.155
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27964
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.69289
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.57613
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.62114
[32m[0323 19:30:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 19:30:06 @monitor.py:363][0m train-error-top1: 0.51489
[32m[0323 19:30:06 @monitor.py:363][0m val-error-top1: 0.57635
[32m[0323 19:30:06 @monitor.py:363][0m val-utt-error: 0.23111
[32m[0323 19:30:06 @monitor.py:363][0m validation_cost: 2.2911
[32m[0323 19:30:06 @monitor.py:363][0m wd_cost: 0.091274
[32m[0323 19:30:06 @group.py:42][0m Callbacks took 76.344 sec in total. InferenceRunner: 76.128sec
[32m[0323 19:30:06 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9757/173481[03:00<50:20,54.20it/s]  6%|5         |10302/173481[03:10<50:10,54.20it/s] 11%|#         |19010/173481[06:00<48:47,52.76it/s] 11%|#1        |19524/173481[06:10<48:37,52.76it/s] 16%|#6        |28347/173481[09:00<46:14,52.31it/s] 17%|#6        |28900/173481[09:10<46:03,52.31it/s] 21%|##1       |37273/173481[12:00<44:35,50.91it/s] 22%|##1       |37800/173481[12:10<44:24,50.91it/s] 27%|##6       |46044/173481[15:00<42:39,49.80it/s] 27%|##6       |46534/173481[15:10<42:29,49.80it/s] 31%|###1      |54575/173481[18:00<40:48,48.55it/s] 32%|###1      |55124/173481[18:10<40:37,48.55it/s] 37%|###6      |63742/173481[21:00<36:47,49.71it/s] 37%|###7      |64254/173481[21:11<36:37,49.71it/s] 42%|####2     |73075/173481[24:00<32:58,50.75it/s] 42%|####2     |73584/173481[24:11<32:48,50.75it/s] 48%|####7     |82497/173481[27:00<29:25,51.54it/s] 48%|####7     |83089/173481[27:11<29:13,51.54it/s] 53%|#####2    |91906/173481[30:00<26:11,51.90it/s] 53%|#####3    |92499/173481[30:11<26:00,51.90it/s] 59%|#####8    |101540/173481[33:00<22:45,52.70it/s] 59%|#####8    |102154/173481[33:11<22:33,52.70it/s] 64%|######4   |111095/173481[36:00<19:39,52.88it/s] 64%|######4   |111709/173481[36:11<19:28,52.88it/s] 69%|######9   |120485/173481[39:00<16:49,52.52it/s] 70%|######9   |121099/173481[39:12<16:37,52.52it/s] 75%|#######4  |129985/173481[42:00<13:46,52.64it/s] 75%|#######5  |130584/173481[42:12<13:34,52.64it/s] 81%|########  |140326/173481[45:00<10:03,54.94it/s] 81%|########1 |140988/173481[45:12<09:51,54.94it/s] 87%|########7 |151546/173481[48:00<06:15,58.40it/s] 88%|########7 |152299/173481[48:12<06:02,58.40it/s] 95%|#########5|165186/173481[51:00<02:05,65.96it/s] 96%|#########5|165924/173481[51:12<01:54,65.96it/s]100%|##########|173481/173481[53:19<00:00,54.22it/s]
[32m[0323 20:23:26 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3199.57 sec.
[32m[0323 20:23:26 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-2081772.
[32m[0323 20:23:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,199.10it/s]
11
[32m[0323 20:25:01 @monitor.py:363][0m QueueInput/queue_size: 0.34709
[32m[0323 20:25:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.337
[32m[0323 20:25:01 @monitor.py:363][0m activation-summaries/output-rms: 0.035737
[32m[0323 20:25:01 @monitor.py:363][0m cross_entropy_loss: 2.0001
[32m[0323 20:25:01 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.51553
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1583
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29112
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.74178
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.61541
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.66607
[32m[0323 20:25:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 20:25:01 @monitor.py:363][0m train-error-top1: 0.52398
[32m[0323 20:25:01 @monitor.py:363][0m val-error-top1: 0.57987
[32m[0323 20:25:01 @monitor.py:363][0m val-utt-error: 0.23372
[32m[0323 20:25:01 @monitor.py:363][0m validation_cost: 2.2902
[32m[0323 20:25:01 @monitor.py:363][0m wd_cost: 0.02064
[32m[0323 20:25:01 @group.py:42][0m Callbacks took 95.136 sec in total. InferenceRunner: 94.543sec
[32m[0323 20:25:01 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12165/173481[03:00<39:46,67.58it/s]  7%|7         |12878/173481[03:10<39:36,67.58it/s] 13%|#3        |23294/173481[06:00<38:45,64.57it/s] 14%|#3        |23908/173481[06:10<38:36,64.57it/s] 19%|#8        |32220/173481[09:00<41:58,56.10it/s] 19%|#8        |32748/173481[09:10<41:48,56.10it/s] 24%|##3       |41349/173481[12:00<41:20,53.27it/s] 24%|##4       |41898/173481[12:10<41:10,53.27it/s] 29%|##9       |50564/173481[15:00<39:14,52.21it/s] 29%|##9       |51123/173481[15:10<39:03,52.21it/s] 35%|###4      |60139/173481[18:00<35:50,52.69it/s] 35%|###5      |60733/173481[18:10<35:39,52.69it/s] 41%|####      |70503/173481[21:00<31:11,55.03it/s] 41%|####1     |71171/173481[21:11<30:59,55.03it/s] 47%|####6     |81140/173481[24:00<27:00,56.99it/s] 47%|####7     |81784/173481[24:11<26:49,56.99it/s] 53%|#####2    |91177/173481[27:00<24:20,56.37it/s] 53%|#####2    |91788/173481[27:11<24:09,56.37it/s] 58%|#####8    |101032/173481[30:00<21:44,55.55it/s] 59%|#####8    |101664/173481[30:11<21:32,55.55it/s] 64%|######3   |111009/173481[33:00<18:45,55.49it/s] 64%|######4   |111638/173481[33:11<18:34,55.49it/s] 70%|######9   |121225/173481[36:00<15:31,56.11it/s] 70%|#######   |121883/173481[36:11<15:19,56.11it/s] 76%|#######5  |131493/173481[39:00<12:22,56.57it/s] 76%|#######6  |132261/173481[39:12<12:08,56.57it/s] 82%|########2 |142807/173481[42:00<08:35,59.55it/s] 83%|########2 |143509/173481[42:12<08:23,59.55it/s] 89%|########8 |153804/173481[45:00<05:26,60.30it/s] 89%|########9 |154593/173481[45:12<05:13,60.30it/s] 95%|#########4|164281/173481[48:00<02:35,59.23it/s] 95%|#########5|165009/173481[48:12<02:23,59.23it/s]100%|##########|173481/173481[50:34<00:00,57.17it/s]
[32m[0323 21:15:35 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3034.38 sec.
[32m[0323 21:15:36 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-2255253.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:27<00:00,216.26it/s]
12
[32m[0323 21:17:03 @monitor.py:363][0m QueueInput/queue_size: 0.54978
[32m[0323 21:17:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 29.357
[32m[0323 21:17:03 @monitor.py:363][0m activation-summaries/output-rms: 0.03581
[32m[0323 21:17:03 @monitor.py:363][0m cross_entropy_loss: 1.9759
[32m[0323 21:17:03 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.54206
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1602
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.30093
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.78988
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.65491
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.71102
[32m[0323 21:17:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 21:17:03 @monitor.py:363][0m train-error-top1: 0.51636
[32m[0323 21:17:03 @monitor.py:363][0m val-error-top1: 0.58012
[32m[0323 21:17:03 @monitor.py:363][0m val-utt-error: 0.23945
[32m[0323 21:17:03 @monitor.py:363][0m validation_cost: 2.2963
[32m[0323 21:17:03 @monitor.py:363][0m wd_cost: 0.023119
[32m[0323 21:17:03 @group.py:42][0m Callbacks took 87.182 sec in total. InferenceRunner: 87.045sec
[32m[0323 21:17:03 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11223/173481[03:00<43:22,62.34it/s]  7%|6         |11752/173481[03:10<43:14,62.34it/s] 12%|#1        |20513/173481[06:00<45:08,56.47it/s] 12%|#2        |21078/173481[06:10<44:58,56.47it/s] 18%|#7        |31143/173481[09:00<41:05,57.73it/s] 18%|#8        |31762/173481[09:10<40:54,57.73it/s] 24%|##4       |42205/173481[12:00<36:45,59.53it/s] 25%|##4       |42888/173481[12:10<36:33,59.53it/s] 31%|###       |53298/173481[15:00<33:04,60.55it/s] 31%|###1      |53907/173481[15:10<32:54,60.55it/s] 37%|###7      |64588/173481[18:00<29:27,61.61it/s] 38%|###7      |65323/173481[18:11<29:15,61.61it/s] 44%|####4     |76573/173481[21:00<25:14,64.00it/s] 45%|####4     |77289/173481[21:11<25:03,64.00it/s] 51%|#####1    |88563/173481[24:00<21:40,65.28it/s] 52%|#####1    |89347/173481[24:11<21:28,65.28it/s] 58%|#####8    |100638/173481[27:00<18:20,66.16it/s] 58%|#####8    |101377/173481[27:11<18:09,66.16it/s] 65%|######4   |112198/173481[30:00<15:40,65.17it/s] 65%|######5   |112912/173481[30:11<15:29,65.17it/s] 71%|#######1  |123775/173481[33:00<12:47,64.74it/s] 72%|#######1  |124543/173481[33:11<12:35,64.74it/s] 78%|#######8  |135483/173481[36:00<09:45,64.89it/s] 79%|#######8  |136202/173481[36:12<09:34,64.89it/s] 84%|########4 |146138/173481[39:00<07:21,61.91it/s] 85%|########4 |146947/173481[39:12<07:08,61.91it/s] 91%|######### |157848/173481[42:00<04:06,63.44it/s] 91%|#########1|158623/173481[42:12<03:54,63.44it/s] 97%|#########7|168617/173481[45:00<01:18,61.58it/s] 98%|#########7|169363/173481[45:12<01:06,61.58it/s]100%|##########|173481/173481[46:26<00:00,62.26it/s]
[32m[0323 22:03:29 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:2786.20 sec.
[32m[0323 22:03:29 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-2428734.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:19<00:00,236.94it/s]
13
[32m[0323 22:04:48 @monitor.py:363][0m QueueInput/queue_size: 0.31683
[32m[0323 22:04:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31
[32m[0323 22:04:48 @monitor.py:363][0m activation-summaries/output-rms: 0.035607
[32m[0323 22:04:48 @monitor.py:363][0m cross_entropy_loss: 1.986
[32m[0323 22:04:48 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56367
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.162
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.30762
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.82565
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.68471
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.74481
[32m[0323 22:04:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 22:04:48 @monitor.py:363][0m train-error-top1: 0.51798
[32m[0323 22:04:48 @monitor.py:363][0m val-error-top1: 0.57381
[32m[0323 22:04:48 @monitor.py:363][0m val-utt-error: 0.23908
[32m[0323 22:04:48 @monitor.py:363][0m validation_cost: 2.2713
[32m[0323 22:04:48 @monitor.py:363][0m wd_cost: 0.0050151
[32m[0323 22:04:48 @group.py:42][0m Callbacks took 79.610 sec in total. InferenceRunner: 79.447sec
[32m[0323 22:04:48 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11602/173481[03:00<41:52,64.44it/s]  7%|7         |12316/173481[03:10<41:41,64.44it/s] 13%|#3        |22787/173481[06:00<39:42,63.26it/s] 13%|#3        |23276/173481[06:10<39:34,63.26it/s] 18%|#8        |31863/173481[09:00<42:03,56.11it/s] 19%|#8        |32479/173481[09:10<41:52,56.11it/s] 24%|##4       |42409/173481[12:00<38:06,57.32it/s] 25%|##4       |43041/173481[12:10<37:55,57.32it/s] 30%|###       |52863/173481[15:00<34:50,57.70it/s] 31%|###       |53451/173481[15:10<34:40,57.70it/s] 35%|###5      |61216/173481[18:00<36:22,51.44it/s] 36%|###5      |61836/173481[18:11<36:10,51.44it/s] 42%|####1     |72073/173481[21:00<30:26,55.52it/s] 42%|####1     |72721/173481[21:11<30:14,55.52it/s] 48%|####7     |82691/173481[24:00<26:27,57.20it/s] 48%|####8     |83306/173481[24:11<26:16,57.20it/s] 53%|#####3    |92392/173481[27:00<24:21,55.49it/s] 54%|#####3    |92871/173481[27:11<24:12,55.49it/s] 58%|#####8    |100920/173481[30:00<23:39,51.11it/s] 58%|#####8    |101436/173481[30:11<23:29,51.11it/s] 64%|######4   |111879/173481[33:00<18:28,55.57it/s] 65%|######4   |112543/173481[33:11<18:16,55.57it/s] 71%|#######1  |123317/173481[36:00<14:06,59.29it/s] 71%|#######1  |123946/173481[36:11<13:55,59.29it/s] 77%|#######6  |132982/173481[39:00<11:58,56.34it/s] 77%|#######7  |133621/173481[39:12<11:47,56.34it/s] 82%|########2 |142847/173481[42:00<09:11,55.56it/s] 83%|########2 |143486/173481[42:12<08:59,55.56it/s] 88%|########8 |153442/173481[45:00<05:50,57.16it/s] 89%|########8 |154146/173481[45:12<05:38,57.16it/s] 94%|#########4|163422/173481[48:00<02:58,56.29it/s] 95%|#########4|164158/173481[48:12<02:45,56.29it/s]100%|##########|173481/173481[50:46<00:00,56.95it/s]
[32m[0323 22:55:35 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3046.08 sec.
[32m[0323 22:55:35 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-2602215.
[32m[0323 22:55:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:20<00:00,234.50it/s]
14
[32m[0323 22:56:55 @monitor.py:363][0m QueueInput/queue_size: 0.33634
[32m[0323 22:56:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.844
[32m[0323 22:56:55 @monitor.py:363][0m activation-summaries/output-rms: 0.037115
[32m[0323 22:56:55 @monitor.py:363][0m cross_entropy_loss: 1.9313
[32m[0323 22:56:55 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5778
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1632
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.31166
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.85211
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.70581
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.76916
[32m[0323 22:56:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 22:56:55 @monitor.py:363][0m train-error-top1: 0.50678
[32m[0323 22:56:55 @monitor.py:363][0m val-error-top1: 0.5752
[32m[0323 22:56:55 @monitor.py:363][0m val-utt-error: 0.23032
[32m[0323 22:56:55 @monitor.py:363][0m validation_cost: 2.2745
[32m[0323 22:56:55 @monitor.py:363][0m wd_cost: 0.0053012
[32m[0323 22:56:55 @group.py:42][0m Callbacks took 80.859 sec in total. InferenceRunner: 80.272sec
[32m[0323 22:56:55 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12011/173481[03:00<40:19,66.73it/s]  7%|7         |12605/173481[03:10<40:10,66.73it/s] 14%|#3        |23906/173481[06:00<37:32,66.40it/s] 14%|#4        |24495/173481[06:10<37:23,66.40it/s] 20%|##        |35009/173481[09:00<36:05,63.95it/s] 21%|##        |35602/173481[09:10<35:55,63.95it/s] 26%|##6       |45645/173481[12:00<34:41,61.43it/s] 27%|##6       |46290/173481[12:10<34:30,61.43it/s] 32%|###2      |56148/173481[15:00<32:40,59.85it/s] 33%|###2      |56821/173481[15:10<32:29,59.85it/s] 39%|###8      |66847/173481[18:00<29:47,59.64it/s] 39%|###8      |67451/173481[18:11<29:37,59.64it/s] 45%|####4     |77653/173481[21:00<26:41,59.84it/s] 45%|####5     |78374/173481[21:11<26:29,59.84it/s] 52%|#####1    |90111/173481[24:00<21:39,64.17it/s] 52%|#####2    |90874/173481[24:11<21:27,64.17it/s] 59%|#####8    |102216/173481[27:00<18:05,65.67it/s] 59%|#####9    |102930/173481[27:11<17:54,65.67it/s] 66%|######6   |114777/173481[30:00<14:27,67.66it/s] 67%|######6   |115667/173481[30:11<14:14,67.66it/s] 73%|#######3  |126971/173481[33:00<11:27,67.70it/s] 74%|#######3  |127695/173481[33:11<11:16,67.70it/s] 80%|#######9  |138037/173481[36:00<09:10,64.44it/s] 80%|#######9  |138765/173481[36:12<08:58,64.44it/s] 86%|########5 |148791/173481[39:00<06:38,62.00it/s] 86%|########6 |149495/173481[39:12<06:26,62.00it/s] 92%|#########1|159187/173481[42:00<03:59,59.80it/s] 92%|#########2|159860/173481[42:12<03:47,59.80it/s] 99%|#########9|172481/173481[45:00<00:15,66.09it/s]100%|#########9|173280/173481[45:12<00:03,66.09it/s]100%|##########|173481/173481[45:15<00:00,63.88it/s]
[32m[0323 23:42:11 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:2715.65 sec.
[32m[0323 23:42:11 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-2775696.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:21<00:00,229.85it/s]
15
[32m[0323 23:43:33 @monitor.py:363][0m QueueInput/queue_size: 0.24426
[32m[0323 23:43:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 32.787
[32m[0323 23:43:33 @monitor.py:363][0m activation-summaries/output-rms: 0.035839
[32m[0323 23:43:33 @monitor.py:363][0m cross_entropy_loss: 1.9336
[32m[0323 23:43:33 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59202
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1645
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.31524
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.87795
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.72667
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.79328
[32m[0323 23:43:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0323 23:43:33 @monitor.py:363][0m train-error-top1: 0.5051
[32m[0323 23:43:33 @monitor.py:363][0m val-error-top1: 0.57944
[32m[0323 23:43:33 @monitor.py:363][0m val-utt-error: 0.23488
[32m[0323 23:43:33 @monitor.py:363][0m validation_cost: 2.2799
[32m[0323 23:43:33 @monitor.py:363][0m wd_cost: 0.0055898
[32m[0323 23:43:33 @group.py:42][0m Callbacks took 82.093 sec in total. InferenceRunner: 81.896sec
[32m[0323 23:43:33 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11536/173481[03:00<42:06,64.09it/s]  7%|7         |12243/173481[03:10<41:55,64.09it/s] 14%|#3        |23786/173481[06:00<37:47,66.01it/s] 14%|#4        |24444/173481[06:10<37:37,66.01it/s] 21%|##1       |37121/173481[09:00<32:33,69.81it/s] 22%|##1       |38141/173481[09:10<32:18,69.81it/s] 31%|###1      |54600/173481[12:00<24:23,81.23it/s] 32%|###1      |55334/173481[12:10<24:14,81.23it/s] 39%|###8      |67115/173481[15:00<23:39,74.92it/s] 39%|###9      |67799/173481[15:10<23:30,74.92it/s] 45%|####5     |78215/173481[18:00<23:28,67.65it/s] 46%|####5     |78979/173481[18:11<23:16,67.65it/s] 53%|#####3    |91998/173481[21:00<18:54,71.83it/s] 54%|#####3    |93234/173481[21:11<18:37,71.83it/s] 62%|######1   |107072/173481[24:00<14:18,77.33it/s] 62%|######2   |108409/173481[24:11<14:01,77.33it/s] 69%|######9   |120150/173481[27:00<11:51,74.91it/s] 70%|######9   |120914/173481[27:11<11:41,74.91it/s] 76%|#######5  |131745/173481[30:00<10:02,69.26it/s] 76%|#######6  |132454/173481[30:11<09:52,69.26it/s] 83%|########2 |143392/173481[33:00<07:29,66.90it/s] 83%|########3 |144102/173481[33:11<07:19,66.90it/s] 89%|########9 |154795/173481[36:00<04:47,65.07it/s] 90%|########9 |155514/173481[36:12<04:36,65.07it/s] 96%|#########5|166118/173481[39:00<01:55,63.97it/s] 96%|#########6|166959/173481[39:12<01:41,63.97it/s]100%|##########|173481/173481[41:03<00:00,70.41it/s]
[32m[0324 00:24:37 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:2463.73 sec.
[32m[0324 00:24:37 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-2949177.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,208.90it/s]
16
[32m[0324 00:26:07 @monitor.py:363][0m QueueInput/queue_size: 0.065987
[32m[0324 00:26:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 33.91
[32m[0324 00:26:07 @monitor.py:363][0m activation-summaries/output-rms: 0.036553
[32m[0324 00:26:07 @monitor.py:363][0m cross_entropy_loss: 1.9498
[32m[0324 00:26:07 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60133
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1658
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.31726
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.89404
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.73951
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.80811
[32m[0324 00:26:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 00:26:07 @monitor.py:363][0m train-error-top1: 0.5101
[32m[0324 00:26:07 @monitor.py:363][0m val-error-top1: 0.577
[32m[0324 00:26:07 @monitor.py:363][0m val-utt-error: 0.23095
[32m[0324 00:26:07 @monitor.py:363][0m validation_cost: 2.2823
[32m[0324 00:26:07 @monitor.py:363][0m wd_cost: 0.0011545
[32m[0324 00:26:07 @group.py:42][0m Callbacks took 90.357 sec in total. InferenceRunner: 90.110sec
[32m[0324 00:26:07 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12268/173481[03:00<39:25,68.15it/s]  7%|7         |12957/173481[03:10<39:15,68.15it/s] 14%|#3        |23979/173481[06:00<37:25,66.57it/s] 14%|#4        |24558/173481[06:10<37:17,66.57it/s] 19%|#9        |33805/173481[09:00<38:48,59.99it/s] 20%|#9        |34413/173481[09:10<38:38,59.99it/s] 25%|##5       |44194/173481[12:00<36:38,58.81it/s] 26%|##5       |44754/173481[12:10<36:28,58.81it/s] 31%|###       |53694/173481[15:00<35:53,55.63it/s] 31%|###1      |54323/173481[15:10<35:41,55.63it/s] 37%|###6      |63784/173481[18:00<32:44,55.83it/s] 37%|###7      |64439/173481[18:10<32:33,55.83it/s] 43%|####3     |74949/173481[21:00<27:56,58.76it/s] 44%|####3     |75568/173481[21:11<27:46,58.76it/s] 49%|####9     |85830/173481[24:00<24:30,59.59it/s] 50%|####9     |86538/173481[24:11<24:18,59.59it/s] 56%|#####5    |96768/173481[27:00<21:14,60.17it/s] 56%|#####6    |97428/173481[27:11<21:03,60.17it/s] 62%|######2   |107617/173481[30:00<18:13,60.22it/s] 62%|######2   |108327/173481[30:11<18:01,60.22it/s] 69%|######8   |119089/173481[33:00<14:38,61.93it/s] 69%|######9   |119844/173481[33:11<14:26,61.93it/s] 75%|#######4  |129879/173481[36:00<11:55,60.91it/s] 75%|#######5  |130615/173481[36:12<11:43,60.91it/s] 81%|########1 |140654/173481[39:00<09:03,60.37it/s] 82%|########1 |141413/173481[39:12<08:51,60.37it/s] 88%|########7 |151819/173481[42:00<05:54,61.18it/s] 88%|########7 |152582/173481[42:12<05:41,61.18it/s] 94%|#########4|163109/173481[45:00<02:47,61.94it/s] 95%|#########4|163943/173481[45:12<02:33,61.94it/s]100%|##########|173481/173481[47:49<00:00,60.46it/s]
[32m[0324 01:13:57 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:2869.34 sec.
[32m[0324 01:13:57 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-3122658.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:22<00:00,229.42it/s]
17
[32m[0324 01:15:19 @monitor.py:363][0m QueueInput/queue_size: 0.49641
[32m[0324 01:15:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 33.828
[32m[0324 01:15:19 @monitor.py:363][0m activation-summaries/output-rms: 0.036011
[32m[0324 01:15:19 @monitor.py:363][0m cross_entropy_loss: 1.96
[32m[0324 01:15:19 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60822
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1662
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.31867
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.90715
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.74997
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.8203
[32m[0324 01:15:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 01:15:19 @monitor.py:363][0m train-error-top1: 0.51298
[32m[0324 01:15:19 @monitor.py:363][0m val-error-top1: 0.57271
[32m[0324 01:15:19 @monitor.py:363][0m val-utt-error: 0.22203
[32m[0324 01:15:19 @monitor.py:363][0m validation_cost: 2.2541
[32m[0324 01:15:19 @monitor.py:363][0m wd_cost: 0.0011842
[32m[0324 01:15:19 @group.py:42][0m Callbacks took 82.414 sec in total. InferenceRunner: 82.050sec
[32m[0324 01:15:19 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11902/173481[03:00<40:43,66.12it/s]  7%|7         |12530/173481[03:10<40:34,66.12it/s] 13%|#2        |22275/173481[06:00<40:55,61.58it/s] 13%|#3        |22882/173481[06:10<40:45,61.58it/s] 19%|#8        |32263/173481[09:00<40:19,58.37it/s] 19%|#8        |32892/173481[09:10<40:08,58.37it/s] 25%|##4       |42989/173481[12:00<36:52,58.97it/s] 25%|##5       |43631/173481[12:10<36:41,58.97it/s] 31%|###1      |53943/173481[15:00<33:15,59.90it/s] 31%|###1      |54477/173481[15:10<33:06,59.90it/s] 37%|###7      |64200/173481[18:00<31:11,58.40it/s] 37%|###7      |64833/173481[18:11<31:00,58.40it/s] 43%|####3     |75063/173481[21:00<27:38,59.35it/s] 44%|####3     |75728/173481[21:11<27:26,59.35it/s] 49%|####9     |85273/173481[24:00<25:20,58.00it/s] 50%|####9     |85922/173481[24:11<25:09,58.00it/s] 55%|#####4    |95178/173481[27:00<23:06,56.48it/s] 55%|#####5    |95732/173481[27:11<22:56,56.48it/s] 61%|######    |105306/173481[30:00<20:09,56.37it/s] 61%|######1   |106037/173481[30:11<19:56,56.37it/s] 67%|######6   |116153/173481[33:00<16:24,58.25it/s] 67%|######7   |116865/173481[33:11<16:11,58.25it/s] 73%|#######2  |126608/173481[36:00<13:26,58.15it/s] 73%|#######3  |127237/173481[36:12<13:15,58.15it/s] 79%|#######8  |136883/173481[39:00<10:35,57.61it/s] 79%|#######9  |137597/173481[39:12<10:22,57.61it/s] 85%|########5 |147914/173481[42:00<07:10,59.39it/s] 86%|########5 |148662/173481[42:12<06:57,59.39it/s] 92%|#########1|159218/173481[45:00<03:53,61.04it/s] 92%|#########2|160007/173481[45:12<03:40,61.04it/s] 98%|#########8|170268/173481[48:00<00:52,61.21it/s] 99%|#########8|170992/173481[48:12<00:40,61.21it/s]100%|##########|173481/173481[48:54<00:00,59.11it/s]
[32m[0324 02:04:14 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:2934.66 sec.
[32m[0324 02:04:14 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-3296139.
[32m[0324 02:04:15 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:22<00:00,229.00it/s]
18
[32m[0324 02:05:37 @monitor.py:363][0m QueueInput/queue_size: 0.51815
[32m[0324 02:05:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 34.376
[32m[0324 02:05:37 @monitor.py:363][0m activation-summaries/output-rms: 0.035481
[32m[0324 02:05:37 @monitor.py:363][0m cross_entropy_loss: 1.97
[32m[0324 02:05:37 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61544
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1665
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32003
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.92031
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76053
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.83257
[32m[0324 02:05:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 02:05:37 @monitor.py:363][0m train-error-top1: 0.50827
[32m[0324 02:05:37 @monitor.py:363][0m val-error-top1: 0.5815
[32m[0324 02:05:37 @monitor.py:363][0m val-utt-error: 0.2377
[32m[0324 02:05:37 @monitor.py:363][0m validation_cost: 2.2748
[32m[0324 02:05:37 @monitor.py:363][0m wd_cost: 0.0012146
[32m[0324 02:05:37 @group.py:42][0m Callbacks took 83.353 sec in total. InferenceRunner: 82.199sec
[32m[0324 02:05:37 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10413/173481[03:00<46:58,57.85it/s]  6%|6         |10966/173481[03:10<46:49,57.85it/s] 12%|#2        |21267/173481[06:00<42:57,59.05it/s] 13%|#2        |21836/173481[06:10<42:48,59.05it/s] 19%|#8        |32522/173481[09:00<38:40,60.73it/s] 19%|#9        |33181/173481[09:10<38:30,60.73it/s] 25%|##5       |43409/173481[12:00<35:46,60.61it/s] 25%|##5       |44026/173481[12:10<35:35,60.61it/s] 32%|###1      |55017/173481[15:00<31:35,62.48it/s] 32%|###2      |55785/173481[15:10<31:23,62.48it/s] 39%|###9      |68027/173481[18:00<26:13,67.02it/s] 40%|###9      |68856/173481[18:10<26:01,67.02it/s] 47%|####6     |81352/173481[21:00<21:49,70.34it/s] 47%|####7     |82153/173481[21:11<21:38,70.34it/s] 56%|#####5    |97139/173481[24:00<16:17,78.07it/s] 57%|#####6    |98186/173481[24:11<16:04,78.07it/s] 65%|######5   |113564/173481[27:00<11:52,84.15it/s] 66%|######6   |114607/173481[27:11<11:39,84.15it/s] 75%|#######4  |130024/173481[30:00<08:15,87.64it/s] 76%|#######5  |131082/173481[30:11<08:03,87.64it/s] 84%|########4 |146532/173481[33:00<05:00,89.63it/s] 85%|########5 |147598/173481[33:11<04:48,89.63it/s] 94%|#########3|163029/173481[36:00<01:55,90.63it/s] 95%|#########4|164106/173481[36:11<01:43,90.63it/s][32m[0324 02:43:31 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:2274.12 sec.
100%|##########|173481/173481[37:54<00:00,76.29it/s]
[32m[0324 02:43:31 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-3469620.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:15<00:00,248.14it/s]
19
[32m[0324 02:44:47 @monitor.py:363][0m QueueInput/queue_size: 0.79084
[32m[0324 02:44:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 34.948
[32m[0324 02:44:47 @monitor.py:363][0m activation-summaries/output-rms: 0.03738
[32m[0324 02:44:47 @monitor.py:363][0m cross_entropy_loss: 1.9007
[32m[0324 02:44:47 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61946
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1671
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32067
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.92681
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.76572
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.8386
[32m[0324 02:44:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 02:44:47 @monitor.py:363][0m train-error-top1: 0.50565
[32m[0324 02:44:47 @monitor.py:363][0m val-error-top1: 0.58161
[32m[0324 02:44:47 @monitor.py:363][0m val-utt-error: 0.24402
[32m[0324 02:44:47 @monitor.py:363][0m validation_cost: 2.3043
[32m[0324 02:44:47 @monitor.py:363][0m wd_cost: 0.00024599
[32m[0324 02:44:47 @group.py:42][0m Callbacks took 75.980 sec in total. InferenceRunner: 75.860sec
[32m[0324 02:44:47 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11341/173481[03:00<42:53,62.99it/s]  7%|6         |11908/173481[03:10<42:44,62.99it/s] 13%|#2        |21726/173481[06:00<42:00,60.22it/s] 13%|#2        |22330/173481[06:10<41:50,60.22it/s] 19%|#8        |32179/173481[09:00<39:49,59.12it/s] 19%|#8        |32800/173481[09:10<39:39,59.12it/s] 25%|##4       |43081/173481[12:00<36:19,59.83it/s] 25%|##5       |43687/173481[12:10<36:09,59.83it/s] 31%|###       |53591/173481[15:00<33:49,59.09it/s] 31%|###1      |54190/173481[15:10<33:38,59.09it/s] 37%|###7      |64356/173481[18:00<30:35,59.44it/s] 37%|###7      |64940/173481[18:10<30:26,59.44it/s] 43%|####3     |74866/173481[21:00<27:54,58.90it/s] 44%|####3     |75535/173481[21:11<27:42,58.90it/s] 50%|####9     |85986/173481[24:00<24:10,60.30it/s] 50%|####9     |86628/173481[24:11<24:00,60.30it/s] 56%|#####6    |97203/173481[27:00<20:44,61.29it/s] 56%|#####6    |97905/173481[27:11<20:33,61.29it/s] 62%|######2   |108136/173481[30:00<17:51,61.00it/s] 63%|######2   |108810/173481[30:11<17:40,61.00it/s] 69%|######8   |119321/173481[33:00<14:39,61.56it/s] 69%|######9   |120060/173481[33:11<14:27,61.56it/s] 75%|#######5  |130425/173481[36:00<11:38,61.63it/s] 76%|#######5  |131145/173481[36:11<11:26,61.63it/s] 82%|########1 |141526/173481[39:00<08:38,61.64it/s] 82%|########2 |142257/173481[39:12<08:26,61.64it/s] 88%|########7 |152381/173481[42:00<05:46,60.96it/s] 88%|########8 |153070/173481[42:12<05:34,60.96it/s] 94%|#########4|163856/173481[45:00<02:34,62.32it/s] 95%|#########4|164727/173481[45:12<02:20,62.32it/s]100%|##########|173481/173481[47:20<00:00,61.08it/s]
[32m[0324 03:32:07 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:2840.24 sec.
[32m[0324 03:32:08 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-3643101.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:17<00:00,244.33it/s]
20
[32m[0324 03:33:25 @monitor.py:363][0m QueueInput/queue_size: 0.75477
[32m[0324 03:33:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 34.966
[32m[0324 03:33:25 @monitor.py:363][0m activation-summaries/output-rms: 0.036366
[32m[0324 03:33:25 @monitor.py:363][0m cross_entropy_loss: 1.9101
[32m[0324 03:33:25 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62298
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1673
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32124
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.93324
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.7709
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.84462
[32m[0324 03:33:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 03:33:25 @monitor.py:363][0m train-error-top1: 0.50287
[32m[0324 03:33:25 @monitor.py:363][0m val-error-top1: 0.57174
[32m[0324 03:33:25 @monitor.py:363][0m val-utt-error: 0.23542
[32m[0324 03:33:25 @monitor.py:363][0m validation_cost: 2.2679
[32m[0324 03:33:25 @monitor.py:363][0m wd_cost: 0.000249
[32m[0324 03:33:25 @group.py:42][0m Callbacks took 77.293 sec in total. InferenceRunner: 77.042sec
[32m[0324 03:33:25 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11580/173481[03:00<41:56,64.32it/s]  7%|7         |12259/173481[03:10<41:46,64.32it/s] 13%|#3        |23335/173481[06:00<38:36,64.81it/s] 14%|#3        |24036/173481[06:10<38:25,64.81it/s] 20%|#9        |34175/173481[09:00<37:11,62.42it/s] 20%|##        |34721/173481[09:10<37:03,62.42it/s] 26%|##5       |44365/173481[12:00<36:14,59.37it/s] 26%|##5       |44975/173481[12:10<36:04,59.37it/s] 32%|###2      |55670/173481[15:00<32:10,61.03it/s] 32%|###2      |56339/173481[15:10<31:59,61.03it/s] 39%|###8      |67633/173481[18:00<27:43,63.63it/s] 39%|###9      |68340/173481[18:11<27:32,63.63it/s] 45%|####5     |78725/173481[21:00<25:13,62.61it/s] 46%|####5     |79369/173481[21:11<25:03,62.61it/s] 52%|#####1    |89825/173481[24:00<22:26,62.13it/s] 52%|#####2    |90524/173481[24:11<22:15,62.13it/s] 58%|#####8    |100960/173481[27:00<19:29,61.99it/s] 59%|#####8    |101704/173481[27:11<19:17,61.99it/s] 65%|######5   |112922/173481[30:00<15:44,64.15it/s] 66%|######5   |113689/173481[30:11<15:32,64.15it/s] 72%|#######1  |124225/173481[33:00<12:56,63.46it/s] 72%|#######2  |124964/173481[33:11<12:44,63.46it/s] 78%|#######8  |135495/173481[36:00<10:02,63.02it/s] 79%|#######8  |136201/173481[36:11<09:51,63.02it/s] 85%|########4 |146744/173481[39:00<07:06,62.75it/s] 85%|########5 |147464/173481[39:12<06:54,62.75it/s] 91%|#########1|158137/173481[42:00<04:03,63.02it/s] 92%|#########1|158874/173481[42:12<03:51,63.02it/s] 98%|#########7|169334/173481[45:00<01:06,62.61it/s] 98%|#########8|170086/173481[45:12<00:54,62.61it/s]100%|##########|173481/173481[46:04<00:00,62.75it/s]
[32m[0324 04:19:29 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:2764.72 sec.
[32m[0324 04:19:30 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-3816582.
[32m[0324 04:19:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:19<00:00,236.00it/s]
21
[32m[0324 04:20:50 @monitor.py:363][0m QueueInput/queue_size: 0.34489
[32m[0324 04:20:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.379
[32m[0324 04:20:50 @monitor.py:363][0m activation-summaries/output-rms: 0.036595
[32m[0324 04:20:50 @monitor.py:363][0m cross_entropy_loss: 1.94
[32m[0324 04:20:50 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62618
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1676
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32171
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.93886
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.77542
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.84988
[32m[0324 04:20:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 04:20:50 @monitor.py:363][0m train-error-top1: 0.50656
[32m[0324 04:20:50 @monitor.py:363][0m val-error-top1: 0.56416
[32m[0324 04:20:50 @monitor.py:363][0m val-utt-error: 0.21948
[32m[0324 04:20:50 @monitor.py:363][0m validation_cost: 2.2221
[32m[0324 04:20:50 @monitor.py:363][0m wd_cost: 0.00025165
[32m[0324 04:20:50 @group.py:42][0m Callbacks took 80.709 sec in total. InferenceRunner: 79.768sec
[32m[0324 04:20:50 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13066/173481[03:00<36:49,72.59it/s]  8%|7         |13727/173481[03:10<36:40,72.59it/s] 15%|#4        |25469/173481[06:00<34:53,70.70it/s] 15%|#5        |26128/173481[06:10<34:44,70.70it/s] 21%|##1       |36474/173481[09:00<34:49,65.57it/s] 21%|##1       |37103/173481[09:10<34:39,65.57it/s] 27%|##7       |47240/173481[12:00<33:38,62.56it/s] 28%|##7       |47868/173481[12:10<33:27,62.56it/s] 33%|###3      |57959/173481[15:00<31:33,61.02it/s] 34%|###3      |58618/173481[15:10<31:22,61.02it/s] 40%|####      |69441/173481[18:00<27:48,62.37it/s] 40%|####      |70161/173481[18:11<27:36,62.37it/s] 47%|####6     |81319/173481[21:00<23:57,64.12it/s] 47%|####7     |82042/173481[21:11<23:46,64.12it/s] 54%|#####3    |93014/173481[24:00<20:46,64.54it/s] 54%|#####4    |93739/173481[24:11<20:35,64.54it/s] 60%|######    |104521/173481[27:00<17:53,64.23it/s] 61%|######    |105246/173481[27:11<17:42,64.23it/s] 68%|######8   |118107/173481[30:00<13:17,69.40it/s] 69%|######8   |118915/173481[30:11<13:06,69.40it/s] 75%|#######5  |130602/173481[33:00<10:17,69.41it/s] 76%|#######5  |131346/173481[33:11<10:07,69.41it/s] 82%|########2 |142426/173481[36:00<07:40,67.50it/s] 83%|########2 |143223/173481[36:12<07:28,67.50it/s] 89%|########8 |154321/173481[39:00<04:46,66.78it/s] 89%|########9 |155138/173481[39:12<04:34,66.78it/s] 96%|#########5|166374/173481[42:00<01:46,66.87it/s] 96%|#########6|167212/173481[42:12<01:33,66.87it/s]100%|##########|173481/173481[43:47<00:00,66.01it/s]
[32m[0324 05:04:38 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:2627.97 sec.
[32m[0324 05:04:38 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-3990063.
[32m[0324 05:04:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:20<00:00,234.76it/s]
22
[32m[0324 05:05:59 @monitor.py:363][0m QueueInput/queue_size: 0.4617
[32m[0324 05:05:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.281
[32m[0324 05:05:59 @monitor.py:363][0m activation-summaries/output-rms: 0.036376
[32m[0324 05:05:59 @monitor.py:363][0m cross_entropy_loss: 1.9355
[32m[0324 05:05:59 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62802
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1677
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32196
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.94192
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.77791
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.85277
[32m[0324 05:05:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 05:05:59 @monitor.py:363][0m train-error-top1: 0.51412
[32m[0324 05:05:59 @monitor.py:363][0m val-error-top1: 0.57879
[32m[0324 05:05:59 @monitor.py:363][0m val-utt-error: 0.23993
[32m[0324 05:05:59 @monitor.py:363][0m validation_cost: 2.2885
[32m[0324 05:05:59 @monitor.py:363][0m wd_cost: 5.0623e-05
[32m[0324 05:05:59 @group.py:42][0m Callbacks took 80.988 sec in total. InferenceRunner: 80.183sec
[32m[0324 05:05:59 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12514/173481[03:00<38:35,69.52it/s]  8%|7         |13207/173481[03:10<38:25,69.52it/s] 14%|#3        |23764/173481[06:00<37:54,65.82it/s] 14%|#4        |24402/173481[06:10<37:44,65.82it/s] 21%|##        |35811/173481[09:00<34:34,66.37it/s] 21%|##1       |36487/173481[09:10<34:24,66.37it/s] 28%|##7       |48063/173481[12:00<31:06,67.20it/s] 28%|##8       |48775/173481[12:10<30:55,67.20it/s] 35%|###4      |60223/173481[15:00<28:00,67.38it/s] 35%|###5      |60977/173481[15:10<27:49,67.38it/s] 42%|####2     |73349/173481[18:00<23:49,70.04it/s] 43%|####2     |74207/173481[18:11<23:37,70.04it/s] 50%|#####     |87364/173481[21:00<19:27,73.74it/s] 51%|#####     |88207/173481[21:11<19:16,73.74it/s] 58%|#####7    |100541/173481[24:00<16:32,73.47it/s] 58%|#####8    |101342/173481[24:11<16:21,73.47it/s] 65%|######5   |113114/173481[27:00<14:02,71.61it/s] 66%|######5   |113926/173481[27:11<13:51,71.61it/s] 72%|#######2  |125463/173481[30:00<11:25,70.06it/s] 73%|#######2  |126271/173481[30:11<11:13,70.06it/s] 79%|#######9  |137788/173481[33:00<08:35,69.26it/s] 80%|#######9  |138602/173481[33:11<08:23,69.26it/s] 87%|########6 |150643/173481[36:00<05:24,70.32it/s] 87%|########7 |151612/173481[36:12<05:10,70.32it/s] 95%|#########5|164968/173481[39:00<01:54,74.66it/s] 96%|#########5|165915/173481[39:12<01:41,74.66it/s]100%|##########|173481/173481[40:51<00:00,70.77it/s]
[32m[0324 05:46:51 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:2451.50 sec.
[32m[0324 05:46:51 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-4163544.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:21<00:00,231.66it/s]
23
[32m[0324 05:48:12 @monitor.py:363][0m QueueInput/queue_size: 0.050427
[32m[0324 05:48:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.642
[32m[0324 05:48:12 @monitor.py:363][0m activation-summaries/output-rms: 0.035704
[32m[0324 05:48:12 @monitor.py:363][0m cross_entropy_loss: 1.9427
[32m[0324 05:48:12 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.62989
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1678
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32221
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.945
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78041
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.85569
[32m[0324 05:48:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 05:48:12 @monitor.py:363][0m train-error-top1: 0.50445
[32m[0324 05:48:12 @monitor.py:363][0m val-error-top1: 0.57544
[32m[0324 05:48:12 @monitor.py:363][0m val-utt-error: 0.23696
[32m[0324 05:48:12 @monitor.py:363][0m validation_cost: 2.2695
[32m[0324 05:48:12 @monitor.py:363][0m wd_cost: 5.0919e-05
[32m[0324 05:48:12 @group.py:42][0m Callbacks took 81.434 sec in total. InferenceRunner: 81.255sec
[32m[0324 05:48:12 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14236/173481[03:00<33:33,79.08it/s]  9%|8         |15357/173481[03:10<33:19,79.08it/s] 19%|#8        |32427/173481[06:00<26:29,88.73it/s] 19%|#9        |33066/173481[06:10<26:22,88.73it/s] 25%|##5       |44017/173481[09:00<28:55,74.61it/s] 26%|##5       |44736/173481[09:10<28:45,74.61it/s] 35%|###5      |61002/173481[12:00<22:29,83.33it/s] 36%|###5      |62042/173481[12:10<22:17,83.33it/s] 45%|####4     |77506/173481[15:00<18:19,87.31it/s] 45%|####5     |78468/173481[15:10<18:08,87.31it/s] 54%|#####4    |94293/173481[18:00<14:38,90.18it/s] 55%|#####4    |95285/173481[18:11<14:27,90.18it/s] 64%|######4   |111326/173481[21:00<11:13,92.35it/s] 65%|######4   |112365/173481[21:11<11:01,92.35it/s] 74%|#######3  |127869/173481[24:00<08:15,92.13it/s] 74%|#######4  |128919/173481[24:11<08:03,92.13it/s] 83%|########3 |144192/173481[27:00<05:20,91.40it/s] 84%|########3 |145236/173481[27:11<05:09,91.40it/s] 93%|#########2|161133/173481[30:00<02:13,92.74it/s] 93%|#########3|162200/173481[30:11<02:01,92.74it/s]100%|##########|173481/173481[32:15<00:00,89.63it/s]
[32m[0324 06:20:28 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:1935.60 sec.
[32m[0324 06:20:28 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-4337025.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:19<00:00,236.86it/s]
24
[32m[0324 06:21:47 @monitor.py:363][0m QueueInput/queue_size: 0.95115
[32m[0324 06:21:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.795
[32m[0324 06:21:47 @monitor.py:363][0m activation-summaries/output-rms: 0.03792
[32m[0324 06:21:47 @monitor.py:363][0m cross_entropy_loss: 1.8828
[32m[0324 06:21:47 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63134
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1681
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32239
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.9471
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78215
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.85768
[32m[0324 06:21:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 06:21:47 @monitor.py:363][0m train-error-top1: 0.5004
[32m[0324 06:21:47 @monitor.py:363][0m val-error-top1: 0.58264
[32m[0324 06:21:47 @monitor.py:363][0m val-utt-error: 0.25258
[32m[0324 06:21:47 @monitor.py:363][0m validation_cost: 2.3324
[32m[0324 06:21:47 @monitor.py:363][0m wd_cost: 1.0225e-05
[32m[0324 06:21:47 @group.py:42][0m Callbacks took 79.665 sec in total. InferenceRunner: 79.472sec
[32m[0324 06:21:47 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17632/173481[03:00<26:31,97.95it/s] 11%|#         |18625/173481[03:10<26:20,97.95it/s] 18%|#7        |31191/173481[06:00<27:51,85.15it/s] 18%|#8        |31841/173481[06:10<27:43,85.15it/s] 25%|##4       |42676/173481[09:00<29:53,72.94it/s] 25%|##4       |43357/173481[09:10<29:43,72.94it/s] 31%|###1      |54261/173481[12:00<29:03,68.38it/s] 32%|###1      |55019/173481[12:10<28:52,68.38it/s] 38%|###8      |66279/173481[15:00<26:26,67.56it/s] 39%|###8      |67015/173481[15:10<26:15,67.56it/s] 45%|####4     |77706/173481[18:00<24:23,65.45it/s] 45%|####5     |78467/173481[18:11<24:11,65.45it/s] 52%|#####1    |89586/173481[21:00<21:16,65.72it/s] 52%|#####2    |90345/173481[21:11<21:04,65.72it/s] 58%|#####8    |101355/173481[24:00<18:20,65.55it/s] 59%|#####8    |102075/173481[24:11<18:09,65.55it/s] 65%|######5   |113186/173481[27:00<15:18,65.64it/s] 66%|######5   |113960/173481[27:11<15:06,65.64it/s] 72%|#######2  |125162/173481[30:00<12:11,66.08it/s] 73%|#######2  |125923/173481[30:11<11:59,66.08it/s] 79%|#######8  |136768/173481[33:00<09:22,65.27it/s] 79%|#######9  |137450/173481[33:11<09:12,65.27it/s] 85%|########5 |148326/173481[36:00<06:28,64.73it/s] 86%|########5 |149080/173481[36:12<06:16,64.73it/s] 92%|#########2|159611/173481[39:00<03:37,63.69it/s] 92%|#########2|160415/173481[39:12<03:25,63.69it/s] 99%|#########9|172566/173481[42:00<00:13,67.57it/s]100%|#########9|173384/173481[42:12<00:01,67.57it/s]100%|##########|173481/173481[42:14<00:00,68.46it/s]
[32m[0324 07:04:01 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:2534.01 sec.
[32m[0324 07:04:01 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:18<00:00,240.91it/s]
25
[32m[0324 07:05:20 @monitor.py:363][0m QueueInput/queue_size: 0.30615
[32m[0324 07:05:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.712
[32m[0324 07:05:20 @monitor.py:363][0m activation-summaries/output-rms: 0.035997
[32m[0324 07:05:20 @monitor.py:363][0m cross_entropy_loss: 1.9088
[32m[0324 07:05:20 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63218
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1681
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32251
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.94853
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78336
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.85907
[32m[0324 07:05:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 07:05:20 @monitor.py:363][0m train-error-top1: 0.49757
[32m[0324 07:05:20 @monitor.py:363][0m val-error-top1: 0.56878
[32m[0324 07:05:20 @monitor.py:363][0m val-utt-error: 0.2258
[32m[0324 07:05:20 @monitor.py:363][0m validation_cost: 2.2261
[32m[0324 07:05:20 @monitor.py:363][0m wd_cost: 1.0253e-05
[32m[0324 07:05:20 @group.py:42][0m Callbacks took 78.369 sec in total. InferenceRunner: 78.137sec
[32m[0324 07:05:20 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11970/173481[03:00<40:29,66.48it/s]  7%|7         |12589/173481[03:10<40:20,66.48it/s] 14%|#3        |23853/173481[06:00<37:38,66.25it/s] 14%|#4        |24534/173481[06:10<37:28,66.25it/s] 20%|##        |34988/173481[09:00<36:04,63.98it/s] 21%|##        |35598/173481[09:10<35:55,63.98it/s] 26%|##6       |45641/173481[12:00<34:39,61.49it/s] 27%|##6       |46242/173481[12:10<34:29,61.49it/s] 33%|###2      |56685/173481[15:00<31:41,61.42it/s] 33%|###3      |57365/173481[15:10<31:30,61.42it/s] 39%|###8      |67633/173481[18:00<28:51,61.12it/s] 39%|###9      |68309/173481[18:10<28:40,61.12it/s] 46%|####5     |79090/173481[21:00<25:13,62.36it/s] 46%|####6     |79804/173481[21:11<25:02,62.36it/s] 52%|#####2    |90750/173481[24:00<21:42,63.53it/s] 53%|#####2    |91494/173481[24:11<21:30,63.53it/s] 59%|#####8    |102298/173481[27:00<18:35,63.84it/s] 59%|#####9    |103054/173481[27:11<18:23,63.84it/s] 66%|######5   |114146/173481[30:00<15:15,64.82it/s] 66%|######6   |114870/173481[30:11<15:04,64.82it/s] 72%|#######2  |125165/173481[33:00<12:47,62.95it/s] 73%|#######2  |125849/173481[33:11<12:36,62.95it/s] 78%|#######8  |136100/173481[36:00<10:04,61.82it/s] 79%|#######8  |136778/173481[36:11<09:53,61.82it/s] 85%|########4 |146920/173481[39:00<07:15,60.95it/s] 85%|########5 |147618/173481[39:12<07:04,60.95it/s] 91%|#########1|158136/173481[42:00<04:09,61.62it/s] 92%|#########1|158869/173481[42:12<03:57,61.62it/s] 98%|#########7|169605/173481[45:00<01:01,62.65it/s] 98%|#########8|170344/173481[45:12<00:50,62.65it/s]100%|##########|173481/173481[46:01<00:00,62.83it/s]
[32m[0324 07:51:21 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:2761.19 sec.
[32m[0324 07:51:21 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:18<00:00,241.26it/s]
26
[32m[0324 07:52:39 @monitor.py:363][0m QueueInput/queue_size: 0.29177
[32m[0324 07:52:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.975
[32m[0324 07:52:39 @monitor.py:363][0m activation-summaries/output-rms: 0.036728
[32m[0324 07:52:39 @monitor.py:363][0m cross_entropy_loss: 1.941
[32m[0324 07:52:39 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63302
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1682
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32261
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.94997
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78458
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86047
[32m[0324 07:52:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 07:52:39 @monitor.py:363][0m train-error-top1: 0.50876
[32m[0324 07:52:39 @monitor.py:363][0m val-error-top1: 0.57947
[32m[0324 07:52:39 @monitor.py:363][0m val-utt-error: 0.24014
[32m[0324 07:52:39 @monitor.py:363][0m validation_cost: 2.2878
[32m[0324 07:52:39 @monitor.py:363][0m wd_cost: 1.0281e-05
[32m[0324 07:52:39 @group.py:42][0m Callbacks took 78.217 sec in total. InferenceRunner: 78.022sec
[32m[0324 07:52:39 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12594/173481[03:00<38:19,69.96it/s]  8%|7         |13254/173481[03:10<38:10,69.96it/s] 15%|#4        |25209/173481[06:00<35:17,70.02it/s] 15%|#4        |25848/173481[06:10<35:08,70.02it/s] 21%|##        |35924/173481[09:00<35:37,64.35it/s] 21%|##1       |36532/173481[09:10<35:28,64.35it/s] 27%|##6       |46754/173481[12:00<33:58,62.17it/s] 27%|##7       |47317/173481[12:10<33:49,62.17it/s] 33%|###3      |57418/173481[15:00<31:52,60.67it/s] 33%|###3      |58033/173481[15:10<31:42,60.67it/s] 40%|###9      |68709/173481[18:00<28:18,61.67it/s] 40%|####      |69481/173481[18:10<28:06,61.67it/s] 47%|####6     |80786/173481[21:00<24:02,64.27it/s] 47%|####6     |81533/173481[21:11<23:50,64.27it/s] 53%|#####3    |92574/173481[24:00<20:47,64.87it/s] 54%|#####3    |93298/173481[24:11<20:36,64.87it/s] 60%|#####9    |103939/173481[27:00<18:06,63.99it/s] 60%|######    |104593/173481[27:11<17:56,63.99it/s] 67%|######6   |115895/173481[30:00<14:43,65.18it/s] 67%|######7   |116610/173481[30:11<14:32,65.18it/s] 73%|#######3  |127320/173481[33:00<11:57,64.32it/s] 74%|#######3  |128078/173481[33:11<11:45,64.32it/s] 80%|########  |138804/173481[36:00<09:01,64.05it/s] 80%|########  |139573/173481[36:11<08:49,64.05it/s] 87%|########6 |150504/173481[39:00<05:56,64.52it/s] 87%|########7 |151254/173481[39:12<05:44,64.52it/s] 94%|#########3|162299/173481[42:00<02:52,65.01it/s] 94%|#########4|163098/173481[42:12<02:39,65.01it/s]100%|##########|173481/173481[44:49<00:00,64.51it/s]
[32m[0324 08:37:28 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:2689.35 sec.
[32m[0324 08:37:29 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-4857468.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,200.06it/s]
27
[32m[0324 08:39:03 @monitor.py:363][0m QueueInput/queue_size: 0.15184
[32m[0324 08:39:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.702
[32m[0324 08:39:03 @monitor.py:363][0m activation-summaries/output-rms: 0.036528
[32m[0324 08:39:03 @monitor.py:363][0m cross_entropy_loss: 1.9489
[32m[0324 08:39:03 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63354
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1683
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32268
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95071
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78527
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86124
[32m[0324 08:39:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 08:39:03 @monitor.py:363][0m train-error-top1: 0.51648
[32m[0324 08:39:03 @monitor.py:363][0m val-error-top1: 0.58503
[32m[0324 08:39:03 @monitor.py:363][0m val-utt-error: 0.25991
[32m[0324 08:39:03 @monitor.py:363][0m validation_cost: 2.3412
[32m[0324 08:39:03 @monitor.py:363][0m wd_cost: 2.0594e-06
[32m[0324 08:39:03 @group.py:42][0m Callbacks took 94.314 sec in total. InferenceRunner: 94.091sec
[32m[0324 08:39:03 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12288/173481[03:00<39:22,68.24it/s]  7%|7         |12942/173481[03:10<39:12,68.24it/s] 13%|#3        |23328/173481[06:00<38:44,64.60it/s] 14%|#3        |23955/173481[06:10<38:34,64.60it/s] 20%|#9        |34696/173481[09:00<36:13,63.87it/s] 20%|##        |35363/173481[09:10<36:02,63.87it/s] 27%|##6       |46629/173481[12:00<32:29,65.06it/s] 27%|##7       |47342/173481[12:10<32:18,65.06it/s] 34%|###3      |58203/173481[15:00<29:42,64.68it/s] 34%|###3      |58906/173481[15:10<29:31,64.68it/s] 40%|####      |70118/173481[18:00<26:19,65.42it/s] 41%|####      |70852/173481[18:10<26:08,65.42it/s] 47%|####7     |82098/173481[21:00<23:05,65.98it/s] 48%|####7     |82863/173481[21:11<22:53,65.98it/s] 54%|#####4    |93938/173481[24:00<20:07,65.87it/s] 55%|#####4    |94608/173481[24:11<19:57,65.87it/s] 61%|######1   |105862/173481[27:00<17:03,66.06it/s] 61%|######1   |106608/173481[27:11<16:52,66.06it/s] 68%|######7   |117913/173481[30:00<13:55,66.49it/s] 68%|######8   |118642/173481[30:11<13:44,66.49it/s] 75%|#######4  |129846/173481[33:00<10:57,66.39it/s] 75%|#######5  |130662/173481[33:11<10:44,66.39it/s] 82%|########1 |141868/173481[36:00<07:54,66.58it/s] 82%|########2 |142659/173481[36:11<07:42,66.58it/s] 89%|########8 |154133/173481[39:00<04:47,67.35it/s] 89%|########9 |154924/173481[39:12<04:35,67.35it/s] 96%|#########5|166225/173481[42:00<01:47,67.26it/s] 96%|#########6|166996/173481[42:12<01:36,67.26it/s]100%|##########|173481/173481[43:53<00:00,65.88it/s]
[32m[0324 09:22:56 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:2633.11 sec.
[32m[0324 09:22:56 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-5030949.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:26<00:00,217.37it/s]
28
[32m[0324 09:24:23 @monitor.py:363][0m QueueInput/queue_size: 0.78977
[32m[0324 09:24:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.987
[32m[0324 09:24:23 @monitor.py:363][0m activation-summaries/output-rms: 0.036216
[32m[0324 09:24:23 @monitor.py:363][0m cross_entropy_loss: 1.9455
[32m[0324 09:24:23 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63396
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1683
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32274
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95128
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78582
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86185
[32m[0324 09:24:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 09:24:23 @monitor.py:363][0m train-error-top1: 0.51448
[32m[0324 09:24:23 @monitor.py:363][0m val-error-top1: 0.57333
[32m[0324 09:24:23 @monitor.py:363][0m val-utt-error: 0.22415
[32m[0324 09:24:23 @monitor.py:363][0m validation_cost: 2.2472
[32m[0324 09:24:23 @monitor.py:363][0m wd_cost: 2.0619e-06
[32m[0324 09:24:23 @group.py:42][0m Callbacks took 86.791 sec in total. InferenceRunner: 86.598sec
[32m[0324 09:24:23 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12837/173481[03:00<37:32,71.31it/s]  8%|7         |13761/173481[03:10<37:19,71.31it/s] 17%|#6        |28962/173481[06:00<30:19,79.41it/s] 17%|#7        |29889/173481[06:10<30:08,79.41it/s] 24%|##4       |41842/173481[09:00<29:08,75.27it/s] 25%|##4       |42551/173481[09:10<28:59,75.27it/s] 32%|###1      |54702/173481[12:00<27:00,73.30it/s] 32%|###2      |55543/173481[12:10<26:48,73.30it/s] 40%|###9      |69253/173481[15:00<22:35,76.89it/s] 40%|####      |70211/173481[15:10<22:23,76.89it/s] 49%|####9     |85392/173481[18:00<17:44,82.78it/s] 50%|####9     |86386/173481[18:11<17:32,82.78it/s] 59%|#####8    |101593/173481[21:00<13:53,86.24it/s] 59%|#####9    |102571/173481[21:11<13:42,86.24it/s] 65%|######5   |113312/173481[24:00<13:30,74.19it/s] 66%|######5   |114071/173481[24:11<13:20,74.19it/s] 72%|#######1  |124782/173481[27:00<11:50,68.55it/s] 72%|#######2  |125498/173481[27:11<11:39,68.55it/s] 79%|#######8  |136278/173481[30:00<09:22,66.13it/s] 79%|#######8  |137006/173481[30:11<09:11,66.13it/s] 85%|########5 |147757/173481[33:00<06:36,64.92it/s] 86%|########5 |148522/173481[33:11<06:24,64.92it/s] 92%|#########1|159147/173481[36:00<03:43,64.08it/s] 92%|#########2|159833/173481[36:12<03:32,64.08it/s] 98%|#########8|170243/173481[39:00<00:51,62.84it/s] 99%|#########8|170935/173481[39:12<00:40,62.84it/s][32m[0324 10:04:19 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:2396.41 sec.
100%|##########|173481/173481[39:56<00:00,72.39it/s]
[32m[0324 10:04:19 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-5204430.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:17<00:00,242.15it/s]
29
[32m[0324 10:05:37 @monitor.py:363][0m QueueInput/queue_size: 0.24398
[32m[0324 10:05:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.945
[32m[0324 10:05:37 @monitor.py:363][0m activation-summaries/output-rms: 0.037497
[32m[0324 10:05:37 @monitor.py:363][0m cross_entropy_loss: 1.8802
[32m[0324 10:05:37 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63438
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1683
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32279
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95181
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78636
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86243
[32m[0324 10:05:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 10:05:37 @monitor.py:363][0m train-error-top1: 0.50565
[32m[0324 10:05:37 @monitor.py:363][0m val-error-top1: 0.56178
[32m[0324 10:05:37 @monitor.py:363][0m val-utt-error: 0.2207
[32m[0324 10:05:37 @monitor.py:363][0m validation_cost: 2.2064
[32m[0324 10:05:37 @monitor.py:363][0m wd_cost: 2.0643e-06
[32m[0324 10:05:37 @group.py:42][0m Callbacks took 77.928 sec in total. InferenceRunner: 77.735sec
[32m[0324 10:05:37 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12326/173481[03:00<39:14,68.46it/s]  7%|7         |12965/173481[03:10<39:04,68.46it/s] 14%|#3        |23786/173481[06:00<37:49,65.97it/s] 14%|#4        |24426/173481[06:10<37:39,65.97it/s] 20%|##        |34833/173481[09:00<36:20,63.59it/s] 20%|##        |35485/173481[09:10<36:10,63.59it/s] 26%|##6       |45892/173481[12:00<34:01,62.49it/s] 27%|##6       |46533/173481[12:10<33:51,62.49it/s] 33%|###2      |56911/173481[15:00<31:24,61.84it/s] 33%|###3      |57593/173481[15:10<31:13,61.84it/s] 39%|###9      |68091/173481[18:00<28:20,61.97it/s] 40%|###9      |68720/173481[18:11<28:10,61.97it/s] 46%|####5     |79243/173481[21:00<25:20,61.96it/s] 46%|####6     |79944/173481[21:11<25:09,61.96it/s] 52%|#####2    |90728/173481[24:00<21:56,62.87it/s] 53%|#####2    |91435/173481[24:11<21:45,62.87it/s] 59%|#####8    |102091/173481[27:00<18:53,62.99it/s] 59%|#####9    |102800/173481[27:11<18:42,62.99it/s] 65%|######5   |113456/173481[30:00<15:51,63.06it/s] 66%|######5   |114182/173481[30:11<15:40,63.06it/s] 72%|#######1  |124900/173481[33:00<12:47,63.32it/s] 72%|#######2  |125631/173481[33:11<12:35,63.32it/s] 78%|#######8  |135906/173481[36:00<10:04,62.19it/s] 79%|#######8  |136605/173481[36:12<09:52,62.19it/s] 85%|########4 |146881/173481[39:00<07:11,61.57it/s] 85%|########5 |147580/173481[39:12<07:00,61.57it/s] 91%|######### |157646/173481[42:00<04:21,60.66it/s] 91%|#########1|158365/173481[42:12<04:09,60.66it/s] 98%|#########7|169691/173481[45:00<00:59,63.63it/s] 98%|#########8|170405/173481[45:12<00:48,63.63it/s]100%|##########|173481/173481[46:00<00:00,62.84it/s]
[32m[0324 10:51:37 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:2760.49 sec.
[32m[0324 10:51:38 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-5377911.
[32m[0324 10:51:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:12<00:00,258.92it/s]
30
[32m[0324 10:52:51 @monitor.py:363][0m QueueInput/queue_size: 0.50103
[32m[0324 10:52:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.957
[32m[0324 10:52:51 @monitor.py:363][0m activation-summaries/output-rms: 0.035807
[32m[0324 10:52:51 @monitor.py:363][0m cross_entropy_loss: 1.8996
[32m[0324 10:52:51 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63455
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1683
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32282
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95201
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78657
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86264
[32m[0324 10:52:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 10:52:51 @monitor.py:363][0m train-error-top1: 0.494
[32m[0324 10:52:51 @monitor.py:363][0m val-error-top1: 0.58124
[32m[0324 10:52:51 @monitor.py:363][0m val-utt-error: 0.22638
[32m[0324 10:52:51 @monitor.py:363][0m validation_cost: 2.2938
[32m[0324 10:52:51 @monitor.py:363][0m wd_cost: 4.1303e-07
[32m[0324 10:52:51 @group.py:42][0m Callbacks took 73.444 sec in total. InferenceRunner: 72.702sec
[32m[0324 10:52:51 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11571/173481[03:00<41:58,64.28it/s]  7%|7         |12286/173481[03:10<41:47,64.28it/s] 14%|#3        |23590/173481[06:00<38:08,65.50it/s] 14%|#4        |24299/173481[06:10<37:57,65.50it/s] 20%|#9        |34475/173481[09:00<36:51,62.87it/s] 20%|##        |35039/173481[09:10<36:42,62.87it/s] 26%|##6       |45140/173481[12:00<35:03,61.00it/s] 26%|##6       |45757/173481[12:10<34:53,61.00it/s] 32%|###2      |56176/173481[15:00<31:58,61.15it/s] 33%|###2      |56869/173481[15:10<31:46,61.15it/s] 39%|###8      |66872/173481[18:00<29:28,60.27it/s] 39%|###8      |67528/173481[18:10<29:17,60.27it/s] 45%|####4     |78019/173481[21:00<26:02,61.08it/s] 45%|####5     |78699/173481[21:11<25:51,61.08it/s] 52%|#####1    |89400/173481[24:00<22:33,62.13it/s] 52%|#####1    |90104/173481[24:11<22:21,62.13it/s] 58%|#####7    |100590/173481[27:00<19:32,62.14it/s] 58%|#####8    |101329/173481[27:11<19:21,62.14it/s] 65%|######5   |112945/173481[30:00<15:28,65.23it/s] 66%|######5   |113699/173481[30:11<15:16,65.23it/s] 72%|#######1  |124475/173481[33:00<12:38,64.63it/s] 72%|#######2  |125216/173481[33:11<12:26,64.63it/s] 80%|#######9  |138630/173481[36:00<08:11,70.95it/s] 80%|########  |139644/173481[36:11<07:56,70.95it/s] 88%|########7 |152300/173481[39:00<04:48,73.36it/s] 88%|########8 |153069/173481[39:12<04:38,73.36it/s] 95%|#########4|164095/173481[42:00<02:15,69.22it/s] 95%|#########5|164872/173481[42:12<02:04,69.22it/s]100%|##########|173481/173481[44:29<00:00,64.98it/s]
[32m[0324 11:37:21 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:2669.76 sec.
[32m[0324 11:37:21 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:15<00:00,249.78it/s]
31
[32m[0324 11:38:36 @monitor.py:363][0m QueueInput/queue_size: 0.31901
[32m[0324 11:38:36 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.094
[32m[0324 11:38:36 @monitor.py:363][0m activation-summaries/output-rms: 0.03693
[32m[0324 11:38:36 @monitor.py:363][0m cross_entropy_loss: 1.9321
[32m[0324 11:38:36 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63473
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32284
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/linear1/W-rms: 0.9522
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78679
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86285
[32m[0324 11:38:36 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 11:38:36 @monitor.py:363][0m train-error-top1: 0.5037
[32m[0324 11:38:36 @monitor.py:363][0m val-error-top1: 0.57153
[32m[0324 11:38:36 @monitor.py:363][0m val-utt-error: 0.22654
[32m[0324 11:38:36 @monitor.py:363][0m validation_cost: 2.2466
[32m[0324 11:38:36 @monitor.py:363][0m wd_cost: 4.1321e-07
[32m[0324 11:38:36 @group.py:42][0m Callbacks took 75.499 sec in total. InferenceRunner: 75.360sec
[32m[0324 11:38:36 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11498/173481[03:00<42:16,63.87it/s]  7%|7         |12175/173481[03:10<42:05,63.87it/s] 14%|#3        |23644/173481[06:00<38:03,65.62it/s] 14%|#3        |24282/173481[06:10<37:53,65.62it/s] 20%|#9        |34149/173481[09:00<37:35,61.77it/s] 20%|##        |34787/173481[09:10<37:25,61.77it/s] 26%|##5       |44765/173481[12:00<35:33,60.34it/s] 26%|##6       |45393/173481[12:10<35:22,60.34it/s] 32%|###1      |55304/173481[15:00<33:08,59.43it/s] 32%|###2      |55911/173481[15:10<32:58,59.43it/s] 38%|###8      |66029/173481[18:00<30:05,59.50it/s] 38%|###8      |66754/173481[18:11<29:53,59.50it/s] 45%|####5     |78139/173481[21:00<25:09,63.15it/s] 45%|####5     |78848/173481[21:11<24:58,63.15it/s] 52%|#####1    |89919/173481[24:00<21:40,64.26it/s] 52%|#####2    |90598/173481[24:11<21:29,64.26it/s] 58%|#####8    |101129/173481[27:00<19:03,63.25it/s] 59%|#####8    |101803/173481[27:11<18:53,63.25it/s] 65%|######4   |112392/173481[30:00<16:11,62.91it/s] 65%|######5   |113223/173481[30:11<15:57,62.91it/s] 73%|#######2  |125800/173481[33:00<11:39,68.21it/s] 73%|#######2  |126552/173481[33:11<11:28,68.21it/s] 80%|#######9  |138764/173481[36:00<08:15,70.06it/s] 80%|########  |139618/173481[36:12<08:03,70.06it/s] 87%|########7 |151786/173481[39:00<05:04,71.18it/s] 88%|########8 |152668/173481[39:12<04:52,71.18it/s] 94%|#########4|163775/173481[42:00<02:21,68.81it/s] 95%|#########4|164583/173481[42:12<02:09,68.81it/s]100%|##########|173481/173481[44:34<00:00,64.88it/s]
[32m[0324 12:23:10 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:2674.01 sec.
[32m[0324 12:23:10 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-5724873.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:13<00:00,257.57it/s]
32
[32m[0324 12:24:23 @monitor.py:363][0m QueueInput/queue_size: 0.41126
[32m[0324 12:24:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.891
[32m[0324 12:24:23 @monitor.py:363][0m activation-summaries/output-rms: 0.03681
[32m[0324 12:24:23 @monitor.py:363][0m cross_entropy_loss: 1.942
[32m[0324 12:24:23 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63483
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32287
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95236
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78696
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86302
[32m[0324 12:24:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 12:24:23 @monitor.py:363][0m train-error-top1: 0.51379
[32m[0324 12:24:23 @monitor.py:363][0m val-error-top1: 0.56713
[32m[0324 12:24:23 @monitor.py:363][0m val-utt-error: 0.22824
[32m[0324 12:24:23 @monitor.py:363][0m validation_cost: 2.2318
[32m[0324 12:24:23 @monitor.py:363][0m wd_cost: 4.1335e-07
[32m[0324 12:24:23 @group.py:42][0m Callbacks took 73.264 sec in total. InferenceRunner: 73.082sec
[32m[0324 12:24:23 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11538/173481[03:00<42:07,64.08it/s]  7%|7         |12176/173481[03:10<41:57,64.08it/s] 13%|#2        |22323/173481[06:00<40:40,61.92it/s] 13%|#3        |22942/173481[06:10<40:30,61.92it/s] 19%|#9        |33248/173481[09:00<38:07,61.30it/s] 20%|#9        |33855/173481[09:10<37:57,61.30it/s] 26%|##5       |44558/173481[12:00<34:37,62.05it/s] 26%|##6       |45309/173481[12:10<34:25,62.05it/s] 33%|###2      |57248/173481[15:00<29:21,66.00it/s] 33%|###3      |57981/173481[15:10<29:10,66.00it/s] 41%|####1     |71418/173481[18:00<23:41,71.80it/s] 42%|####1     |72327/173481[18:11<23:28,71.80it/s] 48%|####8     |83873/173481[21:00<21:11,70.47it/s] 49%|####8     |84591/173481[21:11<21:01,70.47it/s] 55%|#####5    |95693/173481[24:00<19:04,67.97it/s] 56%|#####5    |96422/173481[24:11<18:53,67.97it/s] 62%|######1   |107403/173481[27:00<16:33,66.48it/s] 62%|######2   |108142/173481[27:11<16:22,66.48it/s] 68%|######8   |118814/173481[30:00<14:02,64.90it/s] 69%|######8   |119552/173481[30:11<13:50,64.90it/s] 75%|#######4  |130038/173481[33:00<11:23,63.59it/s] 75%|#######5  |130806/173481[33:11<11:11,63.59it/s] 82%|########1 |142008/173481[36:00<08:04,65.01it/s] 82%|########2 |142761/173481[36:12<07:52,65.01it/s] 89%|########8 |153683/173481[39:00<05:04,64.93it/s] 89%|########9 |154490/173481[39:12<04:52,64.93it/s] 95%|#########5|165273/173481[42:00<02:06,64.65it/s] 96%|#########5|166042/173481[42:12<01:55,64.65it/s]100%|##########|173481/173481[44:16<00:00,65.30it/s]
[32m[0324 13:08:40 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:2656.87 sec.
[32m[0324 13:08:40 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:15<00:00,249.65it/s]
33
[32m[0324 13:09:56 @monitor.py:363][0m QueueInput/queue_size: 0.59679
[32m[0324 13:09:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.075
[32m[0324 13:09:56 @monitor.py:363][0m activation-summaries/output-rms: 0.035752
[32m[0324 13:09:56 @monitor.py:363][0m cross_entropy_loss: 1.94
[32m[0324 13:09:56 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63479
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32288
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95246
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78704
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86311
[32m[0324 13:09:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 13:09:56 @monitor.py:363][0m train-error-top1: 0.50422
[32m[0324 13:09:56 @monitor.py:363][0m val-error-top1: 0.56925
[32m[0324 13:09:56 @monitor.py:363][0m val-utt-error: 0.2216
[32m[0324 13:09:56 @monitor.py:363][0m validation_cost: 2.2241
[32m[0324 13:09:56 @monitor.py:363][0m wd_cost: 8.2682e-08
[32m[0324 13:09:56 @group.py:42][0m Callbacks took 75.565 sec in total. InferenceRunner: 75.405sec
[32m[0324 13:09:56 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13044/173481[03:00<36:53,72.47it/s]  8%|8         |13926/173481[03:10<36:41,72.47it/s] 16%|#6        |28477/173481[06:00<30:46,78.54it/s] 17%|#6        |29349/173481[06:10<30:35,78.54it/s] 23%|##3       |40607/173481[09:00<30:31,72.53it/s] 24%|##3       |41273/173481[09:10<30:22,72.53it/s] 30%|###       |52902/173481[12:00<28:33,70.35it/s] 31%|###       |53646/173481[12:10<28:23,70.35it/s] 39%|###8      |66968/173481[15:00<23:58,74.04it/s] 39%|###9      |67869/173481[15:10<23:46,74.04it/s] 48%|####7     |82897/173481[18:00<18:43,80.62it/s] 48%|####8     |83894/173481[18:11<18:31,80.62it/s] 57%|#####7    |99006/173481[21:00<14:37,84.83it/s] 58%|#####7    |99996/173481[21:11<14:26,84.83it/s] 65%|######5   |112862/173481[24:00<12:31,80.71it/s] 65%|######5   |113602/173481[24:11<12:21,80.71it/s] 72%|#######1  |124169/173481[27:00<11:38,70.65it/s] 72%|#######1  |124906/173481[27:11<11:27,70.65it/s] 78%|#######8  |135897/173481[30:00<09:14,67.78it/s] 79%|#######8  |136664/173481[30:11<09:03,67.78it/s] 85%|########4 |147302/173481[33:00<06:39,65.49it/s] 85%|########5 |148073/173481[33:11<06:27,65.49it/s] 92%|#########1|158802/173481[36:00<03:46,64.68it/s] 92%|#########1|159576/173481[36:12<03:34,64.68it/s] 98%|#########8|170142/173481[39:00<00:52,63.82it/s] 98%|#########8|170866/173481[39:12<00:40,63.82it/s][32m[0324 13:49:50 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:2394.58 sec.
100%|##########|173481/173481[39:54<00:00,72.45it/s]
[32m[0324 13:49:51 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-6071835.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:16<00:00,244.88it/s]
34
[32m[0324 13:51:07 @monitor.py:363][0m QueueInput/queue_size: 0.3015
[32m[0324 13:51:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.034
[32m[0324 13:51:07 @monitor.py:363][0m activation-summaries/output-rms: 0.03776
[32m[0324 13:51:07 @monitor.py:363][0m cross_entropy_loss: 1.8951
[32m[0324 13:51:07 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63474
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32289
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95255
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78712
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.8632
[32m[0324 13:51:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 13:51:07 @monitor.py:363][0m train-error-top1: 0.5019
[32m[0324 13:51:07 @monitor.py:363][0m val-error-top1: 0.57507
[32m[0324 13:51:07 @monitor.py:363][0m val-utt-error: 0.22819
[32m[0324 13:51:07 @monitor.py:363][0m validation_cost: 2.2529
[32m[0324 13:51:07 @monitor.py:363][0m wd_cost: 8.2694e-08
[32m[0324 13:51:07 @group.py:42][0m Callbacks took 77.058 sec in total. InferenceRunner: 76.869sec
[32m[0324 13:51:07 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10963/173481[03:00<44:28,60.90it/s]  7%|6         |11665/173481[03:10<44:16,60.90it/s] 13%|#2        |22506/173481[06:00<40:16,62.47it/s] 13%|#3        |23175/173481[06:10<40:06,62.47it/s] 19%|#9        |33141/173481[09:00<38:30,60.73it/s] 19%|#9        |33680/173481[09:10<38:22,60.73it/s] 24%|##4       |42256/173481[12:00<39:36,55.22it/s] 25%|##4       |42822/173481[12:10<39:26,55.22it/s] 30%|##9       |51486/173481[15:00<38:14,53.17it/s] 30%|##9       |52010/173481[15:10<38:04,53.17it/s] 35%|###5      |61331/173481[18:00<34:39,53.92it/s] 36%|###5      |62005/173481[18:11<34:27,53.92it/s] 42%|####1     |72126/173481[21:00<29:44,56.79it/s] 42%|####1     |72850/173481[21:11<29:32,56.79it/s] 48%|####8     |83796/173481[24:00<24:41,60.54it/s] 49%|####8     |84507/173481[24:11<24:29,60.54it/s] 55%|#####5    |95423/173481[27:00<20:48,62.50it/s] 55%|#####5    |96161/173481[27:11<20:37,62.50it/s] 62%|######1   |106696/173481[30:00<17:47,62.56it/s] 62%|######1   |107405/173481[30:11<17:36,62.56it/s] 68%|######8   |118255/173481[33:00<14:31,63.38it/s] 69%|######8   |119015/173481[33:11<14:19,63.38it/s] 75%|#######4  |129571/173481[36:00<11:35,63.12it/s] 75%|#######5  |130295/173481[36:12<11:24,63.12it/s] 81%|########1 |140688/173481[39:00<08:45,62.43it/s] 82%|########1 |141488/173481[39:12<08:32,62.43it/s] 87%|########7 |151577/173481[42:00<05:56,61.45it/s] 88%|########7 |152305/173481[42:12<05:44,61.45it/s] 94%|#########3|162931/173481[45:00<02:49,62.25it/s] 94%|#########4|163898/173481[45:12<02:33,62.25it/s]100%|##########|173481/173481[47:35<00:00,60.75it/s]
[32m[0324 14:38:43 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:2855.45 sec.
[32m[0324 14:38:43 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:13<00:00,256.03it/s]
35
[32m[0324 14:39:57 @monitor.py:363][0m QueueInput/queue_size: 0.33574
[32m[0324 14:39:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.039
[32m[0324 14:39:57 @monitor.py:363][0m activation-summaries/output-rms: 0.035958
[32m[0324 14:39:57 @monitor.py:363][0m cross_entropy_loss: 1.9014
[32m[0324 14:39:57 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63458
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32289
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.9526
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78717
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86325
[32m[0324 14:39:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 14:39:57 @monitor.py:363][0m train-error-top1: 0.4943
[32m[0324 14:39:57 @monitor.py:363][0m val-error-top1: 0.56401
[32m[0324 14:39:57 @monitor.py:363][0m val-utt-error: 0.2224
[32m[0324 14:39:57 @monitor.py:363][0m validation_cost: 2.2085
[32m[0324 14:39:57 @monitor.py:363][0m wd_cost: 1.6539e-08
[32m[0324 14:39:57 @group.py:42][0m Callbacks took 73.673 sec in total. InferenceRunner: 73.523sec
[32m[0324 14:39:57 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11666/173481[03:00<41:36,64.81it/s]  7%|7         |12354/173481[03:10<41:26,64.81it/s] 13%|#3        |23395/173481[06:00<38:29,64.98it/s] 14%|#3        |24081/173481[06:10<38:19,64.98it/s] 20%|#9        |34060/173481[09:00<37:29,61.98it/s] 20%|#9        |34629/173481[09:10<37:20,61.98it/s] 26%|##5       |44351/173481[12:00<36:11,59.48it/s] 26%|##5       |44969/173481[12:10<36:00,59.48it/s] 32%|###1      |54885/173481[15:00<33:30,58.98it/s] 32%|###2      |55515/173481[15:10<33:19,58.98it/s] 38%|###7      |65520/173481[18:00<30:29,59.02it/s] 38%|###8      |66164/173481[18:10<30:18,59.02it/s] 44%|####4     |76357/173481[21:00<27:09,59.61it/s] 44%|####4     |76990/173481[21:11<26:58,59.61it/s] 50%|#####     |87300/173481[24:00<23:51,60.19it/s] 51%|#####     |88009/173481[24:11<23:39,60.19it/s] 57%|#####6    |98430/173481[27:00<20:30,61.00it/s] 57%|#####7    |99115/173481[27:11<20:19,61.00it/s] 63%|######3   |109910/173481[30:00<16:59,62.36it/s] 64%|######3   |110639/173481[30:11<16:47,62.36it/s] 70%|######9   |120891/173481[33:00<14:12,61.67it/s] 70%|#######   |121569/173481[33:11<14:01,61.67it/s] 76%|#######5  |131584/173481[36:00<11:32,60.52it/s] 76%|#######6  |132274/173481[36:11<11:20,60.52it/s] 82%|########1 |141995/173481[39:00<08:52,59.14it/s] 82%|########2 |142714/173481[39:12<08:40,59.14it/s] 88%|########8 |153016/173481[42:00<05:40,60.16it/s] 89%|########8 |153784/173481[42:12<05:27,60.16it/s] 94%|#########4|163810/173481[45:00<02:41,60.06it/s] 95%|#########4|164569/173481[45:12<02:28,60.06it/s]100%|##########|173481/173481[47:41<00:00,60.62it/s]
[32m[0324 15:27:38 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:2861.66 sec.
[32m[0324 15:27:38 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:13<00:00,257.21it/s]
36
[32m[0324 15:28:52 @monitor.py:363][0m QueueInput/queue_size: 0.29735
[32m[0324 15:28:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.175
[32m[0324 15:28:52 @monitor.py:363][0m activation-summaries/output-rms: 0.036479
[32m[0324 15:28:52 @monitor.py:363][0m cross_entropy_loss: 1.9394
[32m[0324 15:28:52 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63433
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1683
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95264
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78719
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86328
[32m[0324 15:28:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 15:28:52 @monitor.py:363][0m train-error-top1: 0.50861
[32m[0324 15:28:52 @monitor.py:363][0m val-error-top1: 0.57292
[32m[0324 15:28:52 @monitor.py:363][0m val-utt-error: 0.22734
[32m[0324 15:28:52 @monitor.py:363][0m validation_cost: 2.2483
[32m[0324 15:28:52 @monitor.py:363][0m wd_cost: 1.6538e-08
[32m[0324 15:28:52 @group.py:42][0m Callbacks took 73.391 sec in total. InferenceRunner: 73.185sec
[32m[0324 15:28:52 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13019/173481[03:00<36:59,72.31it/s]  8%|7         |13641/173481[03:10<36:50,72.31it/s] 14%|#4        |25124/173481[06:00<35:28,69.68it/s] 15%|#4        |25744/173481[06:10<35:20,69.68it/s] 21%|##        |35709/173481[09:00<36:00,63.78it/s] 21%|##        |36357/173481[09:10<35:49,63.78it/s] 27%|##6       |46470/173481[12:00<34:17,61.72it/s] 27%|##7       |47016/173481[12:10<34:09,61.72it/s] 33%|###2      |56722/173481[15:00<32:51,59.24it/s] 33%|###3      |57353/173481[15:10<32:40,59.24it/s] 39%|###8      |67319/173481[18:00<29:57,59.05it/s] 39%|###9      |67938/173481[18:11<29:47,59.05it/s] 46%|####5     |78965/173481[21:00<25:30,61.75it/s] 46%|####5     |79648/173481[21:11<25:19,61.75it/s] 52%|#####2    |90494/173481[24:00<22:00,62.87it/s] 53%|#####2    |91203/173481[24:11<21:48,62.87it/s] 58%|#####8    |101461/173481[27:00<19:23,61.88it/s] 59%|#####8    |102128/173481[27:11<19:13,61.88it/s] 65%|######4   |112549/173481[30:00<16:26,61.74it/s] 65%|######5   |113347/173481[30:11<16:14,61.74it/s] 72%|#######1  |124727/173481[33:00<12:35,64.56it/s] 72%|#######2  |125441/173481[33:11<12:24,64.56it/s] 78%|#######8  |136020/173481[36:00<09:48,63.64it/s] 79%|#######8  |136771/173481[36:11<09:36,63.64it/s] 85%|########4 |147449/173481[39:00<06:49,63.56it/s] 85%|########5 |148135/173481[39:12<06:38,63.56it/s] 92%|#########1|158869/173481[42:00<03:50,63.50it/s] 92%|#########2|159710/173481[42:12<03:36,63.50it/s]100%|#########9|172620/173481[45:00<00:12,69.35it/s]100%|#########9|173442/173481[45:12<00:00,69.35it/s]100%|##########|173481/173481[45:13<00:00,63.94it/s]
[32m[0324 16:14:05 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:2713.03 sec.
[32m[0324 16:14:05 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-6592278.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,198.73it/s]
37
[32m[0324 16:15:40 @monitor.py:363][0m QueueInput/queue_size: 0.69213
[32m[0324 16:15:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.967
[32m[0324 16:15:40 @monitor.py:363][0m activation-summaries/output-rms: 0.036316
[32m[0324 16:15:40 @monitor.py:363][0m cross_entropy_loss: 1.9438
[32m[0324 16:15:40 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63409
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1683
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95267
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78722
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86331
[32m[0324 16:15:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 16:15:40 @monitor.py:363][0m train-error-top1: 0.51888
[32m[0324 16:15:40 @monitor.py:363][0m val-error-top1: 0.57877
[32m[0324 16:15:40 @monitor.py:363][0m val-utt-error: 0.24153
[32m[0324 16:15:40 @monitor.py:363][0m validation_cost: 2.3066
[32m[0324 16:15:40 @monitor.py:363][0m wd_cost: 1.6538e-08
[32m[0324 16:15:40 @group.py:42][0m Callbacks took 94.911 sec in total. InferenceRunner: 94.718sec
[32m[0324 16:15:40 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11868/173481[03:00<40:51,65.92it/s]  7%|7         |12574/173481[03:10<40:40,65.92it/s] 13%|#2        |22077/173481[06:00<41:23,60.97it/s] 13%|#3        |22683/173481[06:10<41:13,60.97it/s] 19%|#8        |32262/173481[09:00<40:06,58.69it/s] 19%|#8        |32863/173481[09:10<39:55,58.69it/s] 25%|##4       |42934/173481[12:00<36:53,58.99it/s] 25%|##5       |43591/173481[12:10<36:41,58.99it/s] 31%|###       |53665/173481[15:00<33:40,59.30it/s] 31%|###1      |54328/173481[15:11<33:29,59.30it/s] 37%|###6      |64141/173481[18:00<31:01,58.74it/s] 37%|###7      |64785/173481[18:11<30:50,58.74it/s] 43%|####3     |74993/173481[21:00<27:35,59.50it/s] 44%|####3     |75623/173481[21:11<27:24,59.50it/s] 49%|####9     |85376/173481[24:00<25:04,58.58it/s] 50%|####9     |86030/173481[24:11<24:52,58.58it/s] 55%|#####5    |95610/173481[27:00<22:29,57.70it/s] 55%|#####5    |96270/173481[27:11<22:18,57.70it/s] 61%|######1   |105833/173481[30:00<19:42,57.23it/s] 61%|######1   |106512/173481[30:12<19:30,57.23it/s] 67%|######6   |116022/173481[33:00<16:49,56.92it/s] 67%|######7   |116684/173481[33:12<16:37,56.92it/s] 73%|#######2  |126630/173481[36:00<13:29,57.91it/s] 73%|#######3  |127357/173481[36:12<13:16,57.91it/s] 79%|#######9  |137150/173481[39:00<10:24,58.16it/s] 79%|#######9  |137866/173481[39:12<10:12,58.16it/s] 85%|########4 |147370/173481[42:00<07:34,57.46it/s] 85%|########5 |148067/173481[42:12<07:22,57.46it/s] 91%|######### |157581/173481[45:00<04:38,57.09it/s] 91%|#########1|158365/173481[45:13<04:24,57.09it/s] 97%|#########6|167541/173481[48:00<01:45,56.20it/s] 97%|#########6|168242/173481[48:13<01:33,56.20it/s]100%|##########|173481/173481[49:50<00:00,58.00it/s]
[32m[0324 17:05:30 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:2990.88 sec.
[32m[0324 17:05:31 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:18<00:00,135.72it/s]
38
[32m[0324 17:07:49 @monitor.py:363][0m QueueInput/queue_size: 3.8148
[32m[0324 17:07:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.048
[32m[0324 17:07:49 @monitor.py:363][0m activation-summaries/output-rms: 0.036367
[32m[0324 17:07:49 @monitor.py:363][0m cross_entropy_loss: 1.8849
[32m[0324 17:07:49 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63381
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1683
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95267
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86331
[32m[0324 17:07:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 17:07:49 @monitor.py:363][0m train-error-top1: 0.49146
[32m[0324 17:07:49 @monitor.py:363][0m val-error-top1: 0.58017
[32m[0324 17:07:49 @monitor.py:363][0m val-utt-error: 0.2352
[32m[0324 17:07:49 @monitor.py:363][0m validation_cost: 2.279
[32m[0324 17:07:49 @monitor.py:363][0m wd_cost: 3.3072e-09
[32m[0324 17:07:49 @group.py:42][0m Callbacks took 138.886 sec in total. InferenceRunner: 138.704sec
[32m[0324 17:07:49 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9988/173481[03:00<49:07,55.48it/s]  6%|6         |10546/173481[03:10<48:57,55.48it/s] 12%|#1        |20000/173481[06:00<46:03,55.55it/s] 12%|#1        |20611/173481[06:10<45:52,55.55it/s] 17%|#7        |30115/173481[09:00<42:46,55.86it/s] 18%|#7        |30721/173481[09:10<42:35,55.86it/s] 23%|##3       |40343/173481[12:00<39:23,56.34it/s] 24%|##3       |40989/173481[12:10<39:11,56.34it/s] 29%|##8       |50254/173481[15:00<36:52,55.69it/s] 30%|##9       |51330/173481[15:10<36:33,55.69it/s] 36%|###5      |61646/173481[18:00<31:27,59.24it/s] 36%|###5      |62302/173481[18:11<31:16,59.24it/s] 42%|####1     |72069/173481[21:00<28:51,58.57it/s] 42%|####1     |72826/173481[21:11<28:38,58.57it/s] 48%|####7     |82619/173481[24:00<25:50,58.59it/s] 48%|####8     |83307/173481[24:11<25:39,58.59it/s] 54%|#####3    |93212/173481[27:00<22:47,58.72it/s] 54%|#####4    |93785/173481[27:11<22:37,58.72it/s] 60%|#####9    |103576/173481[30:00<20:02,58.14it/s] 60%|######    |104251/173481[30:12<19:50,58.14it/s] 66%|######5   |113950/173481[33:00<17:08,57.89it/s] 66%|######6   |114688/173481[33:12<16:55,57.89it/s] 72%|#######1  |124487/173481[36:00<14:01,58.21it/s] 72%|#######2  |125211/173481[36:12<13:49,58.21it/s] 78%|#######7  |134827/173481[39:00<11:08,57.82it/s] 78%|#######8  |135546/173481[39:12<10:56,57.82it/s] 84%|########3 |145257/173481[42:00<08:07,57.88it/s] 84%|########4 |145962/173481[42:12<07:55,57.88it/s] 90%|########9 |155950/173481[45:00<04:59,58.63it/s] 90%|######### |156754/173481[45:13<04:45,58.63it/s] 96%|#########6|166619/173481[48:00<01:56,58.95it/s] 97%|#########6|167420/173481[48:13<01:42,58.95it/s][32m[0324 17:57:49 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:2999.37 sec.
100%|##########|173481/173481[49:59<00:00,57.84it/s]
[32m[0324 17:57:49 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-6939240.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:39<00:00,118.38it/s]
39
[32m[0324 18:00:28 @monitor.py:363][0m QueueInput/queue_size: 1.8337
[32m[0324 18:00:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.07
[32m[0324 18:00:28 @monitor.py:363][0m activation-summaries/output-rms: 0.03791
[32m[0324 18:00:28 @monitor.py:363][0m cross_entropy_loss: 1.8804
[32m[0324 18:00:28 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63352
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95267
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0324 18:00:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 18:00:28 @monitor.py:363][0m train-error-top1: 0.49806
[32m[0324 18:00:28 @monitor.py:363][0m val-error-top1: 0.58256
[32m[0324 18:00:28 @monitor.py:363][0m val-utt-error: 0.24843
[32m[0324 18:00:28 @monitor.py:363][0m validation_cost: 2.3259
[32m[0324 18:00:28 @monitor.py:363][0m wd_cost: 3.3068e-09
[32m[0324 18:00:28 @group.py:42][0m Callbacks took 159.200 sec in total. InferenceRunner: 159.028sec
[32m[0324 18:00:28 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12228/173481[03:00<39:33,67.93it/s]  7%|7         |12809/173481[03:10<39:25,67.93it/s] 13%|#3        |22781/173481[06:00<39:54,62.93it/s] 13%|#3        |23410/173481[06:10<39:44,62.93it/s] 19%|#9        |33341/173481[09:00<38:28,60.72it/s] 20%|#9        |33934/173481[09:10<38:18,60.72it/s] 25%|##5       |43531/173481[12:00<36:58,58.58it/s] 25%|##5       |44115/173481[12:10<36:48,58.58it/s] 30%|###       |52746/173481[15:00<36:49,54.63it/s] 31%|###       |53304/173481[15:10<36:39,54.63it/s] 36%|###6      |62938/173481[18:00<33:07,55.61it/s] 37%|###6      |63590/173481[18:11<32:56,55.61it/s] 42%|####1     |72846/173481[21:00<30:18,55.32it/s] 42%|####2     |73473/173481[21:11<30:07,55.32it/s] 48%|####7     |82726/173481[24:00<27:27,55.10it/s] 48%|####8     |83298/173481[24:11<27:16,55.10it/s] 53%|#####2    |91869/173481[27:00<25:44,52.86it/s] 53%|#####3    |92451/173481[27:11<25:32,52.86it/s] 58%|#####8    |100960/173481[30:00<23:23,51.65it/s] 59%|#####8    |101540/173481[30:11<23:12,51.65it/s] 64%|######3   |110656/173481[33:00<19:51,52.74it/s] 64%|######4   |111255/173481[33:11<19:39,52.74it/s] 69%|######9   |119859/173481[36:00<17:12,51.92it/s] 69%|######9   |120491/173481[36:12<17:00,51.92it/s] 74%|#######4  |129131/173481[39:00<14:17,51.71it/s] 75%|#######4  |129715/173481[39:12<14:06,51.71it/s] 80%|#######9  |138408/173481[42:00<11:19,51.62it/s] 80%|########  |139055/173481[42:12<11:06,51.62it/s] 85%|########5 |147586/173481[45:00<08:24,51.30it/s] 85%|########5 |148218/173481[45:12<08:12,51.30it/s] 91%|######### |157273/173481[48:00<05:08,52.52it/s] 91%|#########1|157938/173481[48:12<04:55,52.52it/s] 96%|#########6|167109/173481[51:00<01:58,53.56it/s] 97%|#########6|167765/173481[51:12<01:46,53.56it/s]100%|##########|173481/173481[52:56<00:00,54.62it/s]
[32m[0324 18:53:24 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:3176.01 sec.
[32m[0324 18:53:24 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:44<00:00,114.72it/s]
40
[32m[0324 18:56:08 @monitor.py:363][0m QueueInput/queue_size: 0.42324
[32m[0324 18:56:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.913
[32m[0324 18:56:08 @monitor.py:363][0m activation-summaries/output-rms: 0.036618
[32m[0324 18:56:08 @monitor.py:363][0m cross_entropy_loss: 1.8668
[32m[0324 18:56:08 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63323
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95267
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0324 18:56:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 18:56:08 @monitor.py:363][0m train-error-top1: 0.48784
[32m[0324 18:56:08 @monitor.py:363][0m val-error-top1: 0.5302
[32m[0324 18:56:08 @monitor.py:363][0m val-utt-error: 0.17639
[32m[0324 18:56:08 @monitor.py:363][0m validation_cost: 2.0401
[32m[0324 18:56:08 @monitor.py:363][0m wd_cost: 3.3064e-09
[32m[0324 18:56:08 @group.py:42][0m Callbacks took 164.266 sec in total. InferenceRunner: 164.087sec
[32m[0324 18:56:08 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10800/173481[03:00<45:11,59.99it/s]  7%|6         |11343/173481[03:10<45:02,59.99it/s] 12%|#1        |20575/173481[06:00<44:42,57.01it/s] 12%|#2        |21111/173481[06:10<44:32,57.01it/s] 18%|#7        |30465/173481[09:00<42:35,55.96it/s] 18%|#7        |31034/173481[09:10<42:25,55.96it/s] 22%|##2       |39033/173481[12:00<43:33,51.44it/s] 23%|##2       |39525/173481[12:10<43:24,51.44it/s] 27%|##7       |47339/173481[15:00<43:13,48.65it/s] 28%|##7       |47838/173481[15:10<43:02,48.65it/s] 32%|###2      |56250/173481[18:00<39:49,49.07it/s] 33%|###2      |56764/173481[18:11<39:38,49.07it/s] 38%|###7      |65539/173481[21:00<35:45,50.31it/s] 38%|###8      |66164/173481[21:11<35:33,50.31it/s] 44%|####3     |75511/173481[24:00<30:57,52.73it/s] 44%|####3     |76139/173481[24:11<30:46,52.73it/s] 49%|####9     |85320/173481[27:00<27:25,53.59it/s] 50%|####9     |85933/173481[27:11<27:13,53.59it/s] 55%|#####4    |95341/173481[30:00<23:50,54.61it/s] 55%|#####5    |95954/173481[30:11<23:39,54.61it/s] 61%|######    |105249/173481[33:00<20:44,54.82it/s] 61%|######1   |105906/173481[33:12<20:32,54.82it/s] 66%|######6   |114895/173481[36:00<18:01,54.19it/s] 67%|######6   |115489/173481[36:12<17:50,54.19it/s] 71%|#######1  |124007/173481[39:00<15:45,52.34it/s] 72%|#######1  |124624/173481[39:12<15:33,52.34it/s] 77%|#######6  |133000/173481[42:00<13:11,51.12it/s] 77%|#######7  |133631/173481[42:12<12:59,51.12it/s] 82%|########1 |141775/173481[45:00<10:35,49.91it/s] 82%|########2 |142298/173481[45:12<10:24,49.91it/s] 87%|########6 |150820/173481[48:00<07:32,50.08it/s] 87%|########7 |151467/173481[48:12<07:19,50.08it/s] 92%|#########2|159809/173481[51:00<04:33,50.01it/s] 93%|#########2|160530/173481[51:13<04:18,50.01it/s] 97%|#########7|168703/173481[54:00<01:36,49.71it/s] 98%|#########7|169373/173481[54:13<01:22,49.71it/s][32m[0324 19:51:42 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3333.52 sec.
100%|##########|173481/173481[55:33<00:00,52.04it/s]
[32m[0324 19:51:42 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-7286202.
[32m[0324 19:51:44 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:54<00:00,107.94it/s]
41
[32m[0324 19:54:38 @monitor.py:363][0m QueueInput/queue_size: 0.62679
[32m[0324 19:54:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.098
[32m[0324 19:54:38 @monitor.py:363][0m activation-summaries/output-rms: 0.038023
[32m[0324 19:54:38 @monitor.py:363][0m cross_entropy_loss: 1.8673
[32m[0324 19:54:38 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63307
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95267
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0324 19:54:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 19:54:38 @monitor.py:363][0m train-error-top1: 0.48567
[32m[0324 19:54:38 @monitor.py:363][0m val-error-top1: 0.53242
[32m[0324 19:54:38 @monitor.py:363][0m val-utt-error: 0.17968
[32m[0324 19:54:38 @monitor.py:363][0m validation_cost: 2.0498
[32m[0324 19:54:38 @monitor.py:363][0m wd_cost: 6.6124e-10
[32m[0324 19:54:38 @group.py:42][0m Callbacks took 176.496 sec in total. InferenceRunner: 174.393sec
[32m[0324 19:54:38 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10149/173481[03:00<48:17,56.37it/s]  6%|6         |10682/173481[03:10<48:08,56.37it/s] 11%|#1        |19558/173481[06:00<47:17,54.24it/s] 12%|#1        |20103/173481[06:10<47:07,54.24it/s] 16%|#6        |27906/173481[09:00<48:31,50.00it/s] 16%|#6        |28341/173481[09:10<48:22,50.00it/s] 21%|##        |35904/173481[12:00<48:43,47.05it/s] 21%|##        |36393/173481[12:10<48:33,47.05it/s] 25%|##5       |44118/173481[15:00<46:32,46.33it/s] 26%|##5       |44613/173481[15:10<46:21,46.33it/s] 30%|###       |52474/173481[18:00<43:29,46.37it/s] 31%|###       |53003/173481[18:11<43:18,46.37it/s] 35%|###5      |60993/173481[21:00<40:01,46.84it/s] 35%|###5      |61498/173481[21:11<39:50,46.84it/s] 40%|####      |70046/173481[24:00<35:32,48.50it/s] 41%|####      |70604/173481[24:11<35:21,48.50it/s] 46%|####5     |79614/173481[27:00<30:50,50.72it/s] 46%|####6     |80173/173481[27:11<30:39,50.72it/s] 51%|#####1    |88624/173481[30:00<28:04,50.38it/s] 51%|#####1    |89208/173481[30:11<27:52,50.38it/s] 56%|#####6    |97642/173481[33:00<25:09,50.24it/s] 57%|#####6    |98228/173481[33:11<24:57,50.24it/s] 61%|######1   |106534/173481[36:00<22:23,49.81it/s] 62%|######1   |107138/173481[36:11<22:11,49.81it/s] 67%|######6   |115607/173481[39:00<19:15,50.11it/s] 67%|######6   |116199/173481[39:12<19:03,50.11it/s] 72%|#######1  |124599/173481[42:00<16:17,50.03it/s] 72%|#######2  |125218/173481[42:12<16:04,50.03it/s] 77%|#######7  |133909/173481[45:00<12:58,50.86it/s] 78%|#######7  |134585/173481[45:12<12:44,50.86it/s] 83%|########2 |143533/173481[48:00<09:34,52.13it/s] 83%|########3 |144199/173481[48:12<09:21,52.13it/s] 88%|########8 |153070/173481[51:00<06:28,52.55it/s] 89%|########8 |153733/173481[51:12<06:15,52.55it/s] 94%|#########3|162495/173481[54:00<03:29,52.46it/s] 94%|#########4|163155/173481[54:12<03:16,52.46it/s] 99%|#########9|172031/173481[57:00<00:27,52.72it/s]100%|#########9|172675/173481[57:13<00:15,52.72it/s][32m[0324 20:52:07 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3449.03 sec.
100%|##########|173481/173481[57:29<00:00,50.30it/s]
[32m[0324 20:52:08 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:24<00:00,129.95it/s]
42
[32m[0324 20:54:32 @monitor.py:363][0m QueueInput/queue_size: 1.1318
[32m[0324 20:54:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.965
[32m[0324 20:54:32 @monitor.py:363][0m activation-summaries/output-rms: 0.037158
[32m[0324 20:54:32 @monitor.py:363][0m cross_entropy_loss: 1.8833
[32m[0324 20:54:32 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6329
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0324 20:54:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 20:54:32 @monitor.py:363][0m train-error-top1: 0.50617
[32m[0324 20:54:32 @monitor.py:363][0m val-error-top1: 0.52623
[32m[0324 20:54:32 @monitor.py:363][0m val-utt-error: 0.1766
[32m[0324 20:54:32 @monitor.py:363][0m validation_cost: 2.0168
[32m[0324 20:54:32 @monitor.py:363][0m wd_cost: 6.6119e-10
[32m[0324 20:54:32 @group.py:42][0m Callbacks took 145.163 sec in total. InferenceRunner: 144.846sec
[32m[0324 20:54:32 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9763/173481[03:00<50:19,54.22it/s]  6%|5         |10231/173481[03:10<50:10,54.22it/s] 11%|#         |18608/173481[06:00<50:04,51.55it/s] 11%|#1        |19092/173481[06:10<49:54,51.55it/s] 16%|#6        |27948/173481[09:00<46:53,51.72it/s] 16%|#6        |28522/173481[09:10<46:42,51.72it/s] 22%|##1       |37750/173481[12:00<42:38,53.05it/s] 22%|##2       |38318/173481[12:10<42:27,53.05it/s] 28%|##7       |48031/173481[15:00<38:00,55.01it/s] 28%|##8       |48595/173481[15:10<37:50,55.01it/s] 33%|###3      |58028/173481[18:00<34:49,55.26it/s] 34%|###3      |58677/173481[18:11<34:37,55.26it/s] 40%|###9      |68593/173481[21:00<30:42,56.93it/s] 40%|###9      |69327/173481[21:11<30:29,56.93it/s] 46%|####5     |79181/173481[24:00<27:09,57.86it/s] 46%|####6     |79812/173481[24:11<26:58,57.86it/s] 52%|#####1    |89554/173481[27:00<24:13,57.74it/s] 52%|#####2    |90230/173481[27:11<24:01,57.74it/s] 58%|#####7    |99973/173481[30:00<21:11,57.81it/s] 58%|#####8    |100661/173481[30:11<20:59,57.81it/s] 64%|######3   |110469/173481[33:00<18:05,58.06it/s] 64%|######4   |111152/173481[33:12<17:53,58.06it/s] 70%|######9   |121038/173481[36:00<14:58,58.38it/s] 70%|#######   |121746/173481[36:12<14:46,58.38it/s] 76%|#######5  |131687/173481[39:00<11:51,58.77it/s] 76%|#######6  |132481/173481[39:12<11:37,58.77it/s] 82%|########2 |142408/173481[42:00<08:45,59.16it/s] 83%|########2 |143143/173481[42:12<08:32,59.16it/s] 88%|########8 |152843/173481[45:00<05:52,58.55it/s] 89%|########8 |153556/173481[45:12<05:40,58.55it/s] 94%|#########3|163054/173481[48:00<03:00,57.63it/s] 94%|#########4|163736/173481[48:12<02:49,57.63it/s]100%|#########9|172747/173481[51:00<00:13,55.67it/s]100%|#########9|173480/173481[51:13<00:00,55.67it/s]100%|##########|173481/173481[51:13<00:00,56.45it/s]
[32m[0324 21:45:45 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3073.04 sec.
[32m[0324 21:45:46 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-7633164.
[32m[0324 21:45:46 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:27<00:00,127.89it/s]
43
[32m[0324 21:48:13 @monitor.py:363][0m QueueInput/queue_size: 0.48354
[32m[0324 21:48:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.026
[32m[0324 21:48:13 @monitor.py:363][0m activation-summaries/output-rms: 0.036717
[32m[0324 21:48:13 @monitor.py:363][0m cross_entropy_loss: 1.8547
[32m[0324 21:48:13 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6328
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0324 21:48:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 21:48:13 @monitor.py:363][0m train-error-top1: 0.48683
[32m[0324 21:48:13 @monitor.py:363][0m val-error-top1: 0.51454
[32m[0324 21:48:13 @monitor.py:363][0m val-utt-error: 0.169
[32m[0324 21:48:13 @monitor.py:363][0m validation_cost: 1.9734
[32m[0324 21:48:13 @monitor.py:363][0m wd_cost: 6.6117e-10
[32m[0324 21:48:13 @group.py:42][0m Callbacks took 147.957 sec in total. InferenceRunner: 147.221sec
[32m[0324 21:48:13 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10368/173481[03:00<47:11,57.60it/s]  6%|6         |10943/173481[03:10<47:01,57.60it/s] 12%|#2        |20853/173481[06:00<43:55,57.92it/s] 12%|#2        |21386/173481[06:10<43:45,57.92it/s] 18%|#7        |30422/173481[09:00<43:00,55.44it/s] 18%|#7        |31033/173481[09:10<42:49,55.44it/s] 24%|##3       |41240/173481[12:00<38:12,57.67it/s] 24%|##4       |41911/173481[12:10<38:01,57.67it/s] 30%|##9       |52042/173481[15:00<34:24,58.82it/s] 30%|###       |52644/173481[15:10<34:14,58.82it/s] 36%|###6      |62702/173481[18:00<31:17,59.01it/s] 37%|###6      |63401/173481[18:11<31:05,59.01it/s] 42%|####2     |73350/173481[21:00<28:14,59.08it/s] 43%|####2     |74012/173481[21:11<28:03,59.08it/s] 49%|####8     |84180/173481[24:00<24:57,59.62it/s] 49%|####8     |84876/173481[24:11<24:46,59.62it/s] 55%|#####4    |94962/173481[27:00<21:53,59.76it/s] 55%|#####5    |95673/173481[27:11<21:42,59.76it/s] 61%|######1   |105835/173481[30:00<18:45,60.08it/s] 61%|######1   |106526/173481[30:11<18:34,60.08it/s] 67%|######7   |116383/173481[33:00<16:02,59.33it/s] 67%|######7   |117050/173481[33:11<15:51,59.33it/s] 73%|#######3  |127066/173481[36:00<13:02,59.34it/s] 74%|#######3  |127832/173481[36:12<12:49,59.34it/s] 79%|#######9  |137787/173481[39:00<10:00,59.45it/s] 80%|#######9  |138484/173481[39:12<09:48,59.45it/s] 86%|########5 |148407/173481[42:00<07:03,59.21it/s] 86%|########5 |149071/173481[42:12<06:52,59.21it/s] 92%|#########1|159261/173481[45:00<03:57,59.75it/s] 92%|#########2|159982/173481[45:12<03:45,59.75it/s] 98%|#########8|170065/173481[48:00<00:57,59.89it/s] 98%|#########8|170763/173481[48:12<00:45,59.89it/s][32m[0324 22:37:13 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:2939.52 sec.
100%|##########|173481/173481[48:59<00:00,59.02it/s]
[32m[0324 22:37:13 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-7806645.
[32m[0324 22:37:14 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:30<00:00,125.28it/s]
44
[32m[0324 22:39:44 @monitor.py:363][0m QueueInput/queue_size: 0.41545
[32m[0324 22:39:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.96
[32m[0324 22:39:44 @monitor.py:363][0m activation-summaries/output-rms: 0.03818
[32m[0324 22:39:44 @monitor.py:363][0m cross_entropy_loss: 1.8121
[32m[0324 22:39:44 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63277
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0324 22:39:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 22:39:44 @monitor.py:363][0m train-error-top1: 0.48165
[32m[0324 22:39:44 @monitor.py:363][0m val-error-top1: 0.52918
[32m[0324 22:39:44 @monitor.py:363][0m val-utt-error: 0.18457
[32m[0324 22:39:44 @monitor.py:363][0m validation_cost: 2.0518
[32m[0324 22:39:44 @monitor.py:363][0m wd_cost: 1.3223e-10
[32m[0324 22:39:44 @group.py:42][0m Callbacks took 151.482 sec in total. InferenceRunner: 150.248sec
[32m[0324 22:39:44 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10901/173481[03:00<44:45,60.55it/s]  7%|6         |11510/173481[03:10<44:34,60.55it/s] 12%|#2        |21468/173481[06:00<42:30,59.61it/s] 13%|#2        |22050/173481[06:10<42:20,59.61it/s] 18%|#8        |31679/173481[09:00<40:39,58.13it/s] 19%|#8        |32250/173481[09:10<40:29,58.13it/s] 24%|##3       |41575/173481[12:00<38:54,56.51it/s] 24%|##4       |42160/173481[12:10<38:43,56.51it/s] 30%|##9       |51709/173481[15:00<35:58,56.40it/s] 30%|###       |52288/173481[15:10<35:48,56.40it/s] 36%|###5      |62145/173481[18:00<32:27,57.18it/s] 36%|###6      |62761/173481[18:11<32:16,57.18it/s] 42%|####1     |72377/173481[21:00<29:33,57.01it/s] 42%|####2     |72984/173481[21:11<29:22,57.01it/s] 48%|####7     |82429/173481[24:00<26:53,56.42it/s] 48%|####7     |83094/173481[24:11<26:42,56.42it/s] 53%|#####3    |92500/173481[27:00<24:01,56.18it/s] 54%|#####3    |93148/173481[27:11<23:49,56.18it/s] 59%|#####9    |102466/173481[30:00<21:13,55.77it/s] 59%|#####9    |103105/173481[30:11<21:01,55.77it/s] 65%|######4   |112528/173481[33:00<18:11,55.83it/s] 65%|######5   |113168/173481[33:11<18:00,55.83it/s] 71%|#######   |122626/173481[36:00<15:08,55.97it/s] 71%|#######1  |123278/173481[36:12<14:57,55.97it/s] 77%|#######6  |132786/173481[39:00<12:04,56.20it/s] 77%|#######6  |133475/173481[39:12<11:51,56.20it/s] 83%|########2 |143180/173481[42:00<08:51,56.96it/s] 83%|########2 |143870/173481[42:12<08:39,56.96it/s] 88%|########8 |153367/173481[45:00<05:54,56.78it/s] 89%|########8 |153989/173481[45:12<05:43,56.78it/s] 94%|#########4|163209/173481[48:00<03:04,55.71it/s] 94%|#########4|163923/173481[48:12<02:51,55.71it/s]100%|#########9|173216/173481[51:00<00:04,55.65it/s]100%|##########|173481/173481[51:04<00:00,56.60it/s]
[32m[0324 23:30:49 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:3064.83 sec.
[32m[0324 23:30:50 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-7980126.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:18<00:00,136.02it/s]
45
[32m[0324 23:33:08 @monitor.py:363][0m QueueInput/queue_size: 0.28712
[32m[0324 23:33:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.928
[32m[0324 23:33:08 @monitor.py:363][0m activation-summaries/output-rms: 0.036077
[32m[0324 23:33:08 @monitor.py:363][0m cross_entropy_loss: 1.8278
[32m[0324 23:33:08 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63274
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0324 23:33:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0324 23:33:08 @monitor.py:363][0m train-error-top1: 0.47596
[32m[0324 23:33:08 @monitor.py:363][0m val-error-top1: 0.51232
[32m[0324 23:33:08 @monitor.py:363][0m val-utt-error: 0.16869
[32m[0324 23:33:08 @monitor.py:363][0m validation_cost: 1.9678
[32m[0324 23:33:08 @monitor.py:363][0m wd_cost: 1.3223e-10
[32m[0324 23:33:08 @group.py:42][0m Callbacks took 138.767 sec in total. InferenceRunner: 138.393sec
[32m[0324 23:33:08 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9986/173481[03:00<49:07,55.48it/s]  6%|6         |10589/173481[03:10<48:56,55.48it/s] 11%|#1        |19300/173481[06:00<47:59,53.54it/s] 12%|#1        |20005/173481[06:10<47:46,53.54it/s] 17%|#7        |29771/173481[09:00<42:57,55.76it/s] 18%|#7        |30366/173481[09:10<42:46,55.76it/s] 22%|##2       |38865/173481[12:00<42:19,53.01it/s] 23%|##2       |39404/173481[12:10<42:09,53.01it/s] 28%|##7       |48165/173481[15:00<39:54,52.33it/s] 28%|##8       |48725/173481[15:10<39:44,52.33it/s] 33%|###3      |58092/173481[18:00<35:48,53.70it/s] 34%|###3      |58703/173481[18:10<35:37,53.70it/s] 39%|###9      |67894/173481[21:00<32:32,54.07it/s] 39%|###9      |68524/173481[21:11<32:20,54.07it/s] 45%|####4     |77971/173481[24:00<28:56,55.01it/s] 45%|####5     |78585/173481[24:11<28:45,55.01it/s] 51%|#####     |88080/173481[27:00<25:36,55.58it/s] 51%|#####1    |88749/173481[27:11<25:24,55.58it/s] 57%|#####6    |98200/173481[30:00<22:26,55.89it/s] 57%|#####6    |98864/173481[30:11<22:15,55.89it/s] 62%|######2   |108331/173481[33:00<19:21,56.08it/s] 63%|######2   |108952/173481[33:11<19:10,56.08it/s] 68%|######8   |118319/173481[36:00<16:28,55.78it/s] 69%|######8   |118965/173481[36:11<16:17,55.78it/s] 74%|#######3  |128200/173481[39:00<13:38,55.33it/s] 74%|#######4  |128857/173481[39:12<13:26,55.33it/s] 80%|#######9  |138133/173481[42:00<10:39,55.25it/s] 80%|#######9  |138773/173481[42:12<10:28,55.25it/s] 85%|########5 |148159/173481[45:00<07:36,55.47it/s] 86%|########5 |148824/173481[45:12<07:24,55.47it/s] 91%|#########1|158132/173481[48:00<04:36,55.44it/s] 92%|#########1|158840/173481[48:12<04:24,55.44it/s] 97%|#########7|168294/173481[51:00<01:32,55.94it/s] 97%|#########7|169014/173481[51:12<01:19,55.94it/s]100%|##########|173481/173481[52:30<00:00,55.07it/s]
[32m[0325 00:25:38 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:3150.42 sec.
[32m[0325 00:25:39 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-8153607.
[32m[0325 00:25:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:30<00:00,207.74it/s]
46
[32m[0325 00:27:10 @monitor.py:363][0m QueueInput/queue_size: 0.60753
[32m[0325 00:27:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.14
[32m[0325 00:27:10 @monitor.py:363][0m activation-summaries/output-rms: 0.037333
[32m[0325 00:27:10 @monitor.py:363][0m cross_entropy_loss: 1.8638
[32m[0325 00:27:10 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63273
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 00:27:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 00:27:10 @monitor.py:363][0m train-error-top1: 0.48994
[32m[0325 00:27:10 @monitor.py:363][0m val-error-top1: 0.51385
[32m[0325 00:27:10 @monitor.py:363][0m val-utt-error: 0.16343
[32m[0325 00:27:10 @monitor.py:363][0m validation_cost: 1.9646
[32m[0325 00:27:10 @monitor.py:363][0m wd_cost: 1.3223e-10
[32m[0325 00:27:10 @group.py:42][0m Callbacks took 91.497 sec in total. InferenceRunner: 90.611sec
[32m[0325 00:27:10 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10854/173481[03:00<44:57,60.29it/s]  7%|6         |11449/173481[03:10<44:47,60.29it/s] 12%|#2        |21614/173481[06:00<42:09,60.03it/s] 13%|#2        |22192/173481[06:10<42:00,60.03it/s] 18%|#7        |30878/173481[09:00<42:53,55.42it/s] 18%|#8        |31463/173481[09:10<42:42,55.42it/s] 23%|##3       |40659/173481[12:00<40:20,54.87it/s] 24%|##3       |41228/173481[12:10<40:10,54.87it/s] 29%|##9       |50335/173481[15:00<37:47,54.31it/s] 29%|##9       |50938/173481[15:10<37:36,54.31it/s] 35%|###4      |60584/173481[18:00<33:51,55.58it/s] 35%|###5      |61208/173481[18:10<33:39,55.58it/s] 41%|####1     |71499/173481[21:00<29:18,57.99it/s] 42%|####1     |72179/173481[21:11<29:06,57.99it/s] 48%|####7     |82504/173481[24:00<25:28,59.52it/s] 48%|####7     |83193/173481[24:11<25:16,59.52it/s] 54%|#####3    |93522/173481[27:00<22:04,60.35it/s] 54%|#####4    |94167/173481[27:11<21:54,60.35it/s] 60%|######    |104509/173481[30:00<18:56,60.69it/s] 61%|######    |105183/173481[30:11<18:45,60.69it/s] 67%|######6   |115744/173481[33:00<15:38,61.54it/s] 67%|######7   |116426/173481[33:11<15:27,61.54it/s] 73%|#######3  |126674/173481[36:00<12:45,61.13it/s] 73%|#######3  |127418/173481[36:11<12:33,61.13it/s] 80%|#######9  |137979/173481[39:00<09:33,61.95it/s] 80%|#######9  |138708/173481[39:11<09:21,61.95it/s] 86%|########6 |149220/173481[42:00<06:30,62.20it/s] 86%|########6 |149984/173481[42:12<06:17,62.20it/s] 92%|#########2|160118/173481[45:00<03:37,61.36it/s] 93%|#########2|160818/173481[45:12<03:26,61.36it/s] 98%|#########8|170759/173481[48:00<00:45,60.21it/s] 99%|#########8|171471/173481[48:12<00:33,60.21it/s]100%|##########|173481/173481[48:47<00:00,59.26it/s]
[32m[0325 01:15:57 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:2927.47 sec.
[32m[0325 01:15:58 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-8327088.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:21<00:00,133.13it/s]
47
[32m[0325 01:18:19 @monitor.py:363][0m QueueInput/queue_size: 3.8847
[32m[0325 01:18:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.844
[32m[0325 01:18:19 @monitor.py:363][0m activation-summaries/output-rms: 0.037146
[32m[0325 01:18:19 @monitor.py:363][0m cross_entropy_loss: 1.8611
[32m[0325 01:18:19 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 01:18:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 01:18:19 @monitor.py:363][0m train-error-top1: 0.49756
[32m[0325 01:18:19 @monitor.py:363][0m val-error-top1: 0.51991
[32m[0325 01:18:19 @monitor.py:363][0m val-utt-error: 0.17251
[32m[0325 01:18:19 @monitor.py:363][0m validation_cost: 1.9915
[32m[0325 01:18:19 @monitor.py:363][0m wd_cost: 2.6446e-11
[32m[0325 01:18:19 @group.py:42][0m Callbacks took 141.793 sec in total. InferenceRunner: 141.408sec
[32m[0325 01:18:19 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10537/173481[03:00<46:23,58.53it/s]  6%|6         |11093/173481[03:10<46:14,58.53it/s] 12%|#1        |20430/173481[06:00<44:59,56.69it/s] 12%|#2        |20944/173481[06:10<44:50,56.69it/s] 18%|#7        |30637/173481[09:00<41:59,56.70it/s] 18%|#8        |31252/173481[09:10<41:48,56.70it/s] 24%|##4       |41648/173481[12:00<37:20,58.85it/s] 24%|##4       |42327/173481[12:10<37:08,58.85it/s] 31%|###       |53045/173481[15:00<32:54,61.00it/s] 31%|###       |53707/173481[15:10<32:43,61.00it/s] 36%|###6      |63179/173481[18:00<31:23,58.55it/s] 37%|###6      |63822/173481[18:10<31:12,58.55it/s] 42%|####2     |73525/173481[21:00<28:43,58.01it/s] 43%|####2     |74112/173481[21:11<28:32,58.01it/s] 48%|####8     |83880/173481[24:00<25:51,57.77it/s] 49%|####8     |84514/173481[24:11<25:40,57.77it/s] 54%|#####4    |94232/173481[27:00<22:54,57.64it/s] 55%|#####4    |94925/173481[27:11<22:42,57.64it/s] 60%|######    |104767/173481[30:00<19:43,58.08it/s] 61%|######    |105467/173481[30:11<19:31,58.08it/s] 66%|######6   |115284/173481[33:00<16:39,58.25it/s] 67%|######6   |115870/173481[33:11<16:29,58.25it/s] 72%|#######2  |125613/173481[36:00<13:48,57.81it/s] 73%|#######2  |126278/173481[36:11<13:36,57.81it/s] 78%|#######8  |135972/173481[39:00<10:50,57.68it/s] 79%|#######8  |136662/173481[39:12<10:38,57.68it/s] 84%|########4 |146507/173481[42:00<07:44,58.10it/s] 85%|########4 |147240/173481[42:12<07:31,58.10it/s] 90%|######### |156858/173481[45:00<04:47,57.80it/s] 91%|######### |157620/173481[45:12<04:34,57.80it/s] 96%|#########6|167148/173481[48:00<01:50,57.48it/s] 97%|#########6|167832/173481[48:12<01:38,57.48it/s][32m[0325 02:08:17 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:2997.85 sec.
100%|##########|173481/173481[49:57<00:00,57.87it/s]
[32m[0325 02:08:17 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-8500569.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:11<00:00,142.81it/s]
48
[32m[0325 02:10:29 @monitor.py:363][0m QueueInput/queue_size: 0.41695
[32m[0325 02:10:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.054
[32m[0325 02:10:29 @monitor.py:363][0m activation-summaries/output-rms: 0.036768
[32m[0325 02:10:29 @monitor.py:363][0m cross_entropy_loss: 1.8613
[32m[0325 02:10:29 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 02:10:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 02:10:29 @monitor.py:363][0m train-error-top1: 0.4881
[32m[0325 02:10:29 @monitor.py:363][0m val-error-top1: 0.51263
[32m[0325 02:10:29 @monitor.py:363][0m val-utt-error: 0.16274
[32m[0325 02:10:29 @monitor.py:363][0m validation_cost: 1.9599
[32m[0325 02:10:29 @monitor.py:363][0m wd_cost: 2.6446e-11
[32m[0325 02:10:29 @group.py:42][0m Callbacks took 132.018 sec in total. InferenceRunner: 131.805sec
[32m[0325 02:10:29 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10147/173481[03:00<48:17,56.37it/s]  6%|6         |10736/173481[03:10<48:07,56.37it/s] 12%|#1        |20420/173481[06:00<44:58,56.72it/s] 12%|#2        |21016/173481[06:10<44:48,56.72it/s] 17%|#7        |30159/173481[09:00<43:08,55.38it/s] 18%|#7        |30746/173481[09:10<42:57,55.38it/s] 23%|##3       |40358/173481[12:00<39:36,56.01it/s] 24%|##3       |40967/173481[12:10<39:25,56.01it/s] 29%|##9       |50802/173481[15:00<35:52,57.00it/s] 30%|##9       |51441/173481[15:10<35:41,57.00it/s] 35%|###5      |60961/173481[18:00<33:03,56.72it/s] 35%|###5      |61580/173481[18:11<32:53,56.72it/s] 41%|####      |71081/173481[21:00<30:13,56.47it/s] 41%|####1     |71711/173481[21:11<30:02,56.47it/s] 47%|####6     |81135/173481[24:00<27:24,56.16it/s] 47%|####7     |81806/173481[24:11<27:12,56.16it/s] 53%|#####2    |91252/173481[27:00<24:23,56.18it/s] 53%|#####2    |91883/173481[27:11<24:12,56.18it/s] 58%|#####8    |101137/173481[30:00<21:42,55.54it/s] 59%|#####8    |101761/173481[30:11<21:31,55.54it/s] 64%|######4   |111038/173481[33:00<18:49,55.27it/s] 64%|######4   |111687/173481[33:11<18:38,55.27it/s] 70%|######9   |121386/173481[36:00<15:24,56.36it/s] 70%|#######   |122093/173481[36:12<15:11,56.36it/s] 76%|#######5  |131672/173481[39:00<12:16,56.74it/s] 76%|#######6  |132378/173481[39:12<12:04,56.74it/s] 82%|########2 |142452/173481[42:00<08:52,58.27it/s] 83%|########2 |143170/173481[42:12<08:40,58.27it/s] 89%|########8 |153901/173481[45:00<05:21,60.82it/s] 89%|########9 |154701/173481[45:12<05:08,60.82it/s] 95%|#########4|164802/173481[48:00<02:23,60.69it/s] 95%|#########5|165484/173481[48:12<02:11,60.69it/s]100%|##########|173481/173481[50:32<00:00,57.20it/s]
[32m[0325 03:01:02 @base.py:257][0m Epoch 51 (global_step 8674050) finished, time:3032.70 sec.
[32m[0325 03:01:02 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-8674050.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:39<00:00,117.97it/s]
49
[32m[0325 03:03:42 @monitor.py:363][0m QueueInput/queue_size: 0.69787
[32m[0325 03:03:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.957
[32m[0325 03:03:42 @monitor.py:363][0m activation-summaries/output-rms: 0.038201
[32m[0325 03:03:42 @monitor.py:363][0m cross_entropy_loss: 1.8128
[32m[0325 03:03:42 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 03:03:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 03:03:42 @monitor.py:363][0m train-error-top1: 0.48318
[32m[0325 03:03:42 @monitor.py:363][0m val-error-top1: 0.51413
[32m[0325 03:03:42 @monitor.py:363][0m val-utt-error: 0.16932
[32m[0325 03:03:42 @monitor.py:363][0m validation_cost: 1.9734
[32m[0325 03:03:42 @monitor.py:363][0m wd_cost: 5.2892e-12
[32m[0325 03:03:42 @group.py:42][0m Callbacks took 159.833 sec in total. InferenceRunner: 159.577sec
[32m[0325 03:03:42 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13105/173481[03:00<36:42,72.80it/s]  8%|7         |13786/173481[03:10<36:33,72.80it/s] 15%|#5        |26293/173481[06:00<33:35,73.03it/s] 16%|#5        |26925/173481[06:10<33:26,73.03it/s] 21%|##1       |37035/173481[09:00<34:37,65.68it/s] 22%|##1       |37665/173481[09:10<34:27,65.68it/s] 28%|##7       |47825/173481[12:00<33:24,62.68it/s] 28%|##7       |48474/173481[12:10<33:14,62.68it/s] 34%|###3      |58689/173481[15:00<31:06,61.50it/s] 34%|###4      |59396/173481[15:10<30:55,61.50it/s] 40%|####      |69913/173481[18:00<27:52,61.92it/s] 41%|####      |70565/173481[18:11<27:42,61.92it/s] 46%|####6     |80411/173481[21:00<25:49,60.06it/s] 47%|####6     |81042/173481[21:11<25:39,60.06it/s] 52%|#####2    |90922/173481[24:00<23:14,59.21it/s] 53%|#####2    |91606/173481[24:11<23:02,59.21it/s] 59%|#####8    |101581/173481[27:00<20:14,59.21it/s] 59%|#####8    |102245/173481[27:11<20:03,59.21it/s] 65%|######4   |112191/173481[30:00<17:17,59.07it/s] 65%|######5   |112869/173481[30:11<17:06,59.07it/s] 71%|#######   |122607/173481[33:00<14:30,58.46it/s] 71%|#######1  |123258/173481[33:11<14:19,58.46it/s] 77%|#######6  |133197/173481[36:00<11:26,58.65it/s] 77%|#######7  |133946/173481[36:12<11:14,58.65it/s] 83%|########3 |144098/173481[39:00<08:13,59.59it/s] 83%|########3 |144798/173481[39:12<08:01,59.59it/s] 89%|########9 |154482/173481[42:00<05:24,58.62it/s] 89%|########9 |155188/173481[42:12<05:12,58.62it/s] 95%|#########5|164866/173481[45:00<02:28,58.14it/s] 95%|#########5|165589/173481[45:12<02:15,58.14it/s]100%|##########|173481/173481[47:26<00:00,60.95it/s]
[32m[0325 03:51:08 @base.py:257][0m Epoch 52 (global_step 8847531) finished, time:2846.37 sec.
[32m[0325 03:51:08 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-8847531.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,109.10it/s]
50
[32m[0325 03:54:01 @monitor.py:363][0m QueueInput/queue_size: 0.32659
[32m[0325 03:54:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.931
[32m[0325 03:54:01 @monitor.py:363][0m activation-summaries/output-rms: 0.036118
[32m[0325 03:54:01 @monitor.py:363][0m cross_entropy_loss: 1.8301
[32m[0325 03:54:01 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 03:54:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 03:54:01 @monitor.py:363][0m train-error-top1: 0.47481
[32m[0325 03:54:01 @monitor.py:363][0m val-error-top1: 0.51084
[32m[0325 03:54:01 @monitor.py:363][0m val-utt-error: 0.16364
[32m[0325 03:54:01 @monitor.py:363][0m validation_cost: 1.9526
[32m[0325 03:54:01 @monitor.py:363][0m wd_cost: 5.2892e-12
[32m[0325 03:54:01 @group.py:42][0m Callbacks took 172.835 sec in total. InferenceRunner: 172.532sec
[32m[0325 03:54:01 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12985/173481[03:00<37:04,72.14it/s]  8%|7         |13689/173481[03:10<36:55,72.14it/s] 15%|#4        |25714/173481[06:00<34:29,71.42it/s] 15%|#5        |26308/173481[06:10<34:20,71.42it/s] 21%|##        |35800/173481[09:00<36:32,62.79it/s] 21%|##        |36380/173481[09:10<36:23,62.79it/s] 26%|##6       |45669/173481[12:00<36:23,58.54it/s] 27%|##6       |46286/173481[12:10<36:12,58.54it/s] 32%|###2      |55887/173481[15:00<34:00,57.64it/s] 33%|###2      |56535/173481[15:10<33:49,57.64it/s] 38%|###8      |65973/173481[18:00<31:32,56.82it/s] 38%|###8      |66624/173481[18:11<31:20,56.82it/s] 44%|####4     |76619/173481[21:00<27:51,57.96it/s] 45%|####4     |77290/173481[21:11<27:39,57.96it/s] 50%|#####     |87109/173481[24:00<24:46,58.11it/s] 51%|#####     |87786/173481[24:11<24:34,58.11it/s] 56%|#####6    |97885/173481[27:00<21:21,58.97it/s] 57%|#####6    |98550/173481[27:11<21:10,58.97it/s] 63%|######2   |108535/173481[30:00<18:19,59.06it/s] 63%|######2   |109194/173481[30:11<18:08,59.06it/s] 69%|######8   |119136/173481[33:00<15:21,58.98it/s] 69%|######9   |119830/173481[33:11<15:09,58.98it/s] 75%|#######4  |129530/173481[36:00<12:33,58.35it/s] 75%|#######5  |130199/173481[36:12<12:21,58.35it/s] 81%|########  |140026/173481[39:00<09:33,58.33it/s] 81%|########1 |140729/173481[39:12<09:21,58.33it/s] 87%|########6 |150755/173481[42:00<06:25,58.96it/s] 87%|########7 |151515/173481[42:12<06:12,58.96it/s] 93%|#########3|161594/173481[45:00<03:19,59.58it/s] 94%|#########3|162265/173481[45:12<03:08,59.58it/s] 99%|#########9|172130/173481[48:00<00:22,59.05it/s]100%|#########9|172796/173481[48:12<00:11,59.05it/s]100%|##########|173481/173481[48:24<00:00,59.72it/s]
[32m[0325 04:42:26 @base.py:257][0m Epoch 53 (global_step 9021012) finished, time:2904.99 sec.
[32m[0325 04:42:26 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-9021012.
[32m[0325 04:42:26 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:54<00:00,108.10it/s]
51
[32m[0325 04:45:20 @monitor.py:363][0m QueueInput/queue_size: 1.0053
[32m[0325 04:45:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.169
[32m[0325 04:45:20 @monitor.py:363][0m activation-summaries/output-rms: 0.037368
[32m[0325 04:45:20 @monitor.py:363][0m cross_entropy_loss: 1.8639
[32m[0325 04:45:20 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 04:45:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 04:45:20 @monitor.py:363][0m train-error-top1: 0.49158
[32m[0325 04:45:20 @monitor.py:363][0m val-error-top1: 0.5187
[32m[0325 04:45:20 @monitor.py:363][0m val-utt-error: 0.17655
[32m[0325 04:45:20 @monitor.py:363][0m validation_cost: 1.9976
[32m[0325 04:45:20 @monitor.py:363][0m wd_cost: 5.2892e-12
[32m[0325 04:45:20 @group.py:42][0m Callbacks took 174.642 sec in total. InferenceRunner: 174.147sec
[32m[0325 04:45:20 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12436/173481[03:00<38:51,69.08it/s]  8%|7         |13174/173481[03:10<38:40,69.08it/s] 15%|#4        |25509/173481[06:00<34:49,70.81it/s] 15%|#5        |26282/173481[06:10<34:38,70.81it/s] 21%|##1       |36703/173481[09:00<34:25,66.22it/s] 21%|##1       |37288/173481[09:10<34:16,66.22it/s] 27%|##6       |46801/173481[12:00<34:45,60.74it/s] 27%|##7       |47425/173481[12:10<34:35,60.74it/s] 33%|###2      |57160/173481[15:00<32:48,59.10it/s] 33%|###3      |57810/173481[15:11<32:37,59.10it/s] 39%|###9      |68285/173481[18:00<29:01,60.42it/s] 40%|###9      |69034/173481[18:11<28:48,60.42it/s] 46%|####5     |79284/173481[21:00<25:50,60.76it/s] 46%|####6     |79987/173481[21:11<25:38,60.76it/s] 52%|#####2    |90711/173481[24:00<22:13,62.09it/s] 53%|#####2    |91427/173481[24:11<22:01,62.09it/s] 59%|#####8    |101500/173481[27:00<19:40,61.00it/s] 59%|#####8    |102181/173481[27:11<19:28,61.00it/s] 65%|######5   |113250/173481[30:00<15:55,63.06it/s] 66%|######5   |114008/173481[30:12<15:43,63.06it/s] 72%|#######1  |124483/173481[33:00<13:01,62.73it/s] 72%|#######2  |125379/173481[33:12<12:46,62.73it/s] 78%|#######8  |135628/173481[36:00<10:07,62.32it/s] 79%|#######8  |136281/173481[36:12<09:56,62.32it/s] 84%|########4 |146176/173481[39:00<07:32,60.40it/s] 85%|########4 |146798/173481[39:12<07:21,60.40it/s] 91%|######### |157578/173481[42:00<04:17,61.84it/s] 91%|#########1|158515/173481[42:12<04:02,61.84it/s] 98%|#########7|169474/173481[45:00<01:02,63.89it/s] 98%|#########8|170134/173481[45:12<00:52,63.89it/s][32m[0325 05:31:36 @base.py:257][0m Epoch 54 (global_step 9194493) finished, time:2775.42 sec.
100%|##########|173481/173481[46:15<00:00,62.51it/s]
[32m[0325 05:31:36 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-9194493.
  0%|          |0/18822[00:00<?,?it/s] 99%|#########9|18652/18822[03:00<00:01,103.62it/s]100%|##########|18822/18822[03:01<00:00,103.75it/s]
52
[32m[0325 05:34:38 @monitor.py:363][0m QueueInput/queue_size: 49.745
[32m[0325 05:34:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.897
[32m[0325 05:34:38 @monitor.py:363][0m activation-summaries/output-rms: 0.037591
[32m[0325 05:34:38 @monitor.py:363][0m cross_entropy_loss: 1.7958
[32m[0325 05:34:38 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 05:34:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 05:34:38 @monitor.py:363][0m train-error-top1: 0.47338
[32m[0325 05:34:38 @monitor.py:363][0m val-error-top1: 0.51587
[32m[0325 05:34:38 @monitor.py:363][0m val-utt-error: 0.17203
[32m[0325 05:34:38 @monitor.py:363][0m validation_cost: 1.9834
[32m[0325 05:34:38 @monitor.py:363][0m wd_cost: 1.0578e-12
[32m[0325 05:34:38 @group.py:42][0m Callbacks took 181.818 sec in total. InferenceRunner: 181.417sec
[32m[0325 05:34:38 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14502/173481[03:00<32:53,80.56it/s]  9%|8         |15107/173481[03:10<32:45,80.56it/s] 16%|#5        |27536/173481[06:00<31:53,76.27it/s] 16%|#6        |28228/173481[06:10<31:44,76.27it/s] 22%|##2       |38168/173481[09:00<33:52,66.57it/s] 22%|##2       |38722/173481[09:10<33:44,66.57it/s] 27%|##7       |47163/173481[12:00<36:52,57.09it/s] 27%|##7       |47660/173481[12:10<36:44,57.09it/s] 34%|###3      |58686/173481[15:00<31:42,60.35it/s] 34%|###4      |59336/173481[15:10<31:31,60.35it/s] 41%|####      |70909/173481[18:00<26:45,63.90it/s] 41%|####1     |71639/173481[18:11<26:33,63.90it/s] 48%|####8     |83410/173481[21:00<22:33,66.56it/s] 48%|####8     |84117/173481[21:11<22:22,66.56it/s] 55%|#####5    |96148/173481[24:00<18:47,68.60it/s] 56%|#####5    |96979/173481[24:11<18:35,68.60it/s] 63%|######2   |108769/173481[27:00<15:33,69.35it/s] 63%|######3   |109522/173481[27:11<15:22,69.35it/s] 69%|######9   |120521/173481[30:00<13:07,67.26it/s] 70%|######9   |121397/173481[30:11<12:54,67.26it/s] 75%|#######5  |130374/173481[33:00<11:54,60.35it/s] 75%|#######5  |130945/173481[33:11<11:44,60.35it/s] 82%|########1 |141752/173481[36:00<08:33,61.75it/s] 82%|########2 |142370/173481[36:12<08:23,61.75it/s] 87%|########6 |150875/173481[39:00<06:46,55.67it/s] 87%|########7 |151514/173481[39:12<06:34,55.67it/s] 92%|#########2|160119/173481[42:00<04:10,53.42it/s] 93%|#########2|160783/173481[42:12<03:57,53.42it/s] 98%|#########7|169809/173481[45:00<01:08,53.62it/s] 98%|#########8|170540/173481[45:12<00:54,53.62it/s]100%|##########|173481/173481[46:06<00:00,62.71it/s]
[32m[0325 06:20:44 @base.py:257][0m Epoch 55 (global_step 9367974) finished, time:2766.50 sec.
[32m[0325 06:20:44 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-9367974.
  0%|          |0/18822[00:00<?,?it/s] 48%|####8     |9126/18822[03:00<03:11,50.69it/s] 51%|#####1    |9682/18822[03:10<03:00,50.69it/s]100%|##########|18822/18822[05:13<00:00,60.11it/s]
53
[32m[0325 06:25:57 @monitor.py:363][0m QueueInput/queue_size: 0.4191
[32m[0325 06:25:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.039
[32m[0325 06:25:57 @monitor.py:363][0m activation-summaries/output-rms: 0.036228
[32m[0325 06:25:57 @monitor.py:363][0m cross_entropy_loss: 1.8629
[32m[0325 06:25:57 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 06:25:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 06:25:57 @monitor.py:363][0m train-error-top1: 0.49044
[32m[0325 06:25:57 @monitor.py:363][0m val-error-top1: 0.5178
[32m[0325 06:25:57 @monitor.py:363][0m val-utt-error: 0.16954
[32m[0325 06:25:57 @monitor.py:363][0m validation_cost: 1.982
[32m[0325 06:25:58 @monitor.py:363][0m wd_cost: 1.0578e-12
[32m[0325 06:25:58 @group.py:42][0m Callbacks took 313.307 sec in total. InferenceRunner: 313.149sec
[32m[0325 06:25:58 @base.py:247][0m Start Epoch 56 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14127/173481[03:00<33:50,78.48it/s]  9%|8         |15012/173481[03:10<33:39,78.48it/s] 15%|#5        |26723/173481[06:00<33:03,73.99it/s] 16%|#5        |27321/173481[06:10<32:55,73.99it/s] 22%|##2       |38382/173481[09:00<32:35,69.07it/s] 22%|##2       |39023/173481[09:10<32:26,69.07it/s] 29%|##8       |49977/173481[12:00<30:52,66.66it/s] 29%|##9       |50696/173481[12:10<30:41,66.66it/s] 36%|###5      |62070/173481[15:00<27:44,66.92it/s] 36%|###6      |62568/173481[15:10<27:37,66.92it/s] 41%|####      |71114/173481[18:00<29:43,57.39it/s] 41%|####1     |71623/173481[18:11<29:34,57.39it/s] 47%|####7     |82020/173481[21:00<25:51,58.94it/s] 48%|####7     |82533/173481[21:11<25:42,58.94it/s] 52%|#####2    |90832/173481[24:00<25:45,53.48it/s] 53%|#####2    |91441/173481[24:11<25:34,53.48it/s] 57%|#####6    |98462/173481[27:00<26:26,47.29it/s] 57%|#####7    |99026/173481[27:11<26:14,47.29it/s] 62%|######1   |107293/173481[30:00<22:54,48.15it/s] 62%|######2   |107909/173481[30:11<22:41,48.15it/s] 67%|######7   |116690/173481[33:00<18:53,50.10it/s] 68%|######7   |117365/173481[33:12<18:40,50.10it/s] 73%|#######2  |126368/173481[36:00<15:08,51.87it/s] 73%|#######3  |127001/173481[36:12<14:56,51.87it/s] 78%|#######8  |135694/173481[39:00<12:09,51.83it/s] 79%|#######8  |136297/173481[39:12<11:57,51.83it/s] 84%|########3 |145212/173481[42:00<09:00,52.35it/s] 84%|########4 |145885/173481[42:12<08:47,52.35it/s] 89%|########9 |154962/173481[45:00<05:47,53.24it/s] 90%|########9 |155671/173481[45:12<05:34,53.24it/s] 94%|#########4|163812/173481[48:00<03:09,51.11it/s] 95%|#########4|164271/173481[48:12<03:00,51.11it/s] 99%|#########8|171624/173481[51:00<00:39,46.94it/s] 99%|#########9|172081/173481[51:13<00:29,46.94it/s][32m[0325 07:17:44 @base.py:257][0m Epoch 56 (global_step 9541455) finished, time:3106.83 sec.
100%|##########|173481/173481[51:46<00:00,55.84it/s]
[32m[0325 07:17:44 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-9541455.
  0%|          |0/18822[00:00<?,?it/s] 91%|######### |17040/18822[03:00<00:18,94.67it/s] 98%|#########7|18381/18822[03:10<00:04,94.67it/s]100%|##########|18822/18822[03:13<00:00,97.19it/s]
54
[32m[0325 07:20:58 @monitor.py:363][0m QueueInput/queue_size: 0.36022
[32m[0325 07:20:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.955
[32m[0325 07:20:58 @monitor.py:363][0m activation-summaries/output-rms: 0.038194
[32m[0325 07:20:58 @monitor.py:363][0m cross_entropy_loss: 1.8194
[32m[0325 07:20:58 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 07:20:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 07:20:58 @monitor.py:363][0m train-error-top1: 0.48262
[32m[0325 07:20:58 @monitor.py:363][0m val-error-top1: 0.51663
[32m[0325 07:20:58 @monitor.py:363][0m val-utt-error: 0.1706
[32m[0325 07:20:58 @monitor.py:363][0m validation_cost: 1.9911
[32m[0325 07:20:58 @monitor.py:363][0m wd_cost: 1.0578e-12
[32m[0325 07:20:58 @group.py:42][0m Callbacks took 193.883 sec in total. InferenceRunner: 193.696sec
[32m[0325 07:20:58 @base.py:247][0m Start Epoch 57 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9266/173481[03:00<53:10,51.46it/s]  6%|5         |9664/173481[03:10<53:03,51.46it/s] 11%|#         |18627/173481[06:00<49:53,51.73it/s] 11%|#1        |19185/173481[06:10<49:42,51.73it/s] 16%|#6        |28275/173481[09:00<45:58,52.65it/s] 17%|#6        |28773/173481[09:10<45:48,52.65it/s] 22%|##1       |37573/173481[12:00<43:26,52.15it/s] 22%|##1       |38135/173481[12:10<43:15,52.15it/s] 27%|##7       |47016/173481[15:00<40:18,52.30it/s] 27%|##7       |47590/173481[15:10<40:07,52.30it/s] 33%|###2      |56436/173481[18:00<37:17,52.31it/s] 33%|###2      |57022/173481[18:11<37:06,52.31it/s] 38%|###8      |66033/173481[21:00<33:54,52.81it/s] 38%|###8      |66670/173481[21:11<33:42,52.81it/s] 43%|####3     |75237/173481[24:00<31:30,51.96it/s] 44%|####3     |75852/173481[24:11<31:19,51.96it/s] 49%|####8     |84556/173481[27:00<28:34,51.86it/s] 49%|####9     |85169/173481[27:11<28:22,51.86it/s] 54%|#####4    |93851/173481[30:00<25:39,51.74it/s] 54%|#####4    |94425/173481[30:11<25:27,51.74it/s] 59%|#####9    |102753/173481[33:00<23:18,50.57it/s] 60%|#####9    |103395/173481[33:12<23:05,50.57it/s] 65%|######4   |112137/173481[36:00<19:54,51.34it/s] 65%|######5   |112790/173481[36:12<19:42,51.34it/s] 70%|#######   |121574/173481[39:00<16:40,51.88it/s] 70%|#######   |122188/173481[39:12<16:28,51.88it/s] 76%|#######5  |131158/173481[42:00<13:25,52.55it/s] 76%|#######5  |131795/173481[42:12<13:13,52.55it/s] 81%|########1 |140692/173481[45:00<10:21,52.76it/s] 81%|########1 |141346/173481[45:12<10:09,52.76it/s] 87%|########6 |150066/173481[48:00<07:26,52.41it/s] 87%|########6 |150711/173481[48:12<07:14,52.41it/s] 92%|#########1|159218/173481[51:00<04:36,51.61it/s] 92%|#########2|159897/173481[51:13<04:23,51.61it/s] 97%|#########7|168491/173481[54:00<01:36,51.55it/s] 98%|#########7|169160/173481[54:13<01:23,51.55it/s]100%|##########|173481/173481[55:36<00:00,52.00it/s]
[32m[0325 08:16:34 @base.py:257][0m Epoch 57 (global_step 9714936) finished, time:3336.22 sec.
[32m[0325 08:16:35 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-9714936.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:45<00:00,113.40it/s]
55
[32m[0325 08:19:21 @monitor.py:363][0m QueueInput/queue_size: 0.30621
[32m[0325 08:19:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.884
[32m[0325 08:19:21 @monitor.py:363][0m activation-summaries/output-rms: 0.036239
[32m[0325 08:19:21 @monitor.py:363][0m cross_entropy_loss: 1.8234
[32m[0325 08:19:21 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 08:19:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 08:19:21 @monitor.py:363][0m train-error-top1: 0.47153
[32m[0325 08:19:21 @monitor.py:363][0m val-error-top1: 0.51374
[32m[0325 08:19:21 @monitor.py:363][0m val-utt-error: 0.16481
[32m[0325 08:19:21 @monitor.py:363][0m validation_cost: 1.9644
[32m[0325 08:19:21 @monitor.py:363][0m wd_cost: 2.1157e-13
[32m[0325 08:19:21 @group.py:42][0m Callbacks took 166.191 sec in total. InferenceRunner: 165.994sec
[32m[0325 08:19:21 @base.py:247][0m Start Epoch 58 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9678/173481[03:00<50:46,53.77it/s]  6%|5         |10179/173481[03:10<50:37,53.77it/s] 11%|#1        |19088/173481[06:00<48:32,53.01it/s] 11%|#1        |19642/173481[06:10<48:22,53.01it/s] 16%|#6        |28445/173481[09:00<46:03,52.49it/s] 17%|#6        |29039/173481[09:10<45:51,52.49it/s] 22%|##1       |37400/173481[12:00<44:24,51.08it/s] 22%|##1       |37914/173481[12:10<44:14,51.08it/s] 27%|##6       |46370/173481[15:00<42:00,50.44it/s] 27%|##7       |46941/173481[15:10<41:48,50.44it/s] 32%|###2      |55661/173481[18:00<38:29,51.02it/s] 32%|###2      |56232/173481[18:11<38:18,51.02it/s] 37%|###7      |65055/173481[21:00<35:01,51.60it/s] 38%|###7      |65652/173481[21:11<34:49,51.60it/s] 43%|####3     |74685/173481[24:00<31:20,52.53it/s] 43%|####3     |75209/173481[24:11<31:10,52.53it/s] 48%|####8     |84081/173481[27:00<28:27,52.36it/s] 49%|####8     |84671/173481[27:11<28:16,52.36it/s] 54%|#####3    |93515/173481[30:00<25:26,52.39it/s] 54%|#####4    |94149/173481[30:11<25:14,52.39it/s] 59%|#####9    |102834/173481[33:00<22:36,52.07it/s] 60%|#####9    |103394/173481[33:11<22:25,52.07it/s] 64%|######4   |111785/173481[36:00<20:12,50.87it/s] 65%|######4   |112407/173481[36:12<20:00,50.87it/s] 70%|######9   |121085/173481[39:00<17:02,51.26it/s] 70%|#######   |121712/173481[39:12<16:49,51.26it/s] 75%|#######5  |130340/173481[42:00<14:00,51.32it/s] 75%|#######5  |130944/173481[42:12<13:48,51.32it/s] 81%|########  |139703/173481[45:00<10:53,51.67it/s] 81%|########  |140367/173481[45:12<10:40,51.67it/s] 86%|########6 |149210/173481[48:00<07:44,52.23it/s] 86%|########6 |149818/173481[48:12<07:33,52.23it/s] 91%|#########1|158550/173481[51:00<04:46,52.06it/s] 92%|#########1|159194/173481[51:12<04:34,52.06it/s] 97%|#########6|167715/173481[54:00<01:52,51.48it/s] 97%|#########7|168419/173481[54:13<01:38,51.48it/s]100%|##########|173481/173481[55:52<00:00,51.74it/s]
[32m[0325 09:15:14 @base.py:257][0m Epoch 58 (global_step 9888417) finished, time:3352.99 sec.
[32m[0325 09:15:14 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:46<00:00,113.35it/s]
56
[32m[0325 09:18:00 @monitor.py:363][0m QueueInput/queue_size: 0.34698
[32m[0325 09:18:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.147
[32m[0325 09:18:00 @monitor.py:363][0m activation-summaries/output-rms: 0.037368
[32m[0325 09:18:00 @monitor.py:363][0m cross_entropy_loss: 1.8648
[32m[0325 09:18:00 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 09:18:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 09:18:00 @monitor.py:363][0m train-error-top1: 0.4897
[32m[0325 09:18:00 @monitor.py:363][0m val-error-top1: 0.51675
[32m[0325 09:18:00 @monitor.py:363][0m val-utt-error: 0.16799
[32m[0325 09:18:00 @monitor.py:363][0m validation_cost: 1.9785
[32m[0325 09:18:00 @monitor.py:363][0m wd_cost: 2.1157e-13
[32m[0325 09:18:00 @group.py:42][0m Callbacks took 166.239 sec in total. InferenceRunner: 166.070sec
[32m[0325 09:18:00 @base.py:247][0m Start Epoch 59 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9941/173481[03:00<49:21,55.22it/s]  6%|6         |10437/173481[03:10<49:12,55.22it/s] 11%|#1        |19285/173481[06:00<48:01,53.51it/s] 11%|#1        |19875/173481[06:10<47:50,53.51it/s] 16%|#6        |28394/173481[09:00<46:29,52.02it/s] 17%|#6        |28932/173481[09:10<46:18,52.02it/s] 21%|##1       |37274/173481[12:00<44:50,50.63it/s] 22%|##1       |37783/173481[12:10<44:40,50.63it/s] 27%|##6       |46165/173481[15:00<42:26,50.00it/s] 27%|##6       |46683/173481[15:10<42:15,50.00it/s] 32%|###1      |54989/173481[18:00<39:53,49.51it/s] 32%|###1      |55491/173481[18:11<39:43,49.51it/s] 37%|###6      |63930/173481[21:00<36:49,49.59it/s] 37%|###7      |64514/173481[21:11<36:37,49.59it/s] 42%|####2     |73343/173481[24:00<32:47,50.90it/s] 43%|####2     |73976/173481[24:11<32:34,50.90it/s] 48%|####7     |83043/173481[27:00<28:47,52.35it/s] 48%|####8     |83665/173481[27:11<28:35,52.35it/s] 53%|#####3    |92565/173481[30:00<25:37,52.62it/s] 54%|#####3    |93201/173481[30:11<25:25,52.62it/s] 59%|#####8    |102013/173481[33:00<22:39,52.55it/s] 59%|#####9    |102675/173481[33:11<22:27,52.55it/s] 64%|######4   |111585/173481[36:00<19:30,52.86it/s] 65%|######4   |112225/173481[36:12<19:18,52.86it/s] 70%|######9   |120915/173481[39:00<16:44,52.34it/s] 70%|#######   |121539/173481[39:12<16:32,52.34it/s] 75%|#######5  |130324/173481[42:00<13:45,52.30it/s] 75%|#######5  |130944/173481[42:12<13:33,52.30it/s] 81%|########  |140087/173481[45:00<10:27,53.25it/s] 81%|########1 |140796/173481[45:12<10:13,53.25it/s] 86%|########6 |150012/173481[48:00<07:13,54.18it/s] 87%|########6 |150708/173481[48:12<07:00,54.18it/s] 92%|#########2|159854/173481[51:00<04:10,54.42it/s] 93%|#########2|160518/173481[51:13<03:58,54.42it/s] 98%|#########7|169829/173481[54:00<01:06,54.91it/s] 98%|#########8|170511/173481[54:13<00:54,54.91it/s]100%|##########|173481/173481[55:06<00:00,52.46it/s]
[32m[0325 10:13:07 @base.py:257][0m Epoch 59 (global_step 10061898) finished, time:3306.72 sec.
[32m[0325 10:13:07 @saver.py:84][0m Model saved to train_log/fcn1_w_2_a_32_quant_ends_False/model-10061898.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,109.31it/s]
57
[32m[0325 10:15:59 @monitor.py:363][0m QueueInput/queue_size: 1.0665
[32m[0325 10:15:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 35.88
[32m[0325 10:15:59 @monitor.py:363][0m activation-summaries/output-rms: 0.037266
[32m[0325 10:15:59 @monitor.py:363][0m cross_entropy_loss: 1.866
[32m[0325 10:15:59 @monitor.py:363][0m lr: 4.7684e-10
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63272
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1684
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3229
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.091786
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.95268
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091827
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.78723
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.092133
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.86332
[32m[0325 10:15:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088849
[32m[0325 10:15:59 @monitor.py:363][0m train-error-top1: 0.50151
[32m[0325 10:15:59 @monitor.py:363][0m val-error-top1: 0.51596
[32m[0325 10:15:59 @monitor.py:363][0m val-utt-error: 0.16725
[32m[0325 10:15:59 @monitor.py:363][0m validation_cost: 1.9804
[32m[0325 10:15:59 @monitor.py:363][0m wd_cost: 2.1157e-13
[32m[0325 10:15:59 @group.py:42][0m Callbacks took 172.354 sec in total. InferenceRunner: 172.202sec
[32m[0325 10:15:59 @base.py:247][0m Start Epoch 60 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10252/173481[03:00<47:46,56.95it/s]  6%|6         |10813/173481[03:10<47:36,56.95it/s] 11%|#1        |19649/173481[06:00<47:04,54.47it/s] 12%|#1        |20172/173481[06:10<46:54,54.47it/s] 17%|#6        |29248/173481[09:00<44:36,53.89it/s] 17%|#7        |29796/173481[09:10<44:26,53.89it/s] 23%|##2       |39104/173481[12:00<41:13,54.32it/s] 23%|##2       |39707/173481[12:10<41:02,54.32it/s] 28%|##8       |49250/173481[15:00<37:25,55.32it/s] 29%|##8       |49878/173481[15:10<37:14,55.32it/s] 34%|###4      |59168/173481[18:00<34:30,55.21it/s] 34%|###4      |59775/173481[18:11<34:19,55.21it/s] 40%|###9      |69152/173481[21:00<31:25,55.33it/s] 40%|####      |69772/173481[21:11<31:14,55.33it/s] 46%|####5     |79228/173481[24:00<28:13,55.65it/s] 46%|####5     |79744/173481[24:11<28:04,55.65it/s] 51%|#####1    |88963/173481[27:00<25:40,54.85it/s] 52%|#####1    |89547/173481[27:11<25:30,54.85it/s] 57%|#####7    |99008/173481[30:00<22:26,55.32it/s] 57%|#####7    |99663/173481[30:11<22:14,55.32it/s] 63%|######2   |109240/173481[33:00<19:05,56.07it/s] 63%|######3   |109872/173481[33:12<18:54,56.07it/s] 69%|######8   |119445/173481[36:00<15:58,56.38it/s] 69%|######9   |120102/173481[36:12<15:46,56.38it/s] 75%|#######4  |129286/173481[39:00<13:16,55.51it/s] 75%|#######4  |130007/173481[39:12<13:03,55.51it/s]slurmstepd: *** STEP 82593.0 ON sls-titan-10 CANCELLED AT 2018-03-25T10:57:36 DUE TO TIME LIMIT ***
srun: error: sls-titan-10: task 0: Terminated
srun: Force Terminated job step 82593.0
