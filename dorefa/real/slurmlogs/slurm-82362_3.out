sls-titan-10 1
SLURM_JOBID=82365
SLURM_TASKID=3
[32m[0322 10:59:18 @logger.py:74][0m Argv: drf_run.py --model_name=cnn --bitw=8 --bita=8 --quant_ends=True --load_ckpt=train_log/cnn_w_8_a_32_quant_ends_True_preload/checkpoint
[32m[0322 10:59:24 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0322 10:59:24 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0322 10:59:24 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0322 10:59:24 @drf_run.py:166][0m Using host: sls-titan-10
[32m[0322 10:59:24 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0322 10:59:24 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0322 10:59:25 @drf_run.py:188][0m Using GPU: 1
[32m[0322 10:59:25 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0322 10:59:25 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0322 10:59:25 @training.py:108][0m Building graph for training tower 0 ...
[32m[0322 10:59:25 @registry.py:122][0m conv0 input: [None, 50, 20, 1]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight conv0/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight conv0/b
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing conv0/bn/beta
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing conv0/bn/gamma
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing conv0/bn/mean/EMA
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing conv0/bn/variance/EMA
[32m[0322 10:59:25 @registry.py:130][0m conv0 output: [None, 10, 4, 6]
[32m[0322 10:59:25 @registry.py:122][0m linear0 input: [None, 10, 4, 6]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 10:59:25 @registry.py:130][0m linear0 output: [None, 256]
[32m[0322 10:59:25 @registry.py:122][0m linear1 input: [None, 256]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 10:59:25 @registry.py:130][0m linear1 output: [None, 256]
[32m[0322 10:59:25 @registry.py:122][0m linear2 input: [None, 256]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 10:59:25 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 10:59:25 @registry.py:130][0m linear2 output: [None, 256]
[32m[0322 10:59:25 @registry.py:122][0m last_linear input: [None, 256]
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 10:59:25 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 10:59:25 @registry.py:130][0m last_linear output: [None, 255]
[32m[0322 10:59:25 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 10:59:25 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0322 10:59:25 @regularize.py:18][0m Applying regularizer for conv0/W:0, linear0/W:0, linear1/W:0, linear2/W:0, last_linear/W:0
[32m[0322 10:59:25 @drf_run.py:123][0m Parameter count: {'mults': 265808, 'weights': 259979}
[32m[0322 10:59:26 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  ------------  -----
conv0/W:0           [5, 5, 1, 6]    150
conv0/b:0           [6]               6
conv0/bn/beta:0     [6]               6
conv0/bn/gamma:0    [6]               6
linear0/W:0         [240, 256]    61440
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=260519, size=0.99MB[0m
[32m[0322 10:59:26 @base.py:196][0m Setup callbacks graph ...
[32m[0322 10:59:26 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight conv0/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight conv0/b
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing conv0/bn/beta
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing conv0/bn/gamma
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing conv0/bn/mean/EMA
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing conv0/bn/variance/EMA
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 10:59:26 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 10:59:26 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 10:59:26 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 10:59:26 @drf_run.py:123][0m Parameter count: {'mults': 531616, 'weights': 519958}
[32m[0322 10:59:26 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0322 10:59:26 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0322 10:59:27 @base.py:212][0m Creating the session ...
2018-03-22 10:59:27.498392: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-22 10:59:30.250222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:03:00.0
totalMemory: 11.92GiB freeMemory: 11.81GiB
2018-03-22 10:59:30.250262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
[32m[0322 10:59:34 @base.py:220][0m Initializing the session ...
[32m[0322 10:59:34 @sessinit.py:116][0m Restoring checkpoint from train_log/cnn_w_8_a_32_quant_ends_True_preload/model-5030949 ...
[32m[0322 10:59:34 @base.py:227][0m Graph Finalized.
[32m[0322 10:59:34 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0322 10:59:34 @steps.py:127][0m Start training with global_step=5030949
[32m[0322 10:59:40 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10171/173481[03:00<48:10,56.49it/s]  6%|6         |10770/173481[03:10<48:00,56.49it/s] 12%|#2        |21100/173481[06:00<43:23,58.53it/s] 13%|#2        |21712/173481[06:10<43:13,58.53it/s] 18%|#8        |31551/173481[09:00<40:35,58.28it/s] 18%|#8        |32045/173481[09:10<40:26,58.28it/s] 23%|##3       |40531/173481[12:00<41:13,53.76it/s] 24%|##3       |41049/173481[12:10<41:03,53.76it/s] 29%|##8       |50036/173481[15:00<38:37,53.27it/s] 29%|##9       |50610/173481[15:10<38:26,53.27it/s] 35%|###4      |59911/173481[18:00<35:01,54.05it/s] 35%|###4      |60505/173481[18:11<34:50,54.05it/s] 40%|####      |69811/173481[21:00<31:41,54.52it/s] 41%|####      |70415/173481[21:11<31:30,54.52it/s] 46%|####5     |79631/173481[24:00<28:40,54.54it/s] 46%|####6     |80290/173481[24:11<28:28,54.54it/s] 52%|#####1    |89508/173481[27:00<25:35,54.70it/s] 52%|#####1    |90120/173481[27:11<25:23,54.70it/s] 57%|#####6    |98385/173481[30:00<24:07,51.87it/s] 57%|#####7    |98925/173481[30:11<23:57,51.87it/s] 62%|######1   |107191/173481[33:00<21:56,50.35it/s] 62%|######2   |107799/173481[33:11<21:44,50.35it/s] 67%|######7   |116408/173481[36:00<18:44,50.77it/s] 67%|######7   |117010/173481[36:11<18:32,50.77it/s] 73%|#######2  |125860/173481[39:00<15:22,51.63it/s] 73%|#######2  |126496/173481[39:12<15:10,51.63it/s] 78%|#######8  |135329/173481[42:00<12:12,52.11it/s] 78%|#######8  |135952/173481[42:12<12:00,52.11it/s] 83%|########3 |144596/173481[45:00<09:17,51.78it/s] 84%|########3 |145200/173481[45:12<09:06,51.78it/s] 88%|########8 |153153/173481[48:00<06:50,49.57it/s] 89%|########8 |153711/173481[48:12<06:38,49.57it/s] 93%|#########2|161191/173481[51:00<04:21,46.97it/s] 93%|#########3|161775/173481[51:12<04:09,46.97it/s] 98%|#########7|169531/173481[54:00<01:24,46.65it/s] 98%|#########8|170131/173481[54:13<01:11,46.65it/s]100%|##########|173481/173481[55:19<00:00,52.26it/s]
[32m[0322 11:54:59 @base.py:257][0m Epoch 1 (global_step 5204430) finished, time:3319.40 sec.
[32m[0322 11:54:59 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-5204430.
  0%|          |0/18822[00:00<?,?it/s] 78%|#######8  |14758/18822[03:00<00:49,81.98it/s] 82%|########2 |15483/18822[03:10<00:40,81.98it/s]100%|##########|18822/18822[03:55<00:00,79.99it/s]
0
[32m[0322 11:58:55 @monitor.py:363][0m QueueInput/queue_size: 1.1742
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 30.787
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/output-rms: 0.007785
[32m[0322 11:58:55 @monitor.py:363][0m cross_entropy_loss: 5.7424
[32m[0322 11:58:55 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67524
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087606
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61933
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4126
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3418
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30023
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29477
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 11:58:55 @monitor.py:363][0m train-error-top1: 0.98876
[32m[0322 11:58:55 @monitor.py:363][0m val-error-top1: 0.98745
[32m[0322 11:58:55 @monitor.py:363][0m val-utt-error: 0.97997
[32m[0322 11:58:55 @monitor.py:363][0m validation_cost: 5.7987
[32m[0322 11:58:55 @monitor.py:363][0m wd_cost: 4.4941e-07
[32m[0322 11:58:55 @group.py:42][0m Callbacks took 235.524 sec in total. InferenceRunner: 235.315sec
[32m[0322 11:58:55 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8900/173481[03:00<55:28,49.44it/s]  5%|5         |9399/173481[03:10<55:18,49.44it/s] 10%|#         |18123/173481[06:00<51:27,50.32it/s] 11%|#         |18659/173481[06:10<51:16,50.32it/s] 16%|#5        |27455/173481[09:00<47:39,51.07it/s] 16%|#6        |28004/173481[09:10<47:28,51.07it/s] 21%|##        |36307/173481[12:00<45:37,50.11it/s] 21%|##1       |36814/173481[12:10<45:27,50.11it/s] 26%|##5       |44645/173481[15:00<44:36,48.13it/s] 26%|##6       |45152/173481[15:10<44:26,48.13it/s] 31%|###       |53200/173481[18:00<41:55,47.82it/s] 31%|###       |53719/173481[18:10<41:44,47.82it/s] 36%|###5      |62208/173481[21:00<37:55,48.91it/s] 36%|###6      |62794/173481[21:11<37:43,48.91it/s] 41%|####      |70508/173481[24:00<36:09,47.47it/s] 41%|####      |71060/173481[24:11<35:57,47.47it/s] 46%|####6     |79977/173481[27:00<31:13,49.90it/s] 46%|####6     |80592/173481[27:11<31:01,49.90it/s] 51%|#####1    |89315/173481[30:00<27:34,50.86it/s] 52%|#####1    |89904/173481[30:11<27:23,50.86it/s] 57%|#####7    |99125/173481[33:00<23:33,52.61it/s] 57%|#####7    |99705/173481[33:11<23:22,52.61it/s] 63%|######2   |108575/173481[36:00<20:35,52.55it/s] 63%|######2   |109164/173481[36:11<20:24,52.55it/s] 68%|######7   |117194/173481[39:00<18:43,50.11it/s] 68%|######7   |117749/173481[39:12<18:32,50.11it/s] 73%|#######2  |126310/173481[42:00<15:36,50.37it/s] 73%|#######3  |126912/173481[42:12<15:24,50.37it/s] 78%|#######8  |135395/173481[45:00<12:35,50.42it/s] 78%|#######8  |136089/173481[45:12<12:21,50.42it/s] 84%|########3 |144930/173481[48:00<09:12,51.66it/s] 84%|########3 |145520/173481[48:12<09:01,51.66it/s] 89%|########8 |153690/173481[51:00<06:34,50.11it/s] 89%|########8 |154259/173481[51:12<06:23,50.11it/s] 94%|#########3|162858/173481[54:00<03:30,50.52it/s] 94%|#########4|163494/173481[54:12<03:17,50.52it/s]100%|#########9|172640/173481[57:00<00:16,52.36it/s]100%|#########9|173444/173481[57:13<00:00,52.36it/s]100%|##########|173481/173481[57:13<00:00,50.52it/s]
[32m[0322 12:56:09 @base.py:257][0m Epoch 2 (global_step 5377911) finished, time:3433.89 sec.
[32m[0322 12:56:09 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-5377911.
[32m[0322 12:56:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:40<00:00,117.08it/s]
1
[32m[0322 12:58:50 @monitor.py:363][0m QueueInput/queue_size: 0.74047
[32m[0322 12:58:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.143
[32m[0322 12:58:50 @monitor.py:363][0m activation-summaries/output-rms: 0.0070349
[32m[0322 12:58:50 @monitor.py:363][0m cross_entropy_loss: 5.5547
[32m[0322 12:58:50 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67573
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087492
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61817
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4122
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34179
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30025
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29491
[32m[0322 12:58:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 12:58:50 @monitor.py:363][0m train-error-top1: 0.98928
[32m[0322 12:58:50 @monitor.py:363][0m val-error-top1: 0.9853
[32m[0322 12:58:50 @monitor.py:363][0m val-utt-error: 0.97944
[32m[0322 12:58:50 @monitor.py:363][0m validation_cost: 5.6083
[32m[0322 12:58:50 @monitor.py:363][0m wd_cost: 8.9701e-08
[32m[0322 12:58:50 @group.py:42][0m Callbacks took 161.022 sec in total. InferenceRunner: 160.770sec
[32m[0322 12:58:50 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12229/173481[03:00<39:34,67.92it/s]  7%|7         |12813/173481[03:10<39:25,67.92it/s] 13%|#2        |22374/173481[06:00<40:52,61.60it/s] 13%|#3        |22947/173481[06:10<40:43,61.60it/s] 18%|#7        |30935/173481[09:00<44:15,53.68it/s] 18%|#8        |31423/173481[09:10<44:06,53.68it/s] 23%|##3       |40114/173481[12:00<42:30,52.29it/s] 23%|##3       |40603/173481[12:10<42:21,52.29it/s] 28%|##8       |48839/173481[15:00<41:17,50.31it/s] 28%|##8       |49408/173481[15:10<41:06,50.31it/s] 34%|###3      |58304/173481[18:00<37:20,51.42it/s] 34%|###3      |58880/173481[18:10<37:08,51.42it/s] 39%|###8      |67619/173481[21:00<34:12,51.58it/s] 39%|###9      |68203/173481[21:11<34:01,51.58it/s] 45%|####4     |78041/173481[24:00<29:09,54.55it/s] 45%|####5     |78675/173481[24:11<28:57,54.55it/s] 51%|#####     |87954/173481[27:00<26:00,54.80it/s] 51%|#####1    |88563/173481[27:11<25:49,54.80it/s] 56%|#####6    |97454/173481[30:00<23:33,53.77it/s] 57%|#####6    |98043/173481[30:11<23:22,53.77it/s] 62%|######1   |106951/173481[33:00<20:49,53.26it/s] 62%|######2   |107603/173481[33:11<20:36,53.26it/s] 67%|######7   |116685/173481[36:00<17:38,53.66it/s] 68%|######7   |117338/173481[36:11<17:26,53.66it/s] 73%|#######2  |126429/173481[39:00<14:33,53.90it/s] 73%|#######3  |127093/173481[39:12<14:20,53.90it/s] 79%|#######8  |137022/173481[42:00<10:48,56.26it/s] 79%|#######9  |137698/173481[42:12<10:35,56.26it/s] 85%|########4 |147104/173481[45:00<07:49,56.13it/s] 85%|########5 |147806/173481[45:12<07:37,56.13it/s] 91%|######### |157293/173481[48:00<04:47,56.36it/s] 91%|#########1|157963/173481[48:12<04:35,56.36it/s] 96%|#########6|166909/173481[51:00<01:59,54.84it/s] 97%|#########6|167618/173481[51:12<01:46,54.84it/s]100%|##########|173481/173481[52:56<00:00,54.62it/s]
[32m[0322 13:51:46 @base.py:257][0m Epoch 3 (global_step 5551392) finished, time:3176.09 sec.
[32m[0322 13:51:46 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-5551392.
[32m[0322 13:51:46 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:50<00:00,110.13it/s]
2
[32m[0322 13:54:37 @monitor.py:363][0m QueueInput/queue_size: 0.55745
[32m[0322 13:54:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.168
[32m[0322 13:54:37 @monitor.py:363][0m activation-summaries/output-rms: 0.0070038
[32m[0322 13:54:37 @monitor.py:363][0m cross_entropy_loss: 5.4219
[32m[0322 13:54:37 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67622
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087401
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6174
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.412
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34177
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30026
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29506
[32m[0322 13:54:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 13:54:37 @monitor.py:363][0m train-error-top1: 0.98369
[32m[0322 13:54:37 @monitor.py:363][0m val-error-top1: 0.98353
[32m[0322 13:54:37 @monitor.py:363][0m val-utt-error: 0.97604
[32m[0322 13:54:37 @monitor.py:363][0m validation_cost: 5.4801
[32m[0322 13:54:37 @monitor.py:363][0m wd_cost: 8.9585e-08
[32m[0322 13:54:37 @group.py:42][0m Callbacks took 171.708 sec in total. InferenceRunner: 170.917sec
[32m[0322 13:54:37 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13123/173481[03:00<36:39,72.91it/s]  8%|7         |13659/173481[03:10<36:32,72.91it/s] 13%|#3        |23014/173481[06:00<40:01,62.67it/s] 14%|#3        |23607/173481[06:10<39:51,62.67it/s] 19%|#9        |33808/173481[09:00<37:59,61.28it/s] 20%|#9        |34466/173481[09:10<37:48,61.28it/s] 26%|##5       |44613/173481[12:00<35:25,60.64it/s] 26%|##6       |45210/173481[12:10<35:15,60.64it/s] 31%|###1      |54589/173481[15:00<34:12,57.91it/s] 32%|###1      |55145/173481[15:10<34:03,57.91it/s] 37%|###7      |64468/173481[18:00<32:14,56.35it/s] 37%|###7      |65019/173481[18:10<32:04,56.35it/s] 43%|####3     |74759/173481[21:00<28:59,56.76it/s] 43%|####3     |75436/173481[21:11<28:47,56.76it/s] 49%|####9     |85593/173481[24:00<25:04,58.42it/s] 50%|####9     |86212/173481[24:11<24:53,58.42it/s] 55%|#####5    |95808/173481[27:00<22:29,57.57it/s] 56%|#####5    |96487/173481[27:11<22:17,57.57it/s] 61%|######1   |106513/173481[30:00<19:04,58.50it/s] 62%|######1   |107187/173481[30:11<18:53,58.50it/s] 67%|######7   |116723/173481[33:00<16:25,57.60it/s] 68%|######7   |117422/173481[33:11<16:13,57.60it/s] 73%|#######3  |127462/173481[36:00<13:05,58.61it/s] 74%|#######3  |128163/173481[36:11<12:53,58.61it/s] 80%|#######9  |138393/173481[39:00<09:48,59.64it/s] 80%|########  |139124/173481[39:12<09:36,59.64it/s] 86%|########5 |148513/173481[42:00<07:11,57.88it/s] 86%|########5 |149112/173481[42:12<07:01,57.88it/s] 92%|#########1|158828/173481[45:00<04:14,57.58it/s] 92%|#########1|159562/173481[45:12<04:01,57.58it/s] 97%|#########7|169130/173481[48:00<01:15,57.41it/s] 98%|#########7|169662/173481[48:12<01:06,57.41it/s]100%|##########|173481/173481[49:23<00:00,58.53it/s]
[32m[0322 14:44:01 @base.py:257][0m Epoch 4 (global_step 5724873) finished, time:2963.93 sec.
[32m[0322 14:44:01 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-5724873.
[32m[0322 14:44:02 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,166.55it/s]
3
[32m[0322 14:45:55 @monitor.py:363][0m QueueInput/queue_size: 0.32686
[32m[0322 14:45:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.352
[32m[0322 14:45:55 @monitor.py:363][0m activation-summaries/output-rms: 0.006906
[32m[0322 14:45:55 @monitor.py:363][0m cross_entropy_loss: 5.3486
[32m[0322 14:45:55 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67658
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087243
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61695
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4119
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34175
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30026
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29519
[32m[0322 14:45:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 14:45:55 @monitor.py:363][0m train-error-top1: 0.98097
[32m[0322 14:45:55 @monitor.py:363][0m val-error-top1: 0.98198
[32m[0322 14:45:55 @monitor.py:363][0m val-utt-error: 0.97439
[32m[0322 14:45:55 @monitor.py:363][0m validation_cost: 5.4013
[32m[0322 14:45:55 @monitor.py:363][0m wd_cost: 8.952e-08
[32m[0322 14:45:55 @group.py:42][0m Callbacks took 113.308 sec in total. InferenceRunner: 113.030sec
[32m[0322 14:45:55 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10803/173481[03:00<45:10,60.02it/s]  7%|6         |11315/173481[03:10<45:02,60.02it/s] 12%|#1        |20317/173481[06:00<45:25,56.20it/s] 12%|#1        |20786/173481[06:10<45:17,56.20it/s] 17%|#7        |30031/173481[09:00<43:25,55.06it/s] 18%|#7        |30611/173481[09:10<43:14,55.06it/s] 23%|##3       |40652/173481[12:00<38:52,56.95it/s] 24%|##3       |41306/173481[12:10<38:40,56.95it/s] 30%|##9       |51312/173481[15:00<35:04,58.06it/s] 30%|##9       |51919/173481[15:10<34:53,58.06it/s] 36%|###5      |62075/173481[18:00<31:31,58.91it/s] 36%|###6      |62701/173481[18:10<31:20,58.91it/s] 42%|####1     |72787/173481[21:00<28:20,59.20it/s] 42%|####2     |73421/173481[21:11<28:10,59.20it/s] 48%|####7     |83212/173481[24:00<25:41,58.55it/s] 48%|####8     |83856/173481[24:11<25:30,58.55it/s] 54%|#####3    |93394/173481[27:00<23:11,57.54it/s] 54%|#####4    |94016/173481[27:11<23:01,57.54it/s] 60%|#####9    |103704/173481[30:00<20:15,57.41it/s] 60%|######    |104396/173481[30:11<20:03,57.41it/s] 66%|######5   |114157/173481[33:00<17:07,57.73it/s] 66%|######6   |114801/173481[33:11<16:56,57.73it/s] 72%|#######1  |124384/173481[36:00<14:17,57.27it/s] 72%|#######2  |125056/173481[36:11<14:05,57.27it/s] 77%|#######7  |134397/173481[39:00<11:32,56.43it/s] 78%|#######7  |135066/173481[39:12<11:20,56.43it/s] 83%|########3 |144669/173481[42:00<08:27,56.75it/s] 84%|########3 |145371/173481[42:12<08:15,56.75it/s] 89%|########9 |155037/173481[45:00<05:22,57.16it/s] 90%|########9 |155621/173481[45:12<05:12,57.16it/s] 95%|#########4|164641/173481[48:00<02:40,55.19it/s] 95%|#########5|165297/173481[48:12<02:28,55.19it/s]100%|##########|173481/173481[50:42<00:00,57.03it/s]
[32m[0322 15:36:37 @base.py:257][0m Epoch 5 (global_step 5898354) finished, time:3042.11 sec.
[32m[0322 15:36:37 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-5898354.
[32m[0322 15:36:37 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.27it/s]
4
[32m[0322 15:38:45 @monitor.py:363][0m QueueInput/queue_size: 0.70693
[32m[0322 15:38:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.232
[32m[0322 15:38:45 @monitor.py:363][0m activation-summaries/output-rms: 0.0067499
[32m[0322 15:38:45 @monitor.py:363][0m cross_entropy_loss: 5.2781
[32m[0322 15:38:45 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67672
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/conv0/b-rms: 0.0008716
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61674
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4118
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34174
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30027
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29528
[32m[0322 15:38:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 15:38:45 @monitor.py:363][0m train-error-top1: 0.98058
[32m[0322 15:38:45 @monitor.py:363][0m val-error-top1: 0.98106
[32m[0322 15:38:45 @monitor.py:363][0m val-utt-error: 0.97248
[32m[0322 15:38:45 @monitor.py:363][0m validation_cost: 5.3599
[32m[0322 15:38:45 @monitor.py:363][0m wd_cost: 1.7898e-08
[32m[0322 15:38:45 @group.py:42][0m Callbacks took 128.098 sec in total. InferenceRunner: 127.825sec
[32m[0322 15:38:45 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11078/173481[03:00<43:58,61.54it/s]  7%|6         |11565/173481[03:10<43:50,61.54it/s] 12%|#1        |20561/173481[06:00<44:53,56.76it/s] 12%|#2        |21115/173481[06:10<44:44,56.76it/s] 18%|#7        |30366/173481[09:00<42:54,55.59it/s] 18%|#7        |30960/173481[09:10<42:43,55.59it/s] 23%|##3       |40441/173481[12:00<39:45,55.78it/s] 24%|##3       |41020/173481[12:10<39:34,55.78it/s] 29%|##9       |50581/173481[15:00<36:32,56.05it/s] 29%|##9       |51150/173481[15:10<36:22,56.05it/s] 35%|###5      |60744/173481[18:00<33:23,56.26it/s] 35%|###5      |61349/173481[18:10<33:13,56.26it/s] 41%|####      |70551/173481[21:00<30:59,55.35it/s] 41%|####1     |71160/173481[21:11<30:48,55.35it/s] 46%|####6     |80286/173481[24:00<28:23,54.70it/s] 47%|####6     |80946/173481[24:11<28:11,54.70it/s] 52%|#####1    |90177/173481[27:00<25:19,54.83it/s] 52%|#####2    |90809/173481[27:11<25:07,54.83it/s] 58%|#####7    |99755/173481[30:00<22:45,54.01it/s] 58%|#####7    |100405/173481[30:11<22:33,54.01it/s] 63%|######2   |109021/173481[33:00<20:22,52.71it/s] 63%|######3   |109697/173481[33:11<20:10,52.71it/s] 68%|######8   |118811/173481[36:00<17:01,53.52it/s] 69%|######8   |119399/173481[36:11<16:50,53.52it/s] 74%|#######4  |129016/173481[39:00<13:27,55.06it/s] 75%|#######4  |129691/173481[39:12<13:15,55.06it/s] 80%|########  |138956/173481[42:00<10:26,55.14it/s] 81%|########  |139668/173481[42:12<10:13,55.14it/s] 86%|########6 |149276/173481[45:00<07:10,56.21it/s] 86%|########6 |149953/173481[45:12<06:58,56.21it/s] 91%|#########1|158718/173481[48:00<04:32,54.27it/s] 92%|#########1|159362/173481[48:12<04:20,54.27it/s] 97%|#########7|168321/173481[51:00<01:35,53.80it/s] 97%|#########7|168984/173481[51:12<01:23,53.80it/s]100%|##########|173481/173481[52:36<00:00,54.96it/s]
[32m[0322 16:31:21 @base.py:257][0m Epoch 6 (global_step 6071835) finished, time:3156.41 sec.
[32m[0322 16:31:21 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-6071835.
[32m[0322 16:31:21 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:30<00:00,124.66it/s]
5
[32m[0322 16:33:52 @monitor.py:363][0m QueueInput/queue_size: 0.59861
[32m[0322 16:33:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.453
[32m[0322 16:33:52 @monitor.py:363][0m activation-summaries/output-rms: 0.006775
[32m[0322 16:33:52 @monitor.py:363][0m cross_entropy_loss: 5.2814
[32m[0322 16:33:52 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67684
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087063
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61656
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4117
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30027
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29536
[32m[0322 16:33:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 16:33:52 @monitor.py:363][0m train-error-top1: 0.98107
[32m[0322 16:33:52 @monitor.py:363][0m val-error-top1: 0.98045
[32m[0322 16:33:52 @monitor.py:363][0m val-utt-error: 0.97152
[32m[0322 16:33:52 @monitor.py:363][0m validation_cost: 5.3216
[32m[0322 16:33:52 @monitor.py:363][0m wd_cost: 1.7894e-08
[32m[0322 16:33:52 @group.py:42][0m Callbacks took 151.289 sec in total. InferenceRunner: 150.999sec
[32m[0322 16:33:52 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12182/173481[03:00<39:43,67.68it/s]  7%|7         |12703/173481[03:10<39:35,67.68it/s] 13%|#2        |22125/173481[06:00<41:28,60.82it/s] 13%|#3        |22709/173481[06:10<41:19,60.82it/s] 19%|#8        |32345/173481[09:00<40:03,58.72it/s] 19%|#8        |32849/173481[09:10<39:55,58.72it/s] 23%|##3       |40325/173481[12:00<43:55,50.52it/s] 24%|##3       |40830/173481[12:10<43:45,50.52it/s] 29%|##8       |49545/173481[15:00<40:36,50.87it/s] 29%|##8       |50110/173481[15:10<40:25,50.87it/s] 34%|###4      |59460/173481[18:00<35:56,52.88it/s] 35%|###4      |60069/173481[18:11<35:44,52.88it/s] 40%|###9      |69020/173481[21:00<32:51,52.99it/s] 40%|####      |69653/173481[21:11<32:39,52.99it/s] 45%|####5     |78900/173481[24:00<29:14,53.92it/s] 46%|####5     |79456/173481[24:11<29:03,53.92it/s] 51%|#####     |88417/173481[27:00<26:33,53.39it/s] 51%|#####1    |89089/173481[27:11<26:20,53.39it/s] 57%|#####6    |98445/173481[30:00<22:56,54.52it/s] 57%|#####7    |99066/173481[30:11<22:44,54.52it/s] 63%|######2   |108585/173481[33:00<19:31,55.41it/s] 63%|######2   |109211/173481[33:11<19:19,55.41it/s] 68%|######8   |118205/173481[36:00<16:56,54.39it/s] 68%|######8   |118814/173481[36:12<16:45,54.39it/s] 74%|#######3  |127559/173481[39:00<14:23,53.15it/s] 74%|#######3  |128184/173481[39:12<14:12,53.15it/s] 79%|#######8  |136730/173481[42:00<11:46,52.03it/s] 79%|#######9  |137374/173481[42:12<11:34,52.03it/s] 84%|########4 |146400/173481[45:00<08:32,52.85it/s] 85%|########4 |147056/173481[45:12<08:20,52.85it/s] 88%|########8 |152683/173481[48:00<08:14,42.04it/s] 88%|########8 |153374/173481[48:12<07:58,42.04it/s] 94%|#########3|162795/173481[51:00<03:42,48.09it/s] 94%|#########4|163219/173481[51:12<03:33,48.09it/s]100%|#########9|172891/173481[54:00<00:11,51.78it/s]100%|##########|173481/173481[54:10<00:00,53.36it/s]
[32m[0322 17:28:03 @base.py:257][0m Epoch 7 (global_step 6245316) finished, time:3250.90 sec.
[32m[0322 17:28:03 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-6245316.
[32m[0322 17:28:04 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:12<00:00,142.32it/s]
6
[32m[0322 17:30:16 @monitor.py:363][0m QueueInput/queue_size: 0.36755
[32m[0322 17:30:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.257
[32m[0322 17:30:16 @monitor.py:363][0m activation-summaries/output-rms: 0.0068062
[32m[0322 17:30:16 @monitor.py:363][0m cross_entropy_loss: 5.2656
[32m[0322 17:30:16 @monitor.py:363][0m lr: 1.2207e-07
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67693
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087051
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61634
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4116
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34172
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30027
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29543
[32m[0322 17:30:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 17:30:16 @monitor.py:363][0m train-error-top1: 0.98294
[32m[0322 17:30:16 @monitor.py:363][0m val-error-top1: 0.97976
[32m[0322 17:30:16 @monitor.py:363][0m val-utt-error: 0.96988
[32m[0322 17:30:16 @monitor.py:363][0m validation_cost: 5.3004
[32m[0322 17:30:16 @monitor.py:363][0m wd_cost: 3.5775e-09
[32m[0322 17:30:16 @group.py:42][0m Callbacks took 133.027 sec in total. InferenceRunner: 132.260sec
[32m[0322 17:30:16 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12511/173481[03:00<38:35,69.50it/s]  8%|7         |13133/173481[03:10<38:27,69.50it/s] 13%|#3        |23140/173481[06:00<39:14,63.85it/s] 14%|#3        |23728/173481[06:10<39:05,63.85it/s] 19%|#9        |32974/173481[09:00<39:46,58.87it/s] 19%|#9        |33576/173481[09:10<39:36,58.87it/s] 25%|##4       |43157/173481[12:00<37:38,57.70it/s] 25%|##5       |43748/173481[12:10<37:28,57.70it/s] 31%|###       |53594/173481[15:00<34:32,57.84it/s] 31%|###1      |54283/173481[15:10<34:20,57.84it/s] 37%|###6      |63804/173481[18:00<31:55,57.27it/s] 37%|###7      |64488/173481[18:11<31:43,57.27it/s] 43%|####2     |73781/173481[21:00<29:29,56.33it/s] 43%|####2     |74363/173481[21:11<29:19,56.33it/s] 48%|####8     |83764/173481[24:00<26:45,55.89it/s] 49%|####8     |84321/173481[24:11<26:35,55.89it/s] 54%|#####4    |94329/173481[27:00<23:02,57.26it/s] 55%|#####4    |94964/173481[27:11<22:51,57.26it/s] 60%|######    |104916/173481[30:00<19:41,58.03it/s] 61%|######    |105544/173481[30:11<19:30,58.03it/s] 67%|######6   |116179/173481[33:00<15:51,60.21it/s] 67%|######7   |116873/173481[33:11<15:40,60.21it/s] 73%|#######3  |126920/173481[36:00<12:56,59.94it/s] 74%|#######3  |127646/173481[36:12<12:44,59.94it/s] 79%|#######9  |137519/173481[39:00<10:05,59.40it/s] 80%|#######9  |138239/173481[39:12<09:53,59.40it/s] 85%|########5 |148164/173481[42:00<07:07,59.27it/s] 86%|########5 |148850/173481[42:12<06:55,59.27it/s] 92%|#########1|158965/173481[45:00<04:03,59.63it/s] 92%|#########2|159723/173481[45:12<03:50,59.63it/s] 98%|#########7|169864/173481[48:00<01:00,60.09it/s] 98%|#########8|170635/173481[48:12<00:47,60.09it/s]100%|##########|173481/173481[49:01<00:00,58.98it/s]
[32m[0322 18:19:18 @base.py:257][0m Epoch 8 (global_step 6418797) finished, time:2941.50 sec.
[32m[0322 18:19:18 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-6418797.
[32m[0322 18:19:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.74it/s]
7
[32m[0322 18:21:22 @monitor.py:363][0m QueueInput/queue_size: 1.8097
[32m[0322 18:21:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.212
[32m[0322 18:21:22 @monitor.py:363][0m activation-summaries/output-rms: 0.0069487
[32m[0322 18:21:22 @monitor.py:363][0m cross_entropy_loss: 5.2357
[32m[0322 18:21:22 @monitor.py:363][0m lr: 1.2207e-07
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67698
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087007
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61609
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4116
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34172
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30028
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29547
[32m[0322 18:21:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 18:21:22 @monitor.py:363][0m train-error-top1: 0.98074
[32m[0322 18:21:22 @monitor.py:363][0m val-error-top1: 0.97953
[32m[0322 18:21:22 @monitor.py:363][0m val-utt-error: 0.96961
[32m[0322 18:21:22 @monitor.py:363][0m validation_cost: 5.2824
[32m[0322 18:21:22 @monitor.py:363][0m wd_cost: 3.576e-09
[32m[0322 18:21:22 @group.py:42][0m Callbacks took 123.698 sec in total. InferenceRunner: 122.439sec
[32m[0322 18:21:22 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12224/173481[03:00<39:34,67.91it/s]  7%|7         |12743/173481[03:10<39:27,67.91it/s] 13%|#2        |22168/173481[06:00<41:23,60.92it/s] 13%|#3        |22682/173481[06:10<41:15,60.92it/s] 18%|#8        |31729/173481[09:00<41:37,56.75it/s] 19%|#8        |32348/173481[09:10<41:26,56.75it/s] 24%|##4       |42288/173481[12:00<37:54,57.68it/s] 25%|##4       |42865/173481[12:10<37:44,57.68it/s] 31%|###       |53218/173481[15:00<33:53,59.15it/s] 31%|###1      |53847/173481[15:10<33:42,59.15it/s] 36%|###6      |62903/173481[18:00<32:42,56.35it/s] 37%|###6      |63512/173481[18:10<32:31,56.35it/s] 42%|####2     |73727/173481[21:00<28:34,58.18it/s] 43%|####2     |74390/173481[21:11<28:23,58.18it/s] 49%|####8     |84596/173481[24:00<24:59,59.26it/s] 49%|####9     |85297/173481[24:11<24:48,59.26it/s] 55%|#####5    |95668/173481[27:00<21:29,60.36it/s] 56%|#####5    |96322/173481[27:11<21:18,60.36it/s] 61%|######1   |106668/173481[30:00<18:20,60.73it/s] 62%|######1   |107352/173481[30:11<18:08,60.73it/s] 68%|######7   |117830/173481[33:00<15:06,61.36it/s] 68%|######8   |118462/173481[33:11<14:56,61.36it/s] 74%|#######4  |128529/173481[36:00<12:24,60.38it/s] 74%|#######4  |129232/173481[36:11<12:12,60.38it/s] 80%|########  |139298/173481[39:00<09:28,60.09it/s] 81%|########  |139947/173481[39:11<09:18,60.09it/s] 86%|########6 |149663/173481[42:00<06:44,58.81it/s] 87%|########6 |150337/173481[42:12<06:33,58.81it/s] 92%|#########2|160278/173481[45:00<03:44,58.89it/s] 93%|#########2|160950/173481[45:12<03:32,58.89it/s] 98%|#########8|170274/173481[48:00<00:56,57.16it/s] 98%|#########8|170877/173481[48:12<00:45,57.16it/s]100%|##########|173481/173481[49:01<00:00,58.99it/s]
[32m[0322 19:10:23 @base.py:257][0m Epoch 9 (global_step 6592278) finished, time:2941.04 sec.
[32m[0322 19:10:23 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-6592278.
[32m[0322 19:10:23 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:20<00:00,133.50it/s]
8
[32m[0322 19:12:44 @monitor.py:363][0m QueueInput/queue_size: 0.89569
[32m[0322 19:12:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.384
[32m[0322 19:12:44 @monitor.py:363][0m activation-summaries/output-rms: 0.0068928
[32m[0322 19:12:44 @monitor.py:363][0m cross_entropy_loss: 5.2165
[32m[0322 19:12:44 @monitor.py:363][0m lr: 1.2207e-07
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67704
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00087004
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61584
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4116
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34172
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30028
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29552
[32m[0322 19:12:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 19:12:44 @monitor.py:363][0m train-error-top1: 0.97861
[32m[0322 19:12:44 @monitor.py:363][0m val-error-top1: 0.97918
[32m[0322 19:12:44 @monitor.py:363][0m val-utt-error: 0.96977
[32m[0322 19:12:44 @monitor.py:363][0m validation_cost: 5.2689
[32m[0322 19:12:44 @monitor.py:363][0m wd_cost: 3.5745e-09
[32m[0322 19:12:44 @group.py:42][0m Callbacks took 141.283 sec in total. InferenceRunner: 141.000sec
[32m[0322 19:12:44 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11947/173481[03:00<40:34,66.35it/s]  7%|7         |12524/173481[03:10<40:25,66.35it/s] 13%|#2        |22139/173481[06:00<41:16,61.10it/s] 13%|#3        |22616/173481[06:10<41:09,61.10it/s] 19%|#8        |32491/173481[09:00<39:39,59.25it/s] 19%|#9        |33046/173481[09:10<39:30,59.25it/s] 25%|##5       |44222/173481[12:00<34:42,62.06it/s] 26%|##5       |44946/173481[12:10<34:31,62.06it/s] 33%|###3      |57671/173481[15:00<28:28,67.80it/s] 34%|###4      |59017/173481[15:10<28:08,67.80it/s] 41%|####      |70792/173481[18:00<24:21,70.25it/s] 41%|####1     |71476/173481[18:10<24:12,70.25it/s] 48%|####8     |83512/173481[21:00<21:16,70.46it/s] 49%|####8     |84262/173481[21:11<21:06,70.46it/s] 55%|#####5    |96134/173481[24:00<18:20,70.29it/s] 56%|#####5    |96921/173481[24:11<18:09,70.29it/s] 62%|######2   |108237/173481[27:00<15:49,68.73it/s] 63%|######2   |108999/173481[27:11<15:38,68.73it/s] 70%|######9   |120807/173481[30:00<12:40,69.27it/s] 70%|#######   |121601/173481[30:11<12:28,69.27it/s] 77%|#######6  |133542/173481[33:00<09:30,69.99it/s] 77%|#######7  |134306/173481[33:11<09:19,69.99it/s] 84%|########4 |146208/173481[36:00<06:28,70.18it/s] 85%|########4 |146981/173481[36:11<06:17,70.18it/s] 91%|#########1|158363/173481[39:00<03:39,68.83it/s] 92%|#########1|159181/173481[39:12<03:27,68.83it/s] 99%|#########8|170902/173481[42:00<00:37,69.23it/s] 99%|#########9|171842/173481[42:12<00:23,69.23it/s]100%|##########|173481/173481[42:32<00:00,67.97it/s]
[32m[0322 19:55:16 @base.py:257][0m Epoch 10 (global_step 6765759) finished, time:2552.40 sec.
[32m[0322 19:55:16 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-6765759.
[32m[0322 19:55:17 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:09<00:00,145.56it/s]
9
[32m[0322 19:57:26 @monitor.py:363][0m QueueInput/queue_size: 0.81105
[32m[0322 19:57:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.194
[32m[0322 19:57:26 @monitor.py:363][0m activation-summaries/output-rms: 0.0067992
[32m[0322 19:57:26 @monitor.py:363][0m cross_entropy_loss: 5.1929
[32m[0322 19:57:26 @monitor.py:363][0m lr: 6.1035e-08
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67702
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/conv0/b-rms: 0.0008698
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61563
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34172
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30028
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29555
[32m[0322 19:57:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 19:57:26 @monitor.py:363][0m train-error-top1: 0.97829
[32m[0322 19:57:26 @monitor.py:363][0m val-error-top1: 0.97883
[32m[0322 19:57:26 @monitor.py:363][0m val-utt-error: 0.96722
[32m[0322 19:57:26 @monitor.py:363][0m validation_cost: 5.2618
[32m[0322 19:57:26 @monitor.py:363][0m wd_cost: 7.1464e-10
[32m[0322 19:57:26 @group.py:42][0m Callbacks took 129.546 sec in total. InferenceRunner: 129.316sec
[32m[0322 19:57:26 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15459/173481[03:00<30:40,85.88it/s]  9%|9         |16324/173481[03:10<30:29,85.88it/s] 17%|#7        |30286/173481[06:00<28:23,84.07it/s] 18%|#7        |30873/173481[06:10<28:16,84.07it/s] 23%|##3       |40655/173481[09:00<32:22,68.37it/s] 24%|##3       |41255/173481[09:10<32:14,68.37it/s] 30%|##9       |51381/173481[12:00<31:57,63.67it/s] 30%|##9       |51935/173481[12:10<31:49,63.67it/s] 36%|###5      |62146/173481[15:00<30:05,61.67it/s] 36%|###6      |62740/173481[15:10<29:55,61.67it/s] 42%|####1     |72507/173481[18:00<28:15,59.54it/s] 42%|####2     |73095/173481[18:10<28:05,59.54it/s] 48%|####7     |82946/173481[21:00<25:40,58.75it/s] 48%|####8     |83582/173481[21:11<25:30,58.75it/s] 54%|#####3    |93016/173481[24:00<23:24,57.31it/s] 54%|#####3    |93675/173481[24:11<23:12,57.31it/s] 60%|#####9    |103273/173481[27:00<20:28,57.14it/s] 60%|#####9    |103915/173481[27:11<20:17,57.14it/s] 66%|######5   |113675/173481[30:00<17:20,57.46it/s] 66%|######5   |114374/173481[30:11<17:08,57.46it/s] 71%|#######1  |124028/173481[33:00<14:20,57.49it/s] 72%|#######1  |124730/173481[33:11<14:07,57.49it/s] 77%|#######7  |134282/173481[36:00<11:24,57.23it/s] 78%|#######7  |134995/173481[36:11<11:12,57.23it/s] 84%|########3 |145086/173481[39:00<08:04,58.58it/s] 84%|########4 |145756/173481[39:12<07:53,58.58it/s] 90%|########9 |155452/173481[42:00<05:10,58.08it/s] 90%|########9 |156121/173481[42:12<04:58,58.08it/s] 95%|#########5|165674/173481[45:00<02:15,57.43it/s] 96%|#########5|166323/173481[45:12<02:04,57.43it/s]100%|##########|173481/173481[47:15<00:00,61.18it/s]
[32m[0322 20:44:41 @base.py:257][0m Epoch 11 (global_step 6939240) finished, time:2835.53 sec.
[32m[0322 20:44:42 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-6939240.
[32m[0322 20:44:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.00it/s]
10
[32m[0322 20:46:48 @monitor.py:363][0m QueueInput/queue_size: 0.35516
[32m[0322 20:46:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.406
[32m[0322 20:46:48 @monitor.py:363][0m activation-summaries/output-rms: 0.0068039
[32m[0322 20:46:48 @monitor.py:363][0m cross_entropy_loss: 5.2177
[32m[0322 20:46:48 @monitor.py:363][0m lr: 6.1035e-08
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67699
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086965
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61542
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30028
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29557
[32m[0322 20:46:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 20:46:48 @monitor.py:363][0m train-error-top1: 0.97934
[32m[0322 20:46:48 @monitor.py:363][0m val-error-top1: 0.97868
[32m[0322 20:46:48 @monitor.py:363][0m val-utt-error: 0.96711
[32m[0322 20:46:48 @monitor.py:363][0m validation_cost: 5.254
[32m[0322 20:46:48 @monitor.py:363][0m wd_cost: 7.1438e-10
[32m[0322 20:46:48 @group.py:42][0m Callbacks took 126.728 sec in total. InferenceRunner: 124.657sec
[32m[0322 20:46:48 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11795/173481[03:00<41:07,65.52it/s]  7%|7         |12349/173481[03:10<40:59,65.52it/s] 13%|#2        |22365/173481[06:00<40:40,61.93it/s] 13%|#3        |22931/173481[06:10<40:31,61.93it/s] 19%|#8        |32535/173481[09:00<39:46,59.07it/s] 19%|#9        |33094/173481[09:10<39:36,59.07it/s] 24%|##4       |42042/173481[12:00<39:16,55.77it/s] 25%|##4       |42569/173481[12:10<39:07,55.77it/s] 30%|##9       |51860/173481[15:00<36:45,55.14it/s] 30%|###       |52420/173481[15:10<36:35,55.14it/s] 36%|###5      |62075/173481[18:00<33:11,55.93it/s] 36%|###6      |62664/173481[18:11<33:01,55.93it/s] 41%|####1     |71900/173481[21:00<30:38,55.25it/s] 42%|####1     |72539/173481[21:11<30:27,55.25it/s] 47%|####7     |82240/173481[24:00<27:00,56.32it/s] 48%|####7     |82874/173481[24:11<26:48,56.32it/s] 53%|#####3    |92382/173481[27:00<23:59,56.33it/s] 54%|#####3    |93014/173481[27:11<23:48,56.33it/s] 59%|#####9    |102684/173481[30:00<20:46,56.78it/s] 60%|#####9    |103334/173481[30:11<20:35,56.78it/s] 65%|######5   |112945/173481[33:00<17:44,56.89it/s] 65%|######5   |113594/173481[33:11<17:32,56.89it/s] 71%|#######   |122853/173481[36:00<15:04,55.95it/s] 71%|#######1  |123529/173481[36:12<14:52,55.95it/s] 77%|#######6  |132854/173481[39:00<12:08,55.76it/s] 77%|#######6  |133543/173481[39:12<11:56,55.76it/s] 82%|########2 |142895/173481[42:00<09:08,55.77it/s] 83%|########2 |143599/173481[42:12<08:55,55.77it/s] 88%|########8 |153385/173481[45:00<05:52,56.99it/s] 89%|########8 |154125/173481[45:12<05:39,56.99it/s] 95%|#########4|164298/173481[48:00<02:36,58.75it/s] 95%|#########5|165039/173481[48:12<02:23,58.75it/s]100%|##########|173481/173481[50:29<00:00,57.26it/s]
[32m[0322 21:37:18 @base.py:257][0m Epoch 12 (global_step 7112721) finished, time:3029.83 sec.
[32m[0322 21:37:18 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-7112721.
[32m[0322 21:37:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:29<00:00,125.49it/s]
11
[32m[0322 21:39:49 @monitor.py:363][0m QueueInput/queue_size: 0.41531
[32m[0322 21:39:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.243
[32m[0322 21:39:49 @monitor.py:363][0m activation-summaries/output-rms: 0.0068186
[32m[0322 21:39:49 @monitor.py:363][0m cross_entropy_loss: 5.216
[32m[0322 21:39:49 @monitor.py:363][0m lr: 3.0518e-08
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67697
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086941
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61522
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30029
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2956
[32m[0322 21:39:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 21:39:49 @monitor.py:363][0m train-error-top1: 0.98084
[32m[0322 21:39:49 @monitor.py:363][0m val-error-top1: 0.97861
[32m[0322 21:39:49 @monitor.py:363][0m val-utt-error: 0.96621
[32m[0322 21:39:49 @monitor.py:363][0m validation_cost: 5.2501
[32m[0322 21:39:49 @monitor.py:363][0m wd_cost: 7.1414e-10
[32m[0322 21:39:49 @group.py:42][0m Callbacks took 150.651 sec in total. InferenceRunner: 149.996sec
[32m[0322 21:39:49 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14094/173481[03:00<33:55,78.30it/s]  8%|8         |14725/173481[03:10<33:47,78.30it/s] 14%|#4        |25140/173481[06:00<35:56,68.80it/s] 15%|#4        |25713/173481[06:10<35:47,68.80it/s] 20%|##        |35089/173481[09:00<37:37,61.30it/s] 21%|##        |35704/173481[09:10<37:27,61.30it/s] 26%|##6       |45497/173481[12:00<35:50,59.51it/s] 27%|##6       |46128/173481[12:10<35:40,59.51it/s] 32%|###2      |55699/173481[15:00<33:49,58.05it/s] 32%|###2      |56334/173481[15:10<33:38,58.05it/s] 38%|###8      |66367/173481[18:00<30:26,58.65it/s] 39%|###8      |67085/173481[18:11<30:14,58.65it/s] 45%|####4     |77769/173481[21:00<26:11,60.90it/s] 45%|####5     |78488/173481[21:11<25:59,60.90it/s] 51%|#####1    |89254/173481[24:00<22:31,62.32it/s] 52%|#####1    |89955/173481[24:11<22:20,62.32it/s] 58%|#####7    |100436/173481[27:00<19:34,62.22it/s] 58%|#####8    |101133/173481[27:11<19:22,62.22it/s] 64%|######4   |111491/173481[30:00<16:42,61.81it/s] 65%|######4   |112228/173481[30:11<16:30,61.81it/s] 72%|#######1  |124143/173481[33:00<12:30,65.78it/s] 72%|#######2  |125065/173481[33:11<12:16,65.78it/s] 81%|########  |139798/173481[36:00<07:29,74.90it/s] 81%|########1 |140841/173481[36:12<07:15,74.90it/s] 90%|########9 |155883/173481[39:00<03:35,81.49it/s] 90%|######### |156953/173481[39:12<03:22,81.49it/s] 98%|#########8|170850/173481[42:00<00:31,82.31it/s] 99%|#########8|171681/173481[42:12<00:21,82.31it/s]100%|##########|173481/173481[42:42<00:00,67.71it/s]
[32m[0322 22:22:31 @base.py:257][0m Epoch 13 (global_step 7286202) finished, time:2562.02 sec.
[32m[0322 22:22:31 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-7286202.
[32m[0322 22:22:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s] 95%|#########5|17955/18822[03:00<00:08,99.75it/s]100%|##########|18822/18822[03:07<00:00,100.57it/s]
12
[32m[0322 22:25:39 @monitor.py:363][0m QueueInput/queue_size: 0.47553
[32m[0322 22:25:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.212
[32m[0322 22:25:39 @monitor.py:363][0m activation-summaries/output-rms: 0.006936
[32m[0322 22:25:39 @monitor.py:363][0m cross_entropy_loss: 5.1985
[32m[0322 22:25:39 @monitor.py:363][0m lr: 3.0518e-08
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67696
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086931
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61508
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30029
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29561
[32m[0322 22:25:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 22:25:39 @monitor.py:363][0m train-error-top1: 0.98022
[32m[0322 22:25:39 @monitor.py:363][0m val-error-top1: 0.9786
[32m[0322 22:25:39 @monitor.py:363][0m val-utt-error: 0.96679
[32m[0322 22:25:39 @monitor.py:363][0m validation_cost: 5.2453
[32m[0322 22:25:39 @monitor.py:363][0m wd_cost: 1.4279e-10
[32m[0322 22:25:39 @group.py:42][0m Callbacks took 188.328 sec in total. InferenceRunner: 187.164sec
[32m[0322 22:25:39 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16313/173481[03:00<28:54,90.61it/s] 10%|9         |16865/173481[03:10<28:48,90.61it/s] 15%|#5        |26848/173481[06:00<34:22,71.11it/s] 16%|#5        |27504/173481[06:10<34:12,71.11it/s] 22%|##2       |38498/173481[09:00<33:12,67.76it/s] 23%|##2       |39122/173481[09:10<33:02,67.76it/s] 29%|##8       |49831/173481[12:00<31:34,65.27it/s] 29%|##9       |50487/173481[12:10<31:24,65.27it/s] 35%|###5      |61018/173481[15:00<29:26,63.67it/s] 36%|###5      |61699/173481[15:10<29:15,63.67it/s] 42%|####1     |72098/173481[18:00<26:59,62.59it/s] 42%|####1     |72813/173481[18:11<26:48,62.59it/s] 48%|####7     |83093/173481[21:00<24:22,61.82it/s] 48%|####8     |83803/173481[21:11<24:10,61.82it/s] 54%|#####4    |94483/173481[24:00<21:03,62.54it/s] 55%|#####4    |95227/173481[24:11<20:51,62.54it/s] 61%|######1   |106018/173481[27:00<17:45,63.30it/s] 62%|######1   |106747/173481[27:11<17:34,63.30it/s] 68%|######7   |117326/173481[30:00<14:50,63.06it/s] 68%|######8   |118055/173481[30:11<14:38,63.06it/s] 74%|#######4  |128938/173481[33:00<11:38,63.77it/s] 75%|#######4  |129662/173481[33:11<11:27,63.77it/s] 81%|########1 |140603/173481[36:00<08:31,64.28it/s] 81%|########1 |141381/173481[36:12<08:19,64.28it/s] 88%|########7 |152138/173481[39:00<05:32,64.18it/s] 88%|########8 |152937/173481[39:12<05:20,64.18it/s] 94%|#########4|163550/173481[42:00<02:35,63.79it/s] 95%|#########4|164313/173481[42:12<02:23,63.79it/s]100%|##########|173481/173481[44:46<00:00,64.58it/s]
[32m[0322 23:10:25 @base.py:257][0m Epoch 14 (global_step 7459683) finished, time:2686.47 sec.
[32m[0322 23:10:26 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-7459683.
[32m[0322 23:10:26 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:28<00:00,126.89it/s]
13
[32m[0322 23:12:54 @monitor.py:363][0m QueueInput/queue_size: 0.53273
[32m[0322 23:12:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.379
[32m[0322 23:12:54 @monitor.py:363][0m activation-summaries/output-rms: 0.0069017
[32m[0322 23:12:54 @monitor.py:363][0m cross_entropy_loss: 5.189
[32m[0322 23:12:54 @monitor.py:363][0m lr: 3.0518e-08
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67695
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086915
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61494
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30029
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29562
[32m[0322 23:12:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 23:12:54 @monitor.py:363][0m train-error-top1: 0.97885
[32m[0322 23:12:54 @monitor.py:363][0m val-error-top1: 0.97851
[32m[0322 23:12:54 @monitor.py:363][0m val-utt-error: 0.96658
[32m[0322 23:12:54 @monitor.py:363][0m validation_cost: 5.2437
[32m[0322 23:12:54 @monitor.py:363][0m wd_cost: 1.4276e-10
[32m[0322 23:12:54 @group.py:42][0m Callbacks took 148.806 sec in total. InferenceRunner: 148.344sec
[32m[0322 23:12:54 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13408/173481[03:00<35:48,74.49it/s]  8%|8         |14030/173481[03:10<35:40,74.49it/s] 14%|#3        |24052/173481[06:00<37:46,65.93it/s] 14%|#4        |24636/173481[06:10<37:37,65.93it/s] 20%|##        |35157/173481[09:00<36:10,63.74it/s] 21%|##        |35821/173481[09:10<35:59,63.74it/s] 27%|##7       |46949/173481[12:00<32:38,64.61it/s] 27%|##7       |47633/173481[12:10<32:27,64.61it/s] 34%|###3      |58922/173481[15:00<29:07,65.55it/s] 34%|###4      |59633/173481[15:10<28:56,65.55it/s] 41%|####      |70387/173481[18:00<26:35,64.60it/s] 41%|####      |71091/173481[18:11<26:24,64.60it/s] 51%|#####1    |88643/173481[21:00<17:54,78.93it/s] 52%|#####1    |89741/173481[21:11<17:40,78.93it/s] 61%|######    |105630/173481[24:00<13:09,85.96it/s] 61%|######1   |106526/173481[24:11<12:58,85.96it/s] 69%|######9   |119903/173481[27:00<10:49,82.49it/s] 70%|######9   |120786/173481[27:11<10:38,82.49it/s] 77%|#######6  |133076/173481[30:00<08:40,77.56it/s] 77%|#######7  |133901/173481[30:11<08:30,77.56it/s] 85%|########4 |146920/173481[33:00<05:43,77.23it/s] 85%|########5 |147831/173481[33:12<05:32,77.23it/s] 94%|#########4|163702/173481[36:00<01:55,84.48it/s] 95%|#########5|164881/173481[36:12<01:41,84.48it/s]100%|##########|173481/173481[38:14<00:00,75.60it/s]
[32m[0322 23:51:09 @base.py:257][0m Epoch 15 (global_step 7633164) finished, time:2294.60 sec.
[32m[0322 23:51:09 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-7633164.
[32m[0322 23:51:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:15<00:00,138.52it/s]
14
[32m[0322 23:53:25 @monitor.py:363][0m QueueInput/queue_size: 0.63463
[32m[0322 23:53:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.186
[32m[0322 23:53:25 @monitor.py:363][0m activation-summaries/output-rms: 0.0068237
[32m[0322 23:53:25 @monitor.py:363][0m cross_entropy_loss: 5.1737
[32m[0322 23:53:25 @monitor.py:363][0m lr: 1.5259e-08
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086898
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61486
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30029
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29563
[32m[0322 23:53:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0322 23:53:25 @monitor.py:363][0m train-error-top1: 0.97889
[32m[0322 23:53:25 @monitor.py:363][0m val-error-top1: 0.97837
[32m[0322 23:53:25 @monitor.py:363][0m val-utt-error: 0.96706
[32m[0322 23:53:25 @monitor.py:363][0m validation_cost: 5.2416
[32m[0322 23:53:25 @monitor.py:363][0m wd_cost: 1.4274e-10
[32m[0322 23:53:25 @group.py:42][0m Callbacks took 136.243 sec in total. InferenceRunner: 135.893sec
[32m[0322 23:53:25 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11705/173481[03:00<41:27,65.03it/s]  7%|7         |12300/173481[03:10<41:18,65.03it/s] 13%|#2        |22511/173481[06:00<40:18,62.43it/s] 13%|#3        |23135/173481[06:10<40:08,62.43it/s] 19%|#8        |32568/173481[09:00<39:49,58.97it/s] 19%|#9        |33140/173481[09:10<39:39,58.97it/s] 24%|##4       |41749/173481[12:00<40:08,54.70it/s] 24%|##4       |42300/173481[12:10<39:58,54.70it/s] 29%|##9       |51164/173481[15:00<38:07,53.47it/s] 30%|##9       |51722/173481[15:10<37:56,53.47it/s] 35%|###5      |60892/173481[18:00<34:54,53.76it/s] 36%|###5      |61599/173481[18:11<34:41,53.76it/s] 41%|####1     |71391/173481[21:00<30:24,55.94it/s] 41%|####1     |71953/173481[21:11<30:14,55.94it/s] 47%|####6     |80986/173481[24:00<28:14,54.59it/s] 47%|####7     |81580/173481[24:11<28:03,54.59it/s] 52%|#####2    |90578/173481[27:00<25:37,53.93it/s] 53%|#####2    |91250/173481[27:11<25:24,53.93it/s] 58%|#####7    |100016/173481[30:00<23:02,53.13it/s] 58%|#####8    |100620/173481[30:11<22:51,53.13it/s] 63%|######2   |109273/173481[33:00<20:28,52.26it/s] 63%|######3   |109875/173481[33:11<20:16,52.26it/s] 68%|######8   |118467/173481[36:00<17:44,51.66it/s] 69%|######8   |119121/173481[36:12<17:32,51.66it/s] 74%|#######3  |128015/173481[39:00<14:28,52.34it/s] 74%|#######4  |128645/173481[39:12<14:16,52.34it/s] 79%|#######9  |137403/173481[42:00<11:30,52.25it/s] 80%|#######9  |138070/173481[42:12<11:17,52.25it/s] 85%|########4 |146872/173481[45:00<08:27,52.43it/s] 85%|########5 |147500/173481[45:12<08:15,52.43it/s] 90%|######### |156673/173481[48:00<05:14,53.42it/s] 91%|######### |157325/173481[48:12<05:02,53.42it/s] 96%|#########5|165936/173481[51:00<02:23,52.42it/s] 96%|#########6|166560/173481[51:12<02:12,52.42it/s]100%|##########|173481/173481[53:33<00:00,53.98it/s]
[32m[0323 00:46:59 @base.py:257][0m Epoch 16 (global_step 7806645) finished, time:3213.66 sec.
[32m[0323 00:46:59 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-7806645.
[32m[0323 00:47:01 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:06<00:00,149.34it/s]
15
[32m[0323 00:49:07 @monitor.py:363][0m QueueInput/queue_size: 0.45255
[32m[0323 00:49:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.394
[32m[0323 00:49:07 @monitor.py:363][0m activation-summaries/output-rms: 0.0068122
[32m[0323 00:49:07 @monitor.py:363][0m cross_entropy_loss: 5.2041
[32m[0323 00:49:07 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086891
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61483
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30029
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 00:49:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 00:49:07 @monitor.py:363][0m train-error-top1: 0.97853
[32m[0323 00:49:07 @monitor.py:363][0m val-error-top1: 0.97838
[32m[0323 00:49:07 @monitor.py:363][0m val-utt-error: 0.96621
[32m[0323 00:49:07 @monitor.py:363][0m validation_cost: 5.2396
[32m[0323 00:49:07 @monitor.py:363][0m wd_cost: 2.8547e-11
[32m[0323 00:49:07 @group.py:42][0m Callbacks took 128.567 sec in total. InferenceRunner: 126.044sec
[32m[0323 00:49:07 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10690/173481[03:00<45:41,59.37it/s]  6%|6         |11244/173481[03:10<45:32,59.37it/s] 12%|#1        |20115/173481[06:00<45:56,55.64it/s] 12%|#1        |20659/173481[06:10<45:46,55.64it/s] 17%|#7        |29660/173481[09:00<44:08,54.29it/s] 17%|#7        |30164/173481[09:10<43:59,54.29it/s] 22%|##2       |38303/173481[12:00<44:12,50.96it/s] 22%|##2       |38799/173481[12:10<44:02,50.96it/s] 27%|##6       |46770/173481[15:00<43:10,48.92it/s] 27%|##7       |47271/173481[15:10<43:00,48.92it/s] 32%|###2      |55538/173481[18:00<40:16,48.81it/s] 32%|###2      |56094/173481[18:11<40:04,48.81it/s] 37%|###7      |64506/173481[21:00<36:49,49.31it/s] 37%|###7      |65031/173481[21:11<36:39,49.31it/s] 42%|####2     |73660/173481[24:00<33:13,50.07it/s] 43%|####2     |74249/173481[24:11<33:01,50.07it/s] 48%|####7     |83081/173481[27:00<29:26,51.18it/s] 48%|####8     |83643/173481[27:11<29:15,51.18it/s] 53%|#####3    |92455/173481[30:00<26:09,51.62it/s] 54%|#####3    |93074/173481[30:11<25:57,51.62it/s] 59%|#####8    |101845/173481[33:00<23:00,51.88it/s] 59%|#####9    |102494/173481[33:11<22:48,51.88it/s] 64%|######4   |111525/173481[36:00<19:33,52.81it/s] 65%|######4   |112079/173481[36:12<19:22,52.81it/s] 70%|######9   |120570/173481[39:00<17:07,51.49it/s] 70%|######9   |121191/173481[39:12<16:55,51.49it/s] 75%|#######4  |129850/173481[42:00<14:06,51.52it/s] 75%|#######5  |130475/173481[42:12<13:54,51.52it/s] 80%|########  |139110/173481[45:00<11:07,51.48it/s] 81%|########  |139754/173481[45:12<10:55,51.48it/s] 86%|########5 |148623/173481[48:00<07:56,52.15it/s] 86%|########6 |149294/173481[48:12<07:43,52.15it/s] 91%|#########1|158275/173481[51:00<04:47,52.87it/s] 92%|#########1|158934/173481[51:12<04:35,52.87it/s] 97%|#########6|167470/173481[54:00<01:55,51.95it/s] 97%|#########6|168139/173481[54:13<01:42,51.95it/s]100%|##########|173481/173481[55:55<00:00,51.71it/s]
[32m[0323 01:45:03 @base.py:257][0m Epoch 17 (global_step 7980126) finished, time:3355.20 sec.
[32m[0323 01:45:03 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-7980126.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.51it/s]
16
[32m[0323 01:46:57 @monitor.py:363][0m QueueInput/queue_size: 0.4066
[32m[0323 01:46:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.238
[32m[0323 01:46:57 @monitor.py:363][0m activation-summaries/output-rms: 0.0068156
[32m[0323 01:46:57 @monitor.py:363][0m cross_entropy_loss: 5.2067
[32m[0323 01:46:57 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086888
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61481
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30029
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 01:46:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 01:46:57 @monitor.py:363][0m train-error-top1: 0.97947
[32m[0323 01:46:57 @monitor.py:363][0m val-error-top1: 0.97832
[32m[0323 01:46:57 @monitor.py:363][0m val-utt-error: 0.966
[32m[0323 01:46:57 @monitor.py:363][0m validation_cost: 5.2406
[32m[0323 01:46:57 @monitor.py:363][0m wd_cost: 2.8545e-11
[32m[0323 01:46:57 @group.py:42][0m Callbacks took 114.657 sec in total. InferenceRunner: 114.422sec
[32m[0323 01:46:57 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10940/173481[03:00<44:34,60.78it/s]  7%|6         |11533/173481[03:10<44:24,60.78it/s] 13%|#2        |21774/173481[06:00<41:48,60.48it/s] 13%|#2        |22344/173481[06:10<41:38,60.48it/s] 18%|#7        |31160/173481[09:00<42:21,56.00it/s] 18%|#8        |31698/173481[09:10<42:11,56.00it/s] 23%|##3       |40274/173481[12:00<41:44,53.18it/s] 24%|##3       |40808/173481[12:10<41:34,53.18it/s] 31%|###       |53084/173481[15:00<32:58,60.86it/s] 31%|###1      |53897/173481[15:10<32:44,60.86it/s] 40%|###9      |68739/173481[18:00<24:22,71.60it/s] 40%|###9      |69359/173481[18:11<24:14,71.60it/s] 45%|####5     |78834/173481[21:00<25:04,62.89it/s] 46%|####5     |79393/173481[21:11<24:56,62.89it/s] 51%|#####     |88143/173481[24:00<25:03,56.76it/s] 51%|#####1    |88765/173481[24:11<24:52,56.76it/s] 56%|#####6    |97446/173481[27:00<23:25,54.10it/s] 57%|#####6    |98045/173481[27:11<23:14,54.10it/s] 62%|######1   |106874/173481[30:00<20:51,53.22it/s] 62%|######1   |107532/173481[30:11<20:39,53.22it/s] 67%|######7   |116844/173481[33:00<17:23,54.28it/s] 68%|######7   |117458/173481[33:12<17:12,54.28it/s] 73%|#######3  |126704/173481[36:00<14:17,54.52it/s] 73%|#######3  |127393/173481[36:12<14:05,54.52it/s] 79%|#######9  |137479/173481[39:00<10:30,57.06it/s] 80%|#######9  |138198/173481[39:12<10:18,57.06it/s] 85%|########5 |148074/173481[42:00<07:18,57.94it/s] 86%|########5 |148806/173481[42:12<07:05,57.94it/s] 92%|#########1|158799/173481[45:00<04:09,58.75it/s] 92%|#########1|159512/173481[45:12<03:57,58.75it/s] 98%|#########7|169455/173481[48:00<01:08,58.97it/s] 98%|#########8|170174/173481[48:12<00:56,58.97it/s]100%|##########|173481/173481[49:09<00:00,58.83it/s]
[32m[0323 02:36:06 @base.py:257][0m Epoch 18 (global_step 8153607) finished, time:2949.02 sec.
[32m[0323 02:36:06 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-8153607.
[32m[0323 02:36:07 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.29it/s]
17
[32m[0323 02:38:06 @monitor.py:363][0m QueueInput/queue_size: 0.66032
[32m[0323 02:38:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.21
[32m[0323 02:38:06 @monitor.py:363][0m activation-summaries/output-rms: 0.0069264
[32m[0323 02:38:06 @monitor.py:363][0m cross_entropy_loss: 5.1912
[32m[0323 02:38:06 @monitor.py:363][0m lr: 7.6294e-09
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086886
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6148
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30029
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 02:38:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 02:38:06 @monitor.py:363][0m train-error-top1: 0.97867
[32m[0323 02:38:06 @monitor.py:363][0m val-error-top1: 0.97843
[32m[0323 02:38:06 @monitor.py:363][0m val-utt-error: 0.96594
[32m[0323 02:38:06 @monitor.py:363][0m validation_cost: 5.2382
[32m[0323 02:38:06 @monitor.py:363][0m wd_cost: 2.8545e-11
[32m[0323 02:38:06 @group.py:42][0m Callbacks took 120.054 sec in total. InferenceRunner: 119.689sec
[32m[0323 02:38:06 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17206/173481[03:00<27:14,95.58it/s] 10%|#         |18168/173481[03:10<27:04,95.58it/s] 17%|#7        |29971/173481[06:00<29:22,81.42it/s] 18%|#7        |30674/173481[06:10<29:13,81.42it/s] 24%|##4       |42252/173481[09:00<29:27,74.24it/s] 25%|##4       |42917/173481[09:10<29:18,74.24it/s] 31%|###1      |54150/173481[12:00<28:26,69.93it/s] 32%|###1      |54827/173481[12:10<28:16,69.93it/s] 38%|###7      |65563/173481[15:00<27:02,66.51it/s] 38%|###8      |66297/173481[15:10<26:51,66.51it/s] 44%|####4     |77046/173481[18:00<24:40,65.12it/s] 45%|####4     |77667/173481[18:11<24:31,65.12it/s] 51%|#####     |88433/173481[21:00<22:05,64.17it/s] 51%|#####1    |89133/173481[21:11<21:54,64.17it/s] 58%|#####7    |100028/173481[24:00<19:02,64.29it/s] 58%|#####8    |100754/173481[24:11<18:51,64.29it/s] 64%|######4   |111252/173481[27:00<16:22,63.31it/s] 65%|######4   |112009/173481[27:11<16:10,63.31it/s] 71%|#######   |122849/173481[30:00<13:12,63.86it/s] 71%|#######1  |123632/173481[30:11<13:00,63.86it/s] 78%|#######7  |134461/173481[33:00<10:07,64.19it/s] 78%|#######7  |135237/173481[33:12<09:55,64.19it/s] 84%|########3 |145690/173481[36:00<07:19,63.27it/s] 84%|########4 |146517/173481[36:12<07:06,63.27it/s] 91%|######### |157283/173481[39:00<04:13,63.83it/s] 91%|#########1|158102/173481[39:12<04:00,63.83it/s] 97%|#########6|167578/173481[42:00<01:37,60.33it/s] 97%|#########7|168277/173481[42:12<01:26,60.33it/s]100%|##########|173481/173481[43:43<00:00,66.13it/s]
[32m[0323 03:21:50 @base.py:257][0m Epoch 19 (global_step 8327088) finished, time:2623.46 sec.
[32m[0323 03:21:50 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-8327088.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.46it/s]
18
[32m[0323 03:23:51 @monitor.py:363][0m QueueInput/queue_size: 0.11695
[32m[0323 03:23:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.376
[32m[0323 03:23:51 @monitor.py:363][0m activation-summaries/output-rms: 0.0069098
[32m[0323 03:23:51 @monitor.py:363][0m cross_entropy_loss: 5.1855
[32m[0323 03:23:51 @monitor.py:363][0m lr: 7.6294e-09
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086886
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 03:23:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 03:23:51 @monitor.py:363][0m train-error-top1: 0.97889
[32m[0323 03:23:51 @monitor.py:363][0m val-error-top1: 0.97837
[32m[0323 03:23:51 @monitor.py:363][0m val-utt-error: 0.96648
[32m[0323 03:23:51 @monitor.py:363][0m validation_cost: 5.2389
[32m[0323 03:23:51 @monitor.py:363][0m wd_cost: 5.7089e-12
[32m[0323 03:23:51 @group.py:42][0m Callbacks took 121.235 sec in total. InferenceRunner: 121.083sec
[32m[0323 03:23:51 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17912/173481[03:00<26:03,99.51it/s] 11%|#         |18779/173481[03:10<25:54,99.51it/s] 16%|#6        |28263/173481[06:00<33:12,72.89it/s] 17%|#6        |28868/173481[06:10<33:04,72.89it/s] 23%|##2       |39096/173481[09:00<33:58,65.93it/s] 23%|##2       |39769/173481[09:10<33:48,65.93it/s] 29%|##9       |50467/173481[12:00<31:46,64.51it/s] 29%|##9       |51086/173481[12:10<31:37,64.51it/s] 35%|###5      |61272/173481[15:00<30:04,62.19it/s] 36%|###5      |61971/173481[15:10<29:53,62.19it/s] 42%|####2     |72926/173481[18:00<26:25,63.44it/s] 43%|####2     |74112/173481[18:11<26:06,63.44it/s] 53%|#####3    |92357/173481[21:00<16:55,79.92it/s] 54%|#####3    |93535/173481[21:11<16:40,79.92it/s] 62%|######2   |108291/173481[24:00<12:56,84.00it/s] 63%|######2   |109199/173481[24:11<12:45,84.00it/s] 70%|######9   |120890/173481[27:00<11:28,76.36it/s] 70%|#######   |121660/173481[27:11<11:18,76.36it/s] 77%|#######6  |132893/173481[30:00<09:30,71.19it/s] 77%|#######7  |133638/173481[30:11<09:19,71.19it/s] 84%|########4 |146122/173481[33:00<06:18,72.32it/s] 85%|########4 |146992/173481[33:11<06:06,72.32it/s] 94%|#########3|162510/173481[36:00<02:16,80.61it/s] 94%|#########4|163830/173481[36:12<01:59,80.61it/s][32m[0323 04:02:25 @base.py:257][0m Epoch 20 (global_step 8500569) finished, time:2313.83 sec.
100%|##########|173481/173481[38:33<00:00,74.98it/s]
[32m[0323 04:02:25 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-8500569.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.18it/s]
19
[32m[0323 04:04:22 @monitor.py:363][0m QueueInput/queue_size: 0.47954
[32m[0323 04:04:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.188
[32m[0323 04:04:22 @monitor.py:363][0m activation-summaries/output-rms: 0.006839
[32m[0323 04:04:22 @monitor.py:363][0m cross_entropy_loss: 5.1706
[32m[0323 04:04:22 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086884
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 04:04:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 04:04:22 @monitor.py:363][0m train-error-top1: 0.97788
[32m[0323 04:04:22 @monitor.py:363][0m val-error-top1: 0.97827
[32m[0323 04:04:22 @monitor.py:363][0m val-utt-error: 0.96648
[32m[0323 04:04:22 @monitor.py:363][0m validation_cost: 5.2384
[32m[0323 04:04:22 @monitor.py:363][0m wd_cost: 5.7089e-12
[32m[0323 04:04:22 @group.py:42][0m Callbacks took 117.015 sec in total. InferenceRunner: 116.803sec
[32m[0323 04:04:22 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13695/173481[03:00<35:00,76.08it/s]  8%|8         |14345/173481[03:10<34:51,76.08it/s] 14%|#4        |24961/173481[06:00<36:02,68.68it/s] 15%|#4        |25604/173481[06:10<35:53,68.68it/s] 21%|##        |36211/173481[09:00<34:57,65.43it/s] 21%|##1       |36862/173481[09:10<34:47,65.43it/s] 27%|##7       |46986/173481[12:00<33:43,62.52it/s] 27%|##7       |47572/173481[12:10<33:33,62.52it/s] 33%|###3      |57893/173481[15:00<31:18,61.54it/s] 34%|###3      |58610/173481[15:10<31:06,61.54it/s] 40%|###9      |68906/173481[18:00<28:24,61.36it/s] 40%|####      |69544/173481[18:11<28:13,61.36it/s] 46%|####5     |79386/173481[21:00<26:14,59.74it/s] 46%|####6     |80050/173481[21:11<26:03,59.74it/s] 52%|#####1    |90066/173481[24:00<23:21,59.53it/s] 52%|#####2    |90740/173481[24:11<23:09,59.53it/s] 58%|#####8    |100743/173481[27:00<20:24,59.42it/s] 59%|#####8    |101489/173481[27:11<20:11,59.42it/s] 64%|######4   |111444/173481[30:00<17:23,59.44it/s] 65%|######4   |112133/173481[30:11<17:12,59.44it/s] 70%|#######   |122096/173481[33:00<14:26,59.30it/s] 71%|#######   |122790/173481[33:11<14:14,59.30it/s] 77%|#######6  |132995/173481[36:00<11:15,59.92it/s] 77%|#######7  |133712/173481[36:12<11:03,59.92it/s] 83%|########3 |144239/173481[39:00<07:58,61.17it/s] 84%|########3 |144946/173481[39:12<07:46,61.17it/s] 89%|########9 |154491/173481[42:00<05:21,58.98it/s] 89%|########9 |155187/173481[42:12<05:10,58.98it/s] 95%|#########4|164801/173481[45:00<02:29,58.11it/s] 95%|#########5|165496/173481[45:12<02:17,58.11it/s]100%|##########|173481/173481[47:28<00:00,60.89it/s]
[32m[0323 04:51:51 @base.py:257][0m Epoch 21 (global_step 8674050) finished, time:2848.91 sec.
[32m[0323 04:51:51 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-8674050.
[32m[0323 04:51:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,172.64it/s]
20
[32m[0323 04:53:41 @monitor.py:363][0m QueueInput/queue_size: 0.52601
[32m[0323 04:53:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.393
[32m[0323 04:53:41 @monitor.py:363][0m activation-summaries/output-rms: 0.0068163
[32m[0323 04:53:41 @monitor.py:363][0m cross_entropy_loss: 5.2019
[32m[0323 04:53:41 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086884
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 04:53:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 04:53:41 @monitor.py:363][0m train-error-top1: 0.97878
[32m[0323 04:53:41 @monitor.py:363][0m val-error-top1: 0.97833
[32m[0323 04:53:41 @monitor.py:363][0m val-utt-error: 0.96632
[32m[0323 04:53:41 @monitor.py:363][0m validation_cost: 5.2373
[32m[0323 04:53:41 @monitor.py:363][0m wd_cost: 1.1418e-12
[32m[0323 04:53:41 @group.py:42][0m Callbacks took 110.058 sec in total. InferenceRunner: 109.031sec
[32m[0323 04:53:41 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17379/173481[03:00<26:56,96.54it/s] 10%|#         |18029/173481[03:10<26:50,96.54it/s] 16%|#6        |28175/173481[06:00<32:43,73.99it/s] 17%|#6        |28846/173481[06:10<32:34,73.99it/s] 22%|##2       |38570/173481[09:00<34:40,64.86it/s] 23%|##2       |39128/173481[09:10<34:31,64.86it/s] 28%|##7       |48103/173481[12:00<35:50,58.31it/s] 28%|##8       |48714/173481[12:10<35:39,58.31it/s] 34%|###3      |58575/173481[15:00<32:52,58.24it/s] 34%|###4      |59221/173481[15:10<32:41,58.24it/s] 40%|###9      |69215/173481[18:00<29:37,58.67it/s] 40%|####      |69895/173481[18:11<29:25,58.67it/s] 46%|####6     |80070/173481[21:00<26:10,59.47it/s] 47%|####6     |80774/173481[21:11<25:58,59.47it/s] 52%|#####2    |90888/173481[24:00<23:01,59.79it/s] 53%|#####2    |91579/173481[24:11<22:49,59.79it/s] 59%|#####8    |101555/173481[27:00<20:08,59.52it/s] 59%|#####8    |102242/173481[27:11<19:56,59.52it/s] 65%|######4   |112348/173481[30:00<17:03,59.74it/s] 65%|######5   |113045/173481[30:11<16:51,59.74it/s] 71%|#######   |122535/173481[33:00<14:36,58.11it/s] 71%|#######1  |123189/173481[33:11<14:25,58.11it/s] 76%|#######6  |132524/173481[36:00<12:01,56.77it/s] 77%|#######6  |133189/173481[36:12<11:49,56.77it/s] 82%|########2 |143003/173481[39:00<08:50,57.48it/s] 83%|########2 |143726/173481[39:12<08:37,57.48it/s] 89%|########8 |153611/173481[42:00<05:41,58.20it/s] 89%|########8 |154292/173481[42:12<05:29,58.20it/s] 94%|#########4|163666/173481[45:00<02:52,57.01it/s] 95%|#########4|164358/173481[45:12<02:40,57.01it/s]100%|##########|173481/173481[47:52<00:00,60.39it/s]
[32m[0323 05:41:34 @base.py:257][0m Epoch 22 (global_step 8847531) finished, time:2872.85 sec.
[32m[0323 05:41:34 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-8847531.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,168.24it/s]
21
[32m[0323 05:43:26 @monitor.py:363][0m QueueInput/queue_size: 0.21651
[32m[0323 05:43:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.239
[32m[0323 05:43:26 @monitor.py:363][0m activation-summaries/output-rms: 0.0068192
[32m[0323 05:43:26 @monitor.py:363][0m cross_entropy_loss: 5.2043
[32m[0323 05:43:26 @monitor.py:363][0m lr: 3.8147e-09
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086884
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 05:43:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 05:43:26 @monitor.py:363][0m train-error-top1: 0.97906
[32m[0323 05:43:26 @monitor.py:363][0m val-error-top1: 0.97827
[32m[0323 05:43:26 @monitor.py:363][0m val-utt-error: 0.96573
[32m[0323 05:43:26 @monitor.py:363][0m validation_cost: 5.2393
[32m[0323 05:43:26 @monitor.py:363][0m wd_cost: 1.1418e-12
[32m[0323 05:43:26 @group.py:42][0m Callbacks took 112.016 sec in total. InferenceRunner: 111.890sec
[32m[0323 05:43:26 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17768/173481[03:00<26:17,98.71it/s] 11%|#         |18422/173481[03:10<26:10,98.71it/s] 17%|#6        |29051/173481[06:00<31:23,76.67it/s] 17%|#7        |29618/173481[06:10<31:16,76.67it/s] 23%|##2       |39139/173481[09:00<34:34,64.75it/s] 23%|##2       |39704/173481[09:10<34:26,64.75it/s] 30%|###       |52067/173481[12:00<29:42,68.10it/s] 30%|###       |52813/173481[12:10<29:31,68.10it/s] 39%|###9      |67658/173481[15:00<23:07,76.25it/s] 40%|###9      |68670/173481[15:10<22:54,76.25it/s] 46%|####5     |78947/173481[18:00<22:53,68.82it/s] 46%|####5     |79631/173481[18:11<22:43,68.82it/s] 52%|#####1    |90151/173481[21:00<21:14,65.37it/s] 52%|#####2    |90863/173481[21:11<21:03,65.37it/s] 58%|#####8    |101180/173481[24:00<19:03,63.25it/s] 59%|#####8    |101831/173481[24:11<18:52,63.25it/s] 65%|######4   |112232/173481[27:00<16:22,62.31it/s] 65%|######5   |112974/173481[27:11<16:11,62.31it/s] 71%|#######1  |123211/173481[30:00<13:35,61.64it/s] 71%|#######1  |123892/173481[30:11<13:24,61.64it/s] 77%|#######7  |134266/173481[33:00<10:37,61.53it/s] 78%|#######7  |134963/173481[33:12<10:26,61.53it/s] 84%|########3 |145272/173481[36:00<07:39,61.34it/s] 84%|########4 |145991/173481[36:12<07:28,61.34it/s] 90%|######### |156219/173481[39:00<04:42,61.06it/s] 90%|######### |156994/173481[39:12<04:29,61.06it/s] 97%|#########6|167413/173481[42:00<01:38,61.62it/s] 97%|#########6|168173/173481[42:12<01:26,61.62it/s]100%|##########|173481/173481[43:39<00:00,66.22it/s]
[32m[0323 06:27:06 @base.py:257][0m Epoch 23 (global_step 9021012) finished, time:2619.89 sec.
[32m[0323 06:27:06 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-9021012.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,177.14it/s]
22
[32m[0323 06:28:52 @monitor.py:363][0m QueueInput/queue_size: 0.79835
[32m[0323 06:28:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.206
[32m[0323 06:28:52 @monitor.py:363][0m activation-summaries/output-rms: 0.006932
[32m[0323 06:28:52 @monitor.py:363][0m cross_entropy_loss: 5.1903
[32m[0323 06:28:52 @monitor.py:363][0m lr: 1.9073e-09
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086884
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 06:28:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 06:28:52 @monitor.py:363][0m train-error-top1: 0.97965
[32m[0323 06:28:52 @monitor.py:363][0m val-error-top1: 0.9784
[32m[0323 06:28:52 @monitor.py:363][0m val-utt-error: 0.96594
[32m[0323 06:28:52 @monitor.py:363][0m validation_cost: 5.2372
[32m[0323 06:28:52 @monitor.py:363][0m wd_cost: 1.1418e-12
[32m[0323 06:28:52 @group.py:42][0m Callbacks took 106.385 sec in total. InferenceRunner: 106.269sec
[32m[0323 06:28:52 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16873/173481[03:00<27:50,93.74it/s] 10%|#         |17837/173481[03:10<27:40,93.74it/s] 17%|#7        |29517/173481[06:00<29:52,80.31it/s] 17%|#7        |30244/173481[06:10<29:43,80.31it/s] 24%|##4       |42440/173481[09:00<28:48,75.81it/s] 25%|##4       |43197/173481[09:10<28:38,75.81it/s] 32%|###2      |55514/173481[12:00<26:30,74.18it/s] 32%|###2      |56140/173481[12:10<26:21,74.18it/s] 39%|###9      |68188/173481[15:00<24:17,72.25it/s] 40%|###9      |68965/173481[15:10<24:06,72.25it/s] 47%|####6     |81288/173481[18:00<21:11,72.50it/s] 47%|####7     |82064/173481[18:10<21:00,72.50it/s] 54%|#####4    |94528/173481[21:00<18:01,73.02it/s] 55%|#####4    |95354/173481[21:11<17:49,73.02it/s] 62%|######2   |108038/173481[24:00<14:44,74.02it/s] 63%|######2   |108773/173481[24:11<14:34,74.02it/s] 69%|######8   |119628/173481[27:00<13:02,68.86it/s] 69%|######9   |120340/173481[27:11<12:51,68.86it/s] 76%|#######5  |131233/173481[30:00<10:34,66.59it/s] 76%|#######6  |131939/173481[30:11<10:23,66.59it/s] 82%|########2 |142333/173481[33:00<08:06,64.03it/s] 82%|########2 |142970/173481[33:11<07:56,64.03it/s] 88%|########8 |153338/173481[36:00<05:22,62.55it/s] 89%|########8 |154192/173481[36:12<05:08,62.55it/s] 95%|#########4|164803/173481[39:00<02:17,63.11it/s] 95%|#########5|165542/173481[39:12<02:05,63.11it/s]100%|##########|173481/173481[41:36<00:00,69.50it/s]
[32m[0323 07:10:28 @base.py:257][0m Epoch 24 (global_step 9194493) finished, time:2496.30 sec.
[32m[0323 07:10:28 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-9194493.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,170.59it/s]
23
[32m[0323 07:12:19 @monitor.py:363][0m QueueInput/queue_size: 0.45493
[32m[0323 07:12:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.377
[32m[0323 07:12:19 @monitor.py:363][0m activation-summaries/output-rms: 0.0069107
[32m[0323 07:12:19 @monitor.py:363][0m cross_entropy_loss: 5.1847
[32m[0323 07:12:19 @monitor.py:363][0m lr: 1.9073e-09
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086884
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 07:12:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 07:12:19 @monitor.py:363][0m train-error-top1: 0.97921
[32m[0323 07:12:19 @monitor.py:363][0m val-error-top1: 0.97835
[32m[0323 07:12:19 @monitor.py:363][0m val-utt-error: 0.96658
[32m[0323 07:12:19 @monitor.py:363][0m validation_cost: 5.2382
[32m[0323 07:12:19 @monitor.py:363][0m wd_cost: 2.2836e-13
[32m[0323 07:12:19 @group.py:42][0m Callbacks took 110.496 sec in total. InferenceRunner: 110.344sec
[32m[0323 07:12:19 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17824/173481[03:00<26:12,99.02it/s] 11%|#         |18545/173481[03:10<26:04,99.02it/s] 17%|#6        |28888/173481[06:00<31:46,75.85it/s] 17%|#7        |29555/173481[06:10<31:37,75.85it/s] 23%|##3       |40447/173481[09:00<31:53,69.54it/s] 24%|##3       |41160/173481[09:10<31:42,69.54it/s] 30%|##9       |51988/173481[12:00<30:20,66.72it/s] 30%|###       |52686/173481[12:10<30:10,66.72it/s] 37%|###6      |63547/173481[15:00<28:00,65.43it/s] 37%|###7      |64254/173481[15:10<27:49,65.43it/s] 43%|####3     |74608/173481[18:00<26:00,63.38it/s] 43%|####3     |75276/173481[18:11<25:49,63.38it/s] 51%|#####1    |88914/173481[21:00<19:59,70.52it/s] 52%|#####1    |90149/173481[21:11<19:41,70.52it/s] 60%|#####9    |103402/173481[24:00<15:32,75.17it/s] 60%|#####9    |104072/173481[24:11<15:23,75.17it/s] 66%|######6   |114752/173481[27:00<14:16,68.58it/s] 67%|######6   |115436/173481[27:11<14:06,68.58it/s] 73%|#######3  |126911/173481[30:00<11:24,68.06it/s] 74%|#######3  |127896/173481[30:11<11:09,68.06it/s] 80%|########  |138989/173481[33:00<08:30,67.58it/s] 81%|########  |139726/173481[33:11<08:19,67.58it/s] 87%|########6 |150288/173481[36:00<05:56,65.08it/s] 87%|########7 |151040/173481[36:12<05:44,65.08it/s] 93%|#########2|161201/173481[39:00<03:15,62.78it/s] 93%|#########3|161910/173481[39:12<03:04,62.78it/s] 99%|#########9|172252/173481[42:00<00:19,62.07it/s]100%|#########9|172941/173481[42:12<00:08,62.07it/s]100%|##########|173481/173481[42:21<00:00,68.26it/s]
[32m[0323 07:54:40 @base.py:257][0m Epoch 25 (global_step 9367974) finished, time:2541.31 sec.
[32m[0323 07:54:40 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-9367974.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.94it/s]
24
[32m[0323 07:56:47 @monitor.py:363][0m QueueInput/queue_size: 0.21255
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.189
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/output-rms: 0.0068412
[32m[0323 07:56:47 @monitor.py:363][0m cross_entropy_loss: 5.1702
[32m[0323 07:56:47 @monitor.py:363][0m lr: 1.9073e-09
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086884
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29564
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 07:56:47 @monitor.py:363][0m train-error-top1: 0.97764
[32m[0323 07:56:47 @monitor.py:363][0m val-error-top1: 0.97825
[32m[0323 07:56:47 @monitor.py:363][0m val-utt-error: 0.96589
[32m[0323 07:56:47 @monitor.py:363][0m validation_cost: 5.238
[32m[0323 07:56:47 @monitor.py:363][0m wd_cost: 2.2836e-13
[32m[0323 07:56:47 @group.py:42][0m Callbacks took 127.314 sec in total. InferenceRunner: 127.235sec
[32m[0323 07:56:47 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12884/173481[03:00<37:23,71.58it/s]  8%|7         |13535/173481[03:10<37:14,71.58it/s] 14%|#3        |24218/173481[06:00<37:07,67.00it/s] 14%|#4        |24870/173481[06:10<36:58,67.00it/s] 20%|##        |35417/173481[09:00<35:39,64.52it/s] 21%|##        |36055/173481[09:10<35:30,64.52it/s] 27%|##6       |46425/173481[12:00<33:43,62.79it/s] 27%|##7       |47050/173481[12:10<33:33,62.79it/s] 33%|###2      |57065/173481[15:00<31:51,60.89it/s] 33%|###3      |57720/173481[15:10<31:41,60.89it/s] 39%|###9      |68146/173481[18:00<28:40,61.22it/s] 40%|###9      |68802/173481[18:11<28:29,61.22it/s] 45%|####5     |78792/173481[21:00<26:13,60.16it/s] 46%|####5     |79445/173481[21:11<26:03,60.16it/s] 52%|#####1    |89374/173481[24:00<23:34,59.47it/s] 52%|#####1    |90035/173481[24:11<23:23,59.47it/s] 58%|#####7    |99802/173481[27:00<20:55,58.69it/s] 58%|#####7    |100485/173481[27:11<20:43,58.69it/s] 64%|######3   |110441/173481[30:00<17:50,58.89it/s] 64%|######4   |111099/173481[30:11<17:39,58.89it/s] 70%|######9   |120816/173481[33:00<15:04,58.25it/s] 70%|#######   |121505/173481[33:11<14:52,58.25it/s] 76%|#######5  |131521/173481[36:00<11:53,58.84it/s] 76%|#######6  |132200/173481[36:12<11:41,58.84it/s] 82%|########1 |142221/173481[39:00<08:48,59.13it/s] 82%|########2 |142945/173481[39:12<08:36,59.13it/s] 88%|########8 |152777/173481[42:00<05:51,58.89it/s] 88%|########8 |153510/173481[42:12<05:39,58.89it/s] 94%|#########4|163281/173481[45:00<02:54,58.61it/s] 95%|#########4|163990/173481[45:12<02:41,58.61it/s]100%|##########|173481/173481[47:54<00:00,60.34it/s]
[32m[0323 08:44:42 @base.py:257][0m Epoch 26 (global_step 9541455) finished, time:2874.89 sec.
[32m[0323 08:44:42 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-9541455.
[32m[0323 08:44:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.39it/s]
25
[32m[0323 08:46:47 @monitor.py:363][0m QueueInput/queue_size: 0.63345
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.394
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/output-rms: 0.0068186
[32m[0323 08:46:47 @monitor.py:363][0m cross_entropy_loss: 5.2016
[32m[0323 08:46:47 @monitor.py:363][0m lr: 9.5367e-10
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086885
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29565
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 08:46:47 @monitor.py:363][0m train-error-top1: 0.97912
[32m[0323 08:46:47 @monitor.py:363][0m val-error-top1: 0.9783
[32m[0323 08:46:47 @monitor.py:363][0m val-utt-error: 0.96616
[32m[0323 08:46:47 @monitor.py:363][0m validation_cost: 5.2371
[32m[0323 08:46:47 @monitor.py:363][0m wd_cost: 2.2836e-13
[32m[0323 08:46:47 @group.py:42][0m Callbacks took 124.779 sec in total. InferenceRunner: 124.345sec
[32m[0323 08:46:47 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16634/173481[03:00<28:17,92.41it/s] 10%|#         |17508/173481[03:10<28:07,92.41it/s] 16%|#6        |27790/173481[06:00<32:43,74.19it/s] 16%|#6        |28356/173481[06:10<32:36,74.19it/s] 21%|##1       |37103/173481[09:00<37:17,60.96it/s] 22%|##1       |37644/173481[09:10<37:08,60.96it/s] 27%|##6       |46751/173481[12:00<37:01,57.04it/s] 27%|##7       |47334/173481[12:10<36:51,57.04it/s] 33%|###2      |57096/173481[15:00<33:52,57.26it/s] 33%|###3      |57777/173481[15:10<33:40,57.26it/s] 39%|###9      |68103/173481[18:00<29:41,59.14it/s] 40%|###9      |68767/173481[18:11<29:30,59.14it/s] 46%|####5     |79200/173481[21:00<26:01,60.37it/s] 46%|####6     |79880/173481[21:11<25:50,60.37it/s] 52%|#####2    |90515/173481[24:00<22:27,61.57it/s] 53%|#####2    |91213/173481[24:11<22:16,61.57it/s] 58%|#####8    |101420/173481[27:00<19:40,61.07it/s] 59%|#####8    |102104/173481[27:11<19:28,61.07it/s] 65%|######4   |112545/173481[30:00<16:32,61.43it/s] 65%|######5   |113263/173481[30:11<16:20,61.43it/s] 71%|#######1  |123431/173481[33:00<13:41,60.95it/s] 72%|#######1  |124139/173481[33:11<13:29,60.95it/s] 77%|#######7  |134310/173481[36:00<10:45,60.67it/s] 78%|#######7  |134985/173481[36:12<10:34,60.67it/s] 84%|########3 |145280/173481[39:00<07:43,60.81it/s] 84%|########4 |145940/173481[39:12<07:32,60.81it/s] 90%|######### |156149/173481[42:00<04:46,60.60it/s] 90%|######### |156933/173481[42:12<04:33,60.60it/s] 96%|#########6|167270/173481[45:00<01:41,61.18it/s] 97%|#########6|168020/173481[45:12<01:29,61.18it/s]100%|##########|173481/173481[46:39<00:00,61.96it/s]
[32m[0323 09:33:27 @base.py:257][0m Epoch 27 (global_step 9714936) finished, time:2799.73 sec.
[32m[0323 09:33:27 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-9714936.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.59it/s]
26
[32m[0323 09:35:26 @monitor.py:363][0m QueueInput/queue_size: 0.31623
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.24
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/output-rms: 0.0068186
[32m[0323 09:35:26 @monitor.py:363][0m cross_entropy_loss: 5.2042
[32m[0323 09:35:26 @monitor.py:363][0m lr: 9.5367e-10
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086885
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29565
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 09:35:26 @monitor.py:363][0m train-error-top1: 0.97882
[32m[0323 09:35:26 @monitor.py:363][0m val-error-top1: 0.97827
[32m[0323 09:35:26 @monitor.py:363][0m val-utt-error: 0.96525
[32m[0323 09:35:26 @monitor.py:363][0m validation_cost: 5.2391
[32m[0323 09:35:26 @monitor.py:363][0m wd_cost: 4.5671e-14
[32m[0323 09:35:26 @group.py:42][0m Callbacks took 118.802 sec in total. InferenceRunner: 118.693sec
[32m[0323 09:35:26 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16587/173481[03:00<28:22,92.15it/s] 10%|#         |17577/173481[03:10<28:11,92.15it/s] 17%|#7        |30114/173481[06:00<28:51,82.78it/s] 18%|#7        |30746/173481[06:10<28:44,82.78it/s] 24%|##3       |41354/173481[09:00<30:56,71.19it/s] 24%|##4       |42025/173481[09:10<30:46,71.19it/s] 33%|###2      |56837/173481[12:00<24:57,77.90it/s] 33%|###3      |57775/173481[12:10<24:45,77.90it/s] 42%|####2     |73589/173481[15:00<19:37,84.81it/s] 43%|####2     |74555/173481[15:10<19:26,84.81it/s] 52%|#####1    |89848/173481[18:00<15:56,87.48it/s] 52%|#####2    |90875/173481[18:11<15:44,87.48it/s] 61%|######1   |106072/173481[21:00<12:39,88.78it/s] 62%|######1   |107039/173481[21:11<12:28,88.78it/s] 71%|#######   |122336/173481[24:00<09:31,89.56it/s] 71%|#######1  |123379/173481[24:11<09:19,89.56it/s] 80%|#######9  |138581/173481[27:00<06:28,89.90it/s] 80%|########  |139639/173481[27:11<06:16,89.90it/s] 88%|########7 |152044/173481[30:00<04:22,81.65it/s] 88%|########8 |152798/173481[30:11<04:13,81.65it/s] 94%|#########4|163615/173481[33:00<02:17,71.93it/s] 95%|#########4|164376/173481[33:11<02:06,71.93it/s]100%|##########|173481/173481[35:22<00:00,81.73it/s]
[32m[0323 10:10:48 @base.py:257][0m Epoch 28 (global_step 9888417) finished, time:2122.53 sec.
[32m[0323 10:10:48 @saver.py:84][0m Model saved to train_log/cnn_w_8_a_8_quant_ends_True_preload/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,175.87it/s]
27
[32m[0323 10:12:35 @monitor.py:363][0m QueueInput/queue_size: 0.77344
[32m[0323 10:12:35 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.205
[32m[0323 10:12:35 @monitor.py:363][0m activation-summaries/output-rms: 0.0069313
[32m[0323 10:12:35 @monitor.py:363][0m cross_entropy_loss: 5.1902
[32m[0323 10:12:35 @monitor.py:363][0m lr: 9.5367e-10
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/conv0/W-rms: 0.67694
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/conv0/b-rms: 0.00086886
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.61479
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.4115
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/linear0/W-rms: 0.34173
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/linear0/b-rms: 0.085677
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3003
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/linear1/b-rms: 0.091136
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29565
[32m[0323 10:12:35 @monitor.py:363][0m param-summary/linear2/b-rms: 0.083938
[32m[0323 10:12:35 @monitor.py:363][0m train-error-top1: 0.97978
[32m[0323 10:12:35 @monitor.py:363][0m val-error-top1: 0.9784
[32m[0323 10:12:35 @monitor.py:363][0m val-utt-error: 0.96594
[32m[0323 10:12:35 @monitor.py:363][0m validation_cost: 5.2371
[32m[0323 10:12:35 @monitor.py:363][0m wd_cost: 4.5671e-14
[32m[0323 10:12:35 @group.py:42][0m Callbacks took 107.120 sec in total. InferenceRunner: 107.032sec
[32m[0323 10:12:35 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17338/173481[03:00<27:01,96.32it/s] 11%|#         |18312/173481[03:10<26:50,96.32it/s] 19%|#8        |32528/173481[06:00<26:07,89.92it/s] 19%|#9        |33252/173481[06:10<25:59,89.92it/s] 26%|##6       |45377/173481[09:00<26:49,79.58it/s] 27%|##6       |46092/173481[09:10<26:40,79.58it/s] 34%|###3      |58512/173481[12:00<25:10,76.13it/s] 34%|###4      |59337/173481[12:10<24:59,76.13it/s] 42%|####1     |72325/173481[15:00<22:03,76.43it/s] 42%|####2     |73164/173481[15:10<21:52,76.43it/s] 50%|####9     |86335/173481[18:00<18:49,77.13it/s] 50%|#####     |87142/173481[18:11<18:39,77.13it/s] 58%|#####7    |100361/173481[21:00<15:43,77.52it/s] 58%|#####8    |101247/173481[21:11<15:31,77.52it/s] 66%|######6   |115201/173481[24:00<12:09,79.91it/s] 67%|######6   |116190/173481[24:11<11:56,79.91it/s]srun: got SIGCONT
slurmstepd: *** STEP 82365.0 ON sls-titan-10 CANCELLED AT 2018-03-23T10:38:12 ***
slurmstepd: *** JOB 82365 ON sls-titan-10 CANCELLED AT 2018-03-23T10:38:12 ***
srun: forcing job termination
