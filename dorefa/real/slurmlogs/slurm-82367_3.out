sls-titanx-1 3
SLURM_JOBID=82367
SLURM_TASKID=3
[32m[0322 11:10:00 @logger.py:74][0m Argv: drf_run.py --model_name=fcn2 --bitw=16 --bita=16 --quant_ends=True --load_ckpt=train_log/fcn2_w_16_a_32_quant_ends_True/checkpoint
[32m[0322 11:11:57 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0322 11:11:57 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0322 11:11:57 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0322 11:11:57 @drf_run.py:166][0m Using host: sls-titanx-1
[32m[0322 11:11:57 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0322 11:11:57 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0322 11:11:57 @drf_run.py:188][0m Using GPU: 3
[32m[0322 11:11:57 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0322 11:11:57 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0322 11:11:57 @training.py:108][0m Building graph for training tower 0 ...
[32m[0322 11:11:57 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear0 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear1 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear1 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear2 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear2 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m linear3 input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0322 11:11:57 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0322 11:11:57 @registry.py:130][0m linear3 output: [None, 504]
[32m[0322 11:11:57 @registry.py:122][0m last_linear input: [None, 504]
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 11:11:57 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 11:11:57 @registry.py:130][0m last_linear output: [None, 255]
[32m[0322 11:11:57 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:11:57 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0322 11:11:57 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0322 11:11:57 @drf_run.py:123][0m Parameter count: {'mults': 1398600, 'weights': 1398855}
[32m[0322 11:11:58 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 504]  504000
linear0/b:0         [504]           504
linear0/bn/beta:0   [504]           504
linear0/bn/gamma:0  [504]           504
linear1/W:0         [504, 504]   254016
linear1/b:0         [504]           504
linear1/bn/beta:0   [504]           504
linear1/bn/gamma:0  [504]           504
linear2/W:0         [504, 504]   254016
linear2/b:0         [504]           504
linear2/bn/beta:0   [504]           504
linear2/bn/gamma:0  [504]           504
linear3/W:0         [504, 504]   254016
linear3/b:0         [504]           504
linear3/bn/beta:0   [504]           504
linear3/bn/gamma:0  [504]           504
last_linear/W:0     [504, 255]   128520
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=1400871, size=5.34MB[0m
[32m[0322 11:11:58 @base.py:196][0m Setup callbacks graph ...
[32m[0322 11:11:58 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0322 11:11:58 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0322 11:11:58 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0322 11:11:59 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0322 11:11:59 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0322 11:11:59 @drf_run.py:123][0m Parameter count: {'mults': 2797200, 'weights': 2797710}
[32m[0322 11:11:59 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0322 11:11:59 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0322 11:11:59 @base.py:212][0m Creating the session ...
2018-03-22 11:12:00.047207: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-22 11:12:07.581590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:09:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-22 11:12:07.581654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:09:00.0, compute capability: 6.1)
[32m[0322 11:12:08 @base.py:220][0m Initializing the session ...
[32m[0322 11:12:08 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn2_w_16_a_32_quant_ends_True/model-3296139 ...
[32m[0322 11:12:09 @base.py:227][0m Graph Finalized.
[32m[0322 11:12:09 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0322 11:12:09 @steps.py:127][0m Start training with global_step=3296139
[32m[0322 11:12:12 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20510/173481[03:00<22:22,113.94it/s] 12%|#2        |21647/173481[03:10<22:12,113.94it/s] 23%|##3       |40696/173481[06:00<19:34,113.03it/s] 24%|##4       |41855/173481[06:10<19:24,113.03it/s] 35%|###4      |60587/173481[09:00<16:50,111.75it/s] 36%|###5      |61688/173481[09:10<16:40,111.75it/s] 46%|####6     |80323/173481[12:00<14:01,110.69it/s] 47%|####6     |81425/173481[12:10<13:51,110.69it/s] 53%|#####2    |91261/173481[15:00<17:27,78.46it/s]  53%|#####2    |91795/173481[15:10<17:21,78.46it/s] 58%|#####7    |99903/173481[18:00<20:35,59.57it/s] 58%|#####7    |100410/173481[18:10<20:26,59.57it/s] 63%|######2   |108768/173481[21:00<20:00,53.92it/s] 63%|######3   |109360/173481[21:11<19:49,53.92it/s] 68%|######8   |118021/173481[24:00<17:33,52.63it/s] 68%|######8   |118644/173481[24:11<17:21,52.63it/s] 74%|#######3  |127596/173481[27:00<14:27,52.91it/s] 74%|#######3  |128185/173481[27:11<14:16,52.91it/s] 79%|#######8  |136992/173481[30:00<11:34,52.55it/s] 79%|#######9  |137570/173481[30:11<11:23,52.55it/s] 84%|########4 |146151/173481[33:00<08:48,51.70it/s] 85%|########4 |146707/173481[33:11<08:37,51.70it/s] 89%|########9 |154575/173481[36:00<06:24,49.13it/s] 89%|########9 |155070/173481[36:11<06:14,49.13it/s] 94%|#########3|162646/173481[39:00<03:51,46.88it/s] 94%|#########4|163230/173481[39:12<03:38,46.88it/s] 99%|#########8|171106/173481[42:00<00:50,46.93it/s] 99%|#########8|171690/173481[42:12<00:38,46.93it/s]100%|##########|173481/173481[42:47<00:00,67.56it/s]
[32m[0322 11:54:59 @base.py:257][0m Epoch 1 (global_step 3469620) finished, time:2567.86 sec.
[32m[0322 11:55:00 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-3469620.
  0%|          |0/18822[00:00<?,?it/s] 79%|#######8  |14808/18822[03:00<00:48,82.27it/s] 83%|########2 |15543/18822[03:10<00:39,82.27it/s]100%|##########|18822/18822[03:54<00:00,80.25it/s]
0
[32m[0322 11:58:55 @monitor.py:363][0m QueueInput/queue_size: 2.0953
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.443
[32m[0322 11:58:55 @monitor.py:363][0m activation-summaries/output-rms: 0.010184
[32m[0322 11:58:55 @monitor.py:363][0m cross_entropy_loss: 4.3621
[32m[0322 11:58:55 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.63969
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1582
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.26987
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26712
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20656
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20129
[32m[0322 11:58:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 11:58:55 @monitor.py:363][0m train-error-top1: 0.92695
[32m[0322 11:58:55 @monitor.py:363][0m val-error-top1: 0.92633
[32m[0322 11:58:55 @monitor.py:363][0m val-utt-error: 0.76772
[32m[0322 11:58:55 @monitor.py:363][0m validation_cost: 4.3978
[32m[0322 11:58:55 @monitor.py:363][0m wd_cost: 0.00016455
[32m[0322 11:58:55 @group.py:42][0m Callbacks took 235.162 sec in total. InferenceRunner: 234.544sec
[32m[0322 11:58:55 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |8901/173481[03:00<55:28,49.45it/s]  5%|5         |9399/173481[03:10<55:18,49.45it/s] 10%|#         |18125/173481[06:00<51:26,50.33it/s] 11%|#         |18659/173481[06:10<51:16,50.33it/s] 16%|#5        |27456/173481[09:00<47:39,51.07it/s] 16%|#6        |28002/173481[09:10<47:28,51.07it/s] 21%|##        |36305/173481[12:00<45:38,50.09it/s] 21%|##1       |36809/173481[12:10<45:28,50.09it/s] 26%|##5       |44645/173481[15:00<44:36,48.14it/s] 26%|##6       |45148/173481[15:10<44:26,48.14it/s] 31%|###       |53195/173481[18:00<41:55,47.82it/s] 31%|###       |53714/173481[18:10<41:44,47.82it/s] 36%|###5      |62205/173481[21:00<37:55,48.91it/s] 36%|###6      |62789/173481[21:10<37:43,48.91it/s] 41%|####      |70507/173481[24:00<36:09,47.47it/s] 41%|####      |71054/173481[24:11<35:57,47.47it/s] 46%|####6     |79975/173481[27:00<31:13,49.90it/s] 46%|####6     |80584/173481[27:11<31:01,49.90it/s] 51%|#####1    |89315/173481[30:00<27:34,50.87it/s] 52%|#####1    |89894/173481[30:11<27:23,50.87it/s] 57%|#####7    |99125/173481[33:00<23:33,52.62it/s] 57%|#####7    |99693/173481[33:11<23:22,52.62it/s] 63%|######2   |108575/173481[36:00<20:35,52.55it/s] 63%|######2   |109150/173481[36:11<20:24,52.55it/s] 68%|######7   |117190/173481[39:00<18:43,50.09it/s] 68%|######7   |117739/173481[39:11<18:32,50.09it/s] 73%|#######2  |126311/173481[42:00<15:36,50.38it/s] 73%|#######3  |126894/173481[42:11<15:24,50.38it/s] 78%|#######8  |135395/173481[45:00<12:35,50.42it/s] 78%|#######8  |136069/173481[45:12<12:22,50.42it/s] 84%|########3 |144930/173481[48:00<09:12,51.66it/s] 84%|########3 |145501/173481[48:12<09:01,51.66it/s] 89%|########8 |153690/173481[51:00<06:34,50.11it/s] 89%|########8 |154234/173481[51:12<06:24,50.11it/s] 94%|#########3|162861/173481[54:00<03:30,50.53it/s] 94%|#########4|163470/173481[54:12<03:18,50.53it/s]100%|#########9|172641/173481[57:00<00:16,52.36it/s]100%|#########9|173408/173481[57:12<00:01,52.36it/s]100%|##########|173481/173481[57:13<00:00,50.52it/s]
[32m[0322 12:56:09 @base.py:257][0m Epoch 2 (global_step 3643101) finished, time:3433.94 sec.
[32m[0322 12:56:09 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-3643101.
[32m[0322 12:56:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,163.88it/s]
1
[32m[0322 12:58:05 @monitor.py:363][0m QueueInput/queue_size: 0.64006
[32m[0322 12:58:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.673
[32m[0322 12:58:05 @monitor.py:363][0m activation-summaries/output-rms: 0.013577
[32m[0322 12:58:05 @monitor.py:363][0m cross_entropy_loss: 3.8271
[32m[0322 12:58:05 @monitor.py:363][0m lr: 7.8125e-06
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.64628
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1571
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27073
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26748
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20675
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20329
[32m[0322 12:58:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 12:58:05 @monitor.py:363][0m train-error-top1: 0.86565
[32m[0322 12:58:05 @monitor.py:363][0m val-error-top1: 0.8685
[32m[0322 12:58:05 @monitor.py:363][0m val-utt-error: 0.59595
[32m[0322 12:58:05 @monitor.py:363][0m validation_cost: 3.8954
[32m[0322 12:58:05 @monitor.py:363][0m wd_cost: 0.00016659
[32m[0322 12:58:05 @group.py:42][0m Callbacks took 116.590 sec in total. InferenceRunner: 114.864sec
[32m[0322 12:58:05 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9769/173481[03:00<50:16,54.27it/s]  6%|5         |10328/173481[03:10<50:06,54.27it/s] 11%|#1        |19938/173481[06:00<46:13,55.36it/s] 12%|#1        |20553/173481[06:10<46:02,55.36it/s] 17%|#6        |28824/173481[09:00<46:12,52.18it/s] 17%|#6        |29313/173481[09:10<46:02,52.18it/s] 22%|##1       |37809/173481[12:00<44:19,51.02it/s] 22%|##2       |38363/173481[12:10<44:08,51.02it/s] 27%|##6       |46534/173481[15:00<42:33,49.71it/s] 27%|##7       |47034/173481[15:10<42:23,49.71it/s] 32%|###2      |55898/173481[18:00<38:33,50.84it/s] 33%|###2      |56473/173481[18:10<38:21,50.84it/s] 38%|###7      |65127/173481[21:00<35:22,51.05it/s] 38%|###7      |65693/173481[21:11<35:11,51.05it/s] 43%|####3     |75435/173481[24:00<30:16,53.98it/s] 44%|####3     |76099/173481[24:11<30:04,53.98it/s] 49%|####9     |85598/173481[27:00<26:32,55.19it/s] 50%|####9     |86193/173481[27:11<26:21,55.19it/s] 55%|#####4    |95156/173481[30:00<24:07,54.13it/s] 55%|#####5    |95738/173481[30:11<23:56,54.13it/s] 60%|######    |104526/173481[33:00<21:39,53.07it/s] 61%|######    |105120/173481[33:11<21:28,53.07it/s] 66%|######5   |114294/173481[36:00<18:23,53.65it/s] 66%|######6   |114918/173481[36:11<18:11,53.65it/s] 71%|#######1  |123951/173481[39:00<15:23,53.65it/s] 72%|#######1  |124623/173481[39:11<15:10,53.65it/s] 77%|#######7  |134353/173481[42:00<11:43,55.64it/s] 78%|#######7  |135098/173481[42:12<11:29,55.64it/s] 83%|########3 |144639/173481[45:00<08:31,56.38it/s] 84%|########3 |145301/173481[45:12<08:19,56.38it/s] 89%|########9 |154810/173481[48:00<05:30,56.44it/s] 90%|########9 |155482/173481[48:12<05:18,56.44it/s] 95%|#########4|164733/173481[51:00<02:36,55.78it/s] 95%|#########5|165228/173481[51:12<02:27,55.78it/s]100%|##########|173481/173481[53:40<00:00,53.87it/s]
[32m[0322 13:51:46 @base.py:257][0m Epoch 3 (global_step 3816582) finished, time:3220.47 sec.
[32m[0322 13:51:46 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-3816582.
[32m[0322 13:51:47 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.31it/s]
2
[32m[0322 13:53:34 @monitor.py:363][0m QueueInput/queue_size: 0.54265
[32m[0322 13:53:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.304
[32m[0322 13:53:34 @monitor.py:363][0m activation-summaries/output-rms: 0.016176
[32m[0322 13:53:34 @monitor.py:363][0m cross_entropy_loss: 3.5642
[32m[0322 13:53:34 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.65355
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1568
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27167
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2679
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20704
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20447
[32m[0322 13:53:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 13:53:34 @monitor.py:363][0m train-error-top1: 0.82115
[32m[0322 13:53:34 @monitor.py:363][0m val-error-top1: 0.8263
[32m[0322 13:53:34 @monitor.py:363][0m val-utt-error: 0.49708
[32m[0322 13:53:34 @monitor.py:363][0m validation_cost: 3.6064
[32m[0322 13:53:34 @monitor.py:363][0m wd_cost: 0.00016874
[32m[0322 13:53:34 @group.py:42][0m Callbacks took 108.259 sec in total. InferenceRunner: 106.772sec
[32m[0322 13:53:34 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10043/173481[03:00<48:50,55.78it/s]  6%|6         |10499/173481[03:10<48:42,55.78it/s] 11%|#1        |19354/173481[06:00<47:51,53.67it/s] 11%|#1        |19897/173481[06:10<47:41,53.67it/s] 17%|#7        |30039/173481[09:00<42:24,56.37it/s] 18%|#7        |30662/173481[09:10<42:13,56.37it/s] 24%|##3       |40803/173481[12:00<38:06,58.04it/s] 24%|##3       |41436/173481[12:10<37:55,58.04it/s] 29%|##9       |51063/173481[15:00<35:28,57.51it/s] 30%|##9       |51657/173481[15:10<35:18,57.51it/s] 35%|###5      |60968/173481[18:00<33:20,56.24it/s] 35%|###5      |61552/173481[18:10<33:10,56.24it/s] 41%|####      |71053/173481[21:00<30:24,56.13it/s] 41%|####1     |71727/173481[21:11<30:12,56.13it/s] 47%|####7     |81756/173481[24:00<26:28,57.74it/s] 48%|####7     |82452/173481[24:11<26:16,57.74it/s] 53%|#####3    |92085/173481[27:00<23:34,57.56it/s] 53%|#####3    |92724/173481[27:11<23:22,57.56it/s] 59%|#####9    |102723/173481[30:00<20:13,58.31it/s] 60%|#####9    |103395/173481[30:11<20:01,58.31it/s] 65%|######5   |113023/173481[33:00<17:26,57.75it/s] 66%|######5   |113633/173481[33:11<17:16,57.75it/s] 71%|#######1  |123668/173481[36:00<14:12,58.44it/s] 72%|#######1  |124327/173481[36:11<14:01,58.44it/s] 78%|#######7  |134578/173481[39:00<10:53,59.49it/s] 78%|#######7  |135272/173481[39:12<10:42,59.49it/s] 84%|########3 |145283/173481[42:00<07:54,59.48it/s] 84%|########4 |145914/173481[42:12<07:43,59.48it/s] 89%|########9 |155068/173481[45:00<05:24,56.80it/s] 90%|########9 |155767/173481[45:12<05:11,56.80it/s] 96%|#########5|165823/173481[48:00<02:11,58.23it/s] 96%|#########5|166442/173481[48:12<02:00,58.23it/s]100%|##########|173481/173481[50:27<00:00,57.30it/s]
[32m[0322 14:44:01 @base.py:257][0m Epoch 4 (global_step 3990063) finished, time:3027.43 sec.
[32m[0322 14:44:02 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-3990063.
[32m[0322 14:44:03 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.22it/s]
3
[32m[0322 14:45:50 @monitor.py:363][0m QueueInput/queue_size: 0.67797
[32m[0322 14:45:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.078
[32m[0322 14:45:50 @monitor.py:363][0m activation-summaries/output-rms: 0.017351
[32m[0322 14:45:50 @monitor.py:363][0m cross_entropy_loss: 3.4595
[32m[0322 14:45:50 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.65806
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1566
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27222
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26816
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20726
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20501
[32m[0322 14:45:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 14:45:50 @monitor.py:363][0m train-error-top1: 0.8071
[32m[0322 14:45:50 @monitor.py:363][0m val-error-top1: 0.80525
[32m[0322 14:45:50 @monitor.py:363][0m val-utt-error: 0.45569
[32m[0322 14:45:50 @monitor.py:363][0m validation_cost: 3.4704
[32m[0322 14:45:50 @monitor.py:363][0m wd_cost: 3.4011e-05
[32m[0322 14:45:50 @group.py:42][0m Callbacks took 108.613 sec in total. InferenceRunner: 106.824sec
[32m[0322 14:45:50 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10554/173481[03:00<46:18,58.63it/s]  6%|6         |11066/173481[03:10<46:10,58.63it/s] 12%|#1        |20067/173481[06:00<45:59,55.59it/s] 12%|#1        |20586/173481[06:10<45:50,55.59it/s] 17%|#7        |29762/173481[09:00<43:47,54.71it/s] 17%|#7        |30346/173481[09:10<43:36,54.71it/s] 23%|##3       |40362/173481[12:00<39:07,56.70it/s] 24%|##3       |41007/173481[12:10<38:56,56.70it/s] 29%|##9       |51042/173481[15:00<35:11,57.99it/s] 30%|##9       |51648/173481[15:10<35:01,57.99it/s] 36%|###5      |61783/173481[18:00<31:39,58.82it/s] 36%|###5      |62441/173481[18:10<31:27,58.82it/s] 42%|####1     |72504/173481[21:00<28:26,59.19it/s] 42%|####2     |73161/173481[21:11<28:15,59.19it/s] 48%|####7     |82928/173481[24:00<25:46,58.54it/s] 48%|####8     |83606/173481[24:11<25:35,58.54it/s] 54%|#####3    |93134/173481[27:00<23:14,57.60it/s] 54%|#####4    |93761/173481[27:11<23:03,57.60it/s] 60%|#####9    |103432/173481[30:00<20:20,57.41it/s] 60%|######    |104116/173481[30:11<20:08,57.41it/s] 66%|######5   |113871/173481[33:00<17:13,57.70it/s] 66%|######6   |114521/173481[33:11<17:01,57.70it/s] 72%|#######1  |124127/173481[36:00<14:20,57.32it/s] 72%|#######1  |124781/173481[36:11<14:09,57.32it/s] 77%|#######7  |134127/173481[39:00<11:37,56.42it/s] 78%|#######7  |134816/173481[39:12<11:25,56.42it/s] 83%|########3 |144393/173481[42:00<08:32,56.72it/s] 84%|########3 |145086/173481[42:12<08:20,56.72it/s] 89%|########9 |154807/173481[45:00<05:26,57.28it/s] 90%|########9 |155394/173481[45:12<05:15,57.28it/s] 95%|#########4|164419/173481[48:00<02:43,55.27it/s] 95%|#########5|165046/173481[48:12<02:32,55.27it/s]100%|##########|173481/173481[50:46<00:00,56.94it/s]
[32m[0322 15:36:37 @base.py:257][0m Epoch 5 (global_step 4163544) finished, time:3046.79 sec.
[32m[0322 15:36:37 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-4163544.
[32m[0322 15:36:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.21it/s]
4
[32m[0322 15:38:33 @monitor.py:363][0m QueueInput/queue_size: 0.81553
[32m[0322 15:38:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.712
[32m[0322 15:38:33 @monitor.py:363][0m activation-summaries/output-rms: 0.018589
[32m[0322 15:38:33 @monitor.py:363][0m cross_entropy_loss: 3.3335
[32m[0322 15:38:33 @monitor.py:363][0m lr: 3.9063e-06
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.66271
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1564
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27281
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26845
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20753
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20549
[32m[0322 15:38:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 15:38:33 @monitor.py:363][0m train-error-top1: 0.78838
[32m[0322 15:38:33 @monitor.py:363][0m val-error-top1: 0.78728
[32m[0322 15:38:33 @monitor.py:363][0m val-utt-error: 0.42445
[32m[0322 15:38:33 @monitor.py:363][0m validation_cost: 3.3624
[32m[0322 15:38:33 @monitor.py:363][0m wd_cost: 3.4285e-05
[32m[0322 15:38:33 @group.py:42][0m Callbacks took 116.231 sec in total. InferenceRunner: 114.640sec
[32m[0322 15:38:33 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10433/173481[03:00<46:53,57.96it/s]  6%|6         |10980/173481[03:10<46:43,57.96it/s] 11%|#1        |19886/173481[06:00<46:27,55.10it/s] 12%|#1        |20475/173481[06:10<46:16,55.10it/s] 17%|#7        |29731/173481[09:00<43:38,54.90it/s] 17%|#7        |30288/173481[09:10<43:28,54.90it/s] 23%|##2       |39761/173481[12:00<40:18,55.30it/s] 23%|##3       |40365/173481[12:10<40:07,55.30it/s] 29%|##8       |49941/173481[15:00<36:49,55.92it/s] 29%|##9       |50530/173481[15:10<36:38,55.92it/s] 35%|###4      |60091/173481[18:00<33:39,56.15it/s] 35%|###4      |60684/173481[18:10<33:28,56.15it/s] 40%|####      |69907/173481[21:00<31:11,55.33it/s] 41%|####      |70505/173481[21:11<31:01,55.33it/s] 46%|####5     |79606/173481[24:00<28:39,54.59it/s] 46%|####6     |80245/173481[24:11<28:27,54.59it/s] 52%|#####1    |89536/173481[27:00<25:29,54.88it/s] 52%|#####1    |90145/173481[27:11<25:18,54.88it/s] 57%|#####7    |99086/173481[30:00<22:59,53.94it/s] 57%|#####7    |99730/173481[30:11<22:47,53.94it/s] 62%|######2   |108344/173481[33:00<20:37,52.66it/s] 63%|######2   |109002/173481[33:11<20:24,52.66it/s] 68%|######8   |118248/173481[36:00<17:06,53.81it/s] 68%|######8   |118803/173481[36:11<16:56,53.81it/s] 74%|#######3  |128311/173481[39:00<13:43,54.84it/s] 74%|#######4  |129010/173481[39:12<13:30,54.84it/s] 80%|#######9  |138281/173481[42:00<10:38,55.11it/s] 80%|########  |138955/173481[42:12<10:26,55.11it/s] 86%|########5 |148617/173481[45:00<07:22,56.24it/s] 86%|########6 |149285/173481[45:12<07:10,56.24it/s] 91%|#########1|158110/173481[48:00<04:42,54.43it/s] 91%|#########1|158731/173481[48:12<04:30,54.43it/s] 97%|#########6|167661/173481[51:00<01:48,53.74it/s] 97%|#########7|168340/173481[51:12<01:35,53.74it/s]100%|##########|173481/173481[52:48<00:00,54.76it/s]
[32m[0322 16:31:21 @base.py:257][0m Epoch 6 (global_step 4337025) finished, time:3168.22 sec.
[32m[0322 16:31:22 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-4337025.
[32m[0322 16:31:23 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,175.90it/s]
5
[32m[0322 16:33:10 @monitor.py:363][0m QueueInput/queue_size: 0.60915
[32m[0322 16:33:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.084
[32m[0322 16:33:10 @monitor.py:363][0m activation-summaries/output-rms: 0.019189
[32m[0322 16:33:10 @monitor.py:363][0m cross_entropy_loss: 3.2509
[32m[0322 16:33:10 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.66622
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1563
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27326
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26869
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20777
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20581
[32m[0322 16:33:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 16:33:10 @monitor.py:363][0m train-error-top1: 0.76499
[32m[0322 16:33:10 @monitor.py:363][0m val-error-top1: 0.77416
[32m[0322 16:33:10 @monitor.py:363][0m val-utt-error: 0.40006
[32m[0322 16:33:10 @monitor.py:363][0m validation_cost: 3.2827
[32m[0322 16:33:10 @monitor.py:363][0m wd_cost: 6.8988e-06
[32m[0322 16:33:10 @group.py:42][0m Callbacks took 108.901 sec in total. InferenceRunner: 107.016sec
[32m[0322 16:33:10 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10003/173481[03:00<49:01,55.57it/s]  6%|6         |10555/173481[03:10<48:51,55.57it/s] 11%|#1        |19825/173481[06:00<46:30,55.06it/s] 12%|#1        |20362/173481[06:10<46:20,55.06it/s] 17%|#7        |30013/173481[09:00<42:50,55.82it/s] 18%|#7        |30604/173481[09:10<42:39,55.82it/s] 22%|##2       |38381/173481[12:00<44:23,50.73it/s] 22%|##2       |38844/173481[12:10<44:14,50.73it/s] 27%|##7       |47270/173481[15:00<42:02,50.04it/s] 28%|##7       |47861/173481[15:10<41:50,50.04it/s] 33%|###2      |57165/173481[18:00<37:00,52.39it/s] 33%|###3      |57723/173481[18:10<36:49,52.39it/s] 38%|###8      |66755/173481[21:00<33:40,52.83it/s] 39%|###8      |67309/173481[21:11<33:29,52.83it/s] 44%|####4     |76808/173481[24:00<29:40,54.30it/s] 45%|####4     |77389/173481[24:11<29:29,54.30it/s] 50%|####9     |86010/173481[27:00<27:41,52.66it/s] 50%|####9     |86629/173481[27:11<27:29,52.66it/s] 55%|#####5    |96085/173481[30:00<23:46,54.26it/s] 56%|#####5    |96719/173481[30:11<23:34,54.26it/s] 61%|######1   |106200/173481[33:00<20:18,55.20it/s] 62%|######1   |106834/173481[33:11<20:07,55.20it/s] 67%|######6   |115874/173481[36:00<17:37,54.46it/s] 67%|######7   |116487/173481[36:11<17:26,54.46it/s] 72%|#######2  |125426/173481[39:00<14:53,53.76it/s] 73%|#######2  |125974/173481[39:11<14:43,53.76it/s] 78%|#######7  |134520/173481[42:00<12:28,52.08it/s] 78%|#######7  |135089/173481[42:12<12:17,52.08it/s] 83%|########3 |144168/173481[45:00<09:14,52.83it/s] 83%|########3 |144804/173481[45:12<09:02,52.83it/s] 87%|########7 |151513/173481[48:00<07:57,46.05it/s] 87%|########7 |151709/173481[48:12<07:52,46.05it/s] 93%|#########2|160634/173481[51:00<04:26,48.25it/s] 93%|#########2|161277/173481[51:12<04:12,48.25it/s] 98%|#########8|170420/173481[54:00<00:59,51.12it/s] 99%|#########8|171159/173481[54:12<00:45,51.12it/s]100%|##########|173481/173481[54:53<00:00,52.68it/s]
[32m[0322 17:28:03 @base.py:257][0m Epoch 7 (global_step 4510506) finished, time:3293.32 sec.
[32m[0322 17:28:04 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-4510506.
[32m[0322 17:28:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.81it/s]
6
[32m[0322 17:29:49 @monitor.py:363][0m QueueInput/queue_size: 0.69555
[32m[0322 17:29:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.721
[32m[0322 17:29:49 @monitor.py:363][0m activation-summaries/output-rms: 0.020067
[32m[0322 17:29:49 @monitor.py:363][0m cross_entropy_loss: 3.1876
[32m[0322 17:29:49 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.66858
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1562
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27357
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26886
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20794
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.206
[32m[0322 17:29:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 17:29:49 @monitor.py:363][0m train-error-top1: 0.75578
[32m[0322 17:29:49 @monitor.py:363][0m val-error-top1: 0.76685
[32m[0322 17:29:49 @monitor.py:363][0m val-utt-error: 0.38853
[32m[0322 17:29:49 @monitor.py:363][0m validation_cost: 3.2387
[32m[0322 17:29:49 @monitor.py:363][0m wd_cost: 6.927e-06
[32m[0322 17:29:49 @group.py:42][0m Callbacks took 105.914 sec in total. InferenceRunner: 104.695sec
[32m[0322 17:29:49 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10869/173481[03:00<44:53,60.38it/s]  7%|6         |11465/173481[03:10<44:43,60.38it/s] 12%|#2        |21506/173481[06:00<42:24,59.73it/s] 13%|#2        |22099/173481[06:10<42:14,59.73it/s] 18%|#8        |31449/173481[09:00<41:14,57.39it/s] 18%|#8        |32033/173481[09:10<41:04,57.39it/s] 24%|##3       |41629/173481[12:00<38:34,56.97it/s] 24%|##4       |42238/173481[12:10<38:23,56.97it/s] 30%|###       |52110/173481[15:00<35:07,57.59it/s] 30%|###       |52713/173481[15:10<34:57,57.59it/s] 36%|###5      |62222/173481[18:00<32:36,56.87it/s] 36%|###6      |62858/173481[18:10<32:25,56.87it/s] 42%|####1     |72424/173481[21:00<29:40,56.76it/s] 42%|####2     |72938/173481[21:11<29:31,56.76it/s] 47%|####7     |82359/173481[24:00<27:08,55.96it/s] 48%|####7     |82918/173481[24:11<26:58,55.96it/s] 53%|#####3    |92739/173481[27:00<23:41,56.80it/s] 54%|#####3    |93403/173481[27:11<23:29,56.80it/s] 60%|#####9    |103429/173481[30:00<20:06,58.06it/s] 60%|#####9    |104067/173481[30:11<19:55,58.06it/s] 66%|######5   |114474/173481[33:00<16:29,59.66it/s] 66%|######6   |115217/173481[33:11<16:16,59.66it/s] 72%|#######2  |125234/173481[36:00<13:27,59.71it/s] 73%|#######2  |125959/173481[36:11<13:15,59.71it/s] 78%|#######8  |135861/173481[39:00<10:33,59.37it/s] 79%|#######8  |136568/173481[39:11<10:21,59.37it/s] 85%|########4 |146614/173481[42:00<07:31,59.55it/s] 85%|########4 |147273/173481[42:12<07:20,59.55it/s] 91%|######### |157339/173481[45:00<04:31,59.56it/s] 91%|#########1|158063/173481[45:12<04:18,59.56it/s] 97%|#########6|168175/173481[48:00<01:28,59.88it/s] 97%|#########7|168952/173481[48:12<01:15,59.88it/s]100%|##########|173481/173481[49:28<00:00,58.44it/s]
[32m[0322 18:19:18 @base.py:257][0m Epoch 8 (global_step 4683987) finished, time:2968.66 sec.
[32m[0322 18:19:19 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-4683987.
[32m[0322 18:19:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.91it/s]
7
[32m[0322 18:21:04 @monitor.py:363][0m QueueInput/queue_size: 0.63176
[32m[0322 18:21:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.537
[32m[0322 18:21:04 @monitor.py:363][0m activation-summaries/output-rms: 0.020568
[32m[0322 18:21:04 @monitor.py:363][0m cross_entropy_loss: 3.1664
[32m[0322 18:21:04 @monitor.py:363][0m lr: 1.9531e-06
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67094
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1561
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27387
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26904
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20813
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20618
[32m[0322 18:21:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 18:21:04 @monitor.py:363][0m train-error-top1: 0.75665
[32m[0322 18:21:04 @monitor.py:363][0m val-error-top1: 0.75864
[32m[0322 18:21:04 @monitor.py:363][0m val-utt-error: 0.37658
[32m[0322 18:21:04 @monitor.py:363][0m validation_cost: 3.1933
[32m[0322 18:21:04 @monitor.py:363][0m wd_cost: 6.9553e-06
[32m[0322 18:21:04 @group.py:42][0m Callbacks took 106.170 sec in total. InferenceRunner: 104.050sec
[32m[0322 18:21:04 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11229/173481[03:00<43:20,62.38it/s]  7%|6         |11808/173481[03:10<43:11,62.38it/s] 12%|#2        |21230/173481[06:00<43:10,58.77it/s] 13%|#2        |21812/173481[06:10<43:00,58.77it/s] 18%|#7        |30699/173481[09:00<42:51,55.52it/s] 18%|#8        |31324/173481[09:10<42:40,55.52it/s] 24%|##3       |41263/173481[12:00<38:37,57.05it/s] 24%|##4       |41885/173481[12:10<38:26,57.05it/s] 30%|###       |52105/173481[15:00<34:31,58.60it/s] 30%|###       |52785/173481[15:10<34:19,58.60it/s] 36%|###5      |61926/173481[18:00<32:54,56.51it/s] 36%|###6      |62559/173481[18:10<32:42,56.51it/s] 42%|####1     |72641/173481[21:00<28:59,57.98it/s] 42%|####2     |73321/173481[21:11<28:47,57.98it/s] 48%|####8     |83480/173481[24:00<25:23,59.07it/s] 49%|####8     |84167/173481[24:11<25:11,59.07it/s] 55%|#####4    |94615/173481[27:00<21:44,60.43it/s] 55%|#####4    |95257/173481[27:11<21:34,60.43it/s] 61%|######    |105558/173481[30:00<18:40,60.61it/s] 61%|######1   |106285/173481[30:11<18:28,60.61it/s] 67%|######7   |116718/173481[33:00<15:26,61.30it/s] 68%|######7   |117462/173481[33:11<15:13,61.30it/s] 73%|#######3  |127438/173481[36:00<12:42,60.40it/s] 74%|#######3  |128165/173481[36:11<12:30,60.40it/s] 80%|#######9  |138248/173481[39:00<09:45,60.22it/s] 80%|########  |138950/173481[39:11<09:33,60.22it/s] 86%|########5 |148694/173481[42:00<06:59,59.11it/s] 86%|########6 |149362/173481[42:12<06:48,59.11it/s] 92%|#########1|159235/173481[45:00<04:02,58.83it/s] 92%|#########2|159948/173481[45:12<03:50,58.83it/s] 98%|#########7|169373/173481[48:00<01:11,57.54it/s] 98%|#########7|169980/173481[48:12<01:00,57.54it/s]100%|##########|173481/173481[49:18<00:00,58.64it/s]
[32m[0322 19:10:23 @base.py:257][0m Epoch 9 (global_step 4857468) finished, time:2958.56 sec.
[32m[0322 19:10:23 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-4857468.
[32m[0322 19:10:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.60it/s]
8
[32m[0322 19:12:09 @monitor.py:363][0m QueueInput/queue_size: 0.84262
[32m[0322 19:12:09 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.991
[32m[0322 19:12:09 @monitor.py:363][0m activation-summaries/output-rms: 0.020489
[32m[0322 19:12:09 @monitor.py:363][0m cross_entropy_loss: 3.1542
[32m[0322 19:12:09 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67236
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.1561
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27406
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26915
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20825
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20628
[32m[0322 19:12:09 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 19:12:09 @monitor.py:363][0m train-error-top1: 0.75268
[32m[0322 19:12:09 @monitor.py:363][0m val-error-top1: 0.75345
[32m[0322 19:12:09 @monitor.py:363][0m val-utt-error: 0.36925
[32m[0322 19:12:09 @monitor.py:363][0m validation_cost: 3.1631
[32m[0322 19:12:09 @monitor.py:363][0m wd_cost: 1.3945e-06
[32m[0322 19:12:09 @group.py:42][0m Callbacks took 106.476 sec in total. InferenceRunner: 104.818sec
[32m[0322 19:12:09 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10197/173481[03:00<48:02,56.65it/s]  6%|6         |10721/173481[03:10<47:53,56.65it/s] 12%|#1        |20318/173481[06:00<45:13,56.44it/s] 12%|#2        |20821/173481[06:10<45:04,56.44it/s] 18%|#7        |30444/173481[09:00<42:18,56.35it/s] 18%|#7        |31066/173481[09:10<42:07,56.35it/s] 25%|##5       |43542/173481[12:00<34:06,63.51it/s] 26%|##5       |44476/173481[12:10<33:51,63.51it/s] 34%|###3      |58594/173481[15:00<26:31,72.19it/s] 34%|###4      |59582/173481[15:10<26:17,72.19it/s] 42%|####2     |73622/173481[18:00<21:29,77.42it/s] 43%|####2     |74465/173481[18:10<21:18,77.42it/s] 51%|#####     |88391/173481[21:00<17:48,79.67it/s] 51%|#####1    |89331/173481[21:11<17:36,79.67it/s] 60%|#####9    |103883/173481[24:00<14:01,82.74it/s] 60%|######    |104790/173481[24:11<13:50,82.74it/s] 68%|######8   |118149/173481[27:00<11:23,80.96it/s] 69%|######8   |119036/173481[27:11<11:12,80.96it/s] 76%|#######5  |131752/173481[30:00<08:53,78.17it/s] 76%|#######6  |132580/173481[30:11<08:43,78.17it/s] 83%|########3 |144462/173481[33:00<06:31,74.19it/s] 84%|########3 |145346/173481[33:11<06:19,74.19it/s] 91%|######### |157574/173481[36:00<03:36,73.51it/s] 91%|#########1|158452/173481[36:11<03:24,73.51it/s] 98%|#########7|169618/173481[39:00<00:55,70.05it/s] 98%|#########8|170353/173481[39:12<00:44,70.05it/s]100%|##########|173481/173481[40:07<00:00,72.07it/s]
[32m[0322 19:52:16 @base.py:257][0m Epoch 10 (global_step 5030949) finished, time:2407.01 sec.
[32m[0322 19:52:17 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-5030949.
[32m[0322 19:52:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,154.08it/s]
9
[32m[0322 19:54:20 @monitor.py:363][0m QueueInput/queue_size: 0.76547
[32m[0322 19:54:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.072
[32m[0322 19:54:20 @monitor.py:363][0m activation-summaries/output-rms: 0.020742
[32m[0322 19:54:20 @monitor.py:363][0m cross_entropy_loss: 3.1239
[32m[0322 19:54:20 @monitor.py:363][0m lr: 9.7656e-07
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67352
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27421
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26924
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20835
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20635
[32m[0322 19:54:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 19:54:20 @monitor.py:363][0m train-error-top1: 0.74842
[32m[0322 19:54:20 @monitor.py:363][0m val-error-top1: 0.75035
[32m[0322 19:54:20 @monitor.py:363][0m val-utt-error: 0.36468
[32m[0322 19:54:20 @monitor.py:363][0m validation_cost: 3.1473
[32m[0322 19:54:20 @monitor.py:363][0m wd_cost: 1.3973e-06
[32m[0322 19:54:20 @group.py:42][0m Callbacks took 123.591 sec in total. InferenceRunner: 122.178sec
[32m[0322 19:54:20 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10666/173481[03:00<45:47,59.25it/s]  6%|6         |11205/173481[03:10<45:38,59.25it/s] 12%|#1        |20534/173481[06:00<44:45,56.95it/s] 12%|#2        |21112/173481[06:10<44:35,56.95it/s] 17%|#7        |29965/173481[09:00<43:49,54.58it/s] 18%|#7        |30522/173481[09:10<43:39,54.58it/s] 23%|##3       |40324/173481[12:00<39:36,56.02it/s] 24%|##3       |40907/173481[12:10<39:26,56.02it/s] 29%|##9       |51031/173481[15:00<35:22,57.70it/s] 30%|##9       |51615/173481[15:10<35:12,57.70it/s] 36%|###5      |61801/173481[18:00<31:41,58.74it/s] 36%|###5      |62396/173481[18:10<31:31,58.74it/s] 42%|####1     |72161/173481[21:00<29:02,58.13it/s] 42%|####1     |72775/173481[21:11<28:52,58.13it/s] 48%|####7     |82562/173481[24:00<26:08,57.96it/s] 48%|####7     |83245/173481[24:11<25:56,57.96it/s] 53%|#####3    |92670/173481[27:00<23:36,57.04it/s] 54%|#####3    |93329/173481[27:11<23:25,57.04it/s] 59%|#####9    |102924/173481[30:00<20:37,57.00it/s] 60%|#####9    |103558/173481[30:11<20:26,57.00it/s] 65%|######5   |113301/173481[33:00<17:29,57.32it/s] 66%|######5   |114015/173481[33:11<17:17,57.32it/s] 71%|#######1  |123658/173481[36:00<14:27,57.43it/s] 72%|#######1  |124362/173481[36:11<14:15,57.43it/s] 77%|#######7  |133906/173481[39:00<11:32,57.18it/s] 78%|#######7  |134622/173481[39:11<11:19,57.18it/s] 83%|########3 |144728/173481[42:00<08:10,58.61it/s] 84%|########3 |145410/173481[42:12<07:58,58.61it/s] 89%|########9 |155103/173481[45:00<05:16,58.12it/s] 90%|########9 |155781/173481[45:12<05:04,58.12it/s] 95%|#########5|165346/173481[48:00<02:21,57.50it/s] 96%|#########5|165997/173481[48:12<02:10,57.50it/s]100%|##########|173481/173481[50:21<00:00,57.41it/s]
[32m[0322 20:44:41 @base.py:257][0m Epoch 11 (global_step 5204430) finished, time:3021.63 sec.
[32m[0322 20:44:42 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-5204430.
[32m[0322 20:44:44 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,179.06it/s]
10
[32m[0322 20:46:29 @monitor.py:363][0m QueueInput/queue_size: 0.43969
[32m[0322 20:46:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.661
[32m[0322 20:46:29 @monitor.py:363][0m activation-summaries/output-rms: 0.020864
[32m[0322 20:46:29 @monitor.py:363][0m cross_entropy_loss: 3.0844
[32m[0322 20:46:29 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67463
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27436
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26932
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20845
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20643
[32m[0322 20:46:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 20:46:29 @monitor.py:363][0m train-error-top1: 0.7422
[32m[0322 20:46:29 @monitor.py:363][0m val-error-top1: 0.74628
[32m[0322 20:46:29 @monitor.py:363][0m val-utt-error: 0.35745
[32m[0322 20:46:29 @monitor.py:363][0m validation_cost: 3.1238
[32m[0322 20:46:29 @monitor.py:363][0m wd_cost: 1.4e-06
[32m[0322 20:46:29 @group.py:42][0m Callbacks took 107.684 sec in total. InferenceRunner: 105.137sec
[32m[0322 20:46:29 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10773/173481[03:00<45:18,59.85it/s]  7%|6         |11314/173481[03:10<45:09,59.85it/s] 12%|#2        |21218/173481[06:00<43:04,58.92it/s] 13%|#2        |21844/173481[06:10<42:53,58.92it/s] 18%|#8        |31470/173481[09:00<40:52,57.91it/s] 18%|#8        |32049/173481[09:10<40:42,57.91it/s] 24%|##3       |41085/173481[12:00<39:42,55.57it/s] 24%|##3       |41609/173481[12:10<39:33,55.57it/s] 29%|##9       |50830/173481[15:00<37:16,54.84it/s] 30%|##9       |51404/173481[15:10<37:06,54.84it/s] 35%|###5      |61015/173481[18:00<33:39,55.68it/s] 36%|###5      |61609/173481[18:10<33:29,55.68it/s] 41%|####      |70785/173481[21:00<31:08,54.97it/s] 41%|####1     |71419/173481[21:11<30:56,54.97it/s] 47%|####6     |81148/173481[24:00<27:21,56.24it/s] 47%|####7     |81784/173481[24:11<27:10,56.24it/s] 53%|#####2    |91288/173481[27:00<24:20,56.29it/s] 53%|#####2    |91920/173481[27:11<24:09,56.29it/s] 59%|#####8    |101601/173481[30:00<21:05,56.79it/s] 59%|#####8    |102239/173481[30:11<20:54,56.79it/s] 64%|######4   |111870/173481[33:00<18:02,56.91it/s] 65%|######4   |112504/173481[33:11<17:51,56.91it/s] 70%|#######   |121819/173481[36:00<15:21,56.08it/s] 71%|#######   |122439/173481[36:11<15:10,56.08it/s] 76%|#######5  |131760/173481[39:00<12:29,55.65it/s] 76%|#######6  |132419/173481[39:11<12:17,55.65it/s] 82%|########1 |141840/173481[42:00<09:26,55.82it/s] 82%|########2 |142489/173481[42:12<09:15,55.82it/s] 88%|########7 |152230/173481[45:00<06:14,56.75it/s] 88%|########8 |152940/173481[45:12<06:01,56.75it/s] 94%|#########4|163136/173481[48:00<02:56,58.61it/s] 94%|#########4|163869/173481[48:12<02:44,58.61it/s]100%|##########|173481/173481[50:48<00:00,56.90it/s]
[32m[0322 21:37:18 @base.py:257][0m Epoch 12 (global_step 5377911) finished, time:3048.87 sec.
[32m[0322 21:37:19 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-5377911.
[32m[0322 21:37:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,175.54it/s]
11
[32m[0322 21:39:07 @monitor.py:363][0m QueueInput/queue_size: 0.46373
[32m[0322 21:39:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.44
[32m[0322 21:39:07 @monitor.py:363][0m activation-summaries/output-rms: 0.021037
[32m[0322 21:39:07 @monitor.py:363][0m cross_entropy_loss: 3.0652
[32m[0322 21:39:07 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67518
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27444
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26937
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2085
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20647
[32m[0322 21:39:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 21:39:07 @monitor.py:363][0m train-error-top1: 0.72695
[32m[0322 21:39:07 @monitor.py:363][0m val-error-top1: 0.74535
[32m[0322 21:39:07 @monitor.py:363][0m val-utt-error: 0.35384
[32m[0322 21:39:07 @monitor.py:363][0m validation_cost: 3.1171
[32m[0322 21:39:07 @monitor.py:363][0m wd_cost: 2.8027e-07
[32m[0322 21:39:07 @group.py:42][0m Callbacks took 109.429 sec in total. InferenceRunner: 107.244sec
[32m[0322 21:39:07 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11547/173481[03:00<42:04,64.15it/s]  7%|7         |12159/173481[03:10<41:54,64.15it/s] 13%|#3        |22764/173481[06:00<39:44,63.22it/s] 13%|#3        |23411/173481[06:10<39:33,63.22it/s] 19%|#8        |32729/173481[09:00<39:44,59.03it/s] 19%|#9        |33314/173481[09:10<39:34,59.03it/s] 25%|##4       |43131/173481[12:00<37:11,58.40it/s] 25%|##5       |43748/173481[12:10<37:01,58.40it/s] 31%|###       |53409/173481[15:00<34:39,57.74it/s] 31%|###1      |53990/173481[15:10<34:29,57.74it/s] 37%|###6      |63763/173481[18:00<31:43,57.63it/s] 37%|###7      |64453/173481[18:10<31:31,57.63it/s] 43%|####3     |75142/173481[21:00<27:11,60.29it/s] 44%|####3     |75843/173481[21:11<26:59,60.29it/s] 50%|####9     |86555/173481[24:00<23:26,61.81it/s] 50%|#####     |87248/173481[24:11<23:15,61.81it/s] 57%|#####6    |98063/173481[27:00<19:59,62.85it/s] 57%|#####6    |98722/173481[27:11<19:49,62.85it/s] 63%|######2   |108844/173481[30:00<17:33,61.34it/s] 63%|######3   |109561/173481[30:11<17:22,61.34it/s] 70%|######9   |121079/173481[33:00<13:32,64.48it/s] 70%|#######   |121878/173481[33:11<13:20,64.48it/s] 79%|#######8  |136229/173481[36:00<08:30,73.01it/s] 79%|#######9  |137232/173481[36:11<08:16,73.01it/s] 88%|########8 |153076/173481[39:00<04:08,82.03it/s] 89%|########8 |154197/173481[39:11<03:55,82.03it/s] 97%|#########6|168140/173481[42:00<01:04,82.85it/s] 97%|#########7|168944/173481[42:12<00:54,82.85it/s]100%|##########|173481/173481[43:23<00:00,66.64it/s]
[32m[0322 22:22:31 @base.py:257][0m Epoch 13 (global_step 5551392) finished, time:2603.25 sec.
[32m[0322 22:22:31 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-5551392.
[32m[0322 22:22:32 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,175.60it/s]
12
[32m[0322 22:24:19 @monitor.py:363][0m QueueInput/queue_size: 0.50032
[32m[0322 22:24:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.334
[32m[0322 22:24:19 @monitor.py:363][0m activation-summaries/output-rms: 0.021541
[32m[0322 22:24:19 @monitor.py:363][0m cross_entropy_loss: 3.0797
[32m[0322 22:24:19 @monitor.py:363][0m lr: 4.8828e-07
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67572
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27451
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26942
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20856
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2065
[32m[0322 22:24:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 22:24:19 @monitor.py:363][0m train-error-top1: 0.7398
[32m[0322 22:24:19 @monitor.py:363][0m val-error-top1: 0.74332
[32m[0322 22:24:19 @monitor.py:363][0m val-utt-error: 0.35373
[32m[0322 22:24:19 @monitor.py:363][0m validation_cost: 3.1062
[32m[0322 22:24:19 @monitor.py:363][0m wd_cost: 2.8054e-07
[32m[0322 22:24:19 @group.py:42][0m Callbacks took 108.483 sec in total. InferenceRunner: 107.201sec
[32m[0322 22:24:19 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11636/173481[03:00<41:43,64.64it/s]  7%|7         |12242/173481[03:10<41:34,64.64it/s] 13%|#2        |22078/173481[06:00<41:16,61.15it/s] 13%|#3        |22687/173481[06:10<41:06,61.15it/s] 19%|#9        |33218/173481[09:00<38:00,61.51it/s] 19%|#9        |33822/173481[09:10<37:50,61.51it/s] 26%|##5       |44728/173481[12:00<34:13,62.70it/s] 26%|##6       |45446/173481[12:10<34:02,62.70it/s] 32%|###2      |56028/173481[15:00<31:12,62.74it/s] 33%|###2      |56652/173481[15:10<31:02,62.74it/s] 39%|###8      |67253/173481[18:00<28:18,62.54it/s] 39%|###9      |67956/173481[18:10<28:07,62.54it/s] 45%|####5     |78138/173481[21:00<25:50,61.49it/s] 45%|####5     |78800/173481[21:11<25:39,61.49it/s] 52%|#####1    |89418/173481[24:00<22:34,62.07it/s] 52%|#####1    |90128/173481[24:11<22:22,62.07it/s] 58%|#####8    |100988/173481[27:00<19:07,63.15it/s] 59%|#####8    |101661/173481[27:11<18:57,63.15it/s] 65%|######4   |112277/173481[30:00<16:12,62.93it/s] 65%|######5   |112978/173481[30:11<16:01,62.93it/s] 71%|#######1  |123740/173481[33:00<13:05,63.30it/s] 72%|#######1  |124467/173481[33:11<12:54,63.30it/s] 78%|#######8  |135458/173481[36:00<09:52,64.19it/s] 79%|#######8  |136227/173481[36:11<09:40,64.19it/s] 85%|########4 |146993/173481[39:00<06:53,64.13it/s] 85%|########5 |147752/173481[39:11<06:41,64.13it/s] 91%|#########1|158458/173481[42:00<03:55,63.91it/s] 92%|#########1|159227/173481[42:12<03:43,63.91it/s] 98%|#########7|169592/173481[45:00<01:01,62.86it/s] 98%|#########8|170262/173481[45:12<00:51,62.86it/s]100%|##########|173481/173481[46:06<00:00,62.71it/s]
[32m[0322 23:10:25 @base.py:257][0m Epoch 14 (global_step 5724873) finished, time:2766.34 sec.
[32m[0322 23:10:26 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-5724873.
[32m[0322 23:10:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,178.24it/s]
13
[32m[0322 23:12:13 @monitor.py:363][0m QueueInput/queue_size: 0.38278
[32m[0322 23:12:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.86
[32m[0322 23:12:13 @monitor.py:363][0m activation-summaries/output-rms: 0.021254
[32m[0322 23:12:13 @monitor.py:363][0m cross_entropy_loss: 3.0835
[32m[0322 23:12:13 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67613
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27457
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26946
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2086
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20653
[32m[0322 23:12:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 23:12:13 @monitor.py:363][0m train-error-top1: 0.74506
[32m[0322 23:12:13 @monitor.py:363][0m val-error-top1: 0.7411
[32m[0322 23:12:13 @monitor.py:363][0m val-utt-error: 0.34943
[32m[0322 23:12:13 @monitor.py:363][0m validation_cost: 3.0946
[32m[0322 23:12:13 @monitor.py:363][0m wd_cost: 2.8074e-07
[32m[0322 23:12:13 @group.py:42][0m Callbacks took 107.410 sec in total. InferenceRunner: 105.615sec
[32m[0322 23:12:13 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10887/173481[03:00<44:49,60.47it/s]  7%|6         |11441/173481[03:10<44:39,60.47it/s] 13%|#2        |21844/173481[06:00<41:39,60.67it/s] 13%|#2        |22350/173481[06:10<41:31,60.67it/s] 19%|#8        |32532/173481[09:00<39:08,60.02it/s] 19%|#9        |33196/173481[09:10<38:57,60.02it/s] 26%|##5       |44265/173481[12:00<34:27,62.49it/s] 26%|##5       |44986/173481[12:10<34:16,62.49it/s] 32%|###2      |56160/173481[15:00<30:26,64.24it/s] 33%|###2      |56894/173481[15:10<30:14,64.24it/s] 39%|###9      |67818/173481[18:00<27:18,64.50it/s] 39%|###9      |68507/173481[18:10<27:07,64.50it/s] 46%|####5     |79471/173481[21:00<24:14,64.62it/s] 46%|####6     |80197/173481[21:11<24:03,64.62it/s] 53%|#####2    |91272/173481[24:00<21:03,65.08it/s] 53%|#####3    |92010/173481[24:11<20:51,65.08it/s] 60%|#####9    |103862/173481[27:00<17:12,67.43it/s] 60%|######    |104712/173481[27:11<16:59,67.43it/s] 68%|######7   |117782/173481[30:00<12:53,72.04it/s] 68%|######8   |118767/173481[30:11<12:39,72.04it/s] 76%|#######6  |132698/173481[33:00<08:49,77.07it/s] 77%|#######7  |133652/173481[33:11<08:36,77.07it/s] 85%|########4 |146876/173481[36:00<05:41,77.91it/s] 85%|########5 |147776/173481[36:11<05:29,77.91it/s] 92%|#########1|159136/173481[39:00<03:17,72.68it/s] 92%|#########2|159911/173481[39:11<03:06,72.68it/s]100%|#########9|172757/173481[42:00<00:09,74.14it/s]100%|##########|173481/173481[42:09<00:00,68.59it/s]
[32m[0322 23:54:22 @base.py:257][0m Epoch 15 (global_step 5898354) finished, time:2529.28 sec.
[32m[0322 23:54:23 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-5898354.
[32m[0322 23:54:24 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,172.64it/s]
14
[32m[0322 23:56:13 @monitor.py:363][0m QueueInput/queue_size: 0.3931
[32m[0322 23:56:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.993
[32m[0322 23:56:13 @monitor.py:363][0m activation-summaries/output-rms: 0.02132
[32m[0322 23:56:13 @monitor.py:363][0m cross_entropy_loss: 3.0727
[32m[0322 23:56:13 @monitor.py:363][0m lr: 2.4414e-07
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67629
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.2746
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26948
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20863
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20655
[32m[0322 23:56:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0322 23:56:13 @monitor.py:363][0m train-error-top1: 0.73859
[32m[0322 23:56:13 @monitor.py:363][0m val-error-top1: 0.7408
[32m[0322 23:56:13 @monitor.py:363][0m val-utt-error: 0.35023
[32m[0322 23:56:13 @monitor.py:363][0m validation_cost: 3.0947
[32m[0322 23:56:13 @monitor.py:363][0m wd_cost: 5.6166e-08
[32m[0322 23:56:13 @group.py:42][0m Callbacks took 110.880 sec in total. InferenceRunner: 109.040sec
[32m[0322 23:56:13 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15813/173481[03:00<29:54,87.85it/s] 10%|9         |16749/173481[03:10<29:44,87.85it/s] 18%|#8        |31941/173481[06:00<26:35,88.70it/s] 19%|#8        |32482/173481[06:10<26:29,88.70it/s] 24%|##3       |41100/173481[09:00<34:07,64.67it/s] 24%|##4       |41662/173481[09:10<33:58,64.67it/s] 29%|##9       |50511/173481[12:00<35:26,57.82it/s] 29%|##9       |51081/173481[12:10<35:16,57.82it/s] 35%|###4      |60151/173481[15:00<33:58,55.60it/s] 35%|###5      |60810/173481[15:10<33:46,55.60it/s] 41%|####      |70776/173481[18:00<29:53,57.26it/s] 41%|####1     |71331/173481[18:10<29:44,57.26it/s] 46%|####6     |80311/173481[21:00<28:13,55.02it/s] 47%|####6     |80930/173481[21:11<28:02,55.02it/s] 52%|#####1    |89880/173481[24:00<25:46,54.07it/s] 52%|#####2    |90518/173481[24:11<25:34,54.07it/s] 57%|#####7    |99366/173481[27:00<23:08,53.37it/s] 58%|#####7    |99974/173481[27:11<22:57,53.37it/s] 63%|######2   |108616/173481[30:00<20:38,52.36it/s] 63%|######2   |109230/173481[30:11<20:27,52.36it/s] 68%|######7   |117896/173481[33:00<17:49,51.95it/s] 68%|######8   |118425/173481[33:11<17:39,51.95it/s] 73%|#######3  |127391/173481[36:00<14:40,52.35it/s] 74%|#######3  |127980/173481[36:11<14:29,52.35it/s] 79%|#######8  |136781/173481[39:00<11:42,52.25it/s] 79%|#######9  |137380/173481[39:11<11:30,52.25it/s] 84%|########4 |146256/173481[42:00<08:39,52.44it/s] 85%|########4 |146856/173481[42:12<08:27,52.44it/s] 90%|########9 |156061/173481[45:00<05:26,53.43it/s] 90%|######### |156660/173481[45:12<05:14,53.43it/s] 95%|#########5|165344/173481[48:00<02:35,52.48it/s] 96%|#########5|165933/173481[48:12<02:23,52.48it/s]100%|##########|173481/173481[50:45<00:00,56.96it/s]
[32m[0323 00:46:59 @base.py:257][0m Epoch 16 (global_step 6071835) finished, time:3045.72 sec.
[32m[0323 00:46:59 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-6071835.
[32m[0323 00:47:01 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,172.42it/s]
15
[32m[0323 00:48:50 @monitor.py:363][0m QueueInput/queue_size: 0.34009
[32m[0323 00:48:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.613
[32m[0323 00:48:50 @monitor.py:363][0m activation-summaries/output-rms: 0.021279
[32m[0323 00:48:50 @monitor.py:363][0m cross_entropy_loss: 3.0451
[32m[0323 00:48:50 @monitor.py:363][0m lr: 2.4414e-07
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67646
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27463
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2695
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20866
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20656
[32m[0323 00:48:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 00:48:50 @monitor.py:363][0m train-error-top1: 0.7366
[32m[0323 00:48:50 @monitor.py:363][0m val-error-top1: 0.73952
[32m[0323 00:48:50 @monitor.py:363][0m val-utt-error: 0.34757
[32m[0323 00:48:50 @monitor.py:363][0m validation_cost: 3.086
[32m[0323 00:48:50 @monitor.py:363][0m wd_cost: 5.6184e-08
[32m[0323 00:48:50 @group.py:42][0m Callbacks took 111.525 sec in total. InferenceRunner: 109.182sec
[32m[0323 00:48:50 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9785/173481[03:00<50:12,54.34it/s]  6%|5         |10319/173481[03:10<50:02,54.34it/s] 11%|#1        |19257/173481[06:00<48:04,53.47it/s] 11%|#1        |19767/173481[06:10<47:54,53.47it/s] 17%|#6        |28695/173481[09:00<45:34,52.94it/s] 17%|#6        |29296/173481[09:10<45:23,52.94it/s] 22%|##1       |37505/173481[12:00<44:33,50.86it/s] 22%|##1       |37996/173481[12:10<44:24,50.86it/s] 26%|##6       |45950/173481[15:00<43:33,48.80it/s] 27%|##6       |46459/173481[15:10<43:22,48.80it/s] 32%|###1      |54675/173481[18:00<40:42,48.64it/s] 32%|###1      |55219/173481[18:10<40:31,48.64it/s] 37%|###6      |63735/173481[21:00<36:58,49.47it/s] 37%|###7      |64230/173481[21:11<36:48,49.47it/s] 42%|####1     |72825/173481[24:00<33:34,49.98it/s] 42%|####2     |73345/173481[24:11<33:23,49.98it/s] 47%|####7     |82210/173481[27:00<29:48,51.03it/s] 48%|####7     |82772/173481[27:11<29:37,51.03it/s] 53%|#####2    |91575/173481[30:00<26:29,51.52it/s] 53%|#####3    |92149/173481[30:11<26:18,51.52it/s] 58%|#####8    |100950/173481[33:00<23:20,51.79it/s] 59%|#####8    |101553/173481[33:11<23:08,51.79it/s] 64%|######3   |110634/173481[36:00<19:50,52.78it/s] 64%|######4   |111239/173481[36:11<19:39,52.78it/s] 69%|######8   |119677/173481[39:00<17:25,51.48it/s] 69%|######9   |120286/173481[39:11<17:13,51.48it/s] 74%|#######4  |128995/173481[42:00<14:21,51.62it/s] 75%|#######4  |129591/173481[42:12<14:10,51.62it/s] 80%|#######9  |138215/173481[45:00<11:25,51.42it/s] 80%|########  |138833/173481[45:12<11:13,51.42it/s] 85%|########5 |147715/173481[48:00<08:14,52.08it/s] 86%|########5 |148334/173481[48:12<08:02,52.08it/s] 91%|######### |157400/173481[51:00<05:03,52.93it/s] 91%|#########1|158019/173481[51:12<04:52,52.93it/s] 96%|#########6|166675/173481[54:00<02:10,52.21it/s] 96%|#########6|167259/173481[54:12<01:59,52.21it/s]100%|##########|173481/173481[56:12<00:00,51.44it/s]
[32m[0323 01:45:03 @base.py:257][0m Epoch 17 (global_step 6245316) finished, time:3372.22 sec.
[32m[0323 01:45:03 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-6245316.
[32m[0323 01:45:05 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,174.32it/s]
16
[32m[0323 01:46:53 @monitor.py:363][0m QueueInput/queue_size: 0.45894
[32m[0323 01:46:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.397
[32m[0323 01:46:53 @monitor.py:363][0m activation-summaries/output-rms: 0.021341
[32m[0323 01:46:53 @monitor.py:363][0m cross_entropy_loss: 3.034
[32m[0323 01:46:53 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67638
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27464
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26951
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20868
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20658
[32m[0323 01:46:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 01:46:53 @monitor.py:363][0m train-error-top1: 0.72547
[32m[0323 01:46:53 @monitor.py:363][0m val-error-top1: 0.7397
[32m[0323 01:46:53 @monitor.py:363][0m val-utt-error: 0.34577
[32m[0323 01:46:53 @monitor.py:363][0m validation_cost: 3.0861
[32m[0323 01:46:53 @monitor.py:363][0m wd_cost: 1.1237e-08
[32m[0323 01:46:53 @group.py:42][0m Callbacks took 110.920 sec in total. InferenceRunner: 107.988sec
[32m[0323 01:46:53 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10743/173481[03:00<45:26,59.68it/s]  7%|6         |11299/173481[03:10<45:17,59.68it/s] 12%|#2        |21573/173481[06:00<42:15,59.92it/s] 13%|#2        |22123/173481[06:10<42:05,59.92it/s] 18%|#7        |30964/173481[09:00<42:35,55.78it/s] 18%|#8        |31513/173481[09:10<42:25,55.78it/s] 23%|##3       |40066/173481[12:00<41:55,53.04it/s] 23%|##3       |40618/173481[12:10<41:44,53.04it/s] 30%|###       |52773/173481[15:00<33:12,60.57it/s] 31%|###       |53615/173481[15:10<32:58,60.57it/s] 39%|###9      |68518/173481[18:00<24:26,71.58it/s] 40%|###9      |69138/173481[18:10<24:17,71.58it/s] 45%|####5     |78631/173481[21:00<25:06,62.95it/s] 46%|####5     |79198/173481[21:11<24:57,62.95it/s] 51%|#####     |87916/173481[24:00<25:08,56.70it/s] 51%|#####1    |88528/173481[24:11<24:58,56.70it/s] 56%|#####6    |97234/173481[27:00<23:29,54.10it/s] 56%|#####6    |97848/173481[27:11<23:17,54.10it/s] 61%|######1   |106660/173481[30:00<20:55,53.22it/s] 62%|######1   |107309/173481[30:11<20:43,53.22it/s] 67%|######7   |116634/173481[33:00<17:27,54.29it/s] 68%|######7   |117258/173481[33:11<17:15,54.29it/s] 73%|#######2  |126496/173481[36:00<14:21,54.54it/s] 73%|#######3  |127143/173481[36:11<14:09,54.54it/s] 79%|#######9  |137254/173481[39:00<10:35,57.03it/s] 80%|#######9  |137956/173481[39:11<10:22,57.03it/s] 85%|########5 |147871/173481[42:00<07:21,57.99it/s] 86%|########5 |148548/173481[42:12<07:09,57.99it/s] 91%|#########1|158587/173481[45:00<04:13,58.75it/s] 92%|#########1|159264/173481[45:12<04:01,58.75it/s] 98%|#########7|169206/173481[48:00<01:12,58.87it/s] 98%|#########7|169926/173481[48:12<01:00,58.87it/s]100%|##########|173481/173481[49:12<00:00,58.75it/s]
[32m[0323 02:36:06 @base.py:257][0m Epoch 18 (global_step 6418797) finished, time:2952.81 sec.
[32m[0323 02:36:07 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.50it/s]
17
[32m[0323 02:37:59 @monitor.py:363][0m QueueInput/queue_size: 0.22173
[32m[0323 02:37:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.291
[32m[0323 02:37:59 @monitor.py:363][0m activation-summaries/output-rms: 0.02178
[32m[0323 02:37:59 @monitor.py:363][0m cross_entropy_loss: 3.0556
[32m[0323 02:37:59 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67616
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27465
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26952
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20869
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20658
[32m[0323 02:37:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 02:37:59 @monitor.py:363][0m train-error-top1: 0.73459
[32m[0323 02:37:59 @monitor.py:363][0m val-error-top1: 0.73908
[32m[0323 02:37:59 @monitor.py:363][0m val-utt-error: 0.348
[32m[0323 02:37:59 @monitor.py:363][0m validation_cost: 3.0829
[32m[0323 02:37:59 @monitor.py:363][0m wd_cost: 1.1234e-08
[32m[0323 02:37:59 @group.py:42][0m Callbacks took 113.016 sec in total. InferenceRunner: 112.384sec
[32m[0323 02:37:59 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17464/173481[03:00<26:48,97.02it/s] 10%|#         |18198/173481[03:10<26:40,97.02it/s] 17%|#7        |29508/173481[06:00<30:17,79.20it/s] 17%|#7        |30209/173481[06:10<30:09,79.20it/s] 24%|##4       |41777/173481[09:00<29:57,73.27it/s] 24%|##4       |42457/173481[09:10<29:48,73.27it/s] 31%|###       |53703/173481[12:00<28:41,69.58it/s] 31%|###1      |54374/173481[12:10<28:31,69.58it/s] 38%|###7      |65106/173481[15:00<27:14,66.32it/s] 38%|###7      |65818/173481[15:10<27:03,66.32it/s] 44%|####4     |76648/173481[18:00<24:45,65.19it/s] 45%|####4     |77261/173481[18:10<24:35,65.19it/s] 51%|#####     |87978/173481[21:00<22:14,64.05it/s] 51%|#####1    |88682/173481[21:11<22:03,64.05it/s] 57%|#####7    |99612/173481[24:00<19:08,64.34it/s] 58%|#####7    |100282/173481[24:11<18:57,64.34it/s] 64%|######3   |110788/173481[27:00<16:32,63.19it/s] 64%|######4   |111537/173481[27:11<16:20,63.19it/s] 71%|#######   |122378/173481[30:00<13:21,63.78it/s] 71%|#######   |123157/173481[30:11<13:09,63.78it/s] 77%|#######7  |134007/173481[33:00<10:14,64.19it/s] 78%|#######7  |134748/173481[33:11<10:03,64.19it/s] 84%|########3 |145288/173481[36:00<07:24,63.42it/s] 84%|########4 |146015/173481[36:11<07:13,63.42it/s] 90%|######### |156828/173481[39:00<04:21,63.76it/s] 91%|######### |157616/173481[39:11<04:08,63.76it/s] 96%|#########6|167173/173481[42:00<01:44,60.45it/s] 97%|#########6|167880/173481[42:12<01:32,60.45it/s]100%|##########|173481/173481[43:50<00:00,65.95it/s]
[32m[0323 03:21:50 @base.py:257][0m Epoch 19 (global_step 6592278) finished, time:2630.42 sec.
[32m[0323 03:21:50 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-6592278.
[32m[0323 03:21:52 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.79it/s]
18
[32m[0323 03:23:50 @monitor.py:363][0m QueueInput/queue_size: 0.49332
[32m[0323 03:23:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.834
[32m[0323 03:23:50 @monitor.py:363][0m activation-summaries/output-rms: 0.021441
[32m[0323 03:23:50 @monitor.py:363][0m cross_entropy_loss: 3.0659
[32m[0323 03:23:50 @monitor.py:363][0m lr: 1.2207e-07
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67594
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27466
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26953
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2087
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 03:23:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 03:23:50 @monitor.py:363][0m train-error-top1: 0.73972
[32m[0323 03:23:50 @monitor.py:363][0m val-error-top1: 0.73788
[32m[0323 03:23:50 @monitor.py:363][0m val-utt-error: 0.34401
[32m[0323 03:23:50 @monitor.py:363][0m validation_cost: 3.0771
[32m[0323 03:23:50 @monitor.py:363][0m wd_cost: 1.1231e-08
[32m[0323 03:23:50 @group.py:42][0m Callbacks took 120.604 sec in total. InferenceRunner: 118.547sec
[32m[0323 03:23:50 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17289/173481[03:00<27:06,96.05it/s] 11%|#         |18237/173481[03:10<26:56,96.05it/s] 16%|#6        |28227/173481[06:00<32:31,74.42it/s] 17%|#6        |28801/173481[06:10<32:23,74.42it/s] 23%|##2       |39062/173481[09:00<33:39,66.55it/s] 23%|##2       |39726/173481[09:10<33:29,66.55it/s] 29%|##9       |50431/173481[12:00<31:38,64.81it/s] 29%|##9       |51046/173481[12:10<31:29,64.81it/s] 35%|###5      |61232/173481[15:00<30:01,62.31it/s] 36%|###5      |61932/173481[15:10<29:50,62.31it/s] 42%|####1     |72427/173481[18:00<27:03,62.25it/s] 42%|####2     |73131/173481[18:10<26:52,62.25it/s] 48%|####8     |83931/173481[21:00<23:39,63.07it/s] 49%|####8     |84643/173481[21:11<23:28,63.07it/s] 55%|#####4    |94702/173481[24:00<21:22,61.40it/s] 55%|#####4    |95334/173481[24:11<21:12,61.40it/s] 62%|######1   |106848/173481[27:00<17:16,64.30it/s] 62%|######2   |107685/173481[27:11<17:03,64.30it/s] 69%|######9   |120327/173481[30:00<12:48,69.19it/s] 70%|######9   |121266/173481[30:11<12:34,69.19it/s] 78%|#######7  |134702/173481[33:00<08:43,74.14it/s] 78%|#######8  |135496/173481[33:11<08:32,74.14it/s] 85%|########4 |147358/173481[36:00<06:01,72.17it/s] 85%|########5 |148276/173481[36:11<05:49,72.17it/s] 92%|#########1|159556/173481[39:00<03:19,69.90it/s] 92%|#########2|160256/173481[39:12<03:09,69.90it/s] 99%|#########9|172125/173481[42:00<00:19,69.86it/s]100%|#########9|173086/173481[42:12<00:05,69.86it/s]100%|##########|173481/173481[42:17<00:00,68.37it/s]
[32m[0323 04:06:07 @base.py:257][0m Epoch 20 (global_step 6765759) finished, time:2537.21 sec.
[32m[0323 04:06:08 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-6765759.
[32m[0323 04:06:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.82it/s]
19
[32m[0323 04:07:54 @monitor.py:363][0m QueueInput/queue_size: 0.71154
[32m[0323 04:07:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.959
[32m[0323 04:07:54 @monitor.py:363][0m activation-summaries/output-rms: 0.02145
[32m[0323 04:07:54 @monitor.py:363][0m cross_entropy_loss: 3.0586
[32m[0323 04:07:54 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67559
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27466
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26953
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20871
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 04:07:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 04:07:54 @monitor.py:363][0m train-error-top1: 0.73747
[32m[0323 04:07:54 @monitor.py:363][0m val-error-top1: 0.73822
[32m[0323 04:07:54 @monitor.py:363][0m val-utt-error: 0.34555
[32m[0323 04:07:54 @monitor.py:363][0m validation_cost: 3.0807
[32m[0323 04:07:54 @monitor.py:363][0m wd_cost: 2.2453e-09
[32m[0323 04:07:54 @group.py:42][0m Callbacks took 106.537 sec in total. InferenceRunner: 104.687sec
[32m[0323 04:07:54 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14849/173481[03:00<32:02,82.49it/s]  9%|9         |15724/173481[03:10<31:52,82.49it/s] 18%|#7        |31101/173481[06:00<27:31,86.21it/s] 18%|#8        |32059/173481[06:10<27:20,86.21it/s] 28%|##7       |47981/173481[09:00<23:16,89.84it/s] 28%|##8       |48970/173481[09:10<23:05,89.84it/s] 35%|###4      |60025/173481[12:00<24:39,76.70it/s] 35%|###4      |60660/173481[12:10<24:31,76.70it/s] 41%|####      |70814/173481[15:00<25:25,67.29it/s] 41%|####1     |71430/173481[15:10<25:16,67.29it/s] 47%|####6     |81341/173481[18:00<24:32,62.57it/s] 47%|####7     |82015/173481[18:10<24:21,62.57it/s] 53%|#####3    |92013/173481[21:00<22:18,60.89it/s] 53%|#####3    |92666/173481[21:11<22:07,60.89it/s] 59%|#####9    |102711/173481[24:00<19:36,60.15it/s] 60%|#####9    |103377/173481[24:11<19:25,60.15it/s] 65%|######5   |113401/173481[27:00<16:45,59.76it/s] 66%|######5   |114083/173481[27:11<16:33,59.76it/s] 71%|#######1  |124031/173481[30:00<13:52,59.40it/s] 72%|#######1  |124760/173481[30:11<13:40,59.40it/s] 78%|#######7  |134999/173481[33:00<10:39,60.16it/s] 78%|#######8  |135701/173481[33:11<10:28,60.16it/s] 84%|########4 |146136/173481[36:00<07:28,61.00it/s] 85%|########4 |146867/173481[36:11<07:16,61.00it/s] 90%|######### |156321/173481[39:00<04:52,58.71it/s] 90%|######### |156993/173481[39:12<04:40,58.71it/s] 96%|#########6|166626/173481[42:00<01:58,57.96it/s] 96%|#########6|167350/173481[42:12<01:45,57.96it/s]100%|##########|173481/173481[43:56<00:00,65.80it/s]
[32m[0323 04:51:51 @base.py:257][0m Epoch 21 (global_step 6939240) finished, time:2636.69 sec.
[32m[0323 04:51:51 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-6939240.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,156.91it/s]
20
[32m[0323 04:53:51 @monitor.py:363][0m QueueInput/queue_size: 0.39717
[32m[0323 04:53:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.568
[32m[0323 04:53:51 @monitor.py:363][0m activation-summaries/output-rms: 0.021357
[32m[0323 04:53:51 @monitor.py:363][0m cross_entropy_loss: 3.0336
[32m[0323 04:53:51 @monitor.py:363][0m lr: 6.1035e-08
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67522
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27467
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26954
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20871
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 04:53:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 04:53:51 @monitor.py:363][0m train-error-top1: 0.73545
[32m[0323 04:53:51 @monitor.py:363][0m val-error-top1: 0.73772
[32m[0323 04:53:51 @monitor.py:363][0m val-utt-error: 0.34555
[32m[0323 04:53:51 @monitor.py:363][0m validation_cost: 3.0757
[32m[0323 04:53:51 @monitor.py:363][0m wd_cost: 2.2443e-09
[32m[0323 04:53:51 @group.py:42][0m Callbacks took 120.611 sec in total. InferenceRunner: 119.972sec
[32m[0323 04:53:51 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17330/173481[03:00<27:02,96.27it/s] 11%|#         |18274/173481[03:10<26:52,96.27it/s] 17%|#6        |28855/173481[06:00<31:20,76.90it/s] 17%|#7        |29509/173481[06:10<31:12,76.90it/s] 23%|##2       |39131/173481[09:00<34:10,65.53it/s] 23%|##2       |39719/173481[09:10<34:01,65.53it/s] 28%|##8       |48705/173481[12:00<35:25,58.71it/s] 28%|##8       |49294/173481[12:10<35:15,58.71it/s] 34%|###4      |59200/173481[15:00<32:33,58.50it/s] 35%|###4      |59864/173481[15:10<32:22,58.50it/s] 40%|####      |69867/173481[18:00<29:19,58.88it/s] 41%|####      |70527/173481[18:10<29:08,58.88it/s] 47%|####6     |80736/173481[21:00<25:55,59.62it/s] 47%|####6     |81397/173481[21:11<25:44,59.62it/s] 53%|#####2    |91535/173481[24:00<22:50,59.80it/s] 53%|#####3    |92184/173481[24:11<22:39,59.80it/s] 59%|#####8    |102190/173481[27:00<19:58,59.48it/s] 59%|#####9    |102894/173481[27:11<19:46,59.48it/s] 65%|######5   |112996/173481[30:00<16:52,59.76it/s] 65%|######5   |113627/173481[30:11<16:41,59.76it/s] 71%|#######   |123125/173481[33:00<14:28,57.96it/s] 71%|#######1  |123729/173481[33:11<14:18,57.96it/s] 77%|#######6  |133125/173481[36:00<11:51,56.73it/s] 77%|#######7  |133744/173481[36:11<11:40,56.73it/s] 83%|########2 |143625/173481[39:00<08:39,57.51it/s] 83%|########3 |144354/173481[39:12<08:26,57.51it/s] 89%|########8 |154208/173481[42:00<05:31,58.14it/s] 89%|########9 |154849/173481[42:12<05:20,58.14it/s] 95%|#########4|164253/173481[45:00<02:42,56.95it/s] 95%|#########5|164892/173481[45:12<02:30,56.95it/s]100%|##########|173481/173481[47:42<00:00,60.61it/s]
[32m[0323 05:41:34 @base.py:257][0m Epoch 22 (global_step 7112721) finished, time:2862.31 sec.
[32m[0323 05:41:34 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-7112721.
[32m[0323 05:41:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,159.75it/s]
21
[32m[0323 05:43:33 @monitor.py:363][0m QueueInput/queue_size: 0.28967
[32m[0323 05:43:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.346
[32m[0323 05:43:33 @monitor.py:363][0m activation-summaries/output-rms: 0.021384
[32m[0323 05:43:33 @monitor.py:363][0m cross_entropy_loss: 3.0264
[32m[0323 05:43:33 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67489
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27467
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26954
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20872
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 05:43:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 05:43:33 @monitor.py:363][0m train-error-top1: 0.72393
[32m[0323 05:43:33 @monitor.py:363][0m val-error-top1: 0.73827
[32m[0323 05:43:33 @monitor.py:363][0m val-utt-error: 0.34332
[32m[0323 05:43:33 @monitor.py:363][0m validation_cost: 3.078
[32m[0323 05:43:33 @monitor.py:363][0m wd_cost: 2.2433e-09
[32m[0323 05:43:33 @group.py:42][0m Callbacks took 119.807 sec in total. InferenceRunner: 117.836sec
[32m[0323 05:43:33 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17049/173481[03:00<27:31,94.71it/s] 10%|#         |17974/173481[03:10<27:21,94.71it/s] 17%|#6        |29474/173481[06:00<30:03,79.85it/s] 17%|#7        |30073/173481[06:10<29:55,79.85it/s] 23%|##2       |39575/173481[09:00<33:51,65.91it/s] 23%|##3       |40131/173481[09:10<33:43,65.91it/s] 30%|###       |52634/173481[12:00<29:09,69.07it/s] 31%|###       |53462/173481[12:10<28:57,69.07it/s] 39%|###9      |68358/173481[15:00<22:42,77.14it/s] 40%|###9      |69319/173481[15:10<22:30,77.14it/s] 46%|####5     |79429/173481[18:00<22:54,68.43it/s] 46%|####6     |80093/173481[18:10<22:44,68.43it/s] 52%|#####2    |90644/173481[21:00<21:10,65.22it/s] 53%|#####2    |91370/173481[21:11<20:58,65.22it/s] 59%|#####8    |101644/173481[24:00<18:58,63.09it/s] 59%|#####8    |102303/173481[24:11<18:48,63.09it/s] 65%|######4   |112749/173481[27:00<16:13,62.38it/s] 65%|######5   |113478/173481[27:11<16:01,62.38it/s] 71%|#######1  |123663/173481[30:00<13:30,61.49it/s] 72%|#######1  |124383/173481[30:11<13:18,61.49it/s] 78%|#######7  |134734/173481[33:00<10:30,61.50it/s] 78%|#######8  |135413/173481[33:11<10:19,61.50it/s] 84%|########4 |145729/173481[36:00<07:32,61.28it/s] 84%|########4 |146458/173481[36:11<07:20,61.28it/s] 90%|######### |156729/173481[39:00<04:33,61.19it/s] 91%|######### |157481/173481[39:12<04:21,61.19it/s] 97%|#########6|167894/173481[42:00<01:30,61.60it/s] 97%|#########7|168642/173481[42:12<01:18,61.60it/s]100%|##########|173481/173481[43:32<00:00,66.41it/s]
[32m[0323 06:27:06 @base.py:257][0m Epoch 23 (global_step 7286202) finished, time:2612.11 sec.
[32m[0323 06:27:06 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-7286202.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.58it/s]
22
[32m[0323 06:29:03 @monitor.py:363][0m QueueInput/queue_size: 0.63667
[32m[0323 06:29:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.232
[32m[0323 06:29:03 @monitor.py:363][0m activation-summaries/output-rms: 0.021786
[32m[0323 06:29:03 @monitor.py:363][0m cross_entropy_loss: 3.0498
[32m[0323 06:29:03 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6747
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27467
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26954
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20872
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 06:29:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 06:29:03 @monitor.py:363][0m train-error-top1: 0.73329
[32m[0323 06:29:03 @monitor.py:363][0m val-error-top1: 0.73801
[32m[0323 06:29:03 @monitor.py:363][0m val-utt-error: 0.34529
[32m[0323 06:29:03 @monitor.py:363][0m validation_cost: 3.0767
[32m[0323 06:29:03 @monitor.py:363][0m wd_cost: 4.4856e-10
[32m[0323 06:29:03 @group.py:42][0m Callbacks took 117.867 sec in total. InferenceRunner: 117.228sec
[32m[0323 06:29:03 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |18181/173481[03:00<25:37,101.00it/s] 11%|#         |18887/173481[03:10<25:30,101.00it/s] 17%|#7        |30328/173481[06:00<29:29,80.90it/s]  18%|#7        |31057/173481[06:10<29:20,80.90it/s] 25%|##4       |43268/173481[09:00<28:30,76.13it/s] 25%|##5       |43987/173481[09:10<28:20,76.13it/s] 32%|###2      |56189/173481[12:00<26:27,73.89it/s] 33%|###2      |56846/173481[12:10<26:18,73.89it/s] 40%|###9      |69053/173481[15:00<23:57,72.65it/s] 40%|####      |69799/173481[15:10<23:47,72.65it/s] 47%|####7     |82098/173481[18:00<20:59,72.55it/s] 48%|####7     |82822/173481[18:10<20:49,72.55it/s] 55%|#####4    |95399/173481[21:00<17:46,73.22it/s] 55%|#####5    |96187/173481[21:11<17:35,73.22it/s] 63%|######2   |108798/173481[24:00<14:36,73.82it/s] 63%|######3   |109534/173481[24:11<14:26,73.82it/s] 69%|######9   |120349/173481[27:00<12:53,68.66it/s] 70%|######9   |121201/173481[27:11<12:41,68.66it/s] 76%|#######6  |131938/173481[30:00<10:25,66.45it/s] 76%|#######6  |132651/173481[30:11<10:14,66.45it/s] 82%|########2 |142963/173481[33:00<07:58,63.73it/s] 83%|########2 |143646/173481[33:11<07:48,63.73it/s] 89%|########8 |154178/173481[36:00<05:06,63.01it/s] 89%|########9 |154918/173481[36:11<04:54,63.01it/s] 95%|#########5|165511/173481[39:00<02:06,62.98it/s] 96%|#########5|166185/173481[39:12<01:55,62.98it/s]100%|##########|173481/173481[41:24<00:00,69.82it/s]
[32m[0323 07:10:28 @base.py:257][0m Epoch 24 (global_step 7459683) finished, time:2484.82 sec.
[32m[0323 07:10:29 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-7459683.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.60it/s]
23
[32m[0323 07:12:28 @monitor.py:363][0m QueueInput/queue_size: 0.83662
[32m[0323 07:12:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.77
[32m[0323 07:12:28 @monitor.py:363][0m activation-summaries/output-rms: 0.021432
[32m[0323 07:12:28 @monitor.py:363][0m cross_entropy_loss: 3.0617
[32m[0323 07:12:28 @monitor.py:363][0m lr: 3.0518e-08
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67452
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27467
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26954
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20872
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 07:12:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 07:12:28 @monitor.py:363][0m train-error-top1: 0.73879
[32m[0323 07:12:28 @monitor.py:363][0m val-error-top1: 0.73713
[32m[0323 07:12:28 @monitor.py:363][0m val-utt-error: 0.34247
[32m[0323 07:12:28 @monitor.py:363][0m validation_cost: 3.0726
[32m[0323 07:12:28 @monitor.py:363][0m wd_cost: 4.4846e-10
[32m[0323 07:12:28 @group.py:42][0m Callbacks took 120.097 sec in total. InferenceRunner: 119.444sec
[32m[0323 07:12:28 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17062/173481[03:00<27:30,94.78it/s] 10%|#         |18021/173481[03:10<27:20,94.78it/s] 17%|#7        |29512/173481[06:00<30:00,79.97it/s] 17%|#7        |30176/173481[06:10<29:52,79.97it/s] 24%|##3       |41106/173481[09:00<30:55,71.35it/s] 24%|##4       |41920/173481[09:10<30:43,71.35it/s] 30%|###       |52624/173481[12:00<29:51,67.47it/s] 31%|###       |53314/173481[12:10<29:41,67.47it/s] 37%|###6      |64186/173481[15:00<27:40,65.81it/s] 37%|###7      |64846/173481[15:10<27:30,65.81it/s] 43%|####3     |75205/173481[18:00<25:49,63.43it/s] 44%|####3     |75806/173481[18:10<25:39,63.43it/s] 50%|####9     |86117/173481[21:00<23:29,61.99it/s] 50%|#####     |86773/173481[21:11<23:18,61.99it/s] 57%|#####6    |98884/173481[24:00<18:47,66.16it/s] 58%|#####7    |99843/173481[24:11<18:33,66.16it/s] 66%|######6   |115162/173481[27:00<12:43,76.41it/s] 67%|######6   |116031/173481[27:11<12:31,76.41it/s] 74%|#######3  |127694/173481[30:00<10:28,72.86it/s] 74%|#######4  |128611/173481[30:11<10:15,72.86it/s] 80%|########  |139592/173481[33:00<08:08,69.31it/s] 81%|########  |140316/173481[33:11<07:58,69.31it/s] 87%|########6 |150907/173481[36:00<05:42,65.92it/s] 87%|########7 |151641/173481[36:11<05:31,65.92it/s] 93%|#########3|161769/173481[39:00<03:05,63.01it/s] 94%|#########3|162511/173481[39:12<02:54,63.01it/s]100%|#########9|172804/173481[42:00<00:10,62.15it/s]100%|##########|173481/173481[42:11<00:00,68.53it/s]
[32m[0323 07:54:40 @base.py:257][0m Epoch 25 (global_step 7633164) finished, time:2531.64 sec.
[32m[0323 07:54:41 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-7633164.
[32m[0323 07:54:42 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.48it/s]
24
[32m[0323 07:56:47 @monitor.py:363][0m QueueInput/queue_size: 0.51362
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 37.903
[32m[0323 07:56:47 @monitor.py:363][0m activation-summaries/output-rms: 0.021443
[32m[0323 07:56:47 @monitor.py:363][0m cross_entropy_loss: 3.0555
[32m[0323 07:56:47 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6744
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27467
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26954
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20872
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 07:56:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 07:56:47 @monitor.py:363][0m train-error-top1: 0.73753
[32m[0323 07:56:47 @monitor.py:363][0m val-error-top1: 0.73765
[32m[0323 07:56:47 @monitor.py:363][0m val-utt-error: 0.34481
[32m[0323 07:56:47 @monitor.py:363][0m validation_cost: 3.0774
[32m[0323 07:56:47 @monitor.py:363][0m wd_cost: 4.4839e-10
[32m[0323 07:56:47 @group.py:42][0m Callbacks took 127.215 sec in total. InferenceRunner: 125.094sec
[32m[0323 07:56:47 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12876/173481[03:00<37:25,71.53it/s]  8%|7         |13522/173481[03:10<37:16,71.53it/s] 14%|#3        |24211/173481[06:00<37:08,66.98it/s] 14%|#4        |24860/173481[06:10<36:58,66.98it/s] 20%|##        |35411/173481[09:00<35:40,64.51it/s] 21%|##        |36050/173481[09:10<35:30,64.51it/s] 27%|##6       |46421/173481[12:00<33:43,62.79it/s] 27%|##7       |47042/173481[12:10<33:33,62.79it/s] 33%|###2      |57061/173481[15:00<31:51,60.89it/s] 33%|###3      |57705/173481[15:10<31:41,60.89it/s] 39%|###9      |68141/173481[18:00<28:40,61.22it/s] 40%|###9      |68790/173481[18:10<28:30,61.22it/s] 45%|####5     |78791/173481[21:00<26:13,60.17it/s] 46%|####5     |79435/173481[21:11<26:03,60.17it/s] 52%|#####1    |89371/173481[24:00<23:34,59.46it/s] 52%|#####1    |90020/173481[24:11<23:23,59.46it/s] 58%|#####7    |99801/173481[27:00<20:55,58.69it/s] 58%|#####7    |100470/173481[27:11<20:43,58.69it/s] 64%|######3   |110441/173481[30:00<17:50,58.90it/s] 64%|######4   |111085/173481[30:11<17:39,58.90it/s] 70%|######9   |120814/173481[33:00<15:04,58.25it/s] 70%|#######   |121490/173481[33:11<14:52,58.25it/s] 76%|#######5  |131520/173481[36:00<11:52,58.86it/s] 76%|#######6  |132180/173481[36:11<11:41,58.86it/s] 82%|########1 |142214/173481[39:00<08:48,59.13it/s] 82%|########2 |142925/173481[39:12<08:36,59.13it/s] 88%|########8 |152768/173481[42:00<05:51,58.88it/s] 88%|########8 |153492/173481[42:12<05:39,58.88it/s] 94%|#########4|163271/173481[45:00<02:54,58.61it/s] 95%|#########4|163970/173481[45:12<02:42,58.61it/s]100%|##########|173481/173481[47:54<00:00,60.34it/s]
[32m[0323 08:44:42 @base.py:257][0m Epoch 26 (global_step 7806645) finished, time:2874.99 sec.
[32m[0323 08:44:43 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-7806645.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,151.57it/s]
25
[32m[0323 08:46:47 @monitor.py:363][0m QueueInput/queue_size: 0.48428
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.52
[32m[0323 08:46:47 @monitor.py:363][0m activation-summaries/output-rms: 0.021354
[32m[0323 08:46:47 @monitor.py:363][0m cross_entropy_loss: 3.0309
[32m[0323 08:46:47 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67437
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27467
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26954
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20872
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 08:46:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 08:46:47 @monitor.py:363][0m train-error-top1: 0.73318
[32m[0323 08:46:47 @monitor.py:363][0m val-error-top1: 0.73729
[32m[0323 08:46:47 @monitor.py:363][0m val-utt-error: 0.34486
[32m[0323 08:46:47 @monitor.py:363][0m validation_cost: 3.0732
[32m[0323 08:46:47 @monitor.py:363][0m wd_cost: 8.9674e-11
[32m[0323 08:46:47 @group.py:42][0m Callbacks took 124.815 sec in total. InferenceRunner: 124.191sec
[32m[0323 08:46:47 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16847/173481[03:00<27:53,93.59it/s] 10%|#         |17777/173481[03:10<27:43,93.59it/s] 16%|#6        |27790/173481[06:00<32:57,73.69it/s] 16%|#6        |28356/173481[06:10<32:49,73.69it/s] 21%|##1       |37105/173481[09:00<37:23,60.79it/s] 22%|##1       |37644/173481[09:10<37:14,60.79it/s] 27%|##6       |46758/173481[12:00<37:03,56.98it/s] 27%|##7       |47334/173481[12:10<36:53,56.98it/s] 33%|###2      |57105/173481[15:00<33:53,57.23it/s] 33%|###3      |57775/173481[15:10<33:41,57.23it/s] 39%|###9      |68110/173481[18:00<29:42,59.11it/s] 40%|###9      |68769/173481[18:10<29:31,59.11it/s] 46%|####5     |79210/173481[21:00<26:01,60.36it/s] 46%|####6     |79879/173481[21:11<25:50,60.36it/s] 52%|#####2    |90520/173481[24:00<22:27,61.57it/s] 53%|#####2    |91210/173481[24:11<22:16,61.57it/s] 58%|#####8    |101425/173481[27:00<19:40,61.06it/s] 59%|#####8    |102099/173481[27:11<19:28,61.06it/s] 65%|######4   |112550/173481[30:00<16:31,61.43it/s] 65%|######5   |113257/173481[30:11<16:20,61.43it/s] 71%|#######1  |123437/173481[33:00<13:41,60.95it/s] 72%|#######1  |124134/173481[33:11<13:29,60.95it/s] 77%|#######7  |134312/173481[36:00<10:45,60.68it/s] 78%|#######7  |134984/173481[36:11<10:34,60.68it/s] 84%|########3 |145280/173481[39:00<07:43,60.81it/s] 84%|########4 |145939/173481[39:12<07:32,60.81it/s] 90%|######### |156150/173481[42:00<04:46,60.59it/s] 90%|######### |156931/173481[42:12<04:33,60.59it/s] 96%|#########6|167274/173481[45:00<01:41,61.19it/s] 97%|#########6|168019/173481[45:12<01:29,61.19it/s]100%|##########|173481/173481[46:39<00:00,61.96it/s]
[32m[0323 09:33:27 @base.py:257][0m Epoch 27 (global_step 7980126) finished, time:2799.78 sec.
[32m[0323 09:33:27 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-7980126.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,159.19it/s]
26
[32m[0323 09:35:26 @monitor.py:363][0m QueueInput/queue_size: 0.61698
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.306
[32m[0323 09:35:26 @monitor.py:363][0m activation-summaries/output-rms: 0.021387
[32m[0323 09:35:26 @monitor.py:363][0m cross_entropy_loss: 3.0248
[32m[0323 09:35:26 @monitor.py:363][0m lr: 1.5259e-08
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67433
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27467
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26954
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20872
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 09:35:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 09:35:26 @monitor.py:363][0m train-error-top1: 0.72389
[32m[0323 09:35:26 @monitor.py:363][0m val-error-top1: 0.73801
[32m[0323 09:35:26 @monitor.py:363][0m val-utt-error: 0.34221
[32m[0323 09:35:26 @monitor.py:363][0m validation_cost: 3.0763
[32m[0323 09:35:26 @monitor.py:363][0m wd_cost: 8.967e-11
[32m[0323 09:35:26 @group.py:42][0m Callbacks took 118.835 sec in total. InferenceRunner: 118.254sec
[32m[0323 09:35:26 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17095/173481[03:00<27:26,94.97it/s] 10%|#         |18047/173481[03:10<27:16,94.97it/s] 17%|#7        |30119/173481[06:00<29:05,82.13it/s] 18%|#7        |30753/173481[06:10<28:57,82.13it/s] 24%|##3       |41361/173481[09:00<31:02,70.95it/s] 24%|##4       |42026/173481[09:10<30:52,70.95it/s] 34%|###4      |59742/173481[12:00<22:38,83.73it/s] 35%|###5      |60879/173481[12:10<22:24,83.73it/s] 45%|####5     |78578/173481[15:00<17:00,93.02it/s] 46%|####5     |79599/173481[15:10<16:49,93.02it/s] 55%|#####5    |96066/173481[18:00<13:34,95.04it/s] 56%|#####5    |97124/173481[18:10<13:23,95.04it/s] 65%|######5   |113299/173481[21:00<10:30,95.39it/s] 66%|######5   |114338/173481[21:11<10:20,95.39it/s] 74%|#######4  |129099/173481[24:00<08:05,91.42it/s] 75%|#######4  |129813/173481[24:11<07:57,91.42it/s] 81%|########1 |140637/173481[27:00<07:15,75.36it/s] 81%|########1 |141361/173481[27:11<07:06,75.36it/s] 88%|########7 |152049/173481[30:00<05:11,68.86it/s] 88%|########8 |152783/173481[30:11<05:00,68.86it/s] 94%|#########4|163621/173481[33:00<02:28,66.50it/s] 95%|#########4|164363/173481[33:11<02:17,66.50it/s]100%|##########|173481/173481[35:22<00:00,81.74it/s]
[32m[0323 10:10:48 @base.py:257][0m Epoch 28 (global_step 8153607) finished, time:2122.47 sec.
[32m[0323 10:10:49 @saver.py:84][0m Model saved to train_log/fcn2_w_16_a_16_quant_ends_True_preload/model-8153607.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,166.53it/s]
27
[32m[0323 10:12:42 @monitor.py:363][0m QueueInput/queue_size: 0.79599
[32m[0323 10:12:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.203
[32m[0323 10:12:42 @monitor.py:363][0m activation-summaries/output-rms: 0.02179
[32m[0323 10:12:42 @monitor.py:363][0m cross_entropy_loss: 3.0485
[32m[0323 10:12:42 @monitor.py:363][0m lr: 7.6294e-09
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.67432
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 2.156
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27467
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.061952
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26954
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.063535
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20872
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.064254
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.20659
[32m[0323 10:12:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.063219
[32m[0323 10:12:42 @monitor.py:363][0m train-error-top1: 0.73351
[32m[0323 10:12:42 @monitor.py:363][0m val-error-top1: 0.73784
[32m[0323 10:12:42 @monitor.py:363][0m val-utt-error: 0.34449
[32m[0323 10:12:42 @monitor.py:363][0m validation_cost: 3.0754
[32m[0323 10:12:42 @monitor.py:363][0m wd_cost: 8.9669e-11
[32m[0323 10:12:42 @group.py:42][0m Callbacks took 113.608 sec in total. InferenceRunner: 113.039sec
[32m[0323 10:12:42 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#1        |19163/173481[03:00<24:09,106.46it/s] 12%|#1        |20244/173481[03:10<23:59,106.46it/s] 22%|##2       |38437/173481[06:00<21:04,106.77it/s] 23%|##2       |39527/173481[06:10<20:54,106.77it/s] 33%|###3      |57673/173481[09:00<18:04,106.82it/s] 34%|###3      |58799/173481[09:10<17:53,106.82it/s] 43%|####2     |73972/173481[12:00<16:55,98.01it/s]  43%|####3     |74858/173481[12:10<16:46,98.01it/s] 51%|#####     |88111/173481[15:00<16:18,87.21it/s] 51%|#####1    |88982/173481[15:10<16:08,87.21it/s] 59%|#####8    |102192/173481[18:00<14:24,82.47it/s] 59%|#####9    |103057/173481[18:10<14:13,82.47it/s] 66%|######6   |114885/173481[21:00<12:50,76.03it/s] 67%|######6   |115602/173481[21:10<12:41,76.03it/s] 73%|#######2  |126548/173481[24:00<11:10,69.96it/s] 73%|#######3  |127265/173481[24:11<11:00,69.96it/s] 80%|#######9  |138573/173481[27:00<08:30,68.34it/s] 80%|########  |139342/173481[27:11<08:19,68.34it/s]srun: got SIGCONT
slurmstepd: *** JOB 82367 ON sls-titanx-1 CANCELLED AT 2018-03-23T10:41:19 ***
srun: forcing job termination
slurmstepd: *** STEP 82367.0 ON sls-titanx-1 CANCELLED AT 2018-03-23T10:41:19 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
