sls-titanx-1 1
SLURM_JOBID=82592
SLURM_TASKID=5
[32m[0323 10:57:36 @logger.py:67][0m Existing log file 'train_log/fcn1_w_32_a_32_quant_ends_False/log.log' backuped to 'train_log/fcn1_w_32_a_32_quant_ends_False/log.log.0323-105736'
[32m[0323 10:57:36 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=32 --bita=32 --quant_ends=False
[32m[0323 10:57:43 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 10:57:43 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 10:57:44 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 10:57:44 @drf_run.py:166][0m Using host: sls-titanx-1
[32m[0323 10:57:44 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 10:57:44 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 10:57:44 @drf_run.py:188][0m Using GPU: 1
[32m[0323 10:57:44 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 10:57:44 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 10:57:44 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 10:57:44 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0323 10:57:44 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0323 10:57:44 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0323 10:57:44 @registry.py:130][0m linear0 output: [None, 256]
[32m[0323 10:57:44 @registry.py:122][0m linear1 input: [None, 256]
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:57:44 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 10:57:44 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:57:44 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 10:57:44 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:57:44 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 10:57:44 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 10:57:44 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:57:44 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:57:44 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 10:57:44 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:57:44 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0323 10:57:44 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 10:57:44 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0323 10:57:44 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0323 10:57:44 @base.py:196][0m Setup callbacks graph ...
[32m[0323 10:57:45 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 10:57:45 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0323 10:57:45 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:57:45 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:57:45 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:57:45 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:57:45 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0323 10:57:45 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 10:57:45 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0323 10:57:45 @base.py:212][0m Creating the session ...
2018-03-23 10:57:45.708247: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-23 10:57:52.844962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:05:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-23 10:57:52.845005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:05:00.0, compute capability: 6.1)
[32m[0323 10:57:56 @base.py:220][0m Initializing the session ...
[32m[0323 10:57:56 @base.py:227][0m Graph Finalized.
[32m[0323 10:57:56 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 10:57:57 @monitor.py:251][0m Found existing JSON at train_log/fcn1_w_32_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 10:57:57 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 10:57:57 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |18206/173481[03:00<25:35,101.13it/s] 11%|#1        |19115/173481[03:10<25:26,101.13it/s] 20%|##        |35211/173481[06:00<23:35,97.69it/s]  21%|##        |36185/173481[06:10<23:25,97.69it/s] 30%|###       |52076/173481[09:00<21:09,95.64it/s] 31%|###       |53092/173481[09:10<20:58,95.64it/s] 40%|####      |69788/173481[12:00<17:48,97.00it/s] 41%|####      |70853/173481[12:10<17:37,97.00it/s] 50%|#####     |87023/173481[15:00<14:57,96.37it/s] 51%|#####     |87985/173481[15:10<14:47,96.37it/s] 59%|#####9    |102871/173481[18:00<12:47,92.01it/s] 60%|#####9    |103569/173481[18:10<12:39,92.01it/s] 66%|######5   |114421/173481[21:00<13:01,75.59it/s] 66%|######6   |115102/173481[21:11<12:52,75.59it/s] 73%|#######2  |125896/173481[24:00<11:28,69.16it/s] 73%|#######3  |126665/173481[24:11<11:16,69.16it/s] 79%|#######9  |137483/173481[27:00<08:59,66.67it/s] 80%|#######9  |138223/173481[27:11<08:48,66.67it/s] 86%|########5 |148711/173481[30:00<06:24,64.45it/s] 86%|########6 |149364/173481[30:11<06:14,64.45it/s] 92%|#########1|159044/173481[33:00<03:57,60.72it/s] 92%|#########2|159734/173481[33:11<03:46,60.72it/s] 98%|#########8|170215/173481[36:00<00:53,61.38it/s] 99%|#########8|170935/173481[36:11<00:41,61.38it/s]100%|##########|173481/173481[36:52<00:00,78.39it/s]
[32m[0323 11:34:50 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2212.99 sec.
[32m[0323 11:34:51 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.57it/s]
0
[32m[0323 11:36:51 @monitor.py:363][0m QueueInput/queue_size: 0.50816
[32m[0323 11:36:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.7605
[32m[0323 11:36:51 @monitor.py:363][0m activation-summaries/output-rms: 0.02723
[32m[0323 11:36:51 @monitor.py:363][0m cross_entropy_loss: 2.5982
[32m[0323 11:36:51 @monitor.py:363][0m lr: 0.001
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13525
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.63311
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.097461
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13319
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11944
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11309
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081144
[32m[0323 11:36:51 @monitor.py:363][0m train-error-top1: 0.64033
[32m[0323 11:36:51 @monitor.py:363][0m val-error-top1: 0.70519
[32m[0323 11:36:51 @monitor.py:363][0m val-utt-error: 0.37796
[32m[0323 11:36:51 @monitor.py:363][0m validation_cost: 2.9351
[32m[0323 11:36:51 @monitor.py:363][0m wd_cost: 0.65628
[32m[0323 11:36:51 @group.py:42][0m Callbacks took 120.553 sec in total. InferenceRunner: 120.229sec
[32m[0323 11:36:51 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13850/173481[03:00<34:34,76.93it/s]  8%|8         |14614/173481[03:10<34:25,76.93it/s] 15%|#4        |25765/173481[06:00<34:35,71.16it/s] 15%|#5        |26390/173481[06:10<34:27,71.16it/s] 21%|##        |36118/173481[09:00<35:59,63.61it/s] 21%|##1       |36712/173481[09:10<35:50,63.61it/s] 27%|##7       |46986/173481[12:00<34:01,61.95it/s] 27%|##7       |47607/173481[12:10<33:51,61.95it/s] 34%|###3      |58148/173481[15:00<31:00,61.97it/s] 34%|###3      |58849/173481[15:10<30:49,61.97it/s] 40%|###9      |69079/173481[18:00<28:21,61.34it/s] 40%|####      |69774/173481[18:11<28:10,61.34it/s] 46%|####6     |80315/173481[21:00<25:05,61.87it/s] 47%|####6     |80988/173481[21:11<24:54,61.87it/s] 53%|#####2    |91482/173481[24:00<22:03,61.95it/s] 53%|#####3    |92166/173481[24:11<21:52,61.95it/s] 59%|#####9    |102599/173481[27:00<19:05,61.85it/s] 60%|#####9    |103313/173481[27:11<18:54,61.85it/s] 66%|######5   |113968/173481[30:00<15:52,62.50it/s] 66%|######6   |114675/173481[30:11<15:40,62.50it/s] 72%|#######1  |124830/173481[33:00<13:12,61.40it/s] 72%|#######2  |125507/173481[33:11<13:01,61.40it/s] 78%|#######7  |135257/173481[36:00<10:41,59.61it/s] 78%|#######8  |135926/173481[36:11<10:29,59.61it/s] 84%|########3 |145645/173481[39:00<07:54,58.64it/s] 84%|########4 |146382/173481[39:12<07:42,58.64it/s] 90%|######### |156397/173481[42:00<04:48,59.18it/s] 91%|######### |157173/173481[42:12<04:35,59.18it/s] 97%|#########6|167639/173481[45:00<01:36,60.77it/s] 97%|#########7|168415/173481[45:12<01:23,60.77it/s]100%|##########|173481/173481[46:34<00:00,62.08it/s]
[32m[0323 12:23:26 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2794.63 sec.
[32m[0323 12:23:26 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-346962.
[32m[0323 12:23:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:50<00:00,170.83it/s]
1
[32m[0323 12:25:17 @monitor.py:363][0m QueueInput/queue_size: 0.11756
[32m[0323 12:25:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8838
[32m[0323 12:25:17 @monitor.py:363][0m activation-summaries/output-rms: 0.028843
[32m[0323 12:25:17 @monitor.py:363][0m cross_entropy_loss: 2.6474
[32m[0323 12:25:17 @monitor.py:363][0m lr: 0.001
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13583
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.87353
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.097489
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13366
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11708
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.08649
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11056
[32m[0323 12:25:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 12:25:17 @monitor.py:363][0m train-error-top1: 0.6433
[32m[0323 12:25:17 @monitor.py:363][0m val-error-top1: 0.70158
[32m[0323 12:25:17 @monitor.py:363][0m val-utt-error: 0.36431
[32m[0323 12:25:17 @monitor.py:363][0m validation_cost: 2.9172
[32m[0323 12:25:17 @monitor.py:363][0m wd_cost: 0.65069
[32m[0323 12:25:17 @group.py:42][0m Callbacks took 111.227 sec in total. InferenceRunner: 110.194sec
[32m[0323 12:25:17 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15864/173481[03:00<29:48,88.13it/s] 10%|9         |16538/173481[03:10<29:40,88.13it/s] 16%|#5        |27014/173481[06:00<33:33,72.74it/s] 16%|#5        |27598/173481[06:10<33:25,72.74it/s] 21%|##1       |37199/173481[09:00<35:41,63.65it/s] 22%|##1       |37803/173481[09:10<35:31,63.65it/s] 27%|##7       |47534/173481[12:00<34:46,60.37it/s] 28%|##7       |48133/173481[12:10<34:36,60.37it/s] 33%|###3      |57931/173481[15:00<32:37,59.04it/s] 34%|###3      |58599/173481[15:10<32:25,59.04it/s] 40%|###9      |69004/173481[18:00<28:54,60.25it/s] 40%|####      |69728/173481[18:10<28:42,60.25it/s] 46%|####6     |80529/173481[21:00<24:57,62.07it/s] 47%|####6     |81257/173481[21:11<24:45,62.07it/s] 53%|#####3    |92109/173481[24:00<21:27,63.18it/s] 54%|#####3    |92828/173481[24:11<21:16,63.18it/s] 60%|#####9    |103612/173481[27:00<18:19,63.54it/s] 60%|######    |104211/173481[27:11<18:10,63.54it/s] 66%|######6   |114968/173481[30:00<15:24,63.31it/s] 67%|######6   |115715/173481[30:11<15:12,63.31it/s] 73%|#######2  |126285/173481[33:00<12:28,63.09it/s] 73%|#######3  |127070/173481[33:11<12:15,63.09it/s] 80%|#######9  |138208/173481[36:00<09:05,64.62it/s] 80%|########  |138978/173481[36:11<08:53,64.62it/s] 86%|########6 |150054/173481[39:00<05:59,65.20it/s] 87%|########6 |150813/173481[39:12<05:47,65.20it/s] 93%|#########3|162094/173481[42:00<02:52,66.03it/s] 94%|#########3|162893/173481[42:12<02:40,66.03it/s]100%|##########|173481/173481[44:52<00:00,64.43it/s]
[32m[0323 13:10:10 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2692.68 sec.
[32m[0323 13:10:10 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-520443.
[32m[0323 13:10:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,188.89it/s]
2
[32m[0323 13:11:50 @monitor.py:363][0m QueueInput/queue_size: 0.3381
[32m[0323 13:11:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.8212
[32m[0323 13:11:50 @monitor.py:363][0m activation-summaries/output-rms: 0.035112
[32m[0323 13:11:50 @monitor.py:363][0m cross_entropy_loss: 2.1037
[32m[0323 13:11:50 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.18565
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0264
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.14131
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.17926
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088303
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.15851
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.08649
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.15251
[32m[0323 13:11:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 13:11:50 @monitor.py:363][0m train-error-top1: 0.54519
[32m[0323 13:11:50 @monitor.py:363][0m val-error-top1: 0.57546
[32m[0323 13:11:50 @monitor.py:363][0m val-utt-error: 0.21161
[32m[0323 13:11:50 @monitor.py:363][0m validation_cost: 2.2596
[32m[0323 13:11:50 @monitor.py:363][0m wd_cost: 0.25274
[32m[0323 13:11:50 @group.py:42][0m Callbacks took 100.220 sec in total. InferenceRunner: 99.656sec
[32m[0323 13:11:50 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12213/173481[03:00<39:37,67.84it/s]  7%|7         |12854/173481[03:10<39:27,67.84it/s] 14%|#3        |23513/173481[06:00<38:19,65.21it/s] 14%|#3        |24126/173481[06:10<38:10,65.21it/s] 20%|##        |35194/173481[09:00<35:25,65.05it/s] 21%|##        |35887/173481[09:10<35:15,65.05it/s] 27%|##7       |47173/173481[12:00<31:59,65.79it/s] 28%|##7       |47912/173481[12:10<31:48,65.79it/s] 34%|###4      |59123/173481[15:00<28:50,66.08it/s] 34%|###4      |59835/173481[15:10<28:39,66.08it/s] 41%|####1     |71318/173481[18:00<25:27,66.90it/s] 42%|####1     |72021/173481[18:10<25:16,66.90it/s] 48%|####8     |83278/173481[21:00<22:33,66.66it/s] 48%|####8     |83991/173481[21:11<22:22,66.66it/s] 55%|#####4    |95139/173481[24:00<19:42,66.27it/s] 55%|#####5    |95887/173481[24:11<19:30,66.27it/s] 62%|######1   |107231/173481[27:00<16:32,66.72it/s] 62%|######2   |107992/173481[27:11<16:21,66.72it/s] 69%|######8   |119085/173481[30:00<13:40,66.29it/s] 69%|######9   |119817/173481[30:11<13:29,66.29it/s] 76%|#######5  |130988/173481[33:00<10:41,66.21it/s] 76%|#######5  |131767/173481[33:11<10:30,66.21it/s] 83%|########2 |143162/173481[36:00<07:33,66.91it/s] 83%|########2 |143851/173481[36:11<07:22,66.91it/s] 89%|########9 |154716/173481[39:00<04:46,65.52it/s] 90%|########9 |155423/173481[39:12<04:35,65.52it/s] 96%|#########5|166180/173481[42:00<01:53,64.59it/s] 96%|#########6|166883/173481[42:12<01:42,64.59it/s]100%|##########|173481/173481[44:02<00:00,65.64it/s]
[32m[0323 13:55:53 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2642.98 sec.
[32m[0323 13:55:53 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-693924.
[32m[0323 13:55:54 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,210.55it/s]
3
[32m[0323 13:57:23 @monitor.py:363][0m QueueInput/queue_size: 0.13872
[32m[0323 13:57:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.4448
[32m[0323 13:57:23 @monitor.py:363][0m activation-summaries/output-rms: 0.035958
[32m[0323 13:57:23 @monitor.py:363][0m cross_entropy_loss: 2.0316
[32m[0323 13:57:23 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21688
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1011
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.1496
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20992
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088303
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.18634
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.17566
[32m[0323 13:57:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 13:57:23 @monitor.py:363][0m train-error-top1: 0.51555
[32m[0323 13:57:23 @monitor.py:363][0m val-error-top1: 0.55086
[32m[0323 13:57:23 @monitor.py:363][0m val-utt-error: 0.18468
[32m[0323 13:57:23 @monitor.py:363][0m validation_cost: 2.1449
[32m[0323 13:57:23 @monitor.py:363][0m wd_cost: 0.31971
[32m[0323 13:57:23 @group.py:42][0m Callbacks took 90.384 sec in total. InferenceRunner: 89.405sec
[32m[0323 13:57:23 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11353/173481[03:00<42:50,63.06it/s]  7%|6         |11996/173481[03:10<42:40,63.06it/s] 13%|#3        |22572/173481[06:00<40:07,62.69it/s] 13%|#3        |23136/173481[06:10<39:58,62.69it/s] 20%|#9        |34434/173481[09:00<36:04,64.25it/s] 20%|##        |35104/173481[09:10<35:53,64.25it/s] 27%|##6       |46227/173481[12:00<32:41,64.88it/s] 27%|##7       |46896/173481[12:10<32:31,64.88it/s] 33%|###3      |57982/173481[15:00<29:34,65.09it/s] 34%|###3      |58687/173481[15:10<29:23,65.09it/s] 40%|####      |69550/173481[18:00<26:47,64.67it/s] 40%|####      |70161/173481[18:10<26:37,64.67it/s] 47%|####6     |80966/173481[21:00<24:04,64.04it/s] 47%|####7     |81681/173481[21:11<23:53,64.04it/s] 53%|#####3    |92535/173481[24:00<21:01,64.16it/s] 54%|#####3    |93241/173481[24:11<20:50,64.16it/s] 60%|######    |104097/173481[27:00<18:00,64.19it/s] 60%|######    |104828/173481[27:11<17:49,64.19it/s] 67%|######6   |115665/173481[30:00<15:00,64.23it/s] 67%|######7   |116406/173481[30:11<14:48,64.23it/s] 73%|#######3  |127207/173481[33:00<12:01,64.17it/s] 74%|#######3  |127964/173481[33:11<11:49,64.17it/s] 80%|########  |138820/173481[36:00<08:58,64.34it/s] 80%|########  |139583/173481[36:11<08:46,64.34it/s] 87%|########6 |150707/173481[39:00<05:49,65.18it/s] 87%|########7 |151473/173481[39:12<05:37,65.18it/s] 93%|#########3|162197/173481[42:00<02:54,64.49it/s] 94%|#########3|162976/173481[42:12<02:42,64.49it/s]100%|#########9|173062/173481[45:00<00:06,62.35it/s]100%|##########|173481/173481[45:07<00:00,64.08it/s]
[32m[0323 14:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2707.09 sec.
[32m[0323 14:42:30 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-867405.
[32m[0323 14:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,199.15it/s]
4
[32m[0323 14:44:05 @monitor.py:363][0m QueueInput/queue_size: 0.08951
[32m[0323 14:44:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.3922
[32m[0323 14:44:05 @monitor.py:363][0m activation-summaries/output-rms: 0.036802
[32m[0323 14:44:05 @monitor.py:363][0m cross_entropy_loss: 1.969
[32m[0323 14:44:05 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.22043
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.159
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.15087
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.21251
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.18906
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.17748
[32m[0323 14:44:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081143
[32m[0323 14:44:05 @monitor.py:363][0m train-error-top1: 0.51113
[32m[0323 14:44:05 @monitor.py:363][0m val-error-top1: 0.54856
[32m[0323 14:44:05 @monitor.py:363][0m val-utt-error: 0.19222
[32m[0323 14:44:05 @monitor.py:363][0m validation_cost: 2.1373
[32m[0323 14:44:05 @monitor.py:363][0m wd_cost: 0.32731
[32m[0323 14:44:05 @group.py:42][0m Callbacks took 95.134 sec in total. InferenceRunner: 94.526sec
[32m[0323 14:44:05 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12559/173481[03:00<38:26,69.76it/s]  8%|7         |13228/173481[03:10<38:17,69.76it/s] 14%|#4        |24341/173481[06:00<36:48,67.54it/s] 14%|#4        |25015/173481[06:10<36:38,67.54it/s] 20%|##        |35386/173481[09:00<35:47,64.29it/s] 21%|##        |36030/173481[09:10<35:37,64.29it/s] 28%|##8       |48902/173481[12:00<29:58,69.27it/s] 29%|##8       |49704/173481[12:10<29:46,69.27it/s] 36%|###6      |62936/173481[15:00<25:06,73.36it/s] 37%|###6      |63788/173481[15:10<24:55,73.36it/s] 44%|####4     |76715/173481[18:00<21:31,74.92it/s] 45%|####4     |77529/173481[18:10<21:20,74.92it/s] 52%|#####2    |90816/173481[21:00<17:59,76.58it/s] 53%|#####2    |91803/173481[21:11<17:46,76.58it/s] 59%|#####9    |102875/173481[24:00<16:27,71.47it/s] 60%|#####9    |103510/173481[24:11<16:19,71.47it/s] 66%|######5   |113651/173481[27:00<15:18,65.15it/s] 66%|######5   |114344/173481[27:11<15:07,65.15it/s] 72%|#######1  |124417/173481[30:00<13:06,62.37it/s] 72%|#######2  |125120/173481[30:11<12:55,62.37it/s] 78%|#######8  |135462/173481[33:00<10:14,61.86it/s] 78%|#######8  |136167/173481[33:11<10:03,61.86it/s] 84%|########4 |146417/173481[36:00<07:21,61.35it/s] 85%|########4 |147132/173481[36:11<07:09,61.35it/s] 91%|######### |157028/173481[39:00<04:33,60.13it/s] 91%|######### |157737/173481[39:12<04:21,60.13it/s] 97%|#########6|167988/173481[42:00<01:30,60.50it/s] 97%|#########7|168720/173481[42:12<01:18,60.50it/s]100%|##########|173481/173481[43:31<00:00,66.44it/s]
[32m[0323 15:27:36 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:2611.10 sec.
[32m[0323 15:27:37 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-1040886.
[32m[0323 15:27:37 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:26<00:00,128.80it/s]
5
[32m[0323 15:30:03 @monitor.py:363][0m QueueInput/queue_size: 0.21617
[32m[0323 15:30:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.646
[32m[0323 15:30:03 @monitor.py:363][0m activation-summaries/output-rms: 0.038364
[32m[0323 15:30:03 @monitor.py:363][0m cross_entropy_loss: 1.7684
[32m[0323 15:30:03 @monitor.py:363][0m lr: 0.00025
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26295
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1974
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.19073
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.23458
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.20873
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.19789
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081143
[32m[0323 15:30:03 @monitor.py:363][0m train-error-top1: 0.47129
[32m[0323 15:30:03 @monitor.py:363][0m val-error-top1: 0.48802
[32m[0323 15:30:03 @monitor.py:363][0m val-utt-error: 0.13946
[32m[0323 15:30:03 @monitor.py:363][0m validation_cost: 1.8583
[32m[0323 15:30:03 @monitor.py:363][0m wd_cost: 0.091412
[32m[0323 15:30:03 @group.py:42][0m Callbacks took 146.891 sec in total. InferenceRunner: 146.143sec
[32m[0323 15:30:03 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14045/173481[03:00<34:03,78.03it/s]  8%|8         |14662/173481[03:10<33:55,78.03it/s] 14%|#4        |25150/173481[06:00<35:53,68.89it/s] 15%|#4        |25750/173481[06:10<35:44,68.89it/s] 20%|##        |35481/173481[09:00<36:43,62.62it/s] 21%|##        |36057/173481[09:10<36:34,62.62it/s] 26%|##6       |45510/173481[12:00<36:10,58.96it/s] 27%|##6       |46113/173481[12:10<36:00,58.96it/s] 33%|###2      |56445/173481[15:00<32:35,59.83it/s] 33%|###2      |57133/173481[15:10<32:24,59.83it/s] 39%|###8      |67332/173481[18:00<29:24,60.16it/s] 39%|###9      |68004/173481[18:11<29:13,60.16it/s] 45%|####5     |78540/173481[21:00<25:51,61.19it/s] 46%|####5     |79195/173481[21:11<25:40,61.19it/s] 52%|#####1    |89865/173481[24:00<22:27,62.04it/s] 52%|#####2    |90591/173481[24:11<22:16,62.04it/s] 58%|#####8    |101109/173481[27:00<19:22,62.25it/s] 59%|#####8    |101789/173481[27:11<19:11,62.25it/s] 65%|######4   |112189/173481[30:00<16:30,61.90it/s] 65%|######5   |112829/173481[30:11<16:19,61.90it/s] 71%|#######   |123120/173481[33:00<13:41,61.31it/s] 71%|#######1  |123824/173481[33:11<13:29,61.31it/s] 77%|#######7  |134101/173481[36:00<10:43,61.16it/s] 78%|#######7  |134804/173481[36:11<10:32,61.16it/s] 84%|########4 |146234/173481[39:00<07:04,64.13it/s] 85%|########4 |147074/173481[39:12<06:51,64.13it/s] 91%|#########1|158179/173481[42:00<03:54,65.22it/s] 92%|#########1|159220/173481[42:12<03:38,65.22it/s]100%|##########|173481/173481[44:42<00:00,64.67it/s]
[32m[0323 16:14:46 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:2682.73 sec.
[32m[0323 16:14:46 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-1214367.
[32m[0323 16:14:47 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.77it/s]
6
[32m[0323 16:16:47 @monitor.py:363][0m QueueInput/queue_size: 0.2411
[32m[0323 16:16:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 17.208
[32m[0323 16:16:47 @monitor.py:363][0m activation-summaries/output-rms: 0.039478
[32m[0323 16:16:47 @monitor.py:363][0m cross_entropy_loss: 1.7581
[32m[0323 16:16:47 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31871
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2178
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.21717
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.271
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.24086
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.23041
[32m[0323 16:16:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081143
[32m[0323 16:16:47 @monitor.py:363][0m train-error-top1: 0.46837
[32m[0323 16:16:47 @monitor.py:363][0m val-error-top1: 0.47682
[32m[0323 16:16:47 @monitor.py:363][0m val-utt-error: 0.1291
[32m[0323 16:16:47 @monitor.py:363][0m validation_cost: 1.8077
[32m[0323 16:16:47 @monitor.py:363][0m wd_cost: 0.12319
[32m[0323 16:16:47 @group.py:42][0m Callbacks took 121.076 sec in total. InferenceRunner: 120.076sec
[32m[0323 16:16:47 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17384/173481[03:00<26:56,96.57it/s] 11%|#         |18344/173481[03:10<26:46,96.57it/s] 17%|#6        |29279/173481[06:00<30:37,78.46it/s] 17%|#7        |29870/173481[06:10<30:30,78.46it/s] 23%|##2       |39759/173481[09:00<33:21,66.83it/s] 23%|##3       |40370/173481[09:10<33:11,66.83it/s] 29%|##9       |50329/173481[12:00<32:50,62.50it/s] 29%|##9       |50899/173481[12:10<32:41,62.50it/s] 35%|###5      |60754/173481[15:00<31:15,60.12it/s] 35%|###5      |61391/173481[15:10<31:04,60.12it/s] 42%|####1     |72114/173481[18:00<27:26,61.57it/s] 42%|####1     |72767/173481[18:10<27:15,61.57it/s] 48%|####8     |83450/173481[21:00<24:05,62.27it/s] 48%|####8     |84123/173481[21:11<23:55,62.27it/s] 55%|#####4    |94619/173481[24:00<21:08,62.16it/s] 55%|#####4    |95265/173481[24:11<20:58,62.16it/s] 61%|######1   |106085/173481[27:00<17:51,62.91it/s] 62%|######1   |106815/173481[27:11<17:39,62.91it/s] 68%|######7   |117684/173481[30:00<14:36,63.66it/s] 68%|######8   |118428/173481[30:11<14:24,63.66it/s] 74%|#######4  |128957/173481[33:00<11:45,63.14it/s] 75%|#######4  |129678/173481[33:11<11:33,63.14it/s] 81%|########1 |140529/173481[36:00<08:37,63.71it/s] 81%|########1 |141338/173481[36:11<08:24,63.71it/s] 88%|########7 |152434/173481[39:00<05:24,64.89it/s] 88%|########8 |153238/173481[39:12<05:11,64.89it/s] 94%|#########4|163774/173481[42:00<02:31,63.92it/s] 95%|#########4|164548/173481[42:12<02:19,63.92it/s]100%|##########|173481/173481[44:30<00:00,64.96it/s]
[32m[0323 17:01:18 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:2670.67 sec.
[32m[0323 17:01:18 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-1387848.
[32m[0323 17:01:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,184.55it/s]
7
[32m[0323 17:03:00 @monitor.py:363][0m QueueInput/queue_size: 0.26393
[32m[0323 17:03:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 20.091
[32m[0323 17:03:00 @monitor.py:363][0m activation-summaries/output-rms: 0.040048
[32m[0323 17:03:00 @monitor.py:363][0m cross_entropy_loss: 1.706
[32m[0323 17:03:00 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.35514
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2374
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.22331
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29001
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25775
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.24645
[32m[0323 17:03:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 17:03:00 @monitor.py:363][0m train-error-top1: 0.45424
[32m[0323 17:03:00 @monitor.py:363][0m val-error-top1: 0.47219
[32m[0323 17:03:00 @monitor.py:363][0m val-utt-error: 0.12565
[32m[0323 17:03:00 @monitor.py:363][0m validation_cost: 1.7865
[32m[0323 17:03:00 @monitor.py:363][0m wd_cost: 0.13938
[32m[0323 17:03:00 @group.py:42][0m Callbacks took 102.657 sec in total. InferenceRunner: 101.999sec
[32m[0323 17:03:00 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12208/173481[03:00<39:38,67.81it/s]  7%|7         |12849/173481[03:10<39:28,67.81it/s] 13%|#3        |23068/173481[06:00<39:15,63.85it/s] 14%|#3        |23702/173481[06:10<39:05,63.85it/s] 20%|#9        |34410/173481[09:00<36:32,63.43it/s] 20%|##        |35092/173481[09:10<36:21,63.43it/s] 27%|##6       |46098/173481[12:00<33:05,64.17it/s] 27%|##6       |46802/173481[12:10<32:54,64.17it/s] 33%|###3      |57427/173481[15:00<30:26,63.55it/s] 33%|###3      |58109/173481[15:10<30:15,63.55it/s] 40%|###9      |69101/173481[18:00<27:06,64.19it/s] 40%|####      |69852/173481[18:11<26:54,64.19it/s] 47%|####6     |80698/173481[21:00<24:02,64.31it/s] 47%|####6     |81393/173481[21:11<23:52,64.31it/s] 53%|#####2    |91783/173481[24:00<21:38,62.92it/s] 53%|#####3    |92452/173481[24:11<21:27,62.92it/s] 60%|#####9    |103257/173481[27:00<18:28,63.33it/s] 60%|#####9    |103987/173481[27:11<18:17,63.33it/s] 66%|######6   |114768/173481[30:00<15:22,63.64it/s] 67%|######6   |115520/173481[30:11<15:10,63.64it/s] 73%|#######2  |126148/173481[33:00<12:26,63.42it/s] 73%|#######3  |126909/173481[33:11<12:14,63.42it/s] 79%|#######9  |137413/173481[36:00<09:32,63.00it/s] 80%|#######9  |138172/173481[36:12<09:20,63.00it/s] 86%|########5 |148933/173481[39:00<06:26,63.49it/s] 86%|########6 |149697/173481[39:12<06:14,63.49it/s] 93%|#########2|160883/173481[42:00<03:14,64.90it/s] 93%|#########3|161687/173481[42:12<03:01,64.90it/s] 99%|#########8|171076/173481[45:00<00:39,60.48it/s] 99%|#########9|171757/173481[45:12<00:28,60.48it/s]100%|##########|173481/173481[45:42<00:00,63.27it/s]
[32m[0323 17:48:42 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:2742.01 sec.
[32m[0323 17:48:43 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-1561329.
[32m[0323 17:48:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:31<00:00,205.90it/s]
8
[32m[0323 17:50:15 @monitor.py:363][0m QueueInput/queue_size: 0.137
[32m[0323 17:50:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 24.927
[32m[0323 17:50:15 @monitor.py:363][0m activation-summaries/output-rms: 0.040628
[32m[0323 17:50:15 @monitor.py:363][0m cross_entropy_loss: 1.6245
[32m[0323 17:50:15 @monitor.py:363][0m lr: 0.000125
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.39373
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2496
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.24659
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.2999
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26622
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25494
[32m[0323 17:50:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 17:50:15 @monitor.py:363][0m train-error-top1: 0.43698
[32m[0323 17:50:15 @monitor.py:363][0m val-error-top1: 0.44622
[32m[0323 17:50:15 @monitor.py:363][0m val-utt-error: 0.11088
[32m[0323 17:50:15 @monitor.py:363][0m validation_cost: 1.6793
[32m[0323 17:50:15 @monitor.py:363][0m wd_cost: 0.032387
[32m[0323 17:50:15 @group.py:42][0m Callbacks took 92.075 sec in total. InferenceRunner: 91.431sec
[32m[0323 17:50:15 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11762/173481[03:00<41:15,65.33it/s]  7%|7         |12406/173481[03:10<41:05,65.33it/s] 13%|#3        |22615/173481[06:00<40:05,62.71it/s] 13%|#3        |23148/173481[06:10<39:57,62.71it/s] 20%|#9        |33991/173481[09:00<36:55,62.95it/s] 20%|#9        |34646/173481[09:10<36:45,62.95it/s] 26%|##6       |45287/173481[12:00<33:59,62.85it/s] 26%|##6       |45954/173481[12:10<33:48,62.85it/s] 33%|###2      |56654/173481[15:00<30:54,63.00it/s] 33%|###3      |57344/173481[15:10<30:43,63.00it/s] 39%|###8      |67618/173481[18:00<28:29,61.93it/s] 39%|###9      |68246/173481[18:10<28:19,61.93it/s] 45%|####5     |78690/173481[21:00<25:35,61.72it/s] 46%|####5     |79402/173481[21:11<25:24,61.72it/s] 52%|#####1    |90028/173481[24:00<22:18,62.34it/s] 52%|#####2    |90716/173481[24:11<22:07,62.34it/s] 58%|#####8    |100896/173481[27:00<19:43,61.34it/s] 59%|#####8    |101572/173481[27:11<19:32,61.34it/s] 64%|######4   |111506/173481[30:00<17:10,60.12it/s] 65%|######4   |112196/173481[30:11<16:59,60.12it/s] 71%|#######1  |123462/173481[33:00<13:12,63.11it/s] 72%|#######1  |124406/173481[33:11<12:57,63.11it/s] 80%|#######9  |138418/173481[36:00<08:08,71.73it/s] 80%|########  |139227/173481[36:11<07:57,71.73it/s] 87%|########7 |151037/173481[39:00<05:16,70.90it/s] 88%|########7 |151881/173481[39:12<05:04,70.90it/s] 95%|#########5|164842/173481[42:00<01:57,73.68it/s] 96%|#########5|165745/173481[42:12<01:44,73.68it/s]100%|##########|173481/173481[44:03<00:00,65.63it/s]
[32m[0323 18:34:18 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:2643.15 sec.
[32m[0323 18:34:18 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-1734810.
[32m[0323 18:34:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:32<00:00,204.57it/s]
9
[32m[0323 18:35:51 @monitor.py:363][0m QueueInput/queue_size: 0.17598
[32m[0323 18:35:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.43
[32m[0323 18:35:51 @monitor.py:363][0m activation-summaries/output-rms: 0.042627
[32m[0323 18:35:51 @monitor.py:363][0m cross_entropy_loss: 1.5727
[32m[0323 18:35:51 @monitor.py:363][0m lr: 0.000125
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.43357
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2566
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27028
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31179
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27652
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26546
[32m[0323 18:35:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 18:35:51 @monitor.py:363][0m train-error-top1: 0.41707
[32m[0323 18:35:51 @monitor.py:363][0m val-error-top1: 0.44458
[32m[0323 18:35:51 @monitor.py:363][0m val-utt-error: 0.10966
[32m[0323 18:35:51 @monitor.py:363][0m validation_cost: 1.6731
[32m[0323 18:35:51 @monitor.py:363][0m wd_cost: 0.037578
[32m[0323 18:35:51 @group.py:42][0m Callbacks took 93.029 sec in total. InferenceRunner: 92.023sec
[32m[0323 18:35:51 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11689/173481[03:00<41:31,64.94it/s]  7%|7         |12440/173481[03:10<41:19,64.94it/s] 14%|#3        |24210/173481[06:00<37:02,67.17it/s] 14%|#4        |24810/173481[06:10<36:53,67.17it/s] 20%|#9        |33933/173481[09:00<38:50,59.88it/s] 20%|#9        |34427/173481[09:10<38:42,59.88it/s] 24%|##4       |42480/173481[12:00<41:13,52.96it/s] 25%|##4       |42986/173481[12:10<41:03,52.96it/s] 29%|##9       |51078/173481[15:00<40:36,50.23it/s] 30%|##9       |51575/173481[15:10<40:26,50.23it/s] 35%|###4      |60022/173481[18:00<37:51,49.96it/s] 35%|###4      |60620/173481[18:11<37:39,49.96it/s] 40%|####      |69846/173481[21:00<33:06,52.16it/s] 41%|####      |70364/173481[21:11<32:56,52.16it/s] 45%|####5     |78884/173481[24:00<30:49,51.16it/s] 46%|####5     |79455/173481[24:11<30:37,51.16it/s] 51%|#####     |88106/173481[27:00<27:47,51.19it/s] 51%|#####1    |88695/173481[27:11<27:36,51.19it/s] 56%|#####6    |97422/173481[30:00<24:37,51.47it/s] 56%|#####6    |98002/173481[30:11<24:26,51.47it/s] 61%|######1   |106416/173481[33:00<22:02,50.70it/s] 62%|######1   |106999/173481[33:11<21:51,50.70it/s] 68%|######7   |117741/173481[36:00<16:32,56.15it/s] 68%|######8   |118415/173481[36:12<16:20,56.15it/s] 74%|#######4  |128433/173481[39:00<13:00,57.73it/s] 74%|#######4  |129195/173481[39:12<12:47,57.73it/s] 80%|#######9  |138746/173481[42:00<10:04,57.51it/s] 80%|########  |139422/173481[42:12<09:52,57.51it/s] 86%|########5 |148509/173481[45:00<07:27,55.82it/s] 86%|########5 |149168/173481[45:12<07:15,55.82it/s] 91%|#########1|158318/173481[48:00<04:34,55.15it/s] 92%|#########1|159024/173481[48:12<04:22,55.15it/s] 97%|#########6|167531/173481[51:00<01:52,53.08it/s] 97%|#########6|168160/173481[51:12<01:40,53.08it/s]100%|##########|173481/173481[52:59<00:00,54.57it/s]
[32m[0323 19:28:50 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3179.28 sec.
[32m[0323 19:28:50 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-1908291.
[32m[0323 19:28:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:48<00:00,174.06it/s]
10
[32m[0323 19:30:39 @monitor.py:363][0m QueueInput/queue_size: 0.34582
[32m[0323 19:30:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.396
[32m[0323 19:30:39 @monitor.py:363][0m activation-summaries/output-rms: 0.041495
[32m[0323 19:30:39 @monitor.py:363][0m cross_entropy_loss: 1.5665
[32m[0323 19:30:39 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.4689
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2631
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.285
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32155
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28505
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2742
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 19:30:39 @monitor.py:363][0m train-error-top1: 0.41703
[32m[0323 19:30:39 @monitor.py:363][0m val-error-top1: 0.43302
[32m[0323 19:30:39 @monitor.py:363][0m val-utt-error: 0.10339
[32m[0323 19:30:39 @monitor.py:363][0m validation_cost: 1.6235
[32m[0323 19:30:39 @monitor.py:363][0m wd_cost: 0.04174
[32m[0323 19:30:39 @group.py:42][0m Callbacks took 108.679 sec in total. InferenceRunner: 108.149sec
[32m[0323 19:30:39 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11505/173481[03:00<42:14,63.91it/s]  7%|6         |12034/173481[03:10<42:06,63.91it/s] 12%|#1        |20693/173481[06:00<44:51,56.76it/s] 12%|#2        |21269/173481[06:10<44:41,56.76it/s] 17%|#7        |30095/173481[09:00<43:55,54.40it/s] 18%|#7        |30631/173481[09:10<43:45,54.40it/s] 22%|##2       |38862/173481[12:00<43:39,51.39it/s] 23%|##2       |39389/173481[12:10<43:29,51.39it/s] 27%|##7       |47465/173481[15:00<42:24,49.52it/s] 28%|##7       |47986/173481[15:10<42:14,49.52it/s] 32%|###2      |56204/173481[18:00<39:51,49.03it/s] 33%|###2      |56769/173481[18:10<39:40,49.03it/s] 38%|###7      |65315/173481[21:00<36:12,49.80it/s] 38%|###7      |65874/173481[21:11<36:00,49.80it/s] 43%|####3     |74685/173481[24:00<32:21,50.89it/s] 43%|####3     |75250/173481[24:11<32:10,50.89it/s] 49%|####8     |84235/173481[27:00<28:38,51.93it/s] 49%|####8     |84832/173481[27:11<28:27,51.93it/s] 54%|#####3    |93643/173481[30:00<25:32,52.10it/s] 54%|#####4    |94225/173481[30:11<25:21,52.10it/s] 60%|#####9    |103275/173481[33:00<22:09,52.79it/s] 60%|#####9    |103869/173481[33:11<21:58,52.79it/s] 65%|######5   |112798/173481[36:00<19:08,52.85it/s] 65%|######5   |113415/173481[36:11<18:56,52.85it/s] 70%|#######   |122205/173481[39:00<16:15,52.55it/s] 71%|#######   |122840/173481[39:12<16:03,52.55it/s] 76%|#######5  |131655/173481[42:00<13:16,52.52it/s] 76%|#######6  |132234/173481[42:12<13:05,52.52it/s] 82%|########1 |142239/173481[45:00<09:23,55.48it/s] 82%|########2 |142969/173481[45:12<09:09,55.48it/s] 89%|########8 |153535/173481[48:00<05:38,58.89it/s] 89%|########8 |154285/173481[48:12<05:25,58.89it/s] 94%|#########4|163842/173481[51:00<02:46,58.06it/s] 95%|#########5|164982/173481[51:12<02:26,58.06it/s]100%|##########|173481/173481[52:50<00:00,54.72it/s]
[32m[0323 20:23:29 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3170.62 sec.
[32m[0323 20:23:30 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-2081772.
[32m[0323 20:23:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:31<00:00,205.57it/s]
11
[32m[0323 20:25:02 @monitor.py:363][0m QueueInput/queue_size: 0.54746
[32m[0323 20:25:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 34.436
[32m[0323 20:25:02 @monitor.py:363][0m activation-summaries/output-rms: 0.041738
[32m[0323 20:25:02 @monitor.py:363][0m cross_entropy_loss: 1.5955
[32m[0323 20:25:02 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.49282
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2672
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29681
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32512
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28798
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086492
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27732
[32m[0323 20:25:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 20:25:02 @monitor.py:363][0m train-error-top1: 0.42812
[32m[0323 20:25:02 @monitor.py:363][0m val-error-top1: 0.42973
[32m[0323 20:25:02 @monitor.py:363][0m val-utt-error: 0.099033
[32m[0323 20:25:02 @monitor.py:363][0m validation_cost: 1.6074
[32m[0323 20:25:02 @monitor.py:363][0m wd_cost: 0.0089296
[32m[0323 20:25:02 @group.py:42][0m Callbacks took 92.378 sec in total. InferenceRunner: 91.578sec
[32m[0323 20:25:02 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12199/173481[03:00<39:40,67.76it/s]  7%|7         |12918/173481[03:10<39:29,67.76it/s] 13%|#3        |23326/173481[06:00<38:42,64.65it/s] 14%|#3        |23938/173481[06:10<38:33,64.65it/s] 19%|#8        |32249/173481[09:00<41:57,56.11it/s] 19%|#8        |32778/173481[09:10<41:47,56.11it/s] 24%|##3       |41386/173481[12:00<41:18,53.30it/s] 24%|##4       |41930/173481[12:10<41:08,53.30it/s] 29%|##9       |50598/173481[15:00<39:13,52.22it/s] 29%|##9       |51148/173481[15:10<39:02,52.22it/s] 35%|###4      |60180/173481[18:00<35:49,52.72it/s] 35%|###5      |60763/173481[18:10<35:38,52.72it/s] 41%|####      |70538/173481[21:00<31:10,55.03it/s] 41%|####1     |71211/173481[21:11<30:58,55.03it/s] 47%|####6     |81177/173481[24:00<26:59,56.99it/s] 47%|####7     |81824/173481[24:11<26:48,56.99it/s] 53%|#####2    |91210/173481[27:00<24:19,56.36it/s] 53%|#####2    |91814/173481[27:11<24:09,56.36it/s] 58%|#####8    |101069/173481[30:00<21:43,55.55it/s] 59%|#####8    |101692/173481[30:11<21:32,55.55it/s] 64%|######4   |111049/173481[33:00<18:44,55.50it/s] 64%|######4   |111677/173481[33:11<18:33,55.50it/s] 70%|######9   |121270/173481[36:00<15:30,56.13it/s] 70%|#######   |121918/173481[36:11<15:18,56.13it/s] 76%|#######5  |131538/173481[39:00<12:21,56.58it/s] 76%|#######6  |132301/173481[39:12<12:07,56.58it/s] 82%|########2 |142852/173481[42:00<08:34,59.55it/s] 83%|########2 |143543/173481[42:12<08:22,59.55it/s] 89%|########8 |153843/173481[45:00<05:25,60.29it/s] 89%|########9 |154634/173481[45:12<05:12,60.29it/s] 95%|#########4|164319/173481[48:00<02:34,59.23it/s] 95%|#########5|165045/173481[48:12<02:22,59.23it/s]100%|##########|173481/173481[50:33<00:00,57.18it/s]
[32m[0323 21:15:35 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3033.79 sec.
[32m[0323 21:15:36 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-2255253.
[32m[0323 21:15:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:29<00:00,209.93it/s]
12
[32m[0323 21:17:06 @monitor.py:363][0m QueueInput/queue_size: 0.1429
[32m[0323 21:17:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.637
[32m[0323 21:17:06 @monitor.py:363][0m activation-summaries/output-rms: 0.041189
[32m[0323 21:17:06 @monitor.py:363][0m cross_entropy_loss: 1.5564
[32m[0323 21:17:06 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.51625
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2706
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.30727
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3288
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29109
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28057
[32m[0323 21:17:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 21:17:06 @monitor.py:363][0m train-error-top1: 0.4132
[32m[0323 21:17:06 @monitor.py:363][0m val-error-top1: 0.42903
[32m[0323 21:17:06 @monitor.py:363][0m val-utt-error: 0.1001
[32m[0323 21:17:06 @monitor.py:363][0m validation_cost: 1.605
[32m[0323 21:17:06 @monitor.py:363][0m wd_cost: 0.0094983
[32m[0323 21:17:06 @group.py:42][0m Callbacks took 90.202 sec in total. InferenceRunner: 89.672sec
[32m[0323 21:17:06 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11391/173481[03:00<42:41,63.28it/s]  7%|6         |11947/173481[03:10<42:32,63.28it/s] 12%|#1        |20675/173481[06:00<44:48,56.83it/s] 12%|#2        |21255/173481[06:10<44:38,56.83it/s] 18%|#8        |31328/173481[09:00<40:51,57.98it/s] 18%|#8        |31964/173481[09:10<40:40,57.98it/s] 24%|##4       |42406/173481[12:00<36:35,59.71it/s] 25%|##4       |43092/173481[12:10<36:23,59.71it/s] 31%|###       |53455/173481[15:00<33:02,60.53it/s] 31%|###1      |54063/173481[15:10<32:52,60.53it/s] 37%|###7      |64802/173481[18:00<29:19,61.76it/s] 38%|###7      |65526/173481[18:10<29:07,61.76it/s] 44%|####4     |76763/173481[21:00<25:10,64.01it/s] 45%|####4     |77499/173481[21:11<24:59,64.01it/s] 51%|#####1    |88773/173481[24:00<21:36,65.34it/s] 52%|#####1    |89550/173481[24:11<21:24,65.34it/s] 58%|#####8    |100834/173481[27:00<18:18,66.16it/s] 59%|#####8    |101586/173481[27:11<18:06,66.16it/s] 65%|######4   |112386/173481[30:00<15:37,65.15it/s] 65%|######5   |113115/173481[30:11<15:26,65.15it/s] 71%|#######1  |123961/173481[33:00<12:45,64.73it/s] 72%|#######1  |124736/173481[33:11<12:33,64.73it/s] 78%|#######8  |135658/173481[36:00<09:43,64.85it/s] 79%|#######8  |136367/173481[36:11<09:32,64.85it/s] 84%|########4 |146331/173481[39:00<07:18,61.94it/s] 85%|########4 |147133/173481[39:12<07:05,61.94it/s] 91%|#########1|158033/173481[42:00<04:03,63.44it/s] 92%|#########1|158811/173481[42:12<03:51,63.44it/s] 97%|#########7|168803/173481[45:00<01:15,61.58it/s] 98%|#########7|169510/173481[45:12<01:04,61.58it/s]100%|##########|173481/173481[46:23<00:00,62.33it/s]
[32m[0323 22:03:29 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:2783.13 sec.
[32m[0323 22:03:29 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-2428734.
[32m[0323 22:03:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:28<00:00,213.18it/s]
13
[32m[0323 22:04:58 @monitor.py:363][0m QueueInput/queue_size: 0.28606
[32m[0323 22:04:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.698
[32m[0323 22:04:58 @monitor.py:363][0m activation-summaries/output-rms: 0.041746
[32m[0323 22:04:58 @monitor.py:363][0m cross_entropy_loss: 1.539
[32m[0323 22:04:58 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.53522
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2735
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3144
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33135
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29319
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28282
[32m[0323 22:04:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 22:04:58 @monitor.py:363][0m train-error-top1: 0.41928
[32m[0323 22:04:58 @monitor.py:363][0m val-error-top1: 0.42298
[32m[0323 22:04:58 @monitor.py:363][0m val-utt-error: 0.095952
[32m[0323 22:04:58 @monitor.py:363][0m validation_cost: 1.5822
[32m[0323 22:04:58 @monitor.py:363][0m wd_cost: 0.0019864
[32m[0323 22:04:58 @group.py:42][0m Callbacks took 88.899 sec in total. InferenceRunner: 88.311sec
[32m[0323 22:04:58 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12256/173481[03:00<39:27,68.09it/s]  7%|7         |12940/173481[03:10<39:17,68.09it/s] 13%|#3        |23218/173481[06:00<38:57,64.29it/s] 14%|#3        |23752/173481[06:10<38:48,64.29it/s] 19%|#8        |32412/173481[09:00<41:18,56.92it/s] 19%|#9        |33020/173481[09:10<41:07,56.92it/s] 25%|##4       |42972/173481[12:00<37:38,57.78it/s] 25%|##5       |43578/173481[12:10<37:28,57.78it/s] 31%|###       |53372/173481[15:00<34:39,57.77it/s] 31%|###1      |53941/173481[15:10<34:29,57.77it/s] 36%|###5      |61742/173481[18:00<36:08,51.52it/s] 36%|###5      |62346/173481[18:10<35:57,51.52it/s] 42%|####1     |72602/173481[21:00<30:15,55.58it/s] 42%|####2     |73266/173481[21:11<30:03,55.58it/s] 48%|####7     |83212/173481[24:00<26:17,57.21it/s] 48%|####8     |83776/173481[24:11<26:08,57.21it/s] 53%|#####3    |92792/173481[27:00<24:23,55.14it/s] 54%|#####3    |93286/173481[27:11<24:14,55.14it/s] 58%|#####8    |101349/173481[30:00<23:32,51.05it/s] 59%|#####8    |101921/173481[30:11<23:21,51.05it/s] 65%|######4   |112426/173481[33:00<18:14,55.81it/s] 65%|######5   |113104/173481[33:11<18:01,55.81it/s] 71%|#######1  |123817/173481[36:00<13:57,59.30it/s] 72%|#######1  |124432/173481[36:11<13:47,59.30it/s] 77%|#######6  |133497/173481[39:00<11:49,56.39it/s] 77%|#######7  |134136/173481[39:12<11:37,56.39it/s] 83%|########2 |143359/173481[42:00<09:02,55.58it/s] 83%|########2 |143976/173481[42:12<08:50,55.58it/s] 89%|########8 |153985/173481[45:00<05:40,57.25it/s] 89%|########9 |154646/173481[45:12<05:28,57.25it/s] 95%|#########4|163954/173481[48:00<02:49,56.30it/s] 95%|#########4|164736/173481[48:12<02:35,56.30it/s]100%|##########|173481/173481[50:36<00:00,57.13it/s]
[32m[0323 22:55:35 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3036.86 sec.
[32m[0323 22:55:35 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-2602215.
[32m[0323 22:55:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.14it/s]
14
[32m[0323 22:57:22 @monitor.py:363][0m QueueInput/queue_size: 0.013891
[32m[0323 22:57:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 40.248
[32m[0323 22:57:22 @monitor.py:363][0m activation-summaries/output-rms: 0.04345
[32m[0323 22:57:22 @monitor.py:363][0m cross_entropy_loss: 1.5124
[32m[0323 22:57:22 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.548
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2751
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.31874
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33239
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29401
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2837
[32m[0323 22:57:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 22:57:22 @monitor.py:363][0m train-error-top1: 0.41017
[32m[0323 22:57:22 @monitor.py:363][0m val-error-top1: 0.42315
[32m[0323 22:57:22 @monitor.py:363][0m val-utt-error: 0.097599
[32m[0323 22:57:22 @monitor.py:363][0m validation_cost: 1.5806
[32m[0323 22:57:22 @monitor.py:363][0m wd_cost: 0.0020413
[32m[0323 22:57:22 @group.py:42][0m Callbacks took 107.404 sec in total. InferenceRunner: 106.866sec
[32m[0323 22:57:22 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13554/173481[03:00<35:23,75.30it/s]  8%|8         |14149/173481[03:10<35:16,75.30it/s] 15%|#4        |25521/173481[06:00<34:55,70.60it/s] 15%|#5        |26243/173481[06:10<34:45,70.60it/s] 21%|##1       |36519/173481[09:00<34:50,65.51it/s] 21%|##1       |37110/173481[09:10<34:41,65.51it/s] 27%|##7       |47261/173481[12:00<33:40,62.46it/s] 28%|##7       |47920/173481[12:10<33:30,62.46it/s] 33%|###3      |57758/173481[15:00<31:58,60.31it/s] 34%|###3      |58441/173481[15:10<31:47,60.31it/s] 39%|###9      |68334/173481[18:00<29:26,59.52it/s] 40%|###9      |68983/173481[18:10<29:15,59.52it/s] 46%|####5     |79411/173481[21:00<25:54,60.51it/s] 46%|####6     |80204/173481[21:11<25:41,60.51it/s] 53%|#####3    |91971/173481[24:00<20:57,64.81it/s] 53%|#####3    |92722/173481[24:11<20:46,64.81it/s] 60%|#####9    |103907/173481[27:00<17:41,65.55it/s] 60%|######    |104651/173481[27:11<17:30,65.55it/s] 67%|######7   |116706/173481[30:00<13:52,68.21it/s] 68%|######7   |117505/173481[30:11<13:40,68.21it/s] 74%|#######4  |128634/173481[33:00<11:07,67.22it/s] 75%|#######4  |129309/173481[33:11<10:57,67.22it/s] 81%|########  |139671/173481[36:00<08:47,64.13it/s] 81%|########  |140356/173481[36:11<08:36,64.13it/s] 87%|########6 |150366/173481[39:00<06:14,61.68it/s] 87%|########7 |151045/173481[39:11<06:03,61.68it/s] 93%|#########2|160867/173481[42:00<03:30,59.95it/s] 93%|#########3|161837/173481[42:12<03:14,59.95it/s]100%|##########|173481/173481[44:49<00:00,64.51it/s]
[32m[0323 23:42:11 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:2689.06 sec.
[32m[0323 23:42:11 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-2775696.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,186.29it/s]
15
[32m[0323 23:43:52 @monitor.py:363][0m QueueInput/queue_size: 0.099978
[32m[0323 23:43:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.556
[32m[0323 23:43:52 @monitor.py:363][0m activation-summaries/output-rms: 0.041951
[32m[0323 23:43:52 @monitor.py:363][0m cross_entropy_loss: 1.5202
[32m[0323 23:43:52 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56049
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2767
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32272
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33339
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29482
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28455
[32m[0323 23:43:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0323 23:43:52 @monitor.py:363][0m train-error-top1: 0.40493
[32m[0323 23:43:52 @monitor.py:363][0m val-error-top1: 0.4218
[32m[0323 23:43:52 @monitor.py:363][0m val-utt-error: 0.09457
[32m[0323 23:43:52 @monitor.py:363][0m validation_cost: 1.5772
[32m[0323 23:43:52 @monitor.py:363][0m wd_cost: 0.0020946
[32m[0323 23:43:52 @group.py:42][0m Callbacks took 101.245 sec in total. InferenceRunner: 101.046sec
[32m[0323 23:43:52 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12869/173481[03:00<37:26,71.49it/s]  8%|7         |13514/173481[03:10<37:17,71.49it/s] 14%|#4        |25031/173481[06:00<35:36,69.47it/s] 15%|#4        |25694/173481[06:10<35:27,69.47it/s] 21%|##1       |37264/173481[09:00<33:02,68.71it/s] 22%|##1       |37985/173481[09:10<32:52,68.71it/s] 28%|##8       |48920/173481[12:00<31:08,66.67it/s] 29%|##8       |49612/173481[12:10<30:57,66.67it/s] 36%|###6      |62711/173481[15:00<25:53,71.29it/s] 37%|###6      |63522/173481[15:10<25:42,71.29it/s] 44%|####3     |76145/173481[18:00<22:14,72.92it/s] 44%|####4     |77167/173481[18:10<22:00,72.92it/s] 53%|#####2    |91820/173481[21:00<17:08,79.37it/s] 53%|#####3    |92513/173481[21:11<17:00,79.37it/s] 61%|######    |105435/173481[24:00<14:38,77.46it/s] 61%|######1   |106338/173481[24:11<14:26,77.46it/s] 69%|######8   |119500/173481[27:00<11:33,77.78it/s] 69%|######9   |120431/173481[27:11<11:22,77.78it/s] 77%|#######6  |132946/173481[30:00<08:51,76.21it/s] 77%|#######7  |133660/173481[30:11<08:42,76.21it/s] 83%|########3 |144615/173481[33:00<06:52,70.05it/s] 84%|########3 |145338/173481[33:11<06:41,70.05it/s] 90%|########9 |155940/173481[36:00<04:24,66.29it/s] 90%|######### |156655/173481[36:11<04:13,66.29it/s] 96%|#########6|167350/173481[39:00<01:34,64.80it/s] 97%|#########6|168044/173481[39:12<01:23,64.80it/s]100%|##########|173481/173481[40:44<00:00,70.97it/s]
[32m[0324 00:24:37 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:2444.58 sec.
[32m[0324 00:24:37 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-2949177.
[32m[0324 00:24:37 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,171.14it/s]
16
[32m[0324 00:26:27 @monitor.py:363][0m QueueInput/queue_size: 0.16145
[32m[0324 00:26:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 42.756
[32m[0324 00:26:27 @monitor.py:363][0m activation-summaries/output-rms: 0.042395
[32m[0324 00:26:27 @monitor.py:363][0m cross_entropy_loss: 1.5491
[32m[0324 00:26:27 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56881
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2778
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32506
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33387
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29516
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28495
[32m[0324 00:26:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 00:26:27 @monitor.py:363][0m train-error-top1: 0.41822
[32m[0324 00:26:27 @monitor.py:363][0m val-error-top1: 0.41908
[32m[0324 00:26:27 @monitor.py:363][0m val-utt-error: 0.092711
[32m[0324 00:26:27 @monitor.py:363][0m validation_cost: 1.5641
[32m[0324 00:26:27 @monitor.py:363][0m wd_cost: 0.00042564
[32m[0324 00:26:27 @group.py:42][0m Callbacks took 110.571 sec in total. InferenceRunner: 109.989sec
[32m[0324 00:26:27 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13569/173481[03:00<35:21,75.38it/s]  8%|8         |14196/173481[03:10<35:13,75.38it/s] 14%|#4        |25113/173481[06:00<35:40,69.30it/s] 15%|#4        |25689/173481[06:10<35:32,69.30it/s] 20%|##        |34979/173481[09:00<37:42,61.21it/s] 21%|##        |35595/173481[09:10<37:32,61.21it/s] 26%|##6       |45264/173481[12:00<36:09,59.10it/s] 26%|##6       |45840/173481[12:10<35:59,59.10it/s] 32%|###1      |54879/173481[15:00<35:13,56.11it/s] 32%|###1      |55471/173481[15:10<35:03,56.11it/s] 37%|###7      |64989/173481[18:00<32:12,56.14it/s] 38%|###7      |65613/173481[18:10<32:01,56.14it/s] 44%|####3     |76122/173481[21:00<27:34,58.85it/s] 44%|####4     |76771/173481[21:11<27:23,58.85it/s] 50%|#####     |87074/173481[24:00<24:04,59.83it/s] 51%|#####     |87774/173481[24:11<23:52,59.83it/s] 56%|#####6    |97974/173481[27:00<20:54,60.19it/s] 57%|#####6    |98648/173481[27:11<20:43,60.19it/s] 63%|######2   |108844/173481[30:00<17:52,60.29it/s] 63%|######3   |109508/173481[30:11<17:41,60.29it/s] 69%|######9   |120349/173481[33:00<14:16,62.05it/s] 70%|######9   |121017/173481[33:11<14:05,62.05it/s] 76%|#######5  |131099/173481[36:00<11:36,60.86it/s] 76%|#######5  |131838/173481[36:11<11:24,60.86it/s] 82%|########1 |141959/173481[39:00<08:40,60.59it/s] 82%|########2 |142707/173481[39:12<08:27,60.59it/s] 88%|########8 |153056/173481[42:00<05:34,61.11it/s] 89%|########8 |153809/173481[42:12<05:21,61.11it/s] 95%|#########4|164384/173481[45:00<02:26,62.01it/s] 95%|#########5|165208/173481[45:12<02:13,62.01it/s]100%|##########|173481/173481[47:29<00:00,60.89it/s]
[32m[0324 01:13:57 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:2849.15 sec.
[32m[0324 01:13:57 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-3122658.
[32m[0324 01:13:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.28it/s]
17
[32m[0324 01:15:43 @monitor.py:363][0m QueueInput/queue_size: 0.15548
[32m[0324 01:15:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.448
[32m[0324 01:15:43 @monitor.py:363][0m activation-summaries/output-rms: 0.041658
[32m[0324 01:15:43 @monitor.py:363][0m cross_entropy_loss: 1.521
[32m[0324 01:15:43 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57539
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2788
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32669
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33414
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29536
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28517
[32m[0324 01:15:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 01:15:43 @monitor.py:363][0m train-error-top1: 0.41098
[32m[0324 01:15:43 @monitor.py:363][0m val-error-top1: 0.41886
[32m[0324 01:15:43 @monitor.py:363][0m val-utt-error: 0.092658
[32m[0324 01:15:43 @monitor.py:363][0m validation_cost: 1.5643
[32m[0324 01:15:43 @monitor.py:363][0m wd_cost: 0.0004307
[32m[0324 01:15:43 @group.py:42][0m Callbacks took 105.908 sec in total. InferenceRunner: 105.033sec
[32m[0324 01:15:43 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13378/173481[03:00<35:54,74.32it/s]  8%|8         |14027/173481[03:10<35:45,74.32it/s] 14%|#3        |23591/173481[06:00<38:49,64.35it/s] 14%|#3        |24082/173481[06:10<38:41,64.35it/s] 19%|#9        |33611/173481[09:00<39:03,59.69it/s] 20%|#9        |34270/173481[09:10<38:52,59.69it/s] 26%|##5       |44398/173481[12:00<35:58,59.81it/s] 26%|##5       |45092/173481[12:10<35:46,59.81it/s] 32%|###1      |55094/173481[15:00<33:05,59.61it/s] 32%|###2      |55625/173481[15:10<32:57,59.61it/s] 38%|###7      |65641/173481[18:00<30:24,59.10it/s] 38%|###8      |66345/173481[18:10<30:12,59.10it/s] 44%|####4     |76472/173481[21:00<27:06,59.63it/s] 44%|####4     |77139/173481[21:11<26:55,59.63it/s] 50%|####9     |86622/173481[24:00<24:58,57.96it/s] 50%|#####     |87227/173481[24:11<24:48,57.96it/s] 56%|#####5    |96381/173481[27:00<22:56,56.03it/s] 56%|#####5    |97030/173481[27:11<22:44,56.03it/s] 62%|######1   |106761/173481[30:00<19:33,56.83it/s] 62%|######1   |107424/173481[30:11<19:22,56.83it/s] 68%|######7   |117571/173481[33:00<15:57,58.40it/s] 68%|######8   |118253/173481[33:11<15:45,58.40it/s] 74%|#######3  |127882/173481[36:00<13:08,57.84it/s] 74%|#######4  |128544/173481[36:11<12:56,57.84it/s] 79%|#######9  |137668/173481[39:00<10:39,56.00it/s] 80%|#######9  |138697/173481[39:11<10:21,56.00it/s] 90%|######### |156773/173481[42:00<03:47,73.32it/s] 91%|#########1|157905/173481[42:12<03:32,73.32it/s]100%|##########|173481/173481[44:24<00:00,65.11it/s]
[32m[0324 02:00:07 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:2664.58 sec.
[32m[0324 02:00:07 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-3296139.
[32m[0324 02:00:08 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,188.44it/s]
18
[32m[0324 02:01:48 @monitor.py:363][0m QueueInput/queue_size: 0.57071
[32m[0324 02:01:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.422
[32m[0324 02:01:48 @monitor.py:363][0m activation-summaries/output-rms: 0.041835
[32m[0324 02:01:48 @monitor.py:363][0m cross_entropy_loss: 1.5232
[32m[0324 02:01:48 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58182
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2796
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32821
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33439
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29554
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28538
[32m[0324 02:01:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 02:01:48 @monitor.py:363][0m train-error-top1: 0.41233
[32m[0324 02:01:48 @monitor.py:363][0m val-error-top1: 0.41761
[32m[0324 02:01:48 @monitor.py:363][0m val-utt-error: 0.092339
[32m[0324 02:01:48 @monitor.py:363][0m validation_cost: 1.5603
[32m[0324 02:01:48 @monitor.py:363][0m wd_cost: 0.00043562
[32m[0324 02:01:48 @group.py:42][0m Callbacks took 100.752 sec in total. InferenceRunner: 99.895sec
[32m[0324 02:01:48 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#1        |20268/173481[03:00<22:40,112.60it/s] 12%|#2        |21206/173481[03:10<22:32,112.60it/s] 23%|##3       |40315/173481[06:00<19:49,111.98it/s] 24%|##3       |41233/173481[06:10<19:41,111.98it/s] 31%|###1      |54637/173481[09:00<21:17,93.02it/s]  32%|###1      |55495/173481[09:10<21:08,93.02it/s] 39%|###9      |67740/173481[12:00<21:34,81.67it/s] 39%|###9      |68421/173481[12:10<21:26,81.67it/s] 45%|####5     |78837/173481[15:00<22:27,70.26it/s] 46%|####5     |79481/173481[15:10<22:17,70.26it/s] 51%|#####1    |89257/173481[18:00<22:06,63.48it/s] 52%|#####1    |89975/173481[18:10<21:55,63.48it/s] 58%|#####7    |100003/173481[21:00<19:54,61.53it/s] 58%|#####8    |100646/173481[21:11<19:43,61.53it/s] 64%|######3   |110861/173481[24:00<17:07,60.92it/s] 64%|######4   |111536/173481[24:11<16:56,60.92it/s] 70%|#######   |121757/173481[27:00<14:11,60.72it/s] 71%|#######   |122443/173481[27:11<14:00,60.72it/s] 77%|#######6  |132827/173481[30:00<11:05,61.11it/s] 77%|#######6  |133545/173481[30:11<10:53,61.11it/s] 83%|########2 |143670/173481[33:00<08:11,60.67it/s] 83%|########3 |144374/173481[33:11<07:59,60.67it/s] 89%|########9 |154837/173481[36:00<05:03,61.34it/s] 90%|########9 |155577/173481[36:11<04:51,61.34it/s] 95%|#########5|165497/173481[39:00<02:12,60.26it/s] 96%|#########5|166194/173481[39:12<02:00,60.26it/s]100%|##########|173481/173481[41:12<00:00,70.17it/s]
[32m[0324 02:43:00 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:2472.46 sec.
[32m[0324 02:43:00 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-3469620.
[32m[0324 02:43:01 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,166.26it/s]
19
[32m[0324 02:44:55 @monitor.py:363][0m QueueInput/queue_size: 0.040477
[32m[0324 02:44:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.785
[32m[0324 02:44:55 @monitor.py:363][0m activation-summaries/output-rms: 0.043531
[32m[0324 02:44:55 @monitor.py:363][0m cross_entropy_loss: 1.4988
[32m[0324 02:44:55 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58525
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.28
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32892
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33446
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29558
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28543
[32m[0324 02:44:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 02:44:55 @monitor.py:363][0m train-error-top1: 0.40826
[32m[0324 02:44:55 @monitor.py:363][0m val-error-top1: 0.41809
[32m[0324 02:44:55 @monitor.py:363][0m val-utt-error: 0.094145
[32m[0324 02:44:55 @monitor.py:363][0m validation_cost: 1.5596
[32m[0324 02:44:55 @monitor.py:363][0m wd_cost: 8.7619e-05
[32m[0324 02:44:55 @group.py:42][0m Callbacks took 114.317 sec in total. InferenceRunner: 113.230sec
[32m[0324 02:44:55 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11756/173481[03:00<41:16,65.31it/s]  7%|7         |12344/173481[03:10<41:07,65.31it/s] 13%|#2        |22161/173481[06:00<41:07,61.33it/s] 13%|#3        |22743/173481[06:10<40:57,61.33it/s] 19%|#8        |32616/173481[09:00<39:21,59.66it/s] 19%|#9        |33260/173481[09:10<39:10,59.66it/s] 25%|##5       |43514/173481[12:00<36:02,60.10it/s] 25%|##5       |44155/173481[12:10<35:52,60.10it/s] 31%|###1      |53996/173481[15:00<33:40,59.14it/s] 31%|###1      |54639/173481[15:10<33:29,59.14it/s] 37%|###7      |64772/173481[18:00<30:27,59.50it/s] 38%|###7      |65372/173481[18:10<30:17,59.50it/s] 43%|####3     |75315/173481[21:00<27:42,59.03it/s] 44%|####3     |76011/173481[21:11<27:31,59.03it/s] 50%|####9     |86416/173481[24:00<24:03,60.32it/s] 50%|#####     |87073/173481[24:11<23:52,60.32it/s] 56%|#####6    |97674/173481[27:00<20:34,61.41it/s] 57%|#####6    |98360/173481[27:11<20:23,61.41it/s] 63%|######2   |108591/173481[30:00<17:43,61.02it/s] 63%|######2   |109280/173481[30:11<17:32,61.02it/s] 69%|######9   |119804/173481[33:00<14:30,61.65it/s] 69%|######9   |120505/173481[33:11<14:19,61.65it/s] 75%|#######5  |130886/173481[36:00<11:31,61.61it/s] 76%|#######5  |131589/173481[36:11<11:19,61.61it/s] 82%|########1 |142004/173481[39:00<08:30,61.69it/s] 82%|########2 |142720/173481[39:11<08:18,61.69it/s] 88%|########8 |152801/173481[42:00<05:40,60.82it/s] 88%|########8 |153510/173481[42:12<05:28,60.82it/s] 95%|#########4|164729/173481[45:00<02:17,63.42it/s] 96%|#########5|165706/173481[45:12<02:02,63.42it/s]100%|##########|173481/173481[47:12<00:00,61.24it/s]
[32m[0324 03:32:07 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:2832.71 sec.
[32m[0324 03:32:08 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-3643101.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,186.31it/s]
20
[32m[0324 03:33:49 @monitor.py:363][0m QueueInput/queue_size: 0.11517
[32m[0324 03:33:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.139
[32m[0324 03:33:49 @monitor.py:363][0m activation-summaries/output-rms: 0.042078
[32m[0324 03:33:49 @monitor.py:363][0m cross_entropy_loss: 1.5069
[32m[0324 03:33:49 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58871
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2805
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32959
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33454
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29563
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28548
[32m[0324 03:33:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 03:33:49 @monitor.py:363][0m train-error-top1: 0.40171
[32m[0324 03:33:49 @monitor.py:363][0m val-error-top1: 0.41728
[32m[0324 03:33:49 @monitor.py:363][0m val-utt-error: 0.094517
[32m[0324 03:33:49 @monitor.py:363][0m validation_cost: 1.5572
[32m[0324 03:33:49 @monitor.py:363][0m wd_cost: 8.8112e-05
[32m[0324 03:33:49 @group.py:42][0m Callbacks took 101.328 sec in total. InferenceRunner: 101.038sec
[32m[0324 03:33:49 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13154/173481[03:00<36:34,73.07it/s]  8%|7         |13797/173481[03:10<36:25,73.07it/s] 14%|#4        |24897/173481[06:00<35:55,68.93it/s] 15%|#4        |25548/173481[06:10<35:46,68.93it/s] 20%|##        |35449/173481[09:00<36:18,63.36it/s] 21%|##        |36043/173481[09:10<36:09,63.36it/s] 26%|##6       |45728/173481[12:00<35:26,60.07it/s] 27%|##6       |46338/173481[12:10<35:16,60.07it/s] 33%|###2      |57152/173481[15:00<31:24,61.72it/s] 33%|###3      |57779/173481[15:10<31:14,61.72it/s] 40%|###9      |69145/173481[18:00<27:08,64.08it/s] 40%|####      |69817/173481[18:10<26:57,64.08it/s] 46%|####6     |80148/173481[21:00<24:51,62.57it/s] 47%|####6     |80807/173481[21:11<24:41,62.57it/s] 53%|#####2    |91323/173481[24:00<21:58,62.32it/s] 53%|#####2    |91559/173481[24:11<21:54,62.32it/s] 59%|#####9    |102519/173481[27:00<18:59,62.26it/s] 60%|#####9    |103250/173481[27:11<18:48,62.26it/s] 66%|######6   |114504/173481[30:00<15:16,64.34it/s] 66%|######6   |115171/173481[30:11<15:06,64.34it/s] 72%|#######2  |125715/173481[33:00<12:34,63.29it/s] 73%|#######2  |126453/173481[33:11<12:23,63.29it/s] 79%|#######8  |136945/173481[36:00<09:41,62.83it/s] 79%|#######9  |137652/173481[36:11<09:30,62.83it/s] 85%|########5 |148218/173481[39:00<06:42,62.72it/s] 86%|########5 |148955/173481[39:11<06:31,62.72it/s] 92%|#########2|159625/173481[42:00<03:39,63.04it/s] 92%|#########2|160374/173481[42:12<03:27,63.04it/s] 98%|#########8|170832/173481[45:00<00:42,62.65it/s] 99%|#########8|171642/173481[45:12<00:29,62.65it/s]100%|##########|173481/173481[45:40<00:00,63.30it/s]
[32m[0324 04:19:29 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:2740.70 sec.
[32m[0324 04:19:30 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-3816582.
[32m[0324 04:19:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,187.07it/s]
21
[32m[0324 04:21:11 @monitor.py:363][0m QueueInput/queue_size: 0.017267
[32m[0324 04:21:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.691
[32m[0324 04:21:11 @monitor.py:363][0m activation-summaries/output-rms: 0.04252
[32m[0324 04:21:11 @monitor.py:363][0m cross_entropy_loss: 1.5361
[32m[0324 04:21:11 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59179
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2808
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33016
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3346
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29565
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28552
[32m[0324 04:21:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 04:21:11 @monitor.py:363][0m train-error-top1: 0.41681
[32m[0324 04:21:11 @monitor.py:363][0m val-error-top1: 0.41671
[32m[0324 04:21:11 @monitor.py:363][0m val-utt-error: 0.09117
[32m[0324 04:21:11 @monitor.py:363][0m validation_cost: 1.5545
[32m[0324 04:21:11 @monitor.py:363][0m wd_cost: 8.8546e-05
[32m[0324 04:21:11 @group.py:42][0m Callbacks took 101.438 sec in total. InferenceRunner: 100.626sec
[32m[0324 04:21:11 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12855/173481[03:00<37:29,71.42it/s]  8%|7         |13791/173481[03:10<37:16,71.42it/s] 15%|#5        |26760/173481[06:00<32:56,74.22it/s] 16%|#5        |27389/173481[06:10<32:48,74.22it/s] 22%|##1       |37564/173481[09:00<34:08,66.34it/s] 22%|##2       |38377/173481[09:10<33:56,66.34it/s] 28%|##7       |48481/173481[12:00<32:52,63.36it/s] 28%|##8       |49106/173481[12:10<32:42,63.36it/s] 34%|###4      |59234/173481[15:00<30:57,61.49it/s] 35%|###4      |59881/173481[15:10<30:47,61.49it/s] 41%|####      |70841/173481[18:00<27:10,62.95it/s] 41%|####1     |71559/173481[18:10<26:59,62.95it/s] 48%|####7     |82629/173481[21:00<23:35,64.19it/s] 48%|####8     |83328/173481[21:11<23:24,64.19it/s] 54%|#####4    |94338/173481[24:00<20:24,64.62it/s] 55%|#####4    |95008/173481[24:11<20:14,64.62it/s] 61%|######1   |105959/173481[27:00<17:25,64.59it/s] 62%|######1   |106786/173481[27:11<17:12,64.59it/s] 69%|######8   |119583/173481[30:00<12:53,69.70it/s] 69%|######9   |120395/173481[30:11<12:41,69.70it/s] 76%|#######6  |131942/173481[33:00<10:00,69.17it/s] 76%|#######6  |132707/173481[33:11<09:49,69.17it/s] 83%|########2 |143844/173481[36:00<07:18,67.61it/s] 83%|########3 |144605/173481[36:11<07:07,67.61it/s] 90%|########9 |155719/173481[39:00<04:25,66.78it/s] 90%|######### |156476/173481[39:11<04:14,66.78it/s] 97%|#########6|167802/173481[42:00<01:24,66.95it/s] 97%|#########7|168598/173481[42:12<01:12,66.95it/s]100%|##########|173481/173481[43:27<00:00,66.54it/s]
[32m[0324 05:04:38 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:2607.23 sec.
[32m[0324 05:04:38 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-3990063.
[32m[0324 05:04:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,186.29it/s]
22
[32m[0324 05:06:20 @monitor.py:363][0m QueueInput/queue_size: 0.079162
[32m[0324 05:06:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.81
[32m[0324 05:06:20 @monitor.py:363][0m activation-summaries/output-rms: 0.041785
[32m[0324 05:06:20 @monitor.py:363][0m cross_entropy_loss: 1.5131
[32m[0324 05:06:20 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59354
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2811
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33047
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33462
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28554
[32m[0324 05:06:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 05:06:20 @monitor.py:363][0m train-error-top1: 0.40591
[32m[0324 05:06:20 @monitor.py:363][0m val-error-top1: 0.41653
[32m[0324 05:06:20 @monitor.py:363][0m val-utt-error: 0.092126
[32m[0324 05:06:20 @monitor.py:363][0m validation_cost: 1.5543
[32m[0324 05:06:20 @monitor.py:363][0m wd_cost: 1.7757e-05
[32m[0324 05:06:20 @group.py:42][0m Callbacks took 101.915 sec in total. InferenceRunner: 101.050sec
[32m[0324 05:06:20 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13951/173481[03:00<34:18,77.50it/s]  8%|8         |14655/173481[03:10<34:09,77.50it/s] 14%|#4        |25047/173481[06:00<36:01,68.67it/s] 15%|#4        |25722/173481[06:10<35:51,68.67it/s] 21%|##1       |37189/173481[09:00<33:22,68.06it/s] 22%|##1       |37936/173481[09:10<33:11,68.06it/s] 29%|##8       |49486/173481[12:00<30:18,68.18it/s] 29%|##8       |50176/173481[12:10<30:08,68.18it/s] 36%|###5      |61651/173481[15:00<27:27,67.88it/s] 36%|###5      |62417/173481[15:10<27:16,67.88it/s] 43%|####3     |75017/173481[18:00<23:08,70.92it/s] 44%|####3     |75865/173481[18:10<22:56,70.92it/s] 51%|#####1    |88943/173481[21:00<19:02,74.00it/s] 52%|#####1    |89898/173481[21:11<18:49,74.00it/s] 59%|#####8    |102008/173481[24:00<16:15,73.27it/s] 59%|#####9    |102816/173481[24:11<16:04,73.27it/s] 66%|######6   |114553/173481[27:00<13:44,71.44it/s] 66%|######6   |115323/173481[27:11<13:34,71.44it/s] 73%|#######3  |126913/173481[30:00<11:05,70.02it/s] 74%|#######3  |127689/173481[30:11<10:53,70.02it/s] 80%|########  |139233/173481[33:00<08:14,69.22it/s] 81%|########  |140041/173481[33:11<08:03,69.22it/s] 88%|########7 |152275/173481[36:00<04:59,70.80it/s] 88%|########8 |153125/173481[36:11<04:47,70.80it/s] 99%|#########8|170939/173481[39:00<00:30,84.14it/s]100%|#########9|172908/173481[39:12<00:06,84.14it/s]100%|##########|173481/173481[39:15<00:00,73.64it/s]
[32m[0324 05:45:36 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:2355.74 sec.
[32m[0324 05:45:36 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-4163544.
[32m[0324 05:45:38 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,194.63it/s]
23
[32m[0324 05:47:15 @monitor.py:363][0m QueueInput/queue_size: 49.37
[32m[0324 05:47:15 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.119
[32m[0324 05:47:15 @monitor.py:363][0m activation-summaries/output-rms: 0.042494
[32m[0324 05:47:15 @monitor.py:363][0m cross_entropy_loss: 1.5087
[32m[0324 05:47:15 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5953
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2813
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33076
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33464
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 05:47:15 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 05:47:15 @monitor.py:363][0m train-error-top1: 0.4047
[32m[0324 05:47:15 @monitor.py:363][0m val-error-top1: 0.4149
[32m[0324 05:47:15 @monitor.py:363][0m val-utt-error: 0.091117
[32m[0324 05:47:15 @monitor.py:363][0m validation_cost: 1.5482
[32m[0324 05:47:15 @monitor.py:363][0m wd_cost: 1.7806e-05
[32m[0324 05:47:15 @group.py:42][0m Callbacks took 98.971 sec in total. InferenceRunner: 96.725sec
[32m[0324 05:47:15 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s] 11%|#         |18741/173481[03:00<24:46,104.11it/s] 11%|#1        |19675/173481[03:10<24:37,104.11it/s] 22%|##2       |38780/173481[06:00<20:51,107.60it/s] 23%|##3       |40566/173481[06:10<20:35,107.60it/s] 35%|###4      |60625/173481[09:00<16:29,114.07it/s] 36%|###5      |61856/173481[09:10<16:18,114.07it/s] 45%|####4     |77531/173481[12:00<15:31,103.02it/s] 45%|####5     |78520/173481[12:10<15:21,103.02it/s] 54%|#####4    |94246/173481[15:00<13:31,97.68it/s]  55%|#####4    |95263/173481[15:10<13:20,97.68it/s] 64%|######4   |111057/173481[18:00<10:53,95.49it/s] 65%|######4   |112069/173481[18:10<10:43,95.49it/s] 74%|#######3  |127857/173481[21:00<08:03,94.39it/s] 74%|#######4  |128884/173481[21:11<07:52,94.39it/s] 83%|########3 |144592/173481[24:00<05:08,93.68it/s] 84%|########3 |145628/173481[24:11<04:57,93.68it/s] 91%|#########1|158598/173481[27:00<02:55,85.01it/s] 92%|#########1|159076/173481[27:11<02:49,85.01it/s] 98%|#########7|169681/173481[30:00<00:53,71.42it/s] 98%|#########8|170456/173481[30:11<00:42,71.42it/s]100%|##########|173481/173481[30:58<00:00,93.37it/s]
[32m[0324 06:18:13 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:1858.17 sec.
[32m[0324 06:18:13 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-4337025.
[32m[0324 06:18:14 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:42<00:00,183.75it/s]
24
[32m[0324 06:19:56 @monitor.py:363][0m QueueInput/queue_size: 0.087791
[32m[0324 06:19:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.29
[32m[0324 06:19:56 @monitor.py:363][0m activation-summaries/output-rms: 0.043614
[32m[0324 06:19:56 @monitor.py:363][0m cross_entropy_loss: 1.4934
[32m[0324 06:19:56 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59649
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2814
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33097
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33465
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 06:19:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 06:19:56 @monitor.py:363][0m train-error-top1: 0.40543
[32m[0324 06:19:56 @monitor.py:363][0m val-error-top1: 0.41691
[32m[0324 06:19:56 @monitor.py:363][0m val-utt-error: 0.092764
[32m[0324 06:19:56 @monitor.py:363][0m validation_cost: 1.5545
[32m[0324 06:19:56 @monitor.py:363][0m wd_cost: 3.5677e-06
[32m[0324 06:19:56 @group.py:42][0m Callbacks took 103.160 sec in total. InferenceRunner: 102.441sec
[32m[0324 06:19:56 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12396/173481[03:00<38:59,68.86it/s]  8%|7         |13080/173481[03:10<38:49,68.86it/s] 14%|#4        |24296/173481[06:00<36:51,67.45it/s] 14%|#4        |24978/173481[06:10<36:41,67.45it/s] 21%|##        |35586/173481[09:00<35:21,65.00it/s] 21%|##        |36240/173481[09:10<35:11,65.00it/s] 27%|##7       |47121/173481[12:00<32:37,64.54it/s] 28%|##7       |47823/173481[12:10<32:27,64.54it/s] 34%|###4      |59023/173481[15:00<29:12,65.31it/s] 34%|###4      |59744/173481[15:10<29:01,65.31it/s] 41%|####      |70631/173481[18:00<26:24,64.90it/s] 41%|####1     |71295/173481[18:10<26:14,64.90it/s] 47%|####7     |82315/173481[21:00<23:24,64.90it/s] 48%|####7     |82973/173481[21:11<23:14,64.90it/s] 54%|#####4    |94101/173481[24:00<20:17,65.19it/s] 55%|#####4    |94856/173481[24:11<20:06,65.19it/s] 61%|######    |105696/173481[27:00<17:26,64.79it/s] 61%|######1   |106467/173481[27:11<17:14,64.79it/s] 68%|######7   |117716/173481[30:00<14:07,65.77it/s] 68%|######8   |118468/173481[30:11<13:56,65.77it/s] 75%|#######4  |129580/173481[33:00<11:06,65.83it/s] 75%|#######5  |130324/173481[33:11<10:55,65.83it/s] 81%|########1 |141190/173481[36:00<08:15,65.16it/s] 82%|########1 |141980/173481[36:11<08:03,65.16it/s] 88%|########7 |152656/173481[39:00<05:23,64.42it/s] 88%|########8 |153399/173481[39:11<05:11,64.42it/s] 95%|#########5|165160/173481[42:00<02:04,66.84it/s] 96%|#########5|166039/173481[42:12<01:51,66.84it/s]100%|##########|173481/173481[44:05<00:00,65.58it/s]
[32m[0324 07:04:01 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:2645.20 sec.
[32m[0324 07:04:01 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.98it/s]
25
[32m[0324 07:05:48 @monitor.py:363][0m QueueInput/queue_size: 0.22508
[32m[0324 07:05:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.313
[32m[0324 07:05:48 @monitor.py:363][0m activation-summaries/output-rms: 0.042123
[32m[0324 07:05:48 @monitor.py:363][0m cross_entropy_loss: 1.504
[32m[0324 07:05:48 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59739
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2815
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33111
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33466
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 07:05:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 07:05:48 @monitor.py:363][0m train-error-top1: 0.39978
[32m[0324 07:05:48 @monitor.py:363][0m val-error-top1: 0.41618
[32m[0324 07:05:48 @monitor.py:363][0m val-utt-error: 0.09287
[32m[0324 07:05:48 @monitor.py:363][0m validation_cost: 1.5528
[32m[0324 07:05:48 @monitor.py:363][0m wd_cost: 3.5726e-06
[32m[0324 07:05:48 @group.py:42][0m Callbacks took 106.623 sec in total. InferenceRunner: 106.373sec
[32m[0324 07:05:48 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13649/173481[03:00<35:08,75.81it/s]  8%|8         |14367/173481[03:10<34:58,75.81it/s] 15%|#4        |25709/173481[06:00<34:37,71.13it/s] 15%|#5        |26359/173481[06:10<34:28,71.13it/s] 21%|##1       |36635/173481[09:00<34:49,65.50it/s] 21%|##1       |37259/173481[09:10<34:39,65.50it/s] 27%|##7       |47276/173481[12:00<33:50,62.14it/s] 28%|##7       |47904/173481[12:10<33:40,62.14it/s] 34%|###3      |58471/173481[15:00<30:49,62.17it/s] 34%|###4      |59119/173481[15:10<30:39,62.17it/s] 40%|####      |69406/173481[18:00<28:13,61.45it/s] 40%|####      |70106/173481[18:10<28:02,61.45it/s] 47%|####6     |80899/173481[21:00<24:38,62.63it/s] 47%|####7     |81581/173481[21:11<24:27,62.63it/s] 53%|#####3    |92590/173481[24:00<21:08,63.76it/s] 54%|#####3    |93313/173481[24:11<20:57,63.76it/s] 60%|######    |104185/173481[27:00<18:01,64.09it/s] 61%|######    |104970/173481[27:11<17:49,64.09it/s] 67%|######6   |115895/173481[30:00<14:51,64.57it/s] 67%|######7   |116599/173481[30:11<14:40,64.57it/s] 73%|#######3  |126890/173481[33:00<12:22,62.78it/s] 74%|#######3  |127652/173481[33:11<12:10,62.78it/s] 79%|#######9  |137758/173481[36:00<09:40,61.55it/s] 80%|#######9  |138427/173481[36:11<09:29,61.55it/s] 86%|########5 |148570/173481[39:00<06:49,60.79it/s] 86%|########6 |149277/173481[39:11<06:38,60.79it/s] 92%|#########2|159875/173481[42:00<03:40,61.78it/s] 93%|#########2|160642/173481[42:12<03:27,61.78it/s] 99%|#########8|171314/173481[45:00<00:34,62.65it/s] 99%|#########9|172087/173481[45:12<00:22,62.65it/s]100%|##########|173481/173481[45:32<00:00,63.48it/s]
[32m[0324 07:51:21 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:2732.98 sec.
[32m[0324 07:51:21 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,172.26it/s]
26
[32m[0324 07:53:10 @monitor.py:363][0m QueueInput/queue_size: 0.24781
[32m[0324 07:53:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.604
[32m[0324 07:53:10 @monitor.py:363][0m activation-summaries/output-rms: 0.042568
[32m[0324 07:53:10 @monitor.py:363][0m cross_entropy_loss: 1.5316
[32m[0324 07:53:10 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59829
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2816
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33125
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33466
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 07:53:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 07:53:10 @monitor.py:363][0m train-error-top1: 0.41408
[32m[0324 07:53:10 @monitor.py:363][0m val-error-top1: 0.41602
[32m[0324 07:53:10 @monitor.py:363][0m val-utt-error: 0.090692
[32m[0324 07:53:10 @monitor.py:363][0m validation_cost: 1.5518
[32m[0324 07:53:10 @monitor.py:363][0m wd_cost: 3.5774e-06
[32m[0324 07:53:10 @group.py:42][0m Callbacks took 109.485 sec in total. InferenceRunner: 109.277sec
[32m[0324 07:53:10 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14707/173481[03:00<32:23,81.69it/s]  9%|8         |15423/173481[03:10<32:14,81.69it/s] 16%|#5        |27108/173481[06:00<32:38,74.74it/s] 16%|#5        |27707/173481[06:10<32:30,74.74it/s] 22%|##1       |37777/173481[09:00<34:12,66.11it/s] 22%|##2       |38407/173481[09:10<34:03,66.11it/s] 28%|##7       |48369/173481[12:00<33:31,62.21it/s] 28%|##7       |48548/173481[12:10<33:28,62.21it/s] 34%|###4      |59284/173481[15:00<30:59,61.41it/s] 35%|###4      |59909/173481[15:10<30:49,61.41it/s] 41%|####      |70864/173481[18:00<27:13,62.83it/s] 41%|####1     |71528/173481[18:10<27:02,62.83it/s] 48%|####7     |82864/173481[21:00<23:20,64.68it/s] 48%|####8     |83571/173481[21:11<23:10,64.68it/s] 55%|#####4    |94591/173481[24:00<20:15,64.91it/s] 55%|#####4    |95253/173481[24:11<20:05,64.91it/s] 61%|######1   |105849/173481[27:00<17:41,63.70it/s] 61%|######1   |106513/173481[27:11<17:31,63.70it/s] 68%|######7   |117958/173481[30:00<14:08,65.44it/s] 68%|######8   |118677/173481[30:11<13:57,65.44it/s] 75%|#######4  |129311/173481[33:00<11:27,64.23it/s] 75%|#######4  |129873/173481[33:11<11:18,64.23it/s] 81%|########1 |140822/173481[36:00<08:29,64.09it/s] 82%|########1 |141573/173481[36:11<08:17,64.09it/s] 88%|########7 |152591/173481[39:00<05:22,64.73it/s] 88%|########8 |153352/173481[39:11<05:10,64.73it/s] 95%|#########4|164471/173481[42:00<02:17,65.36it/s] 95%|#########5|165204/173481[42:12<02:06,65.36it/s]100%|##########|173481/173481[44:18<00:00,65.27it/s]
[32m[0324 08:37:28 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:2658.06 sec.
[32m[0324 08:37:29 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-4857468.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,184.65it/s]
27
[32m[0324 08:39:11 @monitor.py:363][0m QueueInput/queue_size: 0.11167
[32m[0324 08:39:11 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.553
[32m[0324 08:39:11 @monitor.py:363][0m activation-summaries/output-rms: 0.041805
[32m[0324 08:39:11 @monitor.py:363][0m cross_entropy_loss: 1.5092
[32m[0324 08:39:11 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59882
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2817
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33133
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33466
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 08:39:11 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 08:39:11 @monitor.py:363][0m train-error-top1: 0.40538
[32m[0324 08:39:11 @monitor.py:363][0m val-error-top1: 0.41598
[32m[0324 08:39:11 @monitor.py:363][0m val-utt-error: 0.091329
[32m[0324 08:39:11 @monitor.py:363][0m validation_cost: 1.5516
[32m[0324 08:39:11 @monitor.py:363][0m wd_cost: 7.1604e-07
[32m[0324 08:39:11 @group.py:42][0m Callbacks took 102.202 sec in total. InferenceRunner: 101.951sec
[32m[0324 08:39:11 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12795/173481[03:00<37:40,71.08it/s]  8%|7         |13452/173481[03:10<37:31,71.08it/s] 14%|#3        |23811/173481[06:00<37:55,65.77it/s] 14%|#4        |24422/173481[06:10<37:46,65.77it/s] 20%|##        |35188/173481[09:00<35:45,64.46it/s] 21%|##        |35895/173481[09:10<35:34,64.46it/s] 27%|##7       |47158/173481[12:00<32:09,65.46it/s] 28%|##7       |47880/173481[12:10<31:58,65.46it/s] 34%|###3      |58722/173481[15:00<29:29,64.84it/s] 34%|###4      |59417/173481[15:10<29:19,64.84it/s] 41%|####      |70647/173481[18:00<26:09,65.53it/s] 41%|####1     |71381/173481[18:10<25:58,65.53it/s] 48%|####7     |82653/173481[21:00<22:53,66.11it/s] 48%|####8     |83372/173481[21:11<22:43,66.11it/s] 54%|#####4    |94256/173481[24:00<20:13,65.27it/s] 54%|#####4    |94482/173481[24:11<20:10,65.27it/s] 61%|######1   |106387/173481[27:00<16:51,66.32it/s] 62%|######1   |107111/173481[27:11<16:40,66.32it/s] 68%|######8   |118412/173481[30:00<13:47,66.56it/s] 69%|######8   |119161/173481[30:11<13:36,66.56it/s] 75%|#######5  |130393/173481[33:00<10:47,66.56it/s] 76%|#######5  |131142/173481[33:11<10:36,66.56it/s] 82%|########2 |142387/173481[36:00<07:46,66.60it/s] 83%|########2 |143192/173481[36:11<07:34,66.60it/s] 89%|########9 |154668/173481[39:00<04:39,67.40it/s] 90%|########9 |155422/173481[39:11<04:27,67.40it/s]100%|#########9|173072/173481[42:00<00:05,81.24it/s]100%|##########|173481/173481[42:03<00:00,68.75it/s]
[32m[0324 09:21:14 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:2523.54 sec.
[32m[0324 09:21:14 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-5030949.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,178.18it/s]
28
[32m[0324 09:23:00 @monitor.py:363][0m QueueInput/queue_size: 0.25423
[32m[0324 09:23:00 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 47.084
[32m[0324 09:23:00 @monitor.py:363][0m activation-summaries/output-rms: 0.043087
[32m[0324 09:23:00 @monitor.py:363][0m cross_entropy_loss: 1.4996
[32m[0324 09:23:00 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59926
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2818
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3314
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28556
[32m[0324 09:23:00 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 09:23:00 @monitor.py:363][0m train-error-top1: 0.40421
[32m[0324 09:23:00 @monitor.py:363][0m val-error-top1: 0.41473
[32m[0324 09:23:00 @monitor.py:363][0m val-utt-error: 0.090957
[32m[0324 09:23:00 @monitor.py:363][0m validation_cost: 1.5474
[32m[0324 09:23:00 @monitor.py:363][0m wd_cost: 7.165e-07
[32m[0324 09:23:00 @group.py:42][0m Callbacks took 105.811 sec in total. InferenceRunner: 105.649sec
[32m[0324 09:23:00 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15521/173481[03:00<30:31,86.23it/s]  9%|9         |16106/173481[03:10<30:25,86.23it/s] 15%|#4        |25687/173481[06:00<36:05,68.25it/s] 15%|#5        |26366/173481[06:10<35:55,68.25it/s] 26%|##5       |44555/173481[09:00<25:59,82.67it/s] 26%|##6       |45702/173481[09:10<25:45,82.67it/s] 35%|###4      |60449/173481[12:00<22:03,85.39it/s] 35%|###5      |61301/173481[12:10<21:53,85.39it/s] 42%|####2     |73077/173481[15:00<21:43,77.02it/s] 43%|####2     |73811/173481[15:10<21:34,77.02it/s] 49%|####8     |84812/173481[18:00<20:55,70.61it/s] 49%|####9     |85538/173481[18:10<20:45,70.61it/s] 56%|#####5    |96426/173481[21:00<19:02,67.43it/s] 56%|#####5    |97145/173481[21:11<18:52,67.43it/s] 62%|######2   |108012/173481[24:00<16:34,65.86it/s] 63%|######2   |108711/173481[24:11<16:23,65.86it/s] 69%|######8   |119632/173481[27:00<13:45,65.19it/s] 69%|######9   |120354/173481[27:11<13:34,65.19it/s] 75%|#######5  |130942/173481[30:00<11:04,63.99it/s] 76%|#######5  |131786/173481[30:11<10:51,63.99it/s] 82%|########2 |142431/173481[33:00<08:05,63.91it/s] 83%|########2 |143166/173481[33:11<07:54,63.91it/s] 89%|########8 |153955/173481[36:00<05:05,63.97it/s] 89%|########9 |154724/173481[36:11<04:53,63.97it/s] 95%|#########5|165137/173481[39:00<02:12,63.03it/s] 96%|#########5|165834/173481[39:12<02:01,63.03it/s]100%|##########|173481/173481[41:19<00:00,69.98it/s]
[32m[0324 10:04:19 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:2479.10 sec.
[32m[0324 10:04:19 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-5204430.
[32m[0324 10:04:20 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,186.31it/s]
29
[32m[0324 10:06:01 @monitor.py:363][0m QueueInput/queue_size: 0.20567
[32m[0324 10:06:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.748
[32m[0324 10:06:01 @monitor.py:363][0m activation-summaries/output-rms: 0.043611
[32m[0324 10:06:01 @monitor.py:363][0m cross_entropy_loss: 1.4904
[32m[0324 10:06:01 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59966
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2818
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33147
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28556
[32m[0324 10:06:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 10:06:01 @monitor.py:363][0m train-error-top1: 0.40483
[32m[0324 10:06:01 @monitor.py:363][0m val-error-top1: 0.41659
[32m[0324 10:06:01 @monitor.py:363][0m val-utt-error: 0.09287
[32m[0324 10:06:01 @monitor.py:363][0m validation_cost: 1.5531
[32m[0324 10:06:01 @monitor.py:363][0m wd_cost: 7.1694e-07
[32m[0324 10:06:01 @group.py:42][0m Callbacks took 101.858 sec in total. InferenceRunner: 101.040sec
[32m[0324 10:06:01 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13866/173481[03:00<34:32,77.03it/s]  8%|8         |14485/173481[03:10<34:24,77.03it/s] 15%|#4        |25289/173481[06:00<35:29,69.59it/s] 15%|#4        |25963/173481[06:10<35:19,69.59it/s] 21%|##        |36279/173481[09:00<35:09,65.04it/s] 21%|##1       |36914/173481[09:10<34:59,65.04it/s] 27%|##7       |47371/173481[12:00<33:12,63.29it/s] 28%|##7       |48023/173481[12:10<33:02,63.29it/s] 34%|###3      |58301/173481[15:00<30:58,61.98it/s] 34%|###4      |59140/173481[15:10<30:44,61.98it/s] 40%|####      |69487/173481[18:00<27:55,62.06it/s] 40%|####      |70128/173481[18:10<27:45,62.06it/s] 47%|####6     |80831/173481[21:00<24:41,62.53it/s] 47%|####7     |81560/173481[21:11<24:30,62.53it/s] 53%|#####3    |92223/173481[24:00<21:31,62.90it/s] 54%|#####3    |92903/173481[24:11<21:20,62.90it/s] 60%|#####9    |103536/173481[27:00<18:32,62.87it/s] 60%|######    |104231/173481[27:11<18:21,62.87it/s] 66%|######6   |114966/173481[30:00<15:26,63.18it/s] 67%|######6   |115690/173481[30:11<15:14,63.18it/s] 73%|#######2  |126379/173481[33:00<12:24,63.28it/s] 73%|#######3  |127093/173481[33:11<12:13,63.28it/s] 79%|#######9  |137356/173481[36:00<09:41,62.11it/s] 80%|#######9  |138062/173481[36:11<09:30,62.11it/s] 85%|########5 |148306/173481[39:00<06:49,61.46it/s] 86%|########5 |149028/173481[39:11<06:37,61.46it/s] 92%|#########1|159110/173481[42:00<03:56,60.73it/s] 92%|#########2|159858/173481[42:12<03:44,60.73it/s] 99%|#########8|171146/173481[45:00<00:36,63.65it/s] 99%|#########9|171930/173481[45:12<00:24,63.65it/s]100%|##########|173481/173481[45:36<00:00,63.39it/s]
[32m[0324 10:51:37 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:2736.54 sec.
[32m[0324 10:51:38 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-5377911.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.61it/s]
30
[32m[0324 10:53:16 @monitor.py:363][0m QueueInput/queue_size: 0.10808
[32m[0324 10:53:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.674
[32m[0324 10:53:16 @monitor.py:363][0m activation-summaries/output-rms: 0.042139
[32m[0324 10:53:16 @monitor.py:363][0m cross_entropy_loss: 1.5012
[32m[0324 10:53:16 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59984
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2818
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3315
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28556
[32m[0324 10:53:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 10:53:16 @monitor.py:363][0m train-error-top1: 0.39916
[32m[0324 10:53:16 @monitor.py:363][0m val-error-top1: 0.41589
[32m[0324 10:53:16 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0324 10:53:16 @monitor.py:363][0m validation_cost: 1.5519
[32m[0324 10:53:16 @monitor.py:363][0m wd_cost: 1.4343e-07
[32m[0324 10:53:16 @group.py:42][0m Callbacks took 99.009 sec in total. InferenceRunner: 98.764sec
[32m[0324 10:53:16 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13282/173481[03:00<36:11,73.79it/s]  8%|8         |13943/173481[03:10<36:02,73.79it/s] 15%|#4        |25251/173481[06:00<35:19,69.95it/s] 15%|#4        |25871/173481[06:10<35:10,69.95it/s] 21%|##        |35895/173481[09:00<35:46,64.08it/s] 21%|##1       |36546/173481[09:10<35:36,64.08it/s] 27%|##6       |46658/173481[12:00<34:10,61.86it/s] 27%|##7       |47309/173481[12:10<33:59,61.86it/s] 33%|###3      |57788/173481[15:00<31:10,61.85it/s] 34%|###3      |58442/173481[15:10<31:00,61.85it/s] 39%|###9      |68453/173481[18:00<28:55,60.52it/s] 40%|###9      |69134/173481[18:10<28:44,60.52it/s] 46%|####5     |79586/173481[21:00<25:34,61.18it/s] 46%|####6     |80294/173481[21:11<25:23,61.18it/s] 52%|#####2    |90880/173481[24:00<22:13,61.95it/s] 53%|#####2    |91709/173481[24:11<22:00,61.95it/s] 59%|#####8    |102346/173481[27:00<18:52,62.81it/s] 59%|#####9    |103179/173481[27:11<18:39,62.81it/s] 66%|######6   |114646/173481[30:00<14:58,65.46it/s] 67%|######6   |115394/173481[30:11<14:47,65.46it/s] 73%|#######2  |126070/173481[33:00<12:15,64.44it/s] 73%|#######3  |126858/173481[33:11<12:03,64.44it/s] 81%|########1 |140815/173481[36:00<07:32,72.13it/s] 82%|########1 |141788/173481[36:11<07:19,72.13it/s] 89%|########8 |153933/173481[39:00<04:29,72.50it/s] 89%|########9 |154697/173481[39:12<04:19,72.50it/s] 96%|#########5|165728/173481[42:00<01:52,68.84it/s] 96%|#########5|166494/173481[42:12<01:41,68.84it/s]100%|##########|173481/173481[44:04<00:00,65.61it/s]
[32m[0324 11:37:21 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:2644.15 sec.
[32m[0324 11:37:21 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,191.71it/s]
31
[32m[0324 11:38:59 @monitor.py:363][0m QueueInput/queue_size: 0.039553
[32m[0324 11:38:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.868
[32m[0324 11:38:59 @monitor.py:363][0m activation-summaries/output-rms: 0.04259
[32m[0324 11:38:59 @monitor.py:363][0m cross_entropy_loss: 1.5289
[32m[0324 11:38:59 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60002
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33153
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28556
[32m[0324 11:38:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 11:38:59 @monitor.py:363][0m train-error-top1: 0.41415
[32m[0324 11:38:59 @monitor.py:363][0m val-error-top1: 0.41587
[32m[0324 11:38:59 @monitor.py:363][0m val-utt-error: 0.090745
[32m[0324 11:38:59 @monitor.py:363][0m validation_cost: 1.5509
[32m[0324 11:38:59 @monitor.py:363][0m wd_cost: 1.4347e-07
[32m[0324 11:38:59 @group.py:42][0m Callbacks took 98.375 sec in total. InferenceRunner: 98.190sec
[32m[0324 11:38:59 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12609/173481[03:00<38:18,69.99it/s]  8%|7         |13068/173481[03:10<38:11,69.99it/s] 14%|#4        |25059/173481[06:00<35:33,69.57it/s] 15%|#4        |25662/173481[06:10<35:24,69.57it/s] 20%|##        |35499/173481[09:00<36:21,63.26it/s] 21%|##        |36135/173481[09:10<36:11,63.26it/s] 27%|##6       |46139/173481[12:00<34:43,61.11it/s] 27%|##6       |46753/173481[12:10<34:33,61.11it/s] 33%|###2      |56609/173481[15:00<32:41,59.60it/s] 33%|###2      |57223/173481[15:10<32:30,59.60it/s] 39%|###8      |67555/173481[18:00<29:19,60.20it/s] 39%|###9      |68256/173481[18:10<29:08,60.20it/s] 46%|####5     |79629/173481[21:00<24:39,63.45it/s] 46%|####6     |80318/173481[21:11<24:28,63.45it/s] 53%|#####2    |91348/173481[24:00<21:18,64.26it/s] 53%|#####3    |92006/173481[24:11<21:07,64.26it/s] 59%|#####9    |102538/173481[27:00<18:42,63.20it/s] 60%|#####9    |103248/173481[27:11<18:31,63.20it/s] 66%|######5   |114179/173481[30:00<15:29,63.82it/s] 66%|######6   |114900/173481[30:11<15:17,63.82it/s] 73%|#######3  |127396/173481[33:00<11:14,68.29it/s] 74%|#######3  |128184/173481[33:11<11:03,68.29it/s] 81%|########  |140449/173481[36:00<07:49,70.34it/s] 81%|########1 |141213/173481[36:11<07:38,70.34it/s] 88%|########8 |153513/173481[39:00<04:39,71.43it/s] 89%|########8 |154317/173481[39:11<04:28,71.43it/s] 95%|#########5|165318/173481[42:00<01:59,68.38it/s] 96%|#########5|166023/173481[42:12<01:49,68.38it/s]100%|##########|173481/173481[44:11<00:00,65.44it/s]
[32m[0324 12:23:10 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:2651.18 sec.
[32m[0324 12:23:10 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-5724873.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.40it/s]
32
[32m[0324 12:24:57 @monitor.py:363][0m QueueInput/queue_size: 0.27231
[32m[0324 12:24:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.766
[32m[0324 12:24:57 @monitor.py:363][0m activation-summaries/output-rms: 0.041799
[32m[0324 12:24:57 @monitor.py:363][0m cross_entropy_loss: 1.509
[32m[0324 12:24:57 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60013
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33156
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 12:24:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 12:24:57 @monitor.py:363][0m train-error-top1: 0.40618
[32m[0324 12:24:57 @monitor.py:363][0m val-error-top1: 0.41582
[32m[0324 12:24:57 @monitor.py:363][0m val-utt-error: 0.090904
[32m[0324 12:24:57 @monitor.py:363][0m validation_cost: 1.5512
[32m[0324 12:24:57 @monitor.py:363][0m wd_cost: 1.435e-07
[32m[0324 12:24:57 @group.py:42][0m Callbacks took 106.925 sec in total. InferenceRunner: 106.722sec
[32m[0324 12:24:57 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13657/173481[03:00<35:06,75.87it/s]  8%|8         |14340/173481[03:10<34:57,75.87it/s] 14%|#3        |24256/173481[06:00<37:30,66.31it/s] 14%|#4        |24846/173481[06:10<37:21,66.31it/s] 20%|##        |35267/173481[09:00<36:11,63.64it/s] 21%|##        |35909/173481[09:10<36:01,63.64it/s] 27%|##7       |47018/173481[12:00<32:42,64.45it/s] 28%|##7       |47772/173481[12:10<32:30,64.45it/s] 34%|###4      |59791/173481[15:00<28:03,67.55it/s] 35%|###4      |60645/173481[15:10<27:50,67.55it/s] 43%|####2     |74126/173481[18:00<22:39,73.09it/s] 43%|####3     |74992/173481[18:10<22:27,73.09it/s] 50%|####9     |85998/173481[21:00<21:01,69.34it/s] 50%|####9     |86724/173481[21:11<20:51,69.34it/s] 56%|#####6    |97841/173481[24:00<18:40,67.52it/s] 57%|#####6    |98569/173481[24:11<18:29,67.52it/s] 63%|######3   |109556/173481[27:00<16:04,66.27it/s] 64%|######3   |110302/173481[27:11<15:53,66.27it/s] 70%|######9   |120926/173481[30:00<13:32,64.68it/s] 70%|#######   |121632/173481[30:11<13:21,64.68it/s] 76%|#######6  |132223/173481[33:00<10:47,63.70it/s] 77%|#######6  |133016/173481[33:11<10:35,63.70it/s] 83%|########3 |144117/173481[36:00<07:32,64.87it/s] 84%|########3 |144932/173481[36:11<07:20,64.87it/s] 90%|########9 |155866/173481[39:00<04:30,65.07it/s] 90%|######### |156629/173481[39:11<04:18,65.07it/s]100%|##########|173481/173481[41:57<00:00,68.90it/s]
[32m[0324 13:06:55 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:2517.79 sec.
[32m[0324 13:06:55 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.73it/s]
33
[32m[0324 13:08:34 @monitor.py:363][0m QueueInput/queue_size: 1.4468
[32m[0324 13:08:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.932
[32m[0324 13:08:34 @monitor.py:363][0m activation-summaries/output-rms: 0.041823
[32m[0324 13:08:34 @monitor.py:363][0m cross_entropy_loss: 1.5096
[32m[0324 13:08:34 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60012
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33157
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29567
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 13:08:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 13:08:34 @monitor.py:363][0m train-error-top1: 0.4068
[32m[0324 13:08:34 @monitor.py:363][0m val-error-top1: 0.41459
[32m[0324 13:08:34 @monitor.py:363][0m val-utt-error: 0.091436
[32m[0324 13:08:34 @monitor.py:363][0m validation_cost: 1.548
[32m[0324 13:08:34 @monitor.py:363][0m wd_cost: 2.87e-08
[32m[0324 13:08:34 @group.py:42][0m Callbacks took 98.866 sec in total. InferenceRunner: 98.720sec
[32m[0324 13:08:34 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16135/173481[03:00<29:15,89.64it/s] 10%|9         |16813/173481[03:10<29:07,89.64it/s] 16%|#5        |27572/173481[06:00<32:42,74.36it/s] 16%|#6        |28269/173481[06:10<32:32,74.36it/s] 27%|##7       |47151/173481[09:00<23:50,88.33it/s] 28%|##7       |48032/173481[09:10<23:40,88.33it/s] 36%|###5      |62070/173481[12:00<21:42,85.52it/s] 36%|###6      |62820/173481[12:10<21:34,85.52it/s] 43%|####2     |74116/173481[15:00<22:03,75.08it/s] 43%|####3     |74789/173481[15:10<21:54,75.08it/s] 49%|####9     |85456/173481[18:00<21:24,68.51it/s] 50%|####9     |86141/173481[18:10<21:14,68.51it/s] 56%|#####5    |96697/173481[21:00<19:35,65.34it/s] 56%|#####6    |97391/173481[21:11<19:24,65.34it/s] 62%|######2   |107792/173481[24:00<17:15,63.43it/s] 63%|######2   |108479/173481[24:11<17:04,63.43it/s] 69%|######8   |118975/173481[27:00<14:28,62.77it/s] 69%|######8   |119674/173481[27:11<14:17,62.77it/s] 75%|#######5  |130408/173481[30:00<11:22,63.14it/s] 76%|#######5  |131163/173481[30:11<11:10,63.14it/s] 82%|########1 |142023/173481[33:00<08:12,63.83it/s] 82%|########2 |142759/173481[33:11<08:01,63.83it/s] 89%|########8 |153558/173481[36:00<05:11,63.95it/s] 89%|########8 |154316/173481[36:11<04:59,63.95it/s] 95%|#########5|164974/173481[39:00<02:13,63.69it/s] 96%|#########5|165695/173481[39:11<02:02,63.69it/s]100%|##########|173481/173481[41:16<00:00,70.05it/s]
[32m[0324 13:49:50 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:2476.66 sec.
[32m[0324 13:49:51 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-6071835.
[32m[0324 13:49:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,186.84it/s]
34
[32m[0324 13:51:32 @monitor.py:363][0m QueueInput/queue_size: 0.12221
[32m[0324 13:51:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.863
[32m[0324 13:51:32 @monitor.py:363][0m activation-summaries/output-rms: 0.043606
[32m[0324 13:51:32 @monitor.py:363][0m cross_entropy_loss: 1.4899
[32m[0324 13:51:32 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.60011
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33158
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 13:51:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 13:51:32 @monitor.py:363][0m train-error-top1: 0.4056
[32m[0324 13:51:32 @monitor.py:363][0m val-error-top1: 0.41649
[32m[0324 13:51:32 @monitor.py:363][0m val-utt-error: 0.093083
[32m[0324 13:51:32 @monitor.py:363][0m validation_cost: 1.5526
[32m[0324 13:51:32 @monitor.py:363][0m wd_cost: 2.87e-08
[32m[0324 13:51:32 @group.py:42][0m Callbacks took 101.384 sec in total. InferenceRunner: 100.752sec
[32m[0324 13:51:32 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12611/173481[03:00<38:16,70.06it/s]  8%|7         |13295/173481[03:10<38:06,70.06it/s] 14%|#3        |24056/173481[06:00<37:21,66.66it/s] 14%|#4        |24695/173481[06:10<37:12,66.66it/s] 20%|#9        |34231/173481[09:00<37:58,61.12it/s] 20%|#9        |34440/173481[09:10<37:54,61.12it/s] 25%|##5       |43544/173481[12:00<38:38,56.04it/s] 25%|##5       |44100/173481[12:10<38:28,56.04it/s] 30%|###       |52726/173481[15:00<37:41,53.40it/s] 31%|###       |53248/173481[15:10<37:31,53.40it/s] 36%|###6      |62816/173481[18:00<33:43,54.69it/s] 37%|###6      |63466/173481[18:10<33:31,54.69it/s] 43%|####2     |73775/173481[21:00<28:50,57.62it/s] 43%|####2     |74405/173481[21:11<28:39,57.62it/s] 49%|####9     |85397/173481[24:00<24:06,60.89it/s] 50%|####9     |86045/173481[24:11<23:55,60.89it/s] 56%|#####5    |96990/173481[27:00<20:21,62.60it/s] 56%|#####6    |97711/173481[27:11<20:10,62.60it/s] 62%|######2   |108212/173481[30:00<17:24,62.47it/s] 63%|######2   |108924/173481[30:11<17:13,62.47it/s] 69%|######9   |119812/173481[33:00<14:05,63.44it/s] 69%|######9   |120516/173481[33:11<13:54,63.44it/s] 76%|#######5  |131074/173481[36:00<11:13,63.00it/s] 76%|#######5  |131785/173481[36:11<11:01,63.00it/s] 82%|########1 |141811/173481[39:00<08:37,61.24it/s] 82%|########2 |142537/173481[39:12<08:25,61.24it/s] 88%|########8 |153050/173481[42:00<05:30,61.83it/s] 89%|########8 |153735/173481[42:12<05:19,61.83it/s] 95%|#########5|165320/173481[45:00<02:05,64.84it/s] 96%|#########5|166138/173481[45:12<01:53,64.84it/s]100%|##########|173481/173481[47:11<00:00,61.28it/s]
[32m[0324 14:38:43 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:2831.13 sec.
[32m[0324 14:38:43 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,189.18it/s]
35
[32m[0324 14:40:23 @monitor.py:363][0m QueueInput/queue_size: 0.15487
[32m[0324 14:40:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.763
[32m[0324 14:40:23 @monitor.py:363][0m activation-summaries/output-rms: 0.042134
[32m[0324 14:40:23 @monitor.py:363][0m cross_entropy_loss: 1.5002
[32m[0324 14:40:23 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.6
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33159
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 14:40:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 14:40:23 @monitor.py:363][0m train-error-top1: 0.39886
[32m[0324 14:40:23 @monitor.py:363][0m val-error-top1: 0.41578
[32m[0324 14:40:23 @monitor.py:363][0m val-utt-error: 0.092498
[32m[0324 14:40:23 @monitor.py:363][0m validation_cost: 1.5516
[32m[0324 14:40:23 @monitor.py:363][0m wd_cost: 5.7394e-09
[32m[0324 14:40:23 @group.py:42][0m Callbacks took 99.696 sec in total. InferenceRunner: 99.503sec
[32m[0324 14:40:23 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13370/173481[03:00<35:55,74.28it/s]  8%|8         |14059/173481[03:10<35:46,74.28it/s] 14%|#4        |25005/173481[06:00<35:48,69.09it/s] 15%|#4        |25659/173481[06:10<35:39,69.09it/s] 20%|##        |35460/173481[09:00<36:27,63.10it/s] 21%|##        |36034/173481[09:10<36:18,63.10it/s] 26%|##6       |45865/173481[12:00<35:15,60.34it/s] 27%|##6       |46478/173481[12:10<35:04,60.34it/s] 33%|###2      |56462/173481[15:00<32:43,59.60it/s] 33%|###2      |57094/173481[15:10<32:32,59.60it/s] 39%|###8      |67096/173481[18:00<29:52,59.33it/s] 39%|###9      |67751/173481[18:10<29:41,59.33it/s] 45%|####4     |77923/173481[21:00<26:39,59.74it/s] 45%|####5     |78573/173481[21:11<26:28,59.74it/s] 51%|#####1    |88992/173481[24:00<23:14,60.60it/s] 52%|#####1    |89653/173481[24:11<23:03,60.60it/s] 58%|#####7    |100039/173481[27:00<20:04,60.98it/s] 58%|#####8    |100771/173481[27:11<19:52,60.98it/s] 64%|######4   |111591/173481[30:00<16:29,62.54it/s] 65%|######4   |112286/173481[30:11<16:18,62.54it/s] 71%|#######   |122379/173481[33:00<13:54,61.21it/s] 71%|#######   |123050/173481[33:11<13:43,61.21it/s] 77%|#######6  |133136/173481[36:00<11:07,60.47it/s] 77%|#######7  |133816/173481[36:11<10:55,60.47it/s] 83%|########2 |143612/173481[39:00<08:23,59.32it/s] 83%|########3 |144334/173481[39:11<08:11,59.32it/s] 89%|########9 |154658/173481[42:00<05:12,60.32it/s] 90%|########9 |155354/173481[42:12<05:00,60.32it/s] 95%|#########5|165398/173481[45:00<02:14,59.99it/s] 96%|#########5|166128/173481[45:12<02:02,59.99it/s]100%|##########|173481/173481[47:15<00:00,61.18it/s]
[32m[0324 15:27:38 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:2835.66 sec.
[32m[0324 15:27:38 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:18<00:00,136.31it/s]
36
[32m[0324 15:29:57 @monitor.py:363][0m QueueInput/queue_size: 0.15923
[32m[0324 15:29:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.922
[32m[0324 15:29:57 @monitor.py:363][0m activation-summaries/output-rms: 0.042597
[32m[0324 15:29:57 @monitor.py:363][0m cross_entropy_loss: 1.5284
[32m[0324 15:29:57 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59983
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33159
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 15:29:57 @monitor.py:363][0m train-error-top1: 0.41347
[32m[0324 15:29:57 @monitor.py:363][0m val-error-top1: 0.41581
[32m[0324 15:29:57 @monitor.py:363][0m val-utt-error: 0.090532
[32m[0324 15:29:57 @monitor.py:363][0m validation_cost: 1.5505
[32m[0324 15:29:57 @monitor.py:363][0m wd_cost: 5.7384e-09
[32m[0324 15:29:57 @group.py:42][0m Callbacks took 138.335 sec in total. InferenceRunner: 138.109sec
[32m[0324 15:29:57 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17199/173481[03:00<27:15,95.54it/s] 10%|#         |17913/173481[03:10<27:08,95.54it/s] 17%|#6        |28884/173481[06:00<31:10,77.29it/s] 17%|#7        |29500/173481[06:10<31:02,77.29it/s] 23%|##2       |39631/173481[09:00<33:06,67.37it/s] 23%|##3       |40247/173481[09:10<32:57,67.37it/s] 29%|##8       |50123/173481[12:00<32:53,62.49it/s] 29%|##9       |50723/173481[12:10<32:44,62.49it/s] 35%|###4      |60433/173481[15:00<31:31,59.77it/s] 35%|###5      |61033/173481[15:10<31:21,59.77it/s] 41%|####1     |71452/173481[18:00<28:06,60.48it/s] 42%|####1     |72190/173481[18:10<27:54,60.48it/s] 48%|####7     |83047/173481[21:00<24:09,62.39it/s] 48%|####8     |83759/173481[21:11<23:58,62.39it/s] 54%|#####4    |94496/173481[24:00<20:53,62.99it/s] 55%|#####4    |95152/173481[24:11<20:43,62.99it/s] 61%|######    |105389/173481[27:00<18:23,61.73it/s] 61%|######1   |106097/173481[27:11<18:11,61.73it/s] 68%|######7   |117360/173481[30:00<14:36,64.02it/s] 68%|######8   |118140/173481[30:11<14:24,64.02it/s] 74%|#######4  |128753/173481[33:00<11:42,63.65it/s] 75%|#######4  |129478/173481[33:11<11:31,63.65it/s] 81%|########  |140139/173481[36:00<08:45,63.45it/s] 81%|########1 |140878/173481[36:11<08:33,63.45it/s] 87%|########7 |151494/173481[39:00<05:47,63.26it/s] 88%|########7 |152255/173481[39:11<05:35,63.26it/s] 94%|#########4|163588/173481[42:00<02:31,65.17it/s] 95%|#########4|164685/173481[42:12<02:14,65.17it/s]100%|##########|173481/173481[44:08<00:00,65.51it/s]
[32m[0324 16:14:05 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:2648.12 sec.
[32m[0324 16:14:05 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-6592278.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:40<00:00,187.63it/s]
37
[32m[0324 16:15:45 @monitor.py:363][0m QueueInput/queue_size: 0.050976
[32m[0324 16:15:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.793
[32m[0324 16:15:45 @monitor.py:363][0m activation-summaries/output-rms: 0.041779
[32m[0324 16:15:45 @monitor.py:363][0m cross_entropy_loss: 1.5088
[32m[0324 16:15:45 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59966
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 16:15:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 16:15:45 @monitor.py:363][0m train-error-top1: 0.40704
[32m[0324 16:15:45 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0324 16:15:45 @monitor.py:363][0m val-utt-error: 0.090798
[32m[0324 16:15:45 @monitor.py:363][0m validation_cost: 1.5511
[32m[0324 16:15:45 @monitor.py:363][0m wd_cost: 5.7374e-09
[32m[0324 16:15:45 @group.py:42][0m Callbacks took 100.699 sec in total. InferenceRunner: 100.342sec
[32m[0324 16:15:45 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12376/173481[03:00<39:03,68.75it/s]  7%|7         |12974/173481[03:10<38:54,68.75it/s] 13%|#2        |22465/173481[06:00<40:45,61.75it/s] 13%|#3        |23047/173481[06:10<40:36,61.75it/s] 19%|#8        |32627/173481[09:00<39:48,58.98it/s] 19%|#9        |33168/173481[09:10<39:38,58.98it/s] 25%|##4       |43306/173481[12:00<36:40,59.15it/s] 25%|##5       |43938/173481[12:10<36:29,59.15it/s] 31%|###1      |54034/173481[15:00<33:31,59.37it/s] 32%|###1      |54657/173481[15:10<33:21,59.37it/s] 37%|###7      |64488/173481[18:00<30:56,58.72it/s] 38%|###7      |65115/173481[18:10<30:45,58.72it/s] 43%|####3     |75336/173481[21:00<27:30,59.48it/s] 44%|####3     |75952/173481[21:11<27:19,59.48it/s] 49%|####9     |85718/173481[24:00<24:58,58.56it/s] 50%|####9     |86357/173481[24:11<24:47,58.56it/s] 55%|#####5    |95943/173481[27:00<22:24,57.67it/s] 56%|#####5    |96594/173481[27:11<22:13,57.67it/s] 61%|######1   |106160/173481[30:00<19:36,57.21it/s] 62%|######1   |106837/173481[30:11<19:24,57.21it/s] 67%|######7   |116359/173481[33:00<16:43,56.93it/s] 67%|######7   |117046/173481[33:11<16:31,56.93it/s] 73%|#######2  |126621/173481[36:00<13:42,56.97it/s] 74%|#######3  |127591/173481[36:11<13:25,56.97it/s] 79%|#######9  |137481/173481[39:00<10:14,58.60it/s] 80%|#######9  |138197/173481[39:12<10:02,58.60it/s] 85%|########5 |147691/173481[42:00<07:27,57.64it/s] 86%|########5 |148389/173481[42:12<07:15,57.64it/s] 91%|#########1|157948/173481[45:00<04:31,57.31it/s] 91%|#########1|158674/173481[45:12<04:18,57.31it/s] 97%|#########6|167863/173481[48:00<01:40,56.17it/s] 97%|#########7|168520/173481[48:12<01:28,56.17it/s]100%|##########|173481/173481[49:45<00:00,58.11it/s]
[32m[0324 17:05:31 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:2985.44 sec.
[32m[0324 17:05:31 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:44<00:00,114.20it/s]
38
[32m[0324 17:08:16 @monitor.py:363][0m QueueInput/queue_size: 0.18995
[32m[0324 17:08:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.806
[32m[0324 17:08:16 @monitor.py:363][0m activation-summaries/output-rms: 0.041959
[32m[0324 17:08:16 @monitor.py:363][0m cross_entropy_loss: 1.5058
[32m[0324 17:08:16 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59941
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 17:08:16 @monitor.py:363][0m train-error-top1: 0.40819
[32m[0324 17:08:16 @monitor.py:363][0m val-error-top1: 0.41552
[32m[0324 17:08:16 @monitor.py:363][0m val-utt-error: 0.090639
[32m[0324 17:08:16 @monitor.py:363][0m validation_cost: 1.5513
[32m[0324 17:08:16 @monitor.py:363][0m wd_cost: 1.1471e-09
[32m[0324 17:08:16 @group.py:42][0m Callbacks took 165.262 sec in total. InferenceRunner: 164.864sec
[32m[0324 17:08:16 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11435/173481[03:00<42:31,63.52it/s]  7%|6         |11996/173481[03:10<42:22,63.52it/s] 12%|#2        |21529/173481[06:00<42:30,59.57it/s] 13%|#2        |22065/173481[06:10<42:21,59.57it/s] 18%|#8        |31644/173481[09:00<40:52,57.83it/s] 19%|#8        |32244/173481[09:10<40:42,57.83it/s] 24%|##4       |41952/173481[12:00<38:05,57.54it/s] 25%|##4       |42533/173481[12:10<37:55,57.54it/s] 30%|###       |52364/173481[15:00<34:59,57.69it/s] 31%|###       |53000/173481[15:10<34:48,57.69it/s] 36%|###6      |63293/173481[18:00<31:02,59.16it/s] 37%|###6      |63941/173481[18:10<30:51,59.16it/s] 42%|####2     |73722/173481[21:00<28:24,58.54it/s] 43%|####2     |74368/173481[21:11<28:12,58.54it/s] 49%|####8     |84195/173481[24:00<25:29,58.36it/s] 49%|####8     |84863/173481[24:11<25:18,58.36it/s] 55%|#####4    |94806/173481[27:00<22:21,58.65it/s] 55%|#####5    |95440/173481[27:11<22:10,58.65it/s] 61%|######    |105099/173481[30:00<19:41,57.90it/s] 61%|######    |105765/173481[30:11<19:29,57.90it/s] 67%|######6   |115527/173481[33:00<16:40,57.91it/s] 67%|######6   |116176/173481[33:11<16:29,57.91it/s] 73%|#######2  |126032/173481[36:00<13:36,58.12it/s] 73%|#######3  |126692/173481[36:11<13:25,58.12it/s] 79%|#######8  |136407/173481[39:00<10:40,57.88it/s] 79%|#######9  |137076/173481[39:12<10:29,57.88it/s] 85%|########4 |146850/173481[42:00<07:39,57.94it/s] 85%|########5 |147536/173481[42:12<07:27,57.94it/s] 91%|######### |157527/173481[45:00<04:32,58.62it/s] 91%|#########1|158280/173481[45:12<04:19,58.62it/s] 97%|#########6|167423/173481[48:00<01:46,56.74it/s] 97%|#########7|168496/173481[48:12<01:27,56.74it/s][32m[0324 17:57:59 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:2982.77 sec.
100%|##########|173481/173481[49:42<00:00,58.16it/s]
[32m[0324 17:57:59 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-6939240.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.27it/s]
39
[32m[0324 18:00:04 @monitor.py:363][0m QueueInput/queue_size: 0.22623
[32m[0324 18:00:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.83
[32m[0324 18:00:04 @monitor.py:363][0m activation-summaries/output-rms: 0.043576
[32m[0324 18:00:04 @monitor.py:363][0m cross_entropy_loss: 1.4887
[32m[0324 18:00:04 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59914
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 18:00:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 18:00:04 @monitor.py:363][0m train-error-top1: 0.40538
[32m[0324 18:00:04 @monitor.py:363][0m val-error-top1: 0.41642
[32m[0324 18:00:04 @monitor.py:363][0m val-utt-error: 0.092658
[32m[0324 18:00:04 @monitor.py:363][0m validation_cost: 1.5523
[32m[0324 18:00:05 @monitor.py:363][0m wd_cost: 1.1468e-09
[32m[0324 18:00:05 @group.py:42][0m Callbacks took 125.566 sec in total. InferenceRunner: 125.293sec
[32m[0324 18:00:05 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10874/173481[03:00<44:51,60.41it/s]  7%|6         |11456/173481[03:10<44:42,60.41it/s] 12%|#2        |21439/173481[06:00<42:33,59.54it/s] 13%|#2        |22028/173481[06:10<42:23,59.54it/s] 18%|#8        |31989/173481[09:00<39:55,59.07it/s] 19%|#8        |32579/173481[09:10<39:45,59.07it/s] 24%|##4       |42219/173481[12:00<37:46,57.92it/s] 25%|##4       |42833/173481[12:10<37:35,57.92it/s] 30%|##9       |51548/173481[15:00<37:09,54.70it/s] 30%|###       |52083/173481[15:10<36:59,54.70it/s] 36%|###5      |61612/173481[18:00<33:43,55.29it/s] 36%|###5      |62230/173481[18:10<33:31,55.29it/s] 41%|####1     |71604/173481[21:00<30:39,55.40it/s] 42%|####1     |72169/173481[21:11<30:28,55.40it/s] 47%|####6     |81519/173481[24:00<27:44,55.24it/s] 47%|####7     |82125/173481[24:11<27:33,55.24it/s] 52%|#####2    |90646/173481[27:00<26:06,52.87it/s] 53%|#####2    |91251/173481[27:11<25:55,52.87it/s] 58%|#####7    |99776/173481[30:00<23:43,51.76it/s] 58%|#####7    |100349/173481[30:11<23:32,51.76it/s] 63%|######3   |109445/173481[33:00<20:14,52.72it/s] 63%|######3   |110057/173481[33:11<20:03,52.72it/s] 68%|######8   |118555/173481[36:00<17:43,51.64it/s] 69%|######8   |119197/173481[36:11<17:31,51.64it/s] 74%|#######3  |127978/173481[39:00<14:35,51.99it/s] 74%|#######4  |128573/173481[39:12<14:23,51.99it/s] 79%|#######9  |137233/173481[42:00<11:41,51.70it/s] 79%|#######9  |137803/173481[42:12<11:30,51.70it/s] 84%|########4 |146438/173481[45:00<08:45,51.42it/s] 85%|########4 |147026/173481[45:12<08:34,51.42it/s] 90%|########9 |156016/173481[48:00<05:34,52.29it/s] 90%|######### |156669/173481[48:12<05:21,52.29it/s] 96%|#########5|165851/173481[51:00<02:22,53.43it/s] 96%|#########5|166506/173481[51:12<02:10,53.43it/s]100%|##########|173481/173481[53:19<00:00,54.22it/s]
[32m[0324 18:53:24 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:3199.42 sec.
[32m[0324 18:53:24 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:25<00:00,128.99it/s]
40
[32m[0324 18:55:50 @monitor.py:363][0m QueueInput/queue_size: 0.074365
[32m[0324 18:55:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.712
[32m[0324 18:55:50 @monitor.py:363][0m activation-summaries/output-rms: 0.0421
[32m[0324 18:55:50 @monitor.py:363][0m cross_entropy_loss: 1.5009
[32m[0324 18:55:50 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5989
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 18:55:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 18:55:50 @monitor.py:363][0m train-error-top1: 0.39948
[32m[0324 18:55:50 @monitor.py:363][0m val-error-top1: 0.41578
[32m[0324 18:55:50 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0324 18:55:50 @monitor.py:363][0m validation_cost: 1.5515
[32m[0324 18:55:50 @monitor.py:363][0m wd_cost: 1.1465e-09
[32m[0324 18:55:50 @group.py:42][0m Callbacks took 146.133 sec in total. InferenceRunner: 145.926sec
[32m[0324 18:55:50 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9832/173481[03:00<49:56,54.62it/s]  6%|5         |10376/173481[03:10<49:46,54.62it/s] 11%|#1        |19586/173481[06:00<47:08,54.40it/s] 12%|#1        |20173/173481[06:10<46:57,54.40it/s] 17%|#6        |29463/173481[09:00<43:55,54.64it/s] 17%|#7        |30048/173481[09:10<43:45,54.64it/s] 22%|##2       |38248/173481[12:00<43:43,51.56it/s] 22%|##2       |38702/173481[12:10<43:34,51.56it/s] 27%|##6       |46507/173481[15:00<43:35,48.55it/s] 27%|##7       |46996/173481[15:10<43:25,48.55it/s] 32%|###1      |55375/173481[18:00<40:15,48.90it/s] 32%|###2      |55915/173481[18:10<40:04,48.90it/s] 37%|###7      |64570/173481[21:00<36:19,49.97it/s] 38%|###7      |65156/173481[21:11<36:07,49.97it/s] 43%|####2     |74527/173481[24:00<31:24,52.50it/s] 43%|####3     |75134/173481[24:11<31:13,52.50it/s] 49%|####8     |84400/173481[27:00<27:40,53.65it/s] 49%|####9     |85012/173481[27:11<27:29,53.65it/s] 54%|#####4    |94308/173481[30:00<24:17,54.34it/s] 55%|#####4    |94946/173481[30:11<24:05,54.34it/s] 60%|######    |104238/173481[33:00<21:04,54.75it/s] 60%|######    |104879/173481[33:11<20:53,54.75it/s] 66%|######5   |114055/173481[36:00<18:07,54.64it/s] 66%|######6   |114600/173481[36:11<17:57,54.64it/s] 71%|#######   |123072/173481[39:00<16:04,52.27it/s] 71%|#######1  |123686/173481[39:12<15:52,52.27it/s] 76%|#######6  |132037/173481[42:00<13:32,51.01it/s] 76%|#######6  |132670/173481[42:12<13:20,51.01it/s] 81%|########1 |141029/173481[45:00<10:42,50.48it/s] 82%|########1 |141614/173481[45:12<10:31,50.48it/s] 86%|########6 |149895/173481[48:00<07:53,49.85it/s] 87%|########6 |150520/173481[48:12<07:40,49.85it/s] 92%|#########1|158950/173481[51:00<04:50,50.07it/s] 92%|#########2|159608/173481[51:12<04:37,50.07it/s] 97%|#########6|167862/173481[54:00<01:52,49.79it/s] 97%|#########7|168449/173481[54:12<01:41,49.79it/s]100%|##########|173481/173481[55:51<00:00,51.76it/s]
[32m[0324 19:51:41 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3351.42 sec.
[32m[0324 19:51:43 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-7286202.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:37<00:00,119.19it/s]
41
[32m[0324 19:54:20 @monitor.py:363][0m QueueInput/queue_size: 0.13291
[32m[0324 19:54:20 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.858
[32m[0324 19:54:20 @monitor.py:363][0m activation-summaries/output-rms: 0.042563
[32m[0324 19:54:20 @monitor.py:363][0m cross_entropy_loss: 1.5278
[32m[0324 19:54:20 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59875
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 19:54:20 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 19:54:20 @monitor.py:363][0m train-error-top1: 0.4127
[32m[0324 19:54:20 @monitor.py:363][0m val-error-top1: 0.41586
[32m[0324 19:54:20 @monitor.py:363][0m val-utt-error: 0.090585
[32m[0324 19:54:20 @monitor.py:363][0m validation_cost: 1.5503
[32m[0324 19:54:20 @monitor.py:363][0m wd_cost: 2.2926e-10
[32m[0324 19:54:20 @group.py:42][0m Callbacks took 158.978 sec in total. InferenceRunner: 157.943sec
[32m[0324 19:54:20 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9197/173481[03:00<53:35,51.09it/s]  6%|5         |9748/173481[03:10<53:24,51.09it/s] 11%|#         |18657/173481[06:00<49:48,51.81it/s] 11%|#1        |19173/173481[06:10<49:38,51.81it/s] 16%|#5        |27129/173481[09:00<49:27,49.32it/s] 16%|#5        |27591/173481[09:10<49:18,49.32it/s] 20%|##        |35128/173481[12:00<49:19,46.75it/s] 21%|##        |35589/173481[12:10<49:09,46.75it/s] 25%|##4       |43274/173481[15:00<47:11,45.99it/s] 25%|##5       |43789/173481[15:10<47:00,45.99it/s] 30%|##9       |51605/173481[18:00<44:01,46.13it/s] 30%|###       |52144/173481[18:10<43:50,46.13it/s] 35%|###4      |60177/173481[21:00<40:17,46.87it/s] 35%|###4      |60668/173481[21:11<40:07,46.87it/s] 40%|###9      |69135/173481[24:00<36:01,48.27it/s] 40%|####      |69709/173481[24:11<35:49,48.27it/s] 45%|####5     |78762/173481[27:00<31:06,50.74it/s] 46%|####5     |79245/173481[27:11<30:57,50.74it/s] 51%|#####     |87684/173481[30:00<28:30,50.15it/s] 51%|#####     |88298/173481[30:11<28:18,50.15it/s] 56%|#####5    |96764/173481[33:00<25:25,50.29it/s] 56%|#####6    |97325/173481[33:11<25:14,50.29it/s] 61%|######    |105644/173481[36:00<22:42,49.81it/s] 61%|######1   |106248/173481[36:11<22:29,49.81it/s] 66%|######6   |114669/173481[39:00<19:36,49.97it/s] 66%|######6   |115301/173481[39:12<19:24,49.97it/s] 71%|#######1  |123692/173481[42:00<16:34,50.05it/s] 72%|#######1  |124309/173481[42:12<16:22,50.05it/s] 77%|#######6  |132961/173481[45:00<13:18,50.76it/s] 77%|#######7  |133625/173481[45:12<13:05,50.76it/s] 82%|########2 |142592/173481[48:00<09:52,52.10it/s] 83%|########2 |143257/173481[48:12<09:40,52.10it/s] 88%|########7 |152153/173481[51:00<06:45,52.60it/s] 88%|########8 |152795/173481[51:12<06:33,52.60it/s] 93%|#########3|161531/173481[54:00<03:48,52.34it/s] 93%|#########3|162198/173481[54:12<03:35,52.34it/s] 99%|#########8|171089/173481[57:00<00:45,52.70it/s] 99%|#########9|171768/173481[57:13<00:32,52.70it/s][32m[0324 20:52:07 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3466.75 sec.
100%|##########|173481/173481[57:46<00:00,50.04it/s]
[32m[0324 20:52:08 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:34<00:00,122.13it/s]
42
[32m[0324 20:54:42 @monitor.py:363][0m QueueInput/queue_size: 0.12336
[32m[0324 20:54:42 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0324 20:54:42 @monitor.py:363][0m activation-summaries/output-rms: 0.041736
[32m[0324 20:54:42 @monitor.py:363][0m cross_entropy_loss: 1.5086
[32m[0324 20:54:42 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59859
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 20:54:42 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 20:54:42 @monitor.py:363][0m train-error-top1: 0.40688
[32m[0324 20:54:42 @monitor.py:363][0m val-error-top1: 0.41579
[32m[0324 20:54:42 @monitor.py:363][0m val-utt-error: 0.090798
[32m[0324 20:54:42 @monitor.py:363][0m validation_cost: 1.5508
[32m[0324 20:54:42 @monitor.py:363][0m wd_cost: 2.2922e-10
[32m[0324 20:54:42 @group.py:42][0m Callbacks took 154.704 sec in total. InferenceRunner: 154.130sec
[32m[0324 20:54:42 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10202/173481[03:00<48:01,56.67it/s]  6%|6         |10687/173481[03:10<47:52,56.67it/s] 11%|#         |19053/173481[06:00<48:52,52.65it/s] 11%|#1        |19507/173481[06:10<48:44,52.65it/s] 16%|#6        |28471/173481[09:00<46:02,52.49it/s] 17%|#6        |29045/173481[09:10<45:51,52.49it/s] 22%|##2       |38263/173481[12:00<42:11,53.42it/s] 22%|##2       |38866/173481[12:10<41:59,53.42it/s] 28%|##7       |48523/173481[15:00<37:45,55.15it/s] 28%|##8       |49102/173481[15:10<37:35,55.15it/s] 34%|###3      |58587/173481[18:00<34:29,55.53it/s] 34%|###4      |59205/173481[18:10<34:17,55.53it/s] 40%|###9      |69233/173481[21:00<30:20,57.28it/s] 40%|####      |69872/173481[21:11<30:08,57.28it/s] 46%|####5     |79693/173481[24:00<27:05,57.69it/s] 46%|####6     |80357/173481[24:11<26:54,57.69it/s] 52%|#####1    |90109/173481[27:00<24:02,57.78it/s] 52%|#####2    |90751/173481[27:11<23:51,57.78it/s] 58%|#####7    |100386/173481[30:00<21:12,57.43it/s] 58%|#####8    |101216/173481[30:11<20:58,57.43it/s] 64%|######4   |111033/173481[33:00<17:51,58.27it/s] 64%|######4   |111756/173481[33:11<17:39,58.27it/s] 70%|#######   |121600/173481[36:00<14:47,58.49it/s] 70%|#######   |122267/173481[36:11<14:35,58.49it/s] 76%|#######6  |132317/173481[39:00<11:37,59.01it/s] 77%|#######6  |133037/173481[39:12<11:25,59.01it/s] 82%|########2 |142988/173481[42:00<08:35,59.14it/s] 83%|########2 |143655/173481[42:12<08:24,59.14it/s] 88%|########8 |153381/173481[45:00<05:44,58.43it/s] 89%|########8 |154117/173481[45:12<05:31,58.43it/s] 94%|#########4|163576/173481[48:00<02:52,57.52it/s] 95%|#########4|164228/173481[48:12<02:40,57.52it/s]100%|#########9|173299/173481[51:00<00:03,55.71it/s]100%|##########|173481/173481[51:03<00:00,56.63it/s]
[32m[0324 21:45:45 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3063.56 sec.
[32m[0324 21:45:46 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-7633164.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:32<00:00,123.45it/s]
43
[32m[0324 21:48:18 @monitor.py:363][0m QueueInput/queue_size: 0.13675
[32m[0324 21:48:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.731
[32m[0324 21:48:18 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0324 21:48:18 @monitor.py:363][0m cross_entropy_loss: 1.5057
[32m[0324 21:48:18 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5985
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 21:48:18 @monitor.py:363][0m train-error-top1: 0.40852
[32m[0324 21:48:18 @monitor.py:363][0m val-error-top1: 0.41548
[32m[0324 21:48:18 @monitor.py:363][0m val-utt-error: 0.090267
[32m[0324 21:48:18 @monitor.py:363][0m validation_cost: 1.5509
[32m[0324 21:48:18 @monitor.py:363][0m wd_cost: 2.292e-10
[32m[0324 21:48:18 @group.py:42][0m Callbacks took 152.751 sec in total. InferenceRunner: 152.487sec
[32m[0324 21:48:18 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10661/173481[03:00<45:49,59.22it/s]  6%|6         |11210/173481[03:10<45:40,59.22it/s] 12%|#2        |21110/173481[06:00<43:18,58.63it/s] 12%|#2        |21605/173481[06:10<43:10,58.63it/s] 18%|#7        |30707/173481[09:00<42:36,55.84it/s] 18%|#8        |31289/173481[09:10<42:26,55.84it/s] 24%|##3       |41546/173481[12:00<37:56,57.95it/s] 24%|##4       |42215/173481[12:10<37:45,57.95it/s] 30%|###       |52318/173481[15:00<34:17,58.88it/s] 31%|###       |52918/173481[15:10<34:07,58.88it/s] 36%|###6      |63005/173481[18:00<31:08,59.12it/s] 37%|###6      |63681/173481[18:10<30:57,59.12it/s] 42%|####2     |73652/173481[21:00<28:08,59.13it/s] 43%|####2     |74316/173481[21:11<27:56,59.13it/s] 49%|####8     |84482/173481[24:00<24:52,59.64it/s] 49%|####9     |85151/173481[24:11<24:40,59.64it/s] 55%|#####4    |95254/173481[27:00<21:49,59.74it/s] 55%|#####5    |95957/173481[27:11<21:37,59.74it/s] 61%|######1   |106120/173481[30:00<18:41,60.05it/s] 62%|######1   |106816/173481[30:11<18:30,60.05it/s] 67%|######7   |116660/173481[33:00<15:58,59.29it/s] 68%|######7   |117208/173481[33:11<15:49,59.29it/s] 73%|#######3  |127417/173481[36:00<12:53,59.52it/s] 74%|#######3  |128049/173481[36:11<12:43,59.52it/s] 80%|#######9  |138079/173481[39:00<09:56,59.37it/s] 80%|#######9  |138761/173481[39:12<09:44,59.37it/s] 86%|########5 |148897/173481[42:00<06:51,59.73it/s] 86%|########6 |149630/173481[42:12<06:39,59.73it/s] 92%|#########1|159558/173481[45:00<03:54,59.48it/s] 92%|#########2|160260/173481[45:12<03:42,59.48it/s] 98%|#########8|170361/173481[48:00<00:52,59.74it/s] 99%|#########8|171026/173481[48:12<00:41,59.74it/s]100%|##########|173481/173481[48:57<00:00,59.05it/s]
[32m[0324 22:37:16 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:2937.94 sec.
[32m[0324 22:37:17 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-7806645.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:27<00:00,127.26it/s]
44
[32m[0324 22:39:45 @monitor.py:363][0m QueueInput/queue_size: 0.18865
[32m[0324 22:39:45 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.765
[32m[0324 22:39:45 @monitor.py:363][0m activation-summaries/output-rms: 0.043551
[32m[0324 22:39:45 @monitor.py:363][0m cross_entropy_loss: 1.4886
[32m[0324 22:39:45 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59847
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 22:39:45 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 22:39:45 @monitor.py:363][0m train-error-top1: 0.40588
[32m[0324 22:39:45 @monitor.py:363][0m val-error-top1: 0.41643
[32m[0324 22:39:45 @monitor.py:363][0m val-utt-error: 0.092604
[32m[0324 22:39:45 @monitor.py:363][0m validation_cost: 1.5522
[32m[0324 22:39:45 @monitor.py:363][0m wd_cost: 4.5838e-11
[32m[0324 22:39:45 @group.py:42][0m Callbacks took 149.083 sec in total. InferenceRunner: 147.964sec
[32m[0324 22:39:45 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10956/173481[03:00<44:30,60.86it/s]  7%|6         |11555/173481[03:10<44:20,60.86it/s] 12%|#2        |21519/173481[06:00<42:23,59.75it/s] 13%|#2        |22095/173481[06:10<42:13,59.75it/s] 18%|#8        |31720/173481[09:00<40:37,58.17it/s] 19%|#8        |32304/173481[09:10<40:27,58.17it/s] 24%|##3       |41622/173481[12:00<38:51,56.55it/s] 24%|##4       |42206/173481[12:10<38:41,56.55it/s] 30%|##9       |51751/173481[15:00<35:58,56.41it/s] 30%|###       |52336/173481[15:10<35:47,56.41it/s] 36%|###5      |62195/173481[18:00<32:25,57.20it/s] 36%|###6      |62810/173481[18:10<32:14,57.20it/s] 42%|####1     |72429/173481[21:00<29:31,57.03it/s] 42%|####2     |73025/173481[21:11<29:21,57.03it/s] 48%|####7     |82486/173481[24:00<26:52,56.44it/s] 48%|####7     |83139/173481[24:11<26:40,56.44it/s] 53%|#####3    |92546/173481[27:00<24:01,56.16it/s] 54%|#####3    |93205/173481[27:11<23:49,56.16it/s] 59%|#####9    |102506/173481[30:00<21:13,55.74it/s] 59%|#####9    |103150/173481[30:11<21:01,55.74it/s] 65%|######4   |112569/173481[33:00<18:11,55.82it/s] 65%|######5   |113211/173481[33:11<17:59,55.82it/s] 71%|#######   |122682/173481[36:00<15:07,56.00it/s] 71%|#######1  |123322/173481[36:11<14:55,56.00it/s] 77%|#######6  |132834/173481[39:00<12:03,56.20it/s] 77%|#######6  |133517/173481[39:12<11:51,56.20it/s] 83%|########2 |143235/173481[42:00<08:50,56.98it/s] 83%|########2 |143915/173481[42:12<08:38,56.98it/s] 88%|########8 |153420/173481[45:00<05:53,56.78it/s] 89%|########8 |154030/173481[45:12<05:42,56.78it/s] 94%|#########4|163266/173481[48:00<03:03,55.72it/s] 95%|#########4|163957/173481[48:12<02:50,55.72it/s]100%|#########9|173271/173481[51:00<00:03,55.65it/s]100%|##########|173481/173481[51:03<00:00,56.62it/s]
[32m[0324 23:30:49 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:3063.88 sec.
[32m[0324 23:30:49 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-7980126.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:29<00:00,125.82it/s]
45
[32m[0324 23:33:19 @monitor.py:363][0m QueueInput/queue_size: 0.17562
[32m[0324 23:33:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.659
[32m[0324 23:33:19 @monitor.py:363][0m activation-summaries/output-rms: 0.042083
[32m[0324 23:33:19 @monitor.py:363][0m cross_entropy_loss: 1.5008
[32m[0324 23:33:19 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59844
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0324 23:33:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0324 23:33:19 @monitor.py:363][0m train-error-top1: 0.39935
[32m[0324 23:33:19 @monitor.py:363][0m val-error-top1: 0.41579
[32m[0324 23:33:19 @monitor.py:363][0m val-utt-error: 0.091967
[32m[0324 23:33:19 @monitor.py:363][0m validation_cost: 1.5514
[32m[0324 23:33:19 @monitor.py:363][0m wd_cost: 4.5836e-11
[32m[0324 23:33:19 @group.py:42][0m Callbacks took 149.908 sec in total. InferenceRunner: 149.606sec
[32m[0324 23:33:19 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10645/173481[03:00<45:53,59.14it/s]  6%|6         |10974/173481[03:10<45:48,59.14it/s] 12%|#1        |20470/173481[06:00<44:55,56.77it/s] 12%|#2        |21046/173481[06:10<44:45,56.77it/s] 18%|#7        |30400/173481[09:00<42:37,55.96it/s] 18%|#7        |30960/173481[09:10<42:27,55.96it/s] 23%|##2       |39425/173481[12:00<42:14,52.89it/s] 23%|##3       |39984/173481[12:10<42:04,52.89it/s] 28%|##8       |48740/173481[15:00<39:44,52.31it/s] 28%|##8       |49295/173481[15:10<39:34,52.31it/s] 34%|###3      |58715/173481[18:00<35:32,53.81it/s] 34%|###4      |59332/173481[18:10<35:21,53.81it/s] 40%|###9      |68530/173481[21:00<32:17,54.16it/s] 40%|###9      |69162/173481[21:11<32:06,54.16it/s] 45%|####5     |78579/173481[24:00<28:46,54.98it/s] 46%|####5     |79184/173481[24:11<28:35,54.98it/s] 51%|#####1    |88733/173481[27:00<25:21,55.68it/s] 52%|#####1    |89377/173481[27:11<25:10,55.68it/s] 57%|#####6    |98840/173481[30:00<22:14,55.91it/s] 57%|#####7    |99476/173481[30:11<22:03,55.91it/s] 63%|######2   |108924/173481[33:00<19:13,55.97it/s] 63%|######3   |109556/173481[33:11<19:02,55.97it/s] 69%|######8   |118928/173481[36:00<16:18,55.77it/s] 69%|######8   |119550/173481[36:11<16:07,55.77it/s] 74%|#######4  |128807/173481[39:00<13:27,55.32it/s] 75%|#######4  |129466/173481[39:12<13:15,55.32it/s] 80%|#######9  |138722/173481[42:00<10:29,55.20it/s] 80%|########  |139368/173481[42:12<10:18,55.20it/s] 86%|########5 |148765/173481[45:00<07:25,55.49it/s] 86%|########6 |149454/173481[45:12<07:12,55.49it/s] 92%|#########1|158767/173481[48:00<04:24,55.52it/s] 92%|#########1|159499/173481[48:12<04:11,55.52it/s] 97%|#########7|168935/173481[51:00<01:21,56.00it/s] 98%|#########7|169674/173481[51:12<01:07,56.00it/s]100%|##########|173481/173481[52:19<00:00,55.26it/s]
[32m[0325 00:25:38 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:3139.40 sec.
[32m[0325 00:25:39 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-8153607.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.50it/s]
46
[32m[0325 00:27:39 @monitor.py:363][0m QueueInput/queue_size: 0.026902
[32m[0325 00:27:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.818
[32m[0325 00:27:39 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0325 00:27:39 @monitor.py:363][0m cross_entropy_loss: 1.5276
[32m[0325 00:27:39 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59843
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 00:27:39 @monitor.py:363][0m train-error-top1: 0.41303
[32m[0325 00:27:39 @monitor.py:363][0m val-error-top1: 0.41584
[32m[0325 00:27:39 @monitor.py:363][0m val-utt-error: 0.090426
[32m[0325 00:27:39 @monitor.py:363][0m validation_cost: 1.5502
[32m[0325 00:27:39 @monitor.py:363][0m wd_cost: 4.5836e-11
[32m[0325 00:27:39 @group.py:42][0m Callbacks took 120.440 sec in total. InferenceRunner: 119.521sec
[32m[0325 00:27:39 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12598/173481[03:00<38:18,69.99it/s]  8%|7         |13193/173481[03:10<38:10,69.99it/s] 13%|#3        |23299/173481[06:00<38:56,64.28it/s] 14%|#3        |23833/173481[06:10<38:47,64.28it/s] 19%|#8        |32504/173481[09:00<41:16,56.94it/s] 19%|#8        |32698/173481[09:10<41:12,56.94it/s] 24%|##4       |42204/173481[12:00<39:31,55.37it/s] 25%|##4       |42748/173481[12:10<39:21,55.37it/s] 30%|##9       |51964/173481[15:00<36:58,54.77it/s] 30%|###       |52540/173481[15:10<36:47,54.77it/s] 36%|###5      |62316/173481[18:00<33:01,56.11it/s] 36%|###6      |62943/173481[18:10<32:50,56.11it/s] 42%|####2     |73257/173481[21:00<28:37,58.35it/s] 43%|####2     |73942/173481[21:11<28:25,58.35it/s] 49%|####8     |84309/173481[24:00<24:50,59.83it/s] 49%|####8     |84965/173481[24:11<24:39,59.83it/s] 55%|#####4    |95204/173481[27:00<21:40,60.17it/s] 55%|#####5    |95913/173481[27:11<21:29,60.17it/s] 61%|######1   |106321/173481[30:00<18:21,60.96it/s] 62%|######1   |107024/173481[30:11<18:10,60.96it/s] 68%|######7   |117509/173481[33:00<15:09,61.54it/s] 68%|######8   |118202/173481[33:11<14:58,61.54it/s] 74%|#######4  |128512/173481[36:00<12:13,61.34it/s] 74%|#######4  |129204/173481[36:11<12:01,61.34it/s] 81%|########  |139819/173481[39:00<09:02,62.06it/s] 81%|########1 |140544/173481[39:12<08:50,62.06it/s] 87%|########7 |151048/173481[42:00<06:00,62.22it/s] 87%|########7 |151746/173481[42:12<05:49,62.22it/s] 93%|#########3|161774/173481[45:00<03:12,60.88it/s] 94%|#########3|162452/173481[45:12<03:01,60.88it/s] 99%|#########9|172432/173481[48:00<00:17,60.03it/s]100%|#########9|173128/173481[48:12<00:05,60.03it/s]100%|##########|173481/173481[48:18<00:00,59.85it/s]
[32m[0325 01:15:57 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:2898.37 sec.
[32m[0325 01:15:58 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-8327088.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:40<00:00,116.99it/s]
47
[32m[0325 01:18:39 @monitor.py:363][0m QueueInput/queue_size: 0.024634
[32m[0325 01:18:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.688
[32m[0325 01:18:39 @monitor.py:363][0m activation-summaries/output-rms: 0.041729
[32m[0325 01:18:39 @monitor.py:363][0m cross_entropy_loss: 1.5085
[32m[0325 01:18:39 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 01:18:39 @monitor.py:363][0m train-error-top1: 0.40654
[32m[0325 01:18:39 @monitor.py:363][0m val-error-top1: 0.41579
[32m[0325 01:18:39 @monitor.py:363][0m val-utt-error: 0.090585
[32m[0325 01:18:39 @monitor.py:363][0m validation_cost: 1.5507
[32m[0325 01:18:39 @monitor.py:363][0m wd_cost: 9.1671e-12
[32m[0325 01:18:39 @group.py:42][0m Callbacks took 161.321 sec in total. InferenceRunner: 160.908sec
[32m[0325 01:18:39 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11601/173481[03:00<41:52,64.44it/s]  7%|7         |12192/173481[03:10<41:42,64.44it/s] 12%|#2        |21440/173481[06:00<42:50,59.15it/s] 13%|#2        |22037/173481[06:10<42:40,59.15it/s] 18%|#8        |31783/173481[09:00<40:30,58.29it/s] 19%|#8        |32392/173481[09:10<40:20,58.29it/s] 25%|##4       |42884/173481[12:00<36:19,59.93it/s] 25%|##5       |43571/173481[12:10<36:07,59.93it/s] 31%|###1      |54228/173481[15:00<32:21,61.43it/s] 32%|###1      |54797/173481[15:10<32:12,61.43it/s] 37%|###7      |64346/173481[18:00<30:59,58.70it/s] 37%|###7      |64982/173481[18:10<30:48,58.70it/s] 43%|####2     |74588/173481[21:00<28:31,57.79it/s] 43%|####3     |75242/173481[21:11<28:20,57.79it/s] 49%|####8     |84980/173481[24:00<25:32,57.76it/s] 49%|####9     |85641/173481[24:11<25:20,57.76it/s] 55%|#####4    |95414/173481[27:00<22:29,57.86it/s] 55%|#####5    |96090/173481[27:11<22:17,57.86it/s] 61%|######1   |105953/173481[30:00<19:20,58.20it/s] 61%|######1   |106593/173481[30:11<19:09,58.20it/s] 67%|######7   |116261/173481[33:00<16:31,57.73it/s] 67%|######7   |116916/173481[33:11<16:19,57.73it/s] 73%|#######3  |126719/173481[36:00<13:27,57.91it/s] 73%|#######3  |127401/173481[36:12<13:15,57.91it/s] 79%|#######9  |137123/173481[39:00<10:28,57.85it/s] 79%|#######9  |137825/173481[39:12<10:16,57.85it/s] 85%|########5 |147655/173481[42:00<07:23,58.18it/s] 86%|########5 |148381/173481[42:12<07:11,58.18it/s] 91%|#########1|158019/173481[45:00<04:27,57.88it/s] 91%|#########1|158722/173481[45:12<04:15,57.88it/s] 97%|#########6|168203/173481[48:00<01:32,57.21it/s] 97%|#########7|168896/173481[48:12<01:20,57.21it/s]100%|##########|173481/173481[49:38<00:00,58.24it/s]
[32m[0325 02:08:17 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:2978.50 sec.
[32m[0325 02:08:18 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-8500569.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:30<00:00,125.35it/s]
48
[32m[0325 02:10:49 @monitor.py:363][0m QueueInput/queue_size: 0.054041
[32m[0325 02:10:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.715
[32m[0325 02:10:49 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0325 02:10:49 @monitor.py:363][0m cross_entropy_loss: 1.5063
[32m[0325 02:10:49 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 02:10:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 02:10:49 @monitor.py:363][0m train-error-top1: 0.40861
[32m[0325 02:10:49 @monitor.py:363][0m val-error-top1: 0.41549
[32m[0325 02:10:49 @monitor.py:363][0m val-utt-error: 0.090001
[32m[0325 02:10:49 @monitor.py:363][0m validation_cost: 1.551
[32m[0325 02:10:49 @monitor.py:363][0m wd_cost: 9.1671e-12
[32m[0325 02:10:49 @group.py:42][0m Callbacks took 151.403 sec in total. InferenceRunner: 150.175sec
[32m[0325 02:10:49 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11221/173481[03:00<43:22,62.34it/s]  7%|6         |11795/173481[03:10<43:13,62.34it/s] 12%|#2        |21478/173481[06:00<42:33,59.54it/s] 13%|#2        |21984/173481[06:10<42:24,59.54it/s] 18%|#8        |31234/173481[09:00<41:46,56.74it/s] 18%|#8        |31838/173481[09:10<41:36,56.74it/s] 24%|##3       |41512/173481[12:00<38:38,56.92it/s] 24%|##4       |42131/173481[12:10<38:27,56.92it/s] 30%|##9       |51961/173481[15:00<35:14,57.48it/s] 30%|###       |52557/173481[15:10<35:03,57.48it/s] 36%|###5      |62068/173481[18:00<32:41,56.80it/s] 36%|###6      |62681/173481[18:11<32:30,56.80it/s] 42%|####1     |72182/173481[21:00<29:53,56.49it/s] 42%|####1     |72829/173481[21:11<29:41,56.49it/s] 47%|####7     |82287/173481[24:00<26:59,56.31it/s] 48%|####7     |82894/173481[24:11<26:48,56.31it/s] 53%|#####3    |92325/173481[27:00<24:08,56.04it/s] 54%|#####3    |92930/173481[27:11<23:57,56.04it/s] 59%|#####8    |101817/173481[30:00<21:59,54.31it/s] 59%|#####8    |102325/173481[30:11<21:50,54.31it/s] 65%|######4   |112145/173481[33:00<18:19,55.80it/s] 65%|######5   |112850/173481[33:11<18:06,55.80it/s] 71%|#######   |122552/173481[36:00<14:56,56.79it/s] 71%|#######1  |123250/173481[36:12<14:44,56.79it/s] 77%|#######6  |132796/173481[39:00<11:55,56.85it/s] 77%|#######6  |133535/173481[39:12<11:42,56.85it/s] 83%|########2 |143626/173481[42:00<08:30,58.46it/s] 83%|########3 |144403/173481[42:12<08:17,58.46it/s] 89%|########9 |155167/173481[45:00<04:59,61.16it/s] 90%|########9 |155931/173481[45:12<04:46,61.16it/s] 96%|#########5|165854/173481[48:00<02:06,60.25it/s] 96%|#########5|166534/173481[48:12<01:55,60.25it/s]100%|##########|173481/173481[50:13<00:00,57.57it/s]
[32m[0325 03:01:02 @base.py:257][0m Epoch 51 (global_step 8674050) finished, time:3013.47 sec.
[32m[0325 03:01:03 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-8674050.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:52<00:00,109.12it/s]
49
[32m[0325 03:03:55 @monitor.py:363][0m QueueInput/queue_size: 0.090797
[32m[0325 03:03:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.754
[32m[0325 03:03:55 @monitor.py:363][0m activation-summaries/output-rms: 0.04355
[32m[0325 03:03:55 @monitor.py:363][0m cross_entropy_loss: 1.4886
[32m[0325 03:03:55 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 03:03:55 @monitor.py:363][0m train-error-top1: 0.40585
[32m[0325 03:03:55 @monitor.py:363][0m val-error-top1: 0.41643
[32m[0325 03:03:55 @monitor.py:363][0m val-utt-error: 0.092604
[32m[0325 03:03:55 @monitor.py:363][0m validation_cost: 1.5522
[32m[0325 03:03:55 @monitor.py:363][0m wd_cost: 1.8334e-12
[32m[0325 03:03:55 @group.py:42][0m Callbacks took 173.238 sec in total. InferenceRunner: 172.562sec
[32m[0325 03:03:55 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14256/173481[03:00<33:30,79.20it/s]  9%|8         |15008/173481[03:10<33:20,79.20it/s] 16%|#5        |27129/173481[06:00<32:27,75.16it/s] 16%|#5        |27756/173481[06:10<32:18,75.16it/s] 22%|##1       |37859/173481[09:00<33:59,66.48it/s] 22%|##2       |38477/173481[09:10<33:50,66.48it/s] 28%|##8       |48661/173481[12:00<32:58,63.08it/s] 28%|##8       |49298/173481[12:10<32:48,63.08it/s] 34%|###4      |59584/173481[15:00<30:41,61.85it/s] 35%|###4      |60222/173481[15:10<30:31,61.85it/s] 41%|####      |70712/173481[18:00<27:41,61.83it/s] 41%|####1     |71330/173481[18:10<27:32,61.83it/s] 47%|####6     |81183/173481[21:00<25:39,59.95it/s] 47%|####7     |81840/173481[21:11<25:28,59.95it/s] 53%|#####2    |91743/173481[24:00<22:58,59.30it/s] 53%|#####3    |92394/173481[24:11<22:47,59.30it/s] 59%|#####9    |102384/173481[27:00<20:00,59.21it/s] 59%|#####9    |103065/173481[27:11<19:49,59.21it/s] 65%|######5   |112975/173481[30:00<17:05,59.02it/s] 66%|######5   |113648/173481[30:11<16:53,59.02it/s] 71%|#######1  |123363/173481[33:00<14:18,58.36it/s] 72%|#######1  |124054/173481[33:11<14:07,58.36it/s] 77%|#######7  |134045/173481[36:00<11:10,58.84it/s] 78%|#######7  |134740/173481[36:11<10:58,58.84it/s] 84%|########3 |144888/173481[39:00<08:00,59.53it/s] 84%|########3 |145564/173481[39:12<07:48,59.53it/s] 90%|########9 |155271/173481[42:00<05:10,58.59it/s] 90%|########9 |155980/173481[42:12<04:58,58.59it/s] 95%|#########5|165655/173481[45:00<02:14,58.13it/s] 96%|#########5|166364/173481[45:12<02:02,58.13it/s][32m[0325 03:51:08 @base.py:257][0m Epoch 52 (global_step 8847531) finished, time:2832.76 sec.
100%|##########|173481/173481[47:12<00:00,61.24it/s]
[32m[0325 03:51:09 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-8847531.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:53<00:00,108.53it/s]
50
[32m[0325 03:54:03 @monitor.py:363][0m QueueInput/queue_size: 0.1399
[32m[0325 03:54:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.654
[32m[0325 03:54:03 @monitor.py:363][0m activation-summaries/output-rms: 0.042082
[32m[0325 03:54:03 @monitor.py:363][0m cross_entropy_loss: 1.5008
[32m[0325 03:54:03 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 03:54:03 @monitor.py:363][0m train-error-top1: 0.39916
[32m[0325 03:54:03 @monitor.py:363][0m val-error-top1: 0.4158
[32m[0325 03:54:03 @monitor.py:363][0m val-utt-error: 0.092073
[32m[0325 03:54:03 @monitor.py:363][0m validation_cost: 1.5514
[32m[0325 03:54:03 @monitor.py:363][0m wd_cost: 1.8334e-12
[32m[0325 03:54:03 @group.py:42][0m Callbacks took 174.702 sec in total. InferenceRunner: 173.443sec
[32m[0325 03:54:03 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |13007/173481[03:00<37:00,72.25it/s]  8%|7         |13834/173481[03:10<36:49,72.25it/s] 15%|#4        |25819/173481[06:00<34:19,71.71it/s] 15%|#5        |26401/173481[06:10<34:11,71.71it/s] 21%|##        |35910/173481[09:00<36:26,62.91it/s] 21%|##1       |36483/173481[09:10<36:17,62.91it/s] 26%|##6       |45776/173481[12:00<36:19,58.58it/s] 27%|##6       |46383/173481[12:10<36:09,58.58it/s] 32%|###2      |56003/173481[15:00<33:56,57.68it/s] 33%|###2      |56643/173481[15:10<33:45,57.68it/s] 38%|###8      |66095/173481[18:00<31:28,56.86it/s] 38%|###8      |66742/173481[18:11<31:17,56.86it/s] 44%|####4     |76730/173481[21:00<27:49,57.95it/s] 45%|####4     |77399/173481[21:11<27:38,57.95it/s] 50%|#####     |87233/173481[24:00<24:43,58.14it/s] 51%|#####     |87897/173481[24:11<24:31,58.14it/s] 56%|#####6    |98007/173481[27:00<21:19,58.99it/s] 57%|#####6    |98669/173481[27:11<21:08,58.99it/s] 63%|######2   |108650/173481[30:00<18:17,59.06it/s] 63%|######3   |109304/173481[30:11<18:06,59.06it/s] 69%|######8   |119252/173481[33:00<15:19,58.98it/s] 69%|######9   |119933/173481[33:11<15:07,58.98it/s] 75%|#######4  |129638/173481[36:00<12:31,58.33it/s] 75%|#######5  |130304/173481[36:12<12:20,58.33it/s] 81%|########  |140148/173481[39:00<09:31,58.36it/s] 81%|########1 |140829/173481[39:12<09:19,58.36it/s] 87%|########6 |150875/173481[42:00<06:23,58.97it/s] 87%|########7 |151626/173481[42:12<06:10,58.97it/s] 93%|#########3|161691/173481[45:00<03:18,59.52it/s] 94%|#########3|162358/173481[45:12<03:06,59.52it/s] 99%|#########9|172222/173481[48:00<00:21,59.01it/s]100%|#########9|172897/173481[48:12<00:09,59.01it/s][32m[0325 04:42:26 @base.py:257][0m Epoch 53 (global_step 9021012) finished, time:2903.10 sec.
100%|##########|173481/173481[48:23<00:00,59.76it/s]
[32m[0325 04:42:26 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-9021012.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:38<00:00,118.78it/s]
51
[32m[0325 04:45:05 @monitor.py:363][0m QueueInput/queue_size: 0.19271
[32m[0325 04:45:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.815
[32m[0325 04:45:05 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0325 04:45:05 @monitor.py:363][0m cross_entropy_loss: 1.5276
[32m[0325 04:45:05 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 04:45:05 @monitor.py:363][0m train-error-top1: 0.41303
[32m[0325 04:45:05 @monitor.py:363][0m val-error-top1: 0.41584
[32m[0325 04:45:05 @monitor.py:363][0m val-utt-error: 0.090373
[32m[0325 04:45:05 @monitor.py:363][0m validation_cost: 1.5502
[32m[0325 04:45:05 @monitor.py:363][0m wd_cost: 1.8334e-12
[32m[0325 04:45:05 @group.py:42][0m Callbacks took 158.735 sec in total. InferenceRunner: 158.489sec
[32m[0325 04:45:05 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13780/173481[03:00<34:46,76.55it/s]  8%|8         |14566/173481[03:10<34:35,76.55it/s] 15%|#4        |25668/173481[06:00<34:44,70.91it/s] 15%|#5        |26228/173481[06:10<34:36,70.91it/s] 21%|##        |35740/173481[09:00<36:42,62.55it/s] 21%|##        |36366/173481[09:10<36:32,62.55it/s] 26%|##6       |45851/173481[12:00<35:56,59.19it/s] 27%|##6       |46493/173481[12:10<35:45,59.19it/s] 32%|###2      |56274/173481[15:00<33:22,58.54it/s] 33%|###2      |56919/173481[15:10<33:11,58.54it/s] 39%|###8      |67372/173481[18:00<29:26,60.05it/s] 39%|###9      |68029/173481[18:10<29:15,60.05it/s] 45%|####5     |78260/173481[21:00<26:19,60.27it/s] 46%|####5     |78970/173481[21:11<26:08,60.27it/s] 52%|#####1    |89719/173481[24:00<22:32,61.92it/s] 52%|#####2    |90416/173481[24:11<22:21,61.92it/s] 58%|#####8    |100938/173481[27:00<19:27,62.12it/s] 59%|#####8    |101643/173481[27:11<19:16,62.12it/s] 65%|######4   |112253/173481[30:00<16:19,62.49it/s] 65%|######5   |112979/173481[30:11<16:08,62.49it/s] 71%|#######1  |123552/173481[33:00<13:17,62.63it/s] 72%|#######1  |124248/173481[33:11<13:06,62.63it/s] 78%|#######7  |135064/173481[36:00<10:07,63.28it/s] 78%|#######8  |135823/173481[36:11<09:55,63.28it/s] 85%|########4 |146749/173481[39:00<06:57,64.08it/s] 85%|########5 |147526/173481[39:12<06:45,64.08it/s] 92%|#########2|159649/173481[42:00<03:24,67.66it/s] 93%|#########2|160686/173481[42:12<03:09,67.66it/s]100%|##########|173481/173481[44:36<00:00,64.80it/s]
[32m[0325 05:29:42 @base.py:257][0m Epoch 54 (global_step 9194493) finished, time:2676.99 sec.
[32m[0325 05:29:42 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-9194493.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.31it/s]
52
[32m[0325 05:31:37 @monitor.py:363][0m QueueInput/queue_size: 0.020615
[32m[0325 05:31:37 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.686
[32m[0325 05:31:37 @monitor.py:363][0m activation-summaries/output-rms: 0.04173
[32m[0325 05:31:37 @monitor.py:363][0m cross_entropy_loss: 1.5084
[32m[0325 05:31:37 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 05:31:37 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 05:31:37 @monitor.py:363][0m train-error-top1: 0.40649
[32m[0325 05:31:37 @monitor.py:363][0m val-error-top1: 0.41577
[32m[0325 05:31:37 @monitor.py:363][0m val-utt-error: 0.090745
[32m[0325 05:31:37 @monitor.py:363][0m validation_cost: 1.5507
[32m[0325 05:31:37 @monitor.py:363][0m wd_cost: 3.6668e-13
[32m[0325 05:31:37 @group.py:42][0m Callbacks took 115.674 sec in total. InferenceRunner: 115.281sec
[32m[0325 05:31:37 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16617/173481[03:00<28:19,92.31it/s] 10%|#         |17521/173481[03:10<28:09,92.31it/s] 19%|#8        |32696/173481[06:00<25:50,90.79it/s] 19%|#9        |33608/173481[06:10<25:40,90.79it/s] 28%|##8       |48601/173481[09:00<23:14,89.56it/s] 29%|##8       |49537/173481[09:10<23:03,89.56it/s] 37%|###7      |64636/173481[12:00<20:18,89.31it/s] 38%|###7      |65586/173481[12:10<20:08,89.31it/s] 45%|####4     |77475/173481[15:00<20:10,79.31it/s] 45%|####5     |78132/173481[15:10<20:02,79.31it/s] 51%|#####1    |88987/173481[18:00<19:53,70.81it/s] 52%|#####1    |89718/173481[18:10<19:42,70.81it/s] 58%|#####7    |100605/173481[21:00<17:59,67.53it/s] 58%|#####8    |101335/173481[21:11<17:48,67.53it/s] 64%|######4   |111604/173481[24:00<16:04,64.16it/s] 65%|######4   |112277/173481[24:11<15:53,64.16it/s] 71%|#######   |122586/173481[27:00<13:33,62.54it/s] 71%|#######1  |123313/173481[27:11<13:22,62.54it/s] 77%|#######7  |133938/173481[30:00<10:29,62.80it/s] 78%|#######7  |134642/173481[30:11<10:18,62.80it/s] 84%|########3 |144868/173481[33:00<07:43,61.74it/s] 84%|########3 |145582/173481[33:11<07:31,61.74it/s] 90%|########9 |155553/173481[36:00<04:56,60.53it/s] 90%|######### |156232/173481[36:11<04:44,60.53it/s] 96%|#########6|166692/173481[39:00<01:50,61.19it/s] 97%|#########6|167419/173481[39:12<01:39,61.19it/s]100%|##########|173481/173481[40:58<00:00,70.56it/s]
[32m[0325 06:12:36 @base.py:257][0m Epoch 55 (global_step 9367974) finished, time:2458.79 sec.
[32m[0325 06:12:36 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-9367974.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:47<00:00,175.83it/s]
53
[32m[0325 06:14:23 @monitor.py:363][0m QueueInput/queue_size: 0.025345
[32m[0325 06:14:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0325 06:14:23 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0325 06:14:23 @monitor.py:363][0m cross_entropy_loss: 1.5037
[32m[0325 06:14:23 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 06:14:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 06:14:23 @monitor.py:363][0m train-error-top1: 0.40807
[32m[0325 06:14:23 @monitor.py:363][0m val-error-top1: 0.41534
[32m[0325 06:14:23 @monitor.py:363][0m val-utt-error: 0.09032
[32m[0325 06:14:23 @monitor.py:363][0m validation_cost: 1.5502
[32m[0325 06:14:23 @monitor.py:363][0m wd_cost: 3.6668e-13
[32m[0325 06:14:23 @group.py:42][0m Callbacks took 107.307 sec in total. InferenceRunner: 107.067sec
[32m[0325 06:14:23 @base.py:247][0m Start Epoch 56 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11890/173481[03:00<40:46,66.05it/s]  7%|7         |12513/173481[03:10<40:36,66.05it/s] 13%|#2        |22424/173481[06:00<40:34,62.06it/s] 13%|#3        |23006/173481[06:10<40:24,62.06it/s] 20%|#9        |34021/173481[09:00<36:46,63.22it/s] 20%|#9        |34681/173481[09:10<36:35,63.22it/s] 26%|##6       |45866/173481[12:00<32:59,64.48it/s] 27%|##6       |46529/173481[12:10<32:48,64.48it/s] 33%|###3      |58051/173481[15:00<29:07,66.05it/s] 34%|###3      |58718/173481[15:10<28:57,66.05it/s] 40%|###9      |69267/173481[18:00<27:05,64.12it/s] 40%|####      |69951/173481[18:10<26:54,64.12it/s] 47%|####6     |81307/173481[21:00<23:27,65.47it/s] 47%|####7     |82034/173481[21:11<23:16,65.47it/s] 54%|#####3    |93604/173481[24:00<19:54,66.86it/s] 54%|#####4    |94326/173481[24:11<19:43,66.86it/s] 61%|######1   |105872/173481[27:00<16:41,67.50it/s] 61%|######1   |106639/173481[27:11<16:30,67.50it/s] 68%|######8   |118132/173481[30:00<13:36,67.80it/s] 69%|######8   |118887/173481[30:11<13:25,67.80it/s] 75%|#######4  |129712/173481[33:00<11:02,66.02it/s] 75%|#######5  |130623/173481[33:11<10:49,66.02it/s] 81%|########1 |141293/173481[36:00<08:13,65.17it/s] 82%|########1 |142105/173481[36:11<08:01,65.17it/s] 89%|########8 |153613/173481[39:00<04:57,66.77it/s] 89%|########9 |154489/173481[39:12<04:44,66.77it/s] 95%|#########5|165409/173481[42:00<02:02,66.14it/s] 96%|#########5|166021/173481[42:12<01:52,66.14it/s]100%|##########|173481/173481[44:18<00:00,65.26it/s]
[32m[0325 06:58:42 @base.py:257][0m Epoch 56 (global_step 9541455) finished, time:2658.33 sec.
[32m[0325 06:58:43 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-9541455.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.50it/s]
54
[32m[0325 07:00:43 @monitor.py:363][0m QueueInput/queue_size: 0.36481
[32m[0325 07:00:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.753
[32m[0325 07:00:43 @monitor.py:363][0m activation-summaries/output-rms: 0.04355
[32m[0325 07:00:43 @monitor.py:363][0m cross_entropy_loss: 1.4901
[32m[0325 07:00:43 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 07:00:43 @monitor.py:363][0m train-error-top1: 0.40627
[32m[0325 07:00:43 @monitor.py:363][0m val-error-top1: 0.41638
[32m[0325 07:00:43 @monitor.py:363][0m val-utt-error: 0.092551
[32m[0325 07:00:43 @monitor.py:363][0m validation_cost: 1.552
[32m[0325 07:00:43 @monitor.py:363][0m wd_cost: 3.6668e-13
[32m[0325 07:00:43 @group.py:42][0m Callbacks took 121.457 sec in total. InferenceRunner: 120.282sec
[32m[0325 07:00:43 @base.py:247][0m Start Epoch 57 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13998/173481[03:00<34:10,77.76it/s]  8%|8         |14684/173481[03:10<34:02,77.76it/s] 15%|#4        |26016/173481[06:00<34:12,71.84it/s] 15%|#5        |26705/173481[06:10<34:03,71.84it/s] 22%|##1       |37410/173481[09:00<33:41,67.30it/s] 22%|##1       |38064/173481[09:10<33:32,67.30it/s] 28%|##7       |48276/173481[12:00<32:47,63.63it/s] 28%|##8       |48905/173481[12:10<32:37,63.63it/s] 34%|###3      |58916/173481[15:00<31:09,61.29it/s] 34%|###4      |59572/173481[15:10<30:58,61.29it/s] 40%|####      |69959/173481[18:00<28:08,61.32it/s] 41%|####      |70602/173481[18:10<27:57,61.32it/s] 47%|####6     |80721/173481[21:00<25:32,60.54it/s] 47%|####6     |81400/173481[21:11<25:20,60.54it/s] 53%|#####2    |91502/173481[24:00<22:41,60.21it/s] 53%|#####3    |92150/173481[24:11<22:30,60.21it/s] 59%|#####8    |102141/173481[27:00<19:55,59.65it/s] 59%|#####9    |102791/173481[27:11<19:44,59.65it/s] 65%|######5   |112863/173481[30:00<16:56,59.61it/s] 65%|######5   |113550/173481[30:11<16:45,59.61it/s] 71%|#######   |123077/173481[33:00<14:26,58.14it/s] 72%|#######1  |124152/173481[33:11<14:08,58.14it/s] 78%|#######7  |134461/173481[36:00<10:44,60.58it/s] 78%|#######7  |135158/173481[36:11<10:32,60.58it/s] 84%|########3 |145410/173481[39:00<07:42,60.70it/s] 84%|########4 |146098/173481[39:12<07:31,60.70it/s] 90%|########9 |156017/173481[42:00<04:52,59.80it/s] 90%|######### |156721/173481[42:12<04:40,59.80it/s] 96%|#########6|166769/173481[45:00<01:52,59.76it/s] 97%|#########6|167496/173481[45:12<01:40,59.76it/s]100%|##########|173481/173481[46:49<00:00,61.75it/s]
[32m[0325 07:47:33 @base.py:257][0m Epoch 57 (global_step 9714936) finished, time:2809.50 sec.
[32m[0325 07:47:33 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-9714936.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.58it/s]
55
[32m[0325 07:49:29 @monitor.py:363][0m QueueInput/queue_size: 0.041611
[32m[0325 07:49:29 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.653
[32m[0325 07:49:29 @monitor.py:363][0m activation-summaries/output-rms: 0.042082
[32m[0325 07:49:29 @monitor.py:363][0m cross_entropy_loss: 1.5005
[32m[0325 07:49:29 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 07:49:29 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 07:49:29 @monitor.py:363][0m train-error-top1: 0.39931
[32m[0325 07:49:29 @monitor.py:363][0m val-error-top1: 0.41579
[32m[0325 07:49:29 @monitor.py:363][0m val-utt-error: 0.09202
[32m[0325 07:49:29 @monitor.py:363][0m validation_cost: 1.5513
[32m[0325 07:49:29 @monitor.py:363][0m wd_cost: 7.3336e-14
[32m[0325 07:49:29 @group.py:42][0m Callbacks took 116.735 sec in total. InferenceRunner: 116.502sec
[32m[0325 07:49:29 @base.py:247][0m Start Epoch 58 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12906/173481[03:00<37:19,71.70it/s]  8%|7         |13551/173481[03:10<37:10,71.70it/s] 14%|#3        |23910/173481[06:00<37:46,65.99it/s] 14%|#4        |24519/173481[06:10<37:37,65.99it/s] 20%|#9        |34462/173481[09:00<37:19,62.08it/s] 20%|##        |34994/173481[09:10<37:10,62.08it/s] 26%|##5       |44411/173481[12:00<36:47,58.48it/s] 26%|##5       |45007/173481[12:10<36:36,58.48it/s] 32%|###1      |54665/173481[15:00<34:18,57.71it/s] 32%|###1      |55283/173481[15:10<34:08,57.71it/s] 38%|###7      |65181/173481[18:00<31:05,58.06it/s] 38%|###7      |65808/173481[18:10<30:54,58.06it/s] 44%|####3     |75715/173481[21:00<27:57,58.29it/s] 44%|####4     |76349/173481[21:11<27:46,58.29it/s] 50%|####9     |86239/173481[24:00<24:54,58.38it/s] 50%|#####     |86919/173481[24:11<24:42,58.38it/s] 56%|#####5    |97034/173481[27:00<21:32,59.16it/s] 56%|#####6    |97699/173481[27:11<21:20,59.16it/s] 62%|######2   |107752/173481[30:00<18:27,59.35it/s] 62%|######2   |108394/173481[30:11<18:16,59.35it/s] 68%|######8   |118085/173481[33:00<15:49,58.36it/s] 68%|######8   |118743/173481[33:11<15:37,58.36it/s] 74%|#######3  |128274/173481[36:00<13:06,57.46it/s] 74%|#######4  |128917/173481[36:11<12:55,57.46it/s] 80%|#######9  |138441/173481[39:00<10:15,56.97it/s] 80%|########  |139137/173481[39:12<10:02,56.97it/s] 86%|########5 |148932/173481[42:00<07:06,57.62it/s] 86%|########6 |149646/173481[42:12<06:53,57.62it/s] 92%|#########1|159568/173481[45:00<03:58,58.34it/s] 92%|#########2|160204/173481[45:12<03:47,58.34it/s] 98%|#########7|169990/173481[48:00<01:00,58.12it/s] 98%|#########8|170708/173481[48:12<00:47,58.12it/s]100%|##########|173481/173481[49:01<00:00,58.99it/s]
[32m[0325 08:38:30 @base.py:257][0m Epoch 58 (global_step 9888417) finished, time:2941.03 sec.
[32m[0325 08:38:31 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.01it/s]
56
[32m[0325 08:40:28 @monitor.py:363][0m QueueInput/queue_size: 0.0107
[32m[0325 08:40:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.815
[32m[0325 08:40:28 @monitor.py:363][0m activation-summaries/output-rms: 0.042549
[32m[0325 08:40:28 @monitor.py:363][0m cross_entropy_loss: 1.5277
[32m[0325 08:40:28 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 08:40:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 08:40:28 @monitor.py:363][0m train-error-top1: 0.41303
[32m[0325 08:40:28 @monitor.py:363][0m val-error-top1: 0.41584
[32m[0325 08:40:28 @monitor.py:363][0m val-utt-error: 0.090373
[32m[0325 08:40:28 @monitor.py:363][0m validation_cost: 1.5502
[32m[0325 08:40:28 @monitor.py:363][0m wd_cost: 7.3336e-14
[32m[0325 08:40:28 @group.py:42][0m Callbacks took 117.202 sec in total. InferenceRunner: 116.910sec
[32m[0325 08:40:28 @base.py:247][0m Start Epoch 59 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12611/173481[03:00<38:16,70.06it/s]  8%|7         |13242/173481[03:10<38:07,70.06it/s] 14%|#3        |23585/173481[06:00<38:19,65.19it/s] 14%|#3        |24153/173481[06:10<38:10,65.19it/s] 19%|#9        |33164/173481[09:00<39:54,58.60it/s] 19%|#9        |33757/173481[09:10<39:44,58.60it/s] 25%|##4       |43074/173481[12:00<38:17,56.76it/s] 25%|##5       |43669/173481[12:10<38:06,56.76it/s] 31%|###       |52970/173481[15:00<35:57,55.86it/s] 31%|###       |53571/173481[15:10<35:46,55.86it/s] 36%|###6      |63069/173481[18:00<32:52,55.98it/s] 37%|###6      |63694/173481[18:10<32:41,55.98it/s] 43%|####2     |73924/173481[21:00<28:34,58.06it/s] 43%|####2     |74556/173481[21:11<28:23,58.06it/s] 49%|####8     |84742/173481[24:00<25:02,59.06it/s] 49%|####9     |85422/173481[24:11<24:50,59.06it/s] 55%|#####5    |95644/173481[27:00<21:41,59.80it/s] 56%|#####5    |96321/173481[27:11<21:30,59.80it/s] 61%|######1   |106289/173481[30:00<18:49,59.47it/s] 62%|######1   |106971/173481[30:11<18:38,59.47it/s] 68%|######7   |117501/173481[33:00<15:20,60.84it/s] 68%|######8   |118233/173481[33:11<15:08,60.84it/s] 74%|#######3  |128319/173481[36:00<12:26,60.46it/s] 74%|#######4  |128997/173481[36:11<12:15,60.46it/s] 80%|########  |139531/173481[39:00<09:13,61.36it/s] 81%|########  |140280/173481[39:12<09:01,61.36it/s] 87%|########6 |150837/173481[42:00<06:04,62.08it/s] 87%|########7 |151603/173481[42:12<05:52,62.08it/s] 93%|#########3|162149/173481[45:00<03:01,62.44it/s] 94%|#########3|162642/173481[45:12<02:53,62.44it/s]100%|##########|173481/173481[47:50<00:00,60.43it/s]
[32m[0325 09:28:18 @base.py:257][0m Epoch 59 (global_step 10061898) finished, time:2870.67 sec.
[32m[0325 09:28:18 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-10061898.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,166.02it/s]
57
[32m[0325 09:30:12 @monitor.py:363][0m QueueInput/queue_size: 0.038257
[32m[0325 09:30:12 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.686
[32m[0325 09:30:12 @monitor.py:363][0m activation-summaries/output-rms: 0.04173
[32m[0325 09:30:12 @monitor.py:363][0m cross_entropy_loss: 1.5083
[32m[0325 09:30:12 @monitor.py:363][0m lr: 4.7684e-10
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 09:30:12 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 09:30:12 @monitor.py:363][0m train-error-top1: 0.40646
[32m[0325 09:30:12 @monitor.py:363][0m val-error-top1: 0.41578
[32m[0325 09:30:12 @monitor.py:363][0m val-utt-error: 0.090745
[32m[0325 09:30:12 @monitor.py:363][0m validation_cost: 1.5507
[32m[0325 09:30:12 @monitor.py:363][0m wd_cost: 7.3336e-14
[32m[0325 09:30:12 @group.py:42][0m Callbacks took 113.586 sec in total. InferenceRunner: 113.384sec
[32m[0325 09:30:12 @base.py:247][0m Start Epoch 60 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13548/173481[03:00<35:24,75.26it/s]  8%|8         |14197/173481[03:10<35:16,75.26it/s] 14%|#4        |24540/173481[06:00<36:48,67.43it/s] 14%|#4        |25147/173481[06:10<36:39,67.43it/s] 21%|##        |36157/173481[09:00<34:42,65.95it/s] 21%|##1       |36858/173481[09:10<34:31,65.95it/s] 28%|##7       |48450/173481[12:00<31:03,67.10it/s] 28%|##8       |49213/173481[12:10<30:52,67.10it/s] 35%|###4      |59900/173481[15:00<28:59,65.30it/s] 35%|###4      |60542/173481[15:10<28:49,65.30it/s] 41%|####1     |71181/173481[18:00<26:39,63.96it/s] 41%|####1     |71858/173481[18:10<26:28,63.96it/s] 48%|####7     |82431/173481[21:00<24:00,63.22it/s] 48%|####7     |83123/173481[21:11<23:49,63.22it/s] 54%|#####4    |93752/173481[24:00<21:04,63.05it/s] 54%|#####4    |94435/173481[24:11<20:53,63.05it/s] 61%|######    |105110/173481[27:00<18:03,63.08it/s] 61%|######1   |105834/173481[27:11<17:52,63.08it/s] 67%|######7   |116392/173481[30:00<15:08,62.87it/s] 68%|######7   |117133/173481[30:11<14:56,62.87it/s] 74%|#######3  |127689/173481[33:00<12:09,62.81it/s] 74%|#######4  |128437/173481[33:11<11:57,62.81it/s] 80%|########  |139027/173481[36:00<09:07,62.89it/s] 81%|########  |139735/173481[36:11<08:56,62.89it/s] 86%|########6 |149683/173481[39:00<06:30,60.99it/s] 87%|########6 |150421/173481[39:12<06:18,60.99it/s] 93%|#########2|161042/173481[42:00<03:20,62.02it/s] 93%|#########3|161834/173481[42:12<03:07,62.02it/s] 99%|#########9|171818/173481[45:00<00:27,60.91it/s] 99%|#########9|172591/173481[45:12<00:14,60.91it/s]100%|##########|173481/173481[45:26<00:00,63.62it/s]
[32m[0325 10:15:39 @base.py:257][0m Epoch 60 (global_step 10235379) finished, time:2726.91 sec.
[32m[0325 10:15:39 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-10235379.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,168.93it/s]
58
[32m[0325 10:17:30 @monitor.py:363][0m QueueInput/queue_size: 0.045751
[32m[0325 10:17:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.714
[32m[0325 10:17:30 @monitor.py:363][0m activation-summaries/output-rms: 0.04193
[32m[0325 10:17:30 @monitor.py:363][0m cross_entropy_loss: 1.5057
[32m[0325 10:17:30 @monitor.py:363][0m lr: 4.7684e-10
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 10:17:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 10:17:30 @monitor.py:363][0m train-error-top1: 0.40851
[32m[0325 10:17:30 @monitor.py:363][0m val-error-top1: 0.41551
[32m[0325 10:17:30 @monitor.py:363][0m val-utt-error: 0.090001
[32m[0325 10:17:30 @monitor.py:363][0m validation_cost: 1.551
[32m[0325 10:17:30 @monitor.py:363][0m wd_cost: 1.4667e-14
[32m[0325 10:17:30 @group.py:42][0m Callbacks took 111.623 sec in total. InferenceRunner: 111.428sec
[32m[0325 10:17:30 @base.py:247][0m Start Epoch 61 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15508/173481[03:00<30:33,86.15it/s]  9%|9         |16234/173481[03:10<30:25,86.15it/s] 17%|#7        |29825/173481[06:00<28:56,82.71it/s] 18%|#7        |30687/173481[06:10<28:46,82.71it/s] 25%|##5       |43786/173481[09:00<27:00,80.05it/s] 26%|##5       |44746/173481[09:10<26:48,80.05it/s] 33%|###3      |57593/173481[12:00<24:39,78.34it/s] 34%|###3      |58387/173481[12:10<24:29,78.34it/s] 41%|####1     |71555/173481[15:00<21:47,77.95it/s] 42%|####1     |72379/173481[15:10<21:37,77.95it/s] 49%|####9     |85454/173481[18:00<18:54,77.58it/s] 50%|####9     |86323/173481[18:10<18:43,77.58it/s] 58%|#####7    |100277/173481[21:00<15:16,79.89it/s] 58%|#####8    |101178/173481[21:11<15:05,79.89it/s] 67%|######6   |115753/173481[24:00<11:37,82.82it/s] 67%|######7   |116735/173481[24:11<11:25,82.82it/s] 75%|#######5  |130683/173481[27:00<08:36,82.88it/s] 76%|#######5  |131539/173481[27:11<08:26,82.88it/s] 83%|########2 |143287/173481[30:00<06:37,75.90it/s] 83%|########3 |144109/173481[30:11<06:26,75.90it/s] 90%|######### |156165/173481[33:00<03:55,73.66it/s] 91%|######### |157006/173481[33:11<03:43,73.66it/s] 97%|#########6|167530/173481[36:00<01:27,67.99it/s] 97%|#########6|168211/173481[36:11<01:17,67.99it/s]100%|##########|173481/173481[37:38<00:00,76.80it/s]
[32m[0325 10:55:09 @base.py:257][0m Epoch 61 (global_step 10408860) finished, time:2258.83 sec.
[32m[0325 10:55:09 @saver.py:84][0m Model saved to train_log/fcn1_w_32_a_32_quant_ends_False/model-10408860.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,172.04it/s]
59
[32m[0325 10:56:59 @monitor.py:363][0m QueueInput/queue_size: 0.031496
[32m[0325 10:56:59 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.753
[32m[0325 10:56:59 @monitor.py:363][0m activation-summaries/output-rms: 0.04355
[32m[0325 10:56:59 @monitor.py:363][0m cross_entropy_loss: 1.4886
[32m[0325 10:56:59 @monitor.py:363][0m lr: 2.3842e-10
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59842
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2819
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3316
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/linear0/b-rms: 0.09698
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/linear1/W-rms: 0.33467
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/linear1/b-rms: 0.088304
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/linear2/W-rms: 0.29566
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/linear2/b-rms: 0.086491
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/linear3/W-rms: 0.28555
[32m[0325 10:56:59 @monitor.py:363][0m param-summary/linear3/b-rms: 0.081142
[32m[0325 10:56:59 @monitor.py:363][0m train-error-top1: 0.40586
[32m[0325 10:56:59 @monitor.py:363][0m val-error-top1: 0.41643
[32m[0325 10:56:59 @monitor.py:363][0m val-utt-error: 0.092604
[32m[0325 10:56:59 @monitor.py:363][0m validation_cost: 1.5522
[32m[0325 10:56:59 @monitor.py:363][0m wd_cost: 1.4667e-14
[32m[0325 10:56:59 @group.py:42][0m Callbacks took 109.637 sec in total. InferenceRunner: 109.425sec
[32m[0325 10:56:59 @base.py:247][0m Start Epoch 62 ...
  0%|          |0/173481[00:00<?,?it/s]slurmstepd: *** STEP 82592.0 ON sls-titanx-1 CANCELLED AT 2018-03-25T10:57:36 DUE TO TIME LIMIT ***
srun: error: sls-titanx-1: task 0: Terminated
srun: Force Terminated job step 82592.0
