sls-titanx-1 3
SLURM_JOBID=85146
SLURM_TASKID=4
[32m[0328 11:49:08 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=16 --bita=16 --quant_ends=True --load_ckpt=train_log/fcn1_w_16_a_32_quant_ends_False/checkpoint
[32m[0328 11:49:14 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0328 11:49:14 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0328 11:49:14 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0328 11:49:14 @drf_run.py:166][0m Using host: sls-titanx-1
[32m[0328 11:49:14 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0328 11:49:14 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0328 11:49:14 @drf_run.py:188][0m Using GPU: 3
[32m[0328 11:49:14 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0328 11:49:14 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 11:49:14 @training.py:108][0m Building graph for training tower 0 ...
[32m[0328 11:49:14 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0328 11:49:14 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:49:14 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:49:14 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:49:14 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:49:14 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:49:14 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:49:14 @registry.py:130][0m linear0 output: [None, 256]
[32m[0328 11:49:14 @registry.py:122][0m linear1 input: [None, 256]
[32m[0328 11:49:14 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:49:14 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:49:14 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:49:14 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:49:14 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:49:15 @registry.py:130][0m linear1 output: [None, 256]
[32m[0328 11:49:15 @registry.py:122][0m linear2 input: [None, 256]
[32m[0328 11:49:15 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:49:15 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:49:15 @registry.py:130][0m linear2 output: [None, 256]
[32m[0328 11:49:15 @registry.py:122][0m linear3 input: [None, 256]
[32m[0328 11:49:15 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:49:15 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:49:15 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:49:15 @registry.py:130][0m linear3 output: [None, 256]
[32m[0328 11:49:15 @registry.py:122][0m last_linear input: [None, 256]
[32m[0328 11:49:15 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:49:15 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:49:15 @registry.py:130][0m last_linear output: [None, 255]
[32m[0328 11:49:15 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:49:15 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0328 11:49:15 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0328 11:49:15 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0328 11:49:16 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0328 11:49:16 @base.py:196][0m Setup callbacks graph ...
[32m[0328 11:49:16 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight linear0/W
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight linear0/b
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0328 11:49:16 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight last_linear/W
[32m[0328 11:49:16 @drf_run.py:70][0m Quantizing weight last_linear/b
[32m[0328 11:49:16 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0328 11:49:16 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0328 11:49:16 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0328 11:49:16 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0328 11:49:17 @base.py:212][0m Creating the session ...
2018-03-28 11:49:17.690611: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-28 11:49:26.741670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:09:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-28 11:49:26.741740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:09:00.0, compute capability: 6.1)
[32m[0328 11:49:30 @base.py:220][0m Initializing the session ...
[32m[0328 11:49:30 @sessinit.py:116][0m Restoring checkpoint from train_log/fcn1_w_16_a_32_quant_ends_False/model-10408860 ...
[32m[0328 11:49:30 @base.py:227][0m Graph Finalized.
[32m[0328 11:49:30 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 11:49:30 @steps.py:127][0m Start training with global_step=10408860
[32m[0328 11:49:32 @base.py:247][0m Start Epoch 1 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |16511/173481[03:00<28:31,91.72it/s] 10%|#         |17436/173481[03:10<28:21,91.72it/s] 19%|#8        |32728/173481[06:00<25:48,90.90it/s] 19%|#9        |33656/173481[06:10<25:38,90.90it/s] 28%|##8       |48945/173481[09:00<22:56,90.50it/s] 29%|##8       |49880/173481[09:10<22:45,90.50it/s] 38%|###7      |65151/173481[12:00<20:00,90.26it/s] 38%|###8      |66109/173481[12:10<19:49,90.26it/s] 47%|####6     |81341/173481[15:00<17:02,90.10it/s] 47%|####7     |82312/173481[15:10<16:51,90.10it/s] 56%|#####5    |96971/173481[18:00<14:25,88.44it/s] 56%|#####6    |97955/173481[18:10<14:14,88.44it/s] 65%|######5   |113221/173481[21:00<11:14,89.35it/s] 66%|######5   |114211/173481[21:11<11:03,89.35it/s] 75%|#######4  |129406/173481[24:00<08:11,89.63it/s] 75%|#######5  |130395/173481[24:11<08:00,89.63it/s] 84%|########3 |145581/173481[27:00<05:10,89.74it/s] 85%|########4 |146595/173481[27:11<04:59,89.74it/s] 93%|#########3|161751/173481[30:00<02:10,89.78it/s] 94%|#########3|162471/173481[30:11<02:02,89.78it/s] 99%|#########9|172031/173481[33:00<00:20,69.80it/s]100%|#########9|172668/173481[33:11<00:11,69.80it/s]100%|##########|173481/173481[33:26<00:00,86.46it/s]
[32m[0328 12:22:59 @base.py:257][0m Epoch 1 (global_step 10582341) finished, time:2006.60 sec.
[32m[0328 12:22:59 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-10582341.
  0%|          |0/18822[00:00<?,?it/s] 49%|####8     |9214/18822[03:00<03:07,51.19it/s] 52%|#####2    |9799/18822[03:10<02:56,51.19it/s]100%|##########|18822/18822[05:24<00:00,58.09it/s]
0
[32m[0328 12:28:23 @monitor.py:363][0m QueueInput/queue_size: 1.0788
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.74
[32m[0328 12:28:23 @monitor.py:363][0m activation-summaries/output-rms: 0.016704
[32m[0328 12:28:23 @monitor.py:363][0m cross_entropy_loss: 7.1743
[32m[0328 12:28:23 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 12:28:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 12:28:23 @monitor.py:363][0m train-error-top1: 0.99348
[32m[0328 12:28:23 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0328 12:28:23 @monitor.py:363][0m val-utt-error: 0.99107
[32m[0328 12:28:23 @monitor.py:363][0m validation_cost: 7.2364
[32m[0328 12:28:23 @monitor.py:363][0m wd_cost: 2.8783e-15
[32m[0328 12:28:23 @group.py:42][0m Callbacks took 324.508 sec in total. InferenceRunner: 324.041sec
[32m[0328 12:28:23 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10590/173481[03:00<46:08,58.83it/s]  6%|6         |11125/173481[03:10<45:59,58.83it/s] 12%|#1        |20814/173481[06:00<44:01,57.80it/s] 12%|#2        |21417/173481[06:10<43:50,57.80it/s] 18%|#7        |30835/173481[09:00<41:55,56.70it/s] 18%|#8        |31394/173481[09:10<41:45,56.70it/s] 23%|##2       |39878/173481[12:00<41:47,53.27it/s] 23%|##3       |40414/173481[12:10<41:37,53.27it/s] 28%|##8       |49150/173481[15:00<39:34,52.37it/s] 29%|##8       |49719/173481[15:10<39:23,52.37it/s] 34%|###4      |59165/173481[18:00<35:18,53.95it/s] 34%|###4      |59784/173481[18:11<35:07,53.95it/s] 40%|###9      |69125/173481[21:00<31:50,54.63it/s] 40%|####      |69735/173481[21:11<31:39,54.63it/s] 46%|####5     |79371/173481[24:00<28:08,55.75it/s] 46%|####6     |80019/173481[24:11<27:56,55.75it/s] 52%|#####1    |89621/173481[27:00<24:48,56.34it/s] 52%|#####2    |90244/173481[27:11<24:37,56.34it/s] 58%|#####7    |99770/173481[30:00<21:48,56.35it/s] 58%|#####7    |100397/173481[30:11<21:36,56.35it/s] 63%|######3   |109870/173481[33:00<18:52,56.19it/s] 64%|######3   |110502/173481[33:11<18:40,56.19it/s] 69%|######9   |119795/173481[36:00<16:04,55.66it/s] 69%|######9   |120454/173481[36:11<15:52,55.66it/s] 75%|#######4  |129628/173481[39:00<13:15,55.14it/s] 75%|#######5  |130229/173481[39:12<13:04,55.14it/s] 80%|########  |139435/173481[42:00<10:21,54.81it/s] 81%|########  |140119/173481[42:12<10:08,54.81it/s] 86%|########6 |149466/173481[45:00<07:14,55.26it/s] 87%|########6 |150144/173481[45:12<07:02,55.26it/s] 92%|#########2|159639/173481[48:00<04:07,55.88it/s] 92%|#########2|160300/173481[48:12<03:55,55.88it/s] 98%|#########7|169790/173481[51:00<01:05,56.13it/s] 98%|#########8|170479/173481[51:12<00:53,56.13it/s]100%|##########|173481/173481[52:04<00:00,55.52it/s]
[32m[0328 13:20:28 @base.py:257][0m Epoch 2 (global_step 10755822) finished, time:3124.74 sec.
[32m[0328 13:20:29 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-10755822.
[32m[0328 13:20:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,197.14it/s]
1
[32m[0328 13:22:04 @monitor.py:363][0m QueueInput/queue_size: 0.60424
[32m[0328 13:22:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.732
[32m[0328 13:22:04 @monitor.py:363][0m activation-summaries/output-rms: 0.015972
[32m[0328 13:22:04 @monitor.py:363][0m cross_entropy_loss: 7.1566
[32m[0328 13:22:04 @monitor.py:363][0m lr: 2.3842e-10
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 13:22:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 13:22:04 @monitor.py:363][0m train-error-top1: 0.99236
[32m[0328 13:22:04 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0328 13:22:04 @monitor.py:363][0m val-utt-error: 0.99123
[32m[0328 13:22:04 @monitor.py:363][0m validation_cost: 7.2365
[32m[0328 13:22:04 @monitor.py:363][0m wd_cost: 2.8783e-15
[32m[0328 13:22:04 @group.py:42][0m Callbacks took 96.220 sec in total. InferenceRunner: 95.497sec
[32m[0328 13:22:04 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10890/173481[03:00<44:47,60.50it/s]  7%|6         |11434/173481[03:10<44:38,60.50it/s] 12%|#2        |21663/173481[06:00<42:03,60.17it/s] 13%|#2        |22242/173481[06:10<41:53,60.17it/s] 18%|#7        |31184/173481[09:00<42:07,56.29it/s] 18%|#8        |31724/173481[09:10<41:58,56.29it/s] 23%|##3       |40689/173481[12:00<40:37,54.49it/s] 24%|##3       |41244/173481[12:10<40:26,54.49it/s] 29%|##8       |50144/173481[15:00<38:26,53.49it/s] 29%|##9       |50693/173481[15:10<38:15,53.49it/s] 34%|###4      |59445/173481[18:00<36:09,52.56it/s] 35%|###4      |60013/173481[18:10<35:58,52.56it/s] 40%|####      |69549/173481[21:00<31:54,54.29it/s] 40%|####      |70163/173481[21:10<31:43,54.29it/s] 46%|####5     |79724/173481[24:00<28:13,55.38it/s] 46%|####6     |80354/173481[24:11<28:01,55.38it/s] 52%|#####1    |90181/173481[27:00<24:29,56.70it/s] 52%|#####2    |90829/173481[27:11<24:17,56.70it/s] 58%|#####7    |100442/173481[30:00<21:24,56.85it/s] 58%|#####8    |101111/173481[30:11<21:12,56.85it/s] 64%|######3   |110912/173481[33:00<18:08,57.50it/s] 64%|######4   |111528/173481[33:11<17:57,57.50it/s] 70%|######9   |121399/173481[36:00<14:59,57.87it/s] 70%|#######   |122028/173481[36:11<14:49,57.87it/s] 76%|#######5  |131831/173481[39:00<11:59,57.91it/s] 76%|#######6  |132491/173481[39:11<11:47,57.91it/s] 82%|########1 |142124/173481[42:00<09:04,57.54it/s] 82%|########2 |142863/173481[42:12<08:52,57.54it/s] 88%|########8 |152754/173481[45:00<05:55,58.28it/s] 88%|########8 |153458/173481[45:12<05:43,58.28it/s] 94%|#########4|163505/173481[48:00<02:49,58.99it/s] 95%|#########4|164249/173481[48:12<02:36,58.99it/s]100%|##########|173481/173481[50:43<00:00,56.99it/s]
[32m[0328 14:12:48 @base.py:257][0m Epoch 3 (global_step 10929303) finished, time:3043.83 sec.
[32m[0328 14:12:49 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-10929303.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,195.51it/s]
2
[32m[0328 14:14:25 @monitor.py:363][0m QueueInput/queue_size: 0.79968
[32m[0328 14:14:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.714
[32m[0328 14:14:25 @monitor.py:363][0m activation-summaries/output-rms: 0.016761
[32m[0328 14:14:25 @monitor.py:363][0m cross_entropy_loss: 7.1982
[32m[0328 14:14:25 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 14:14:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 14:14:25 @monitor.py:363][0m train-error-top1: 0.99101
[32m[0328 14:14:25 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0328 14:14:25 @monitor.py:363][0m val-utt-error: 0.99091
[32m[0328 14:14:25 @monitor.py:363][0m validation_cost: 7.2465
[32m[0328 14:14:25 @monitor.py:363][0m wd_cost: 2.8783e-15
[32m[0328 14:14:25 @group.py:42][0m Callbacks took 96.672 sec in total. InferenceRunner: 96.290sec
[32m[0328 14:14:25 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10994/173481[03:00<44:20,61.08it/s]  7%|6         |11527/173481[03:10<44:11,61.08it/s] 12%|#1        |20412/173481[06:00<45:15,56.36it/s] 12%|#2        |20972/173481[06:10<45:05,56.36it/s] 17%|#7        |29808/173481[09:00<44:11,54.19it/s] 18%|#7        |30404/173481[09:10<44:00,54.19it/s] 23%|##3       |39953/173481[12:00<40:16,55.25it/s] 23%|##3       |40552/173481[12:10<40:05,55.25it/s] 29%|##8       |50097/173481[15:00<36:51,55.80it/s] 29%|##9       |50730/173481[15:10<36:39,55.80it/s] 34%|###4      |59726/173481[18:00<34:42,54.62it/s] 35%|###4      |60357/173481[18:11<34:31,54.62it/s] 40%|####      |69916/173481[21:00<31:02,55.60it/s] 41%|####      |70507/173481[21:11<30:52,55.60it/s] 46%|####6     |80068/173481[24:00<27:48,55.99it/s] 47%|####6     |80720/173481[24:11<27:36,55.99it/s] 52%|#####1    |89860/173481[27:00<25:15,55.18it/s] 52%|#####2    |90447/173481[27:11<25:04,55.18it/s] 57%|#####7    |99648/173481[30:00<22:27,54.77it/s] 58%|#####7    |100307/173481[30:11<22:15,54.77it/s] 64%|######3   |110478/173481[33:00<18:18,57.34it/s] 64%|######4   |111147/173481[33:11<18:07,57.34it/s] 70%|######9   |121336/173481[36:00<14:46,58.79it/s] 70%|#######   |122027/173481[36:11<14:35,58.79it/s] 76%|#######6  |131909/173481[39:00<11:47,58.76it/s] 76%|#######6  |132607/173481[39:12<11:35,58.76it/s] 82%|########2 |142303/173481[42:00<08:55,58.25it/s] 82%|########2 |142982/173481[42:12<08:43,58.25it/s] 88%|########7 |152428/173481[45:00<06:07,57.23it/s] 88%|########8 |153123/173481[45:12<05:55,57.23it/s] 94%|#########3|162918/173481[48:00<03:02,57.75it/s] 94%|#########4|163630/173481[48:12<02:50,57.75it/s] 99%|#########9|172180/173481[51:00<00:23,54.42it/s]100%|#########9|172890/173481[51:12<00:10,54.42it/s]100%|##########|173481/173481[51:24<00:00,56.25it/s]
[32m[0328 15:05:49 @base.py:257][0m Epoch 4 (global_step 11102784) finished, time:3084.16 sec.
[32m[0328 15:05:50 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-11102784.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:33<00:00,202.33it/s]
3
[32m[0328 15:07:23 @monitor.py:363][0m QueueInput/queue_size: 0.66606
[32m[0328 15:07:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.719
[32m[0328 15:07:23 @monitor.py:363][0m activation-summaries/output-rms: 0.016504
[32m[0328 15:07:23 @monitor.py:363][0m cross_entropy_loss: 7.2072
[32m[0328 15:07:23 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 15:07:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 15:07:23 @monitor.py:363][0m train-error-top1: 0.99221
[32m[0328 15:07:23 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0328 15:07:23 @monitor.py:363][0m val-utt-error: 0.99134
[32m[0328 15:07:23 @monitor.py:363][0m validation_cost: 7.2364
[32m[0328 15:07:23 @monitor.py:363][0m wd_cost: 5.7566e-16
[32m[0328 15:07:23 @group.py:42][0m Callbacks took 93.590 sec in total. InferenceRunner: 93.039sec
[32m[0328 15:07:23 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9277/173481[03:00<53:06,51.53it/s]  6%|5         |9757/173481[03:10<52:57,51.53it/s] 11%|#1        |19090/173481[06:00<48:34,52.98it/s] 11%|#1        |19696/173481[06:10<48:22,52.98it/s] 17%|#6        |29197/173481[09:00<44:06,54.51it/s] 17%|#7        |29842/173481[09:10<43:55,54.51it/s] 23%|##2       |39557/173481[12:00<39:51,55.99it/s] 23%|##3       |40125/173481[12:10<39:41,55.99it/s] 28%|##8       |49246/173481[15:00<37:43,54.88it/s] 29%|##8       |49861/173481[15:10<37:32,54.88it/s] 34%|###4      |59820/173481[18:00<33:22,56.75it/s] 35%|###4      |60427/173481[18:10<33:12,56.75it/s] 40%|####      |70028/173481[21:00<30:23,56.73it/s] 41%|####      |70647/173481[21:10<30:12,56.73it/s] 46%|####5     |79587/173481[24:00<28:31,54.86it/s] 46%|####6     |80176/173481[24:11<28:20,54.86it/s] 51%|#####1    |88827/173481[27:00<26:36,53.03it/s] 52%|#####1    |89444/173481[27:11<26:24,53.03it/s] 57%|#####6    |98577/173481[30:00<23:17,53.59it/s] 57%|#####7    |99146/173481[30:11<23:07,53.59it/s] 62%|######2   |108070/173481[33:00<20:30,53.16it/s] 63%|######2   |108651/173481[33:11<20:19,53.16it/s] 68%|######7   |117912/173481[36:00<17:10,53.90it/s] 68%|######8   |118536/173481[36:11<16:59,53.90it/s] 74%|#######3  |127682/173481[39:00<14:06,54.09it/s] 74%|#######3  |128258/173481[39:11<13:56,54.09it/s] 79%|#######9  |137193/173481[42:00<11:18,53.46it/s] 79%|#######9  |137776/173481[42:11<11:07,53.46it/s] 85%|########4 |147166/173481[45:00<08:03,54.41it/s] 85%|########5 |147831/173481[45:12<07:51,54.41it/s] 91%|######### |157322/173481[48:00<04:51,55.39it/s] 91%|#########1|157998/173481[48:12<04:39,55.39it/s] 96%|#########6|166867/173481[51:00<02:02,54.18it/s] 97%|#########6|167486/173481[51:12<01:50,54.18it/s]100%|##########|173481/173481[53:07<00:00,54.43it/s]
[32m[0328 16:00:30 @base.py:257][0m Epoch 5 (global_step 11276265) finished, time:3187.43 sec.
[32m[0328 16:00:30 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-11276265.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.78it/s]
4
[32m[0328 16:02:08 @monitor.py:363][0m QueueInput/queue_size: 0.32208
[32m[0328 16:02:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.66
[32m[0328 16:02:08 @monitor.py:363][0m activation-summaries/output-rms: 0.016171
[32m[0328 16:02:08 @monitor.py:363][0m cross_entropy_loss: 7.203
[32m[0328 16:02:08 @monitor.py:363][0m lr: 1.1921e-10
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 16:02:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 16:02:08 @monitor.py:363][0m train-error-top1: 0.99311
[32m[0328 16:02:08 @monitor.py:363][0m val-error-top1: 0.99345
[32m[0328 16:02:08 @monitor.py:363][0m val-utt-error: 0.99044
[32m[0328 16:02:08 @monitor.py:363][0m validation_cost: 7.2623
[32m[0328 16:02:08 @monitor.py:363][0m wd_cost: 5.7566e-16
[32m[0328 16:02:08 @group.py:42][0m Callbacks took 97.536 sec in total. InferenceRunner: 97.147sec
[32m[0328 16:02:08 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10558/173481[03:00<46:17,58.65it/s]  6%|6         |11165/173481[03:10<46:07,58.65it/s] 12%|#2        |21146/173481[06:00<43:13,58.73it/s] 13%|#2        |21726/173481[06:10<43:03,58.73it/s] 18%|#8        |31452/173481[09:00<40:49,57.98it/s] 18%|#8        |31975/173481[09:10<40:40,57.98it/s] 23%|##3       |40441/173481[12:00<41:20,53.65it/s] 24%|##3       |40940/173481[12:10<41:10,53.65it/s] 29%|##8       |49446/173481[15:00<39:55,51.77it/s] 29%|##8       |49977/173481[15:10<39:45,51.77it/s] 34%|###3      |58715/173481[18:00<37:02,51.63it/s] 34%|###4      |59320/173481[18:10<36:51,51.63it/s] 40%|###9      |68721/173481[21:00<32:36,53.54it/s] 40%|###9      |69264/173481[21:11<32:26,53.54it/s] 45%|####4     |77890/173481[24:00<30:31,52.20it/s] 45%|####5     |78461/173481[24:11<30:20,52.20it/s] 50%|#####     |86947/173481[27:00<28:08,51.24it/s] 50%|#####     |87503/173481[27:11<27:57,51.24it/s] 55%|#####5    |95971/173481[30:00<25:29,50.68it/s] 56%|#####5    |96496/173481[30:11<25:19,50.68it/s] 60%|######    |104655/173481[33:00<23:12,49.43it/s] 61%|######    |105205/173481[33:11<23:01,49.43it/s] 65%|######5   |113477/173481[36:00<20:19,49.22it/s] 66%|######5   |114070/173481[36:11<20:07,49.22it/s] 71%|#######   |122761/173481[39:00<16:47,50.36it/s] 71%|#######1  |123375/173481[39:11<16:34,50.36it/s] 76%|#######6  |131876/173481[42:00<13:43,50.50it/s] 76%|#######6  |132464/173481[42:12<13:32,50.50it/s] 81%|########1 |141006/173481[45:00<10:41,50.61it/s] 82%|########1 |141625/173481[45:12<10:29,50.61it/s] 87%|########6 |150078/173481[48:00<07:43,50.50it/s] 87%|########6 |150750/173481[48:12<07:30,50.50it/s] 92%|#########2|159663/173481[51:00<04:26,51.84it/s] 92%|#########2|160297/173481[51:12<04:14,51.84it/s] 97%|#########7|168396/173481[54:00<01:41,50.12it/s] 97%|#########7|168975/173481[54:12<01:29,50.12it/s]100%|##########|173481/173481[55:47<00:00,51.83it/s]
[32m[0328 16:57:55 @base.py:257][0m Epoch 6 (global_step 11449746) finished, time:3347.20 sec.
[32m[0328 16:57:55 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-11449746.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,197.19it/s]
5
[32m[0328 16:59:31 @monitor.py:363][0m QueueInput/queue_size: 0.20715
[32m[0328 16:59:31 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.74
[32m[0328 16:59:31 @monitor.py:363][0m activation-summaries/output-rms: 0.016704
[32m[0328 16:59:31 @monitor.py:363][0m cross_entropy_loss: 7.1743
[32m[0328 16:59:31 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 16:59:31 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 16:59:31 @monitor.py:363][0m train-error-top1: 0.99348
[32m[0328 16:59:31 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0328 16:59:31 @monitor.py:363][0m val-utt-error: 0.99113
[32m[0328 16:59:31 @monitor.py:363][0m validation_cost: 7.2363
[32m[0328 16:59:31 @monitor.py:363][0m wd_cost: 5.7566e-16
[32m[0328 16:59:31 @group.py:42][0m Callbacks took 95.857 sec in total. InferenceRunner: 95.461sec
[32m[0328 16:59:31 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |9652/173481[03:00<50:55,53.62it/s]  6%|5         |10160/173481[03:10<50:45,53.62it/s] 11%|#         |18845/173481[06:00<49:15,52.31it/s] 11%|#1        |19376/173481[06:10<49:05,52.31it/s] 16%|#6        |27950/173481[09:00<47:09,51.43it/s] 16%|#6        |28499/173481[09:10<46:58,51.43it/s] 21%|##1       |36741/173481[12:00<45:29,50.10it/s] 21%|##1       |37239/173481[12:10<45:19,50.10it/s] 26%|##5       |45065/173481[15:00<44:30,48.09it/s] 26%|##6       |45571/173481[15:10<44:19,48.09it/s] 31%|###       |53620/173481[18:00<41:47,47.80it/s] 31%|###1      |54170/173481[18:10<41:36,47.80it/s] 36%|###6      |62791/173481[21:00<37:24,49.32it/s] 36%|###6      |63294/173481[21:11<37:13,49.32it/s] 41%|####1     |71805/173481[24:00<34:06,49.69it/s] 42%|####1     |72379/173481[24:11<33:54,49.69it/s] 47%|####6     |81106/173481[27:00<30:23,50.66it/s] 47%|####7     |81672/173481[27:11<30:12,50.66it/s] 52%|#####2    |90505/173481[30:00<26:53,51.43it/s] 53%|#####2    |91126/173481[30:11<26:41,51.43it/s] 58%|#####7    |99981/173481[33:00<23:32,52.03it/s] 58%|#####7    |100567/173481[33:11<23:21,52.03it/s] 63%|######3   |109335/173481[36:00<20:33,52.00it/s] 63%|######3   |109919/173481[36:11<20:22,52.00it/s] 68%|######8   |118355/173481[39:00<18:00,51.03it/s] 69%|######8   |118933/173481[39:12<17:49,51.03it/s] 73%|#######3  |127357/173481[42:00<15:13,50.51it/s] 74%|#######3  |127949/173481[42:12<15:01,50.51it/s] 78%|#######8  |136114/173481[45:00<12:33,49.56it/s] 79%|#######8  |136693/173481[45:12<12:22,49.56it/s] 84%|########3 |144985/173481[48:00<09:36,49.42it/s] 84%|########3 |145562/173481[48:12<09:24,49.42it/s] 89%|########8 |154105/173481[51:00<06:27,50.03it/s] 89%|########9 |154701/173481[51:12<06:15,50.03it/s] 94%|#########4|163541/173481[54:00<03:14,51.20it/s] 95%|#########4|164169/173481[54:12<03:01,51.20it/s]100%|#########9|173420/173481[57:00<00:01,52.98it/s]100%|##########|173481/173481[57:01<00:00,50.70it/s]
[32m[0328 17:56:32 @base.py:257][0m Epoch 7 (global_step 11623227) finished, time:3421.45 sec.
[32m[0328 17:56:32 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-11623227.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:18<00:00,135.76it/s]
6
[32m[0328 17:58:51 @monitor.py:363][0m QueueInput/queue_size: 0.24578
[32m[0328 17:58:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.732
[32m[0328 17:58:51 @monitor.py:363][0m activation-summaries/output-rms: 0.015972
[32m[0328 17:58:51 @monitor.py:363][0m cross_entropy_loss: 7.1566
[32m[0328 17:58:51 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 17:58:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 17:58:51 @monitor.py:363][0m train-error-top1: 0.99236
[32m[0328 17:58:51 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0328 17:58:51 @monitor.py:363][0m val-utt-error: 0.99118
[32m[0328 17:58:51 @monitor.py:363][0m validation_cost: 7.2364
[32m[0328 17:58:51 @monitor.py:363][0m wd_cost: 1.1513e-16
[32m[0328 17:58:51 @group.py:42][0m Callbacks took 139.050 sec in total. InferenceRunner: 138.662sec
[32m[0328 17:58:51 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13994/173481[03:00<34:11,77.73it/s]  8%|8         |14587/173481[03:10<34:04,77.73it/s] 14%|#3        |23964/173481[06:00<38:31,64.68it/s] 14%|#4        |24449/173481[06:10<38:24,64.68it/s] 19%|#8        |32830/173481[09:00<41:55,55.92it/s] 19%|#9        |33316/173481[09:10<41:46,55.92it/s] 24%|##4       |42300/173481[12:00<40:19,54.21it/s] 25%|##4       |42863/173481[12:10<40:09,54.21it/s] 30%|##9       |51884/173481[15:00<37:43,53.72it/s] 30%|###       |52448/173481[15:10<37:33,53.72it/s] 35%|###5      |61139/173481[18:00<35:38,52.54it/s] 36%|###5      |61688/173481[18:10<35:27,52.54it/s] 41%|####1     |71338/173481[21:00<31:13,54.52it/s] 42%|####1     |72108/173481[21:11<30:59,54.52it/s] 47%|####7     |81970/173481[24:00<26:53,56.70it/s] 48%|####7     |82503/173481[24:11<26:44,56.70it/s] 53%|#####2    |91527/173481[27:00<24:54,54.84it/s] 53%|#####3    |92100/173481[27:11<24:44,54.84it/s] 58%|#####8    |101024/173481[30:00<22:27,53.78it/s] 59%|#####8    |101613/173481[30:11<22:16,53.78it/s] 64%|######3   |110551/173481[33:00<19:39,53.35it/s] 64%|######4   |111173/173481[33:11<19:27,53.35it/s] 69%|######9   |120541/173481[36:00<16:13,54.40it/s] 70%|######9   |121198/173481[36:11<16:01,54.40it/s] 75%|#######5  |130628/173481[39:00<12:56,55.21it/s] 76%|#######5  |131255/173481[39:12<12:44,55.21it/s] 81%|########1 |140939/173481[42:00<09:38,56.22it/s] 82%|########1 |141609/173481[42:12<09:26,56.22it/s] 87%|########7 |150934/173481[45:00<06:43,55.86it/s] 87%|########7 |151611/173481[45:12<06:31,55.86it/s] 93%|#########2|160904/173481[48:00<03:46,55.62it/s] 93%|#########3|161619/173481[48:12<03:33,55.62it/s] 99%|#########8|170889/173481[51:00<00:46,55.55it/s] 99%|#########8|171573/173481[51:12<00:34,55.55it/s]100%|##########|173481/173481[51:47<00:00,55.83it/s]
[32m[0328 18:50:38 @base.py:257][0m Epoch 8 (global_step 11796708) finished, time:3107.13 sec.
[32m[0328 18:50:39 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-11796708.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:49<00:00,172.63it/s]
7
[32m[0328 18:52:28 @monitor.py:363][0m QueueInput/queue_size: 0.2055
[32m[0328 18:52:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.714
[32m[0328 18:52:28 @monitor.py:363][0m activation-summaries/output-rms: 0.016761
[32m[0328 18:52:28 @monitor.py:363][0m cross_entropy_loss: 7.1981
[32m[0328 18:52:28 @monitor.py:363][0m lr: 5.9605e-11
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 18:52:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 18:52:28 @monitor.py:363][0m train-error-top1: 0.99101
[32m[0328 18:52:28 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0328 18:52:28 @monitor.py:363][0m val-utt-error: 0.99091
[32m[0328 18:52:28 @monitor.py:363][0m validation_cost: 7.2465
[32m[0328 18:52:28 @monitor.py:363][0m wd_cost: 1.1513e-16
[32m[0328 18:52:28 @group.py:42][0m Callbacks took 109.398 sec in total. InferenceRunner: 109.046sec
[32m[0328 18:52:28 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11558/173481[03:00<42:01,64.21it/s]  7%|6         |12082/173481[03:10<41:53,64.21it/s] 12%|#1        |20653/173481[06:00<45:02,56.54it/s] 12%|#2        |21200/173481[06:10<44:53,56.54it/s] 18%|#7        |30746/173481[09:00<42:15,56.31it/s] 18%|#8        |31347/173481[09:10<42:04,56.31it/s] 24%|##3       |41316/173481[12:00<38:19,57.49it/s] 24%|##4       |42011/173481[12:10<38:06,57.49it/s] 31%|###       |53053/173481[15:00<32:51,61.10it/s] 31%|###       |53703/173481[15:10<32:40,61.10it/s] 37%|###7      |64199/173481[18:00<29:36,61.51it/s] 37%|###7      |64866/173481[18:10<29:25,61.51it/s] 44%|####3     |75513/173481[21:00<26:15,62.17it/s] 44%|####3     |76167/173481[21:11<26:05,62.17it/s] 50%|####9     |86298/173481[24:00<23:48,61.02it/s] 50%|#####     |86936/173481[24:11<23:38,61.02it/s] 56%|#####6    |97358/173481[27:00<20:43,61.23it/s] 57%|#####6    |98047/173481[27:11<20:31,61.23it/s] 62%|######2   |108417/173481[30:00<17:40,61.33it/s] 63%|######2   |109102/173481[30:11<17:29,61.33it/s] 69%|######8   |119474/173481[33:00<14:39,61.38it/s] 69%|######9   |120165/173481[33:11<14:28,61.38it/s] 75%|#######5  |130515/173481[36:00<11:40,61.36it/s] 76%|#######5  |131202/173481[36:11<11:29,61.36it/s] 82%|########1 |141798/173481[39:00<08:30,62.01it/s] 82%|########2 |142543/173481[39:12<08:18,62.01it/s] 88%|########8 |153060/173481[42:00<05:27,62.28it/s] 89%|########8 |153839/173481[42:12<05:15,62.28it/s] 95%|#########4|164331/173481[45:00<02:26,62.45it/s] 95%|#########5|165067/173481[45:12<02:14,62.45it/s]100%|##########|173481/173481[47:37<00:00,60.71it/s]
[32m[0328 19:40:05 @base.py:257][0m Epoch 9 (global_step 11970189) finished, time:2857.45 sec.
[32m[0328 19:40:06 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-11970189.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,198.65it/s]
8
[32m[0328 19:41:40 @monitor.py:363][0m QueueInput/queue_size: 0.478
[32m[0328 19:41:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.719
[32m[0328 19:41:40 @monitor.py:363][0m activation-summaries/output-rms: 0.016504
[32m[0328 19:41:40 @monitor.py:363][0m cross_entropy_loss: 7.2072
[32m[0328 19:41:40 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 19:41:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 19:41:40 @monitor.py:363][0m train-error-top1: 0.99221
[32m[0328 19:41:40 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0328 19:41:40 @monitor.py:363][0m val-utt-error: 0.99134
[32m[0328 19:41:40 @monitor.py:363][0m validation_cost: 7.2363
[32m[0328 19:41:40 @monitor.py:363][0m wd_cost: 1.1513e-16
[32m[0328 19:41:40 @group.py:42][0m Callbacks took 95.258 sec in total. InferenceRunner: 94.760sec
[32m[0328 19:41:40 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11292/173481[03:00<43:06,62.72it/s]  7%|6         |11895/173481[03:10<42:56,62.72it/s] 13%|#2        |22263/173481[06:00<40:46,61.82it/s] 13%|#3        |22751/173481[06:10<40:38,61.82it/s] 19%|#9        |33246/173481[09:00<38:03,61.41it/s] 20%|#9        |33901/173481[09:10<37:52,61.41it/s] 26%|##5       |44420/173481[12:00<34:50,61.74it/s] 26%|##5       |45075/173481[12:10<34:39,61.74it/s] 32%|###1      |55332/173481[15:00<32:11,61.18it/s] 32%|###2      |55953/173481[15:10<32:01,61.18it/s] 38%|###8      |66042/173481[18:00<29:40,60.33it/s] 38%|###8      |66690/173481[18:10<29:30,60.33it/s] 44%|####4     |76982/173481[21:00<26:33,60.55it/s] 45%|####4     |77661/173481[21:11<26:22,60.55it/s] 51%|#####     |88227/173481[24:00<23:06,61.49it/s] 51%|#####1    |88921/173481[24:11<22:55,61.49it/s] 57%|#####6    |98555/173481[27:00<21:02,59.36it/s] 57%|#####7    |99231/173481[27:11<20:50,59.36it/s] 63%|######2   |108936/173481[30:00<18:23,58.50it/s] 63%|######3   |109561/173481[30:11<18:12,58.50it/s] 68%|######8   |118775/173481[33:00<16:07,56.52it/s] 69%|######8   |119407/173481[33:11<15:56,56.52it/s] 74%|#######4  |128917/173481[36:00<13:09,56.42it/s] 75%|#######4  |129538/173481[36:11<12:58,56.42it/s] 80%|########  |139387/173481[39:00<09:55,57.27it/s] 81%|########  |140107/173481[39:12<09:42,57.27it/s] 87%|########6 |150405/173481[42:00<06:29,59.18it/s] 87%|########7 |151156/173481[42:12<06:17,59.18it/s] 93%|#########2|161237/173481[45:00<03:25,59.66it/s] 93%|#########3|161906/173481[45:12<03:14,59.66it/s] 99%|#########8|171363/173481[48:00<00:36,57.91it/s] 99%|#########9|172081/173481[48:12<00:24,57.91it/s]100%|##########|173481/173481[48:38<00:00,59.44it/s]
[32m[0328 20:30:19 @base.py:257][0m Epoch 10 (global_step 12143670) finished, time:2918.53 sec.
[32m[0328 20:30:19 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-12143670.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.48it/s]
9
[32m[0328 20:31:58 @monitor.py:363][0m QueueInput/queue_size: 0.29908
[32m[0328 20:31:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.66
[32m[0328 20:31:58 @monitor.py:363][0m activation-summaries/output-rms: 0.016171
[32m[0328 20:31:58 @monitor.py:363][0m cross_entropy_loss: 7.2029
[32m[0328 20:31:58 @monitor.py:363][0m lr: 2.9802e-11
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 20:31:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 20:31:58 @monitor.py:363][0m train-error-top1: 0.99311
[32m[0328 20:31:58 @monitor.py:363][0m val-error-top1: 0.99345
[32m[0328 20:31:58 @monitor.py:363][0m val-utt-error: 0.99049
[32m[0328 20:31:58 @monitor.py:363][0m validation_cost: 7.2623
[32m[0328 20:31:58 @monitor.py:363][0m wd_cost: 2.3026e-17
[32m[0328 20:31:58 @group.py:42][0m Callbacks took 99.272 sec in total. InferenceRunner: 98.824sec
[32m[0328 20:31:58 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11693/173481[03:00<41:30,64.96it/s]  7%|7         |12307/173481[03:10<41:21,64.96it/s] 13%|#3        |22811/173481[06:00<39:39,63.32it/s] 14%|#3        |23465/173481[06:10<39:29,63.32it/s] 20%|#9        |33829/173481[09:00<37:23,62.25it/s] 20%|#9        |34436/173481[09:10<37:13,62.25it/s] 26%|##5       |44480/173481[12:00<35:26,60.67it/s] 26%|##6       |45121/173481[12:10<35:15,60.67it/s] 32%|###1      |55046/173481[15:00<33:04,59.67it/s] 32%|###2      |55710/173481[15:10<32:53,59.67it/s] 38%|###8      |66053/173481[18:00<29:38,60.40it/s] 38%|###8      |66730/173481[18:10<29:27,60.40it/s] 44%|####4     |76473/173481[21:00<27:21,59.12it/s] 44%|####4     |77101/173481[21:11<27:10,59.12it/s] 50%|#####     |86937/173481[24:00<24:36,58.62it/s] 50%|#####     |87595/173481[24:11<24:25,58.62it/s] 56%|#####6    |97381/173481[27:00<21:44,58.32it/s] 57%|#####6    |98028/173481[27:11<21:33,58.32it/s] 62%|######2   |107611/173481[30:00<19:04,57.56it/s] 62%|######2   |108272/173481[30:11<18:52,57.56it/s] 68%|######8   |118271/173481[33:00<15:45,58.37it/s] 69%|######8   |118975/173481[33:11<15:33,58.37it/s] 74%|#######4  |128980/173481[36:00<12:35,58.93it/s] 75%|#######4  |129652/173481[36:11<12:23,58.93it/s] 81%|########  |139669/173481[39:00<09:31,59.15it/s] 81%|########  |140365/173481[39:12<09:19,59.15it/s] 87%|########6 |150146/173481[42:00<06:37,58.67it/s] 87%|########6 |150840/173481[42:12<06:25,58.67it/s] 93%|#########2|160517/173481[45:00<03:42,58.14it/s] 93%|#########2|161215/173481[45:12<03:30,58.14it/s] 98%|#########8|170641/173481[48:00<00:49,57.17it/s] 99%|#########8|171330/173481[48:12<00:37,57.17it/s]100%|##########|173481/173481[48:51<00:00,59.18it/s]
[32m[0328 21:20:50 @base.py:257][0m Epoch 11 (global_step 12317151) finished, time:2931.61 sec.
[32m[0328 21:20:50 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-12317151.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:33<00:00,201.73it/s]
10
[32m[0328 21:22:24 @monitor.py:363][0m QueueInput/queue_size: 0.16389
[32m[0328 21:22:24 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.74
[32m[0328 21:22:24 @monitor.py:363][0m activation-summaries/output-rms: 0.016703
[32m[0328 21:22:24 @monitor.py:363][0m cross_entropy_loss: 7.1743
[32m[0328 21:22:24 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 21:22:24 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 21:22:24 @monitor.py:363][0m train-error-top1: 0.99348
[32m[0328 21:22:24 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0328 21:22:24 @monitor.py:363][0m val-utt-error: 0.99113
[32m[0328 21:22:24 @monitor.py:363][0m validation_cost: 7.2363
[32m[0328 21:22:24 @monitor.py:363][0m wd_cost: 2.3026e-17
[32m[0328 21:22:24 @group.py:42][0m Callbacks took 93.732 sec in total. InferenceRunner: 93.320sec
[32m[0328 21:22:24 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11143/173481[03:00<43:42,61.90it/s]  7%|6         |11729/173481[03:10<43:32,61.90it/s] 13%|#2        |21710/173481[06:00<41:58,60.26it/s] 13%|#2        |22346/173481[06:10<41:48,60.26it/s] 19%|#8        |32372/173481[09:00<39:22,59.74it/s] 19%|#8        |32953/173481[09:10<39:12,59.74it/s] 24%|##4       |42075/173481[12:00<38:38,56.67it/s] 25%|##4       |42569/173481[12:10<38:30,56.67it/s] 30%|###       |52085/173481[15:00<36:03,56.12it/s] 30%|###       |52684/173481[15:10<35:52,56.12it/s] 36%|###6      |62905/173481[18:00<31:45,58.04it/s] 37%|###6      |63490/173481[18:11<31:34,58.04it/s] 42%|####2     |73584/173481[21:00<28:22,58.68it/s] 43%|####2     |74299/173481[21:11<28:10,58.68it/s] 49%|####8     |84352/173481[24:00<25:04,59.24it/s] 49%|####8     |84996/173481[24:11<24:53,59.24it/s] 55%|#####4    |94845/173481[27:00<22:18,58.76it/s] 55%|#####5    |95504/173481[27:11<22:06,58.76it/s] 61%|######    |105105/173481[30:00<19:41,57.87it/s] 61%|######    |105768/173481[30:11<19:30,57.87it/s] 67%|######6   |115480/173481[33:00<16:44,57.75it/s] 67%|######6   |116114/173481[33:11<16:33,57.75it/s] 72%|#######2  |125547/173481[36:00<14:03,56.82it/s] 73%|#######2  |126185/173481[36:11<13:52,56.82it/s] 78%|#######8  |135965/173481[39:00<10:54,57.34it/s] 79%|#######8  |136659/173481[39:12<10:42,57.34it/s] 85%|########4 |146795/173481[42:00<07:34,58.71it/s] 85%|########5 |147495/173481[42:12<07:22,58.71it/s] 91%|######### |157544/173481[45:00<04:29,59.21it/s] 91%|#########1|158224/173481[45:12<04:17,59.21it/s] 97%|#########6|168001/173481[48:00<01:33,58.64it/s] 97%|#########7|168749/173481[48:12<01:20,58.64it/s]100%|##########|173481/173481[49:32<00:00,58.35it/s]
[32m[0328 22:11:56 @base.py:257][0m Epoch 12 (global_step 12490632) finished, time:2972.92 sec.
[32m[0328 22:11:57 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-12490632.
[32m[0328 22:11:58 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,195.25it/s]
11
[32m[0328 22:13:34 @monitor.py:363][0m QueueInput/queue_size: 0.31497
[32m[0328 22:13:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.732
[32m[0328 22:13:34 @monitor.py:363][0m activation-summaries/output-rms: 0.015972
[32m[0328 22:13:34 @monitor.py:363][0m cross_entropy_loss: 7.1566
[32m[0328 22:13:34 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 22:13:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 22:13:34 @monitor.py:363][0m train-error-top1: 0.99236
[32m[0328 22:13:34 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0328 22:13:34 @monitor.py:363][0m val-utt-error: 0.99118
[32m[0328 22:13:34 @monitor.py:363][0m validation_cost: 7.2364
[32m[0328 22:13:34 @monitor.py:363][0m wd_cost: 4.6053e-18
[32m[0328 22:13:34 @group.py:42][0m Callbacks took 97.550 sec in total. InferenceRunner: 96.413sec
[32m[0328 22:13:34 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12414/173481[03:00<38:55,68.97it/s]  8%|7         |13093/173481[03:10<38:45,68.97it/s] 13%|#3        |23319/173481[06:00<38:47,64.50it/s] 14%|#3        |23894/173481[06:10<38:39,64.50it/s] 19%|#9        |32989/173481[09:00<39:56,58.62it/s] 19%|#9        |33568/173481[09:10<39:46,58.62it/s] 25%|##4       |43251/173481[12:00<37:33,57.80it/s] 25%|##5       |43833/173481[12:10<37:22,57.80it/s] 31%|###1      |53834/173481[15:00<34:12,58.29it/s] 31%|###1      |54453/173481[15:10<34:01,58.29it/s] 37%|###7      |64319/173481[18:00<31:13,58.26it/s] 37%|###7      |64986/173481[18:10<31:02,58.26it/s] 44%|####3     |75854/173481[21:00<26:39,61.03it/s] 44%|####4     |76663/173481[21:11<26:26,61.03it/s] 50%|#####     |87164/173481[24:00<23:14,61.92it/s] 51%|#####     |87853/173481[24:11<23:02,61.92it/s] 56%|#####6    |97778/173481[27:00<20:53,60.41it/s] 57%|#####6    |98438/173481[27:11<20:42,60.41it/s] 63%|######2   |108479/173481[30:00<18:04,59.92it/s] 63%|######2   |109091/173481[30:11<17:54,59.92it/s] 69%|######8   |119264/173481[33:00<15:04,59.91it/s] 69%|######9   |119973/173481[33:11<14:53,59.91it/s] 75%|#######4  |130059/173481[36:00<12:04,59.94it/s] 75%|#######5  |130748/173481[36:11<11:52,59.94it/s] 81%|########1 |140944/173481[39:00<09:00,60.20it/s] 82%|########1 |141714/173481[39:12<08:47,60.20it/s] 88%|########7 |152009/173481[42:00<05:52,60.83it/s] 88%|########8 |152788/173481[42:12<05:40,60.83it/s] 94%|#########4|163289/173481[45:00<02:45,61.72it/s] 95%|#########4|164110/173481[45:12<02:31,61.72it/s]100%|##########|173481/173481[47:36<00:00,60.74it/s]
[32m[0328 23:01:10 @base.py:257][0m Epoch 13 (global_step 12664113) finished, time:2856.27 sec.
[32m[0328 23:01:11 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-12664113.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:32<00:00,202.75it/s]
12
[32m[0328 23:02:44 @monitor.py:363][0m QueueInput/queue_size: 0.50665
[32m[0328 23:02:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.714
[32m[0328 23:02:44 @monitor.py:363][0m activation-summaries/output-rms: 0.016761
[32m[0328 23:02:44 @monitor.py:363][0m cross_entropy_loss: 7.1981
[32m[0328 23:02:44 @monitor.py:363][0m lr: 1.4901e-11
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 23:02:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 23:02:44 @monitor.py:363][0m train-error-top1: 0.99101
[32m[0328 23:02:44 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0328 23:02:44 @monitor.py:363][0m val-utt-error: 0.99091
[32m[0328 23:02:44 @monitor.py:363][0m validation_cost: 7.2465
[32m[0328 23:02:44 @monitor.py:363][0m wd_cost: 4.6053e-18
[32m[0328 23:02:44 @group.py:42][0m Callbacks took 93.538 sec in total. InferenceRunner: 92.841sec
[32m[0328 23:02:44 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11683/173481[03:00<41:33,64.88it/s]  7%|7         |12310/173481[03:10<41:24,64.88it/s] 13%|#2        |22458/173481[06:00<40:25,62.27it/s] 13%|#3        |23113/173481[06:10<40:14,62.27it/s] 19%|#9        |33405/173481[09:00<37:56,61.53it/s] 20%|#9        |34062/173481[09:10<37:45,61.53it/s] 26%|##5       |44639/173481[12:00<34:39,61.97it/s] 26%|##6       |45322/173481[12:10<34:28,61.97it/s] 32%|###2      |55930/173481[15:00<31:25,62.35it/s] 33%|###2      |56540/173481[15:10<31:15,62.35it/s] 39%|###8      |67243/173481[18:00<28:17,62.59it/s] 39%|###9      |67912/173481[18:10<28:06,62.59it/s] 45%|####5     |78609/173481[21:00<25:09,62.86it/s] 46%|####5     |79283/173481[21:11<24:58,62.86it/s] 52%|#####1    |89898/173481[24:00<22:11,62.78it/s] 52%|#####2    |90583/173481[24:11<22:00,62.78it/s] 58%|#####8    |101272/173481[27:00<19:06,62.98it/s] 59%|#####8    |101912/173481[27:11<18:56,62.98it/s] 65%|######4   |112313/173481[30:00<16:24,62.14it/s] 65%|######5   |112974/173481[30:11<16:13,62.14it/s] 71%|#######1  |123213/173481[33:00<13:39,61.34it/s] 71%|#######1  |123872/173481[33:11<13:28,61.34it/s] 77%|#######7  |134298/173481[36:00<10:37,61.46it/s] 78%|#######7  |134977/173481[36:11<10:26,61.46it/s] 84%|########3 |145543/173481[39:00<07:30,61.95it/s] 84%|########4 |146272/173481[39:11<07:19,61.95it/s] 90%|######### |156915/173481[42:00<04:24,62.56it/s] 91%|######### |157665/173481[42:12<04:12,62.56it/s] 97%|#########6|167980/173481[45:00<01:28,62.01it/s] 97%|#########7|168652/173481[45:12<01:17,62.01it/s]100%|##########|173481/173481[46:36<00:00,62.04it/s]
[32m[0328 23:49:20 @base.py:257][0m Epoch 14 (global_step 12837594) finished, time:2796.29 sec.
[32m[0328 23:49:21 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-12837594.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,198.64it/s]
13
[32m[0328 23:50:55 @monitor.py:363][0m QueueInput/queue_size: 0.31361
[32m[0328 23:50:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.719
[32m[0328 23:50:55 @monitor.py:363][0m activation-summaries/output-rms: 0.016504
[32m[0328 23:50:55 @monitor.py:363][0m cross_entropy_loss: 7.2072
[32m[0328 23:50:55 @monitor.py:363][0m lr: 7.4506e-12
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0328 23:50:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0328 23:50:55 @monitor.py:363][0m train-error-top1: 0.99221
[32m[0328 23:50:55 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0328 23:50:55 @monitor.py:363][0m val-utt-error: 0.99129
[32m[0328 23:50:55 @monitor.py:363][0m validation_cost: 7.2363
[32m[0328 23:50:55 @monitor.py:363][0m wd_cost: 4.6053e-18
[32m[0328 23:50:55 @group.py:42][0m Callbacks took 95.186 sec in total. InferenceRunner: 94.766sec
[32m[0328 23:50:55 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11477/173481[03:00<42:21,63.75it/s]  7%|6         |12099/173481[03:10<42:11,63.75it/s] 13%|#2        |22512/173481[06:00<40:15,62.50it/s] 13%|#3        |23061/173481[06:10<40:06,62.50it/s] 20%|#9        |33907/173481[09:00<36:59,62.90it/s] 20%|#9        |34605/173481[09:10<36:48,62.90it/s] 26%|##6       |45129/173481[12:00<34:09,62.62it/s] 26%|##6       |45786/173481[12:10<33:59,62.62it/s] 32%|###2      |56247/173481[15:00<31:25,62.19it/s] 33%|###2      |56914/173481[15:10<31:14,62.19it/s] 39%|###8      |67537/173481[18:00<28:16,62.45it/s] 39%|###9      |68171/173481[18:10<28:06,62.45it/s] 45%|####5     |78411/173481[21:00<25:48,61.41it/s] 46%|####5     |79089/173481[21:11<25:37,61.41it/s] 52%|#####1    |89411/173481[24:00<22:52,61.26it/s] 52%|#####1    |90109/173481[24:11<22:40,61.26it/s] 58%|#####7    |100227/173481[27:00<20:07,60.66it/s] 58%|#####8    |100918/173481[27:11<19:56,60.66it/s] 64%|######3   |110927/173481[30:00<17:21,60.04it/s] 64%|######4   |111611/173481[30:11<17:10,60.04it/s] 70%|#######   |121547/173481[33:00<14:32,59.51it/s] 70%|#######   |122248/173481[33:11<14:20,59.51it/s] 76%|#######6  |132368/173481[36:00<11:27,59.81it/s] 77%|#######6  |133133/173481[36:11<11:14,59.81it/s] 83%|########2 |143334/173481[39:00<08:19,60.36it/s] 83%|########3 |144062/173481[39:12<08:07,60.36it/s] 89%|########8 |154302/173481[42:00<05:16,60.65it/s] 89%|########9 |155064/173481[42:12<05:03,60.65it/s] 95%|#########5|165262/173481[45:00<02:15,60.76it/s] 96%|#########5|165966/173481[45:12<02:03,60.76it/s]100%|##########|173481/173481[47:19<00:00,61.10it/s]
[32m[0329 00:38:15 @base.py:257][0m Epoch 15 (global_step 13011075) finished, time:2839.42 sec.
[32m[0329 00:38:15 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-13011075.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,194.82it/s]
14
[32m[0329 00:39:52 @monitor.py:363][0m QueueInput/queue_size: 0.1806
[32m[0329 00:39:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.66
[32m[0329 00:39:52 @monitor.py:363][0m activation-summaries/output-rms: 0.016171
[32m[0329 00:39:52 @monitor.py:363][0m cross_entropy_loss: 7.203
[32m[0329 00:39:52 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 00:39:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 00:39:52 @monitor.py:363][0m train-error-top1: 0.99311
[32m[0329 00:39:52 @monitor.py:363][0m val-error-top1: 0.99345
[32m[0329 00:39:52 @monitor.py:363][0m val-utt-error: 0.99049
[32m[0329 00:39:52 @monitor.py:363][0m validation_cost: 7.2623
[32m[0329 00:39:52 @monitor.py:363][0m wd_cost: 9.2106e-19
[32m[0329 00:39:52 @group.py:42][0m Callbacks took 97.164 sec in total. InferenceRunner: 96.624sec
[32m[0329 00:39:52 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11771/173481[03:00<41:12,65.39it/s]  7%|7         |12395/173481[03:10<41:03,65.39it/s] 13%|#3        |22575/173481[06:00<40:10,62.59it/s] 13%|#3        |23210/173481[06:10<40:00,62.59it/s] 19%|#9        |33291/173481[09:00<38:17,61.02it/s] 20%|#9        |33887/173481[09:10<38:07,61.02it/s] 25%|##5       |43668/173481[12:00<36:29,59.29it/s] 26%|##5       |44280/173481[12:10<36:19,59.29it/s] 31%|###1      |53901/173481[15:00<34:20,58.04it/s] 31%|###1      |54550/173481[15:10<34:09,58.04it/s] 37%|###7      |64586/173481[18:00<30:55,58.69it/s] 38%|###7      |65250/173481[18:10<30:44,58.69it/s] 43%|####3     |74881/173481[21:00<28:22,57.93it/s] 44%|####3     |75532/173481[21:11<28:10,57.93it/s] 49%|####9     |85503/173481[24:00<25:04,58.46it/s] 50%|####9     |86132/173481[24:11<24:54,58.46it/s] 55%|#####5    |96014/173481[27:00<22:05,58.43it/s] 56%|#####5    |96655/173481[27:11<21:54,58.43it/s] 61%|######1   |106448/173481[30:00<19:11,58.19it/s] 62%|######1   |107120/173481[30:11<19:00,58.19it/s] 68%|######7   |117190/173481[33:00<15:55,58.93it/s] 68%|######7   |117900/173481[33:11<15:43,58.93it/s] 74%|#######3  |128016/173481[36:00<12:43,59.53it/s] 74%|#######4  |128720/173481[36:11<12:31,59.53it/s] 80%|########  |138906/173481[39:00<09:36,60.01it/s] 80%|########  |139633/173481[39:12<09:24,60.01it/s] 86%|########6 |149676/173481[42:00<06:37,59.92it/s] 87%|########6 |150375/173481[42:12<06:25,59.92it/s] 92%|#########2|160021/173481[45:00<03:49,58.67it/s] 93%|#########2|160710/173481[45:12<03:37,58.67it/s] 98%|#########8|170301/173481[48:00<00:54,57.88it/s] 99%|#########8|171020/173481[48:12<00:42,57.88it/s]100%|##########|173481/173481[48:54<00:00,59.11it/s]
[32m[0329 01:28:47 @base.py:257][0m Epoch 16 (global_step 13184556) finished, time:2934.93 sec.
[32m[0329 01:28:47 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-13184556.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,197.33it/s]
15
[32m[0329 01:30:23 @monitor.py:363][0m QueueInput/queue_size: 0.32126
[32m[0329 01:30:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.74
[32m[0329 01:30:23 @monitor.py:363][0m activation-summaries/output-rms: 0.016703
[32m[0329 01:30:23 @monitor.py:363][0m cross_entropy_loss: 7.1743
[32m[0329 01:30:23 @monitor.py:363][0m lr: 7.4506e-12
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 01:30:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 01:30:23 @monitor.py:363][0m train-error-top1: 0.99348
[32m[0329 01:30:23 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0329 01:30:23 @monitor.py:363][0m val-utt-error: 0.99113
[32m[0329 01:30:23 @monitor.py:363][0m validation_cost: 7.2363
[32m[0329 01:30:23 @monitor.py:363][0m wd_cost: 9.2106e-19
[32m[0329 01:30:23 @group.py:42][0m Callbacks took 95.932 sec in total. InferenceRunner: 95.392sec
[32m[0329 01:30:23 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11341/173481[03:00<42:53,63.00it/s]  7%|6         |11913/173481[03:10<42:44,63.00it/s] 13%|#2        |21777/173481[06:00<41:52,60.39it/s] 13%|#2        |22403/173481[06:10<41:41,60.39it/s] 18%|#8        |32048/173481[09:00<40:10,58.68it/s] 19%|#8        |32626/173481[09:10<40:00,58.68it/s] 24%|##4       |41640/173481[12:00<39:20,55.85it/s] 24%|##4       |42199/173481[12:10<39:10,55.85it/s] 30%|##9       |51500/173481[15:00<36:45,55.30it/s] 30%|###       |52115/173481[15:10<36:34,55.30it/s] 36%|###5      |61900/173481[18:00<32:54,56.51it/s] 36%|###6      |62514/173481[18:10<32:43,56.51it/s] 42%|####1     |72275/173481[21:00<29:33,57.06it/s] 42%|####2     |72915/173481[21:11<29:22,57.06it/s] 48%|####7     |82845/173481[24:00<26:06,57.87it/s] 48%|####8     |83484/173481[24:11<25:55,57.87it/s] 54%|#####3    |93429/173481[27:00<22:52,58.33it/s] 54%|#####4    |94103/173481[27:11<22:40,58.33it/s] 60%|#####9    |103871/173481[30:00<19:56,58.17it/s] 60%|######    |104510/173481[30:11<19:45,58.17it/s] 66%|######5   |114371/173481[33:00<16:54,58.25it/s] 66%|######6   |115050/173481[33:11<16:43,58.25it/s] 72%|#######2  |124917/173481[36:00<13:51,58.42it/s] 72%|#######2  |125601/173481[36:11<13:39,58.42it/s] 78%|#######8  |135490/173481[39:00<10:48,58.57it/s] 79%|#######8  |136186/173481[39:12<10:36,58.57it/s] 84%|########4 |146083/173481[42:00<07:46,58.71it/s] 85%|########4 |146797/173481[42:12<07:34,58.71it/s] 91%|######### |157012/173481[45:00<04:35,59.69it/s] 91%|######### |157719/173481[45:12<04:24,59.69it/s] 97%|#########6|168080/173481[48:00<01:29,60.57it/s] 97%|#########7|168808/173481[48:12<01:17,60.57it/s]100%|##########|173481/173481[49:27<00:00,58.46it/s]
[32m[0329 02:19:50 @base.py:257][0m Epoch 17 (global_step 13358037) finished, time:2967.53 sec.
[32m[0329 02:19:51 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-13358037.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,197.87it/s]
16
[32m[0329 02:21:26 @monitor.py:363][0m QueueInput/queue_size: 0.69455
[32m[0329 02:21:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.732
[32m[0329 02:21:26 @monitor.py:363][0m activation-summaries/output-rms: 0.015972
[32m[0329 02:21:26 @monitor.py:363][0m cross_entropy_loss: 7.1566
[32m[0329 02:21:26 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 02:21:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 02:21:26 @monitor.py:363][0m train-error-top1: 0.99236
[32m[0329 02:21:26 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0329 02:21:26 @monitor.py:363][0m val-utt-error: 0.99118
[32m[0329 02:21:26 @monitor.py:363][0m validation_cost: 7.2364
[32m[0329 02:21:26 @monitor.py:363][0m wd_cost: 9.2106e-19
[32m[0329 02:21:26 @group.py:42][0m Callbacks took 95.581 sec in total. InferenceRunner: 95.137sec
[32m[0329 02:21:26 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13514/173481[03:00<35:31,75.06it/s]  8%|8         |14198/173481[03:10<35:22,75.06it/s] 14%|#4        |24734/173481[06:00<36:23,68.11it/s] 15%|#4        |25298/173481[06:10<36:15,68.11it/s] 20%|##        |35001/173481[09:00<37:10,62.08it/s] 21%|##        |35652/173481[09:10<37:00,62.08it/s] 27%|##6       |45979/173481[12:00<34:32,61.53it/s] 27%|##6       |46688/173481[12:10<34:20,61.53it/s] 33%|###2      |56763/173481[15:00<32:02,60.71it/s] 33%|###3      |57381/173481[15:10<31:52,60.71it/s] 39%|###9      |67779/173481[18:00<28:54,60.95it/s] 39%|###9      |68448/173481[18:11<28:43,60.95it/s] 46%|####5     |79785/173481[21:00<24:31,63.69it/s] 46%|####6     |80454/173481[21:11<24:20,63.69it/s] 52%|#####2    |90684/173481[24:00<22:13,62.08it/s] 53%|#####2    |91351/173481[24:11<22:03,62.08it/s] 58%|#####8    |101214/173481[27:00<19:59,60.23it/s] 59%|#####8    |101855/173481[27:11<19:49,60.23it/s] 65%|######4   |112009/173481[30:00<17:02,60.10it/s] 65%|######4   |112753/173481[30:11<16:50,60.10it/s] 71%|#######   |122994/173481[33:00<13:53,60.56it/s] 71%|#######1  |123673/173481[33:11<13:42,60.56it/s] 77%|#######7  |133917/173481[36:00<10:52,60.62it/s] 78%|#######7  |134641/173481[36:11<10:40,60.62it/s] 84%|########3 |145079/173481[39:00<07:43,61.30it/s] 84%|########4 |145784/173481[39:12<07:31,61.30it/s] 90%|######### |156139/173481[42:00<04:42,61.37it/s] 90%|######### |156913/173481[42:12<04:29,61.37it/s] 97%|#########6|167434/173481[45:00<01:37,62.05it/s] 97%|#########6|168198/173481[45:12<01:25,62.05it/s]100%|##########|173481/173481[46:38<00:00,61.98it/s]
[32m[0329 03:08:05 @base.py:257][0m Epoch 18 (global_step 13531518) finished, time:2798.96 sec.
[32m[0329 03:08:05 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-13531518.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.50it/s]
17
[32m[0329 03:09:43 @monitor.py:363][0m QueueInput/queue_size: 0.41858
[32m[0329 03:09:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.714
[32m[0329 03:09:43 @monitor.py:363][0m activation-summaries/output-rms: 0.016761
[32m[0329 03:09:43 @monitor.py:363][0m cross_entropy_loss: 7.1981
[32m[0329 03:09:43 @monitor.py:363][0m lr: 3.7253e-12
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 03:09:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 03:09:43 @monitor.py:363][0m train-error-top1: 0.99101
[32m[0329 03:09:43 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0329 03:09:43 @monitor.py:363][0m val-utt-error: 0.99091
[32m[0329 03:09:43 @monitor.py:363][0m validation_cost: 7.2465
[32m[0329 03:09:43 @monitor.py:363][0m wd_cost: 1.8421e-19
[32m[0329 03:09:43 @group.py:42][0m Callbacks took 98.002 sec in total. InferenceRunner: 97.286sec
[32m[0329 03:09:43 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12229/173481[03:00<39:33,67.94it/s]  7%|7         |12860/173481[03:10<39:24,67.94it/s] 13%|#3        |22798/173481[06:00<39:52,62.99it/s] 13%|#3        |23387/173481[06:10<39:42,62.99it/s] 19%|#9        |33485/173481[09:00<38:10,61.13it/s] 20%|#9        |34155/173481[09:10<37:59,61.13it/s] 26%|##5       |44728/173481[12:00<34:43,61.78it/s] 26%|##6       |45411/173481[12:10<34:32,61.78it/s] 32%|###2      |55831/173481[15:00<31:45,61.73it/s] 33%|###2      |56441/173481[15:10<31:35,61.73it/s] 39%|###8      |66822/173481[18:00<28:57,61.39it/s] 39%|###8      |67501/173481[18:10<28:46,61.39it/s] 45%|####4     |77828/173481[21:00<26:01,61.26it/s] 45%|####5     |78496/173481[21:11<25:50,61.26it/s] 51%|#####1    |88555/173481[24:00<23:25,60.42it/s] 51%|#####1    |89232/173481[24:11<23:14,60.42it/s] 57%|#####7    |99683/173481[27:00<20:07,61.11it/s] 58%|#####7    |100363/173481[27:11<19:56,61.11it/s] 64%|######3   |110505/173481[30:00<17:19,60.61it/s] 64%|######4   |111198/173481[30:11<17:07,60.61it/s] 70%|######9   |121323/173481[33:00<14:24,60.35it/s] 70%|#######   |121988/173481[33:11<14:13,60.35it/s] 76%|#######6  |131903/173481[36:00<11:38,59.55it/s] 76%|#######6  |132602/173481[36:11<11:26,59.55it/s] 82%|########2 |142794/173481[39:00<08:31,60.02it/s] 83%|########2 |143499/173481[39:11<08:19,60.02it/s] 89%|########8 |153831/173481[42:00<05:23,60.66it/s] 89%|########9 |154555/173481[42:12<05:11,60.66it/s] 95%|#########4|164773/173481[45:00<02:23,60.72it/s] 95%|#########5|165495/173481[45:12<02:11,60.72it/s]100%|##########|173481/173481[47:31<00:00,60.83it/s]
[32m[0329 03:57:15 @base.py:257][0m Epoch 19 (global_step 13704999) finished, time:2851.73 sec.
[32m[0329 03:57:15 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-13704999.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,197.48it/s]
18
[32m[0329 03:58:50 @monitor.py:363][0m QueueInput/queue_size: 0.18067
[32m[0329 03:58:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.719
[32m[0329 03:58:50 @monitor.py:363][0m activation-summaries/output-rms: 0.016504
[32m[0329 03:58:50 @monitor.py:363][0m cross_entropy_loss: 7.2072
[32m[0329 03:58:50 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 03:58:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 03:58:50 @monitor.py:363][0m train-error-top1: 0.99221
[32m[0329 03:58:50 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0329 03:58:50 @monitor.py:363][0m val-utt-error: 0.99129
[32m[0329 03:58:50 @monitor.py:363][0m validation_cost: 7.2363
[32m[0329 03:58:50 @monitor.py:363][0m wd_cost: 1.8421e-19
[32m[0329 03:58:50 @group.py:42][0m Callbacks took 95.719 sec in total. InferenceRunner: 95.321sec
[32m[0329 03:58:50 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11369/173481[03:00<42:46,63.16it/s]  7%|6         |11971/173481[03:10<42:37,63.16it/s] 13%|#2        |22149/173481[06:00<41:01,61.48it/s] 13%|#3        |22681/173481[06:10<40:52,61.48it/s] 19%|#9        |33278/173481[09:00<37:54,61.65it/s] 20%|#9        |33958/173481[09:10<37:43,61.65it/s] 26%|##5       |44547/173481[12:00<34:35,62.12it/s] 26%|##6       |45202/173481[12:10<34:25,62.12it/s] 32%|###2      |55694/173481[15:00<31:39,62.02it/s] 32%|###2      |56352/173481[15:10<31:28,62.02it/s] 39%|###8      |66797/173481[18:00<28:44,61.85it/s] 39%|###8      |67453/173481[18:11<28:34,61.85it/s] 45%|####4     |77772/173481[21:00<25:58,61.40it/s] 45%|####5     |78424/173481[21:11<25:48,61.40it/s] 51%|#####1    |88804/173481[24:00<23:00,61.35it/s] 52%|#####1    |89486/173481[24:11<22:49,61.35it/s] 57%|#####7    |99692/173481[27:00<20:11,60.91it/s] 58%|#####7    |100426/173481[27:11<19:59,60.91it/s] 64%|######3   |110752/173481[30:00<17:05,61.17it/s] 64%|######4   |111438/173481[30:11<16:54,61.17it/s] 70%|#######   |121551/173481[33:00<14:17,60.57it/s] 70%|#######   |122241/173481[33:11<14:05,60.57it/s] 76%|#######6  |132432/173481[36:00<11:18,60.51it/s] 77%|#######6  |133123/173481[36:12<11:07,60.51it/s] 82%|########2 |143037/173481[39:00<08:30,59.69it/s] 83%|########2 |143761/173481[39:12<08:17,59.69it/s] 89%|########8 |154137/173481[42:00<05:18,60.66it/s] 89%|########9 |154911/173481[42:12<05:06,60.66it/s] 96%|#########5|165947/173481[45:00<01:59,63.03it/s] 96%|#########6|166787/173481[45:12<01:46,63.03it/s]100%|##########|173481/173481[46:44<00:00,61.85it/s]
[32m[0329 04:45:35 @base.py:257][0m Epoch 20 (global_step 13878480) finished, time:2804.89 sec.
[32m[0329 04:45:36 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-13878480.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.60it/s]
19
[32m[0329 04:47:13 @monitor.py:363][0m QueueInput/queue_size: 0.53022
[32m[0329 04:47:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.66
[32m[0329 04:47:13 @monitor.py:363][0m activation-summaries/output-rms: 0.016171
[32m[0329 04:47:13 @monitor.py:363][0m cross_entropy_loss: 7.203
[32m[0329 04:47:13 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 04:47:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 04:47:13 @monitor.py:363][0m train-error-top1: 0.99311
[32m[0329 04:47:13 @monitor.py:363][0m val-error-top1: 0.99345
[32m[0329 04:47:13 @monitor.py:363][0m val-utt-error: 0.99049
[32m[0329 04:47:13 @monitor.py:363][0m validation_cost: 7.2623
[32m[0329 04:47:13 @monitor.py:363][0m wd_cost: 1.8421e-19
[32m[0329 04:47:13 @group.py:42][0m Callbacks took 97.672 sec in total. InferenceRunner: 97.233sec
[32m[0329 04:47:13 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15925/173481[03:00<29:40,88.47it/s] 10%|9         |16756/173481[03:10<29:31,88.47it/s] 16%|#5        |27349/173481[06:00<32:57,73.91it/s] 16%|#6        |27990/173481[06:10<32:48,73.91it/s] 22%|##1       |37806/173481[09:00<34:45,65.05it/s] 22%|##2       |38396/173481[09:10<34:36,65.05it/s] 28%|##7       |48386/173481[12:00<33:45,61.75it/s] 28%|##8       |49006/173481[12:10<33:35,61.75it/s] 34%|###4      |59122/173481[15:00<31:24,60.67it/s] 34%|###4      |59763/173481[15:10<31:14,60.67it/s] 40%|####      |69711/173481[18:00<28:57,59.74it/s] 41%|####      |70317/173481[18:10<28:46,59.74it/s] 46%|####6     |80035/173481[21:00<26:36,58.52it/s] 47%|####6     |80692/173481[21:11<26:25,58.52it/s] 52%|#####2    |90608/173481[24:00<23:33,58.63it/s] 53%|#####2    |91284/173481[24:11<23:21,58.63it/s] 58%|#####8    |101083/173481[27:00<20:39,58.41it/s] 59%|#####8    |101735/173481[27:11<20:28,58.41it/s] 64%|######4   |111611/173481[30:00<17:38,58.45it/s] 65%|######4   |112295/173481[30:11<17:26,58.45it/s] 70%|#######   |122263/173481[33:00<14:30,58.80it/s] 71%|#######   |122961/173481[33:11<14:19,58.80it/s] 77%|#######6  |133165/173481[36:00<11:15,59.67it/s] 77%|#######7  |133883/173481[36:11<11:03,59.67it/s] 84%|########3 |145668/173481[39:00<07:13,64.19it/s] 85%|########4 |146646/173481[39:12<06:58,64.19it/s] 93%|#########3|161407/173481[42:00<02:43,74.03it/s] 94%|#########3|162460/173481[42:12<02:28,74.03it/s]100%|##########|173481/173481[44:15<00:00,65.33it/s]
[32m[0329 05:31:28 @base.py:257][0m Epoch 21 (global_step 14051961) finished, time:2655.40 sec.
[32m[0329 05:31:29 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-14051961.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:56<00:00,161.31it/s]
20
[32m[0329 05:33:25 @monitor.py:363][0m QueueInput/queue_size: 16.766
[32m[0329 05:33:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.679
[32m[0329 05:33:25 @monitor.py:363][0m activation-summaries/output-rms: 0.016908
[32m[0329 05:33:25 @monitor.py:363][0m cross_entropy_loss: 7.2127
[32m[0329 05:33:25 @monitor.py:363][0m lr: 1.8626e-12
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 05:33:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 05:33:25 @monitor.py:363][0m train-error-top1: 0.99365
[32m[0329 05:33:25 @monitor.py:363][0m val-error-top1: 0.99346
[32m[0329 05:33:25 @monitor.py:363][0m val-utt-error: 0.99107
[32m[0329 05:33:25 @monitor.py:363][0m validation_cost: 7.239
[32m[0329 05:33:25 @monitor.py:363][0m wd_cost: 3.6842e-20
[32m[0329 05:33:25 @group.py:42][0m Callbacks took 117.084 sec in total. InferenceRunner: 116.694sec
[32m[0329 05:33:25 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13993/173481[03:00<34:11,77.74it/s]  8%|8         |14611/173481[03:10<34:03,77.74it/s] 14%|#4        |24834/173481[06:00<36:30,67.87it/s] 15%|#4        |25419/173481[06:10<36:21,67.87it/s] 20%|##        |34945/173481[09:00<37:33,61.47it/s] 20%|##        |35503/173481[09:10<37:24,61.47it/s] 26%|##5       |44682/173481[12:00<37:18,57.55it/s] 26%|##6       |45254/173481[12:10<37:08,57.55it/s] 32%|###1      |54783/173481[15:00<34:48,56.82it/s] 32%|###1      |55396/173481[15:10<34:38,56.82it/s] 38%|###7      |65196/173481[18:00<31:28,57.33it/s] 38%|###7      |65829/173481[18:10<31:17,57.33it/s] 44%|####3     |75892/173481[21:00<27:52,58.36it/s] 44%|####4     |76550/173481[21:11<27:41,58.36it/s] 50%|####9     |86487/173481[24:00<24:44,58.61it/s] 50%|#####     |87149/173481[24:11<24:33,58.61it/s] 56%|#####6    |97175/173481[27:00<21:33,58.99it/s] 56%|#####6    |97809/173481[27:11<21:22,58.99it/s] 62%|######2   |107746/173481[30:00<18:36,58.86it/s] 63%|######2   |108436/173481[30:11<18:25,58.86it/s] 68%|######8   |118160/173481[33:00<15:48,58.34it/s] 68%|######8   |118810/173481[33:11<15:37,58.34it/s] 74%|#######4  |128503/173481[36:00<12:56,57.90it/s] 74%|#######4  |129158/173481[36:11<12:45,57.90it/s] 80%|########  |138999/173481[39:00<09:53,58.10it/s] 81%|########  |139707/173481[39:11<09:41,58.10it/s] 86%|########6 |149687/173481[42:00<06:45,58.72it/s] 87%|########6 |150409/173481[42:12<06:32,58.72it/s] 92%|#########2|160361/173481[45:00<03:42,59.01it/s] 93%|#########2|161073/173481[45:12<03:30,59.01it/s] 99%|#########8|170993/173481[48:00<00:42,59.03it/s] 99%|#########8|171718/173481[48:12<00:29,59.03it/s]100%|##########|173481/173481[48:40<00:00,59.40it/s]
[32m[0329 06:22:06 @base.py:257][0m Epoch 22 (global_step 14225442) finished, time:2920.72 sec.
[32m[0329 06:22:06 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-14225442.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:34<00:00,199.49it/s]
21
[32m[0329 06:23:41 @monitor.py:363][0m QueueInput/queue_size: 0.81472
[32m[0329 06:23:41 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.732
[32m[0329 06:23:41 @monitor.py:363][0m activation-summaries/output-rms: 0.015972
[32m[0329 06:23:41 @monitor.py:363][0m cross_entropy_loss: 7.1565
[32m[0329 06:23:41 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 06:23:41 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 06:23:41 @monitor.py:363][0m train-error-top1: 0.99238
[32m[0329 06:23:41 @monitor.py:363][0m val-error-top1: 0.99343
[32m[0329 06:23:41 @monitor.py:363][0m val-utt-error: 0.99118
[32m[0329 06:23:41 @monitor.py:363][0m validation_cost: 7.2368
[32m[0329 06:23:41 @monitor.py:363][0m wd_cost: 3.6842e-20
[32m[0329 06:23:41 @group.py:42][0m Callbacks took 94.728 sec in total. InferenceRunner: 94.360sec
[32m[0329 06:23:41 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13339/173481[03:00<36:01,74.10it/s]  8%|8         |14018/173481[03:10<35:52,74.10it/s] 14%|#4        |24511/173481[06:00<36:45,67.55it/s] 14%|#4        |25068/173481[06:10<36:37,67.55it/s] 20%|##        |34857/173481[09:00<37:12,62.10it/s] 20%|##        |35532/173481[09:10<37:01,62.10it/s] 26%|##6       |45925/173481[12:00<34:24,61.79it/s] 27%|##6       |46638/173481[12:10<34:12,61.79it/s] 33%|###2      |57018/173481[15:00<31:27,61.71it/s] 33%|###3      |57661/173481[15:10<31:16,61.71it/s] 39%|###9      |68067/173481[18:00<28:32,61.54it/s] 40%|###9      |68731/173481[18:10<28:22,61.54it/s] 46%|####6     |80058/173481[21:00<24:20,63.98it/s] 47%|####6     |80726/173481[21:11<24:09,63.98it/s] 52%|#####2    |90915/173481[24:00<22:09,62.09it/s] 53%|#####2    |91603/173481[24:11<21:58,62.09it/s] 59%|#####8    |101524/173481[27:00<19:49,60.47it/s] 59%|#####8    |102164/173481[27:11<19:39,60.47it/s] 65%|######4   |112464/173481[30:00<16:46,60.62it/s] 65%|######5   |113183/173481[30:11<16:34,60.62it/s] 71%|#######1  |123543/173481[33:00<13:37,61.08it/s] 72%|#######1  |124250/173481[33:11<13:25,61.08it/s] 78%|#######7  |134606/173481[36:00<10:34,61.27it/s] 78%|#######8  |135333/173481[36:11<10:22,61.27it/s] 84%|########4 |145863/173481[39:00<07:26,61.90it/s] 85%|########4 |146610/173481[39:11<07:14,61.90it/s] 91%|######### |157022/173481[42:00<04:25,61.94it/s] 91%|######### |157747/173481[42:12<04:14,61.94it/s] 97%|#########6|168115/173481[45:00<01:26,61.78it/s] 97%|#########7|168892/173481[45:12<01:14,61.78it/s]100%|##########|173481/173481[46:27<00:00,62.23it/s]
[32m[0329 07:10:08 @base.py:257][0m Epoch 23 (global_step 14398923) finished, time:2787.53 sec.
[32m[0329 07:10:09 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-14398923.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,179.38it/s]
22
[32m[0329 07:11:54 @monitor.py:363][0m QueueInput/queue_size: 0.24673
[32m[0329 07:11:54 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.714
[32m[0329 07:11:54 @monitor.py:363][0m activation-summaries/output-rms: 0.016761
[32m[0329 07:11:54 @monitor.py:363][0m cross_entropy_loss: 7.1981
[32m[0329 07:11:54 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 07:11:54 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 07:11:54 @monitor.py:363][0m train-error-top1: 0.99101
[32m[0329 07:11:54 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0329 07:11:54 @monitor.py:363][0m val-utt-error: 0.99091
[32m[0329 07:11:54 @monitor.py:363][0m validation_cost: 7.2465
[32m[0329 07:11:54 @monitor.py:363][0m wd_cost: 3.6842e-20
[32m[0329 07:11:54 @group.py:42][0m Callbacks took 105.377 sec in total. InferenceRunner: 104.940sec
[32m[0329 07:11:54 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12443/173481[03:00<38:50,69.11it/s]  8%|7         |13062/173481[03:10<38:41,69.11it/s] 13%|#3        |22863/173481[06:00<39:50,63.00it/s] 14%|#3        |23470/173481[06:10<39:40,63.00it/s] 19%|#9        |33538/173481[09:00<38:10,61.10it/s] 20%|#9        |34192/173481[09:10<37:59,61.10it/s] 26%|##5       |44668/173481[12:00<34:55,61.46it/s] 26%|##6       |45346/173481[12:10<34:44,61.46it/s] 32%|###2      |55741/173481[15:00<31:54,61.49it/s] 32%|###2      |56338/173481[15:10<31:45,61.49it/s] 38%|###8      |66494/173481[18:00<29:25,60.60it/s] 39%|###8      |67149/173481[18:10<29:14,60.60it/s] 45%|####4     |77384/173481[21:00<26:27,60.55it/s] 45%|####4     |78039/173481[21:11<26:16,60.55it/s] 51%|#####     |88268/173481[24:00<23:28,60.50it/s] 51%|#####1    |88930/173481[24:11<23:17,60.50it/s] 57%|#####7    |99253/173481[27:00<20:21,60.76it/s] 58%|#####7    |99919/173481[27:11<20:10,60.76it/s] 64%|######3   |110175/173481[30:00<17:22,60.72it/s] 64%|######3   |110847/173481[30:11<17:11,60.72it/s] 70%|######9   |121173/173481[33:00<14:18,60.90it/s] 70%|#######   |121880/173481[33:11<14:07,60.90it/s] 76%|#######6  |131981/173481[36:00<11:26,60.47it/s] 76%|#######6  |132698/173481[36:11<11:14,60.47it/s] 82%|########2 |142925/173481[39:00<08:23,60.63it/s] 83%|########2 |143649/173481[39:12<08:12,60.63it/s] 89%|########8 |154053/173481[42:00<05:17,61.21it/s] 89%|########9 |154788/173481[42:12<05:05,61.21it/s] 95%|#########5|165291/173481[45:00<02:12,61.81it/s] 96%|#########5|166024/173481[45:12<02:00,61.81it/s]100%|##########|173481/173481[47:18<00:00,61.11it/s]
[32m[0329 07:59:12 @base.py:257][0m Epoch 24 (global_step 14572404) finished, time:2838.60 sec.
[32m[0329 07:59:13 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-14572404.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:35<00:00,196.35it/s]
23
[32m[0329 08:00:49 @monitor.py:363][0m QueueInput/queue_size: 0.3185
[32m[0329 08:00:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.719
[32m[0329 08:00:49 @monitor.py:363][0m activation-summaries/output-rms: 0.016504
[32m[0329 08:00:49 @monitor.py:363][0m cross_entropy_loss: 7.2072
[32m[0329 08:00:49 @monitor.py:363][0m lr: 9.3132e-13
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 08:00:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 08:00:49 @monitor.py:363][0m train-error-top1: 0.99221
[32m[0329 08:00:49 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0329 08:00:49 @monitor.py:363][0m val-utt-error: 0.99107
[32m[0329 08:00:49 @monitor.py:363][0m validation_cost: 7.2363
[32m[0329 08:00:49 @monitor.py:363][0m wd_cost: 7.3684e-21
[32m[0329 08:00:49 @group.py:42][0m Callbacks took 96.293 sec in total. InferenceRunner: 95.870sec
[32m[0329 08:00:49 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11437/173481[03:00<42:30,63.54it/s]  7%|6         |12065/173481[03:10<42:20,63.54it/s] 13%|#2        |22214/173481[06:00<40:53,61.65it/s] 13%|#3        |22736/173481[06:10<40:45,61.65it/s] 19%|#9        |33145/173481[09:00<38:13,61.18it/s] 19%|#9        |33796/173481[09:10<38:03,61.18it/s] 25%|##5       |44202/173481[12:00<35:08,61.30it/s] 26%|##5       |44836/173481[12:10<34:58,61.30it/s] 32%|###1      |55372/173481[15:00<31:55,61.67it/s] 32%|###2      |56021/173481[15:10<31:44,61.67it/s] 38%|###8      |66409/173481[18:00<29:01,61.49it/s] 39%|###8      |67087/173481[18:10<28:50,61.49it/s] 44%|####4     |77153/173481[21:00<26:30,60.58it/s] 45%|####4     |77824/173481[21:11<26:19,60.58it/s] 51%|#####1    |89074/173481[24:00<22:13,63.28it/s] 52%|#####1    |90089/173481[24:11<21:57,63.28it/s] 59%|#####9    |102487/173481[27:00<17:17,68.44it/s] 59%|#####9    |103190/173481[27:11<17:07,68.44it/s] 65%|######5   |113225/173481[30:00<15:45,63.75it/s] 66%|######5   |113939/173481[30:11<15:34,63.75it/s] 71%|#######1  |123875/173481[33:00<13:28,61.37it/s] 72%|#######1  |124566/173481[33:11<13:17,61.37it/s] 78%|#######8  |135382/173481[36:00<10:08,62.62it/s] 79%|#######8  |136248/173481[36:11<09:54,62.62it/s] 87%|########6 |150637/173481[39:00<05:17,72.02it/s] 87%|########7 |151692/173481[39:11<05:02,72.02it/s] 96%|#########6|166882/173481[42:00<01:22,80.11it/s] 97%|#########6|167965/173481[42:12<01:08,80.11it/s]100%|##########|173481/173481[43:38<00:00,66.26it/s]
[32m[0329 08:44:27 @base.py:257][0m Epoch 25 (global_step 14745885) finished, time:2618.01 sec.
[32m[0329 08:44:27 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-14745885.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:36<00:00,194.56it/s]
24
[32m[0329 08:46:04 @monitor.py:363][0m QueueInput/queue_size: 0.32095
[32m[0329 08:46:04 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.66
[32m[0329 08:46:04 @monitor.py:363][0m activation-summaries/output-rms: 0.016171
[32m[0329 08:46:04 @monitor.py:363][0m cross_entropy_loss: 7.203
[32m[0329 08:46:04 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 08:46:04 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 08:46:04 @monitor.py:363][0m train-error-top1: 0.99311
[32m[0329 08:46:04 @monitor.py:363][0m val-error-top1: 0.99345
[32m[0329 08:46:04 @monitor.py:363][0m val-utt-error: 0.99049
[32m[0329 08:46:04 @monitor.py:363][0m validation_cost: 7.2623
[32m[0329 08:46:04 @monitor.py:363][0m wd_cost: 7.3684e-21
[32m[0329 08:46:04 @group.py:42][0m Callbacks took 97.176 sec in total. InferenceRunner: 96.756sec
[32m[0329 08:46:04 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12214/173481[03:00<39:36,67.85it/s]  7%|7         |12859/173481[03:10<39:27,67.85it/s] 13%|#3        |23246/173481[06:00<38:52,64.40it/s] 14%|#3        |23877/173481[06:10<38:43,64.40it/s] 20%|#9        |33925/173481[09:00<37:39,61.76it/s] 20%|#9        |34539/173481[09:10<37:29,61.76it/s] 26%|##5       |44572/173481[12:00<35:33,60.43it/s] 26%|##6       |45218/173481[12:10<35:22,60.43it/s] 32%|###1      |55043/173481[15:00<33:18,59.27it/s] 32%|###2      |55670/173481[15:10<33:07,59.27it/s] 38%|###8      |65980/173481[18:00<29:51,60.01it/s] 38%|###8      |66657/173481[18:10<29:40,60.01it/s] 44%|####4     |76418/173481[21:00<27:25,58.98it/s] 44%|####4     |77030/173481[21:11<27:15,58.98it/s] 50%|#####     |86877/173481[24:00<24:39,58.54it/s] 50%|#####     |87543/173481[24:11<24:28,58.54it/s] 56%|#####6    |97350/173481[27:00<21:44,58.36it/s] 56%|#####6    |98001/173481[27:11<21:33,58.36it/s] 62%|######2   |107666/173481[30:00<18:58,57.83it/s] 62%|######2   |108310/173481[30:11<18:47,57.83it/s] 68%|######8   |118236/173481[33:00<15:48,58.27it/s] 69%|######8   |118891/173481[33:11<15:36,58.27it/s] 74%|#######4  |128873/173481[36:00<12:40,58.68it/s] 75%|#######4  |129556/173481[36:11<12:28,58.68it/s] 80%|########  |139567/173481[39:00<09:34,59.04it/s] 81%|########  |140247/173481[39:12<09:22,59.04it/s] 86%|########6 |149978/173481[42:00<06:42,58.43it/s] 87%|########6 |150665/173481[42:12<06:30,58.43it/s] 92%|#########2|160349/173481[45:00<03:46,58.02it/s] 93%|#########2|161022/173481[45:12<03:34,58.02it/s] 98%|#########8|170564/173481[48:00<00:50,57.38it/s] 99%|#########8|171290/173481[48:12<00:38,57.38it/s]100%|##########|173481/173481[48:51<00:00,59.18it/s]
[32m[0329 09:34:55 @base.py:257][0m Epoch 26 (global_step 14919366) finished, time:2931.28 sec.
[32m[0329 09:34:56 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-14919366.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:31<00:00,205.11it/s]
25
[32m[0329 09:36:27 @monitor.py:363][0m QueueInput/queue_size: 0.22228
[32m[0329 09:36:27 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.74
[32m[0329 09:36:27 @monitor.py:363][0m activation-summaries/output-rms: 0.016703
[32m[0329 09:36:27 @monitor.py:363][0m cross_entropy_loss: 7.1743
[32m[0329 09:36:27 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 09:36:27 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 09:36:27 @monitor.py:363][0m train-error-top1: 0.99348
[32m[0329 09:36:27 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0329 09:36:27 @monitor.py:363][0m val-utt-error: 0.99113
[32m[0329 09:36:27 @monitor.py:363][0m validation_cost: 7.2363
[32m[0329 09:36:27 @monitor.py:363][0m wd_cost: 1.4737e-21
[32m[0329 09:36:27 @group.py:42][0m Callbacks took 92.270 sec in total. InferenceRunner: 91.775sec
[32m[0329 09:36:27 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |11196/173481[03:00<43:29,62.20it/s]  7%|6         |11824/173481[03:10<43:19,62.20it/s] 13%|#3        |22689/173481[06:00<39:53,63.01it/s] 13%|#3        |23326/173481[06:10<39:42,63.01it/s] 19%|#9        |33130/173481[09:00<38:44,60.39it/s] 19%|#9        |33705/173481[09:10<38:34,60.39it/s] 26%|##6       |45886/173481[12:00<32:36,65.21it/s] 27%|##6       |46836/173481[12:10<32:22,65.21it/s] 35%|###4      |59930/173481[15:00<26:38,71.04it/s] 35%|###4      |60562/173481[15:10<26:29,71.04it/s] 41%|####      |70593/173481[18:00<26:32,64.60it/s] 41%|####1     |71287/173481[18:10<26:21,64.60it/s] 47%|####7     |81575/173481[21:00<24:24,62.75it/s] 47%|####7     |82224/173481[21:11<24:14,62.75it/s] 53%|#####3    |92241/173481[24:00<22:12,60.95it/s] 54%|#####3    |92884/173481[24:11<22:02,60.95it/s] 59%|#####9    |102745/173481[27:00<19:46,59.62it/s] 60%|#####9    |103429/173481[27:11<19:34,59.62it/s] 65%|######5   |113355/173481[30:00<16:54,59.28it/s] 66%|######5   |114032/173481[30:11<16:42,59.28it/s] 71%|#######1  |124027/173481[33:00<13:54,59.28it/s] 72%|#######1  |124782/173481[33:11<13:41,59.28it/s] 79%|#######9  |137621/173481[36:00<08:59,66.42it/s] 80%|#######9  |138573/173481[36:11<08:45,66.42it/s] 88%|########7 |151947/173481[39:00<04:57,72.41it/s] 88%|########8 |152906/173481[39:12<04:44,72.41it/s] 96%|#########5|166451/173481[42:00<01:32,76.27it/s] 97%|#########6|167427/173481[42:12<01:19,76.27it/s]100%|##########|173481/173481[43:26<00:00,66.57it/s]
[32m[0329 10:19:54 @base.py:257][0m Epoch 27 (global_step 15092847) finished, time:2606.18 sec.
[32m[0329 10:19:54 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-15092847.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.70it/s]
26
[32m[0329 10:21:38 @monitor.py:363][0m QueueInput/queue_size: 0.4764
[32m[0329 10:21:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.732
[32m[0329 10:21:38 @monitor.py:363][0m activation-summaries/output-rms: 0.015972
[32m[0329 10:21:38 @monitor.py:363][0m cross_entropy_loss: 7.1542
[32m[0329 10:21:38 @monitor.py:363][0m lr: 4.6566e-13
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 10:21:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 10:21:38 @monitor.py:363][0m train-error-top1: 0.99242
[32m[0329 10:21:38 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0329 10:21:38 @monitor.py:363][0m val-utt-error: 0.99134
[32m[0329 10:21:38 @monitor.py:363][0m validation_cost: 7.236
[32m[0329 10:21:38 @monitor.py:363][0m wd_cost: 1.4737e-21
[32m[0329 10:21:38 @group.py:42][0m Callbacks took 104.704 sec in total. InferenceRunner: 104.192sec
[32m[0329 10:21:38 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15343/173481[03:00<30:55,85.24it/s]  9%|9         |16183/173481[03:10<30:45,85.24it/s] 17%|#6        |29346/173481[06:00<29:31,81.35it/s] 17%|#7        |29997/173481[06:10<29:23,81.35it/s] 23%|##3       |40219/173481[09:00<32:06,69.19it/s] 24%|##4       |41653/173481[09:20<31:45,69.19it/s] 30%|##9       |51641/173481[12:00<30:40,66.20it/s] 30%|###       |52777/173481[12:20<30:23,66.20it/s] 36%|###5      |62444/173481[15:00<29:23,62.96it/s] 36%|###6      |63028/173481[15:10<29:14,62.96it/s] 43%|####2     |74169/173481[18:00<25:51,64.03it/s] 43%|####3     |74813/173481[18:10<25:41,64.03it/s] 49%|####9     |85676/173481[21:00<22:52,63.98it/s] 50%|####9     |86332/173481[21:11<22:42,63.98it/s] 56%|#####5    |96580/173481[24:00<20:35,62.23it/s] 56%|#####6    |97175/173481[24:11<20:26,62.23it/s] 62%|######1   |107429/173481[27:00<17:58,61.22it/s] 62%|######2   |108102/173481[27:11<17:47,61.22it/s] 68%|######8   |118473/173481[30:00<14:57,61.29it/s] 69%|######8   |119105/173481[30:11<14:47,61.29it/s] 75%|#######4  |129627/173481[33:00<11:51,61.62it/s] 75%|#######5  |130303/173481[33:11<11:40,61.62it/s] 81%|########1 |140630/173481[36:00<08:55,61.37it/s] 81%|########1 |141313/173481[36:11<08:44,61.37it/s] 87%|########7 |151431/173481[39:00<06:03,60.68it/s] 88%|########7 |152105/173481[39:12<05:52,60.68it/s] 94%|#########3|162414/173481[42:00<03:01,60.85it/s] 94%|#########4|163108/173481[42:12<02:50,60.85it/s]100%|##########|173481/173481[45:00<00:00,64.24it/s]
[32m[0329 11:06:39 @base.py:257][0m Epoch 28 (global_step 15266328) finished, time:2700.64 sec.
[32m[0329 11:06:39 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-15266328.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:43<00:00,181.42it/s]
27
[32m[0329 11:08:23 @monitor.py:363][0m QueueInput/queue_size: 0.14113
[32m[0329 11:08:23 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.714
[32m[0329 11:08:23 @monitor.py:363][0m activation-summaries/output-rms: 0.016761
[32m[0329 11:08:23 @monitor.py:363][0m cross_entropy_loss: 7.1979
[32m[0329 11:08:23 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 11:08:23 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 11:08:23 @monitor.py:363][0m train-error-top1: 0.99098
[32m[0329 11:08:23 @monitor.py:363][0m val-error-top1: 0.99342
[32m[0329 11:08:23 @monitor.py:363][0m val-utt-error: 0.99081
[32m[0329 11:08:23 @monitor.py:363][0m validation_cost: 7.2465
[32m[0329 11:08:23 @monitor.py:363][0m wd_cost: 1.4737e-21
[32m[0329 11:08:23 @group.py:42][0m Callbacks took 104.100 sec in total. InferenceRunner: 103.758sec
[32m[0329 11:08:23 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12833/173481[03:00<37:33,71.29it/s]  8%|7         |13442/173481[03:10<37:24,71.29it/s] 13%|#3        |23263/173481[06:00<39:09,63.93it/s] 14%|#3        |23855/173481[06:10<39:00,63.93it/s] 20%|#9        |33986/173481[09:00<37:41,61.67it/s] 20%|#9        |34647/173481[09:10<37:31,61.67it/s] 26%|##5       |44874/173481[12:00<35:05,61.08it/s] 26%|##6       |45527/173481[12:10<34:55,61.08it/s] 32%|###2      |55624/173481[15:00<32:31,60.39it/s] 32%|###2      |56217/173481[15:10<32:21,60.39it/s] 38%|###8      |66387/173481[18:00<29:42,60.09it/s] 39%|###8      |67037/173481[18:10<29:31,60.09it/s] 44%|####4     |77163/173481[21:00<26:45,59.97it/s] 45%|####4     |77791/173481[21:11<26:35,59.97it/s] 51%|#####     |87793/173481[24:00<23:59,59.51it/s] 51%|#####     |88457/173481[24:11<23:48,59.51it/s] 57%|#####6    |98703/173481[27:00<20:45,60.05it/s] 57%|#####7    |99402/173481[27:11<20:33,60.05it/s] 63%|######3   |109568/173481[30:00<17:41,60.20it/s] 64%|######3   |110277/173481[30:11<17:29,60.20it/s] 69%|######9   |120354/173481[33:00<14:44,60.06it/s] 70%|######9   |121061/173481[33:11<14:32,60.06it/s] 76%|#######5  |131200/173481[36:00<11:42,60.16it/s] 76%|#######6  |131910/173481[36:11<11:31,60.16it/s] 82%|########1 |142182/173481[39:00<08:36,60.58it/s] 82%|########2 |142876/173481[39:11<08:25,60.58it/s] 88%|########8 |153240/173481[42:00<05:31,61.00it/s] 89%|########8 |153987/173481[42:12<05:19,61.00it/s] 95%|#########4|164319/173481[45:00<02:29,61.27it/s] 95%|#########5|165091/173481[45:12<02:16,61.27it/s]100%|##########|173481/173481[47:36<00:00,60.73it/s]
[32m[0329 11:56:00 @base.py:257][0m Epoch 29 (global_step 15439809) finished, time:2856.59 sec.
[32m[0329 11:56:00 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_16_quant_ends_True_preload/model-15439809.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:44<00:00,180.73it/s]
28
[32m[0329 11:57:44 @monitor.py:363][0m QueueInput/queue_size: 0.40311
[32m[0329 11:57:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 27.719
[32m[0329 11:57:44 @monitor.py:363][0m activation-summaries/output-rms: 0.016504
[32m[0329 11:57:44 @monitor.py:363][0m cross_entropy_loss: 7.207
[32m[0329 11:57:44 @monitor.py:363][0m lr: 2.3283e-13
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0329 11:57:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0329 11:57:44 @monitor.py:363][0m train-error-top1: 0.99221
[32m[0329 11:57:44 @monitor.py:363][0m val-error-top1: 0.99344
[32m[0329 11:57:44 @monitor.py:363][0m val-utt-error: 0.99123
[32m[0329 11:57:44 @monitor.py:363][0m validation_cost: 7.2363
[32m[0329 11:57:44 @monitor.py:363][0m wd_cost: 2.9474e-22
[32m[0329 11:57:44 @group.py:42][0m Callbacks took 104.720 sec in total. InferenceRunner: 104.183sec
[32m[0329 11:57:44 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12026/173481[03:00<40:16,66.80it/s]  7%|7         |12667/173481[03:10<40:07,66.80it/s] 13%|#3        |22687/173481[06:00<40:01,62.78it/s] 13%|#3        |23216/173481[06:10<39:53,62.78it/s] 19%|#9        |33615/173481[09:00<37:45,61.73it/s] 20%|#9        |34256/173481[09:10<37:35,61.73it/s] 26%|##5       |44532/173481[12:00<35:07,61.18it/s] 26%|##6       |45165/173481[12:10<34:57,61.18it/s] 32%|###2      |55517/173481[15:00<32:10,61.10it/s] 32%|###2      |56165/173481[15:10<32:00,61.10it/s] 38%|###8      |66492/173481[18:00<29:12,61.04it/s] 39%|###8      |67158/173481[18:10<29:01,61.04it/s] 45%|####4     |77337/173481[21:00<26:25,60.64it/s] 45%|####4     |78021/173481[21:11<26:14,60.64it/s] 51%|#####     |88414/173481[24:00<23:12,61.08it/s] 51%|#####1    |89096/173481[24:11<23:01,61.08it/s] 57%|#####7    |99267/173481[27:00<20:23,60.68it/s] 58%|#####7    |99930/173481[27:11<20:12,60.68it/s] 63%|######3   |109866/173481[30:00<17:44,59.77it/s] 64%|######3   |110531/173481[30:11<17:33,59.77it/s] 69%|######9   |120469/173481[33:00<14:53,59.33it/s] 70%|######9   |121136/173481[33:11<14:42,59.33it/s] 76%|#######5  |131115/173481[36:00<11:55,59.24it/s] 76%|#######5  |131786/173481[36:11<11:43,59.24it/s] 82%|########1 |141725/173481[39:00<08:57,59.09it/s] 82%|########2 |142440/173481[39:11<08:45,59.09it/s]slurmstepd: *** STEP 85146.0 ON sls-titanx-1 CANCELLED AT 2018-03-29T12:39:07 ***
slurmstepd: *** JOB 85146 ON sls-titanx-1 CANCELLED AT 2018-03-29T12:39:07 ***
