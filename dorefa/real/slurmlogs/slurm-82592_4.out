sls-titanx-1 0
SLURM_JOBID=82596
SLURM_TASKID=4
[32m[0323 10:57:36 @logger.py:67][0m Existing log file 'train_log/fcn1_w_16_a_32_quant_ends_False/log.log' backuped to 'train_log/fcn1_w_16_a_32_quant_ends_False/log.log.0323-105736'
[32m[0323 10:57:36 @logger.py:74][0m Argv: drf_run.py --model_name=fcn1 --bitw=16 --bita=32 --quant_ends=False
[32m[0323 10:57:43 @parallel.py:282][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0323 10:57:43 @drf_run.py:140][0m Using 5 threads
('whole utterance size', 75290)
[32m[0323 10:57:44 @drf_run.py:165][0m 18822 utterances per val epoch
[32m[0323 10:57:44 @drf_run.py:166][0m Using host: sls-titanx-1
[32m[0323 10:57:44 @inference_runner.py:80][0m InferenceRunner will eval 18822 iterations
[32m[0323 10:57:44 @__init__.py:20][0m [5m[31mWRN[0m get_nr_gpu will not be automatically imported any more! Please do `from tensorpack.utils.gpu import get_nr_gpu`
[32m[0323 10:57:44 @drf_run.py:188][0m Using GPU: 0
[32m[0323 10:57:44 @interface.py:34][0m Automatically applying QueueInput on the DataFlow.
[32m[0323 10:57:44 @input_source.py:193][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0323 10:57:44 @training.py:108][0m Building graph for training tower 0 ...
[32m[0323 10:57:44 @registry.py:122][0m linear0 input: [None, 1000]
[32m[0323 10:57:44 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0323 10:57:44 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0323 10:57:44 @registry.py:130][0m linear0 output: [None, 256]
[32m[0323 10:57:44 @registry.py:122][0m linear1 input: [None, 256]
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:57:44 @registry.py:130][0m linear1 output: [None, 256]
[32m[0323 10:57:44 @registry.py:122][0m linear2 input: [None, 256]
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:57:44 @registry.py:130][0m linear2 output: [None, 256]
[32m[0323 10:57:44 @registry.py:122][0m linear3 input: [None, 256]
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:57:44 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:57:44 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:57:44 @registry.py:130][0m linear3 output: [None, 256]
[32m[0323 10:57:44 @registry.py:122][0m last_linear input: [None, 256]
[32m[0323 10:57:44 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:57:44 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:57:44 @registry.py:130][0m last_linear output: [None, 255]
[32m[0323 10:57:44 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:57:44 @regularize.py:81][0m regularize_cost() found 5 tensors.
[32m[0323 10:57:44 @regularize.py:18][0m Applying regularizer for linear0/W:0, linear1/W:0, linear2/W:0, linear3/W:0, last_linear/W:0
[32m[0323 10:57:44 @drf_run.py:123][0m Parameter count: {'mults': 519936, 'weights': 520191}
[32m[0323 10:57:45 @model_utils.py:49][0m [36mModel Parameters: 
[0mname                shape           dim
------------------  -----------  ------
linear0/W:0         [1000, 256]  256000
linear0/b:0         [256]           256
linear0/bn/beta:0   [256]           256
linear0/bn/gamma:0  [256]           256
linear1/W:0         [256, 256]    65536
linear1/b:0         [256]           256
linear1/bn/beta:0   [256]           256
linear1/bn/gamma:0  [256]           256
linear2/W:0         [256, 256]    65536
linear2/b:0         [256]           256
linear2/bn/beta:0   [256]           256
linear2/bn/gamma:0  [256]           256
linear3/W:0         [256, 256]    65536
linear3/b:0         [256]           256
linear3/bn/beta:0   [256]           256
linear3/bn/gamma:0  [256]           256
last_linear/W:0     [256, 255]    65280
last_linear/b:0     [255]           255[36m
Total #vars=18, #params=521215, size=1.99MB[0m
[32m[0323 10:57:45 @base.py:196][0m Setup callbacks graph ...
[32m[0323 10:57:45 @predict.py:42][0m Building predictor tower 'InferenceTower' on device /gpu:0 ...
[32m[0323 10:57:45 @drf_run.py:67][0m Not quantizing linear0/W
[32m[0323 10:57:45 @drf_run.py:67][0m Not quantizing linear0/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear0/bn/variance/EMA
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear1/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear1/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear1/bn/variance/EMA
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear2/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear2/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear2/bn/variance/EMA
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear3/W
[32m[0323 10:57:45 @drf_run.py:70][0m Quantizing weight linear3/b
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/beta
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/gamma
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/mean/EMA
[32m[0323 10:57:45 @drf_run.py:58][0m Not quantizing linear3/bn/variance/EMA
[32m[0323 10:57:45 @drf_run.py:64][0m Not quantizing last_linear/W
[32m[0323 10:57:45 @drf_run.py:64][0m Not quantizing last_linear/b
[32m[0323 10:57:45 @drf_run.py:112][0m Adding activation tensors to summary: [<tf.Tensor 'tower0/last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'tower0/output:0' shape=(?, 255) dtype=float32>]
[32m[0323 10:57:45 @drf_run.py:123][0m Parameter count: {'mults': 1039872, 'weights': 1040382}
[32m[0323 10:57:45 @summary.py:34][0m Maintain moving average summary of 3 tensors.
[32m[0323 10:57:45 @graph.py:90][0m Applying collection UPDATE_OPS of 8 ops.
[32m[0323 10:57:46 @base.py:212][0m Creating the session ...
2018-03-23 10:57:46.239398: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-23 10:57:52.845951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:04:00.0
totalMemory: 11.90GiB freeMemory: 11.75GiB
2018-03-23 10:57:52.846010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1)
[32m[0323 10:57:56 @base.py:220][0m Initializing the session ...
[32m[0323 10:57:56 @base.py:227][0m Graph Finalized.
[32m[0323 10:57:56 @concurrency.py:36][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0323 10:57:57 @monitor.py:251][0m Found existing JSON at train_log/fcn1_w_16_a_32_quant_ends_False/stat.json, will append to it.
[32m[0323 10:57:57 @monitor.py:262][0m Found training history from JSON, now starting from epoch number 2.
[32m[0323 10:57:57 @base.py:247][0m Start Epoch 2 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |18206/173481[03:00<25:35,101.14it/s] 11%|#1        |19116/173481[03:10<25:26,101.14it/s] 20%|##        |35211/173481[06:00<23:35,97.69it/s]  21%|##        |36185/173481[06:10<23:25,97.69it/s] 30%|###       |52076/173481[09:00<21:09,95.65it/s] 31%|###       |53095/173481[09:10<20:58,95.65it/s] 40%|####      |69787/173481[12:00<17:49,97.00it/s] 41%|####      |70855/173481[12:10<17:38,97.00it/s] 50%|#####     |87019/173481[15:00<14:57,96.36it/s] 51%|#####     |87985/173481[15:10<14:47,96.36it/s] 59%|#####9    |102868/173481[18:00<12:47,92.02it/s] 60%|#####9    |103568/173481[18:10<12:39,92.02it/s] 66%|######5   |114417/173481[21:00<13:01,75.60it/s] 66%|######6   |115103/173481[21:11<12:52,75.60it/s] 73%|#######2  |125891/173481[24:00<11:28,69.16it/s] 73%|#######3  |126665/173481[24:11<11:16,69.16it/s] 79%|#######9  |137476/173481[27:00<09:00,66.67it/s] 80%|#######9  |138225/173481[27:11<08:48,66.67it/s] 86%|########5 |148703/173481[30:00<06:24,64.45it/s] 86%|########6 |149365/173481[30:11<06:14,64.45it/s] 92%|#########1|159036/173481[33:00<03:57,60.72it/s] 92%|#########2|159733/173481[33:11<03:46,60.72it/s] 98%|#########8|170206/173481[36:00<00:53,61.38it/s] 99%|#########8|170935/173481[36:11<00:41,61.38it/s]100%|##########|173481/173481[36:52<00:00,78.39it/s]
[32m[0323 11:34:50 @base.py:257][0m Epoch 2 (global_step 173481) finished, time:2213.00 sec.
[32m[0323 11:34:51 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-173481.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.48it/s]
0
[32m[0323 11:36:51 @monitor.py:363][0m QueueInput/queue_size: 0.40168
[32m[0323 11:36:51 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.8689
[32m[0323 11:36:51 @monitor.py:363][0m activation-summaries/output-rms: 0.028798
[32m[0323 11:36:51 @monitor.py:363][0m cross_entropy_loss: 2.6514
[32m[0323 11:36:51 @monitor.py:363][0m lr: 0.001
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13477
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.62911
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear0/W-rms: 0.09708
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13087
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086698
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11776
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear3/W-rms: 0.11151
[32m[0323 11:36:51 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 11:36:51 @monitor.py:363][0m train-error-top1: 0.65077
[32m[0323 11:36:51 @monitor.py:363][0m val-error-top1: 0.70823
[32m[0323 11:36:51 @monitor.py:363][0m val-utt-error: 0.38545
[32m[0323 11:36:51 @monitor.py:363][0m validation_cost: 2.9505
[32m[0323 11:36:51 @monitor.py:363][0m wd_cost: 0.6445
[32m[0323 11:36:51 @group.py:42][0m Callbacks took 120.668 sec in total. InferenceRunner: 120.305sec
[32m[0323 11:36:51 @base.py:247][0m Start Epoch 3 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13859/173481[03:00<34:33,76.99it/s]  8%|8         |14624/173481[03:10<34:23,76.99it/s] 15%|#4        |25773/173481[06:00<34:35,71.18it/s] 15%|#5        |26399/173481[06:10<34:26,71.18it/s] 21%|##        |36120/173481[09:00<35:59,63.60it/s] 21%|##1       |36719/173481[09:10<35:50,63.60it/s] 27%|##7       |46991/173481[12:00<34:01,61.95it/s] 27%|##7       |47619/173481[12:10<33:51,61.95it/s] 34%|###3      |58156/173481[15:00<31:00,61.99it/s] 34%|###3      |58854/173481[15:10<30:49,61.99it/s] 40%|###9      |69085/173481[18:00<28:22,61.34it/s] 40%|####      |69779/173481[18:10<28:10,61.34it/s] 46%|####6     |80324/173481[21:00<25:05,61.88it/s] 47%|####6     |80994/173481[21:11<24:54,61.88it/s] 53%|#####2    |91490/173481[24:00<22:03,61.95it/s] 53%|#####3    |92171/173481[24:11<21:52,61.95it/s] 59%|#####9    |102605/173481[27:00<19:05,61.85it/s] 60%|#####9    |103324/173481[27:11<18:54,61.85it/s] 66%|######5   |113975/173481[30:00<15:52,62.49it/s] 66%|######6   |114679/173481[30:11<15:41,62.49it/s] 72%|#######1  |124840/173481[33:00<13:12,61.41it/s] 72%|#######2  |125514/173481[33:11<13:01,61.41it/s] 78%|#######7  |135269/173481[36:00<10:40,59.62it/s] 78%|#######8  |135932/173481[36:11<10:29,59.62it/s] 84%|########3 |145656/173481[39:00<07:54,58.65it/s] 84%|########4 |146389/173481[39:12<07:41,58.65it/s] 90%|######### |156405/173481[42:00<04:48,59.17it/s] 91%|######### |157179/173481[42:12<04:35,59.17it/s] 97%|#########6|167651/173481[45:00<01:35,60.78it/s] 97%|#########7|168424/173481[45:12<01:23,60.78it/s]100%|##########|173481/173481[46:34<00:00,62.08it/s]
[32m[0323 12:23:26 @base.py:257][0m Epoch 3 (global_step 346962) finished, time:2794.52 sec.
[32m[0323 12:23:26 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-346962.
[32m[0323 12:23:27 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:52<00:00,167.38it/s]
1
[32m[0323 12:25:19 @monitor.py:363][0m QueueInput/queue_size: 0.91669
[32m[0323 12:25:19 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 3.9658
[32m[0323 12:25:19 @monitor.py:363][0m activation-summaries/output-rms: 0.028864
[32m[0323 12:25:19 @monitor.py:363][0m cross_entropy_loss: 2.6664
[32m[0323 12:25:19 @monitor.py:363][0m lr: 0.001
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.13551
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/last_linear/b-rms: 0.87491
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/linear0/W-rms: 0.097381
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/linear1/W-rms: 0.13135
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086698
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/linear2/W-rms: 0.11493
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/linear3/W-rms: 0.10884
[32m[0323 12:25:19 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 12:25:19 @monitor.py:363][0m train-error-top1: 0.64785
[32m[0323 12:25:19 @monitor.py:363][0m val-error-top1: 0.70442
[32m[0323 12:25:19 @monitor.py:363][0m val-utt-error: 0.3744
[32m[0323 12:25:19 @monitor.py:363][0m validation_cost: 2.9367
[32m[0323 12:25:19 @monitor.py:363][0m wd_cost: 0.63994
[32m[0323 12:25:19 @group.py:42][0m Callbacks took 113.483 sec in total. InferenceRunner: 112.463sec
[32m[0323 12:25:19 @base.py:247][0m Start Epoch 4 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15998/173481[03:00<29:31,88.88it/s] 10%|9         |16692/173481[03:10<29:24,88.88it/s] 16%|#5        |27139/173481[06:00<33:25,72.96it/s] 16%|#5        |27722/173481[06:10<33:17,72.96it/s] 22%|##1       |37334/173481[09:00<35:35,63.77it/s] 22%|##1       |37919/173481[09:10<35:25,63.77it/s] 27%|##7       |47669/173481[12:00<34:42,60.41it/s] 28%|##7       |48263/173481[12:10<34:32,60.41it/s] 33%|###3      |58089/173481[15:00<32:32,59.11it/s] 34%|###3      |58733/173481[15:10<32:21,59.11it/s] 40%|###9      |69164/173481[18:00<28:50,60.29it/s] 40%|####      |69864/173481[18:10<28:38,60.29it/s] 46%|####6     |80662/173481[21:00<24:56,62.03it/s] 47%|####6     |81394/173481[21:11<24:44,62.03it/s] 53%|#####3    |92254/173481[24:00<21:25,63.19it/s] 54%|#####3    |92973/173481[24:11<21:14,63.19it/s] 60%|#####9    |103749/173481[27:00<18:17,63.52it/s] 60%|######    |104333/173481[27:11<18:08,63.52it/s] 66%|######6   |115128/173481[30:00<15:20,63.36it/s] 67%|######6   |115861/173481[30:11<15:09,63.36it/s] 73%|#######2  |126444/173481[33:00<12:25,63.11it/s] 73%|#######3  |127215/173481[33:11<12:13,63.11it/s] 80%|#######9  |138360/173481[36:00<09:03,64.62it/s] 80%|########  |139118/173481[36:11<08:51,64.62it/s] 87%|########6 |150210/173481[39:00<05:56,65.22it/s] 87%|########7 |150950/173481[39:12<05:45,65.22it/s] 94%|#########3|162254/173481[42:00<02:49,66.05it/s] 94%|#########3|163033/173481[42:12<02:38,66.05it/s]100%|##########|173481/173481[44:50<00:00,64.48it/s]
[32m[0323 13:10:10 @base.py:257][0m Epoch 4 (global_step 520443) finished, time:2690.42 sec.
[32m[0323 13:10:10 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-520443.
[32m[0323 13:10:10 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:45<00:00,177.72it/s]
2
[32m[0323 13:11:56 @monitor.py:363][0m QueueInput/queue_size: 0.5558
[32m[0323 13:11:56 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 6.8378
[32m[0323 13:11:56 @monitor.py:363][0m activation-summaries/output-rms: 0.034881
[32m[0323 13:11:56 @monitor.py:363][0m cross_entropy_loss: 2.1026
[32m[0323 13:11:56 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.18572
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0072
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/linear0/W-rms: 0.14126
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/linear1/W-rms: 0.17762
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086698
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/linear2/W-rms: 0.15493
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/linear3/W-rms: 0.14899
[32m[0323 13:11:56 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 13:11:56 @monitor.py:363][0m train-error-top1: 0.54985
[32m[0323 13:11:56 @monitor.py:363][0m val-error-top1: 0.57917
[32m[0323 13:11:56 @monitor.py:363][0m val-utt-error: 0.21262
[32m[0323 13:11:56 @monitor.py:363][0m validation_cost: 2.2693
[32m[0323 13:11:56 @monitor.py:363][0m wd_cost: 0.24909
[32m[0323 13:11:56 @group.py:42][0m Callbacks took 106.610 sec in total. InferenceRunner: 105.924sec
[32m[0323 13:11:56 @base.py:247][0m Start Epoch 5 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12613/173481[03:00<38:15,70.07it/s]  8%|7         |13275/173481[03:10<38:06,70.07it/s] 14%|#3        |23890/173481[06:00<37:41,66.15it/s] 14%|#4        |24507/173481[06:10<37:31,66.15it/s] 21%|##        |35604/173481[09:00<35:01,65.61it/s] 21%|##        |36317/173481[09:10<34:50,65.61it/s] 27%|##7       |47620/173481[12:00<31:41,66.18it/s] 28%|##7       |48317/173481[12:10<31:31,66.18it/s] 34%|###4      |59548/173481[15:00<28:40,66.21it/s] 35%|###4      |60285/173481[15:10<28:29,66.21it/s] 41%|####1     |71758/173481[18:00<25:18,67.01it/s] 42%|####1     |72465/173481[18:10<25:07,67.01it/s] 48%|####8     |83700/173481[21:00<22:26,66.67it/s] 49%|####8     |84438/173481[21:11<22:15,66.67it/s] 55%|#####5    |95583/173481[24:00<19:34,66.34it/s] 56%|#####5    |96310/173481[24:11<19:23,66.34it/s] 62%|######2   |107655/173481[27:00<16:26,66.70it/s] 62%|######2   |108410/173481[27:11<16:15,66.70it/s] 69%|######8   |119496/173481[30:00<13:35,66.24it/s] 69%|######9   |120225/173481[30:11<13:24,66.24it/s] 76%|#######5  |131403/173481[33:00<10:35,66.19it/s] 76%|#######6  |132180/173481[33:11<10:23,66.19it/s] 83%|########2 |143538/173481[36:00<07:28,66.79it/s] 83%|########3 |144222/173481[36:11<07:18,66.79it/s] 89%|########9 |155078/173481[39:00<04:41,65.42it/s] 90%|########9 |155812/173481[39:12<04:30,65.42it/s] 96%|#########6|166550/173481[42:00<01:47,64.57it/s] 96%|#########6|167221/173481[42:12<01:36,64.57it/s]100%|##########|173481/173481[43:56<00:00,65.80it/s]
[32m[0323 13:55:53 @base.py:257][0m Epoch 5 (global_step 693924) finished, time:2636.59 sec.
[32m[0323 13:55:53 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-693924.
[32m[0323 13:55:54 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:38<00:00,190.82it/s]
3
[32m[0323 13:57:32 @monitor.py:363][0m QueueInput/queue_size: 0.37145
[32m[0323 13:57:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.4246
[32m[0323 13:57:32 @monitor.py:363][0m activation-summaries/output-rms: 0.035232
[32m[0323 13:57:32 @monitor.py:363][0m cross_entropy_loss: 2.0653
[32m[0323 13:57:32 @monitor.py:363][0m lr: 0.0005
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.21695
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.0845
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.14895
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20066
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086698
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.17728
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16823
[32m[0323 13:57:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 13:57:32 @monitor.py:363][0m train-error-top1: 0.53546
[32m[0323 13:57:32 @monitor.py:363][0m val-error-top1: 0.55863
[32m[0323 13:57:32 @monitor.py:363][0m val-utt-error: 0.19105
[32m[0323 13:57:32 @monitor.py:363][0m validation_cost: 2.1748
[32m[0323 13:57:32 @monitor.py:363][0m wd_cost: 0.30611
[32m[0323 13:57:32 @group.py:42][0m Callbacks took 99.631 sec in total. InferenceRunner: 98.656sec
[32m[0323 13:57:32 @base.py:247][0m Start Epoch 6 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11928/173481[03:00<40:37,66.27it/s]  7%|7         |12566/173481[03:10<40:28,66.27it/s] 13%|#3        |23078/173481[06:00<39:08,64.03it/s] 14%|#3        |23717/173481[06:10<38:58,64.03it/s] 20%|##        |35027/173481[09:00<35:24,65.18it/s] 21%|##        |35709/173481[09:10<35:13,65.18it/s] 27%|##6       |46809/173481[12:00<32:19,65.32it/s] 27%|##7       |47469/173481[12:10<32:09,65.32it/s] 34%|###3      |58592/173481[15:00<29:16,65.39it/s] 34%|###4      |59296/173481[15:10<29:06,65.39it/s] 40%|####      |70062/173481[18:00<26:42,64.54it/s] 41%|####      |70681/173481[18:10<26:32,64.54it/s] 47%|####7     |81556/173481[21:00<23:51,64.20it/s] 47%|####7     |82258/173481[21:11<23:40,64.20it/s] 54%|#####3    |93127/173481[24:00<20:50,64.24it/s] 54%|#####4    |93846/173481[24:11<20:39,64.24it/s] 60%|######    |104702/173481[27:00<17:50,64.26it/s] 61%|######    |105424/173481[27:11<17:39,64.26it/s] 67%|######7   |116272/173481[30:00<14:50,64.27it/s] 67%|######7   |117009/173481[30:11<14:38,64.27it/s] 74%|#######3  |127808/173481[33:00<11:51,64.18it/s] 74%|#######4  |128587/173481[33:11<11:39,64.18it/s] 80%|########  |139421/173481[36:00<08:49,64.35it/s] 81%|########  |140188/173481[36:11<08:37,64.35it/s] 87%|########7 |151297/173481[39:00<05:40,65.15it/s] 88%|########7 |152086/173481[39:12<05:28,65.15it/s] 94%|#########3|162797/173481[42:00<02:45,64.51it/s] 94%|#########4|163521/173481[42:12<02:34,64.51it/s]100%|##########|173481/173481[44:57<00:00,64.30it/s]
[32m[0323 14:42:30 @base.py:257][0m Epoch 6 (global_step 867405) finished, time:2697.82 sec.
[32m[0323 14:42:30 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-867405.
[32m[0323 14:42:31 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:37<00:00,193.65it/s]
4
[32m[0323 14:44:08 @monitor.py:363][0m QueueInput/queue_size: 0.17233
[32m[0323 14:44:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 8.2901
[32m[0323 14:44:08 @monitor.py:363][0m activation-summaries/output-rms: 0.036358
[32m[0323 14:44:08 @monitor.py:363][0m cross_entropy_loss: 1.9793
[32m[0323 14:44:08 @monitor.py:363][0m lr: 0.0005
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.2204
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1497
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.15021
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.20285
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086698
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.17935
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.16971
[32m[0323 14:44:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 14:44:08 @monitor.py:363][0m train-error-top1: 0.5147
[32m[0323 14:44:08 @monitor.py:363][0m val-error-top1: 0.55582
[32m[0323 14:44:08 @monitor.py:363][0m val-utt-error: 0.1944
[32m[0323 14:44:08 @monitor.py:363][0m validation_cost: 2.167
[32m[0323 14:44:08 @monitor.py:363][0m wd_cost: 0.31279
[32m[0323 14:44:08 @group.py:42][0m Callbacks took 97.858 sec in total. InferenceRunner: 97.213sec
[32m[0323 14:44:08 @base.py:247][0m Start Epoch 7 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12731/173481[03:00<37:52,70.73it/s]  8%|7         |13400/173481[03:10<37:43,70.73it/s] 14%|#4        |24491/173481[06:00<36:34,67.90it/s] 15%|#4        |25193/173481[06:10<36:23,67.90it/s] 21%|##        |35571/173481[09:00<35:35,64.57it/s] 21%|##        |36197/173481[09:10<35:26,64.57it/s] 28%|##8       |49115/173481[12:00<29:49,69.50it/s] 29%|##8       |49920/173481[12:10<29:37,69.50it/s] 36%|###6      |63156/173481[15:00<25:00,73.50it/s] 37%|###6      |63997/173481[15:10<24:49,73.50it/s] 44%|####4     |76926/173481[18:00<21:27,74.97it/s] 45%|####4     |77765/173481[18:11<21:16,74.97it/s] 52%|#####2    |91041/173481[21:00<17:55,76.65it/s] 53%|#####3    |92063/173481[21:11<17:42,76.65it/s] 59%|#####9    |103037/173481[24:00<16:28,71.30it/s] 60%|#####9    |103675/173481[24:11<16:19,71.30it/s] 66%|######5   |113826/173481[27:00<15:16,65.12it/s] 66%|######6   |114507/173481[27:11<15:05,65.12it/s] 72%|#######1  |124586/173481[30:00<13:04,62.33it/s] 72%|#######2  |125295/173481[30:11<12:53,62.33it/s] 78%|#######8  |135641/173481[33:00<10:11,61.86it/s] 79%|#######8  |136345/173481[33:11<10:00,61.86it/s] 85%|########4 |146597/173481[36:00<07:18,61.36it/s] 85%|########4 |147298/173481[36:12<07:06,61.36it/s] 91%|######### |157191/173481[39:00<04:31,60.08it/s] 91%|#########1|157915/173481[39:12<04:19,60.08it/s] 97%|#########6|168164/173481[42:00<01:27,60.52it/s] 97%|#########7|168898/173481[42:12<01:15,60.52it/s]100%|##########|173481/173481[43:28<00:00,66.51it/s]
[32m[0323 15:27:36 @base.py:257][0m Epoch 7 (global_step 1040886) finished, time:2608.40 sec.
[32m[0323 15:27:37 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-1040886.
[32m[0323 15:27:37 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:26<00:00,128.80it/s]
5
[32m[0323 15:30:03 @monitor.py:363][0m QueueInput/queue_size: 0.30658
[32m[0323 15:30:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 12.505
[32m[0323 15:30:03 @monitor.py:363][0m activation-summaries/output-rms: 0.038773
[32m[0323 15:30:03 @monitor.py:363][0m cross_entropy_loss: 1.7846
[32m[0323 15:30:03 @monitor.py:363][0m lr: 0.00025
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.26305
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.1943
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.19033
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.22742
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086698
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.19893
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.18993
[32m[0323 15:30:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 15:30:03 @monitor.py:363][0m train-error-top1: 0.47048
[32m[0323 15:30:03 @monitor.py:363][0m val-error-top1: 0.49298
[32m[0323 15:30:03 @monitor.py:363][0m val-utt-error: 0.13957
[32m[0323 15:30:03 @monitor.py:363][0m validation_cost: 1.8779
[32m[0323 15:30:03 @monitor.py:363][0m wd_cost: 0.088546
[32m[0323 15:30:03 @group.py:42][0m Callbacks took 146.891 sec in total. InferenceRunner: 146.147sec
[32m[0323 15:30:03 @base.py:247][0m Start Epoch 8 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14046/173481[03:00<34:03,78.03it/s]  8%|8         |14660/173481[03:10<33:55,78.03it/s] 14%|#4        |25150/173481[06:00<35:53,68.89it/s] 15%|#4        |25749/173481[06:10<35:44,68.89it/s] 20%|##        |35482/173481[09:00<36:43,62.62it/s] 21%|##        |36054/173481[09:10<36:34,62.62it/s] 26%|##6       |45510/173481[12:00<36:10,58.96it/s] 27%|##6       |46111/173481[12:10<36:00,58.96it/s] 33%|###2      |56445/173481[15:00<32:36,59.83it/s] 33%|###2      |57129/173481[15:10<32:24,59.83it/s] 39%|###8      |67333/173481[18:00<29:24,60.16it/s] 39%|###9      |68001/173481[18:10<29:13,60.16it/s] 45%|####5     |78542/173481[21:00<25:51,61.20it/s] 46%|####5     |79194/173481[21:11<25:40,61.20it/s] 52%|#####1    |89866/173481[24:00<22:27,62.04it/s] 52%|#####2    |90585/173481[24:11<22:16,62.04it/s] 58%|#####8    |101110/173481[27:00<19:22,62.25it/s] 59%|#####8    |101788/173481[27:11<19:11,62.25it/s] 65%|######4   |112190/173481[30:00<16:30,61.89it/s] 65%|######5   |112825/173481[30:11<16:19,61.89it/s] 71%|#######   |123125/173481[33:00<13:41,61.31it/s] 71%|#######1  |123824/173481[33:11<13:29,61.31it/s] 77%|#######7  |134109/173481[36:00<10:43,61.16it/s] 78%|#######7  |134804/173481[36:11<10:32,61.16it/s] 84%|########4 |146240/173481[39:00<07:04,64.12it/s] 85%|########4 |147074/173481[39:12<06:51,64.12it/s] 91%|#########1|158190/173481[42:00<03:54,65.23it/s] 92%|#########1|159219/173481[42:12<03:38,65.23it/s]100%|##########|173481/173481[44:42<00:00,64.67it/s]
[32m[0323 16:14:46 @base.py:257][0m Epoch 8 (global_step 1214367) finished, time:2682.71 sec.
[32m[0323 16:14:46 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-1214367.
[32m[0323 16:14:47 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.98it/s]
6
[32m[0323 16:16:49 @monitor.py:363][0m QueueInput/queue_size: 0.4337
[32m[0323 16:16:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 17.235
[32m[0323 16:16:49 @monitor.py:363][0m activation-summaries/output-rms: 0.038809
[32m[0323 16:16:49 @monitor.py:363][0m cross_entropy_loss: 1.748
[32m[0323 16:16:49 @monitor.py:363][0m lr: 0.00025
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.31811
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2155
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.21665
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.25818
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086698
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.22797
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.21957
[32m[0323 16:16:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 16:16:49 @monitor.py:363][0m train-error-top1: 0.46358
[32m[0323 16:16:49 @monitor.py:363][0m val-error-top1: 0.4835
[32m[0323 16:16:49 @monitor.py:363][0m val-utt-error: 0.13431
[32m[0323 16:16:49 @monitor.py:363][0m validation_cost: 1.837
[32m[0323 16:16:49 @monitor.py:363][0m wd_cost: 0.11822
[32m[0323 16:16:49 @group.py:42][0m Callbacks took 123.259 sec in total. InferenceRunner: 122.253sec
[32m[0323 16:16:49 @base.py:247][0m Start Epoch 9 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17592/173481[03:00<26:35,97.73it/s] 11%|#         |18555/173481[03:10<26:25,97.73it/s] 17%|#6        |29404/173481[06:00<30:34,78.52it/s] 17%|#7        |29998/173481[06:10<30:27,78.52it/s] 23%|##2       |39883/173481[09:00<33:18,66.86it/s] 23%|##3       |40498/173481[09:10<33:08,66.86it/s] 29%|##9       |50451/173481[12:00<32:47,62.52it/s] 29%|##9       |51018/173481[12:10<32:38,62.52it/s] 35%|###5      |60874/173481[15:00<31:13,60.12it/s] 35%|###5      |61510/173481[15:10<31:02,60.12it/s] 42%|####1     |72249/173481[18:00<27:23,61.61it/s] 42%|####2     |72898/173481[18:10<27:12,61.61it/s] 48%|####8     |83591/173481[21:00<24:02,62.30it/s] 49%|####8     |84258/173481[21:11<23:52,62.30it/s] 55%|#####4    |94745/173481[24:00<21:07,62.13it/s] 55%|#####4    |95400/173481[24:11<20:56,62.13it/s] 61%|######1   |106213/173481[27:00<17:49,62.91it/s] 62%|######1   |106963/173481[27:11<17:37,62.91it/s] 68%|######7   |117809/173481[30:00<14:34,63.65it/s] 68%|######8   |118570/173481[30:11<14:22,63.65it/s] 74%|#######4  |129079/173481[33:00<11:43,63.12it/s] 75%|#######4  |129808/173481[33:11<11:31,63.12it/s] 81%|########1 |140648/173481[36:00<08:35,63.69it/s] 82%|########1 |141483/173481[36:11<08:22,63.69it/s] 88%|########7 |152571/173481[39:00<05:21,64.94it/s] 88%|########8 |153383/173481[39:12<05:09,64.94it/s] 94%|#########4|163893/173481[42:00<02:30,63.90it/s] 95%|#########4|164683/173481[42:12<02:17,63.90it/s]100%|##########|173481/173481[44:28<00:00,65.01it/s]
[32m[0323 17:01:18 @base.py:257][0m Epoch 9 (global_step 1387848) finished, time:2668.49 sec.
[32m[0323 17:01:18 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-1387848.
[32m[0323 17:01:18 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:51<00:00,169.24it/s]
7
[32m[0323 17:03:10 @monitor.py:363][0m QueueInput/queue_size: 0.5441
[32m[0323 17:03:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 19.942
[32m[0323 17:03:10 @monitor.py:363][0m activation-summaries/output-rms: 0.039561
[32m[0323 17:03:10 @monitor.py:363][0m cross_entropy_loss: 1.7522
[32m[0323 17:03:10 @monitor.py:363][0m lr: 0.00025
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.35393
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2348
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.22271
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.26928
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.24038
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.23221
[32m[0323 17:03:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 17:03:10 @monitor.py:363][0m train-error-top1: 0.471
[32m[0323 17:03:10 @monitor.py:363][0m val-error-top1: 0.47952
[32m[0323 17:03:10 @monitor.py:363][0m val-utt-error: 0.12783
[32m[0323 17:03:10 @monitor.py:363][0m validation_cost: 1.8147
[32m[0323 17:03:10 @monitor.py:363][0m wd_cost: 0.13179
[32m[0323 17:03:10 @group.py:42][0m Callbacks took 111.899 sec in total. InferenceRunner: 111.230sec
[32m[0323 17:03:10 @base.py:247][0m Start Epoch 10 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12787/173481[03:00<37:42,71.04it/s]  8%|7         |13423/173481[03:10<37:33,71.04it/s] 14%|#3        |23644/173481[06:00<38:16,65.24it/s] 14%|#3        |24267/173481[06:10<38:07,65.24it/s] 20%|##        |35023/173481[09:00<35:56,64.21it/s] 21%|##        |35683/173481[09:10<35:46,64.21it/s] 27%|##6       |46703/173481[12:00<32:44,64.55it/s] 27%|##7       |47415/173481[12:10<32:33,64.55it/s] 33%|###3      |58008/173481[15:00<30:14,63.66it/s] 34%|###3      |58721/173481[15:10<30:02,63.66it/s] 40%|####      |69743/173481[18:00<26:50,64.42it/s] 41%|####      |70414/173481[18:10<26:40,64.42it/s] 47%|####6     |81286/173481[21:00<23:54,64.27it/s] 47%|####7     |81982/173481[21:11<23:43,64.27it/s] 53%|#####3    |92337/173481[24:00<21:32,62.80it/s] 54%|#####3    |93052/173481[24:11<21:20,62.80it/s] 60%|#####9    |103841/173481[27:00<18:19,63.35it/s] 60%|######    |104573/173481[27:11<18:07,63.35it/s] 67%|######6   |115373/173481[30:00<15:12,63.70it/s] 67%|######6   |116097/173481[30:11<15:00,63.70it/s] 73%|#######3  |126748/173481[33:00<12:16,63.45it/s] 73%|#######3  |127477/173481[33:11<12:05,63.45it/s] 80%|#######9  |138003/173481[36:00<09:23,62.98it/s] 80%|#######9  |138737/173481[36:11<09:11,62.98it/s] 86%|########6 |149508/173481[39:00<06:17,63.44it/s] 87%|########6 |150324/173481[39:12<06:05,63.44it/s] 93%|#########3|161506/173481[42:00<03:04,65.01it/s] 94%|#########3|162237/173481[42:12<02:52,65.01it/s] 99%|#########8|171584/173481[45:00<00:31,60.16it/s] 99%|#########9|172292/173481[45:12<00:19,60.16it/s]100%|##########|173481/173481[45:32<00:00,63.48it/s]
[32m[0323 17:48:42 @base.py:257][0m Epoch 10 (global_step 1561329) finished, time:2732.77 sec.
[32m[0323 17:48:43 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-1561329.
[32m[0323 17:48:43 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.13it/s]
8
[32m[0323 17:50:30 @monitor.py:363][0m QueueInput/queue_size: 0.33979
[32m[0323 17:50:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 24.614
[32m[0323 17:50:30 @monitor.py:363][0m activation-summaries/output-rms: 0.040335
[32m[0323 17:50:30 @monitor.py:363][0m cross_entropy_loss: 1.6628
[32m[0323 17:50:30 @monitor.py:363][0m lr: 0.000125
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.39171
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2465
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.24665
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.28007
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2484
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.24012
[32m[0323 17:50:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 17:50:30 @monitor.py:363][0m train-error-top1: 0.44205
[32m[0323 17:50:30 @monitor.py:363][0m val-error-top1: 0.45248
[32m[0323 17:50:30 @monitor.py:363][0m val-utt-error: 0.11115
[32m[0323 17:50:30 @monitor.py:363][0m validation_cost: 1.7043
[32m[0323 17:50:30 @monitor.py:363][0m wd_cost: 0.030842
[32m[0323 17:50:30 @group.py:42][0m Callbacks took 107.613 sec in total. InferenceRunner: 106.883sec
[32m[0323 17:50:30 @base.py:247][0m Start Epoch 11 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12737/173481[03:00<37:52,70.74it/s]  8%|7         |13355/173481[03:10<37:43,70.74it/s] 14%|#3        |23458/173481[06:00<38:39,64.67it/s] 14%|#3        |24110/173481[06:10<38:29,64.67it/s] 20%|##        |34965/173481[09:00<35:54,64.29it/s] 21%|##        |35590/173481[09:10<35:44,64.29it/s] 27%|##6       |46257/173481[12:00<33:23,63.50it/s] 27%|##7       |46891/173481[12:10<33:13,63.50it/s] 33%|###3      |57654/173481[15:00<30:26,63.40it/s] 34%|###3      |58346/173481[15:10<30:15,63.40it/s] 40%|###9      |68542/173481[18:00<28:15,61.90it/s] 40%|###9      |69186/173481[18:10<28:04,61.90it/s] 46%|####5     |79690/173481[21:00<25:14,61.92it/s] 46%|####6     |80380/173481[21:11<25:03,61.92it/s] 52%|#####2    |90994/173481[24:00<22:02,62.35it/s] 53%|#####2    |91646/173481[24:11<21:52,62.35it/s] 59%|#####8    |101817/173481[27:00<19:30,61.22it/s] 59%|#####9    |102472/173481[27:11<19:19,61.22it/s] 65%|######4   |112447/173481[30:00<16:55,60.11it/s] 65%|######5   |113166/173481[30:11<16:43,60.11it/s] 72%|#######1  |124657/173481[33:00<12:46,63.74it/s] 72%|#######2  |125444/173481[33:11<12:33,63.74it/s] 80%|########  |139492/173481[36:00<07:52,71.88it/s] 81%|########  |140361/173481[36:12<07:40,71.88it/s] 88%|########7 |152147/173481[39:00<05:00,71.07it/s] 88%|########8 |152986/173481[39:12<04:48,71.07it/s] 96%|#########5|166017/173481[42:00<01:40,73.94it/s] 96%|#########6|166862/173481[42:12<01:29,73.94it/s]100%|##########|173481/173481[43:47<00:00,66.02it/s]
[32m[0323 18:34:18 @base.py:257][0m Epoch 11 (global_step 1734810) finished, time:2627.60 sec.
[32m[0323 18:34:18 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-1734810.
[32m[0323 18:34:19 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.12it/s]
9
[32m[0323 18:36:06 @monitor.py:363][0m QueueInput/queue_size: 0.44263
[32m[0323 18:36:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 28.17
[32m[0323 18:36:06 @monitor.py:363][0m activation-summaries/output-rms: 0.041402
[32m[0323 18:36:06 @monitor.py:363][0m cross_entropy_loss: 1.6277
[32m[0323 18:36:06 @monitor.py:363][0m lr: 0.000125
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.43055
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2547
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.27105
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.29266
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.25879
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25057
[32m[0323 18:36:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 18:36:06 @monitor.py:363][0m train-error-top1: 0.43833
[32m[0323 18:36:06 @monitor.py:363][0m val-error-top1: 0.44979
[32m[0323 18:36:06 @monitor.py:363][0m val-utt-error: 0.11131
[32m[0323 18:36:06 @monitor.py:363][0m validation_cost: 1.6948
[32m[0323 18:36:06 @monitor.py:363][0m wd_cost: 0.036021
[32m[0323 18:36:06 @group.py:42][0m Callbacks took 107.912 sec in total. InferenceRunner: 106.881sec
[32m[0323 18:36:06 @base.py:247][0m Start Epoch 12 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12813/173481[03:00<37:37,71.18it/s]  8%|7         |13619/173481[03:10<37:25,71.18it/s] 14%|#4        |25056/173481[06:00<35:33,69.56it/s] 15%|#4        |25704/173481[06:10<35:24,69.56it/s] 20%|#9        |34654/173481[09:00<38:19,60.37it/s] 20%|##        |35165/173481[09:10<38:11,60.37it/s] 25%|##4       |43176/173481[12:00<40:55,53.07it/s] 25%|##5       |43680/173481[12:10<40:46,53.07it/s] 30%|##9       |51756/173481[15:00<40:23,50.22it/s] 30%|###       |52220/173481[15:10<40:14,50.22it/s] 35%|###5      |60861/173481[18:00<37:14,50.40it/s] 35%|###5      |61541/173481[18:11<37:01,50.40it/s] 41%|####      |70524/173481[21:00<33:00,51.99it/s] 41%|####      |71012/173481[21:11<32:51,51.99it/s] 46%|####5     |79626/173481[24:00<30:31,51.26it/s] 46%|####6     |80221/173481[24:11<30:19,51.26it/s] 51%|#####1    |88866/173481[27:00<27:29,51.29it/s] 52%|#####1    |89439/173481[27:11<27:18,51.29it/s] 57%|#####6    |98181/173481[30:00<24:21,51.52it/s] 57%|#####6    |98758/173481[30:11<24:10,51.52it/s] 62%|######1   |107161/173481[33:00<21:48,50.69it/s] 62%|######2   |107769/173481[33:11<21:36,50.69it/s] 68%|######8   |118591/173481[36:00<16:13,56.37it/s] 69%|######8   |119311/173481[36:11<16:00,56.37it/s] 75%|#######4  |129366/173481[39:00<12:39,58.06it/s] 75%|#######5  |130153/173481[39:12<12:26,58.06it/s] 80%|########  |139578/173481[42:00<09:50,57.39it/s] 81%|########  |140215/173481[42:12<09:39,57.39it/s] 86%|########6 |149316/173481[45:00<07:13,55.69it/s] 86%|########6 |150000/173481[45:12<07:01,55.69it/s] 92%|#########1|159151/173481[48:00<04:19,55.16it/s] 92%|#########2|159830/173481[48:12<04:07,55.16it/s] 97%|#########6|168276/173481[51:00<01:38,52.83it/s] 97%|#########7|168885/173481[51:12<01:26,52.83it/s]100%|##########|173481/173481[52:44<00:00,54.82it/s]
[32m[0323 19:28:50 @base.py:257][0m Epoch 12 (global_step 1908291) finished, time:3164.41 sec.
[32m[0323 19:28:50 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-1908291.
[32m[0323 19:28:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:48<00:00,173.90it/s]
10
[32m[0323 19:30:39 @monitor.py:363][0m QueueInput/queue_size: 0.41282
[32m[0323 19:30:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 31.094
[32m[0323 19:30:39 @monitor.py:363][0m activation-summaries/output-rms: 0.041465
[32m[0323 19:30:39 @monitor.py:363][0m cross_entropy_loss: 1.5951
[32m[0323 19:30:39 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.46521
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2613
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.28624
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30116
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.26693
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.25895
[32m[0323 19:30:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 19:30:39 @monitor.py:363][0m train-error-top1: 0.42569
[32m[0323 19:30:39 @monitor.py:363][0m val-error-top1: 0.43814
[32m[0323 19:30:39 @monitor.py:363][0m val-utt-error: 0.10265
[32m[0323 19:30:39 @monitor.py:363][0m validation_cost: 1.6398
[32m[0323 19:30:39 @monitor.py:363][0m wd_cost: 0.040089
[32m[0323 19:30:39 @group.py:42][0m Callbacks took 108.835 sec in total. InferenceRunner: 108.246sec
[32m[0323 19:30:39 @base.py:247][0m Start Epoch 13 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11515/173481[03:00<42:12,63.95it/s]  7%|6         |12041/173481[03:10<42:04,63.95it/s] 12%|#1        |20710/173481[06:00<44:50,56.79it/s] 12%|#2        |21281/173481[06:10<44:40,56.79it/s] 17%|#7        |30112/173481[09:00<43:54,54.41it/s] 18%|#7        |30640/173481[09:10<43:45,54.41it/s] 22%|##2       |38873/173481[12:00<43:39,51.38it/s] 23%|##2       |39396/173481[12:10<43:29,51.38it/s] 27%|##7       |47475/173481[15:00<42:24,49.52it/s] 28%|##7       |47999/173481[15:10<42:13,49.52it/s] 32%|###2      |56214/173481[18:00<39:51,49.03it/s] 33%|###2      |56780/173481[18:11<39:40,49.03it/s] 38%|###7      |65325/173481[21:00<36:11,49.80it/s] 38%|###7      |65884/173481[21:11<36:00,49.80it/s] 43%|####3     |74690/173481[24:00<32:21,50.89it/s] 43%|####3     |75268/173481[24:11<32:09,50.89it/s] 49%|####8     |84235/173481[27:00<28:38,51.94it/s] 49%|####8     |84843/173481[27:11<28:26,51.94it/s] 54%|#####3    |93640/173481[30:00<25:32,52.09it/s] 54%|#####4    |94234/173481[30:11<25:21,52.09it/s] 60%|#####9    |103272/173481[33:00<22:09,52.79it/s] 60%|#####9    |103879/173481[33:11<21:58,52.79it/s] 65%|######5   |112795/173481[36:00<19:08,52.85it/s] 65%|######5   |113429/173481[36:11<18:56,52.85it/s] 70%|#######   |122205/173481[39:00<16:15,52.55it/s] 71%|#######   |122851/173481[39:12<16:03,52.55it/s] 76%|#######5  |131655/173481[42:00<13:16,52.52it/s] 76%|#######6  |132240/173481[42:12<13:05,52.52it/s] 82%|########1 |142240/173481[45:00<09:23,55.48it/s] 82%|########2 |142979/173481[45:12<09:09,55.48it/s] 89%|########8 |153535/173481[48:00<05:38,58.89it/s] 89%|########8 |154293/173481[48:12<05:25,58.89it/s] 94%|#########4|163842/173481[51:00<02:46,58.06it/s] 95%|#########5|165001/173481[51:12<02:26,58.06it/s]100%|##########|173481/173481[52:50<00:00,54.72it/s]
[32m[0323 20:23:29 @base.py:257][0m Epoch 13 (global_step 2081772) finished, time:3170.46 sec.
[32m[0323 20:23:30 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-2081772.
[32m[0323 20:23:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:39<00:00,188.90it/s]
11
[32m[0323 20:25:10 @monitor.py:363][0m QueueInput/queue_size: 0.56714
[32m[0323 20:25:10 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 34.26
[32m[0323 20:25:10 @monitor.py:363][0m activation-summaries/output-rms: 0.041202
[32m[0323 20:25:10 @monitor.py:363][0m cross_entropy_loss: 1.5905
[32m[0323 20:25:10 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.48886
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2659
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/linear0/W-rms: 0.29863
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/linear1/W-rms: 0.30657
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27055
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26241
[32m[0323 20:25:10 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 20:25:10 @monitor.py:363][0m train-error-top1: 0.42186
[32m[0323 20:25:10 @monitor.py:363][0m val-error-top1: 0.43468
[32m[0323 20:25:10 @monitor.py:363][0m val-utt-error: 0.10259
[32m[0323 20:25:10 @monitor.py:363][0m validation_cost: 1.6283
[32m[0323 20:25:10 @monitor.py:363][0m wd_cost: 0.0086238
[32m[0323 20:25:10 @group.py:42][0m Callbacks took 100.436 sec in total. InferenceRunner: 99.651sec
[32m[0323 20:25:10 @base.py:247][0m Start Epoch 14 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12774/173481[03:00<37:44,70.96it/s]  8%|7         |13436/173481[03:10<37:35,70.96it/s] 14%|#3        |23833/173481[06:00<37:52,65.86it/s] 14%|#4        |24313/173481[06:10<37:44,65.86it/s] 19%|#8        |32659/173481[09:00<41:45,56.21it/s] 19%|#9        |33153/173481[09:10<41:36,56.21it/s] 24%|##4       |41804/173481[12:00<41:07,53.37it/s] 24%|##4       |42348/173481[12:10<40:57,53.37it/s] 29%|##9       |51009/173481[15:00<39:04,52.23it/s] 30%|##9       |51577/173481[15:10<38:54,52.23it/s] 35%|###4      |60620/173481[18:00<35:37,52.80it/s] 35%|###5      |61223/173481[18:10<35:25,52.80it/s] 41%|####      |71018/173481[21:00<30:57,55.17it/s] 41%|####1     |71712/173481[21:11<30:44,55.17it/s] 47%|####7     |81646/173481[24:00<26:49,57.04it/s] 47%|####7     |82268/173481[24:11<26:39,57.04it/s] 53%|#####2    |91659/173481[27:00<24:12,56.32it/s] 53%|#####3    |92181/173481[27:11<24:03,56.32it/s] 59%|#####8    |101517/173481[30:00<21:35,55.53it/s] 59%|#####8    |102098/173481[30:11<21:25,55.53it/s] 64%|######4   |111464/173481[33:00<18:39,55.39it/s] 65%|######4   |112141/173481[33:11<18:27,55.39it/s] 70%|#######   |121717/173481[36:00<15:21,56.17it/s] 71%|#######   |122383/173481[36:11<15:09,56.17it/s] 76%|#######6  |132053/173481[39:00<12:09,56.78it/s] 77%|#######6  |132833/173481[39:12<11:55,56.78it/s] 83%|########2 |143305/173481[42:00<08:27,59.51it/s] 83%|########3 |144017/173481[42:12<08:15,59.51it/s] 89%|########8 |154375/173481[45:00<05:15,60.49it/s] 89%|########9 |155129/173481[45:12<05:03,60.49it/s] 95%|#########4|164799/173481[48:00<02:26,59.17it/s] 95%|#########5|165503/173481[48:12<02:14,59.17it/s]100%|##########|173481/173481[50:25<00:00,57.34it/s]
[32m[0323 21:15:35 @base.py:257][0m Epoch 14 (global_step 2255253) finished, time:3025.73 sec.
[32m[0323 21:15:36 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-2255253.
[32m[0323 21:15:36 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:41<00:00,185.75it/s]
12
[32m[0323 21:17:17 @monitor.py:363][0m QueueInput/queue_size: 0.060977
[32m[0323 21:17:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 36.269
[32m[0323 21:17:17 @monitor.py:363][0m activation-summaries/output-rms: 0.04148
[32m[0323 21:17:17 @monitor.py:363][0m cross_entropy_loss: 1.5946
[32m[0323 21:17:17 @monitor.py:363][0m lr: 6.25e-05
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.51195
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.27
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.30969
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31176
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27424
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088421
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.2661
[32m[0323 21:17:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088455
[32m[0323 21:17:17 @monitor.py:363][0m train-error-top1: 0.43563
[32m[0323 21:17:17 @monitor.py:363][0m val-error-top1: 0.43425
[32m[0323 21:17:17 @monitor.py:363][0m val-utt-error: 0.10047
[32m[0323 21:17:17 @monitor.py:363][0m validation_cost: 1.6226
[32m[0323 21:17:17 @monitor.py:363][0m wd_cost: 0.0092162
[32m[0323 21:17:17 @group.py:42][0m Callbacks took 101.887 sec in total. InferenceRunner: 101.340sec
[32m[0323 21:17:17 @base.py:247][0m Start Epoch 15 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |12033/173481[03:00<40:15,66.84it/s]  7%|7         |12657/173481[03:10<40:06,66.84it/s] 12%|#2        |21333/173481[06:00<43:31,58.26it/s] 13%|#2        |21937/173481[06:10<43:21,58.26it/s] 18%|#8        |32047/173481[09:00<40:01,58.88it/s] 19%|#8        |32712/173481[09:10<39:50,58.88it/s] 25%|##4       |43168/173481[12:00<36:01,60.29it/s] 25%|##5       |43852/173481[12:10<35:50,60.29it/s] 31%|###1      |54128/173481[15:00<32:50,60.58it/s] 32%|###1      |54757/173481[15:10<32:39,60.58it/s] 38%|###7      |65588/173481[18:00<28:57,62.08it/s] 38%|###8      |66314/173481[18:11<28:46,62.08it/s] 45%|####4     |77543/173481[21:00<24:54,64.18it/s] 45%|####5     |78248/173481[21:11<24:43,64.18it/s] 52%|#####1    |89598/173481[24:00<21:19,65.54it/s] 52%|#####2    |90388/173481[24:11<21:07,65.54it/s] 59%|#####8    |101618/173481[27:00<18:06,66.15it/s] 59%|#####8    |102346/173481[27:11<17:55,66.15it/s] 65%|######5   |113142/173481[30:00<15:27,65.07it/s] 66%|######5   |113892/173481[30:11<15:15,65.07it/s] 72%|#######1  |124747/173481[33:00<12:32,64.77it/s] 72%|#######2  |125467/173481[33:11<12:21,64.77it/s] 79%|#######8  |136368/173481[36:00<09:33,64.66it/s] 79%|#######9  |137092/173481[36:11<09:22,64.66it/s] 85%|########4 |147126/173481[39:00<07:04,62.12it/s] 85%|########5 |147845/173481[39:12<06:52,62.12it/s] 92%|#########1|158793/173481[42:00<03:51,63.43it/s] 92%|#########2|159605/173481[42:12<03:38,63.43it/s] 98%|#########7|169489/173481[45:00<01:05,61.36it/s] 98%|#########8|170152/173481[45:12<00:54,61.36it/s]100%|##########|173481/173481[46:11<00:00,62.60it/s]
[32m[0323 22:03:29 @base.py:257][0m Epoch 15 (global_step 2428734) finished, time:2771.46 sec.
[32m[0323 22:03:29 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-2428734.
[32m[0323 22:03:29 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:46<00:00,176.22it/s]
13
[32m[0323 22:05:16 @monitor.py:363][0m QueueInput/queue_size: 0.14702
[32m[0323 22:05:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 38.272
[32m[0323 22:05:16 @monitor.py:363][0m activation-summaries/output-rms: 0.041378
[32m[0323 22:05:16 @monitor.py:363][0m cross_entropy_loss: 1.5698
[32m[0323 22:05:16 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.53066
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.273
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.31729
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31521
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27674
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26853
[32m[0323 22:05:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0323 22:05:16 @monitor.py:363][0m train-error-top1: 0.43395
[32m[0323 22:05:16 @monitor.py:363][0m val-error-top1: 0.42803
[32m[0323 22:05:16 @monitor.py:363][0m val-utt-error: 0.098183
[32m[0323 22:05:16 @monitor.py:363][0m validation_cost: 1.5997
[32m[0323 22:05:16 @monitor.py:363][0m wd_cost: 0.0019332
[32m[0323 22:05:16 @group.py:42][0m Callbacks took 107.459 sec in total. InferenceRunner: 106.824sec
[32m[0323 22:05:16 @base.py:247][0m Start Epoch 16 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13518/173481[03:00<35:30,75.10it/s]  8%|8         |14219/173481[03:10<35:20,75.10it/s] 14%|#3        |24172/173481[06:00<37:35,66.20it/s] 14%|#4        |24692/173481[06:10<37:27,66.20it/s] 19%|#9        |33490/173481[09:00<40:09,58.10it/s] 20%|#9        |34110/173481[09:10<39:58,58.10it/s] 25%|##5       |44057/173481[12:00<36:56,58.39it/s] 26%|##5       |44711/173481[12:10<36:45,58.39it/s] 31%|###1      |54335/173481[15:00<34:23,57.74it/s] 32%|###1      |54806/173481[15:10<34:15,57.74it/s] 36%|###6      |62759/173481[18:00<35:41,51.70it/s] 37%|###6      |63466/173481[18:10<35:28,51.70it/s] 42%|####2     |73695/173481[21:00<29:46,55.86it/s] 43%|####2     |74327/173481[21:11<29:35,55.86it/s] 49%|####8     |84197/173481[24:00<26:04,57.07it/s] 49%|####8     |84886/173481[24:11<25:52,57.07it/s] 54%|#####3    |93627/173481[27:00<24:21,54.62it/s] 54%|#####4    |94158/173481[27:11<24:12,54.62it/s] 59%|#####8    |102292/173481[30:00<23:11,51.18it/s] 59%|#####9    |102921/173481[30:11<22:58,51.18it/s] 65%|######5   |113502/173481[33:00<17:47,56.18it/s] 66%|######5   |114221/173481[33:11<17:34,56.18it/s] 72%|#######1  |124792/173481[36:00<13:41,59.27it/s] 72%|#######2  |125404/173481[36:11<13:31,59.27it/s] 78%|#######7  |134507/173481[39:00<11:29,56.49it/s] 78%|#######7  |135186/173481[39:12<11:17,56.49it/s] 83%|########3 |144342/173481[42:00<08:44,55.55it/s] 84%|########3 |145016/173481[42:12<08:32,55.55it/s] 89%|########9 |154994/173481[45:00<05:22,57.30it/s] 90%|########9 |155684/173481[45:12<05:10,57.30it/s] 95%|#########5|165094/173481[48:00<02:27,56.70it/s] 96%|#########5|165706/173481[48:12<02:17,56.70it/s][32m[0323 22:55:35 @base.py:257][0m Epoch 16 (global_step 2602215) finished, time:3018.28 sec.
100%|##########|173481/173481[50:18<00:00,57.48it/s]
[32m[0323 22:55:35 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-2602215.
[32m[0323 22:55:35 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:13<00:00,140.65it/s]
14
[32m[0323 22:57:49 @monitor.py:363][0m QueueInput/queue_size: 0.31842
[32m[0323 22:57:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 39.945
[32m[0323 22:57:49 @monitor.py:363][0m activation-summaries/output-rms: 0.042211
[32m[0323 22:57:49 @monitor.py:363][0m cross_entropy_loss: 1.5494
[32m[0323 22:57:49 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.54324
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2752
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32196
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31728
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27794
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.26962
[32m[0323 22:57:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0323 22:57:49 @monitor.py:363][0m train-error-top1: 0.41775
[32m[0323 22:57:49 @monitor.py:363][0m val-error-top1: 0.42726
[32m[0323 22:57:49 @monitor.py:363][0m val-utt-error: 0.10004
[32m[0323 22:57:49 @monitor.py:363][0m validation_cost: 1.5968
[32m[0323 22:57:49 @monitor.py:363][0m wd_cost: 0.0019912
[32m[0323 22:57:49 @group.py:42][0m Callbacks took 134.474 sec in total. InferenceRunner: 133.862sec
[32m[0323 22:57:49 @base.py:247][0m Start Epoch 17 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15191/173481[03:00<31:15,84.39it/s]  9%|9         |15810/173481[03:10<31:08,84.39it/s] 16%|#5        |27481/173481[06:00<32:14,75.47it/s] 16%|#6        |28150/173481[06:10<32:05,75.47it/s] 22%|##1       |38081/173481[09:00<34:07,66.14it/s] 22%|##2       |38485/173481[09:10<34:00,66.14it/s] 28%|##8       |48845/173481[12:00<33:04,62.81it/s] 28%|##8       |49428/173481[12:10<32:55,62.81it/s] 34%|###4      |59464/173481[15:00<31:14,60.84it/s] 35%|###4      |60091/173481[15:10<31:03,60.84it/s] 40%|####      |69876/173481[18:00<29:08,59.26it/s] 40%|####      |70067/173481[18:10<29:05,59.26it/s] 47%|####6     |81443/173481[21:00<24:52,61.66it/s] 47%|####7     |82208/173481[21:11<24:40,61.66it/s] 54%|#####4    |93829/173481[24:00<20:24,65.04it/s] 55%|#####4    |94573/173481[24:11<20:13,65.04it/s] 61%|######    |105716/173481[27:00<17:14,65.53it/s] 61%|######1   |106459/173481[27:11<17:02,65.53it/s] 68%|######8   |118625/173481[30:00<13:21,68.48it/s] 69%|######8   |119391/173481[30:11<13:09,68.48it/s] 75%|#######5  |130274/173481[33:00<10:49,66.54it/s] 75%|#######5  |130960/173481[33:11<10:38,66.54it/s] 81%|########1 |141346/173481[36:00<08:22,63.93it/s] 82%|########1 |142055/173481[36:11<08:11,63.93it/s] 88%|########7 |151931/173481[39:00<05:51,61.25it/s] 88%|########7 |152575/173481[39:12<05:41,61.25it/s] 94%|#########4|163765/173481[42:00<02:33,63.42it/s] 95%|#########5|165137/173481[42:12<02:11,63.42it/s]100%|##########|173481/173481[44:21<00:00,65.17it/s]
[32m[0323 23:42:11 @base.py:257][0m Epoch 17 (global_step 2775696) finished, time:2661.92 sec.
[32m[0323 23:42:11 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-2775696.
[32m[0323 23:42:11 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,149.68it/s]
15
[32m[0323 23:44:17 @monitor.py:363][0m QueueInput/queue_size: 0.43028
[32m[0323 23:44:17 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 41.256
[32m[0323 23:44:17 @monitor.py:363][0m activation-summaries/output-rms: 0.04189
[32m[0323 23:44:17 @monitor.py:363][0m cross_entropy_loss: 1.5614
[32m[0323 23:44:17 @monitor.py:363][0m lr: 3.125e-05
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.55547
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2771
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32623
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/linear1/W-rms: 0.31916
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27909
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27065
[32m[0323 23:44:17 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0323 23:44:17 @monitor.py:363][0m train-error-top1: 0.41868
[32m[0323 23:44:17 @monitor.py:363][0m val-error-top1: 0.4265
[32m[0323 23:44:17 @monitor.py:363][0m val-utt-error: 0.095686
[32m[0323 23:44:17 @monitor.py:363][0m validation_cost: 1.5922
[32m[0323 23:44:17 @monitor.py:363][0m wd_cost: 0.002047
[32m[0323 23:44:17 @group.py:42][0m Callbacks took 126.255 sec in total. InferenceRunner: 125.767sec
[32m[0323 23:44:17 @base.py:247][0m Start Epoch 18 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14536/173481[03:00<32:48,80.75it/s]  9%|8         |15194/173481[03:10<32:40,80.75it/s] 15%|#5        |26623/173481[06:00<33:22,73.33it/s] 16%|#5        |27255/173481[06:10<33:14,73.33it/s] 22%|##2       |38952/173481[09:00<31:39,70.83it/s] 23%|##2       |39620/173481[09:10<31:29,70.83it/s] 29%|##9       |50592/173481[12:00<30:17,67.60it/s] 30%|##9       |51264/173481[12:10<30:07,67.60it/s] 37%|###7      |64590/173481[15:00<25:05,72.33it/s] 38%|###7      |65264/173481[15:10<24:56,72.33it/s] 45%|####5     |78427/173481[18:00<21:15,74.53it/s] 46%|####5     |79418/173481[18:10<21:02,74.53it/s] 54%|#####3    |93380/173481[21:00<16:59,78.57it/s] 54%|#####4    |94056/173481[21:11<16:50,78.57it/s] 62%|######1   |107295/173481[24:00<14:09,77.92it/s] 62%|######2   |108031/173481[24:11<13:59,77.92it/s] 70%|#######   |121548/173481[27:00<11:01,78.54it/s] 71%|#######   |122473/173481[27:11<10:49,78.54it/s] 77%|#######7  |134065/173481[30:00<08:54,73.75it/s] 78%|#######7  |134729/173481[30:11<08:45,73.75it/s] 84%|########4 |146174/173481[33:00<06:28,70.36it/s] 85%|########4 |146902/173481[33:11<06:17,70.36it/s] 91%|######### |157521/173481[36:00<04:00,66.50it/s] 91%|#########1|158267/173481[36:11<03:48,66.50it/s] 97%|#########7|168835/173481[39:00<01:11,64.62it/s] 98%|#########7|169537/173481[39:12<01:01,64.62it/s]100%|##########|173481/173481[40:19<00:00,71.70it/s]
[32m[0324 00:24:37 @base.py:257][0m Epoch 18 (global_step 2949177) finished, time:2419.65 sec.
[32m[0324 00:24:37 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-2949177.
[32m[0324 00:24:37 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.71it/s]
16
[32m[0324 00:26:38 @monitor.py:363][0m QueueInput/queue_size: 0.24527
[32m[0324 00:26:38 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 42.558
[32m[0324 00:26:38 @monitor.py:363][0m activation-summaries/output-rms: 0.041683
[32m[0324 00:26:38 @monitor.py:363][0m cross_entropy_loss: 1.5473
[32m[0324 00:26:38 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56351
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2784
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/linear0/W-rms: 0.32869
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3202
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/linear2/W-rms: 0.27964
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27114
[32m[0324 00:26:38 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 00:26:38 @monitor.py:363][0m train-error-top1: 0.41545
[32m[0324 00:26:38 @monitor.py:363][0m val-error-top1: 0.42335
[32m[0324 00:26:38 @monitor.py:363][0m val-utt-error: 0.095952
[32m[0324 00:26:38 @monitor.py:363][0m validation_cost: 1.5811
[32m[0324 00:26:38 @monitor.py:363][0m wd_cost: 0.00041631
[32m[0324 00:26:38 @group.py:42][0m Callbacks took 120.696 sec in total. InferenceRunner: 120.124sec
[32m[0324 00:26:38 @base.py:247][0m Start Epoch 19 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14193/173481[03:00<33:40,78.85it/s]  9%|8         |14858/173481[03:10<33:31,78.85it/s] 15%|#4        |25681/173481[06:00<34:55,70.54it/s] 15%|#5        |26237/173481[06:10<34:47,70.54it/s] 21%|##        |35579/173481[09:00<37:11,61.80it/s] 21%|##        |36210/173481[09:10<37:01,61.80it/s] 26%|##6       |45818/173481[12:00<35:55,59.24it/s] 27%|##6       |46393/173481[12:10<35:45,59.24it/s] 32%|###1      |55444/173481[15:00<35:00,56.20it/s] 32%|###2      |56018/173481[15:10<34:49,56.20it/s] 38%|###7      |65571/173481[18:00<31:59,56.23it/s] 38%|###8      |66263/173481[18:10<31:46,56.23it/s] 44%|####4     |76720/173481[21:00<27:21,58.95it/s] 45%|####4     |77367/173481[21:11<27:10,58.95it/s] 51%|#####     |87707/173481[24:00<23:50,59.97it/s] 51%|#####     |88441/173481[24:11<23:37,59.97it/s] 57%|#####6    |98578/173481[27:00<20:44,60.18it/s] 57%|#####7    |99257/173481[27:11<20:33,60.18it/s] 63%|######3   |109479/173481[30:00<17:40,60.36it/s] 63%|######3   |110108/173481[30:11<17:29,60.36it/s] 70%|######9   |120942/173481[33:00<14:07,61.98it/s] 70%|#######   |121613/173481[33:11<13:56,61.98it/s] 76%|#######5  |131754/173481[36:00<11:24,61.00it/s] 76%|#######6  |132428/173481[36:11<11:13,61.00it/s] 82%|########2 |142599/173481[39:00<08:29,60.62it/s] 83%|########2 |143313/173481[39:12<08:17,60.62it/s] 89%|########8 |153704/173481[42:00<05:23,61.15it/s] 89%|########9 |154463/173481[42:12<05:11,61.15it/s] 95%|#########5|165089/173481[45:00<02:14,62.17it/s] 96%|#########5|165840/173481[45:12<02:02,62.17it/s]100%|##########|173481/173481[47:19<00:00,61.11it/s]
[32m[0324 01:13:57 @base.py:257][0m Epoch 19 (global_step 3122658) finished, time:2839.05 sec.
[32m[0324 01:13:57 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-3122658.
[32m[0324 01:13:57 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.52it/s]
17
[32m[0324 01:15:57 @monitor.py:363][0m QueueInput/queue_size: 0.22322
[32m[0324 01:15:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 43.165
[32m[0324 01:15:57 @monitor.py:363][0m activation-summaries/output-rms: 0.041882
[32m[0324 01:15:57 @monitor.py:363][0m cross_entropy_loss: 1.5529
[32m[0324 01:15:57 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.56997
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2794
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33046
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32093
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28002
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27147
[32m[0324 01:15:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 01:15:57 @monitor.py:363][0m train-error-top1: 0.42776
[32m[0324 01:15:57 @monitor.py:363][0m val-error-top1: 0.42328
[32m[0324 01:15:57 @monitor.py:363][0m val-utt-error: 0.094623
[32m[0324 01:15:57 @monitor.py:363][0m validation_cost: 1.578
[32m[0324 01:15:57 @monitor.py:363][0m wd_cost: 0.00042165
[32m[0324 01:15:57 @group.py:42][0m Callbacks took 120.312 sec in total. InferenceRunner: 119.518sec
[32m[0324 01:15:57 @base.py:247][0m Start Epoch 20 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14297/173481[03:00<33:24,79.43it/s]  9%|8         |14923/173481[03:10<33:16,79.43it/s] 14%|#3        |24273/173481[06:00<38:05,65.29it/s] 14%|#4        |24757/173481[06:10<37:58,65.29it/s] 20%|#9        |34519/173481[09:00<38:04,60.82it/s] 20%|##        |35147/173481[09:10<37:54,60.82it/s] 26%|##6       |45343/173481[12:00<35:18,60.47it/s] 27%|##6       |46006/173481[12:10<35:07,60.47it/s] 32%|###2      |55807/173481[15:00<33:05,59.28it/s] 32%|###2      |56317/173481[15:10<32:56,59.28it/s] 38%|###8      |66567/173481[18:00<29:56,59.52it/s] 39%|###8      |67268/173481[18:10<29:44,59.52it/s] 45%|####4     |77328/173481[21:00<26:52,59.64it/s] 45%|####4     |77942/173481[21:11<26:41,59.64it/s] 50%|#####     |87423/173481[24:00<24:48,57.80it/s] 51%|#####     |88037/173481[24:11<24:38,57.80it/s] 56%|#####6    |97218/173481[27:00<22:40,56.06it/s] 56%|#####6    |97822/173481[27:11<22:29,56.06it/s] 62%|######2   |107618/173481[30:00<19:17,56.89it/s] 62%|######2   |108289/173481[30:11<19:05,56.89it/s] 68%|######8   |118438/173481[33:00<15:41,58.46it/s] 69%|######8   |119092/173481[33:11<15:30,58.46it/s] 74%|#######4  |128708/173481[36:00<12:55,57.75it/s] 75%|#######4  |129312/173481[36:11<12:44,57.75it/s] 80%|########  |138954/173481[39:00<10:02,57.33it/s] 81%|########  |139882/173481[39:12<09:46,57.33it/s] 91%|#########1|157949/173481[42:00<03:29,74.30it/s] 92%|#########1|159415/173481[42:12<03:09,74.30it/s]100%|##########|173481/173481[44:12<00:00,65.41it/s]
[32m[0324 02:00:09 @base.py:257][0m Epoch 20 (global_step 3296139) finished, time:2652.10 sec.
[32m[0324 02:00:09 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-3296139.
[32m[0324 02:00:09 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:55<00:00,163.22it/s]
18
[32m[0324 02:02:05 @monitor.py:363][0m QueueInput/queue_size: 49.936
[32m[0324 02:02:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.199
[32m[0324 02:02:05 @monitor.py:363][0m activation-summaries/output-rms: 0.042332
[32m[0324 02:02:05 @monitor.py:363][0m cross_entropy_loss: 1.5377
[32m[0324 02:02:05 @monitor.py:363][0m lr: 1.5625e-05
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57623
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2803
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33213
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32162
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28036
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27175
[32m[0324 02:02:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 02:02:05 @monitor.py:363][0m train-error-top1: 0.41037
[32m[0324 02:02:05 @monitor.py:363][0m val-error-top1: 0.42245
[32m[0324 02:02:05 @monitor.py:363][0m val-utt-error: 0.095633
[32m[0324 02:02:05 @monitor.py:363][0m validation_cost: 1.578
[32m[0324 02:02:05 @monitor.py:363][0m wd_cost: 0.00042678
[32m[0324 02:02:05 @group.py:42][0m Callbacks took 115.748 sec in total. InferenceRunner: 115.333sec
[32m[0324 02:02:05 @base.py:247][0m Start Epoch 21 ...
  0%|          |0/173481[00:00<?,?it/s] 12%|#2        |21486/173481[03:00<21:13,119.36it/s] 13%|#3        |22677/173481[03:10<21:03,119.36it/s] 24%|##4       |41888/173481[06:00<18:51,116.27it/s] 25%|##4       |42520/173481[06:10<18:46,116.27it/s] 32%|###2      |55965/173481[09:00<20:56,93.51it/s]  33%|###2      |56863/173481[09:10<20:47,93.51it/s] 40%|###9      |68808/173481[12:00<21:33,80.94it/s] 40%|####      |69456/173481[12:10<21:25,80.94it/s] 46%|####6     |79836/173481[15:00<22:22,69.74it/s] 46%|####6     |80481/173481[15:10<22:13,69.74it/s] 52%|#####2    |90357/173481[18:00<21:47,63.60it/s] 52%|#####2    |91013/173481[18:10<21:36,63.60it/s] 58%|#####8    |101005/173481[21:00<19:42,61.29it/s] 59%|#####8    |101689/173481[21:11<19:31,61.29it/s] 64%|######4   |111888/173481[24:00<16:51,60.87it/s] 65%|######4   |112569/173481[24:11<16:40,60.87it/s] 71%|#######   |122770/173481[27:00<13:55,60.66it/s] 71%|#######1  |123425/173481[27:11<13:45,60.66it/s] 77%|#######7  |133866/173481[30:00<10:47,61.15it/s] 78%|#######7  |134580/173481[30:11<10:36,61.15it/s] 83%|########3 |144702/173481[33:00<07:54,60.67it/s] 84%|########3 |145419/173481[33:11<07:42,60.67it/s] 90%|########9 |155901/173481[36:00<04:46,61.43it/s] 90%|######### |156611/173481[36:11<04:34,61.43it/s] 96%|#########5|166507/173481[39:00<01:55,60.14it/s] 96%|#########6|167226/173481[39:12<01:44,60.14it/s]100%|##########|173481/173481[40:55<00:00,70.65it/s]
[32m[0324 02:43:00 @base.py:257][0m Epoch 21 (global_step 3469620) finished, time:2455.47 sec.
[32m[0324 02:43:00 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-3469620.
[32m[0324 02:43:01 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.39it/s]
19
[32m[0324 02:45:02 @monitor.py:363][0m QueueInput/queue_size: 0.10136
[32m[0324 02:45:02 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.491
[32m[0324 02:45:02 @monitor.py:363][0m activation-summaries/output-rms: 0.042414
[32m[0324 02:45:02 @monitor.py:363][0m cross_entropy_loss: 1.5317
[32m[0324 02:45:02 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.57945
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2809
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3329
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3219
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28048
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27184
[32m[0324 02:45:02 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 02:45:02 @monitor.py:363][0m train-error-top1: 0.41333
[32m[0324 02:45:02 @monitor.py:363][0m val-error-top1: 0.42174
[32m[0324 02:45:02 @monitor.py:363][0m val-utt-error: 0.096058
[32m[0324 02:45:02 @monitor.py:363][0m validation_cost: 1.5731
[32m[0324 02:45:02 @monitor.py:363][0m wd_cost: 8.5862e-05
[32m[0324 02:45:02 @group.py:42][0m Callbacks took 121.446 sec in total. InferenceRunner: 120.364sec
[32m[0324 02:45:02 @base.py:247][0m Start Epoch 22 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12163/173481[03:00<39:47,67.57it/s]  7%|7         |12780/173481[03:10<39:38,67.57it/s] 13%|#3        |22571/173481[06:00<40:21,62.31it/s] 13%|#3        |23165/173481[06:10<40:12,62.31it/s] 19%|#9        |33051/173481[09:00<38:52,60.20it/s] 19%|#9        |33680/173481[09:10<38:42,60.20it/s] 25%|##5       |43942/173481[12:00<35:46,60.35it/s] 26%|##5       |44565/173481[12:10<35:36,60.35it/s] 31%|###1      |54416/173481[15:00<33:29,59.25it/s] 32%|###1      |55076/173481[15:10<33:18,59.25it/s] 38%|###7      |65156/173481[18:00<30:22,59.45it/s] 38%|###7      |65775/173481[18:10<30:11,59.45it/s] 44%|####3     |75766/173481[21:00<27:30,59.19it/s] 44%|####4     |76455/173481[21:11<27:19,59.19it/s] 50%|#####     |86828/173481[24:00<23:56,60.30it/s] 50%|#####     |87517/173481[24:11<23:45,60.30it/s] 57%|#####6    |98106/173481[27:00<20:26,61.46it/s] 57%|#####6    |98800/173481[27:11<20:15,61.46it/s] 63%|######2   |109015/173481[30:00<17:36,61.03it/s] 63%|######3   |109728/173481[30:11<17:24,61.03it/s] 69%|######9   |120244/173481[33:00<14:22,61.70it/s] 70%|######9   |120936/173481[33:11<14:11,61.70it/s] 76%|#######5  |131302/173481[36:00<11:25,61.56it/s] 76%|#######6  |132015/173481[36:11<11:13,61.56it/s] 82%|########2 |142415/173481[39:00<08:23,61.65it/s] 83%|########2 |143180/173481[39:12<08:11,61.65it/s] 88%|########8 |153221/173481[42:00<05:33,60.82it/s] 89%|########8 |153916/173481[42:12<05:21,60.82it/s] 95%|#########5|165319/173481[45:00<02:07,63.86it/s] 96%|#########5|166200/173481[45:12<01:54,63.86it/s]100%|##########|173481/173481[47:05<00:00,61.40it/s]
[32m[0324 03:32:07 @base.py:257][0m Epoch 22 (global_step 3643101) finished, time:2825.60 sec.
[32m[0324 03:32:08 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-3643101.
[32m[0324 03:32:08 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,140.09it/s]
20
[32m[0324 03:34:22 @monitor.py:363][0m QueueInput/queue_size: 0.077151
[32m[0324 03:34:22 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 44.802
[32m[0324 03:34:22 @monitor.py:363][0m activation-summaries/output-rms: 0.042062
[32m[0324 03:34:22 @monitor.py:363][0m cross_entropy_loss: 1.5443
[32m[0324 03:34:22 @monitor.py:363][0m lr: 7.8125e-06
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58287
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2814
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33365
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32219
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28061
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27194
[32m[0324 03:34:22 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 03:34:22 @monitor.py:363][0m train-error-top1: 0.41647
[32m[0324 03:34:22 @monitor.py:363][0m val-error-top1: 0.42145
[32m[0324 03:34:22 @monitor.py:363][0m val-utt-error: 0.094305
[32m[0324 03:34:22 @monitor.py:363][0m validation_cost: 1.5711
[32m[0324 03:34:22 @monitor.py:363][0m wd_cost: 8.6382e-05
[32m[0324 03:34:22 @group.py:42][0m Callbacks took 134.978 sec in total. InferenceRunner: 134.381sec
[32m[0324 03:34:22 @base.py:247][0m Start Epoch 23 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15354/173481[03:00<30:53,85.30it/s]  9%|9         |16005/173481[03:10<30:46,85.30it/s] 16%|#5        |26959/173481[06:00<33:15,73.44it/s] 16%|#5        |27416/173481[06:10<33:09,73.44it/s] 22%|##1       |37416/173481[09:00<34:57,64.87it/s] 22%|##1       |38007/173481[09:10<34:48,64.87it/s] 27%|##7       |47698/173481[12:00<34:30,60.75it/s] 28%|##7       |48377/173481[12:10<34:19,60.75it/s] 34%|###4      |59434/173481[15:00<30:13,62.89it/s] 35%|###4      |60189/173481[15:10<30:01,62.89it/s] 41%|####1     |71215/173481[18:00<26:34,64.14it/s] 41%|####1     |71903/173481[18:10<26:23,64.14it/s] 47%|####7     |82195/173481[21:00<24:19,62.53it/s] 48%|####7     |82844/173481[21:11<24:09,62.53it/s] 54%|#####3    |93324/173481[24:00<21:29,62.18it/s] 54%|#####4    |94032/173481[24:11<21:17,62.18it/s] 60%|######    |104724/173481[27:00<18:15,62.75it/s] 61%|######    |105454/173481[27:11<18:04,62.75it/s] 67%|######7   |116541/173481[30:00<14:47,64.17it/s] 68%|######7   |117272/173481[30:11<14:35,64.17it/s] 74%|#######3  |127865/173481[33:00<11:58,63.52it/s] 74%|#######4  |128594/173481[33:11<11:46,63.52it/s] 80%|########  |139010/173481[36:00<09:09,62.70it/s] 81%|########  |139759/173481[36:11<08:57,62.70it/s] 87%|########6 |150360/173481[39:00<06:07,62.87it/s] 87%|########7 |151139/173481[39:12<05:55,62.87it/s] 93%|#########3|161720/173481[42:00<03:06,62.99it/s] 94%|#########3|162459/173481[42:12<02:54,62.99it/s]100%|#########9|173050/173481[45:00<00:06,62.96it/s]100%|##########|173481/173481[45:07<00:00,64.08it/s]
[32m[0324 04:19:29 @base.py:257][0m Epoch 23 (global_step 3816582) finished, time:2707.05 sec.
[32m[0324 04:19:30 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-3816582.
[32m[0324 04:19:30 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:09<00:00,144.84it/s]
21
[32m[0324 04:21:40 @monitor.py:363][0m QueueInput/queue_size: 0.05291
[32m[0324 04:21:40 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.486
[32m[0324 04:21:40 @monitor.py:363][0m activation-summaries/output-rms: 0.041781
[32m[0324 04:21:40 @monitor.py:363][0m cross_entropy_loss: 1.5355
[32m[0324 04:21:40 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58586
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2818
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33426
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32243
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2807
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27201
[32m[0324 04:21:40 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 04:21:40 @monitor.py:363][0m train-error-top1: 0.4146
[32m[0324 04:21:40 @monitor.py:363][0m val-error-top1: 0.42078
[32m[0324 04:21:40 @monitor.py:363][0m val-utt-error: 0.093614
[32m[0324 04:21:40 @monitor.py:363][0m validation_cost: 1.57
[32m[0324 04:21:40 @monitor.py:363][0m wd_cost: 8.6828e-05
[32m[0324 04:21:40 @group.py:42][0m Callbacks took 130.774 sec in total. InferenceRunner: 129.967sec
[32m[0324 04:21:40 @base.py:247][0m Start Epoch 24 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14926/173481[03:00<31:52,82.92it/s]  9%|9         |16009/173481[03:10<31:39,82.92it/s] 16%|#6        |28505/173481[06:00<30:35,79.00it/s] 17%|#6        |29133/173481[06:10<30:27,79.00it/s] 23%|##2       |39578/173481[09:00<32:15,69.17it/s] 23%|##3       |40242/173481[09:10<32:06,69.17it/s] 29%|##8       |50220/173481[12:00<32:13,63.75it/s] 29%|##9       |50838/173481[12:10<32:03,63.75it/s] 35%|###5      |60975/173481[15:00<30:23,61.68it/s] 36%|###5      |61611/173481[15:10<30:13,61.68it/s] 42%|####1     |72851/173481[18:00<26:18,63.76it/s] 42%|####2     |73566/173481[18:11<26:07,63.76it/s] 49%|####8     |84494/173481[21:00<23:05,64.21it/s] 49%|####9     |85200/173481[21:11<22:54,64.21it/s] 55%|#####5    |96168/173481[24:00<19:58,64.53it/s] 56%|#####5    |96872/173481[24:11<19:47,64.53it/s] 62%|######2   |108140/173481[27:00<16:37,65.50it/s] 63%|######2   |108951/173481[27:11<16:25,65.50it/s] 70%|#######   |121577/173481[30:00<12:23,69.78it/s] 71%|#######   |122382/173481[30:11<12:12,69.78it/s] 77%|#######6  |133544/173481[33:00<09:46,68.08it/s] 77%|#######7  |134008/173481[33:11<09:39,68.08it/s] 84%|########4 |145754/173481[36:00<06:48,67.95it/s] 84%|########4 |146531/173481[36:11<06:36,67.95it/s] 91%|######### |157597/173481[39:00<03:57,66.85it/s] 91%|#########1|158292/173481[39:12<03:47,66.85it/s] 98%|#########7|169751/173481[42:00<00:55,67.19it/s] 98%|#########8|170538/173481[42:12<00:43,67.19it/s]100%|##########|173481/173481[42:57<00:00,67.30it/s]
[32m[0324 05:04:38 @base.py:257][0m Epoch 24 (global_step 3990063) finished, time:2577.88 sec.
[32m[0324 05:04:38 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-3990063.
[32m[0324 05:04:39 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:09<00:00,145.15it/s]
22
[32m[0324 05:06:49 @monitor.py:363][0m QueueInput/queue_size: 0.1566
[32m[0324 05:06:49 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.52
[32m[0324 05:06:49 @monitor.py:363][0m activation-summaries/output-rms: 0.042016
[32m[0324 05:06:49 @monitor.py:363][0m cross_entropy_loss: 1.5424
[32m[0324 05:06:49 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58755
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2821
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33459
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32255
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28075
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27205
[32m[0324 05:06:49 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 05:06:49 @monitor.py:363][0m train-error-top1: 0.42227
[32m[0324 05:06:49 @monitor.py:363][0m val-error-top1: 0.42054
[32m[0324 05:06:49 @monitor.py:363][0m val-utt-error: 0.093773
[32m[0324 05:06:49 @monitor.py:363][0m validation_cost: 1.5671
[32m[0324 05:06:49 @monitor.py:363][0m wd_cost: 1.7416e-05
[32m[0324 05:06:49 @group.py:42][0m Callbacks took 130.576 sec in total. InferenceRunner: 129.693sec
[32m[0324 05:06:49 @base.py:247][0m Start Epoch 25 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15812/173481[03:00<29:54,87.84it/s]  9%|9         |16419/173481[03:10<29:47,87.84it/s] 16%|#5        |27002/173481[06:00<33:31,72.81it/s] 16%|#5        |27707/173481[06:10<33:22,72.81it/s] 23%|##2       |39175/173481[09:00<31:55,70.12it/s] 23%|##2       |39887/173481[09:10<31:45,70.12it/s] 30%|##9       |51393/173481[12:00<29:30,68.98it/s] 30%|###       |52089/173481[12:10<29:19,68.98it/s] 37%|###6      |63670/173481[15:00<26:41,68.59it/s] 37%|###7      |64424/173481[15:10<26:30,68.59it/s] 45%|####4     |77288/173481[18:00<22:17,71.95it/s] 45%|####4     |77982/173481[18:10<22:07,71.95it/s] 53%|#####2    |91198/173481[21:00<18:24,74.50it/s] 53%|#####3    |92023/173481[21:11<18:13,74.50it/s] 60%|#####9    |104079/173481[24:00<15:50,73.00it/s] 60%|######    |104875/173481[24:11<15:39,73.00it/s] 67%|######7   |116548/173481[27:00<13:20,71.08it/s] 68%|######7   |117332/173481[27:11<13:09,71.08it/s] 74%|#######4  |128889/173481[30:00<10:38,69.80it/s] 75%|#######4  |129647/173481[30:11<10:28,69.80it/s] 81%|########1 |141215/173481[33:00<07:46,69.13it/s] 82%|########1 |142045/173481[33:11<07:34,69.13it/s] 89%|########8 |154398/173481[36:00<04:28,71.13it/s] 89%|########9 |155262/173481[36:11<04:16,71.13it/s] 99%|#########9|172546/173481[39:00<00:11,83.41it/s]100%|##########|173481/173481[39:07<00:00,73.90it/s]
[32m[0324 05:45:56 @base.py:257][0m Epoch 25 (global_step 4163544) finished, time:2347.45 sec.
[32m[0324 05:45:56 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-4163544.
[32m[0324 05:45:56 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:04<00:00,150.86it/s]
23
[32m[0324 05:48:01 @monitor.py:363][0m QueueInput/queue_size: 49.918
[32m[0324 05:48:01 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.856
[32m[0324 05:48:01 @monitor.py:363][0m activation-summaries/output-rms: 0.042508
[32m[0324 05:48:01 @monitor.py:363][0m cross_entropy_loss: 1.5275
[32m[0324 05:48:01 @monitor.py:363][0m lr: 3.9063e-06
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.58925
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2823
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33492
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32267
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2808
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27207
[32m[0324 05:48:01 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 05:48:01 @monitor.py:363][0m train-error-top1: 0.41354
[32m[0324 05:48:01 @monitor.py:363][0m val-error-top1: 0.4189
[32m[0324 05:48:01 @monitor.py:363][0m val-utt-error: 0.093773
[32m[0324 05:48:01 @monitor.py:363][0m validation_cost: 1.5604
[32m[0324 05:48:01 @monitor.py:363][0m wd_cost: 1.7465e-05
[32m[0324 05:48:01 @group.py:42][0m Callbacks took 125.160 sec in total. InferenceRunner: 124.781sec
[32m[0324 05:48:01 @base.py:247][0m Start Epoch 26 ...
  0%|          |0/173481[00:00<?,?it/s] 13%|#2        |22184/173481[03:00<20:27,123.24it/s] 13%|#3        |23206/173481[03:10<20:19,123.24it/s] 25%|##4       |42544/173481[06:00<18:30,117.96it/s] 25%|##5       |43795/173481[06:10<18:19,117.96it/s] 37%|###7      |64353/173481[09:00<15:12,119.54it/s] 38%|###7      |65512/173481[09:10<15:03,119.54it/s] 47%|####7     |81860/173481[12:00<14:14,107.25it/s] 48%|####7     |82842/173481[12:10<14:05,107.25it/s] 57%|#####6    |98628/173481[15:00<12:30,99.71it/s]  57%|#####7    |99644/173481[15:10<12:20,99.71it/s] 67%|######6   |115406/173481[18:00<10:02,96.34it/s] 67%|######7   |116424/173481[18:10<09:52,96.34it/s] 76%|#######6  |132183/173481[21:00<07:15,94.75it/s] 77%|#######6  |133221/173481[21:11<07:04,94.75it/s] 86%|########5 |148905/173481[24:00<04:21,93.81it/s] 86%|########6 |149950/173481[24:11<04:10,93.81it/s] 93%|#########2|160968/173481[27:00<02:40,78.18it/s] 93%|#########3|161692/173481[27:11<02:30,78.18it/s]100%|#########9|172764/173481[30:00<00:10,71.30it/s]100%|##########|173481/173481[30:11<00:00,95.76it/s]
[32m[0324 06:18:13 @base.py:257][0m Epoch 26 (global_step 4337025) finished, time:1811.61 sec.
[32m[0324 06:18:13 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-4337025.
[32m[0324 06:18:13 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:59<00:00,157.64it/s]
24
[32m[0324 06:20:13 @monitor.py:363][0m QueueInput/queue_size: 0.13103
[32m[0324 06:20:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.968
[32m[0324 06:20:13 @monitor.py:363][0m activation-summaries/output-rms: 0.042529
[32m[0324 06:20:13 @monitor.py:363][0m cross_entropy_loss: 1.5255
[32m[0324 06:20:13 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59023
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2825
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33515
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32275
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28083
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27209
[32m[0324 06:20:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 06:20:13 @monitor.py:363][0m train-error-top1: 0.41202
[32m[0324 06:20:13 @monitor.py:363][0m val-error-top1: 0.42061
[32m[0324 06:20:13 @monitor.py:363][0m val-utt-error: 0.09542
[32m[0324 06:20:13 @monitor.py:363][0m validation_cost: 1.5676
[32m[0324 06:20:13 @monitor.py:363][0m wd_cost: 3.4992e-06
[32m[0324 06:20:13 @group.py:42][0m Callbacks took 120.036 sec in total. InferenceRunner: 119.409sec
[32m[0324 06:20:13 @base.py:247][0m Start Epoch 27 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13544/173481[03:00<35:25,75.24it/s]  8%|8         |14215/173481[03:10<35:16,75.24it/s] 15%|#4        |25424/173481[06:00<35:05,70.32it/s] 15%|#5        |26124/173481[06:10<34:55,70.32it/s] 21%|##1       |36651/173481[09:00<34:29,66.11it/s] 22%|##1       |37316/173481[09:10<34:19,66.11it/s] 28%|##7       |48229/173481[12:00<32:00,65.20it/s] 28%|##8       |48929/173481[12:10<31:50,65.20it/s] 35%|###4      |60119/173481[15:00<28:47,65.63it/s] 35%|###5      |60838/173481[15:10<28:36,65.63it/s] 41%|####1     |71656/173481[18:00<26:10,64.84it/s] 42%|####1     |72316/173481[18:10<26:00,64.84it/s] 48%|####8     |83363/173481[21:00<23:07,64.94it/s] 48%|####8     |84063/173481[21:11<22:56,64.94it/s] 55%|#####4    |95251/173481[24:00<19:54,65.48it/s] 55%|#####5    |96020/173481[24:11<19:42,65.48it/s] 62%|######1   |106851/173481[27:00<17:05,64.95it/s] 62%|######2   |107587/173481[27:11<16:54,64.95it/s] 68%|######8   |118825/173481[30:00<13:51,65.73it/s] 69%|######8   |119562/173481[30:11<13:40,65.73it/s] 75%|#######5  |130666/173481[33:00<10:51,65.74it/s] 76%|#######5  |131418/173481[33:11<10:39,65.74it/s] 82%|########2 |142309/173481[36:00<07:58,65.21it/s] 82%|########2 |143085/173481[36:11<07:46,65.21it/s] 89%|########8 |153721/173481[39:00<05:07,64.29it/s] 89%|########9 |154458/173481[39:12<04:55,64.29it/s] 96%|#########5|166356/173481[42:00<01:46,67.11it/s] 96%|#########6|167153/173481[42:12<01:34,67.11it/s]100%|##########|173481/173481[43:48<00:00,66.00it/s]
[32m[0324 07:04:01 @base.py:257][0m Epoch 27 (global_step 4510506) finished, time:2628.34 sec.
[32m[0324 07:04:01 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-4510506.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:06<00:00,148.39it/s]
25
[32m[0324 07:06:08 @monitor.py:363][0m QueueInput/queue_size: 0.17192
[32m[0324 07:06:08 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 45.954
[32m[0324 07:06:08 @monitor.py:363][0m activation-summaries/output-rms: 0.042096
[32m[0324 07:06:08 @monitor.py:363][0m cross_entropy_loss: 1.5393
[32m[0324 07:06:08 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59112
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2827
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33531
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/linear1/W-rms: 0.3228
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28084
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27211
[32m[0324 07:06:08 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 07:06:08 @monitor.py:363][0m train-error-top1: 0.41492
[32m[0324 07:06:08 @monitor.py:363][0m val-error-top1: 0.42021
[32m[0324 07:06:08 @monitor.py:363][0m val-utt-error: 0.093189
[32m[0324 07:06:08 @monitor.py:363][0m validation_cost: 1.5663
[32m[0324 07:06:08 @monitor.py:363][0m wd_cost: 3.5043e-06
[32m[0324 07:06:08 @group.py:42][0m Callbacks took 127.091 sec in total. InferenceRunner: 126.856sec
[32m[0324 07:06:08 @base.py:247][0m Start Epoch 28 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15076/173481[03:00<31:31,83.75it/s]  9%|9         |15783/173481[03:10<31:22,83.75it/s] 16%|#5        |26969/173481[06:00<33:03,73.87it/s] 16%|#5        |27582/173481[06:10<32:55,73.87it/s] 22%|##1       |37855/173481[09:00<33:59,66.50it/s] 22%|##2       |38464/173481[09:10<33:50,66.50it/s] 28%|##7       |48490/173481[12:00<33:17,62.57it/s] 28%|##8       |49139/173481[12:10<33:07,62.57it/s] 34%|###4      |59733/173481[15:00<30:19,62.52it/s] 35%|###4      |60424/173481[15:10<30:08,62.52it/s] 41%|####      |70725/173481[18:00<27:43,61.78it/s] 41%|####1     |71439/173481[18:10<27:31,61.78it/s] 47%|####7     |82213/173481[21:00<24:13,62.78it/s] 48%|####7     |82920/173481[21:11<24:02,62.78it/s] 54%|#####4    |93960/173481[24:00<20:42,64.00it/s] 55%|#####4    |94684/173481[24:11<20:31,64.00it/s] 61%|######    |105577/173481[27:00<17:36,64.27it/s] 61%|######1   |106330/173481[27:11<17:24,64.27it/s] 68%|######7   |117158/173481[30:00<14:35,64.30it/s] 68%|######7   |117895/173481[30:11<14:24,64.30it/s] 74%|#######3  |128227/173481[33:00<11:59,62.87it/s] 74%|#######4  |128938/173481[33:11<11:48,62.87it/s] 80%|########  |138964/173481[36:00<09:23,61.22it/s] 81%|########  |139678/173481[36:11<09:12,61.22it/s] 86%|########6 |149800/173481[39:00<06:30,60.70it/s] 87%|########6 |150544/173481[39:12<06:17,60.70it/s] 93%|#########2|161182/173481[42:00<03:18,61.94it/s] 93%|#########3|161948/173481[42:12<03:06,61.94it/s]100%|#########9|172643/173481[45:00<00:13,62.79it/s]100%|#########9|173472/173481[45:12<00:00,62.79it/s][32m[0324 07:51:21 @base.py:257][0m Epoch 28 (global_step 4683987) finished, time:2712.53 sec.
100%|##########|173481/173481[45:12<00:00,63.96it/s]
[32m[0324 07:51:21 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-4683987.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:05<00:00,150.51it/s]
26
[32m[0324 07:53:26 @monitor.py:363][0m QueueInput/queue_size: 0.24397
[32m[0324 07:53:26 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.39
[32m[0324 07:53:26 @monitor.py:363][0m activation-summaries/output-rms: 0.041821
[32m[0324 07:53:26 @monitor.py:363][0m cross_entropy_loss: 1.5315
[32m[0324 07:53:26 @monitor.py:363][0m lr: 1.9531e-06
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59201
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2828
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33546
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32285
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28086
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27211
[32m[0324 07:53:26 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 07:53:26 @monitor.py:363][0m train-error-top1: 0.41203
[32m[0324 07:53:26 @monitor.py:363][0m val-error-top1: 0.42024
[32m[0324 07:53:26 @monitor.py:363][0m val-utt-error: 0.093136
[32m[0324 07:53:26 @monitor.py:363][0m validation_cost: 1.5671
[32m[0324 07:53:26 @monitor.py:363][0m wd_cost: 3.5093e-06
[32m[0324 07:53:26 @group.py:42][0m Callbacks took 125.295 sec in total. InferenceRunner: 125.082sec
[32m[0324 07:53:26 @base.py:247][0m Start Epoch 29 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15829/173481[03:00<29:53,87.92it/s] 10%|9         |16550/173481[03:10<29:44,87.92it/s] 16%|#6        |28024/173481[06:00<31:40,76.53it/s] 16%|#6        |28609/173481[06:10<31:33,76.53it/s] 22%|##2       |38741/173481[09:00<33:31,66.97it/s] 23%|##2       |39392/173481[09:10<33:22,66.97it/s] 28%|##8       |48997/173481[12:00<33:41,61.57it/s] 29%|##8       |49966/173481[12:10<33:26,61.57it/s] 35%|###4      |60215/173481[15:00<30:28,61.94it/s] 35%|###5      |60857/173481[15:10<30:18,61.94it/s] 41%|####1     |71884/173481[18:00<26:43,63.35it/s] 42%|####1     |72627/173481[18:10<26:32,63.35it/s] 48%|####8     |83894/173481[21:00<22:58,64.99it/s] 49%|####8     |84584/173481[21:11<22:47,64.99it/s] 55%|#####5    |95563/173481[24:00<20:00,64.91it/s] 56%|#####5    |96308/173481[24:11<19:48,64.91it/s] 62%|######1   |106781/173481[27:00<17:28,63.59it/s] 62%|######1   |107529/173481[27:11<17:17,63.59it/s] 69%|######8   |118944/173481[30:00<13:52,65.51it/s] 69%|######9   |119729/173481[30:11<13:40,65.51it/s] 75%|#######5  |130268/173481[33:00<11:13,64.19it/s] 75%|#######5  |130888/173481[33:11<11:03,64.19it/s] 82%|########1 |141856/173481[36:00<08:12,64.28it/s] 82%|########2 |142603/173481[36:11<08:00,64.28it/s] 89%|########8 |153617/173481[39:00<05:06,64.80it/s] 89%|########9 |154410/173481[39:12<04:54,64.80it/s] 95%|#########5|165449/173481[42:00<02:03,65.26it/s] 96%|#########5|166226/173481[42:12<01:51,65.26it/s]100%|##########|173481/173481[44:02<00:00,65.66it/s]
[32m[0324 08:37:28 @base.py:257][0m Epoch 29 (global_step 4857468) finished, time:2642.26 sec.
[32m[0324 08:37:29 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-4857468.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.14it/s]
27
[32m[0324 08:39:32 @monitor.py:363][0m QueueInput/queue_size: 0.24944
[32m[0324 08:39:32 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.274
[32m[0324 08:39:32 @monitor.py:363][0m activation-summaries/output-rms: 0.042078
[32m[0324 08:39:32 @monitor.py:363][0m cross_entropy_loss: 1.5389
[32m[0324 08:39:32 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59252
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2829
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33555
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32289
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28087
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27212
[32m[0324 08:39:32 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 08:39:32 @monitor.py:363][0m train-error-top1: 0.42383
[32m[0324 08:39:32 @monitor.py:363][0m val-error-top1: 0.42003
[32m[0324 08:39:32 @monitor.py:363][0m val-utt-error: 0.093826
[32m[0324 08:39:32 @monitor.py:363][0m validation_cost: 1.5644
[32m[0324 08:39:32 @monitor.py:363][0m wd_cost: 7.0246e-07
[32m[0324 08:39:32 @group.py:42][0m Callbacks took 124.016 sec in total. InferenceRunner: 123.728sec
[32m[0324 08:39:32 @base.py:247][0m Start Epoch 30 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14239/173481[03:00<33:33,79.11it/s]  9%|8         |14904/173481[03:10<33:24,79.11it/s] 14%|#4        |25120/173481[06:00<36:04,68.53it/s] 15%|#4        |25746/173481[06:10<35:55,68.53it/s] 21%|##1       |36664/173481[09:00<34:24,66.26it/s] 22%|##1       |37354/173481[09:10<34:14,66.26it/s] 28%|##8       |48622/173481[12:00<31:22,66.34it/s] 28%|##8       |49332/173481[12:10<31:11,66.34it/s] 35%|###4      |60171/173481[15:00<28:57,65.23it/s] 35%|###5      |60877/173481[15:10<28:46,65.23it/s] 42%|####1     |72101/173481[18:00<25:41,65.75it/s] 42%|####1     |72843/173481[18:10<25:30,65.75it/s] 48%|####8     |84006/173481[21:00<22:36,65.94it/s] 49%|####8     |84755/173481[21:11<22:25,65.94it/s] 55%|#####5    |95448/173481[24:00<20:05,64.73it/s] 56%|#####5    |96477/173481[24:11<19:49,64.73it/s] 62%|######2   |107836/173481[27:00<16:24,66.71it/s] 63%|######2   |108580/173481[27:11<16:12,66.71it/s] 69%|######9   |119848/173481[30:00<13:23,66.72it/s] 70%|######9   |120626/173481[30:11<13:12,66.72it/s] 76%|#######6  |131863/173481[33:00<10:23,66.73it/s] 76%|#######6  |132642/173481[33:11<10:12,66.73it/s] 83%|########2 |143893/173481[36:00<07:23,66.78it/s] 83%|########3 |144749/173481[36:11<07:10,66.78it/s] 90%|########9 |156109/173481[39:00<04:18,67.32it/s] 90%|######### |156857/173481[39:12<04:06,67.32it/s] 99%|#########9|171777/173481[42:00<00:22,75.92it/s]100%|#########9|173450/173481[42:12<00:00,75.92it/s]100%|##########|173481/173481[42:12<00:00,68.50it/s]
[32m[0324 09:21:45 @base.py:257][0m Epoch 30 (global_step 5030949) finished, time:2532.50 sec.
[32m[0324 09:21:45 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-5030949.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,153.57it/s]
28
[32m[0324 09:23:48 @monitor.py:363][0m QueueInput/queue_size: 49.953
[32m[0324 09:23:48 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.4
[32m[0324 09:23:48 @monitor.py:363][0m activation-summaries/output-rms: 0.042353
[32m[0324 09:23:48 @monitor.py:363][0m cross_entropy_loss: 1.5014
[32m[0324 09:23:48 @monitor.py:363][0m lr: 9.7656e-07
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59295
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2829
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33563
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32291
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28088
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27213
[32m[0324 09:23:48 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 09:23:48 @monitor.py:363][0m train-error-top1: 0.4054
[32m[0324 09:23:48 @monitor.py:363][0m val-error-top1: 0.41976
[32m[0324 09:23:48 @monitor.py:363][0m val-utt-error: 0.093561
[32m[0324 09:23:48 @monitor.py:363][0m validation_cost: 1.5639
[32m[0324 09:23:48 @monitor.py:363][0m wd_cost: 7.0294e-07
[32m[0324 09:23:48 @group.py:42][0m Callbacks took 122.691 sec in total. InferenceRunner: 122.581sec
[32m[0324 09:23:48 @base.py:247][0m Start Epoch 31 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |18061/173481[03:00<25:48,100.34it/s] 11%|#         |18741/173481[03:10<25:42,100.34it/s] 17%|#6        |28887/173481[06:00<32:02,75.20it/s]  17%|#7        |29582/173481[06:10<31:53,75.20it/s] 28%|##8       |49305/173481[09:00<22:53,90.44it/s] 29%|##9       |50311/173481[09:10<22:41,90.44it/s] 37%|###6      |64027/173481[12:00<21:14,85.89it/s] 37%|###7      |64831/173481[12:10<21:04,85.89it/s] 44%|####3     |76189/173481[15:00<21:26,75.63it/s] 44%|####4     |76883/173481[15:10<21:17,75.63it/s] 51%|#####     |87857/173481[18:00<20:26,69.81it/s] 51%|#####1    |88563/173481[18:10<20:16,69.81it/s] 57%|#####7    |99543/173481[21:00<18:19,67.27it/s] 58%|#####7    |100286/173481[21:11<18:08,67.27it/s] 64%|######4   |111064/173481[24:00<15:51,65.60it/s] 64%|######4   |111791/173481[24:11<15:40,65.60it/s] 71%|#######   |122555/173481[27:00<13:07,64.71it/s] 71%|#######1  |123252/173481[27:11<12:56,64.71it/s] 77%|#######7  |134122/173481[30:00<10:10,64.48it/s] 77%|#######7  |134401/173481[30:11<10:06,64.48it/s] 84%|########3 |145488/173481[33:00<07:18,63.80it/s] 84%|########4 |146231/173481[33:11<07:07,63.80it/s] 91%|######### |157010/173481[36:00<04:17,63.91it/s] 91%|######### |157720/173481[36:11<04:06,63.91it/s] 97%|#########6|168062/173481[39:00<01:26,62.63it/s] 97%|#########7|168796/173481[39:12<01:14,62.63it/s]100%|##########|173481/173481[40:31<00:00,71.35it/s]
[32m[0324 10:04:19 @base.py:257][0m Epoch 31 (global_step 5204430) finished, time:2431.41 sec.
[32m[0324 10:04:19 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-5204430.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:09<00:00,145.89it/s]
29
[32m[0324 10:06:28 @monitor.py:363][0m QueueInput/queue_size: 0.015024
[32m[0324 10:06:28 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.422
[32m[0324 10:06:28 @monitor.py:363][0m activation-summaries/output-rms: 0.042548
[32m[0324 10:06:28 @monitor.py:363][0m cross_entropy_loss: 1.5238
[32m[0324 10:06:28 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59335
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3357
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32293
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28089
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27213
[32m[0324 10:06:28 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 10:06:28 @monitor.py:363][0m train-error-top1: 0.41102
[32m[0324 10:06:28 @monitor.py:363][0m val-error-top1: 0.42039
[32m[0324 10:06:28 @monitor.py:363][0m val-utt-error: 0.094411
[32m[0324 10:06:28 @monitor.py:363][0m validation_cost: 1.5662
[32m[0324 10:06:28 @monitor.py:363][0m wd_cost: 7.034e-07
[32m[0324 10:06:28 @group.py:42][0m Callbacks took 129.292 sec in total. InferenceRunner: 129.033sec
[32m[0324 10:06:28 @base.py:247][0m Start Epoch 32 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15616/173481[03:00<30:19,86.75it/s]  9%|9         |16307/173481[03:10<30:11,86.75it/s] 16%|#5        |27038/173481[06:00<33:18,73.29it/s] 16%|#5        |27710/173481[06:10<33:08,73.29it/s] 22%|##1       |37971/173481[09:00<33:59,66.43it/s] 22%|##2       |38602/173481[09:10<33:50,66.43it/s] 28%|##8       |49068/173481[12:00<32:25,63.95it/s] 29%|##8       |49715/173481[12:10<32:15,63.95it/s] 35%|###4      |60031/173481[15:00<30:18,62.39it/s] 35%|###5      |60860/173481[15:10<30:05,62.39it/s] 41%|####      |71106/173481[18:00<27:32,61.95it/s] 41%|####1     |71731/173481[18:10<27:22,61.95it/s] 48%|####7     |82595/173481[21:00<24:05,62.88it/s] 48%|####8     |83300/173481[21:11<23:54,62.88it/s] 54%|#####4    |93934/173481[24:00<21:03,62.93it/s] 55%|#####4    |94667/173481[24:11<20:52,62.93it/s] 61%|######    |105237/173481[27:00<18:05,62.86it/s] 61%|######1   |105941/173481[27:11<17:54,62.86it/s] 67%|######7   |116686/173481[30:00<14:58,63.23it/s] 68%|######7   |117420/173481[30:11<14:46,63.23it/s] 74%|#######3  |128076/173481[33:00<11:57,63.25it/s] 74%|#######4  |128795/173481[33:11<11:46,63.25it/s] 80%|########  |139051/173481[36:00<09:14,62.09it/s] 81%|########  |139777/173481[36:11<09:02,62.09it/s] 86%|########6 |149968/173481[39:00<06:23,61.36it/s] 87%|########6 |150673/173481[39:12<06:11,61.36it/s] 93%|#########2|160874/173481[42:00<03:26,60.97it/s] 93%|#########3|161845/173481[42:12<03:10,60.97it/s]100%|#########9|172915/173481[45:00<00:08,63.80it/s]100%|##########|173481/173481[45:09<00:00,64.04it/s]
[32m[0324 10:51:37 @base.py:257][0m Epoch 32 (global_step 5377911) finished, time:2709.11 sec.
[32m[0324 10:51:38 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-5377911.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:08<00:00,146.03it/s]
30
[32m[0324 10:53:47 @monitor.py:363][0m QueueInput/queue_size: 0.36568
[32m[0324 10:53:47 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.314
[32m[0324 10:53:47 @monitor.py:363][0m activation-summaries/output-rms: 0.042093
[32m[0324 10:53:47 @monitor.py:363][0m cross_entropy_loss: 1.5369
[32m[0324 10:53:47 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59352
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33574
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32295
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/linear2/W-rms: 0.28089
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27213
[32m[0324 10:53:47 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 10:53:47 @monitor.py:363][0m train-error-top1: 0.41343
[32m[0324 10:53:47 @monitor.py:363][0m val-error-top1: 0.41998
[32m[0324 10:53:47 @monitor.py:363][0m val-utt-error: 0.093508
[32m[0324 10:53:47 @monitor.py:363][0m validation_cost: 1.5653
[32m[0324 10:53:47 @monitor.py:363][0m wd_cost: 1.4072e-07
[32m[0324 10:53:47 @group.py:42][0m Callbacks took 129.168 sec in total. InferenceRunner: 128.914sec
[32m[0324 10:53:47 @base.py:247][0m Start Epoch 33 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15268/173481[03:00<31:05,84.82it/s]  9%|9         |15974/173481[03:10<30:56,84.82it/s] 16%|#5        |27030/173481[06:00<33:04,73.80it/s] 16%|#5        |27656/173481[06:10<32:55,73.80it/s] 22%|##1       |37774/173481[09:00<34:16,66.00it/s] 22%|##2       |38372/173481[09:10<34:07,66.00it/s] 28%|##7       |48502/173481[12:00<33:15,62.64it/s] 28%|##8       |49123/173481[12:10<33:05,62.64it/s] 34%|###4      |59635/173481[15:00<30:29,62.23it/s] 35%|###4      |60289/173481[15:10<30:18,62.23it/s] 41%|####      |70350/173481[18:00<28:14,60.84it/s] 41%|####      |71024/173481[18:10<28:03,60.84it/s] 47%|####6     |81497/173481[21:00<24:58,61.38it/s] 47%|####7     |82174/173481[21:11<24:47,61.38it/s] 54%|#####3    |92900/173481[24:00<21:32,62.34it/s] 54%|#####3    |93624/173481[24:11<21:21,62.34it/s] 60%|######    |104455/173481[27:00<18:11,63.25it/s] 61%|######    |105239/173481[27:11<17:58,63.25it/s] 67%|######7   |116615/173481[30:00<14:30,65.33it/s] 68%|######7   |117325/173481[30:11<14:19,65.33it/s] 74%|#######3  |128215/173481[33:00<11:37,64.88it/s] 74%|#######4  |129144/173481[33:11<11:23,64.88it/s] 83%|########2 |143341/173481[36:00<06:51,73.22it/s] 83%|########3 |144334/173481[36:11<06:38,73.22it/s] 90%|########9 |155865/173481[39:00<04:06,71.34it/s] 90%|######### |156629/173481[39:12<03:56,71.34it/s] 97%|#########6|167598/173481[42:00<01:26,68.12it/s] 97%|#########7|168349/173481[42:12<01:15,68.12it/s][32m[0324 11:37:21 @base.py:257][0m Epoch 33 (global_step 5551392) finished, time:2614.00 sec.
100%|##########|173481/173481[43:33<00:00,66.37it/s]
[32m[0324 11:37:21 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-5551392.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:21<00:00,132.69it/s]
31
[32m[0324 11:39:43 @monitor.py:363][0m QueueInput/queue_size: 0.069063
[32m[0324 11:39:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.65
[32m[0324 11:39:43 @monitor.py:363][0m activation-summaries/output-rms: 0.041829
[32m[0324 11:39:43 @monitor.py:363][0m cross_entropy_loss: 1.5292
[32m[0324 11:39:43 @monitor.py:363][0m lr: 4.8828e-07
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5937
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33577
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32296
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 11:39:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 11:39:43 @monitor.py:363][0m train-error-top1: 0.41147
[32m[0324 11:39:43 @monitor.py:363][0m val-error-top1: 0.41996
[32m[0324 11:39:43 @monitor.py:363][0m val-utt-error: 0.092817
[32m[0324 11:39:43 @monitor.py:363][0m validation_cost: 1.5657
[32m[0324 11:39:43 @monitor.py:363][0m wd_cost: 1.4076e-07
[32m[0324 11:39:43 @group.py:42][0m Callbacks took 142.041 sec in total. InferenceRunner: 141.866sec
[32m[0324 11:39:43 @base.py:247][0m Start Epoch 34 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |15705/173481[03:00<30:08,87.25it/s]  9%|9         |16368/173481[03:10<30:00,87.25it/s] 16%|#5        |27610/173481[06:00<32:18,75.24it/s] 16%|#6        |28197/173481[06:10<32:10,75.24it/s] 22%|##1       |38069/173481[09:00<34:25,65.57it/s] 22%|##2       |38687/173481[09:10<34:15,65.57it/s] 28%|##8       |48689/173481[12:00<33:29,62.10it/s] 28%|##8       |49291/173481[12:10<33:19,62.10it/s] 34%|###4      |59159/173481[15:00<31:43,60.07it/s] 34%|###4      |59795/173481[15:10<31:32,60.07it/s] 41%|####      |70470/173481[18:00<27:57,61.42it/s] 41%|####1     |71209/173481[18:10<27:45,61.42it/s] 47%|####7     |82355/173481[21:00<23:51,63.64it/s] 48%|####7     |83055/173481[21:11<23:40,63.64it/s] 54%|#####4    |94054/173481[24:00<20:35,64.31it/s] 55%|#####4    |94733/173481[24:11<20:24,64.31it/s] 61%|######    |105229/173481[27:00<18:00,63.18it/s] 61%|######1   |105910/173481[27:11<17:49,63.18it/s] 67%|######7   |117051/173481[30:00<14:36,64.40it/s] 68%|######7   |117823/173481[30:11<14:24,64.40it/s] 75%|#######5  |130534/173481[33:00<10:20,69.26it/s] 76%|#######5  |131342/173481[33:11<10:08,69.26it/s] 83%|########2 |143614/173481[36:00<07:01,70.91it/s] 83%|########3 |144528/173481[36:11<06:48,70.91it/s] 90%|######### |156534/173481[39:00<03:57,71.34it/s] 91%|######### |157267/173481[39:12<03:47,71.34it/s] 97%|#########6|168034/173481[42:00<01:20,67.41it/s] 97%|#########7|168828/173481[42:12<01:09,67.41it/s]100%|##########|173481/173481[43:27<00:00,66.53it/s]
[32m[0324 12:23:10 @base.py:257][0m Epoch 34 (global_step 5724873) finished, time:2607.52 sec.
[32m[0324 12:23:10 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-5724873.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.17it/s]
32
[32m[0324 12:25:18 @monitor.py:363][0m QueueInput/queue_size: 0.26449
[32m[0324 12:25:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.497
[32m[0324 12:25:18 @monitor.py:363][0m activation-summaries/output-rms: 0.042071
[32m[0324 12:25:18 @monitor.py:363][0m cross_entropy_loss: 1.5377
[32m[0324 12:25:18 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59381
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.3358
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 12:25:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 12:25:18 @monitor.py:363][0m train-error-top1: 0.42331
[32m[0324 12:25:18 @monitor.py:363][0m val-error-top1: 0.41993
[32m[0324 12:25:18 @monitor.py:363][0m val-utt-error: 0.094039
[32m[0324 12:25:18 @monitor.py:363][0m validation_cost: 1.5638
[32m[0324 12:25:18 @monitor.py:363][0m wd_cost: 1.4079e-07
[32m[0324 12:25:18 @group.py:42][0m Callbacks took 128.104 sec in total. InferenceRunner: 127.908sec
[32m[0324 12:25:18 @base.py:247][0m Start Epoch 35 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15011/173481[03:00<31:40,83.39it/s]  9%|9         |15619/173481[03:10<31:33,83.39it/s] 15%|#4        |25499/173481[06:00<35:57,68.60it/s] 15%|#5        |26137/173481[06:10<35:47,68.60it/s] 21%|##1       |36554/173481[09:00<35:12,64.81it/s] 21%|##1       |37194/173481[09:10<35:02,64.81it/s] 28%|##7       |47985/173481[12:00<32:36,64.15it/s] 28%|##8       |48590/173481[12:10<32:26,64.15it/s] 35%|###5      |61423/173481[15:00<27:03,69.00it/s] 36%|###5      |62237/173481[15:10<26:52,69.00it/s] 44%|####3     |75748/173481[18:00<22:02,73.91it/s] 44%|####4     |76512/173481[18:10<21:51,73.91it/s] 50%|#####     |87401/173481[21:00<20:47,69.02it/s] 51%|#####     |88127/173481[21:11<20:36,69.02it/s] 57%|#####7    |99271/173481[24:00<18:20,67.45it/s] 58%|#####7    |100000/173481[24:11<18:09,67.45it/s] 64%|######3   |110937/173481[27:00<15:46,66.10it/s] 64%|######4   |111679/173481[27:11<15:34,66.10it/s] 70%|#######   |122221/173481[30:00<13:16,64.35it/s] 71%|#######   |122907/173481[30:11<13:05,64.35it/s] 77%|#######7  |133683/173481[33:00<10:21,64.01it/s] 78%|#######7  |134512/173481[33:11<10:08,64.01it/s] 84%|########3 |145588/173481[36:00<07:08,65.05it/s] 84%|########4 |146339/173481[36:11<06:57,65.05it/s] 91%|######### |157218/173481[39:00<04:10,64.83it/s] 91%|#########1|158007/173481[39:12<03:58,64.83it/s]100%|##########|173481/173481[41:39<00:00,69.42it/s]
[32m[0324 13:06:57 @base.py:257][0m Epoch 35 (global_step 5898354) finished, time:2499.01 sec.
[32m[0324 13:06:57 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-5898354.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:54<00:00,164.06it/s]
33
[32m[0324 13:08:52 @monitor.py:363][0m QueueInput/queue_size: 49.979
[32m[0324 13:08:52 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.434
[32m[0324 13:08:52 @monitor.py:363][0m activation-summaries/output-rms: 0.042458
[32m[0324 13:08:52 @monitor.py:363][0m cross_entropy_loss: 1.5013
[32m[0324 13:08:52 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.5938
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33582
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 13:08:52 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 13:08:52 @monitor.py:363][0m train-error-top1: 0.40717
[32m[0324 13:08:52 @monitor.py:363][0m val-error-top1: 0.41881
[32m[0324 13:08:52 @monitor.py:363][0m val-utt-error: 0.093083
[32m[0324 13:08:52 @monitor.py:363][0m validation_cost: 1.5609
[32m[0324 13:08:52 @monitor.py:363][0m wd_cost: 2.8159e-08
[32m[0324 13:08:52 @group.py:42][0m Callbacks took 114.888 sec in total. InferenceRunner: 114.736sec
[32m[0324 13:08:52 @base.py:247][0m Start Epoch 36 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|#         |17362/173481[03:00<26:58,96.46it/s] 10%|#         |17992/173481[03:10<26:52,96.46it/s] 17%|#6        |28813/173481[06:00<31:27,76.66it/s] 17%|#6        |29483/173481[06:10<31:18,76.66it/s] 28%|##8       |48801/173481[09:00<22:54,90.70it/s] 29%|##8       |49857/173481[09:10<22:42,90.70it/s] 37%|###6      |63362/173481[12:00<21:27,85.51it/s] 37%|###6      |64151/173481[12:10<21:18,85.51it/s] 43%|####3     |75265/173481[15:00<21:56,74.58it/s] 44%|####3     |75911/173481[15:10<21:48,74.58it/s] 50%|####9     |86637/173481[18:00<21:09,68.40it/s] 50%|#####     |87266/173481[18:10<21:00,68.40it/s] 56%|#####6    |97859/173481[21:00<19:19,65.23it/s] 57%|#####6    |98565/173481[21:11<19:08,65.23it/s] 63%|######2   |108952/173481[24:00<16:58,63.38it/s] 63%|######3   |109629/173481[24:11<16:47,63.38it/s] 69%|######9   |120144/173481[27:00<14:09,62.77it/s] 70%|######9   |120871/173481[27:11<13:58,62.77it/s] 76%|#######5  |131630/173481[30:00<11:01,63.29it/s] 76%|#######6  |132385/173481[30:11<10:49,63.29it/s] 83%|########2 |143194/173481[33:00<07:55,63.76it/s] 83%|########2 |143893/173481[33:11<07:44,63.76it/s] 89%|########9 |154752/173481[36:00<04:52,63.98it/s] 90%|########9 |155511/173481[36:11<04:40,63.98it/s] 96%|#########5|166111/173481[39:00<01:55,63.54it/s] 96%|#########6|166853/173481[39:12<01:44,63.54it/s][32m[0324 13:49:50 @base.py:257][0m Epoch 36 (global_step 6071835) finished, time:2458.22 sec.
100%|##########|173481/173481[40:58<00:00,70.57it/s]
[32m[0324 13:49:51 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-6071835.
[32m[0324 13:49:51 @saver.py:155][0m Model with minimum 'val-error-top1' saved.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:14<00:00,140.44it/s]
34
[32m[0324 13:52:05 @monitor.py:363][0m QueueInput/queue_size: 0.1335
[32m[0324 13:52:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.539
[32m[0324 13:52:05 @monitor.py:363][0m activation-summaries/output-rms: 0.042558
[32m[0324 13:52:05 @monitor.py:363][0m cross_entropy_loss: 1.5229
[32m[0324 13:52:05 @monitor.py:363][0m lr: 2.4414e-07
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59379
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33583
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32298
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 13:52:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 13:52:05 @monitor.py:363][0m train-error-top1: 0.41034
[32m[0324 13:52:05 @monitor.py:363][0m val-error-top1: 0.42026
[32m[0324 13:52:05 @monitor.py:363][0m val-utt-error: 0.094411
[32m[0324 13:52:05 @monitor.py:363][0m validation_cost: 1.5658
[32m[0324 13:52:05 @monitor.py:363][0m wd_cost: 2.816e-08
[32m[0324 13:52:05 @group.py:42][0m Callbacks took 134.790 sec in total. InferenceRunner: 134.072sec
[32m[0324 13:52:05 @base.py:247][0m Start Epoch 37 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |14746/173481[03:00<32:17,81.92it/s]  9%|8         |15395/173481[03:10<32:09,81.92it/s] 15%|#5        |26206/173481[06:00<34:15,71.64it/s] 15%|#5        |26840/173481[06:10<34:06,71.64it/s] 21%|##        |36076/173481[09:00<36:52,62.10it/s] 21%|##1       |36600/173481[09:10<36:44,62.10it/s] 26%|##6       |45271/173481[12:00<38:07,56.05it/s] 26%|##6       |45814/173481[12:10<37:57,56.05it/s] 31%|###1      |54452/173481[15:00<37:08,53.41it/s] 32%|###1      |55027/173481[15:10<36:57,53.41it/s] 37%|###7      |64891/173481[18:00<32:33,55.60it/s] 38%|###7      |65570/173481[18:10<32:20,55.60it/s] 44%|####3     |75791/173481[21:00<28:05,57.97it/s] 44%|####4     |76510/173481[21:11<27:52,57.97it/s] 50%|#####     |87443/173481[24:00<23:26,61.17it/s] 51%|#####     |88172/173481[24:11<23:14,61.17it/s] 57%|#####7    |99136/173481[27:00<19:40,63.00it/s] 58%|#####7    |99826/173481[27:11<19:29,63.00it/s] 64%|######3   |110355/173481[30:00<16:47,62.66it/s] 64%|######4   |111093/173481[30:11<16:35,62.66it/s] 70%|#######   |121935/173481[33:00<13:31,63.49it/s] 71%|#######   |122645/173481[33:11<13:20,63.49it/s] 77%|#######6  |133144/173481[36:00<10:41,62.87it/s] 77%|#######7  |133865/173481[36:11<10:30,62.87it/s] 83%|########3 |144247/173481[39:00<07:49,62.27it/s] 84%|########3 |144940/173481[39:12<07:38,62.27it/s] 89%|########9 |154981/173481[42:00<05:03,60.92it/s] 90%|########9 |155655/173481[42:12<04:52,60.92it/s] 97%|#########6|167471/173481[45:00<01:32,64.87it/s] 97%|#########6|168164/173481[45:12<01:21,64.87it/s]100%|##########|173481/173481[46:37<00:00,62.01it/s]
[32m[0324 14:38:43 @base.py:257][0m Epoch 37 (global_step 6245316) finished, time:2797.72 sec.
[32m[0324 14:38:43 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-6245316.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:06<00:00,148.87it/s]
35
[32m[0324 14:40:50 @monitor.py:363][0m QueueInput/queue_size: 0.67633
[32m[0324 14:40:50 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.401
[32m[0324 14:40:50 @monitor.py:363][0m activation-summaries/output-rms: 0.042085
[32m[0324 14:40:50 @monitor.py:363][0m cross_entropy_loss: 1.5356
[32m[0324 14:40:50 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59369
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32298
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 14:40:50 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 14:40:50 @monitor.py:363][0m train-error-top1: 0.4148
[32m[0324 14:40:50 @monitor.py:363][0m val-error-top1: 0.41992
[32m[0324 14:40:50 @monitor.py:363][0m val-utt-error: 0.093986
[32m[0324 14:40:50 @monitor.py:363][0m validation_cost: 1.565
[32m[0324 14:40:50 @monitor.py:363][0m wd_cost: 5.6315e-09
[32m[0324 14:40:50 @group.py:42][0m Callbacks took 126.647 sec in total. InferenceRunner: 126.449sec
[32m[0324 14:40:50 @base.py:247][0m Start Epoch 38 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|8         |15154/173481[03:00<31:20,84.19it/s]  9%|9         |15777/173481[03:10<31:13,84.19it/s] 15%|#5        |26610/173481[06:00<33:46,72.49it/s] 16%|#5        |27227/173481[06:10<33:37,72.49it/s] 21%|##1       |37025/173481[09:00<35:20,64.35it/s] 22%|##1       |37639/173481[09:10<35:10,64.35it/s] 27%|##7       |47437/173481[12:00<34:28,60.92it/s] 28%|##7       |48046/173481[12:10<34:18,60.92it/s] 33%|###3      |58057/173481[15:00<32:05,59.94it/s] 34%|###3      |58703/173481[15:10<31:54,59.94it/s] 40%|###9      |68712/173481[18:00<29:18,59.57it/s] 40%|###9      |69379/173481[18:10<29:07,59.57it/s] 46%|####5     |79515/173481[21:00<26:11,59.78it/s] 46%|####6     |80161/173481[21:11<26:00,59.78it/s] 52%|#####2    |90630/173481[24:00<22:43,60.75it/s] 53%|#####2    |91301/173481[24:11<22:32,60.75it/s] 59%|#####8    |101758/173481[27:00<19:30,61.28it/s] 59%|#####9    |102480/173481[27:11<19:18,61.28it/s] 65%|######5   |113275/173481[30:00<16:01,62.60it/s] 66%|######5   |113985/173481[30:11<15:50,62.60it/s] 71%|#######1  |123959/173481[33:00<13:32,60.92it/s] 72%|#######1  |124664/173481[33:11<13:21,60.92it/s] 78%|#######7  |134695/173481[36:00<10:43,60.27it/s] 78%|#######7  |135314/173481[36:11<10:33,60.27it/s] 84%|########3 |145256/173481[39:00<07:54,59.46it/s] 84%|########4 |145956/173481[39:12<07:42,59.46it/s] 90%|######### |156250/173481[42:00<04:45,60.26it/s] 91%|######### |157017/173481[42:12<04:33,60.26it/s] 96%|#########6|167040/173481[45:00<01:47,60.09it/s] 97%|#########6|167734/173481[45:12<01:35,60.09it/s]100%|##########|173481/173481[46:48<00:00,61.77it/s]
[32m[0324 15:27:38 @base.py:257][0m Epoch 38 (global_step 6418797) finished, time:2808.71 sec.
[32m[0324 15:27:38 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-6418797.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:18<00:00,136.31it/s]
36
[32m[0324 15:29:57 @monitor.py:363][0m QueueInput/queue_size: 0.16342
[32m[0324 15:29:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.701
[32m[0324 15:29:57 @monitor.py:363][0m activation-summaries/output-rms: 0.041828
[32m[0324 15:29:57 @monitor.py:363][0m cross_entropy_loss: 1.5286
[32m[0324 15:29:57 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59353
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32298
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 15:29:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 15:29:57 @monitor.py:363][0m train-error-top1: 0.41093
[32m[0324 15:29:57 @monitor.py:363][0m val-error-top1: 0.41991
[32m[0324 15:29:57 @monitor.py:363][0m val-utt-error: 0.092923
[32m[0324 15:29:57 @monitor.py:363][0m validation_cost: 1.5653
[32m[0324 15:29:57 @monitor.py:363][0m wd_cost: 5.6305e-09
[32m[0324 15:29:57 @group.py:42][0m Callbacks took 138.329 sec in total. InferenceRunner: 138.106sec
[32m[0324 15:29:57 @base.py:247][0m Start Epoch 39 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17199/173481[03:00<27:15,95.53it/s] 10%|#         |17912/173481[03:10<27:08,95.53it/s] 17%|#6        |28882/173481[06:00<31:10,77.29it/s] 17%|#7        |29502/173481[06:10<31:02,77.29it/s] 23%|##2       |39629/173481[09:00<33:06,67.37it/s] 23%|##3       |40248/173481[09:10<32:57,67.37it/s] 29%|##8       |50117/173481[12:00<32:54,62.49it/s] 29%|##9       |50723/173481[12:10<32:44,62.49it/s] 35%|###4      |60429/173481[15:00<31:31,59.77it/s] 35%|###5      |61034/173481[15:10<31:21,59.77it/s] 41%|####1     |71449/173481[18:00<28:06,60.49it/s] 42%|####1     |72193/173481[18:10<27:54,60.49it/s] 48%|####7     |83043/173481[21:00<24:09,62.38it/s] 48%|####8     |83763/173481[21:11<23:58,62.38it/s] 54%|#####4    |94494/173481[24:00<20:53,62.99it/s] 55%|#####4    |95153/173481[24:11<20:43,62.99it/s] 61%|######    |105389/173481[27:00<18:23,61.73it/s] 61%|######1   |106097/173481[27:11<18:11,61.73it/s] 68%|######7   |117358/173481[30:00<14:36,64.02it/s] 68%|######8   |118139/173481[30:11<14:24,64.02it/s] 74%|#######4  |128750/173481[33:00<11:42,63.65it/s] 75%|#######4  |129478/173481[33:11<11:31,63.65it/s] 81%|########  |140137/173481[36:00<08:45,63.45it/s] 81%|########1 |140879/173481[36:11<08:33,63.45it/s] 87%|########7 |151490/173481[39:00<05:47,63.26it/s] 88%|########7 |152258/173481[39:12<05:35,63.26it/s] 94%|#########4|163572/173481[42:00<02:32,65.13it/s] 95%|#########4|164693/173481[42:12<02:14,65.13it/s]100%|##########|173481/173481[44:08<00:00,65.51it/s]
[32m[0324 16:14:05 @base.py:257][0m Epoch 39 (global_step 6592278) finished, time:2648.10 sec.
[32m[0324 16:14:05 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-6592278.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:08<00:00,146.51it/s]
37
[32m[0324 16:16:13 @monitor.py:363][0m QueueInput/queue_size: 0.10158
[32m[0324 16:16:13 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.526
[32m[0324 16:16:13 @monitor.py:363][0m activation-summaries/output-rms: 0.042053
[32m[0324 16:16:13 @monitor.py:363][0m cross_entropy_loss: 1.5378
[32m[0324 16:16:13 @monitor.py:363][0m lr: 1.2207e-07
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59337
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.2829
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32298
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 16:16:13 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 16:16:13 @monitor.py:363][0m train-error-top1: 0.42322
[32m[0324 16:16:13 @monitor.py:363][0m val-error-top1: 0.4199
[32m[0324 16:16:13 @monitor.py:363][0m val-utt-error: 0.093667
[32m[0324 16:16:13 @monitor.py:363][0m validation_cost: 1.5637
[32m[0324 16:16:13 @monitor.py:363][0m wd_cost: 5.6296e-09
[32m[0324 16:16:13 @group.py:42][0m Callbacks took 128.624 sec in total. InferenceRunner: 128.494sec
[32m[0324 16:16:13 @base.py:247][0m Start Epoch 40 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14078/173481[03:00<33:58,78.20it/s]  8%|8         |14706/173481[03:10<33:50,78.20it/s] 14%|#3        |23985/173481[06:00<38:33,64.61it/s] 14%|#4        |24547/173481[06:10<38:25,64.61it/s] 20%|#9        |34217/173481[09:00<38:22,60.48it/s] 20%|##        |34857/173481[09:10<38:12,60.48it/s] 26%|##5       |44975/173481[12:00<35:37,60.12it/s] 26%|##6       |45628/173481[12:10<35:26,60.12it/s] 32%|###2      |55588/173481[15:00<33:00,59.52it/s] 32%|###2      |56142/173481[15:10<32:51,59.52it/s] 38%|###8      |66148/173481[18:00<30:16,59.09it/s] 39%|###8      |66842/173481[18:10<30:04,59.09it/s] 44%|####4     |76953/173481[21:00<27:00,59.55it/s] 45%|####4     |77584/173481[21:11<26:50,59.55it/s] 50%|#####     |87278/173481[24:00<24:35,58.43it/s] 51%|#####     |87915/173481[24:11<24:24,58.43it/s] 56%|#####6    |97558/173481[27:00<21:54,57.76it/s] 57%|#####6    |98200/173481[27:11<21:43,57.76it/s] 62%|######2   |107736/173481[30:00<19:10,57.15it/s] 62%|######2   |108374/173481[30:11<18:59,57.15it/s] 68%|######8   |118000/173481[33:00<16:11,57.08it/s] 68%|######8   |118689/173481[33:11<15:59,57.08it/s] 74%|#######4  |128674/173481[36:00<12:50,58.17it/s] 75%|#######4  |129342/173481[36:11<12:38,58.17it/s] 80%|########  |139076/173481[39:00<09:53,57.98it/s] 81%|########  |139726/173481[39:12<09:42,57.98it/s] 86%|########6 |149303/173481[42:00<07:01,57.39it/s] 86%|########6 |149967/173481[42:12<06:49,57.39it/s] 92%|#########1|159558/173481[45:00<04:03,57.17it/s] 92%|#########2|160227/173481[45:12<03:51,57.17it/s] 98%|#########7|169393/173481[48:00<01:13,55.87it/s] 98%|#########7|170001/173481[48:12<01:02,55.87it/s]100%|##########|173481/173481[49:17<00:00,58.66it/s]
[32m[0324 17:05:31 @base.py:257][0m Epoch 40 (global_step 6765759) finished, time:2957.60 sec.
[32m[0324 17:05:31 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-6765759.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:44<00:00,114.22it/s]
38
[32m[0324 17:08:16 @monitor.py:363][0m QueueInput/queue_size: 0.1515
[32m[0324 17:08:16 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.406
[32m[0324 17:08:16 @monitor.py:363][0m activation-summaries/output-rms: 0.041915
[32m[0324 17:08:16 @monitor.py:363][0m cross_entropy_loss: 1.5312
[32m[0324 17:08:16 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59312
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 17:08:16 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 17:08:16 @monitor.py:363][0m train-error-top1: 0.42369
[32m[0324 17:08:16 @monitor.py:363][0m val-error-top1: 0.41998
[32m[0324 17:08:16 @monitor.py:363][0m val-utt-error: 0.093136
[32m[0324 17:08:16 @monitor.py:363][0m validation_cost: 1.5652
[32m[0324 17:08:16 @monitor.py:363][0m wd_cost: 1.1256e-09
[32m[0324 17:08:16 @group.py:42][0m Callbacks took 165.197 sec in total. InferenceRunner: 164.810sec
[32m[0324 17:08:16 @base.py:247][0m Start Epoch 41 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11433/173481[03:00<42:31,63.51it/s]  7%|6         |11996/173481[03:10<42:22,63.51it/s] 12%|#2        |21527/173481[06:00<42:31,59.56it/s] 13%|#2        |22063/173481[06:10<42:22,59.56it/s] 18%|#8        |31643/173481[09:00<40:52,57.83it/s] 19%|#8        |32243/173481[09:10<40:42,57.83it/s] 24%|##4       |41951/173481[12:00<38:05,57.54it/s] 25%|##4       |42533/173481[12:10<37:55,57.54it/s] 30%|###       |52362/173481[15:00<34:59,57.69it/s] 31%|###       |53001/173481[15:10<34:48,57.69it/s] 36%|###6      |63292/173481[18:00<31:02,59.16it/s] 37%|###6      |63943/173481[18:11<30:51,59.16it/s] 42%|####2     |73722/173481[21:00<28:24,58.54it/s] 43%|####2     |74369/173481[21:11<28:13,58.54it/s] 49%|####8     |84197/173481[24:00<25:29,58.36it/s] 49%|####8     |84809/173481[24:11<25:19,58.36it/s] 55%|#####4    |94809/173481[27:00<22:21,58.66it/s] 55%|#####5    |95441/173481[27:11<22:10,58.66it/s] 61%|######    |105101/173481[30:00<19:40,57.91it/s] 61%|######    |105766/173481[30:11<19:29,57.91it/s] 67%|######6   |115527/173481[33:00<16:40,57.90it/s] 67%|######6   |116176/173481[33:11<16:29,57.90it/s] 73%|#######2  |126032/173481[36:00<13:36,58.12it/s] 73%|#######3  |126693/173481[36:11<13:25,58.12it/s] 79%|#######8  |136407/173481[39:00<10:40,57.88it/s] 79%|#######9  |137076/173481[39:12<10:29,57.88it/s] 85%|########4 |146850/173481[42:00<07:39,57.95it/s] 85%|########5 |147535/173481[42:12<07:27,57.95it/s] 91%|######### |157527/173481[45:00<04:32,58.62it/s] 91%|#########1|158283/173481[45:12<04:19,58.62it/s] 97%|#########6|167423/173481[48:00<01:46,56.74it/s] 97%|#########7|168497/173481[48:12<01:27,56.74it/s][32m[0324 17:57:59 @base.py:257][0m Epoch 41 (global_step 6939240) finished, time:2982.74 sec.
100%|##########|173481/173481[49:42<00:00,58.16it/s]
[32m[0324 17:57:59 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-6939240.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:07<00:00,147.72it/s]
39
[32m[0324 18:00:06 @monitor.py:363][0m QueueInput/queue_size: 0.20045
[32m[0324 18:00:06 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.51
[32m[0324 18:00:06 @monitor.py:363][0m activation-summaries/output-rms: 0.042537
[32m[0324 18:00:06 @monitor.py:363][0m cross_entropy_loss: 1.5233
[32m[0324 18:00:06 @monitor.py:363][0m lr: 6.1035e-08
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59286
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 18:00:06 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 18:00:06 @monitor.py:363][0m train-error-top1: 0.41048
[32m[0324 18:00:06 @monitor.py:363][0m val-error-top1: 0.4202
[32m[0324 18:00:06 @monitor.py:363][0m val-utt-error: 0.094517
[32m[0324 18:00:06 @monitor.py:363][0m validation_cost: 1.5654
[32m[0324 18:00:06 @monitor.py:363][0m wd_cost: 1.1253e-09
[32m[0324 18:00:06 @group.py:42][0m Callbacks took 127.626 sec in total. InferenceRunner: 127.433sec
[32m[0324 18:00:06 @base.py:247][0m Start Epoch 42 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10985/173481[03:00<44:23,61.02it/s]  7%|6         |11576/173481[03:10<44:13,61.02it/s] 12%|#2        |21543/173481[06:00<42:20,59.81it/s] 13%|#2        |22146/173481[06:10<42:10,59.81it/s] 18%|#8        |32091/173481[09:00<39:48,59.20it/s] 19%|#8        |32697/173481[09:10<39:38,59.20it/s] 24%|##4       |42330/173481[12:00<37:40,58.02it/s] 25%|##4       |42954/173481[12:10<37:29,58.02it/s] 30%|##9       |51651/173481[15:00<37:06,54.72it/s] 30%|###       |52179/173481[15:10<36:56,54.72it/s] 36%|###5      |61736/173481[18:00<33:38,55.36it/s] 36%|###5      |62343/173481[18:10<33:27,55.36it/s] 41%|####1     |71707/173481[21:00<30:37,55.38it/s] 42%|####1     |72270/173481[21:11<30:27,55.38it/s] 47%|####7     |81640/173481[24:00<27:41,55.28it/s] 47%|####7     |82220/173481[24:11<27:30,55.28it/s] 52%|#####2    |90750/173481[27:00<26:05,52.84it/s] 53%|#####2    |91349/173481[27:11<25:54,52.84it/s] 58%|#####7    |99876/173481[30:00<23:42,51.75it/s] 58%|#####7    |100443/173481[30:11<23:31,51.75it/s] 63%|######3   |109545/173481[33:00<20:12,52.71it/s] 63%|######3   |110157/173481[33:11<20:01,52.71it/s] 68%|######8   |118654/173481[36:00<17:41,51.64it/s] 69%|######8   |119302/173481[36:11<17:29,51.64it/s] 74%|#######3  |128061/173481[39:00<14:34,51.95it/s] 74%|#######4  |128672/173481[39:12<14:22,51.95it/s] 79%|#######9  |137321/173481[42:00<11:39,51.69it/s] 79%|#######9  |137910/173481[42:12<11:28,51.69it/s] 84%|########4 |146531/173481[45:00<08:44,51.42it/s] 85%|########4 |147117/173481[45:12<08:32,51.42it/s] 90%|########9 |156111/173481[48:00<05:32,52.30it/s] 90%|######### |156770/173481[48:12<05:19,52.30it/s] 96%|#########5|165947/173481[51:00<02:20,53.45it/s] 96%|#########6|166620/173481[51:12<02:08,53.45it/s][32m[0324 18:53:24 @base.py:257][0m Epoch 42 (global_step 7112721) finished, time:3197.45 sec.
100%|##########|173481/173481[53:17<00:00,54.26it/s]
[32m[0324 18:53:24 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-7112721.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:32<00:00,123.12it/s]
40
[32m[0324 18:55:57 @monitor.py:363][0m QueueInput/queue_size: 0.05044
[32m[0324 18:55:57 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.349
[32m[0324 18:55:57 @monitor.py:363][0m activation-summaries/output-rms: 0.042047
[32m[0324 18:55:57 @monitor.py:363][0m cross_entropy_loss: 1.5369
[32m[0324 18:55:57 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59262
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 18:55:57 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 18:55:57 @monitor.py:363][0m train-error-top1: 0.41456
[32m[0324 18:55:57 @monitor.py:363][0m val-error-top1: 0.41992
[32m[0324 18:55:57 @monitor.py:363][0m val-utt-error: 0.094039
[32m[0324 18:55:57 @monitor.py:363][0m validation_cost: 1.5648
[32m[0324 18:55:57 @monitor.py:363][0m wd_cost: 1.125e-09
[32m[0324 18:55:57 @group.py:42][0m Callbacks took 153.104 sec in total. InferenceRunner: 152.890sec
[32m[0324 18:55:57 @base.py:247][0m Start Epoch 43 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10202/173481[03:00<48:00,56.68it/s]  6%|6         |10752/173481[03:10<47:51,56.68it/s] 12%|#1        |19994/173481[06:00<46:04,55.51it/s] 12%|#1        |20399/173481[06:10<45:57,55.51it/s] 17%|#7        |29849/173481[09:00<43:25,55.13it/s] 18%|#7        |30429/173481[09:10<43:14,55.13it/s] 22%|##2       |38543/173481[12:00<43:40,51.49it/s] 22%|##2       |39010/173481[12:10<43:31,51.49it/s] 27%|##6       |46824/173481[15:00<43:26,48.59it/s] 27%|##7       |47324/173481[15:10<43:16,48.59it/s] 32%|###2      |55715/173481[18:00<40:03,48.99it/s] 32%|###2      |56240/173481[18:10<39:53,48.99it/s] 37%|###7      |64929/173481[21:00<36:08,50.06it/s] 38%|###7      |65534/173481[21:11<35:56,50.06it/s] 43%|####3     |74904/173481[24:00<31:13,52.60it/s] 44%|####3     |75514/173481[24:11<31:02,52.60it/s] 49%|####8     |84784/173481[27:00<27:31,53.72it/s] 49%|####9     |85329/173481[27:11<27:20,53.72it/s] 55%|#####4    |94705/173481[30:00<24:08,54.40it/s] 55%|#####4    |95361/173481[30:11<23:56,54.40it/s] 60%|######    |104614/173481[33:00<20:58,54.72it/s] 61%|######    |105274/173481[33:11<20:46,54.72it/s] 66%|######5   |114392/173481[36:00<18:03,54.52it/s] 66%|######6   |114919/173481[36:11<17:54,54.52it/s] 71%|#######1  |123452/173481[39:00<15:55,52.34it/s] 72%|#######1  |124043/173481[39:12<15:44,52.34it/s] 76%|#######6  |132406/173481[42:00<13:25,51.01it/s] 77%|#######6  |133042/173481[42:12<13:12,51.01it/s] 81%|########1 |141370/173481[45:00<10:37,50.39it/s] 82%|########1 |141969/173481[45:12<10:25,50.39it/s] 87%|########6 |150264/173481[48:00<07:45,49.90it/s] 87%|########6 |150877/173481[48:12<07:33,49.90it/s] 92%|#########1|159319/173481[51:00<04:42,50.10it/s] 92%|#########2|159964/173481[51:12<04:29,50.10it/s] 97%|#########6|168190/173481[54:00<01:46,49.68it/s] 97%|#########7|168785/173481[54:12<01:34,49.68it/s]100%|##########|173481/173481[55:44<00:00,51.87it/s]
[32m[0324 19:51:41 @base.py:257][0m Epoch 43 (global_step 7286202) finished, time:3344.42 sec.
[32m[0324 19:51:42 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-7286202.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:38<00:00,118.51it/s]
41
[32m[0324 19:54:21 @monitor.py:363][0m QueueInput/queue_size: 0.31431
[32m[0324 19:54:21 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.634
[32m[0324 19:54:21 @monitor.py:363][0m activation-summaries/output-rms: 0.041794
[32m[0324 19:54:21 @monitor.py:363][0m cross_entropy_loss: 1.5285
[32m[0324 19:54:21 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59247
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 19:54:21 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 19:54:21 @monitor.py:363][0m train-error-top1: 0.4114
[32m[0324 19:54:21 @monitor.py:363][0m val-error-top1: 0.4199
[32m[0324 19:54:21 @monitor.py:363][0m val-utt-error: 0.092711
[32m[0324 19:54:21 @monitor.py:363][0m validation_cost: 1.5651
[32m[0324 19:54:21 @monitor.py:363][0m wd_cost: 2.2495e-10
[32m[0324 19:54:21 @group.py:42][0m Callbacks took 159.021 sec in total. InferenceRunner: 158.847sec
[32m[0324 19:54:21 @base.py:247][0m Start Epoch 44 ...
  0%|          |0/173481[00:00<?,?it/s]  5%|5         |9198/173481[03:00<53:34,51.10it/s]  6%|5         |9751/173481[03:10<53:24,51.10it/s] 11%|#         |18659/173481[06:00<49:47,51.82it/s] 11%|#1        |19178/173481[06:10<49:37,51.82it/s] 16%|#5        |27129/173481[09:00<49:27,49.32it/s] 16%|#5        |27593/173481[09:10<49:17,49.32it/s] 20%|##        |35129/173481[12:00<49:19,46.75it/s] 21%|##        |35593/173481[12:10<49:09,46.75it/s] 25%|##4       |43278/173481[15:00<47:10,46.00it/s] 25%|##5       |43791/173481[15:10<46:59,46.00it/s] 30%|##9       |51609/173481[18:00<44:02,46.13it/s] 30%|###       |52145/173481[18:10<43:50,46.13it/s] 35%|###4      |60182/173481[21:00<40:17,46.87it/s] 35%|###4      |60668/173481[21:11<40:07,46.87it/s] 40%|###9      |69144/173481[24:00<36:01,48.27it/s] 40%|####      |69712/173481[24:11<35:49,48.27it/s] 45%|####5     |78769/173481[27:00<31:06,50.74it/s] 46%|####5     |79250/173481[27:11<30:57,50.74it/s] 51%|#####     |87695/173481[30:00<28:30,50.16it/s] 51%|#####     |88303/173481[30:11<28:18,50.16it/s] 56%|#####5    |96777/173481[33:00<25:24,50.31it/s] 56%|#####6    |97324/173481[33:11<25:13,50.31it/s] 61%|######    |105654/173481[36:00<22:41,49.80it/s] 61%|######1   |106252/173481[36:11<22:29,49.80it/s] 66%|######6   |114680/173481[39:00<19:36,49.97it/s] 66%|######6   |115303/173481[39:12<19:24,49.97it/s] 71%|#######1  |123704/173481[42:00<16:34,50.05it/s] 72%|#######1  |124313/173481[42:12<16:22,50.05it/s] 77%|#######6  |132972/173481[45:00<13:18,50.76it/s] 77%|#######7  |133625/173481[45:12<13:05,50.76it/s] 82%|########2 |142604/173481[48:00<09:52,52.09it/s] 83%|########2 |143258/173481[48:12<09:40,52.09it/s] 88%|########7 |152167/173481[51:00<06:45,52.60it/s] 88%|########8 |152798/173481[51:12<06:33,52.60it/s] 93%|#########3|161544/173481[54:00<03:48,52.34it/s] 93%|#########3|162200/173481[54:12<03:35,52.34it/s] 99%|#########8|171100/173481[57:00<00:45,52.71it/s] 99%|#########9|171773/173481[57:13<00:32,52.71it/s]100%|##########|173481/173481[57:46<00:00,50.04it/s]
[32m[0324 20:52:07 @base.py:257][0m Epoch 44 (global_step 7459683) finished, time:3466.83 sec.
[32m[0324 20:52:08 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-7459683.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:34<00:00,121.48it/s]
42
[32m[0324 20:54:43 @monitor.py:363][0m QueueInput/queue_size: 0.082666
[32m[0324 20:54:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.446
[32m[0324 20:54:43 @monitor.py:363][0m activation-summaries/output-rms: 0.04201
[32m[0324 20:54:43 @monitor.py:363][0m cross_entropy_loss: 1.5377
[32m[0324 20:54:43 @monitor.py:363][0m lr: 3.0518e-08
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59231
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 20:54:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 20:54:43 @monitor.py:363][0m train-error-top1: 0.42341
[32m[0324 20:54:43 @monitor.py:363][0m val-error-top1: 0.41988
[32m[0324 20:54:43 @monitor.py:363][0m val-utt-error: 0.093401
[32m[0324 20:54:43 @monitor.py:363][0m validation_cost: 1.5634
[32m[0324 20:54:43 @monitor.py:363][0m wd_cost: 2.2491e-10
[32m[0324 20:54:43 @group.py:42][0m Callbacks took 155.272 sec in total. InferenceRunner: 154.955sec
[32m[0324 20:54:43 @base.py:247][0m Start Epoch 45 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|5         |10235/173481[03:00<47:51,56.86it/s]  6%|6         |10722/173481[03:10<47:42,56.86it/s] 11%|#1        |19087/173481[06:00<48:47,52.74it/s] 11%|#1        |19537/173481[06:10<48:38,52.74it/s] 16%|#6        |28508/173481[09:00<45:59,52.53it/s] 17%|#6        |29087/173481[09:10<45:48,52.53it/s] 22%|##2       |38299/173481[12:00<42:09,53.45it/s] 22%|##2       |38905/173481[12:10<41:57,53.45it/s] 28%|##7       |48561/173481[15:00<37:44,55.17it/s] 28%|##8       |49133/173481[15:10<37:33,55.17it/s] 34%|###3      |58628/173481[18:00<34:27,55.54it/s] 34%|###4      |59257/173481[18:10<34:16,55.54it/s] 40%|###9      |69280/173481[21:00<30:18,57.30it/s] 40%|####      |69913/173481[21:11<30:07,57.30it/s] 46%|####5     |79737/173481[24:00<27:04,57.69it/s] 46%|####6     |80395/173481[24:11<26:53,57.69it/s] 52%|#####1    |90153/173481[27:00<24:02,57.77it/s] 52%|#####2    |90791/173481[27:11<23:51,57.77it/s] 58%|#####7    |100443/173481[30:00<21:10,57.47it/s] 58%|#####8    |101262/173481[30:11<20:56,57.47it/s] 64%|######4   |111079/173481[33:00<17:50,58.27it/s] 64%|######4   |111797/173481[33:11<17:38,58.27it/s] 70%|#######   |121649/173481[36:00<14:46,58.49it/s] 70%|#######   |122301/173481[36:11<14:34,58.49it/s] 76%|#######6  |132360/173481[39:00<11:37,58.99it/s] 77%|#######6  |133077/173481[39:12<11:24,58.99it/s] 82%|########2 |143029/173481[42:00<08:35,59.13it/s] 83%|########2 |143689/173481[42:12<08:23,59.13it/s] 88%|########8 |153420/173481[45:00<05:43,58.42it/s] 89%|########8 |154152/173481[45:12<05:30,58.42it/s] 94%|#########4|163610/173481[48:00<02:51,57.50it/s] 95%|#########4|164267/173481[48:12<02:40,57.50it/s]100%|#########9|173338/173481[51:00<00:02,55.72it/s][32m[0324 21:45:45 @base.py:257][0m Epoch 45 (global_step 7633164) finished, time:3062.85 sec.
100%|##########|173481/173481[51:02<00:00,56.64it/s]
[32m[0324 21:45:46 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-7633164.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:32<00:00,123.40it/s]
43
[32m[0324 21:48:18 @monitor.py:363][0m QueueInput/queue_size: 0.18271
[32m[0324 21:48:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.331
[32m[0324 21:48:18 @monitor.py:363][0m activation-summaries/output-rms: 0.041881
[32m[0324 21:48:18 @monitor.py:363][0m cross_entropy_loss: 1.531
[32m[0324 21:48:18 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59221
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 21:48:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 21:48:18 @monitor.py:363][0m train-error-top1: 0.42364
[32m[0324 21:48:18 @monitor.py:363][0m val-error-top1: 0.41995
[32m[0324 21:48:18 @monitor.py:363][0m val-utt-error: 0.092923
[32m[0324 21:48:18 @monitor.py:363][0m validation_cost: 1.5649
[32m[0324 21:48:18 @monitor.py:363][0m wd_cost: 2.2489e-10
[32m[0324 21:48:18 @group.py:42][0m Callbacks took 152.819 sec in total. InferenceRunner: 152.558sec
[32m[0324 21:48:18 @base.py:247][0m Start Epoch 46 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10662/173481[03:00<45:48,59.23it/s]  6%|6         |11216/173481[03:10<45:39,59.23it/s] 12%|#2        |21113/173481[06:00<43:18,58.64it/s] 12%|#2        |21608/173481[06:10<43:10,58.64it/s] 18%|#7        |30711/173481[09:00<42:36,55.85it/s] 18%|#8        |31296/173481[09:10<42:25,55.85it/s] 24%|##3       |41550/173481[12:00<37:56,57.95it/s] 24%|##4       |42220/173481[12:10<37:45,57.95it/s] 30%|###       |52320/173481[15:00<34:17,58.88it/s] 31%|###       |52924/173481[15:10<34:07,58.88it/s] 36%|###6      |63007/173481[18:00<31:08,59.12it/s] 37%|###6      |63686/173481[18:11<30:57,59.12it/s] 42%|####2     |73652/173481[21:00<28:08,59.13it/s] 43%|####2     |74325/173481[21:11<27:57,59.13it/s] 49%|####8     |84485/173481[24:00<24:51,59.65it/s] 49%|####9     |85159/173481[24:11<24:40,59.65it/s] 55%|#####4    |95257/173481[27:00<21:49,59.75it/s] 55%|#####5    |95962/173481[27:11<21:37,59.75it/s] 61%|######1   |106121/173481[30:00<18:41,60.05it/s] 62%|######1   |106821/173481[30:11<18:30,60.05it/s] 67%|######7   |116661/173481[33:00<15:58,59.29it/s] 68%|######7   |117220/173481[33:11<15:48,59.29it/s] 73%|#######3  |127417/173481[36:00<12:53,59.52it/s] 74%|#######3  |128064/173481[36:11<12:43,59.52it/s] 80%|#######9  |138078/173481[39:00<09:56,59.37it/s] 80%|#######9  |138766/173481[39:12<09:44,59.37it/s] 86%|########5 |148897/173481[42:00<06:51,59.73it/s] 86%|########6 |149638/173481[42:12<06:39,59.73it/s] 92%|#########1|159559/173481[45:00<03:54,59.48it/s] 92%|#########2|160268/173481[45:12<03:42,59.48it/s] 98%|#########8|170360/173481[48:00<00:52,59.74it/s] 99%|#########8|171036/173481[48:12<00:40,59.74it/s][32m[0324 22:37:16 @base.py:257][0m Epoch 46 (global_step 7806645) finished, time:2937.90 sec.
100%|##########|173481/173481[48:57<00:00,59.05it/s]
[32m[0324 22:37:16 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-7806645.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:36<00:00,120.43it/s]
44
[32m[0324 22:39:53 @monitor.py:363][0m QueueInput/queue_size: 0.84328
[32m[0324 22:39:53 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.446
[32m[0324 22:39:53 @monitor.py:363][0m activation-summaries/output-rms: 0.042513
[32m[0324 22:39:53 @monitor.py:363][0m cross_entropy_loss: 1.5226
[32m[0324 22:39:53 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59218
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 22:39:53 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 22:39:53 @monitor.py:363][0m train-error-top1: 0.41038
[32m[0324 22:39:53 @monitor.py:363][0m val-error-top1: 0.42021
[32m[0324 22:39:53 @monitor.py:363][0m val-utt-error: 0.094464
[32m[0324 22:39:53 @monitor.py:363][0m validation_cost: 1.5654
[32m[0324 22:39:53 @monitor.py:363][0m wd_cost: 4.4976e-11
[32m[0324 22:39:53 @group.py:42][0m Callbacks took 156.484 sec in total. InferenceRunner: 156.305sec
[32m[0324 22:39:53 @base.py:247][0m Start Epoch 47 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11398/173481[03:00<42:39,63.31it/s]  7%|6         |11972/173481[03:10<42:30,63.31it/s] 13%|#2        |21936/173481[06:00<41:31,60.83it/s] 13%|#2        |22520/173481[06:10<41:21,60.83it/s] 19%|#8        |32125/173481[09:00<40:10,58.64it/s] 19%|#8        |32722/173481[09:10<40:00,58.64it/s] 24%|##4       |42022/173481[12:00<38:36,56.75it/s] 25%|##4       |42635/173481[12:10<38:25,56.75it/s] 30%|###       |52156/173481[15:00<35:46,56.53it/s] 30%|###       |52780/173481[15:10<35:35,56.53it/s] 36%|###6      |62607/173481[18:00<32:15,57.28it/s] 36%|###6      |63229/173481[18:11<32:04,57.28it/s] 42%|####1     |72828/173481[21:00<29:24,57.03it/s] 42%|####2     |73426/173481[21:11<29:14,57.03it/s] 48%|####7     |82914/173481[24:00<26:42,56.53it/s] 48%|####8     |83574/173481[24:11<26:30,56.53it/s] 54%|#####3    |92976/173481[27:00<23:52,56.21it/s] 54%|#####3    |93610/173481[27:11<23:40,56.21it/s] 59%|#####9    |102916/173481[30:00<21:06,55.70it/s] 60%|#####9    |103570/173481[30:11<20:55,55.70it/s] 65%|######5   |112980/173481[33:00<18:04,55.81it/s] 65%|######5   |113623/173481[33:11<17:52,55.81it/s] 71%|#######   |123089/173481[36:00<15:00,55.98it/s] 71%|#######1  |123732/173481[36:11<14:48,55.98it/s] 77%|#######6  |133258/173481[39:00<11:55,56.24it/s] 77%|#######7  |133945/173481[39:12<11:43,56.24it/s] 83%|########2 |143651/173481[42:00<08:43,56.97it/s] 83%|########3 |144345/173481[42:12<08:31,56.97it/s] 89%|########8 |153692/173481[45:00<05:51,56.37it/s] 89%|########9 |154449/173481[45:12<05:37,56.37it/s] 94%|#########4|163689/173481[48:00<02:55,55.95it/s] 95%|#########4|164380/173481[48:12<02:42,55.95it/s][32m[0324 23:30:49 @base.py:257][0m Epoch 47 (global_step 7980126) finished, time:3056.51 sec.
100%|##########|173481/173481[50:56<00:00,56.76it/s]
[32m[0324 23:30:49 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-7980126.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:35<00:00,121.43it/s]
45
[32m[0324 23:33:25 @monitor.py:363][0m QueueInput/queue_size: 0.16061
[32m[0324 23:33:25 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.296
[32m[0324 23:33:25 @monitor.py:363][0m activation-summaries/output-rms: 0.042026
[32m[0324 23:33:25 @monitor.py:363][0m cross_entropy_loss: 1.5369
[32m[0324 23:33:25 @monitor.py:363][0m lr: 1.5259e-08
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59215
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0324 23:33:25 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0324 23:33:25 @monitor.py:363][0m train-error-top1: 0.41454
[32m[0324 23:33:25 @monitor.py:363][0m val-error-top1: 0.41992
[32m[0324 23:33:25 @monitor.py:363][0m val-utt-error: 0.093933
[32m[0324 23:33:25 @monitor.py:363][0m validation_cost: 1.5647
[32m[0324 23:33:25 @monitor.py:363][0m wd_cost: 4.4974e-11
[32m[0324 23:33:25 @group.py:42][0m Callbacks took 155.330 sec in total. InferenceRunner: 155.011sec
[32m[0324 23:33:25 @base.py:247][0m Start Epoch 48 ...
  0%|          |0/173481[00:00<?,?it/s]  6%|6         |10870/173481[03:00<44:57,60.29it/s]  7%|6         |11598/173481[03:20<44:45,60.29it/s] 12%|#1        |20790/173481[06:00<44:12,57.58it/s] 13%|#2        |21917/173481[06:20<43:52,57.58it/s] 18%|#7        |30710/173481[09:00<42:15,56.31it/s] 18%|#8        |31250/173481[09:10<42:05,56.31it/s] 23%|##2       |39725/173481[12:00<42:03,53.00it/s] 23%|##3       |40267/173481[12:10<41:53,53.00it/s] 28%|##8       |49040/173481[15:00<39:36,52.36it/s] 29%|##8       |49569/173481[15:10<39:26,52.36it/s] 34%|###4      |59043/173481[18:00<35:22,53.92it/s] 34%|###4      |59639/173481[18:10<35:11,53.92it/s] 40%|###9      |68852/173481[21:00<32:10,54.20it/s] 40%|####      |69493/173481[21:11<31:58,54.20it/s] 45%|####5     |78900/173481[24:00<28:39,54.99it/s] 46%|####5     |79489/173481[24:11<28:29,54.99it/s] 51%|#####1    |89075/173481[27:00<25:14,55.74it/s] 52%|#####1    |89669/173481[27:11<25:03,55.74it/s] 57%|#####7    |99155/173481[30:00<22:10,55.87it/s] 58%|#####7    |99774/173481[30:11<21:59,55.87it/s] 63%|######2   |109250/173481[33:00<19:07,55.97it/s] 63%|######3   |109869/173481[33:11<18:56,55.97it/s] 69%|######8   |119235/173481[36:00<16:13,55.72it/s] 69%|######9   |119845/173481[36:11<16:02,55.72it/s] 74%|#######4  |129121/173481[39:00<13:21,55.32it/s] 75%|#######4  |129777/173481[39:12<13:10,55.32it/s] 80%|########  |139040/173481[42:00<10:23,55.20it/s] 81%|########  |139680/173481[42:12<10:12,55.20it/s] 86%|########5 |149111/173481[45:00<07:18,55.57it/s] 86%|########6 |149749/173481[45:12<07:07,55.57it/s] 92%|#########1|159120/173481[48:00<04:18,55.58it/s] 92%|#########2|159789/173481[48:12<04:06,55.58it/s] 98%|#########7|169305/173481[51:00<01:14,56.07it/s] 98%|#########7|169964/173481[51:12<01:02,56.07it/s]100%|##########|173481/173481[52:13<00:00,55.36it/s][32m[0325 00:25:38 @base.py:257][0m Epoch 48 (global_step 8153607) finished, time:3133.96 sec.

[32m[0325 00:25:39 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-8153607.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.80it/s]
46
[32m[0325 00:27:39 @monitor.py:363][0m QueueInput/queue_size: 0.34545
[32m[0325 00:27:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.594
[32m[0325 00:27:39 @monitor.py:363][0m activation-summaries/output-rms: 0.041781
[32m[0325 00:27:39 @monitor.py:363][0m cross_entropy_loss: 1.5284
[32m[0325 00:27:39 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 00:27:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 00:27:39 @monitor.py:363][0m train-error-top1: 0.41145
[32m[0325 00:27:39 @monitor.py:363][0m val-error-top1: 0.41989
[32m[0325 00:27:39 @monitor.py:363][0m val-utt-error: 0.092551
[32m[0325 00:27:39 @monitor.py:363][0m validation_cost: 1.565
[32m[0325 00:27:39 @monitor.py:363][0m wd_cost: 4.4974e-11
[32m[0325 00:27:39 @group.py:42][0m Callbacks took 120.502 sec in total. InferenceRunner: 120.048sec
[32m[0325 00:27:39 @base.py:247][0m Start Epoch 49 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12600/173481[03:00<38:18,70.00it/s]  8%|7         |13198/173481[03:10<38:09,70.00it/s] 13%|#3        |23299/173481[06:00<38:56,64.29it/s] 14%|#3        |23838/173481[06:10<38:47,64.29it/s] 19%|#8        |32504/173481[09:00<41:15,56.94it/s] 19%|#8        |32698/173481[09:10<41:12,56.94it/s] 24%|##4       |42204/173481[12:00<39:31,55.37it/s] 25%|##4       |42753/173481[12:10<39:21,55.37it/s] 30%|##9       |51964/173481[15:00<36:58,54.77it/s] 30%|###       |52545/173481[15:10<36:47,54.77it/s] 36%|###5      |62316/173481[18:00<33:01,56.11it/s] 36%|###6      |62948/173481[18:10<32:49,56.11it/s] 42%|####2     |73254/173481[21:00<28:37,58.34it/s] 43%|####2     |73946/173481[21:11<28:25,58.34it/s] 49%|####8     |84307/173481[24:00<24:50,59.84it/s] 49%|####8     |84972/173481[24:11<24:39,59.84it/s] 55%|#####4    |95202/173481[27:00<21:40,60.18it/s] 55%|#####5    |95918/173481[27:11<21:28,60.18it/s] 61%|######1   |106319/173481[30:00<18:21,60.95it/s] 62%|######1   |107028/173481[30:11<18:10,60.95it/s] 68%|######7   |117508/173481[33:00<15:09,61.55it/s] 68%|######8   |118203/173481[33:11<14:58,61.55it/s] 74%|#######4  |128509/173481[36:00<12:13,61.33it/s] 74%|#######4  |129208/173481[36:11<12:01,61.33it/s] 81%|########  |139819/173481[39:00<09:02,62.07it/s] 81%|########1 |140548/173481[39:12<08:50,62.07it/s] 87%|########7 |151046/173481[42:00<06:00,62.22it/s] 87%|########7 |151747/173481[42:12<05:49,62.22it/s] 93%|#########3|161774/173481[45:00<03:12,60.88it/s] 94%|#########3|162451/173481[45:12<03:01,60.88it/s] 99%|#########9|172431/173481[48:00<00:17,60.03it/s]100%|#########9|173128/173481[48:12<00:05,60.03it/s][32m[0325 01:15:57 @base.py:257][0m Epoch 49 (global_step 8327088) finished, time:2898.32 sec.
100%|##########|173481/173481[48:18<00:00,59.86it/s]
[32m[0325 01:15:58 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-8327088.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:40<00:00,116.98it/s]
47
[32m[0325 01:18:39 @monitor.py:363][0m QueueInput/queue_size: 0.21224
[32m[0325 01:18:39 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.42
[32m[0325 01:18:39 @monitor.py:363][0m activation-summaries/output-rms: 0.042005
[32m[0325 01:18:39 @monitor.py:363][0m cross_entropy_loss: 1.5377
[32m[0325 01:18:39 @monitor.py:363][0m lr: 7.6294e-09
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 01:18:39 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 01:18:39 @monitor.py:363][0m train-error-top1: 0.42333
[32m[0325 01:18:39 @monitor.py:363][0m val-error-top1: 0.41987
[32m[0325 01:18:39 @monitor.py:363][0m val-utt-error: 0.093295
[32m[0325 01:18:39 @monitor.py:363][0m validation_cost: 1.5634
[32m[0325 01:18:39 @monitor.py:363][0m wd_cost: 8.9947e-12
[32m[0325 01:18:39 @group.py:42][0m Callbacks took 161.327 sec in total. InferenceRunner: 160.916sec
[32m[0325 01:18:39 @base.py:247][0m Start Epoch 50 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11599/173481[03:00<41:52,64.44it/s]  7%|7         |12191/173481[03:10<41:43,64.44it/s] 12%|#2        |21438/173481[06:00<42:50,59.14it/s] 13%|#2        |22037/173481[06:10<42:40,59.14it/s] 18%|#8        |31782/173481[09:00<40:30,58.29it/s] 19%|#8        |32392/173481[09:10<40:20,58.29it/s] 25%|##4       |42883/173481[12:00<36:19,59.93it/s] 25%|##5       |43572/173481[12:10<36:07,59.93it/s] 31%|###1      |54225/173481[15:00<32:21,61.43it/s] 32%|###1      |54797/173481[15:10<32:11,61.43it/s] 37%|###7      |64341/173481[18:00<30:59,58.70it/s] 37%|###7      |64981/173481[18:10<30:48,58.70it/s] 43%|####2     |74585/173481[21:00<28:31,57.79it/s] 43%|####3     |75237/173481[21:11<28:20,57.79it/s] 49%|####8     |84975/173481[24:00<25:32,57.76it/s] 49%|####9     |85633/173481[24:11<25:21,57.76it/s] 55%|#####4    |95408/173481[27:00<22:29,57.86it/s] 55%|#####5    |96085/173481[27:11<22:17,57.86it/s] 61%|######1   |105950/173481[30:00<19:20,58.21it/s] 61%|######1   |106588/173481[30:11<19:09,58.21it/s] 67%|######7   |116256/173481[33:00<16:31,57.72it/s] 67%|######7   |116912/173481[33:11<16:19,57.72it/s] 73%|#######3  |126713/173481[36:00<13:27,57.91it/s] 73%|#######3  |127396/173481[36:11<13:15,57.91it/s] 79%|#######9  |137118/173481[39:00<10:28,57.86it/s] 79%|#######9  |137822/173481[39:12<10:16,57.86it/s] 85%|########5 |147652/173481[42:00<07:23,58.19it/s] 86%|########5 |148377/173481[42:12<07:11,58.19it/s] 91%|#########1|158015/173481[45:00<04:27,57.88it/s] 91%|#########1|158719/173481[45:12<04:15,57.88it/s] 97%|#########6|168198/173481[48:00<01:32,57.22it/s] 97%|#########7|168891/173481[48:12<01:20,57.22it/s][32m[0325 02:08:17 @base.py:257][0m Epoch 50 (global_step 8500569) finished, time:2978.48 sec.
100%|##########|173481/173481[49:38<00:00,58.24it/s]
[32m[0325 02:08:17 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-8500569.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:40<00:00,117.26it/s]
48
[32m[0325 02:10:58 @monitor.py:363][0m QueueInput/queue_size: 0.36919
[32m[0325 02:10:58 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.314
[32m[0325 02:10:58 @monitor.py:363][0m activation-summaries/output-rms: 0.041879
[32m[0325 02:10:58 @monitor.py:363][0m cross_entropy_loss: 1.5311
[32m[0325 02:10:58 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 02:10:58 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 02:10:58 @monitor.py:363][0m train-error-top1: 0.42486
[32m[0325 02:10:58 @monitor.py:363][0m val-error-top1: 0.41997
[32m[0325 02:10:58 @monitor.py:363][0m val-utt-error: 0.092658
[32m[0325 02:10:58 @monitor.py:363][0m validation_cost: 1.5649
[32m[0325 02:10:58 @monitor.py:363][0m wd_cost: 8.9947e-12
[32m[0325 02:10:58 @group.py:42][0m Callbacks took 160.803 sec in total. InferenceRunner: 160.538sec
[32m[0325 02:10:58 @base.py:247][0m Start Epoch 51 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|6         |11751/173481[03:00<41:17,65.28it/s]  7%|7         |12338/173481[03:10<41:08,65.28it/s] 13%|#2        |21909/173481[06:00<41:43,60.53it/s] 13%|#2        |22469/173481[06:10<41:34,60.53it/s] 18%|#8        |31777/173481[09:00<41:02,57.54it/s] 19%|#8        |32396/173481[09:10<40:52,57.54it/s] 24%|##4       |42063/173481[12:00<38:12,57.33it/s] 25%|##4       |42686/173481[12:10<38:01,57.33it/s] 30%|###       |52486/173481[15:00<35:00,57.61it/s] 31%|###       |53078/173481[15:10<34:49,57.61it/s] 36%|###6      |62592/173481[18:00<32:29,56.87it/s] 36%|###6      |63232/173481[18:11<32:18,56.87it/s] 42%|####1     |72730/173481[21:00<29:40,56.59it/s] 42%|####2     |73395/173481[21:11<29:28,56.59it/s] 48%|####7     |82807/173481[24:00<26:51,56.28it/s] 48%|####8     |83405/173481[24:11<26:40,56.28it/s] 54%|#####3    |92827/173481[27:00<24:01,55.97it/s] 54%|#####3    |93415/173481[27:11<23:50,55.97it/s] 59%|#####8    |102168/173481[30:00<22:04,53.85it/s] 59%|#####9    |102991/173481[30:11<21:48,53.85it/s] 65%|######4   |112699/173481[33:00<18:03,56.08it/s] 65%|######5   |113403/173481[33:11<17:51,56.08it/s] 71%|#######   |123110/173481[36:00<14:44,56.95it/s] 71%|#######1  |123812/173481[36:12<14:32,56.95it/s] 77%|#######6  |133370/173481[39:00<11:44,56.97it/s] 77%|#######7  |134075/173481[39:12<11:31,56.97it/s] 83%|########3 |144202/173481[42:00<08:20,58.53it/s] 84%|########3 |144983/173481[42:12<08:06,58.53it/s] 90%|########9 |155750/173481[45:00<04:49,61.21it/s] 90%|######### |156515/173481[45:12<04:37,61.21it/s] 96%|#########5|166354/173481[48:00<01:58,60.04it/s] 96%|#########6|167034/173481[48:12<01:47,60.04it/s]100%|##########|173481/173481[50:03<00:00,57.75it/s]
[32m[0325 03:01:02 @base.py:257][0m Epoch 51 (global_step 8674050) finished, time:3004.00 sec.
[32m[0325 03:01:02 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-8674050.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:53<00:00,108.78it/s]
49
[32m[0325 03:03:55 @monitor.py:363][0m QueueInput/queue_size: 0.054721
[32m[0325 03:03:55 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.435
[32m[0325 03:03:55 @monitor.py:363][0m activation-summaries/output-rms: 0.042513
[32m[0325 03:03:55 @monitor.py:363][0m cross_entropy_loss: 1.5226
[32m[0325 03:03:55 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 03:03:55 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 03:03:55 @monitor.py:363][0m train-error-top1: 0.41075
[32m[0325 03:03:55 @monitor.py:363][0m val-error-top1: 0.42021
[32m[0325 03:03:55 @monitor.py:363][0m val-utt-error: 0.094464
[32m[0325 03:03:55 @monitor.py:363][0m validation_cost: 1.5653
[32m[0325 03:03:55 @monitor.py:363][0m wd_cost: 1.7989e-12
[32m[0325 03:03:55 @group.py:42][0m Callbacks took 173.325 sec in total. InferenceRunner: 173.054sec
[32m[0325 03:03:55 @base.py:247][0m Start Epoch 52 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |14256/173481[03:00<33:30,79.20it/s]  9%|8         |15007/173481[03:10<33:21,79.20it/s] 16%|#5        |27128/173481[06:00<32:27,75.16it/s] 16%|#5        |27755/173481[06:10<32:18,75.16it/s] 22%|##1       |37857/173481[09:00<33:59,66.48it/s] 22%|##2       |38476/173481[09:10<33:50,66.48it/s] 28%|##8       |48661/173481[12:00<32:58,63.08it/s] 28%|##8       |49296/173481[12:10<32:48,63.08it/s] 34%|###4      |59580/173481[15:00<30:41,61.84it/s] 35%|###4      |60224/173481[15:10<30:31,61.84it/s] 41%|####      |70714/173481[18:00<27:41,61.85it/s] 41%|####1     |71330/173481[18:10<27:31,61.85it/s] 47%|####6     |81181/173481[21:00<25:39,59.94it/s] 47%|####7     |81841/173481[21:11<25:28,59.94it/s] 53%|#####2    |91741/173481[24:00<22:58,59.30it/s] 53%|#####3    |92397/173481[24:11<22:47,59.30it/s] 59%|#####9    |102383/173481[27:00<20:00,59.21it/s] 59%|#####9    |103064/173481[27:11<19:49,59.21it/s] 65%|######5   |112973/173481[30:00<17:05,59.02it/s] 66%|######5   |113652/173481[30:11<16:53,59.02it/s] 71%|#######1  |123362/173481[33:00<14:18,58.36it/s] 72%|#######1  |124058/173481[33:11<14:06,58.36it/s] 77%|#######7  |134041/173481[36:00<11:10,58.83it/s] 78%|#######7  |134742/173481[36:12<10:58,58.83it/s] 84%|########3 |144886/173481[39:00<08:00,59.52it/s] 84%|########3 |145570/173481[39:12<07:48,59.52it/s] 90%|########9 |155269/173481[42:00<05:10,58.59it/s] 90%|########9 |155984/173481[42:12<04:58,58.59it/s] 95%|#########5|165653/173481[45:00<02:14,58.13it/s] 96%|#########5|166373/173481[45:12<02:02,58.13it/s][32m[0325 03:51:08 @base.py:257][0m Epoch 52 (global_step 8847531) finished, time:2832.79 sec.
100%|##########|173481/173481[47:12<00:00,61.24it/s]
[32m[0325 03:51:08 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-8847531.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:54<00:00,107.95it/s]
50
[32m[0325 03:54:03 @monitor.py:363][0m QueueInput/queue_size: 0.10992
[32m[0325 03:54:03 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.29
[32m[0325 03:54:03 @monitor.py:363][0m activation-summaries/output-rms: 0.042026
[32m[0325 03:54:03 @monitor.py:363][0m cross_entropy_loss: 1.5369
[32m[0325 03:54:03 @monitor.py:363][0m lr: 3.8147e-09
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 03:54:03 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 03:54:03 @monitor.py:363][0m train-error-top1: 0.41473
[32m[0325 03:54:03 @monitor.py:363][0m val-error-top1: 0.41991
[32m[0325 03:54:03 @monitor.py:363][0m val-utt-error: 0.093826
[32m[0325 03:54:03 @monitor.py:363][0m validation_cost: 1.5647
[32m[0325 03:54:03 @monitor.py:363][0m wd_cost: 1.7989e-12
[32m[0325 03:54:03 @group.py:42][0m Callbacks took 174.916 sec in total. InferenceRunner: 174.399sec
[32m[0325 03:54:03 @base.py:247][0m Start Epoch 53 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13025/173481[03:00<36:57,72.35it/s]  8%|7         |13857/173481[03:10<36:46,72.35it/s] 15%|#4        |25835/173481[06:00<34:17,71.75it/s] 15%|#5        |26414/173481[06:10<34:09,71.75it/s] 21%|##        |35925/173481[09:00<36:25,62.93it/s] 21%|##1       |36497/173481[09:10<36:16,62.93it/s] 26%|##6       |45787/173481[12:00<36:20,58.57it/s] 27%|##6       |46393/173481[12:10<36:09,58.57it/s] 32%|###2      |56023/173481[15:00<33:55,57.70it/s] 33%|###2      |56654/173481[15:10<33:44,57.70it/s] 38%|###8      |66111/173481[18:00<31:28,56.86it/s] 38%|###8      |66757/173481[18:11<31:16,56.86it/s] 44%|####4     |76745/173481[21:00<27:49,57.95it/s] 45%|####4     |77409/173481[21:11<27:37,57.95it/s] 50%|#####     |87249/173481[24:00<24:43,58.15it/s] 51%|#####     |87903/173481[24:11<24:31,58.15it/s] 57%|#####6    |98021/173481[27:00<21:19,58.98it/s] 57%|#####6    |98675/173481[27:11<21:08,58.98it/s] 63%|######2   |108665/173481[30:00<18:17,59.06it/s] 63%|######3   |109313/173481[30:11<18:06,59.06it/s] 69%|######8   |119266/173481[33:00<15:19,58.97it/s] 69%|######9   |119944/173481[33:11<15:07,58.97it/s] 75%|#######4  |129650/173481[36:00<12:31,58.32it/s] 75%|#######5  |130315/173481[36:11<12:20,58.32it/s] 81%|########  |140162/173481[39:00<09:30,58.36it/s] 81%|########1 |140844/173481[39:12<09:19,58.36it/s] 87%|########6 |150894/173481[42:00<06:22,58.98it/s] 87%|########7 |151637/173481[42:12<06:10,58.98it/s] 93%|#########3|161708/173481[45:00<03:17,59.52it/s] 94%|#########3|162370/173481[45:12<03:06,59.52it/s] 99%|#########9|172235/173481[48:00<00:21,58.99it/s]100%|#########9|172909/173481[48:12<00:09,58.99it/s]100%|##########|173481/173481[48:22<00:00,59.76it/s]
[32m[0325 04:42:26 @base.py:257][0m Epoch 53 (global_step 9021012) finished, time:2902.88 sec.
[32m[0325 04:42:26 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-9021012.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:38<00:00,118.77it/s]
51
[32m[0325 04:45:05 @monitor.py:363][0m QueueInput/queue_size: 0.084157
[32m[0325 04:45:05 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.59
[32m[0325 04:45:05 @monitor.py:363][0m activation-summaries/output-rms: 0.041781
[32m[0325 04:45:05 @monitor.py:363][0m cross_entropy_loss: 1.5284
[32m[0325 04:45:05 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 04:45:05 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 04:45:05 @monitor.py:363][0m train-error-top1: 0.41145
[32m[0325 04:45:05 @monitor.py:363][0m val-error-top1: 0.41989
[32m[0325 04:45:05 @monitor.py:363][0m val-utt-error: 0.092445
[32m[0325 04:45:05 @monitor.py:363][0m validation_cost: 1.5649
[32m[0325 04:45:05 @monitor.py:363][0m wd_cost: 1.7989e-12
[32m[0325 04:45:05 @group.py:42][0m Callbacks took 158.737 sec in total. InferenceRunner: 158.496sec
[32m[0325 04:45:05 @base.py:247][0m Start Epoch 54 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13780/173481[03:00<34:46,76.55it/s]  8%|8         |14568/173481[03:10<34:35,76.55it/s] 15%|#4        |25669/173481[06:00<34:44,70.91it/s] 15%|#5        |26228/173481[06:10<34:36,70.91it/s] 21%|##        |35743/173481[09:00<36:41,62.55it/s] 21%|##        |36364/173481[09:10<36:31,62.55it/s] 26%|##6       |45853/173481[12:00<35:56,59.19it/s] 27%|##6       |46493/173481[12:10<35:45,59.19it/s] 32%|###2      |56279/173481[15:00<33:22,58.54it/s] 33%|###2      |56923/173481[15:10<33:11,58.54it/s] 39%|###8      |67379/173481[18:00<29:26,60.06it/s] 39%|###9      |68033/173481[18:10<29:15,60.06it/s] 45%|####5     |78269/173481[21:00<26:19,60.28it/s] 46%|####5     |78977/173481[21:11<26:07,60.28it/s] 52%|#####1    |89725/173481[24:00<22:32,61.91it/s] 52%|#####2    |90420/173481[24:11<22:21,61.91it/s] 58%|#####8    |100947/173481[27:00<19:27,62.12it/s] 59%|#####8    |101643/173481[27:11<19:16,62.12it/s] 65%|######4   |112259/173481[30:00<16:19,62.48it/s] 65%|######5   |112983/173481[30:11<16:08,62.48it/s] 71%|#######1  |123560/173481[33:00<13:17,62.63it/s] 72%|#######1  |124248/173481[33:11<13:06,62.63it/s] 78%|#######7  |135075/173481[36:00<10:06,63.29it/s] 78%|#######8  |135823/173481[36:11<09:54,63.29it/s] 85%|########4 |146758/173481[39:00<06:56,64.09it/s] 85%|########5 |147527/173481[39:12<06:44,64.09it/s] 92%|#########2|159657/173481[42:00<03:24,67.66it/s] 93%|#########2|160688/173481[42:12<03:09,67.66it/s]100%|##########|173481/173481[44:36<00:00,64.81it/s]
[32m[0325 05:29:42 @base.py:257][0m Epoch 54 (global_step 9194493) finished, time:2676.94 sec.
[32m[0325 05:29:42 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-9194493.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:02<00:00,154.09it/s]
52
[32m[0325 05:31:44 @monitor.py:363][0m QueueInput/queue_size: 0.64819
[32m[0325 05:31:44 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.417
[32m[0325 05:31:44 @monitor.py:363][0m activation-summaries/output-rms: 0.042005
[32m[0325 05:31:44 @monitor.py:363][0m cross_entropy_loss: 1.5378
[32m[0325 05:31:44 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 05:31:44 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 05:31:44 @monitor.py:363][0m train-error-top1: 0.42338
[32m[0325 05:31:44 @monitor.py:363][0m val-error-top1: 0.41987
[32m[0325 05:31:44 @monitor.py:363][0m val-utt-error: 0.093348
[32m[0325 05:31:44 @monitor.py:363][0m validation_cost: 1.5633
[32m[0325 05:31:44 @monitor.py:363][0m wd_cost: 3.5979e-13
[32m[0325 05:31:44 @group.py:42][0m Callbacks took 122.392 sec in total. InferenceRunner: 122.172sec
[32m[0325 05:31:44 @base.py:247][0m Start Epoch 55 ...
  0%|          |0/173481[00:00<?,?it/s] 10%|9         |17208/173481[03:00<27:14,95.60it/s] 10%|#         |18119/173481[03:10<27:05,95.60it/s] 19%|#9        |33282/173481[06:00<25:18,92.34it/s] 20%|#9        |34203/173481[06:10<25:08,92.34it/s] 28%|##8       |49202/173481[09:00<22:55,90.35it/s] 29%|##8       |50134/173481[09:10<22:45,90.35it/s] 38%|###7      |65227/173481[12:00<20:07,89.68it/s] 38%|###8      |66181/173481[12:10<19:56,89.68it/s] 45%|####4     |77870/173481[15:00<20:13,78.78it/s] 45%|####5     |78557/173481[15:10<20:04,78.78it/s] 52%|#####1    |89423/173481[18:00<19:48,70.73it/s] 52%|#####1    |90157/173481[18:10<19:38,70.73it/s] 58%|#####8    |101048/173481[21:00<17:52,67.51it/s] 59%|#####8    |101755/173481[21:11<17:42,67.51it/s] 65%|######4   |112002/173481[24:00<16:00,64.01it/s] 65%|######4   |112632/173481[24:11<15:50,64.01it/s] 71%|#######   |123021/173481[27:00<13:26,62.58it/s] 71%|#######1  |123703/173481[27:11<13:15,62.58it/s] 77%|#######7  |134355/173481[30:00<10:23,62.77it/s] 78%|#######7  |135030/173481[30:11<10:12,62.77it/s] 84%|########3 |145288/173481[33:00<07:36,61.73it/s] 84%|########4 |145987/173481[33:11<07:25,61.73it/s] 90%|########9 |155943/173481[36:00<04:50,60.43it/s] 90%|######### |156642/173481[36:11<04:38,60.43it/s] 96%|#########6|167108/173481[39:00<01:44,61.21it/s] 97%|#########6|167858/173481[39:12<01:31,61.21it/s]100%|##########|173481/173481[40:52<00:00,70.75it/s]
[32m[0325 06:12:36 @base.py:257][0m Epoch 55 (global_step 9367974) finished, time:2452.11 sec.
[32m[0325 06:12:36 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-9367974.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:53<00:00,165.21it/s]
53
[32m[0325 06:14:30 @monitor.py:363][0m QueueInput/queue_size: 0.14063
[32m[0325 06:14:30 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.313
[32m[0325 06:14:30 @monitor.py:363][0m activation-summaries/output-rms: 0.04188
[32m[0325 06:14:30 @monitor.py:363][0m cross_entropy_loss: 1.531
[32m[0325 06:14:30 @monitor.py:363][0m lr: 1.9073e-09
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 06:14:30 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 06:14:30 @monitor.py:363][0m train-error-top1: 0.42478
[32m[0325 06:14:30 @monitor.py:363][0m val-error-top1: 0.41996
[32m[0325 06:14:30 @monitor.py:363][0m val-utt-error: 0.092658
[32m[0325 06:14:30 @monitor.py:363][0m validation_cost: 1.5649
[32m[0325 06:14:30 @monitor.py:363][0m wd_cost: 3.5979e-13
[32m[0325 06:14:30 @group.py:42][0m Callbacks took 114.166 sec in total. InferenceRunner: 113.952sec
[32m[0325 06:14:30 @base.py:247][0m Start Epoch 56 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12302/173481[03:00<39:18,68.33it/s]  7%|7         |12931/173481[03:10<39:09,68.33it/s] 13%|#3        |22804/173481[06:00<39:53,62.95it/s] 13%|#3        |23411/173481[06:10<39:44,62.95it/s] 20%|#9        |34447/173481[09:00<36:19,63.79it/s] 20%|##        |35076/173481[09:10<36:09,63.79it/s] 27%|##6       |46297/173481[12:00<32:42,64.79it/s] 27%|##7       |46957/173481[12:10<32:32,64.79it/s] 34%|###3      |58484/173481[15:00<28:56,66.22it/s] 34%|###4      |59146/173481[15:10<28:46,66.22it/s] 40%|####      |69697/173481[18:00<26:56,64.19it/s] 41%|####      |70416/173481[18:10<26:45,64.19it/s] 47%|####7     |81767/173481[21:00<23:18,65.58it/s] 48%|####7     |82455/173481[21:11<23:07,65.58it/s] 54%|#####4    |94058/173481[24:00<19:47,66.90it/s] 55%|#####4    |94732/173481[24:11<19:37,66.90it/s] 61%|######1   |106352/173481[27:00<16:33,67.59it/s] 62%|######1   |107139/173481[27:11<16:21,67.59it/s] 68%|######8   |118596/173481[30:00<13:29,67.81it/s] 69%|######8   |119345/173481[30:11<13:18,67.81it/s] 75%|#######5  |130337/173481[33:00<10:48,66.49it/s] 76%|#######5  |131086/173481[33:11<10:37,66.49it/s] 82%|########1 |141763/173481[36:00<08:08,64.95it/s] 82%|########2 |142546/173481[36:11<07:56,64.95it/s] 89%|########8 |154092/173481[39:00<04:50,66.66it/s] 89%|########9 |155005/173481[39:12<04:37,66.66it/s] 96%|#########5|165763/173481[42:00<01:57,65.74it/s] 96%|#########5|166411/173481[42:12<01:47,65.74it/s]100%|##########|173481/173481[44:11<00:00,65.43it/s]
[32m[0325 06:58:42 @base.py:257][0m Epoch 56 (global_step 9541455) finished, time:2651.52 sec.
[32m[0325 06:58:42 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-9541455.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:01<00:00,155.17it/s]
54
[32m[0325 07:00:43 @monitor.py:363][0m QueueInput/queue_size: 0.11523
[32m[0325 07:00:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.434
[32m[0325 07:00:43 @monitor.py:363][0m activation-summaries/output-rms: 0.042513
[32m[0325 07:00:43 @monitor.py:363][0m cross_entropy_loss: 1.5226
[32m[0325 07:00:43 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 07:00:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 07:00:43 @monitor.py:363][0m train-error-top1: 0.41097
[32m[0325 07:00:43 @monitor.py:363][0m val-error-top1: 0.4202
[32m[0325 07:00:43 @monitor.py:363][0m val-utt-error: 0.094464
[32m[0325 07:00:43 @monitor.py:363][0m validation_cost: 1.5653
[32m[0325 07:00:43 @monitor.py:363][0m wd_cost: 3.5979e-13
[32m[0325 07:00:43 @group.py:42][0m Callbacks took 121.465 sec in total. InferenceRunner: 121.317sec
[32m[0325 07:00:43 @base.py:247][0m Start Epoch 57 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13997/173481[03:00<34:11,77.76it/s]  8%|8         |14682/173481[03:10<34:02,77.76it/s] 15%|#4        |26015/173481[06:00<34:12,71.84it/s] 15%|#5        |26706/173481[06:10<34:02,71.84it/s] 22%|##1       |37409/173481[09:00<33:41,67.30it/s] 22%|##1       |38065/173481[09:10<33:32,67.30it/s] 28%|##7       |48276/173481[12:00<32:47,63.64it/s] 28%|##8       |48905/173481[12:10<32:37,63.64it/s] 34%|###3      |58914/173481[15:00<31:09,61.28it/s] 34%|###4      |59572/173481[15:10<30:58,61.28it/s] 40%|####      |69957/173481[18:00<28:08,61.31it/s] 41%|####      |70603/173481[18:10<27:57,61.31it/s] 47%|####6     |80720/173481[21:00<25:32,60.54it/s] 47%|####6     |81396/173481[21:11<25:20,60.54it/s] 53%|#####2    |91501/173481[24:00<22:41,60.21it/s] 53%|#####3    |92150/173481[24:11<22:30,60.21it/s] 59%|#####8    |102141/173481[27:00<19:55,59.66it/s] 59%|#####9    |102792/173481[27:11<19:44,59.66it/s] 65%|######5   |112864/173481[30:00<16:56,59.61it/s] 65%|######5   |113550/173481[30:11<16:45,59.61it/s] 71%|#######   |123079/173481[33:00<14:26,58.14it/s] 72%|#######1  |124150/173481[33:11<14:08,58.14it/s] 78%|#######7  |134457/173481[36:00<10:44,60.57it/s] 78%|#######7  |135158/173481[36:11<10:32,60.57it/s] 84%|########3 |145406/173481[39:00<07:42,60.69it/s] 84%|########4 |146096/173481[39:12<07:31,60.69it/s] 90%|########9 |156016/173481[42:00<04:52,59.80it/s] 90%|######### |156721/173481[42:12<04:40,59.80it/s] 96%|#########6|166766/173481[45:00<01:52,59.76it/s] 97%|#########6|167494/173481[45:12<01:40,59.76it/s]100%|##########|173481/173481[46:49<00:00,61.75it/s]
[32m[0325 07:47:33 @base.py:257][0m Epoch 57 (global_step 9714936) finished, time:2809.50 sec.
[32m[0325 07:47:33 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-9714936.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:00<00:00,156.75it/s]
55
[32m[0325 07:49:33 @monitor.py:363][0m QueueInput/queue_size: 0.77433
[32m[0325 07:49:33 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.29
[32m[0325 07:49:33 @monitor.py:363][0m activation-summaries/output-rms: 0.042026
[32m[0325 07:49:33 @monitor.py:363][0m cross_entropy_loss: 1.5368
[32m[0325 07:49:33 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 07:49:33 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 07:49:33 @monitor.py:363][0m train-error-top1: 0.41473
[32m[0325 07:49:33 @monitor.py:363][0m val-error-top1: 0.41992
[32m[0325 07:49:33 @monitor.py:363][0m val-utt-error: 0.093826
[32m[0325 07:49:33 @monitor.py:363][0m validation_cost: 1.5647
[32m[0325 07:49:33 @monitor.py:363][0m wd_cost: 7.1957e-14
[32m[0325 07:49:33 @group.py:42][0m Callbacks took 120.330 sec in total. InferenceRunner: 120.092sec
[32m[0325 07:49:33 @base.py:247][0m Start Epoch 58 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|7         |13139/173481[03:00<36:36,72.99it/s]  8%|7         |13769/173481[03:10<36:28,72.99it/s] 14%|#3        |24125/173481[06:00<37:26,66.47it/s] 14%|#4        |24741/173481[06:10<37:17,66.47it/s] 20%|#9        |34655/173481[09:00<37:11,62.22it/s] 20%|##        |35199/173481[09:10<37:02,62.22it/s] 26%|##5       |44621/173481[12:00<36:39,58.59it/s] 26%|##6       |45214/173481[12:10<36:29,58.59it/s] 32%|###1      |54877/173481[15:00<34:13,57.77it/s] 32%|###1      |55503/173481[15:10<34:02,57.77it/s] 38%|###7      |65390/173481[18:00<31:01,58.08it/s] 38%|###8      |66004/173481[18:10<30:50,58.08it/s] 44%|####3     |75922/173481[21:00<27:53,58.29it/s] 44%|####4     |76549/173481[21:11<27:42,58.29it/s] 50%|####9     |86473/173481[24:00<24:48,58.45it/s] 50%|#####     |87132/173481[24:11<24:37,58.45it/s] 56%|#####6    |97246/173481[27:00<21:29,59.14it/s] 56%|#####6    |97921/173481[27:11<21:17,59.14it/s] 62%|######2   |107965/173481[30:00<18:24,59.34it/s] 63%|######2   |108595/173481[30:11<18:13,59.34it/s] 68%|######8   |118308/173481[33:00<15:44,58.38it/s] 69%|######8   |118935/173481[33:11<15:34,58.38it/s] 74%|#######4  |128460/173481[36:00<13:04,57.37it/s] 74%|#######4  |129124/173481[36:11<12:53,57.37it/s] 80%|#######9  |138685/173481[39:00<10:09,57.09it/s] 80%|########  |139338/173481[39:12<09:58,57.09it/s] 86%|########5 |149153/173481[42:00<07:02,57.62it/s] 86%|########6 |149864/173481[42:12<06:49,57.62it/s] 92%|#########2|159760/173481[45:00<03:55,58.26it/s] 92%|#########2|160404/173481[45:12<03:44,58.26it/s] 98%|#########8|170209/173481[48:00<00:56,58.15it/s] 99%|#########8|170909/173481[48:12<00:44,58.15it/s]100%|##########|173481/173481[48:57<00:00,59.06it/s]
[32m[0325 08:38:30 @base.py:257][0m Epoch 58 (global_step 9888417) finished, time:2937.43 sec.
[32m[0325 08:38:31 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-9888417.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.81it/s]
56
[32m[0325 08:40:34 @monitor.py:363][0m QueueInput/queue_size: 0.035932
[32m[0325 08:40:34 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.59
[32m[0325 08:40:34 @monitor.py:363][0m activation-summaries/output-rms: 0.041781
[32m[0325 08:40:34 @monitor.py:363][0m cross_entropy_loss: 1.5283
[32m[0325 08:40:34 @monitor.py:363][0m lr: 9.5367e-10
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 08:40:34 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 08:40:34 @monitor.py:363][0m train-error-top1: 0.41162
[32m[0325 08:40:34 @monitor.py:363][0m val-error-top1: 0.41989
[32m[0325 08:40:34 @monitor.py:363][0m val-utt-error: 0.092392
[32m[0325 08:40:34 @monitor.py:363][0m validation_cost: 1.5649
[32m[0325 08:40:34 @monitor.py:363][0m wd_cost: 7.1957e-14
[32m[0325 08:40:34 @group.py:42][0m Callbacks took 123.313 sec in total. InferenceRunner: 123.184sec
[32m[0325 08:40:34 @base.py:247][0m Start Epoch 59 ...
  0%|          |0/173481[00:00<?,?it/s]  7%|7         |12998/173481[03:00<37:02,72.21it/s]  8%|7         |13588/173481[03:10<36:54,72.21it/s] 14%|#3        |23929/173481[06:00<37:47,65.97it/s] 14%|#4        |24474/173481[06:10<37:38,65.97it/s] 19%|#9        |33515/173481[09:00<39:35,58.93it/s] 20%|#9        |34093/173481[09:10<39:25,58.93it/s] 25%|##5       |43419/173481[12:00<38:05,56.91it/s] 25%|##5       |43988/173481[12:10<37:55,56.91it/s] 31%|###       |53309/173481[15:00<35:49,55.90it/s] 31%|###1      |53913/173481[15:10<35:38,55.90it/s] 37%|###6      |63424/173481[18:00<32:43,56.05it/s] 37%|###6      |64055/173481[18:10<32:32,56.05it/s] 43%|####2     |74289/173481[21:00<28:26,58.12it/s] 43%|####3     |74915/173481[21:11<28:15,58.12it/s] 49%|####9     |85104/173481[24:00<24:55,59.08it/s] 49%|####9     |85799/173481[24:11<24:44,59.08it/s] 55%|#####5    |96009/173481[27:00<21:35,59.82it/s] 56%|#####5    |96688/173481[27:11<21:23,59.82it/s] 61%|######1   |106644/173481[30:00<18:44,59.44it/s] 62%|######1   |107354/173481[30:11<18:32,59.44it/s] 68%|######7   |117903/173481[33:00<15:11,60.95it/s] 68%|######8   |118596/173481[33:11<15:00,60.95it/s] 74%|#######4  |128667/173481[36:00<12:22,60.37it/s] 75%|#######4  |129372/173481[36:11<12:10,60.37it/s] 81%|########  |139906/173481[39:00<09:06,61.39it/s] 81%|########1 |140652/173481[39:12<08:54,61.39it/s] 87%|########7 |151221/173481[42:00<05:58,62.11it/s] 88%|########7 |151991/173481[42:12<05:45,62.11it/s] 94%|#########3|162229/173481[45:00<03:02,61.61it/s] 94%|#########4|163177/173481[45:12<02:47,61.61it/s]100%|##########|173481/173481[47:44<00:00,60.56it/s]
[32m[0325 09:28:18 @base.py:257][0m Epoch 59 (global_step 10061898) finished, time:2864.53 sec.
[32m[0325 09:28:18 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-10061898.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:58<00:00,158.19it/s]
57
[32m[0325 09:30:18 @monitor.py:363][0m QueueInput/queue_size: 0.030108
[32m[0325 09:30:18 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.417
[32m[0325 09:30:18 @monitor.py:363][0m activation-summaries/output-rms: 0.042005
[32m[0325 09:30:18 @monitor.py:363][0m cross_entropy_loss: 1.5377
[32m[0325 09:30:18 @monitor.py:363][0m lr: 4.7684e-10
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 09:30:18 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 09:30:18 @monitor.py:363][0m train-error-top1: 0.42333
[32m[0325 09:30:18 @monitor.py:363][0m val-error-top1: 0.41987
[32m[0325 09:30:18 @monitor.py:363][0m val-utt-error: 0.093295
[32m[0325 09:30:18 @monitor.py:363][0m validation_cost: 1.5634
[32m[0325 09:30:18 @monitor.py:363][0m wd_cost: 7.1957e-14
[32m[0325 09:30:18 @group.py:42][0m Callbacks took 119.236 sec in total. InferenceRunner: 119.001sec
[32m[0325 09:30:18 @base.py:247][0m Start Epoch 60 ...
  0%|          |0/173481[00:00<?,?it/s]  8%|8         |13901/173481[03:00<34:26,77.23it/s]  8%|8         |14574/173481[03:10<34:17,77.23it/s] 14%|#4        |24872/173481[06:00<36:21,68.13it/s] 15%|#4        |25488/173481[06:10<36:12,68.13it/s] 21%|##1       |36528/173481[09:00<34:22,66.40it/s] 21%|##1       |37227/173481[09:10<34:12,66.40it/s] 28%|##8       |48869/173481[12:00<30:47,67.46it/s] 29%|##8       |49661/173481[12:10<30:35,67.46it/s] 35%|###4      |60233/173481[15:00<28:56,65.22it/s] 35%|###5      |60867/173481[15:10<28:46,65.22it/s] 41%|####1     |71533/173481[18:00<26:33,63.97it/s] 42%|####1     |72212/173481[18:10<26:23,63.97it/s] 48%|####7     |82791/173481[21:00<23:53,63.25it/s] 48%|####8     |83490/173481[21:11<23:42,63.25it/s] 54%|#####4    |94095/173481[24:00<20:59,63.02it/s] 55%|#####4    |94798/173481[24:11<20:48,63.02it/s] 61%|######    |105478/173481[27:00<17:57,63.13it/s] 61%|######1   |106201/173481[27:11<17:45,63.13it/s] 67%|######7   |116753/173481[30:00<15:02,62.88it/s] 68%|######7   |117494/173481[30:11<14:50,62.88it/s] 74%|#######3  |128057/173481[33:00<12:02,62.84it/s] 74%|#######4  |128806/173481[33:11<11:50,62.84it/s] 80%|########  |139392/173481[36:00<09:01,62.90it/s] 81%|########  |140075/173481[36:11<08:51,62.90it/s] 86%|########6 |150038/173481[39:00<06:24,60.96it/s] 87%|########6 |150777/173481[39:12<06:12,60.96it/s] 93%|#########3|161408/173481[42:00<03:14,62.04it/s] 94%|#########3|162208/173481[42:12<03:01,62.04it/s] 99%|#########9|172178/173481[45:00<00:21,60.91it/s]100%|#########9|172957/173481[45:12<00:08,60.91it/s]100%|##########|173481/173481[45:21<00:00,63.75it/s]
[32m[0325 10:15:39 @base.py:257][0m Epoch 60 (global_step 10235379) finished, time:2721.26 sec.
[32m[0325 10:15:39 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-10235379.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[02:03<00:00,152.07it/s]
58
[32m[0325 10:17:43 @monitor.py:363][0m QueueInput/queue_size: 0.15769
[32m[0325 10:17:43 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.313
[32m[0325 10:17:43 @monitor.py:363][0m activation-summaries/output-rms: 0.041879
[32m[0325 10:17:43 @monitor.py:363][0m cross_entropy_loss: 1.531
[32m[0325 10:17:43 @monitor.py:363][0m lr: 4.7684e-10
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 10:17:43 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 10:17:43 @monitor.py:363][0m train-error-top1: 0.42485
[32m[0325 10:17:43 @monitor.py:363][0m val-error-top1: 0.41996
[32m[0325 10:17:43 @monitor.py:363][0m val-utt-error: 0.092658
[32m[0325 10:17:43 @monitor.py:363][0m validation_cost: 1.5649
[32m[0325 10:17:43 @monitor.py:363][0m wd_cost: 1.4391e-14
[32m[0325 10:17:43 @group.py:42][0m Callbacks took 123.996 sec in total. InferenceRunner: 123.788sec
[32m[0325 10:17:43 @base.py:247][0m Start Epoch 61 ...
  0%|          |0/173481[00:00<?,?it/s]  9%|9         |16394/173481[03:00<28:44,91.07it/s] 10%|9         |17146/173481[03:10<28:36,91.07it/s] 18%|#7        |30851/173481[06:00<27:51,85.35it/s] 18%|#8        |31664/173481[06:10<27:41,85.35it/s] 26%|##5       |44897/173481[09:00<26:17,81.53it/s] 26%|##6       |45410/173481[09:10<26:10,81.53it/s] 34%|###3      |58529/173481[12:00<24:23,78.52it/s] 34%|###4      |59326/173481[12:10<24:13,78.52it/s] 42%|####1     |72500/173481[15:00<21:33,78.07it/s] 42%|####2     |73304/173481[15:10<21:23,78.07it/s] 50%|####9     |86443/173481[18:00<18:39,77.76it/s] 50%|#####     |87266/173481[18:10<18:28,77.76it/s] 58%|#####8    |101290/173481[21:00<15:01,80.05it/s] 59%|#####8    |102279/173481[21:11<14:49,80.05it/s] 67%|######7   |116836/173481[24:00<11:21,83.09it/s] 68%|######7   |117711/173481[24:11<11:11,83.09it/s] 76%|#######5  |131614/173481[27:00<08:26,82.59it/s] 76%|#######6  |132468/173481[27:11<08:16,82.59it/s] 83%|########3 |144177/173481[30:00<06:27,75.65it/s] 84%|########3 |145001/173481[30:11<06:16,75.65it/s] 91%|######### |157050/173481[33:00<03:43,73.53it/s] 91%|#########1|157872/173481[33:11<03:32,73.53it/s] 97%|#########6|168249/173481[36:00<01:17,67.40it/s] 97%|#########7|168953/173481[36:11<01:07,67.40it/s][32m[0325 10:55:09 @base.py:257][0m Epoch 61 (global_step 10408860) finished, time:2246.55 sec.
100%|##########|173481/173481[37:26<00:00,77.22it/s]
[32m[0325 10:55:09 @saver.py:84][0m Model saved to train_log/fcn1_w_16_a_32_quant_ends_False/model-10408860.
  0%|          |0/18822[00:00<?,?it/s]100%|##########|18822/18822[01:57<00:00,160.37it/s]
59
[32m[0325 10:57:07 @monitor.py:363][0m QueueInput/queue_size: 0.073775
[32m[0325 10:57:07 @monitor.py:363][0m activation-summaries/last_linear/output-rms: 46.434
[32m[0325 10:57:07 @monitor.py:363][0m activation-summaries/output-rms: 0.042513
[32m[0325 10:57:07 @monitor.py:363][0m cross_entropy_loss: 1.5226
[32m[0325 10:57:07 @monitor.py:363][0m lr: 2.3842e-10
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/last_linear/W-rms: 0.59214
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/last_linear/b-rms: 1.283
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/linear0/W-rms: 0.33584
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/linear0/b-rms: 0.087426
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/linear1/W-rms: 0.32297
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/linear1/b-rms: 0.086699
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/linear2/W-rms: 0.2809
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/linear2/b-rms: 0.088422
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/linear3/W-rms: 0.27214
[32m[0325 10:57:07 @monitor.py:363][0m param-summary/linear3/b-rms: 0.088454
[32m[0325 10:57:07 @monitor.py:363][0m train-error-top1: 0.41097
[32m[0325 10:57:07 @monitor.py:363][0m val-error-top1: 0.4202
[32m[0325 10:57:07 @monitor.py:363][0m val-utt-error: 0.094464
[32m[0325 10:57:07 @monitor.py:363][0m validation_cost: 1.5653
[32m[0325 10:57:07 @monitor.py:363][0m wd_cost: 1.4391e-14
[32m[0325 10:57:07 @group.py:42][0m Callbacks took 117.547 sec in total. InferenceRunner: 117.387sec
[32m[0325 10:57:07 @base.py:247][0m Start Epoch 62 ...
  0%|          |0/173481[00:00<?,?it/s]slurmstepd: *** STEP 82596.0 ON sls-titanx-1 CANCELLED AT 2018-03-25T10:57:36 DUE TO TIME LIMIT ***
srun: error: sls-titanx-1: task 0: Terminated
srun: Force Terminated job step 82596.0
