{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorpack as tp\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers.rsr_run import Model\n",
    "from helpers.rsr_run import create_dataflow\n",
    "from helpers.rsr_run import net_fn_map\n",
    "from helpers.rsr2015 import *\n",
    "from tensorpack import *\n",
    "from tensorpack.utils.gpu import get_nr_gpu\n",
    "from tensorpack.tfutils.varmanip import *\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "def avg(w): return sum(w.flatten())/len(w.flatten())\n",
    "\n",
    "def prune(x, prune_rate=0.10):\n",
    "    a = np.copy(x)\n",
    "    nonzero_vals = a[np.nonzero(a)]\n",
    "    sorted_vals = np.sort(np.abs(nonzero_vals).flatten())\n",
    "    split_idx = int(prune_rate * len(sorted_vals))\n",
    "    thres = sorted_vals[split_idx]\n",
    "    a[np.abs(a) < thres] = 0\n",
    "    return a\n",
    "\n",
    "def is_extra_var(var):\n",
    "    return 'Adam' in var or 'global_step' == var or 'EMA' in var or var.startswith('beta') and var.endswith('_power') or 'bits_for_maxval_var' in var\n",
    "\n",
    "def get_new_var_dict(var_dict, prune_rate=0.1, verbose=False):\n",
    "    new_var_dict = {}\n",
    "    ema_stats = set(); bn_vars = set(); kernel_vars = set(); bias_vars = set()\n",
    "    print\n",
    "    \n",
    "    for var in var_dict:\n",
    "        if is_extra_var(var):\n",
    "            new_var_dict[var] = var_dict[var]\n",
    "        elif 'bn' in var:\n",
    "            bn_vars.add(var)\n",
    "        elif var.endswith('/W') or var.endswith('/depthwise_weights'):\n",
    "            kernel_vars.add(var)\n",
    "        elif var.endswith('/b') or var.endswith('/biases'):\n",
    "            bias_vars.add(var)\n",
    "        else:\n",
    "            print(\"Couldn't classify\", var)\n",
    "\n",
    "    for i,var in enumerate(kernel_vars):\n",
    "        if verbose: print(var)\n",
    "        new_var = prune(var_dict[var], prune_rate)\n",
    "        new_var_dict[var] = new_var\n",
    "\n",
    "    for i,var in enumerate(bn_vars):\n",
    "        if verbose: print(var)\n",
    "        new_var = prune(var_dict[var], prune_rate)\n",
    "        new_var_dict[var] = new_var\n",
    "\n",
    "    for i,var in enumerate(bias_vars):\n",
    "        new_var_dict[var] = prune(var_dict[var], prune_rate)\n",
    "    \n",
    "    return new_var_dict, kernel_vars, bn_vars, bias_vars\n",
    "\n",
    "def get_sparsity(var_dict, interesting_vars = None):\n",
    "    zero_count = []\n",
    "    totals = []\n",
    "    if not interesting_vars: interesting_vars = var_dict.keys()\n",
    "    for name in interesting_vars:\n",
    "        if is_extra_var(name): continue\n",
    "        weight = var_dict[name]\n",
    "        zero_count.append(np.count_nonzero(weight==0))\n",
    "        totals.append(np.prod(weight.shape))\n",
    "    return sum(zero_count)/sum(totals), zero_count, totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Outputting to outdir', 'pruned_models/fcn2_32_32_True')\n",
      "\u001b[32m[0329 11:33:28 @logger.py:74]\u001b[0m Argv: /data/sls/u/meng/skanda/home/envs/tf2cpu/lib/python2.7/site-packages/ipykernel_launcher.py -f /run/user/23571/jupyter/kernel-c259bc5e-774d-43a7-ab67-f24d7288948e.json\n"
     ]
    }
   ],
   "source": [
    "model_name='fcn2'; bn = True; reg = False\n",
    "datadir = '/data/sls/scratch/skoppula/kaldi-rsr/numpy/'\n",
    "spkmap = '/data/sls/scratch/skoppula/backup-exps/rsr-experiments/create_rsr_data_cache/generator_full_dataset/spk_mappings.pickle'\n",
    "cachedir = '/data/sls/scratch/skoppula/backup-exps/rsr-experiments/create_rsr_data_cache/trn_cache/context_50frms/'\n",
    "\n",
    "w_bit = 32; a_bit = 32; end = True\n",
    "ckpt_path = '/data/sls/u/meng/skanda/home/thesis/manfxpt/no_bn_models/' + model_name + '/checkpoint'\n",
    "bn_ckpt_path = '/data/sls/u/meng/skanda/home/thesis/manfxpt/models/sentfiltNone_' + model_name + '_bnTrue_regTrue_noLRSchedule/checkpoint'\n",
    "if bn:\n",
    "    ckpt_path = bn_ckpt_path\n",
    "    \n",
    "outdir=os.path.join('pruned_models', '_'.join([str(x) for x in [model_name, w_bit, a_bit, end]]))\n",
    "print(\"Outputting to outdir\", outdir)\n",
    "logger.set_logger_dir(outdir, action='k')\n",
    "context=50\n",
    "n_spks = get_n_spks(spkmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/sls/u/meng/skanda/home/thesis/manfxpt/models/sentfiltNone_fcn2_bnTrue_regTrue_noLRSchedule/checkpoint\n",
      "('whole utterance size', 75290)\n",
      "('val', False, 18822)\n",
      "('On prune rate', 0)\n",
      "\n",
      "('Adding activation tensors to summary:', [<tf.Tensor 'linear0/bn/output:0' shape=(?, 504) dtype=float32>, <tf.Tensor 'linear0/output:0' shape=(?, 504) dtype=float32>, <tf.Tensor 'linear1/bn/output:0' shape=(?, 504) dtype=float32>, <tf.Tensor 'linear1/output:0' shape=(?, 504) dtype=float32>, <tf.Tensor 'linear2/bn/output:0' shape=(?, 504) dtype=float32>, <tf.Tensor 'linear2/output:0' shape=(?, 504) dtype=float32>, <tf.Tensor 'linear3/bn/output:0' shape=(?, 504) dtype=float32>, <tf.Tensor 'linear3/output:0' shape=(?, 504) dtype=float32>, <tf.Tensor 'last_linear/output:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'output:0' shape=(?, 255) dtype=float32>])\n",
      "\u001b[32m[0329 11:34:37 @rsr_run.py:129]\u001b[0m Parameter count: {'mults': 1398600, 'weights': 1398855}\n",
      "\u001b[32m[0329 11:34:37 @sessinit.py:206]\u001b[0m Variables to restore from dict: linear3/bn/beta:0, last_linear/W:0, linear0/bn/beta:0, linear1/W:0, linear1/bn/variance/EMA:0, linear1/bn/mean/EMA:0, linear2/bn/beta:0, linear0/bn/mean/EMA:0, linear1/bn/beta:0, linear3/W:0, linear0/b:0, linear2/W:0, linear3/b:0, linear1/bn/gamma:0, linear0/bn/gamma:0, linear0/bn/variance/EMA:0, linear2/bn/gamma:0, linear2/bn/variance/EMA:0, linear3/bn/gamma:0, linear2/b:0, linear3/bn/variance/EMA:0, linear2/bn/mean/EMA:0, linear3/bn/mean/EMA:0, last_linear/b:0, linear1/b:0, linear0/W:0\n",
      "\u001b[32m[0329 11:34:37 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the dict, but not found in the graph: EMA/QueueInput/queue_size/biased:0, EMA/QueueInput/queue_size/local_step:0, EMA/QueueInput/queue_size:0, EMA/cross_entropy_loss/biased:0, EMA/cross_entropy_loss/local_step:0, EMA/cross_entropy_loss:0, EMA/train-error-top1/biased:0, EMA/train-error-top1/local_step:0, EMA/train-error-top1:0, EMA/wd_cost/biased:0, EMA/wd_cost/local_step:0, EMA/wd_cost:0, beta1_power:0, beta2_power:0, global_step:0, last_linear/W/Adam:0, last_linear/W/Adam_1:0, last_linear/b/Adam:0, last_linear/b/Adam_1:0, linear0/W/Adam:0, linear0/W/Adam_1:0, linear0/b/Adam:0, linear0/b/Adam_1:0, linear0/bn/beta/Adam:0, linear0/bn/beta/Adam_1:0, linear0/bn/gamma/Adam:0, linear0/bn/gamma/Adam_1:0, linear1/W/Adam:0, linear1/W/Adam_1:0, linear1/b/Adam:0, linear1/b/Adam_1:0, linear1/bn/beta/Adam:0, linear1/bn/beta/Adam_1:0, linear1/bn/gamma/Adam:0, linear1/bn/gamma/Adam_1:0, linear2/W/Adam:0, linear2/W/Adam_1:0, linear2/b/Adam:0, linear2/b/Adam_1:0, linear2/bn/beta/Adam:0, linear2/bn/beta/Adam_1:0, linear2/bn/gamma/Adam:0, linear2/bn/gamma/Adam_1:0, linear3/W/Adam:0, linear3/W/Adam_1:0, linear3/b/Adam:0, linear3/b/Adam_1:0, linear3/bn/beta/Adam:0, linear3/bn/beta/Adam_1:0, linear3/bn/gamma/Adam:0, linear3/bn/gamma/Adam_1:0\n",
      "\u001b[32m[0329 11:34:37 @sessinit.py:219]\u001b[0m Restoring from dict ...\n",
      "0\n",
      "('On', 0, 'of', 18822, 'error:', array([0.]))\n",
      "('On', 100, 'of', 18822, 'error:', array([0.02970297]))\n",
      "('On', 200, 'of', 18822, 'error:', array([0.02985075]))\n"
     ]
    }
   ],
   "source": [
    "prune_rates = [0, 0.25, 0.75]\n",
    "errors = []\n",
    "sparsities = []\n",
    "print(ckpt_path)\n",
    "\n",
    "for i, prune_rate in enumerate(prune_rates):\n",
    "    \n",
    "    val_dataflow, n_batches_val = create_dataflow('val', None, datadir, spkmap, None, context)\n",
    "    val_generator = val_dataflow.get_data()\n",
    "    \n",
    "    print(\"On prune rate\", prune_rate)\n",
    "    var_dict = load_chkpt_vars(ckpt_path)\n",
    "    new_var_dict, _, _, _ = get_new_var_dict(var_dict, prune_rate)\n",
    "    sparsities.append(get_sparsity(new_var_dict))\n",
    "\n",
    "    model = Model(n_spks, net_fn_map[model_name], bn=bn, reg=False, n_context=context)\n",
    "\n",
    "    config = PredictConfig(\n",
    "            model=model,\n",
    "            session_init=DictRestore(new_var_dict),\n",
    "            input_names=['input', 'label'],\n",
    "            output_names=['utt-wrong']# ['utt-wrong']\n",
    "    )\n",
    "    predictor = OfflinePredictor(config)\n",
    "\n",
    "    rc = tp.utils.stats.RatioCounter()\n",
    "    for i in range(n_batches_val):\n",
    "        x,y = next(val_generator)\n",
    "        outputs, = predictor([x,y])\n",
    "        rc.feed(outputs,1)\n",
    "        if i % 100 == 0:\n",
    "            print(\"On\",i,\"of\",n_batches_val, \"error:\", rc.ratio)\n",
    "        if i == 700: break\n",
    "    print(\"error\", rc.ratio)\n",
    "    errors.append(rc.ratio[0])\n",
    "print(errors)\n",
    "print(sparsities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
